{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63975476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "from training_code import *\n",
    "from load_data import initialize_test\n",
    "from reading_datasets import read_test\n",
    "from labels_to_ids import task5_labels_to_ids\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba41d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"results_dev_version2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6ab332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>True_label</th>\n",
       "      <th>xlm-roberta-base3prediction</th>\n",
       "      <th>bert-base-spanish-wwm-cased-overandunder2prediction</th>\n",
       "      <th>bert-base-spanish-wwm-cased4prediction</th>\n",
       "      <th>bert-base-spanish-wwm-uncased4prediction</th>\n",
       "      <th>bert-base-multilingual-cased-overandunder1prediction</th>\n",
       "      <th>bert-base-multilingual-cased4prediction</th>\n",
       "      <th>bert-base-multilingual-uncased-overandunder3prediction</th>\n",
       "      <th>bert-base-multilingual-uncased-extremepositive0prediction</th>\n",
       "      <th>bert-base-multilingual-uncased_oversampled3prediction</th>\n",
       "      <th>bert-base-multilingual-uncased0prediction</th>\n",
       "      <th>majority_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>301284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>100251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>103444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>104896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>102665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  True_label  xlm-roberta-base3prediction  \\\n",
       "0       100460           0                            0   \n",
       "1       301908           1                            1   \n",
       "2       300889           1                            1   \n",
       "3       101501           0                            0   \n",
       "4       105013           0                            0   \n",
       "...        ...         ...                          ...   \n",
       "2006    301284           1                            1   \n",
       "2007    100251           0                            0   \n",
       "2008    103444           0                            0   \n",
       "2009    104896           0                            0   \n",
       "2010    102665           0                            0   \n",
       "\n",
       "      bert-base-spanish-wwm-cased-overandunder2prediction  \\\n",
       "0                                                     0     \n",
       "1                                                     2     \n",
       "2                                                     1     \n",
       "3                                                     0     \n",
       "4                                                     1     \n",
       "...                                                 ...     \n",
       "2006                                                  1     \n",
       "2007                                                  0     \n",
       "2008                                                  0     \n",
       "2009                                                  0     \n",
       "2010                                                  0     \n",
       "\n",
       "      bert-base-spanish-wwm-cased4prediction  \\\n",
       "0                                          0   \n",
       "1                                          2   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          1   \n",
       "...                                      ...   \n",
       "2006                                       1   \n",
       "2007                                       0   \n",
       "2008                                       0   \n",
       "2009                                       0   \n",
       "2010                                       0   \n",
       "\n",
       "      bert-base-spanish-wwm-uncased4prediction  \\\n",
       "0                                            0   \n",
       "1                                            2   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            2   \n",
       "...                                        ...   \n",
       "2006                                         0   \n",
       "2007                                         0   \n",
       "2008                                         0   \n",
       "2009                                         0   \n",
       "2010                                         0   \n",
       "\n",
       "      bert-base-multilingual-cased-overandunder1prediction  \\\n",
       "0                                                     0      \n",
       "1                                                     1      \n",
       "2                                                     1      \n",
       "3                                                     0      \n",
       "4                                                     1      \n",
       "...                                                 ...      \n",
       "2006                                                  1      \n",
       "2007                                                  0      \n",
       "2008                                                  1      \n",
       "2009                                                  1      \n",
       "2010                                                  0      \n",
       "\n",
       "      bert-base-multilingual-cased4prediction  \\\n",
       "0                                           0   \n",
       "1                                           2   \n",
       "2                                           1   \n",
       "3                                           0   \n",
       "4                                           1   \n",
       "...                                       ...   \n",
       "2006                                        1   \n",
       "2007                                        0   \n",
       "2008                                        0   \n",
       "2009                                        0   \n",
       "2010                                        0   \n",
       "\n",
       "      bert-base-multilingual-uncased-overandunder3prediction  \\\n",
       "0                                                     0        \n",
       "1                                                     2        \n",
       "2                                                     1        \n",
       "3                                                     0        \n",
       "4                                                     1        \n",
       "...                                                 ...        \n",
       "2006                                                  1        \n",
       "2007                                                  0        \n",
       "2008                                                  0        \n",
       "2009                                                  0        \n",
       "2010                                                  0        \n",
       "\n",
       "      bert-base-multilingual-uncased-extremepositive0prediction  \\\n",
       "0                                                     0           \n",
       "1                                                     2           \n",
       "2                                                     1           \n",
       "3                                                     0           \n",
       "4                                                     1           \n",
       "...                                                 ...           \n",
       "2006                                                  1           \n",
       "2007                                                  0           \n",
       "2008                                                  0           \n",
       "2009                                                  2           \n",
       "2010                                                  0           \n",
       "\n",
       "      bert-base-multilingual-uncased_oversampled3prediction  \\\n",
       "0                                                     0       \n",
       "1                                                     2       \n",
       "2                                                     1       \n",
       "3                                                     0       \n",
       "4                                                     2       \n",
       "...                                                 ...       \n",
       "2006                                                  1       \n",
       "2007                                                  0       \n",
       "2008                                                  0       \n",
       "2009                                                  0       \n",
       "2010                                                  0       \n",
       "\n",
       "      bert-base-multilingual-uncased0prediction  majority_label  \n",
       "0                                             0               0  \n",
       "1                                             2               2  \n",
       "2                                             0               1  \n",
       "3                                             0               0  \n",
       "4                                             0               1  \n",
       "...                                         ...             ...  \n",
       "2006                                          1               1  \n",
       "2007                                          0               0  \n",
       "2008                                          0               0  \n",
       "2009                                          0               0  \n",
       "2010                                          0               0  \n",
       "\n",
       "[2011 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f214d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186c4abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'True_label', 'xlm-roberta-base3prediction',\n",
       "       'bert-base-spanish-wwm-cased-overandunder2prediction',\n",
       "       'bert-base-spanish-wwm-cased4prediction',\n",
       "       'bert-base-spanish-wwm-uncased4prediction',\n",
       "       'bert-base-multilingual-cased-overandunder1prediction',\n",
       "       'bert-base-multilingual-cased4prediction',\n",
       "       'bert-base-multilingual-uncased-overandunder3prediction',\n",
       "       'bert-base-multilingual-uncased-extremepositive0prediction',\n",
       "       'bert-base-multilingual-uncased_oversampled3prediction',\n",
       "       'bert-base-multilingual-uncased0prediction', 'majority_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27a3a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['xlm-roberta-base3prediction',\n",
    "       'bert-base-spanish-wwm-cased-overandunder2prediction',\n",
    "       'bert-base-spanish-wwm-cased4prediction',\n",
    "       'bert-base-spanish-wwm-uncased4prediction',\n",
    "       'bert-base-multilingual-cased-overandunder1prediction',\n",
    "       'bert-base-multilingual-cased4prediction',\n",
    "       'bert-base-multilingual-uncased-overandunder3prediction',\n",
    "       'bert-base-multilingual-uncased-extremepositive0prediction',\n",
    "       'bert-base-multilingual-uncased_oversampled3prediction',\n",
    "       'bert-base-multilingual-uncased0prediction', 'majority_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1af9b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model:xlm-roberta-base3prediction ------------------------------------------------------\n",
      "Accuracy: 0.8493286921929388\n",
      "Precision: 0.6818181818181818\n",
      "recall: 0.8284883720930233\n",
      "F1 Score: 0.748031496062992\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-spanish-wwm-cased-overandunder2prediction ------------------------------------------------------\n",
      "Accuracy: 0.8180009945300846\n",
      "Precision: 0.6322067594433399\n",
      "recall: 0.9244186046511628\n",
      "F1 Score: 0.7508854781582054\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-spanish-wwm-cased4prediction ------------------------------------------------------\n",
      "Accuracy: 0.8249627051218299\n",
      "Precision: 0.6475770925110133\n",
      "recall: 0.8546511627906976\n",
      "F1 Score: 0.7368421052631579\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-spanish-wwm-uncased4prediction ------------------------------------------------------\n",
      "Accuracy: 0.8324216807558429\n",
      "Precision: 0.6439232409381663\n",
      "recall: 0.877906976744186\n",
      "F1 Score: 0.7429274292742928\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-cased-overandunder1prediction ------------------------------------------------------\n",
      "Accuracy: 0.7956240676280457\n",
      "Precision: 0.6824644549763034\n",
      "recall: 0.8372093023255814\n",
      "F1 Score: 0.751958224543081\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-cased4prediction ------------------------------------------------------\n",
      "Accuracy: 0.8368970661362506\n",
      "Precision: 0.6580645161290323\n",
      "recall: 0.8895348837209303\n",
      "F1 Score: 0.7564894932014833\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-uncased-overandunder3prediction ------------------------------------------------------\n",
      "Accuracy: 0.825957235206365\n",
      "Precision: 0.6387755102040816\n",
      "recall: 0.9098837209302325\n",
      "F1 Score: 0.750599520383693\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-uncased-extremepositive0prediction ------------------------------------------------------\n",
      "Accuracy: 0.8000994530084535\n",
      "Precision: 0.6363636363636364\n",
      "recall: 0.936046511627907\n",
      "F1 Score: 0.7576470588235295\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-uncased_oversampled3prediction ------------------------------------------------------\n",
      "Accuracy: 0.7966185977125808\n",
      "Precision: 0.6448202959830867\n",
      "recall: 0.8866279069767442\n",
      "F1 Score: 0.7466340269277846\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:bert-base-multilingual-uncased0prediction ------------------------------------------------------\n",
      "Accuracy: 0.8513177523620089\n",
      "Precision: 0.687793427230047\n",
      "recall: 0.8517441860465116\n",
      "F1 Score: 0.7610389610389611\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Metrics for model:majority_label ------------------------------------------------------\n",
      "Accuracy: 0.8463451019393337\n",
      "Precision: 0.670995670995671\n",
      "recall: 0.9011627906976745\n",
      "F1 Score: 0.7692307692307693\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print('Metrics for model:' + model + ' ------------------------------------------------------')\n",
    "    \n",
    "    accuracy = accuracy_score(df['True_label'], df[model])\n",
    "    print( f'Accuracy: {accuracy}')\n",
    "\n",
    "    precision = precision_score(df['True_label'], df[model], labels=[0,1,2], average = None, zero_division=0)[2]\n",
    "    print( f'Precision: {precision}')\n",
    "\n",
    "    recall = recall_score(df['True_label'], df[model], labels=[0,1,2], average = None, zero_division=0)[2]\n",
    "    print( f'recall: {recall}')\n",
    "\n",
    "    f1 = f1_score(df['True_label'], df[model], labels=[0,1,2], average = None, zero_division=0)[2]\n",
    "    print( f'F1 Score: {f1}')\n",
    "    print('------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c22046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
