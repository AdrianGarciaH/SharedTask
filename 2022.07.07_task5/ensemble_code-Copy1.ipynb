{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee5017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertPreTrainedModel, BertConfig, BertModel, BertTokenizer, AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, RandomSampler, Dataset, SequentialSampler\n",
    "\n",
    "from load_data_ensemble import initialize_data\n",
    "from reading_datasets import read_task5\n",
    "from labels_to_ids import task5_labels_to_ids\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a09c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEnsemble(BertPreTrainedModel):\n",
    "  def __init__(self, config, *args, **kwargs):\n",
    "      super().__init__(config)\n",
    "\n",
    "      # model 1\n",
    "      self.bert_model_1 = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=3)\n",
    "      # model 2\n",
    "      self.bert_model_2 = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=3)\n",
    "      # combine the 2 models into 1\n",
    "      self.cls = nn.Linear(6, 3)\n",
    "      self.init_weights()\n",
    "\n",
    "  def forward(\n",
    "          self,\n",
    "          input_ids=None,\n",
    "          attention_mask=None,\n",
    "          token_type_ids=None,\n",
    "          position_ids=None,\n",
    "          head_mask=None,\n",
    "          inputs_embeds=None,\n",
    "          labels=None,\n",
    "  ):\n",
    "    outputs = []\n",
    "    \n",
    "    input_ids_1 = input_ids[0].to(device, dtype = torch.long)\n",
    "    attention_mask_1 = attention_mask[0].to(device, dtype = torch.long)\n",
    "    labels_1 = labels[0].to(device, dtype = torch.long)\n",
    "    outputs.append(self.bert_model_1(input_ids_1,\n",
    "                                     attention_mask=attention_mask_1, labels =labels_1))\n",
    "\n",
    "    input_ids_2 = input_ids[1].to(device, dtype = torch.long)\n",
    "    attention_mask_2 = attention_mask[1].to(device, dtype = torch.long)\n",
    "    labels_2 = labels[1].to(device, dtype = torch.long)\n",
    "    outputs.append(self.bert_model_2(input_ids_2,\n",
    "                                     attention_mask=attention_mask_2, labels =labels_2))\n",
    "    print(outputs)\n",
    "\n",
    "    # just get the [CLS] embeddings\n",
    "    last_hidden_states = torch.cat([output[1] for output in outputs], dim=1)\n",
    "    print(\"Printing last hidden states\")\n",
    "    print(last_hidden_states)\n",
    "    logits = self.cls(last_hidden_states)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6359a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/pyenv/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "config = BertConfig()\n",
    "model = BertEnsemble(config)\n",
    "model.to(device)\n",
    "learning_rate = 1e-05\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [{\n",
    "  \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "  }]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f822e8",
   "metadata": {},
   "source": [
    "# Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2588, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.3483,  0.2485,  0.1671],\n",
      "        [-0.3406, -0.0271, -0.1022],\n",
      "        [-0.4085,  0.2256, -0.0616],\n",
      "        [ 0.0439,  0.0538, -0.0476],\n",
      "        [-0.1109,  0.2911,  0.0754],\n",
      "        [ 0.0512,  0.0462, -0.2173]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(1.2196, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0508,  0.2251, -0.0457],\n",
      "        [-0.1034,  0.2494, -0.1685],\n",
      "        [-0.1249,  0.2395,  0.0141],\n",
      "        [-0.1715,  0.1827, -0.2325],\n",
      "        [-0.2362,  0.3657,  0.0971],\n",
      "        [ 0.0620,  0.1640, -0.3860]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[-0.3483,  0.2485,  0.1671, -0.0508,  0.2251, -0.0457],\n",
      "        [-0.3406, -0.0271, -0.1022, -0.1034,  0.2494, -0.1685],\n",
      "        [-0.4085,  0.2256, -0.0616, -0.1249,  0.2395,  0.0141],\n",
      "        [ 0.0439,  0.0538, -0.0476, -0.1715,  0.1827, -0.2325],\n",
      "        [-0.1109,  0.2911,  0.0754, -0.2362,  0.3657,  0.0971],\n",
      "        [ 0.0512,  0.0462, -0.2173,  0.0620,  0.1640, -0.3860]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:0.0015404546866193414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0715, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.2913,  0.5228,  0.0748],\n",
      "        [ 0.5619,  0.2916,  0.1986],\n",
      "        [ 0.1097,  0.4689, -0.0311],\n",
      "        [ 0.4675,  0.6076, -0.0229],\n",
      "        [ 0.4146,  0.4402,  0.2410],\n",
      "        [ 0.3645,  0.2036,  0.2691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(1.7254, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.5124,  0.6749, -0.2651],\n",
      "        [-0.7199,  0.7692,  0.0454],\n",
      "        [-0.2346,  0.7814, -0.2770],\n",
      "        [-0.7331,  0.8727, -0.1226],\n",
      "        [-0.3268,  0.6203, -0.0553],\n",
      "        [-0.3514,  0.5694, -0.2323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 0.2913,  0.5228,  0.0748, -0.5124,  0.6749, -0.2651],\n",
      "        [ 0.5619,  0.2916,  0.1986, -0.7199,  0.7692,  0.0454],\n",
      "        [ 0.1097,  0.4689, -0.0311, -0.2346,  0.7814, -0.2770],\n",
      "        [ 0.4675,  0.6076, -0.0229, -0.7331,  0.8727, -0.1226],\n",
      "        [ 0.4146,  0.4402,  0.2410, -0.3268,  0.6203, -0.0553],\n",
      "        [ 0.3645,  0.2036,  0.2691, -0.3514,  0.5694, -0.2323]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.028997311368584633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8429, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[1.0571, 0.3925, 0.5855],\n",
      "        [1.2264, 0.5389, 0.5269],\n",
      "        [0.8427, 0.3856, 0.4684],\n",
      "        [1.1575, 0.5050, 0.4318],\n",
      "        [1.2055, 0.7662, 0.6006],\n",
      "        [0.9413, 0.4723, 0.4697]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(1.6595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.7807,  1.0317, -0.3185],\n",
      "        [-0.8799,  1.0416, -0.2341],\n",
      "        [-0.5222,  1.2306, -0.4015],\n",
      "        [-0.5997,  1.1219, -0.3226],\n",
      "        [-1.0414,  1.1979, -0.3368],\n",
      "        [-0.7938,  1.3657, -0.5192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 1.0571,  0.3925,  0.5855, -0.7807,  1.0317, -0.3185],\n",
      "        [ 1.2264,  0.5389,  0.5269, -0.8799,  1.0416, -0.2341],\n",
      "        [ 0.8427,  0.3856,  0.4684, -0.5222,  1.2306, -0.4015],\n",
      "        [ 1.1575,  0.5050,  0.4318, -0.5997,  1.1219, -0.3226],\n",
      "        [ 1.2055,  0.7662,  0.6006, -1.0414,  1.1979, -0.3368],\n",
      "        [ 0.9413,  0.4723,  0.4697, -0.7938,  1.3657, -0.5192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.06892432272434235\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[1.4537, 0.5613, 0.8481],\n",
      "        [1.5198, 0.7175, 0.8103],\n",
      "        [1.3705, 0.9732, 0.8112],\n",
      "        [1.5911, 0.7924, 0.8721],\n",
      "        [1.2893, 0.8187, 0.8521],\n",
      "        [1.6949, 0.7800, 0.8257]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(1.5658, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.2061,  1.9012, -0.5818],\n",
      "        [-1.2049,  1.5702, -0.6955],\n",
      "        [-0.9855,  1.8003, -0.3316],\n",
      "        [-1.0068,  1.7313, -0.4636],\n",
      "        [-1.3569,  1.8110, -0.2200],\n",
      "        [-1.0353,  1.4924, -0.4977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 1.4537,  0.5613,  0.8481, -1.2061,  1.9012, -0.5818],\n",
      "        [ 1.5198,  0.7175,  0.8103, -1.2049,  1.5702, -0.6955],\n",
      "        [ 1.3705,  0.9732,  0.8112, -0.9855,  1.8003, -0.3316],\n",
      "        [ 1.5911,  0.7924,  0.8721, -1.0068,  1.7313, -0.4636],\n",
      "        [ 1.2893,  0.8187,  0.8521, -1.3569,  1.8110, -0.2200],\n",
      "        [ 1.6949,  0.7800,  0.8257, -1.0353,  1.4924, -0.4977]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.10343630611896515\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5132, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[2.1071, 0.7467, 1.1312],\n",
      "        [1.7491, 0.9224, 1.0854],\n",
      "        [1.9770, 0.6034, 0.7932],\n",
      "        [1.8905, 0.8205, 1.0296],\n",
      "        [1.9175, 1.0573, 1.0426],\n",
      "        [2.0364, 0.8987, 0.8951]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(2.9279, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.1366,  2.0944, -0.5766],\n",
      "        [-1.4828,  2.1282, -0.5370],\n",
      "        [-1.5396,  2.0083, -0.4232],\n",
      "        [-1.4755,  1.7720, -0.7096],\n",
      "        [-1.6578,  2.3151, -0.6261],\n",
      "        [-1.5337,  2.1373, -0.2682]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 2.1071,  0.7467,  1.1312, -1.1366,  2.0944, -0.5766],\n",
      "        [ 1.7491,  0.9224,  1.0854, -1.4828,  2.1282, -0.5370],\n",
      "        [ 1.9770,  0.6034,  0.7932, -1.5396,  2.0083, -0.4232],\n",
      "        [ 1.8905,  0.8205,  1.0296, -1.4755,  1.7720, -0.7096],\n",
      "        [ 1.9175,  1.0573,  1.0426, -1.6578,  2.3151, -0.6261],\n",
      "        [ 2.0364,  0.8987,  0.8951, -1.5337,  2.1373, -0.2682]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.13269567489624023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[2.2817, 0.9379, 0.8623],\n",
      "        [2.2091, 1.0968, 1.1208],\n",
      "        [2.4927, 0.8206, 1.3895],\n",
      "        [2.2615, 0.9059, 1.3247],\n",
      "        [2.3770, 0.9749, 1.0846],\n",
      "        [2.4017, 1.1253, 0.9201]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.1808, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.6209,  2.2755, -0.5122],\n",
      "        [-1.9480,  2.2138, -0.4508],\n",
      "        [-1.7585,  2.3614, -0.5473],\n",
      "        [-1.6000,  2.0337, -0.5879],\n",
      "        [-1.9522,  2.2569, -0.7763],\n",
      "        [-1.9725,  2.4119, -0.4074]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 2.2817,  0.9379,  0.8623, -1.6209,  2.2755, -0.5122],\n",
      "        [ 2.2091,  1.0968,  1.1208, -1.9480,  2.2138, -0.4508],\n",
      "        [ 2.4927,  0.8206,  1.3895, -1.7585,  2.3614, -0.5473],\n",
      "        [ 2.2615,  0.9059,  1.3247, -1.6000,  2.0337, -0.5879],\n",
      "        [ 2.3770,  0.9749,  1.0846, -1.9522,  2.2569, -0.7763],\n",
      "        [ 2.4017,  1.1253,  0.9201, -1.9725,  2.4119, -0.4074]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.14127713441848755\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.4232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[2.8207, 1.1342, 1.5148],\n",
      "        [2.7544, 1.0801, 1.5317],\n",
      "        [2.5556, 1.0536, 1.7068],\n",
      "        [2.4540, 1.1791, 1.3975],\n",
      "        [2.7735, 1.0688, 1.4063],\n",
      "        [2.7506, 0.9543, 1.7178]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.6503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.8310,  2.4779, -0.6539],\n",
      "        [-2.1689,  2.3596, -0.4381],\n",
      "        [-2.0653,  2.6186, -0.5120],\n",
      "        [-1.9629,  2.7568, -0.6516],\n",
      "        [-2.0946,  2.8264, -0.3547],\n",
      "        [-2.1214,  2.5734, -0.6340]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 2.8207,  1.1342,  1.5148, -1.8310,  2.4779, -0.6539],\n",
      "        [ 2.7544,  1.0801,  1.5317, -2.1689,  2.3596, -0.4381],\n",
      "        [ 2.5556,  1.0536,  1.7068, -2.0653,  2.6186, -0.5120],\n",
      "        [ 2.4540,  1.1791,  1.3975, -1.9629,  2.7568, -0.6516],\n",
      "        [ 2.7735,  1.0688,  1.4063, -2.0946,  2.8264, -0.3547],\n",
      "        [ 2.7506,  0.9543,  1.7178, -2.1214,  2.5734, -0.6340]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.17791691422462463\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[2.9321, 1.1308, 1.6843],\n",
      "        [3.1113, 1.2461, 1.5499],\n",
      "        [3.3121, 1.1817, 1.3990],\n",
      "        [2.9995, 1.4021, 1.5574],\n",
      "        [2.8733, 1.2003, 1.7299],\n",
      "        [3.1010, 1.1621, 1.5338]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.3609, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1508,  2.7776, -0.7291],\n",
      "        [-1.9377,  2.7988, -0.6852],\n",
      "        [-2.5241,  3.0473, -0.7228],\n",
      "        [-2.2964,  2.6774, -0.5662],\n",
      "        [-2.4452,  2.8751, -0.5770],\n",
      "        [-2.4181,  2.7319, -0.6555]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 2.9321,  1.1308,  1.6843, -2.1508,  2.7776, -0.7291],\n",
      "        [ 3.1113,  1.2461,  1.5499, -1.9377,  2.7988, -0.6852],\n",
      "        [ 3.3121,  1.1817,  1.3990, -2.5241,  3.0473, -0.7228],\n",
      "        [ 2.9995,  1.4021,  1.5574, -2.2964,  2.6774, -0.5662],\n",
      "        [ 2.8733,  1.2003,  1.7299, -2.4452,  2.8751, -0.5770],\n",
      "        [ 3.1010,  1.1621,  1.5338, -2.4181,  2.7319, -0.6555]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.19193966686725616\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.4291, 1.3707, 1.7467],\n",
      "        [3.3067, 1.5351, 1.7375],\n",
      "        [3.1199, 1.2997, 1.8402],\n",
      "        [3.2437, 1.3510, 1.7845],\n",
      "        [3.2197, 1.3526, 1.7617],\n",
      "        [3.2595, 1.2453, 1.6836]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(2.7081, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8379,  2.8257, -0.6400],\n",
      "        [-2.1351,  2.8751, -0.5369],\n",
      "        [-1.9505,  3.0816, -0.6744],\n",
      "        [-2.2957,  3.1300, -0.5692],\n",
      "        [-2.3207,  3.2023, -0.6784],\n",
      "        [-2.4029,  3.1222, -0.3492]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.4291,  1.3707,  1.7467, -2.8379,  2.8257, -0.6400],\n",
      "        [ 3.3067,  1.5351,  1.7375, -2.1351,  2.8751, -0.5369],\n",
      "        [ 3.1199,  1.2997,  1.8402, -1.9505,  3.0816, -0.6744],\n",
      "        [ 3.2437,  1.3510,  1.7845, -2.2957,  3.1300, -0.5692],\n",
      "        [ 3.2197,  1.3526,  1.7617, -2.3207,  3.2023, -0.6784],\n",
      "        [ 3.2595,  1.2453,  1.6836, -2.4029,  3.1222, -0.3492]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.21806466579437256\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0203, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.5433, 1.4463, 1.9958],\n",
      "        [3.4314, 1.2191, 1.8035],\n",
      "        [3.5150, 1.2396, 1.7976],\n",
      "        [3.5951, 1.2068, 1.9221],\n",
      "        [3.3591, 1.3329, 2.0844],\n",
      "        [3.5426, 1.1353, 1.8393]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.8393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.3590,  3.4763, -0.5460],\n",
      "        [-2.2099,  3.2257, -0.7235],\n",
      "        [-2.4734,  3.1962, -0.6574],\n",
      "        [-2.5978,  3.3982, -0.6735],\n",
      "        [-2.4573,  3.3442, -0.7517],\n",
      "        [-2.4103,  3.3647, -0.4122]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.5433,  1.4463,  1.9958, -2.3590,  3.4763, -0.5460],\n",
      "        [ 3.4314,  1.2191,  1.8035, -2.2099,  3.2257, -0.7235],\n",
      "        [ 3.5150,  1.2396,  1.7976, -2.4734,  3.1962, -0.6574],\n",
      "        [ 3.5951,  1.2068,  1.9221, -2.5978,  3.3982, -0.6735],\n",
      "        [ 3.3591,  1.3329,  2.0844, -2.4573,  3.3442, -0.7517],\n",
      "        [ 3.5426,  1.1353,  1.8393, -2.4103,  3.3647, -0.4122]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.23083610832691193\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8826, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.5103, 1.4228, 1.9732],\n",
      "        [3.4595, 1.1069, 1.8696],\n",
      "        [3.8929, 1.2059, 2.1414],\n",
      "        [3.6099, 1.4277, 2.2658],\n",
      "        [3.6435, 1.3488, 1.9493],\n",
      "        [3.6359, 1.2293, 2.0671]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.6014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.5169,  3.5114, -0.7687],\n",
      "        [-2.4856,  3.3749, -0.7977],\n",
      "        [-2.5260,  3.3632, -0.5141],\n",
      "        [-2.2584,  3.3834, -0.6926],\n",
      "        [-2.6276,  3.4567, -0.6529],\n",
      "        [-2.4752,  3.4882, -0.5733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.5103,  1.4228,  1.9732, -2.5169,  3.5114, -0.7687],\n",
      "        [ 3.4595,  1.1069,  1.8696, -2.4856,  3.3749, -0.7977],\n",
      "        [ 3.8929,  1.2059,  2.1414, -2.5260,  3.3632, -0.5141],\n",
      "        [ 3.6099,  1.4277,  2.2658, -2.2584,  3.3834, -0.6926],\n",
      "        [ 3.6435,  1.3488,  1.9493, -2.6276,  3.4567, -0.6529],\n",
      "        [ 3.6359,  1.2293,  2.0671, -2.4752,  3.4882, -0.5733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.23156975209712982\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.7775, 1.3991, 2.0597],\n",
      "        [3.8277, 1.4104, 2.0071],\n",
      "        [3.7296, 1.1412, 2.1003],\n",
      "        [3.6250, 1.4416, 2.2082],\n",
      "        [3.7539, 1.2969, 2.1650],\n",
      "        [3.8664, 1.4792, 2.1316]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.5018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.6439,  3.6839, -0.4509],\n",
      "        [-2.6848,  3.8113, -0.6004],\n",
      "        [-2.8933,  3.5387, -0.6941],\n",
      "        [-2.7777,  3.3605, -0.4134],\n",
      "        [-2.6235,  3.4067, -0.4601],\n",
      "        [-2.7309,  3.3962, -0.4359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.7775,  1.3991,  2.0597, -2.6439,  3.6839, -0.4509],\n",
      "        [ 3.8277,  1.4104,  2.0071, -2.6848,  3.8113, -0.6004],\n",
      "        [ 3.7296,  1.1412,  2.1003, -2.8933,  3.5387, -0.6941],\n",
      "        [ 3.6250,  1.4416,  2.2082, -2.7777,  3.3605, -0.4134],\n",
      "        [ 3.7539,  1.2969,  2.1650, -2.6235,  3.4067, -0.4601],\n",
      "        [ 3.8664,  1.4792,  2.1316, -2.7309,  3.3962, -0.4359]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.24450600147247314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.7135, 1.4845, 2.0519],\n",
      "        [3.9293, 1.6359, 2.3407],\n",
      "        [4.0472, 1.2805, 2.3301],\n",
      "        [3.9415, 1.3769, 2.1528],\n",
      "        [4.1887, 1.7566, 2.1231],\n",
      "        [4.1253, 1.5604, 2.2188]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.7563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8639,  3.8430, -0.5523],\n",
      "        [-2.6446,  3.5109, -0.5326],\n",
      "        [-2.8714,  3.5622, -0.5339],\n",
      "        [-2.8517,  3.6334, -0.8045],\n",
      "        [-2.8857,  3.7260, -0.4839],\n",
      "        [-2.7686,  3.6396, -0.6505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.7135,  1.4845,  2.0519, -2.8639,  3.8430, -0.5523],\n",
      "        [ 3.9293,  1.6359,  2.3407, -2.6446,  3.5109, -0.5326],\n",
      "        [ 4.0472,  1.2805,  2.3301, -2.8714,  3.5622, -0.5339],\n",
      "        [ 3.9415,  1.3769,  2.1528, -2.8517,  3.6334, -0.8045],\n",
      "        [ 4.1887,  1.7566,  2.1231, -2.8857,  3.7260, -0.4839],\n",
      "        [ 4.1253,  1.5604,  2.2188, -2.7686,  3.6396, -0.6505]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.24765554070472717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8281, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[3.9785, 1.4300, 2.3729],\n",
      "        [3.8770, 1.5240, 2.5077],\n",
      "        [4.0746, 1.5223, 2.3991],\n",
      "        [4.2836, 1.4045, 2.3847],\n",
      "        [4.2763, 1.4462, 2.2825],\n",
      "        [3.9584, 1.7389, 2.2963]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.8677, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8313,  3.8331, -0.5888],\n",
      "        [-2.8527,  3.7493, -0.7117],\n",
      "        [-3.2327,  3.7548, -0.6749],\n",
      "        [-2.9039,  3.7249, -0.7192],\n",
      "        [-2.6741,  3.6987, -0.5528],\n",
      "        [-2.9469,  3.8019, -0.6263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 3.9785,  1.4300,  2.3729, -2.8313,  3.8331, -0.5888],\n",
      "        [ 3.8770,  1.5240,  2.5077, -2.8527,  3.7493, -0.7117],\n",
      "        [ 4.0746,  1.5223,  2.3991, -3.2327,  3.7548, -0.6749],\n",
      "        [ 4.2836,  1.4045,  2.3847, -2.9039,  3.7249, -0.7192],\n",
      "        [ 4.2763,  1.4462,  2.2825, -2.6741,  3.6987, -0.5528],\n",
      "        [ 3.9584,  1.7389,  2.2963, -2.9469,  3.8019, -0.6263]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.26167526841163635\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6597, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.2108, 1.5439, 2.4225],\n",
      "        [4.2962, 1.6063, 2.4506],\n",
      "        [4.1846, 1.4194, 2.6070],\n",
      "        [4.1374, 1.4106, 2.4692],\n",
      "        [4.1869, 1.5059, 2.4124],\n",
      "        [4.1078, 1.5233, 2.4083]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.0037,  3.9510, -0.5614],\n",
      "        [-3.1432,  3.7805, -0.6219],\n",
      "        [-2.9730,  3.8102, -0.6911],\n",
      "        [-2.8791,  3.8796, -0.5673],\n",
      "        [-3.0711,  3.8137, -0.7747],\n",
      "        [-3.1076,  3.8376, -0.7791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.2108,  1.5439,  2.4225, -3.0037,  3.9510, -0.5614],\n",
      "        [ 4.2962,  1.6063,  2.4506, -3.1432,  3.7805, -0.6219],\n",
      "        [ 4.1846,  1.4194,  2.6070, -2.9730,  3.8102, -0.6911],\n",
      "        [ 4.1374,  1.4106,  2.4692, -2.8791,  3.8796, -0.5673],\n",
      "        [ 4.1869,  1.5059,  2.4124, -3.0711,  3.8137, -0.7747],\n",
      "        [ 4.1078,  1.5233,  2.4083, -3.1076,  3.8376, -0.7791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.2742067873477936\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.6226, 1.6184, 2.3502],\n",
      "        [4.4349, 1.4754, 2.4344],\n",
      "        [4.2234, 1.7161, 2.4285],\n",
      "        [4.3675, 1.5156, 2.4777],\n",
      "        [4.3009, 1.6093, 2.3450],\n",
      "        [4.4658, 1.5830, 2.3076]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.3567, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.0947,  3.7950, -0.7085],\n",
      "        [-3.0544,  3.8183, -0.5083],\n",
      "        [-3.1840,  4.1989, -0.7784],\n",
      "        [-2.9716,  3.8863, -0.5199],\n",
      "        [-3.1358,  3.9827, -0.7804],\n",
      "        [-3.1319,  3.9388, -0.8030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.6226,  1.6184,  2.3502, -3.0947,  3.7950, -0.7085],\n",
      "        [ 4.4349,  1.4754,  2.4344, -3.0544,  3.8183, -0.5083],\n",
      "        [ 4.2234,  1.7161,  2.4285, -3.1840,  4.1989, -0.7784],\n",
      "        [ 4.3675,  1.5156,  2.4777, -2.9716,  3.8863, -0.5199],\n",
      "        [ 4.3009,  1.6093,  2.3450, -3.1358,  3.9827, -0.7804],\n",
      "        [ 4.4658,  1.5830,  2.3076, -3.1319,  3.9388, -0.8030]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.2852892577648163\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.2785, 1.5847, 2.4695],\n",
      "        [4.5133, 1.6964, 2.4793],\n",
      "        [4.5231, 1.7459, 2.5343],\n",
      "        [4.5172, 1.4997, 2.5011],\n",
      "        [4.4328, 1.5367, 2.4553],\n",
      "        [4.6273, 1.5412, 2.8352]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.5328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.0973,  3.9172, -0.7300],\n",
      "        [-2.9873,  4.0336, -0.6241],\n",
      "        [-3.2841,  4.0140, -0.6837],\n",
      "        [-3.2710,  4.1758, -0.6438],\n",
      "        [-3.0679,  3.9629, -0.7910],\n",
      "        [-3.1487,  3.9288, -0.7113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.2785,  1.5847,  2.4695, -3.0973,  3.9172, -0.7300],\n",
      "        [ 4.5133,  1.6964,  2.4793, -2.9873,  4.0336, -0.6241],\n",
      "        [ 4.5231,  1.7459,  2.5343, -3.2841,  4.0140, -0.6837],\n",
      "        [ 4.5172,  1.4997,  2.5011, -3.2710,  4.1758, -0.6438],\n",
      "        [ 4.4328,  1.5367,  2.4553, -3.0679,  3.9629, -0.7910],\n",
      "        [ 4.6273,  1.5412,  2.8352, -3.1487,  3.9288, -0.7113]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.27870234847068787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1501, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.5363, 1.5473, 2.5023],\n",
      "        [4.6383, 1.7503, 2.5897],\n",
      "        [4.5772, 1.5600, 2.6750],\n",
      "        [4.8617, 1.5911, 2.7174],\n",
      "        [4.6598, 1.6738, 2.6081],\n",
      "        [4.4411, 1.5829, 2.6388]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.1725, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.1694,  4.3273, -0.4541],\n",
      "        [-3.0037,  4.1160, -0.8404],\n",
      "        [-3.3386,  4.2856, -0.5899],\n",
      "        [-3.3069,  4.2166, -0.6589],\n",
      "        [-3.2323,  4.1861, -0.6900],\n",
      "        [-3.1615,  4.0615, -1.0275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.5363,  1.5473,  2.5023, -3.1694,  4.3273, -0.4541],\n",
      "        [ 4.6383,  1.7503,  2.5897, -3.0037,  4.1160, -0.8404],\n",
      "        [ 4.5772,  1.5600,  2.6750, -3.3386,  4.2856, -0.5899],\n",
      "        [ 4.8617,  1.5911,  2.7174, -3.3069,  4.2166, -0.6589],\n",
      "        [ 4.6598,  1.6738,  2.6081, -3.2323,  4.1861, -0.6900],\n",
      "        [ 4.4411,  1.5829,  2.6388, -3.1615,  4.0615, -1.0275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.29267266392707825\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.8054, 1.7357, 2.9023],\n",
      "        [4.5177, 1.7144, 2.6914],\n",
      "        [4.5516, 1.6933, 2.6389],\n",
      "        [4.6533, 1.7278, 2.7910],\n",
      "        [4.6736, 1.8087, 2.6197],\n",
      "        [4.8174, 1.7648, 2.8736]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.2900, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2199,  4.3916, -0.5103],\n",
      "        [-3.2969,  4.2784, -0.6030],\n",
      "        [-3.4770,  4.2760, -0.6407],\n",
      "        [-3.2898,  4.2293, -0.7864],\n",
      "        [-3.2211,  4.2110, -0.8444],\n",
      "        [-3.1524,  4.2266, -0.7513]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.8054,  1.7357,  2.9023, -3.2199,  4.3916, -0.5103],\n",
      "        [ 4.5177,  1.7144,  2.6914, -3.2969,  4.2784, -0.6030],\n",
      "        [ 4.5516,  1.6933,  2.6389, -3.4770,  4.2760, -0.6407],\n",
      "        [ 4.6533,  1.7278,  2.7910, -3.2898,  4.2293, -0.7864],\n",
      "        [ 4.6736,  1.8087,  2.6197, -3.2211,  4.2110, -0.8444],\n",
      "        [ 4.8174,  1.7648,  2.8736, -3.1524,  4.2266, -0.7513]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3125797212123871\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.8031, 1.6940, 2.6173],\n",
      "        [4.6547, 1.7127, 2.5955],\n",
      "        [4.9500, 1.7834, 2.6668],\n",
      "        [4.7321, 1.7874, 2.6955],\n",
      "        [4.8419, 1.7161, 2.6868],\n",
      "        [4.5697, 1.5604, 2.7156]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.0986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3434,  4.4087, -0.6203],\n",
      "        [-3.3067,  4.2249, -0.5984],\n",
      "        [-3.3691,  4.3574, -0.6884],\n",
      "        [-3.4424,  4.4629, -0.8434],\n",
      "        [-3.2111,  4.2619, -0.7011],\n",
      "        [-3.2323,  4.1846, -0.5519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.8031,  1.6940,  2.6173, -3.3434,  4.4087, -0.6203],\n",
      "        [ 4.6547,  1.7127,  2.5955, -3.3067,  4.2249, -0.5984],\n",
      "        [ 4.9500,  1.7834,  2.6668, -3.3691,  4.3574, -0.6884],\n",
      "        [ 4.7321,  1.7874,  2.6955, -3.4424,  4.4629, -0.8434],\n",
      "        [ 4.8419,  1.7161,  2.6868, -3.2111,  4.2619, -0.7011],\n",
      "        [ 4.5697,  1.5604,  2.7156, -3.2323,  4.1846, -0.5519]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.30797818303108215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4739, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.7447, 1.8001, 2.7302],\n",
      "        [4.9862, 1.7477, 2.7371],\n",
      "        [4.9056, 1.7728, 2.7729],\n",
      "        [4.5835, 1.7766, 2.6098],\n",
      "        [4.7815, 2.0145, 2.6904],\n",
      "        [5.0219, 1.5662, 2.8330]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.5931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4617,  4.5289, -0.6589],\n",
      "        [-3.5778,  4.1262, -0.6274],\n",
      "        [-3.3224,  4.1487, -0.9115],\n",
      "        [-3.7358,  4.4962, -0.7275],\n",
      "        [-3.6414,  4.3816, -0.6340],\n",
      "        [-3.4167,  4.3841, -0.6893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.7447,  1.8001,  2.7302, -3.4617,  4.5289, -0.6589],\n",
      "        [ 4.9862,  1.7477,  2.7371, -3.5778,  4.1262, -0.6274],\n",
      "        [ 4.9056,  1.7728,  2.7729, -3.3224,  4.1487, -0.9115],\n",
      "        [ 4.5835,  1.7766,  2.6098, -3.7358,  4.4962, -0.7275],\n",
      "        [ 4.7815,  2.0145,  2.6904, -3.6414,  4.3816, -0.6340],\n",
      "        [ 5.0219,  1.5662,  2.8330, -3.4167,  4.3841, -0.6893]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.31249937415122986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.4625, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[4.7480, 1.8749, 2.7455],\n",
      "        [4.7920, 1.8228, 2.5980],\n",
      "        [4.7866, 1.8071, 2.9938],\n",
      "        [4.8308, 1.7399, 2.7655],\n",
      "        [4.8778, 1.7987, 2.8968],\n",
      "        [4.9816, 1.7921, 2.6735]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.8112, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3566,  4.4263, -0.7442],\n",
      "        [-3.2883,  4.3899, -0.6430],\n",
      "        [-3.4284,  4.4104, -0.5559],\n",
      "        [-3.3672,  4.4412, -0.5538],\n",
      "        [-3.5931,  4.5528, -0.6479],\n",
      "        [-3.1541,  4.3138, -0.8813]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 4.7480,  1.8749,  2.7455, -3.3566,  4.4263, -0.7442],\n",
      "        [ 4.7920,  1.8228,  2.5980, -3.2883,  4.3899, -0.6430],\n",
      "        [ 4.7866,  1.8071,  2.9938, -3.4284,  4.4104, -0.5559],\n",
      "        [ 4.8308,  1.7399,  2.7655, -3.3672,  4.4412, -0.5538],\n",
      "        [ 4.8778,  1.7987,  2.8968, -3.5931,  4.5528, -0.6479],\n",
      "        [ 4.9816,  1.7921,  2.6735, -3.1541,  4.3138, -0.8813]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.31156304478645325\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8276, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.0012, 1.9971, 2.7491],\n",
      "        [5.0867, 1.8065, 2.9140],\n",
      "        [4.9664, 1.8473, 2.8573],\n",
      "        [5.1198, 1.8699, 2.9577],\n",
      "        [5.0266, 2.0781, 3.0386],\n",
      "        [4.8730, 1.9362, 3.0138]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.4819, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5875,  4.4763, -0.6304],\n",
      "        [-3.5472,  4.3787, -0.9085],\n",
      "        [-3.6816,  4.5328, -0.8991],\n",
      "        [-3.2151,  4.6920, -0.6391],\n",
      "        [-3.7199,  4.4975, -0.7501],\n",
      "        [-3.5474,  4.7038, -0.7025]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.0012,  1.9971,  2.7491, -3.5875,  4.4763, -0.6304],\n",
      "        [ 5.0867,  1.8065,  2.9140, -3.5472,  4.3787, -0.9085],\n",
      "        [ 4.9664,  1.8473,  2.8573, -3.6816,  4.5328, -0.8991],\n",
      "        [ 5.1198,  1.8699,  2.9577, -3.2151,  4.6920, -0.6391],\n",
      "        [ 5.0266,  2.0781,  3.0386, -3.7199,  4.4975, -0.7501],\n",
      "        [ 4.8730,  1.9362,  3.0138, -3.5474,  4.7038, -0.7025]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.32356253266334534\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1113, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.2584, 1.8703, 2.6406],\n",
      "        [5.1662, 2.0473, 2.8649],\n",
      "        [4.9207, 1.6502, 2.9047],\n",
      "        [5.1586, 1.9110, 3.1007],\n",
      "        [5.1531, 1.7534, 2.8187],\n",
      "        [5.0174, 1.8841, 2.7989]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.4459, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.6152,  4.4238, -0.7829],\n",
      "        [-3.5489,  4.3507, -0.7813],\n",
      "        [-3.6004,  4.6239, -0.6741],\n",
      "        [-3.6398,  4.4269, -0.6903],\n",
      "        [-3.6546,  4.5818, -0.7638],\n",
      "        [-3.5498,  4.7318, -0.6763]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.2584,  1.8703,  2.6406, -3.6152,  4.4238, -0.7829],\n",
      "        [ 5.1662,  2.0473,  2.8649, -3.5489,  4.3507, -0.7813],\n",
      "        [ 4.9207,  1.6502,  2.9047, -3.6004,  4.6239, -0.6741],\n",
      "        [ 5.1586,  1.9110,  3.1007, -3.6398,  4.4269, -0.6903],\n",
      "        [ 5.1531,  1.7534,  2.8187, -3.6546,  4.5818, -0.7638],\n",
      "        [ 5.0174,  1.8841,  2.7989, -3.5498,  4.7318, -0.6763]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.32803165912628174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.1637, 1.7832, 2.7493],\n",
      "        [5.1999, 1.7575, 3.0457],\n",
      "        [5.4527, 1.9259, 3.0405],\n",
      "        [4.8488, 2.0736, 2.9519],\n",
      "        [5.0872, 1.7270, 2.8346],\n",
      "        [5.4100, 1.8506, 2.8281]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.5598, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7542,  4.7417, -0.7546],\n",
      "        [-3.8731,  4.5089, -0.7841],\n",
      "        [-3.7819,  4.8560, -0.7461],\n",
      "        [-3.8126,  4.5668, -0.9864],\n",
      "        [-3.7327,  4.6949, -0.6875],\n",
      "        [-3.7247,  4.8161, -0.6722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.1637,  1.7832,  2.7493, -3.7542,  4.7417, -0.7546],\n",
      "        [ 5.1999,  1.7575,  3.0457, -3.8731,  4.5089, -0.7841],\n",
      "        [ 5.4527,  1.9259,  3.0405, -3.7819,  4.8560, -0.7461],\n",
      "        [ 4.8488,  2.0736,  2.9519, -3.8126,  4.5668, -0.9864],\n",
      "        [ 5.0872,  1.7270,  2.8346, -3.7327,  4.6949, -0.6875],\n",
      "        [ 5.4100,  1.8506,  2.8281, -3.7247,  4.8161, -0.6722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.33221694827079773\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.2932, 1.9219, 2.9235],\n",
      "        [5.3126, 1.9226, 2.7733],\n",
      "        [5.3060, 1.7762, 3.0399],\n",
      "        [5.3678, 1.8993, 2.8375],\n",
      "        [5.4076, 1.6927, 3.0479],\n",
      "        [4.9844, 2.0004, 2.9458]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.0529, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7778,  4.8643, -0.8080],\n",
      "        [-3.8108,  4.8989, -0.9883],\n",
      "        [-3.8244,  4.3562, -0.6806],\n",
      "        [-3.8805,  4.7707, -0.6972],\n",
      "        [-3.5232,  4.6031, -0.7512],\n",
      "        [-3.7483,  4.7673, -0.7417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.2932,  1.9219,  2.9235, -3.7778,  4.8643, -0.8080],\n",
      "        [ 5.3126,  1.9226,  2.7733, -3.8108,  4.8989, -0.9883],\n",
      "        [ 5.3060,  1.7762,  3.0399, -3.8244,  4.3562, -0.6806],\n",
      "        [ 5.3678,  1.8993,  2.8375, -3.8805,  4.7707, -0.6972],\n",
      "        [ 5.4076,  1.6927,  3.0479, -3.5232,  4.6031, -0.7512],\n",
      "        [ 4.9844,  2.0004,  2.9458, -3.7483,  4.7673, -0.7417]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.34323039650917053\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.1266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.3537, 1.8562, 3.0654],\n",
      "        [5.2684, 2.1734, 2.8053],\n",
      "        [5.2795, 2.0323, 2.9348],\n",
      "        [5.0399, 1.9349, 2.8127],\n",
      "        [5.3884, 1.9425, 3.1920],\n",
      "        [5.3792, 2.0019, 2.8908]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.2081, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8110,  4.7404, -0.7128],\n",
      "        [-3.6131,  4.6152, -0.8843],\n",
      "        [-3.7149,  4.9741, -0.7152],\n",
      "        [-3.8817,  4.8630, -0.8356],\n",
      "        [-3.8112,  4.9014, -0.6721],\n",
      "        [-3.6576,  4.7125, -0.9255]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.3537,  1.8562,  3.0654, -3.8110,  4.7404, -0.7128],\n",
      "        [ 5.2684,  2.1734,  2.8053, -3.6131,  4.6152, -0.8843],\n",
      "        [ 5.2795,  2.0323,  2.9348, -3.7149,  4.9741, -0.7152],\n",
      "        [ 5.0399,  1.9349,  2.8127, -3.8817,  4.8630, -0.8356],\n",
      "        [ 5.3884,  1.9425,  3.1920, -3.8112,  4.9014, -0.6721],\n",
      "        [ 5.3792,  2.0019,  2.8908, -3.6576,  4.7125, -0.9255]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.34629401564598083\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.3008, 2.1463, 3.0499],\n",
      "        [5.2117, 2.0841, 3.1579],\n",
      "        [5.4538, 2.0471, 2.9838],\n",
      "        [5.2799, 1.9409, 3.1068],\n",
      "        [5.2023, 1.8227, 3.0359],\n",
      "        [5.3606, 1.9196, 3.0045]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.8780, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7647,  5.0347, -1.0064],\n",
      "        [-3.7482,  4.8321, -0.6436],\n",
      "        [-3.7091,  4.8186, -0.8183],\n",
      "        [-3.8261,  4.6262, -0.7447],\n",
      "        [-3.9009,  4.8885, -0.6980],\n",
      "        [-3.9252,  5.1516, -0.9211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.3008,  2.1463,  3.0499, -3.7647,  5.0347, -1.0064],\n",
      "        [ 5.2117,  2.0841,  3.1579, -3.7482,  4.8321, -0.6436],\n",
      "        [ 5.4538,  2.0471,  2.9838, -3.7091,  4.8186, -0.8183],\n",
      "        [ 5.2799,  1.9409,  3.1068, -3.8261,  4.6262, -0.7447],\n",
      "        [ 5.2023,  1.8227,  3.0359, -3.9009,  4.8885, -0.6980],\n",
      "        [ 5.3606,  1.9196,  3.0045, -3.9252,  5.1516, -0.9211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.350986123085022\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5214, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.2720, 1.9372, 3.1063],\n",
      "        [5.6215, 2.1153, 3.1005],\n",
      "        [5.2766, 2.1109, 2.7818],\n",
      "        [5.4172, 1.8002, 3.1404],\n",
      "        [5.4382, 2.1813, 3.1332],\n",
      "        [5.6060, 1.9655, 3.1076]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.7229, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8403,  4.8598, -1.0236],\n",
      "        [-3.8026,  4.6085, -0.6693],\n",
      "        [-3.7426,  5.0716, -0.7642],\n",
      "        [-3.7528,  4.6362, -1.0890],\n",
      "        [-4.0569,  5.0219, -0.8203],\n",
      "        [-4.1454,  4.7768, -0.8135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.2720,  1.9372,  3.1063, -3.8403,  4.8598, -1.0236],\n",
      "        [ 5.6215,  2.1153,  3.1005, -3.8026,  4.6085, -0.6693],\n",
      "        [ 5.2766,  2.1109,  2.7818, -3.7426,  5.0716, -0.7642],\n",
      "        [ 5.4172,  1.8002,  3.1404, -3.7528,  4.6362, -1.0890],\n",
      "        [ 5.4382,  2.1813,  3.1332, -4.0569,  5.0219, -0.8203],\n",
      "        [ 5.6060,  1.9655,  3.1076, -4.1454,  4.7768, -0.8135]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3481124937534332\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.4367, 1.9254, 3.0166],\n",
      "        [5.5683, 2.0623, 3.2147],\n",
      "        [5.4756, 1.9342, 3.0186],\n",
      "        [5.2676, 1.8797, 3.0044],\n",
      "        [5.4037, 1.4955, 3.1458],\n",
      "        [5.5467, 1.9875, 2.9941]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.9650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8086,  4.9159, -0.6537],\n",
      "        [-4.0603,  4.9745, -0.8307],\n",
      "        [-4.1841,  5.0799, -0.6550],\n",
      "        [-4.0072,  4.9374, -0.7413],\n",
      "        [-4.1852,  4.9276, -0.9878],\n",
      "        [-4.0387,  4.9036, -0.7003]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.4367,  1.9254,  3.0166, -3.8086,  4.9159, -0.6537],\n",
      "        [ 5.5683,  2.0623,  3.2147, -4.0603,  4.9745, -0.8307],\n",
      "        [ 5.4756,  1.9342,  3.0186, -4.1841,  5.0799, -0.6550],\n",
      "        [ 5.2676,  1.8797,  3.0044, -4.0072,  4.9374, -0.7413],\n",
      "        [ 5.4037,  1.4955,  3.1458, -4.1852,  4.9276, -0.9878],\n",
      "        [ 5.5467,  1.9875,  2.9941, -4.0387,  4.9036, -0.7003]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3512875735759735\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.5196, 1.9413, 3.0017],\n",
      "        [5.4817, 2.0734, 2.7920],\n",
      "        [5.2181, 1.9091, 3.0529],\n",
      "        [5.3692, 2.1328, 2.8844],\n",
      "        [5.3640, 2.1180, 2.9996],\n",
      "        [5.7177, 2.3374, 3.1182]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.0054, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.1059,  5.0719, -0.8759],\n",
      "        [-4.1920,  5.0192, -1.0518],\n",
      "        [-3.9482,  5.1392, -0.8605],\n",
      "        [-4.0284,  4.9854, -0.9883],\n",
      "        [-3.9626,  4.8748, -0.9088],\n",
      "        [-3.9588,  4.8303, -0.7348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.5196,  1.9413,  3.0017, -4.1059,  5.0719, -0.8759],\n",
      "        [ 5.4817,  2.0734,  2.7920, -4.1920,  5.0192, -1.0518],\n",
      "        [ 5.2181,  1.9091,  3.0529, -3.9482,  5.1392, -0.8605],\n",
      "        [ 5.3692,  2.1328,  2.8844, -4.0284,  4.9854, -0.9883],\n",
      "        [ 5.3640,  2.1180,  2.9996, -3.9626,  4.8748, -0.9088],\n",
      "        [ 5.7177,  2.3374,  3.1182, -3.9588,  4.8303, -0.7348]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.35925644636154175\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.5894, 2.4238, 3.0253],\n",
      "        [5.4432, 1.8963, 3.1448],\n",
      "        [5.4558, 2.1110, 3.0281],\n",
      "        [5.5690, 2.0721, 2.9395],\n",
      "        [5.5035, 1.9274, 3.1781],\n",
      "        [5.4229, 1.8975, 2.9607]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.0068, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.9744,  5.1316, -0.9456],\n",
      "        [-3.8834,  4.8933, -0.6180],\n",
      "        [-4.0244,  5.1263, -1.0158],\n",
      "        [-4.0273,  5.1382, -1.1095],\n",
      "        [-3.9647,  5.0027, -0.7569],\n",
      "        [-4.0248,  4.8314, -0.6654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.5894,  2.4238,  3.0253, -3.9744,  5.1316, -0.9456],\n",
      "        [ 5.4432,  1.8963,  3.1448, -3.8834,  4.8933, -0.6180],\n",
      "        [ 5.4558,  2.1110,  3.0281, -4.0244,  5.1263, -1.0158],\n",
      "        [ 5.5690,  2.0721,  2.9395, -4.0273,  5.1382, -1.1095],\n",
      "        [ 5.5035,  1.9274,  3.1781, -3.9647,  5.0027, -0.7569],\n",
      "        [ 5.4229,  1.8975,  2.9607, -4.0248,  4.8314, -0.6654]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3662051558494568\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7749, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.5826, 2.1353, 3.1546],\n",
      "        [5.7849, 2.1812, 3.0418],\n",
      "        [5.7274, 2.0823, 3.2330],\n",
      "        [5.4828, 2.2879, 3.1525],\n",
      "        [5.5867, 2.3442, 3.1600],\n",
      "        [5.4938, 2.3278, 3.1682]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.6620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.9450,  5.0693, -1.1739],\n",
      "        [-4.0948,  5.2351, -0.8677],\n",
      "        [-4.1650,  4.8758, -0.7119],\n",
      "        [-4.0265,  5.2223, -1.1556],\n",
      "        [-3.8264,  4.8081, -0.9414],\n",
      "        [-4.0638,  5.1697, -0.6483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.5826,  2.1353,  3.1546, -3.9450,  5.0693, -1.1739],\n",
      "        [ 5.7849,  2.1812,  3.0418, -4.0948,  5.2351, -0.8677],\n",
      "        [ 5.7274,  2.0823,  3.2330, -4.1650,  4.8758, -0.7119],\n",
      "        [ 5.4828,  2.2879,  3.1525, -4.0265,  5.2223, -1.1556],\n",
      "        [ 5.5867,  2.3442,  3.1600, -3.8264,  4.8081, -0.9414],\n",
      "        [ 5.4938,  2.3278,  3.1682, -4.0638,  5.1697, -0.6483]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3654702603816986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.7366, 2.2157, 3.2596],\n",
      "        [5.5484, 2.1596, 3.1130],\n",
      "        [5.6646, 2.2067, 3.0799],\n",
      "        [5.4756, 2.0920, 3.2057],\n",
      "        [5.6633, 2.2074, 3.1783],\n",
      "        [5.7012, 2.2834, 3.1999]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.2493,  4.9475, -0.6662],\n",
      "        [-4.0275,  5.2094, -0.9275],\n",
      "        [-4.0069,  5.0729, -0.9261],\n",
      "        [-4.2811,  5.1337, -0.8960],\n",
      "        [-4.2233,  5.2027, -0.9928],\n",
      "        [-4.3363,  5.1563, -0.7225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.7366,  2.2157,  3.2596, -4.2493,  4.9475, -0.6662],\n",
      "        [ 5.5484,  2.1596,  3.1130, -4.0275,  5.2094, -0.9275],\n",
      "        [ 5.6646,  2.2067,  3.0799, -4.0069,  5.0729, -0.9261],\n",
      "        [ 5.4756,  2.0920,  3.2057, -4.2811,  5.1337, -0.8960],\n",
      "        [ 5.6633,  2.2074,  3.1783, -4.2233,  5.2027, -0.9928],\n",
      "        [ 5.7012,  2.2834,  3.1999, -4.3363,  5.1563, -0.7225]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3742374777793884\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5770, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.7474, 2.0513, 3.0281],\n",
      "        [5.7448, 2.0531, 3.3190],\n",
      "        [5.4883, 2.2351, 3.0650],\n",
      "        [5.8365, 2.0489, 3.0033],\n",
      "        [5.7076, 2.2452, 3.0990],\n",
      "        [5.9882, 2.0328, 3.0254]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.1804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.1841,  5.2135, -0.8025],\n",
      "        [-4.2847,  5.3143, -0.8943],\n",
      "        [-3.9153,  5.0793, -1.0310],\n",
      "        [-4.2967,  5.1795, -0.6708],\n",
      "        [-4.0772,  5.3894, -0.7893],\n",
      "        [-4.1262,  5.1548, -0.8598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.7474,  2.0513,  3.0281, -4.1841,  5.2135, -0.8025],\n",
      "        [ 5.7448,  2.0531,  3.3190, -4.2847,  5.3143, -0.8943],\n",
      "        [ 5.4883,  2.2351,  3.0650, -3.9153,  5.0793, -1.0310],\n",
      "        [ 5.8365,  2.0489,  3.0033, -4.2967,  5.1795, -0.6708],\n",
      "        [ 5.7076,  2.2452,  3.0990, -4.0772,  5.3894, -0.7893],\n",
      "        [ 5.9882,  2.0328,  3.0254, -4.1262,  5.1548, -0.8598]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.3713473975658417\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2755, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.7704, 2.0871, 3.1950],\n",
      "        [5.8448, 2.3968, 3.1047],\n",
      "        [5.6438, 2.2079, 3.3146],\n",
      "        [5.7777, 2.3711, 3.3115],\n",
      "        [5.6570, 1.8643, 3.3556],\n",
      "        [5.6707, 2.2456, 3.3199]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.8306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.2573,  4.9332, -1.0308],\n",
      "        [-4.2207,  5.3601, -0.7476],\n",
      "        [-4.3376,  5.2413, -0.7482],\n",
      "        [-4.2566,  5.1266, -0.9241],\n",
      "        [-3.8522,  5.2785, -0.8983],\n",
      "        [-4.1329,  5.3555, -0.8928]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.7704,  2.0871,  3.1950, -4.2573,  4.9332, -1.0308],\n",
      "        [ 5.8448,  2.3968,  3.1047, -4.2207,  5.3601, -0.7476],\n",
      "        [ 5.6438,  2.2079,  3.3146, -4.3376,  5.2413, -0.7482],\n",
      "        [ 5.7777,  2.3711,  3.3115, -4.2566,  5.1266, -0.9241],\n",
      "        [ 5.6570,  1.8643,  3.3556, -3.8522,  5.2785, -0.8983],\n",
      "        [ 5.6707,  2.2456,  3.3199, -4.1329,  5.3555, -0.8928]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3736395835876465\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.6718, 2.2337, 3.2274],\n",
      "        [5.7265, 2.2795, 3.0845],\n",
      "        [6.0932, 2.2819, 3.1501],\n",
      "        [5.9056, 2.3503, 3.2496],\n",
      "        [5.9594, 2.2188, 3.3125],\n",
      "        [5.8238, 2.3092, 3.2406]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.3333, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8542,  5.4563, -0.7153],\n",
      "        [-4.2477,  5.2709, -1.0169],\n",
      "        [-4.0477,  5.4167, -0.8681],\n",
      "        [-4.1690,  5.1524, -0.9002],\n",
      "        [-4.1427,  5.3173, -0.8719],\n",
      "        [-4.2358,  5.3340, -0.8428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.6718,  2.2337,  3.2274, -3.8542,  5.4563, -0.7153],\n",
      "        [ 5.7265,  2.2795,  3.0845, -4.2477,  5.2709, -1.0169],\n",
      "        [ 6.0932,  2.2819,  3.1501, -4.0477,  5.4167, -0.8681],\n",
      "        [ 5.9056,  2.3503,  3.2496, -4.1690,  5.1524, -0.9002],\n",
      "        [ 5.9594,  2.2188,  3.3125, -4.1427,  5.3173, -0.8719],\n",
      "        [ 5.8238,  2.3092,  3.2406, -4.2358,  5.3340, -0.8428]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3750414550304413\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8397, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.6704, 2.4959, 3.2971],\n",
      "        [6.1239, 2.0856, 3.0440],\n",
      "        [5.8132, 2.1930, 3.3281],\n",
      "        [5.7670, 2.3660, 3.1419],\n",
      "        [5.8403, 2.0747, 3.2216],\n",
      "        [5.8355, 2.3559, 3.0337]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.0344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.4785,  5.4242, -0.8796],\n",
      "        [-4.2363,  5.3326, -0.9125],\n",
      "        [-4.1241,  5.4477, -0.7864],\n",
      "        [-4.2673,  5.2978, -1.0094],\n",
      "        [-4.2547,  5.0398, -0.7181],\n",
      "        [-4.0898,  5.4589, -1.0629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.6704,  2.4959,  3.2971, -4.4785,  5.4242, -0.8796],\n",
      "        [ 6.1239,  2.0856,  3.0440, -4.2363,  5.3326, -0.9125],\n",
      "        [ 5.8132,  2.1930,  3.3281, -4.1241,  5.4477, -0.7864],\n",
      "        [ 5.7670,  2.3660,  3.1419, -4.2673,  5.2978, -1.0094],\n",
      "        [ 5.8403,  2.0747,  3.2216, -4.2547,  5.0398, -0.7181],\n",
      "        [ 5.8355,  2.3559,  3.0337, -4.0898,  5.4589, -1.0629]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3854673206806183\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.7717, 2.2209, 3.1167],\n",
      "        [5.7153, 2.2160, 3.3487],\n",
      "        [5.9390, 2.1287, 3.3377],\n",
      "        [5.8711, 2.3937, 3.2405],\n",
      "        [5.8417, 2.3392, 3.3859],\n",
      "        [6.1116, 2.2546, 3.4489]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.8072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.2866,  5.3987, -0.7564],\n",
      "        [-4.0494,  5.2728, -0.8095],\n",
      "        [-4.0532,  5.4336, -1.0070],\n",
      "        [-4.1995,  5.2357, -1.0509],\n",
      "        [-4.4398,  5.0768, -0.8624],\n",
      "        [-4.2027,  5.5212, -0.9735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.7717,  2.2209,  3.1167, -4.2866,  5.3987, -0.7564],\n",
      "        [ 5.7153,  2.2160,  3.3487, -4.0494,  5.2728, -0.8095],\n",
      "        [ 5.9390,  2.1287,  3.3377, -4.0532,  5.4336, -1.0070],\n",
      "        [ 5.8711,  2.3937,  3.2405, -4.1995,  5.2357, -1.0509],\n",
      "        [ 5.8417,  2.3392,  3.3859, -4.4398,  5.0768, -0.8624],\n",
      "        [ 6.1116,  2.2546,  3.4489, -4.2027,  5.5212, -0.9735]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.37994736433029175\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3664, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.6258, 2.3970, 3.4014],\n",
      "        [6.0952, 2.0652, 3.3721],\n",
      "        [5.9195, 2.1796, 3.2928],\n",
      "        [5.9909, 2.4355, 3.2458],\n",
      "        [5.9776, 2.0713, 3.1404],\n",
      "        [6.0480, 2.1521, 3.2434]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.5343, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.1795,  5.5597, -0.9574],\n",
      "        [-4.1639,  5.3485, -0.7313],\n",
      "        [-4.3166,  5.4619, -0.7569],\n",
      "        [-4.4989,  5.3553, -0.8821],\n",
      "        [-4.3018,  5.5208, -0.8106],\n",
      "        [-4.3316,  5.2241, -1.1685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.6258,  2.3970,  3.4014, -4.1795,  5.5597, -0.9574],\n",
      "        [ 6.0952,  2.0652,  3.3721, -4.1639,  5.3485, -0.7313],\n",
      "        [ 5.9195,  2.1796,  3.2928, -4.3166,  5.4619, -0.7569],\n",
      "        [ 5.9909,  2.4355,  3.2458, -4.4989,  5.3553, -0.8821],\n",
      "        [ 5.9776,  2.0713,  3.1404, -4.3018,  5.5208, -0.8106],\n",
      "        [ 6.0480,  2.1521,  3.2434, -4.3316,  5.2241, -1.1685]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.38465961813926697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0479, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[5.6580, 2.4463, 3.3926],\n",
      "        [6.0928, 2.4431, 3.2845],\n",
      "        [5.9057, 2.1628, 3.3028],\n",
      "        [5.8156, 2.4702, 3.4770],\n",
      "        [6.0630, 2.2247, 3.2647],\n",
      "        [6.0643, 2.3362, 3.1841]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.0510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.5363,  5.4013, -0.8118],\n",
      "        [-4.5255,  5.5684, -0.9475],\n",
      "        [-4.2341,  5.3575, -0.8001],\n",
      "        [-4.3347,  5.4103, -0.8646],\n",
      "        [-4.3296,  5.5745, -0.8122],\n",
      "        [-4.3233,  5.4196, -0.7612]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 5.6580,  2.4463,  3.3926, -4.5363,  5.4013, -0.8118],\n",
      "        [ 6.0928,  2.4431,  3.2845, -4.5255,  5.5684, -0.9475],\n",
      "        [ 5.9057,  2.1628,  3.3028, -4.2341,  5.3575, -0.8001],\n",
      "        [ 5.8156,  2.4702,  3.4770, -4.3347,  5.4103, -0.8646],\n",
      "        [ 6.0630,  2.2247,  3.2647, -4.3296,  5.5745, -0.8122],\n",
      "        [ 6.0643,  2.3362,  3.1841, -4.3233,  5.4196, -0.7612]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.3876141607761383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.2378, 2.2941, 3.4020],\n",
      "        [6.2550, 2.4091, 3.3042],\n",
      "        [6.1392, 2.2354, 3.2801],\n",
      "        [6.1307, 2.3488, 3.3489],\n",
      "        [6.1601, 2.3120, 3.0864],\n",
      "        [6.1198, 2.4729, 3.5551]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.4538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.4615,  5.7497, -0.9047],\n",
      "        [-4.3625,  5.6278, -0.9927],\n",
      "        [-4.4455,  5.4002, -0.9926],\n",
      "        [-4.2175,  5.4414, -0.8477],\n",
      "        [-4.2367,  5.5501, -1.1141],\n",
      "        [-4.1943,  5.4668, -0.9935]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.2378,  2.2941,  3.4020, -4.4615,  5.7497, -0.9047],\n",
      "        [ 6.2550,  2.4091,  3.3042, -4.3625,  5.6278, -0.9927],\n",
      "        [ 6.1392,  2.2354,  3.2801, -4.4455,  5.4002, -0.9926],\n",
      "        [ 6.1307,  2.3488,  3.3489, -4.2175,  5.4414, -0.8477],\n",
      "        [ 6.1601,  2.3120,  3.0864, -4.2367,  5.5501, -1.1141],\n",
      "        [ 6.1198,  2.4729,  3.5551, -4.1943,  5.4668, -0.9935]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.40841788053512573\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3707, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.1219, 2.1653, 3.4471],\n",
      "        [6.0420, 2.2707, 3.2155],\n",
      "        [6.1204, 2.4539, 3.4728],\n",
      "        [6.2120, 2.4972, 3.5932],\n",
      "        [6.0399, 2.1419, 3.4393],\n",
      "        [6.1195, 2.3012, 3.1290]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.6650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.6240,  5.6262, -0.8905],\n",
      "        [-4.4800,  5.8267, -0.8790],\n",
      "        [-4.4769,  5.4742, -1.0170],\n",
      "        [-4.4014,  5.4169, -0.5590],\n",
      "        [-4.2504,  5.5713, -1.0663],\n",
      "        [-4.1961,  5.4025, -1.0514]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.1219,  2.1653,  3.4471, -4.6240,  5.6262, -0.8905],\n",
      "        [ 6.0420,  2.2707,  3.2155, -4.4800,  5.8267, -0.8790],\n",
      "        [ 6.1204,  2.4539,  3.4728, -4.4769,  5.4742, -1.0170],\n",
      "        [ 6.2120,  2.4972,  3.5932, -4.4014,  5.4169, -0.5590],\n",
      "        [ 6.0399,  2.1419,  3.4393, -4.2504,  5.5713, -1.0663],\n",
      "        [ 6.1195,  2.3012,  3.1290, -4.1961,  5.4025, -1.0514]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4048958718776703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0603, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.0942, 2.2332, 3.4134],\n",
      "        [6.0945, 2.4000, 3.4758],\n",
      "        [6.0419, 2.3798, 3.2888],\n",
      "        [6.1722, 2.3943, 3.2913],\n",
      "        [6.0026, 2.3682, 3.5228],\n",
      "        [6.2444, 2.2403, 3.4091]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.4507, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.5196,  5.6083, -1.0498],\n",
      "        [-4.4794,  5.3522, -1.0877],\n",
      "        [-4.5228,  5.4674, -0.8919],\n",
      "        [-4.5364,  5.4751, -1.0404],\n",
      "        [-4.4987,  5.7085, -0.7403],\n",
      "        [-4.5122,  5.3746, -0.9867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.0942,  2.2332,  3.4134, -4.5196,  5.6083, -1.0498],\n",
      "        [ 6.0945,  2.4000,  3.4758, -4.4794,  5.3522, -1.0877],\n",
      "        [ 6.0419,  2.3798,  3.2888, -4.5228,  5.4674, -0.8919],\n",
      "        [ 6.1722,  2.3943,  3.2913, -4.5364,  5.4751, -1.0404],\n",
      "        [ 6.0026,  2.3682,  3.5228, -4.4987,  5.7085, -0.7403],\n",
      "        [ 6.2444,  2.2403,  3.4091, -4.5122,  5.3746, -0.9867]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4031868577003479\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8567, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.1643, 2.3020, 3.2872],\n",
      "        [6.3022, 2.5079, 3.3171],\n",
      "        [6.3565, 2.3716, 3.4467],\n",
      "        [6.2260, 2.3612, 3.5005],\n",
      "        [6.3005, 2.3859, 3.3601],\n",
      "        [6.1953, 2.3080, 3.4473]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.0845, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.4707,  5.7479, -0.8964],\n",
      "        [-4.6398,  5.6973, -1.0637],\n",
      "        [-4.3351,  5.5533, -1.2730],\n",
      "        [-4.6760,  5.5970, -0.9512],\n",
      "        [-4.4056,  5.4599, -0.7667],\n",
      "        [-4.5966,  5.6970, -1.1028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.1643,  2.3020,  3.2872, -4.4707,  5.7479, -0.8964],\n",
      "        [ 6.3022,  2.5079,  3.3171, -4.6398,  5.6973, -1.0637],\n",
      "        [ 6.3565,  2.3716,  3.4467, -4.3351,  5.5533, -1.2730],\n",
      "        [ 6.2260,  2.3612,  3.5005, -4.6760,  5.5970, -0.9512],\n",
      "        [ 6.3005,  2.3859,  3.3601, -4.4056,  5.4599, -0.7667],\n",
      "        [ 6.1953,  2.3080,  3.4473, -4.5966,  5.6970, -1.1028]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.40467947721481323\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.1336, 2.2350, 3.2231],\n",
      "        [6.2326, 2.3689, 3.4476],\n",
      "        [6.1747, 2.2649, 3.3138],\n",
      "        [6.1050, 2.2593, 3.4369],\n",
      "        [6.3047, 2.3379, 3.6544],\n",
      "        [6.1494, 2.3590, 3.2781]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.3989, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.1460,  5.8228, -1.2080],\n",
      "        [-4.5591,  5.5227, -0.9489],\n",
      "        [-4.6838,  5.5128, -1.0714],\n",
      "        [-4.4774,  5.4398, -1.1435],\n",
      "        [-4.5278,  5.8756, -0.8055],\n",
      "        [-4.5819,  5.4322, -1.0225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.1336,  2.2350,  3.2231, -4.1460,  5.8228, -1.2080],\n",
      "        [ 6.2326,  2.3689,  3.4476, -4.5591,  5.5227, -0.9489],\n",
      "        [ 6.1747,  2.2649,  3.3138, -4.6838,  5.5128, -1.0714],\n",
      "        [ 6.1050,  2.2593,  3.4369, -4.4774,  5.4398, -1.1435],\n",
      "        [ 6.3047,  2.3379,  3.6544, -4.5278,  5.8756, -0.8055],\n",
      "        [ 6.1494,  2.3590,  3.2781, -4.5819,  5.4322, -1.0225]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4001022279262543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5135, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.2500, 2.3198, 3.5938],\n",
      "        [6.1011, 2.1289, 3.5143],\n",
      "        [6.0069, 2.3299, 3.2300],\n",
      "        [6.0394, 2.4421, 3.6398],\n",
      "        [6.4030, 2.2536, 3.4930],\n",
      "        [6.1162, 2.3434, 3.4880]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.3612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.6538,  5.4835, -0.7983],\n",
      "        [-4.7553,  5.7962, -1.0092],\n",
      "        [-4.6215,  5.7296, -1.0281],\n",
      "        [-4.4920,  5.7433, -1.1229],\n",
      "        [-4.5266,  5.4942, -1.2101],\n",
      "        [-4.6739,  5.4349, -1.0847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.2500,  2.3198,  3.5938, -4.6538,  5.4835, -0.7983],\n",
      "        [ 6.1011,  2.1289,  3.5143, -4.7553,  5.7962, -1.0092],\n",
      "        [ 6.0069,  2.3299,  3.2300, -4.6215,  5.7296, -1.0281],\n",
      "        [ 6.0394,  2.4421,  3.6398, -4.4920,  5.7433, -1.1229],\n",
      "        [ 6.4030,  2.2536,  3.4930, -4.5266,  5.4942, -1.2101],\n",
      "        [ 6.1162,  2.3434,  3.4880, -4.6739,  5.4349, -1.0847]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4128493368625641\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1861, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.3856, 2.2951, 3.4339],\n",
      "        [6.3621, 2.5754, 3.6480],\n",
      "        [6.0256, 2.3320, 3.4654],\n",
      "        [6.3430, 2.3957, 3.6588],\n",
      "        [6.6073, 2.4724, 3.4267],\n",
      "        [6.3681, 2.4080, 3.5638]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.5924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.3550,  5.5969, -0.8918],\n",
      "        [-4.5183,  5.9074, -0.8138],\n",
      "        [-4.7938,  5.8451, -1.0605],\n",
      "        [-4.5045,  5.7316, -0.9466],\n",
      "        [-4.7372,  5.6846, -0.9396],\n",
      "        [-4.4471,  5.6610, -1.0403]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.3856,  2.2951,  3.4339, -4.3550,  5.5969, -0.8918],\n",
      "        [ 6.3621,  2.5754,  3.6480, -4.5183,  5.9074, -0.8138],\n",
      "        [ 6.0256,  2.3320,  3.4654, -4.7938,  5.8451, -1.0605],\n",
      "        [ 6.3430,  2.3957,  3.6588, -4.5045,  5.7316, -0.9466],\n",
      "        [ 6.6073,  2.4724,  3.4267, -4.7372,  5.6846, -0.9396],\n",
      "        [ 6.3681,  2.4080,  3.5638, -4.4471,  5.6610, -1.0403]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4122159779071808\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8800, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.3368, 2.3123, 3.4760],\n",
      "        [6.5406, 2.2369, 3.5198],\n",
      "        [6.5228, 2.2442, 3.5124],\n",
      "        [6.3871, 2.3980, 3.8477],\n",
      "        [6.6403, 2.4022, 3.7836],\n",
      "        [6.3318, 2.2120, 3.6036]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.2733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.6488,  5.6514, -1.0255],\n",
      "        [-4.3633,  5.9022, -0.9687],\n",
      "        [-4.5804,  5.8092, -0.8697],\n",
      "        [-4.7002,  5.7755, -0.8679],\n",
      "        [-4.7080,  5.7575, -0.9533],\n",
      "        [-4.5713,  5.6086, -0.8152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.3368,  2.3123,  3.4760, -4.6488,  5.6514, -1.0255],\n",
      "        [ 6.5406,  2.2369,  3.5198, -4.3633,  5.9022, -0.9687],\n",
      "        [ 6.5228,  2.2442,  3.5124, -4.5804,  5.8092, -0.8697],\n",
      "        [ 6.3871,  2.3980,  3.8477, -4.7002,  5.7755, -0.8679],\n",
      "        [ 6.6403,  2.4022,  3.7836, -4.7080,  5.7575, -0.9533],\n",
      "        [ 6.3318,  2.2120,  3.6036, -4.5713,  5.6086, -0.8152]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.4160290062427521\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7632, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.5283, 2.3633, 3.6902],\n",
      "        [6.1654, 2.4617, 3.4539],\n",
      "        [6.5771, 2.3255, 3.6700],\n",
      "        [6.5692, 2.2730, 3.5003],\n",
      "        [6.4384, 2.3271, 3.5513],\n",
      "        [6.3624, 2.4405, 3.3414]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.5486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.6152,  5.8052, -0.8687],\n",
      "        [-4.5168,  5.5608, -0.9435],\n",
      "        [-4.5599,  5.8787, -1.1655],\n",
      "        [-4.7783,  5.6384, -0.9950],\n",
      "        [-4.5071,  5.6755, -1.0582],\n",
      "        [-4.5354,  5.6648, -1.0199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.5283,  2.3633,  3.6902, -4.6152,  5.8052, -0.8687],\n",
      "        [ 6.1654,  2.4617,  3.4539, -4.5168,  5.5608, -0.9435],\n",
      "        [ 6.5771,  2.3255,  3.6700, -4.5599,  5.8787, -1.1655],\n",
      "        [ 6.5692,  2.2730,  3.5003, -4.7783,  5.6384, -0.9950],\n",
      "        [ 6.4384,  2.3271,  3.5513, -4.5071,  5.6755, -1.0582],\n",
      "        [ 6.3624,  2.4405,  3.3414, -4.5354,  5.6648, -1.0199]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.42867955565452576\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3618, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.3735, 2.3814, 3.6841],\n",
      "        [6.5495, 2.4675, 3.6046],\n",
      "        [6.4493, 2.4749, 3.4512],\n",
      "        [6.5176, 2.4624, 3.4435],\n",
      "        [6.4327, 2.2253, 3.5247],\n",
      "        [6.4087, 2.3772, 3.3938]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.0193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.5909,  5.7818, -1.0695],\n",
      "        [-4.6999,  5.8857, -0.9655],\n",
      "        [-4.7002,  6.0357, -1.0157],\n",
      "        [-4.7890,  5.6262, -1.0564],\n",
      "        [-4.8449,  5.9171, -0.8484],\n",
      "        [-4.7444,  5.9553, -1.0774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.3735,  2.3814,  3.6841, -4.5909,  5.7818, -1.0695],\n",
      "        [ 6.5495,  2.4675,  3.6046, -4.6999,  5.8857, -0.9655],\n",
      "        [ 6.4493,  2.4749,  3.4512, -4.7002,  6.0357, -1.0157],\n",
      "        [ 6.5176,  2.4624,  3.4435, -4.7890,  5.6262, -1.0564],\n",
      "        [ 6.4327,  2.2253,  3.5247, -4.8449,  5.9171, -0.8484],\n",
      "        [ 6.4087,  2.3772,  3.3938, -4.7444,  5.9553, -1.0774]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.42398539185523987\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.2512, 2.5073, 3.5252],\n",
      "        [6.4901, 2.3866, 3.7418],\n",
      "        [6.3837, 2.3349, 3.5544],\n",
      "        [6.3443, 2.4742, 3.4119],\n",
      "        [6.4344, 2.2228, 3.2620],\n",
      "        [6.3905, 2.5247, 3.6053]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.8182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.5040,  5.8625, -0.9851],\n",
      "        [-4.7740,  5.7630, -0.8242],\n",
      "        [-4.6943,  5.8227, -0.9633],\n",
      "        [-4.6663,  5.8359, -0.7636],\n",
      "        [-4.6692,  5.7783, -0.9763],\n",
      "        [-4.5750,  5.8592, -0.9326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.2512,  2.5073,  3.5252, -4.5040,  5.8625, -0.9851],\n",
      "        [ 6.4901,  2.3866,  3.7418, -4.7740,  5.7630, -0.8242],\n",
      "        [ 6.3837,  2.3349,  3.5544, -4.6943,  5.8227, -0.9633],\n",
      "        [ 6.3443,  2.4742,  3.4119, -4.6663,  5.8359, -0.7636],\n",
      "        [ 6.4344,  2.2228,  3.2620, -4.6692,  5.7783, -0.9763],\n",
      "        [ 6.3905,  2.5247,  3.6053, -4.5750,  5.8592, -0.9326]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.41832444071769714\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2218, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.6341, 2.3484, 3.4221],\n",
      "        [6.5884, 2.6423, 3.6701],\n",
      "        [6.5384, 2.6094, 3.7222],\n",
      "        [6.4317, 2.4812, 3.8133],\n",
      "        [6.6106, 2.3330, 3.7498],\n",
      "        [6.4188, 2.4044, 3.6561]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.4565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.7927,  5.8302, -0.9393],\n",
      "        [-4.8824,  5.6865, -1.0348],\n",
      "        [-4.7015,  6.0196, -0.7232],\n",
      "        [-4.4769,  5.6989, -0.8035],\n",
      "        [-4.6856,  5.9954, -1.0249],\n",
      "        [-4.7782,  5.8887, -1.1396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.6341,  2.3484,  3.4221, -4.7927,  5.8302, -0.9393],\n",
      "        [ 6.5884,  2.6423,  3.6701, -4.8824,  5.6865, -1.0348],\n",
      "        [ 6.5384,  2.6094,  3.7222, -4.7015,  6.0196, -0.7232],\n",
      "        [ 6.4317,  2.4812,  3.8133, -4.4769,  5.6989, -0.8035],\n",
      "        [ 6.6106,  2.3330,  3.7498, -4.6856,  5.9954, -1.0249],\n",
      "        [ 6.4188,  2.4044,  3.6561, -4.7782,  5.8887, -1.1396]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4292861819267273\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.7219, 2.3638, 3.5609],\n",
      "        [6.7016, 2.4402, 3.6956],\n",
      "        [6.2775, 2.5761, 3.7667],\n",
      "        [6.3770, 2.6340, 3.6325],\n",
      "        [6.6162, 2.4665, 3.5422],\n",
      "        [6.5183, 2.3161, 3.8689]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.2524, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.8335,  5.9378, -0.8771],\n",
      "        [-4.7140,  5.6010, -0.9117],\n",
      "        [-4.7075,  6.0314, -1.1415],\n",
      "        [-4.8225,  5.9254, -0.9731],\n",
      "        [-4.7336,  6.1193, -1.1450],\n",
      "        [-4.8307,  5.8724, -0.9151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.7219,  2.3638,  3.5609, -4.8335,  5.9378, -0.8771],\n",
      "        [ 6.7016,  2.4402,  3.6956, -4.7140,  5.6010, -0.9117],\n",
      "        [ 6.2775,  2.5761,  3.7667, -4.7075,  6.0314, -1.1415],\n",
      "        [ 6.3770,  2.6340,  3.6325, -4.8225,  5.9254, -0.9731],\n",
      "        [ 6.6162,  2.4665,  3.5422, -4.7336,  6.1193, -1.1450],\n",
      "        [ 6.5183,  2.3161,  3.8689, -4.8307,  5.8724, -0.9151]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.43713054060935974\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.5003, 2.4124, 3.6222],\n",
      "        [6.6056, 2.5210, 3.7654],\n",
      "        [6.5284, 2.6848, 3.9125],\n",
      "        [6.5882, 2.4214, 3.7030],\n",
      "        [6.7281, 2.0121, 3.8192],\n",
      "        [6.6221, 2.3510, 3.4886]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.7666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.8646,  5.8991, -1.2532],\n",
      "        [-4.7291,  5.9748, -0.8788],\n",
      "        [-4.9241,  5.8000, -1.1512],\n",
      "        [-4.9756,  5.9141, -1.0215],\n",
      "        [-4.6856,  5.8859, -1.0658],\n",
      "        [-4.9747,  6.0418, -1.3656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.5003,  2.4124,  3.6222, -4.8646,  5.8991, -1.2532],\n",
      "        [ 6.6056,  2.5210,  3.7654, -4.7291,  5.9748, -0.8788],\n",
      "        [ 6.5284,  2.6848,  3.9125, -4.9241,  5.8000, -1.1512],\n",
      "        [ 6.5882,  2.4214,  3.7030, -4.9756,  5.9141, -1.0215],\n",
      "        [ 6.7281,  2.0121,  3.8192, -4.6856,  5.8859, -1.0658],\n",
      "        [ 6.6221,  2.3510,  3.4886, -4.9747,  6.0418, -1.3656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.43277761340141296\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7768, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.6197, 2.5535, 3.7972],\n",
      "        [6.7082, 2.4450, 3.6940],\n",
      "        [6.5497, 2.1677, 3.7393],\n",
      "        [6.5771, 2.5074, 3.7087],\n",
      "        [6.7774, 2.3235, 3.6388],\n",
      "        [6.7856, 2.6704, 3.7633]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.7359, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9079,  5.9402, -1.1456],\n",
      "        [-4.7480,  5.9806, -0.9324],\n",
      "        [-4.6778,  6.1441, -0.9982],\n",
      "        [-5.1267,  5.8907, -1.2000],\n",
      "        [-4.6009,  6.0200, -0.8915],\n",
      "        [-4.7456,  5.8449, -1.1854]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.6197,  2.5535,  3.7972, -4.9079,  5.9402, -1.1456],\n",
      "        [ 6.7082,  2.4450,  3.6940, -4.7480,  5.9806, -0.9324],\n",
      "        [ 6.5497,  2.1677,  3.7393, -4.6778,  6.1441, -0.9982],\n",
      "        [ 6.5771,  2.5074,  3.7087, -5.1267,  5.8907, -1.2000],\n",
      "        [ 6.7774,  2.3235,  3.6388, -4.6009,  6.0200, -0.8915],\n",
      "        [ 6.7856,  2.6704,  3.7633, -4.7456,  5.8449, -1.1854]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.4426882863044739\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.5527, 2.7617, 3.6206],\n",
      "        [6.6302, 2.3654, 3.6918],\n",
      "        [6.7280, 2.5668, 3.8241],\n",
      "        [6.6151, 2.5408, 3.7568],\n",
      "        [6.6341, 2.4861, 3.6691],\n",
      "        [6.6957, 2.8105, 3.8899]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.3318, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.8017,  6.2163, -1.1892],\n",
      "        [-4.9945,  5.9145, -1.1108],\n",
      "        [-4.6943,  5.5714, -0.8944],\n",
      "        [-4.7906,  6.0320, -1.0865],\n",
      "        [-4.8322,  6.0923, -0.9022],\n",
      "        [-4.8838,  6.0631, -1.1726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.5527,  2.7617,  3.6206, -4.8017,  6.2163, -1.1892],\n",
      "        [ 6.6302,  2.3654,  3.6918, -4.9945,  5.9145, -1.1108],\n",
      "        [ 6.7280,  2.5668,  3.8241, -4.6943,  5.5714, -0.8944],\n",
      "        [ 6.6151,  2.5408,  3.7568, -4.7906,  6.0320, -1.0865],\n",
      "        [ 6.6341,  2.4861,  3.6691, -4.8322,  6.0923, -0.9022],\n",
      "        [ 6.6957,  2.8105,  3.8899, -4.8838,  6.0631, -1.1726]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4417516887187958\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.6960, 2.6199, 3.7603],\n",
      "        [6.7279, 2.4285, 3.8065],\n",
      "        [6.4398, 2.5943, 3.5641],\n",
      "        [6.6799, 2.6103, 3.6235],\n",
      "        [6.5446, 2.6568, 3.6601],\n",
      "        [6.6420, 2.9224, 3.8404]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9177, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.7807,  5.8737, -1.0175],\n",
      "        [-4.6617,  6.1741, -0.9954],\n",
      "        [-4.7481,  6.1639, -0.9213],\n",
      "        [-4.5768,  6.1297, -0.9656],\n",
      "        [-4.9899,  6.2035, -1.1465],\n",
      "        [-5.1725,  6.0264, -0.8187]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.6960,  2.6199,  3.7603, -4.7807,  5.8737, -1.0175],\n",
      "        [ 6.7279,  2.4285,  3.8065, -4.6617,  6.1741, -0.9954],\n",
      "        [ 6.4398,  2.5943,  3.5641, -4.7481,  6.1639, -0.9213],\n",
      "        [ 6.6799,  2.6103,  3.6235, -4.5768,  6.1297, -0.9656],\n",
      "        [ 6.5446,  2.6568,  3.6601, -4.9899,  6.2035, -1.1465],\n",
      "        [ 6.6420,  2.9224,  3.8404, -5.1725,  6.0264, -0.8187]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4430876672267914\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9202, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.8274, 2.6268, 3.8455],\n",
      "        [6.8971, 2.5076, 3.8417],\n",
      "        [6.8727, 2.4782, 4.1365],\n",
      "        [6.6066, 2.5554, 3.9182],\n",
      "        [6.5972, 2.6283, 3.8297],\n",
      "        [6.8032, 2.7707, 3.9037]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.6814, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.6291,  6.0597, -1.1055],\n",
      "        [-4.8622,  6.0544, -1.0481],\n",
      "        [-4.9897,  6.0469, -1.0956],\n",
      "        [-5.0511,  6.0717, -1.1753],\n",
      "        [-5.1503,  5.8443, -1.2473],\n",
      "        [-4.8803,  5.6820, -0.8380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.8274,  2.6268,  3.8455, -4.6291,  6.0597, -1.1055],\n",
      "        [ 6.8971,  2.5076,  3.8417, -4.8622,  6.0544, -1.0481],\n",
      "        [ 6.8727,  2.4782,  4.1365, -4.9897,  6.0469, -1.0956],\n",
      "        [ 6.6066,  2.5554,  3.9182, -5.0511,  6.0717, -1.1753],\n",
      "        [ 6.5972,  2.6283,  3.8297, -5.1503,  5.8443, -1.2473],\n",
      "        [ 6.8032,  2.7707,  3.9037, -4.8803,  5.6820, -0.8380]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.45036017894744873\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.8158, 2.6233, 3.9889],\n",
      "        [6.7888, 2.5743, 3.5606],\n",
      "        [6.9855, 2.5734, 3.7573],\n",
      "        [6.7009, 2.6063, 3.6536],\n",
      "        [6.6882, 2.7641, 3.9255],\n",
      "        [6.8422, 2.3952, 3.6580]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.7380, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.7458,  5.9190, -1.1497],\n",
      "        [-4.8795,  6.1173, -1.1846],\n",
      "        [-5.0389,  5.8934, -1.1612],\n",
      "        [-4.9326,  6.0899, -1.1972],\n",
      "        [-5.0156,  6.1196, -1.2866],\n",
      "        [-5.1055,  6.2310, -1.1728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.8158,  2.6233,  3.9889, -4.7458,  5.9190, -1.1497],\n",
      "        [ 6.7888,  2.5743,  3.5606, -4.8795,  6.1173, -1.1846],\n",
      "        [ 6.9855,  2.5734,  3.7573, -5.0389,  5.8934, -1.1612],\n",
      "        [ 6.7009,  2.6063,  3.6536, -4.9326,  6.0899, -1.1972],\n",
      "        [ 6.6882,  2.7641,  3.9255, -5.0156,  6.1196, -1.2866],\n",
      "        [ 6.8422,  2.3952,  3.6580, -5.1055,  6.2310, -1.1728]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.45278680324554443\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.9467, 2.6313, 3.7938],\n",
      "        [6.7823, 2.6298, 3.7550],\n",
      "        [6.6458, 2.5686, 3.6065],\n",
      "        [6.8921, 2.6495, 3.8444],\n",
      "        [6.6918, 2.4504, 4.0408],\n",
      "        [6.8359, 2.3906, 3.8407]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.6854, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9960,  6.1378, -1.3453],\n",
      "        [-4.9795,  6.0988, -1.2133],\n",
      "        [-4.9494,  6.3058, -1.2060],\n",
      "        [-5.2509,  6.2345, -1.0182],\n",
      "        [-4.7421,  6.1803, -1.2515],\n",
      "        [-4.9796,  6.2717, -1.0529]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.9467,  2.6313,  3.7938, -4.9960,  6.1378, -1.3453],\n",
      "        [ 6.7823,  2.6298,  3.7550, -4.9795,  6.0988, -1.2133],\n",
      "        [ 6.6458,  2.5686,  3.6065, -4.9494,  6.3058, -1.2060],\n",
      "        [ 6.8921,  2.6495,  3.8444, -5.2509,  6.2345, -1.0182],\n",
      "        [ 6.6918,  2.4504,  4.0408, -4.7421,  6.1803, -1.2515],\n",
      "        [ 6.8359,  2.3906,  3.8407, -4.9796,  6.2717, -1.0529]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4589548408985138\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6084, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.6806, 2.4877, 3.7294],\n",
      "        [6.6896, 2.6365, 3.7432],\n",
      "        [6.4841, 2.7677, 3.5866],\n",
      "        [6.8189, 2.0826, 3.6435],\n",
      "        [6.8114, 2.7470, 3.8029],\n",
      "        [6.8095, 2.5668, 3.9525]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.0325, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0665,  6.1073, -1.1093],\n",
      "        [-5.0468,  6.1044, -0.9120],\n",
      "        [-5.1714,  6.1050, -1.0623],\n",
      "        [-4.6298,  6.0817, -0.9758],\n",
      "        [-4.8379,  5.9618, -0.9839],\n",
      "        [-4.9993,  5.9741, -1.2745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.6806,  2.4877,  3.7294, -5.0665,  6.1073, -1.1093],\n",
      "        [ 6.6896,  2.6365,  3.7432, -5.0468,  6.1044, -0.9120],\n",
      "        [ 6.4841,  2.7677,  3.5866, -5.1714,  6.1050, -1.0623],\n",
      "        [ 6.8189,  2.0826,  3.6435, -4.6298,  6.0817, -0.9758],\n",
      "        [ 6.8114,  2.7470,  3.8029, -4.8379,  5.9618, -0.9839],\n",
      "        [ 6.8095,  2.5668,  3.9525, -4.9993,  5.9741, -1.2745]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.44812777638435364\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4117, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.7900, 2.7069, 4.0833],\n",
      "        [6.7842, 2.5731, 3.9640],\n",
      "        [7.0027, 2.5738, 4.0911],\n",
      "        [6.7360, 2.6258, 3.8548],\n",
      "        [6.8236, 2.5301, 4.0212],\n",
      "        [6.9474, 2.7057, 4.1312]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.7025, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-4.9801,  6.0426, -1.1673],\n",
      "        [-5.0445,  6.0528, -1.0357],\n",
      "        [-5.0956,  6.1955, -1.0720],\n",
      "        [-5.0871,  6.3106, -1.0248],\n",
      "        [-5.2520,  6.4558, -1.1994],\n",
      "        [-5.0256,  5.9862, -1.1057]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.7900,  2.7069,  4.0833, -4.9801,  6.0426, -1.1673],\n",
      "        [ 6.7842,  2.5731,  3.9640, -5.0445,  6.0528, -1.0357],\n",
      "        [ 7.0027,  2.5738,  4.0911, -5.0956,  6.1955, -1.0720],\n",
      "        [ 6.7360,  2.6258,  3.8548, -5.0871,  6.3106, -1.0248],\n",
      "        [ 6.8236,  2.5301,  4.0212, -5.2520,  6.4558, -1.1994],\n",
      "        [ 6.9474,  2.7057,  4.1312, -5.0256,  5.9862, -1.1057]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.45988696813583374\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5505, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.0021, 2.7384, 3.8122],\n",
      "        [7.0629, 2.3980, 3.8740],\n",
      "        [6.6990, 2.5819, 3.7740],\n",
      "        [6.9025, 2.5366, 3.8603],\n",
      "        [6.7662, 2.5581, 4.0874],\n",
      "        [6.7937, 2.7060, 3.8744]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.5377, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0950,  5.8482, -1.0841],\n",
      "        [-4.8923,  6.2187, -0.9992],\n",
      "        [-5.1955,  6.1598, -1.0782],\n",
      "        [-5.0497,  6.1740, -1.3315],\n",
      "        [-4.9367,  6.3059, -1.0777],\n",
      "        [-4.9945,  6.2446, -1.4393]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.0021,  2.7384,  3.8122, -5.0950,  5.8482, -1.0841],\n",
      "        [ 7.0629,  2.3980,  3.8740, -4.8923,  6.2187, -0.9992],\n",
      "        [ 6.6990,  2.5819,  3.7740, -5.1955,  6.1598, -1.0782],\n",
      "        [ 6.9025,  2.5366,  3.8603, -5.0497,  6.1740, -1.3315],\n",
      "        [ 6.7662,  2.5581,  4.0874, -4.9367,  6.3059, -1.0777],\n",
      "        [ 6.7937,  2.7060,  3.8744, -4.9945,  6.2446, -1.4393]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.45981937646865845\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.7807, 2.5253, 4.0158],\n",
      "        [6.9605, 2.5884, 3.9907],\n",
      "        [6.8878, 2.6666, 3.8128],\n",
      "        [7.1486, 2.6642, 4.0765],\n",
      "        [6.8753, 2.7058, 3.8964],\n",
      "        [6.8099, 2.4734, 4.0588]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.7002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2402,  6.4226, -1.3490],\n",
      "        [-5.0945,  6.0925, -1.3189],\n",
      "        [-5.1345,  6.2055, -1.1177],\n",
      "        [-5.1278,  6.2118, -1.3117],\n",
      "        [-5.3070,  6.2883, -1.0185],\n",
      "        [-4.9424,  6.5754, -1.0994]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.7807,  2.5253,  4.0158, -5.2402,  6.4226, -1.3490],\n",
      "        [ 6.9605,  2.5884,  3.9907, -5.0945,  6.0925, -1.3189],\n",
      "        [ 6.8878,  2.6666,  3.8128, -5.1345,  6.2055, -1.1177],\n",
      "        [ 7.1486,  2.6642,  4.0765, -5.1278,  6.2118, -1.3117],\n",
      "        [ 6.8753,  2.7058,  3.8964, -5.3070,  6.2883, -1.0185],\n",
      "        [ 6.8099,  2.4734,  4.0588, -4.9424,  6.5754, -1.0994]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4651161730289459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.1108, 2.8278, 3.6950],\n",
      "        [6.7593, 2.8277, 3.9974],\n",
      "        [7.1395, 2.6453, 3.8696],\n",
      "        [7.0983, 2.5525, 4.0497],\n",
      "        [6.9582, 2.6832, 3.9552],\n",
      "        [6.8590, 2.6099, 3.9156]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.1398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3902,  6.4049, -1.1280],\n",
      "        [-5.3788,  6.3863, -1.0782],\n",
      "        [-5.3453,  6.2762, -1.2312],\n",
      "        [-5.1412,  6.2657, -1.2515],\n",
      "        [-5.0788,  6.2740, -1.2913],\n",
      "        [-5.4021,  6.4514, -0.9889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.1108,  2.8278,  3.6950, -5.3902,  6.4049, -1.1280],\n",
      "        [ 6.7593,  2.8277,  3.9974, -5.3788,  6.3863, -1.0782],\n",
      "        [ 7.1395,  2.6453,  3.8696, -5.3453,  6.2762, -1.2312],\n",
      "        [ 7.0983,  2.5525,  4.0497, -5.1412,  6.2657, -1.2515],\n",
      "        [ 6.9582,  2.6832,  3.9552, -5.0788,  6.2740, -1.2913],\n",
      "        [ 6.8590,  2.6099,  3.9156, -5.4021,  6.4514, -0.9889]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4727925956249237\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.9047, 2.8522, 3.8416],\n",
      "        [6.7664, 2.6586, 4.3098],\n",
      "        [7.0073, 2.7787, 3.8577],\n",
      "        [6.9657, 2.7940, 3.9856],\n",
      "        [6.8646, 2.6977, 4.1869],\n",
      "        [7.0133, 2.9322, 4.0055]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.7127, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0748,  6.3334, -1.1554],\n",
      "        [-5.0618,  6.2076, -0.8487],\n",
      "        [-5.0902,  6.3003, -1.2075],\n",
      "        [-5.1354,  6.4662, -1.2559],\n",
      "        [-5.3717,  6.5069, -1.3038],\n",
      "        [-5.2672,  6.2072, -1.1885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.9047,  2.8522,  3.8416, -5.0748,  6.3334, -1.1554],\n",
      "        [ 6.7664,  2.6586,  4.3098, -5.0618,  6.2076, -0.8487],\n",
      "        [ 7.0073,  2.7787,  3.8577, -5.0902,  6.3003, -1.2075],\n",
      "        [ 6.9657,  2.7940,  3.9856, -5.1354,  6.4662, -1.2559],\n",
      "        [ 6.8646,  2.6977,  4.1869, -5.3717,  6.5069, -1.3038],\n",
      "        [ 7.0133,  2.9322,  4.0055, -5.2672,  6.2072, -1.1885]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.46581166982650757\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[6.9783, 2.7590, 3.9330],\n",
      "        [7.0829, 2.5574, 3.9636],\n",
      "        [6.9344, 2.7891, 4.3336],\n",
      "        [6.8110, 2.8052, 4.1621],\n",
      "        [7.1141, 2.8787, 4.1489],\n",
      "        [6.8959, 2.6100, 4.1059]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.0467,  6.3165, -1.3455],\n",
      "        [-5.2612,  6.2953, -1.3397],\n",
      "        [-5.1205,  6.5971, -1.2022],\n",
      "        [-5.1096,  6.4346, -1.2421],\n",
      "        [-5.2872,  6.3108, -1.0940],\n",
      "        [-5.1082,  6.3684, -1.3580]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 6.9783,  2.7590,  3.9330, -5.0467,  6.3165, -1.3455],\n",
      "        [ 7.0829,  2.5574,  3.9636, -5.2612,  6.2953, -1.3397],\n",
      "        [ 6.9344,  2.7891,  4.3336, -5.1205,  6.5971, -1.2022],\n",
      "        [ 6.8110,  2.8052,  4.1621, -5.1096,  6.4346, -1.2421],\n",
      "        [ 7.1141,  2.8787,  4.1489, -5.2872,  6.3108, -1.0940],\n",
      "        [ 6.8959,  2.6100,  4.1059, -5.1082,  6.3684, -1.3580]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4693024456501007\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0793, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.1124, 2.6263, 4.0131],\n",
      "        [6.8834, 2.7589, 3.9895],\n",
      "        [7.0369, 2.6922, 4.1475],\n",
      "        [7.0709, 2.6252, 3.8898],\n",
      "        [7.0083, 2.8045, 4.2431],\n",
      "        [7.2337, 2.5078, 4.0167]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7390, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3130,  6.4971, -1.4098],\n",
      "        [-5.3942,  6.4476, -1.1961],\n",
      "        [-5.1888,  6.4169, -1.2175],\n",
      "        [-5.1657,  6.4085, -1.5300],\n",
      "        [-5.2270,  6.3721, -1.1719],\n",
      "        [-5.4173,  6.2336, -1.3023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.1124,  2.6263,  4.0131, -5.3130,  6.4971, -1.4098],\n",
      "        [ 6.8834,  2.7589,  3.9895, -5.3942,  6.4476, -1.1961],\n",
      "        [ 7.0369,  2.6922,  4.1475, -5.1888,  6.4169, -1.2175],\n",
      "        [ 7.0709,  2.6252,  3.8898, -5.1657,  6.4085, -1.5300],\n",
      "        [ 7.0083,  2.8045,  4.2431, -5.2270,  6.3721, -1.1719],\n",
      "        [ 7.2337,  2.5078,  4.0167, -5.4173,  6.2336, -1.3023]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.47957852482795715\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.0743, 2.6972, 4.3486],\n",
      "        [6.9838, 2.7223, 4.0280],\n",
      "        [6.9749, 2.6278, 4.0276],\n",
      "        [7.1863, 2.6992, 3.8503],\n",
      "        [7.2592, 2.7909, 3.9247],\n",
      "        [7.1870, 2.8322, 4.1237]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.1162, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4045,  6.6802, -1.3115],\n",
      "        [-4.9656,  6.5252, -1.0620],\n",
      "        [-5.3385,  6.3596, -1.2407],\n",
      "        [-5.0392,  6.5816, -1.0892],\n",
      "        [-5.3893,  6.5973, -1.1801],\n",
      "        [-5.3783,  6.5194, -1.3070]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.0743,  2.6972,  4.3486, -5.4045,  6.6802, -1.3115],\n",
      "        [ 6.9838,  2.7223,  4.0280, -4.9656,  6.5252, -1.0620],\n",
      "        [ 6.9749,  2.6278,  4.0276, -5.3385,  6.3596, -1.2407],\n",
      "        [ 7.1863,  2.6992,  3.8503, -5.0392,  6.5816, -1.0892],\n",
      "        [ 7.2592,  2.7909,  3.9247, -5.3893,  6.5973, -1.1801],\n",
      "        [ 7.1870,  2.8322,  4.1237, -5.3783,  6.5194, -1.3070]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.489841103553772\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.1472, 2.7331, 4.0434],\n",
      "        [7.2413, 2.7668, 4.2322],\n",
      "        [7.0197, 2.9615, 4.0251],\n",
      "        [7.1407, 2.6726, 3.9210],\n",
      "        [7.0474, 2.7657, 4.2473],\n",
      "        [7.1513, 2.7982, 4.2134]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.3082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2050,  6.3870, -1.3335],\n",
      "        [-5.3037,  6.4373, -0.9050],\n",
      "        [-5.3303,  6.3139, -1.2542],\n",
      "        [-5.4561,  6.5491, -1.2118],\n",
      "        [-5.1592,  6.1824, -1.0092],\n",
      "        [-5.1322,  6.5677, -1.3531]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.1472,  2.7331,  4.0434, -5.2050,  6.3870, -1.3335],\n",
      "        [ 7.2413,  2.7668,  4.2322, -5.3037,  6.4373, -0.9050],\n",
      "        [ 7.0197,  2.9615,  4.0251, -5.3303,  6.3139, -1.2542],\n",
      "        [ 7.1407,  2.6726,  3.9210, -5.4561,  6.5491, -1.2118],\n",
      "        [ 7.0474,  2.7657,  4.2473, -5.1592,  6.1824, -1.0092],\n",
      "        [ 7.1513,  2.7982,  4.2134, -5.1322,  6.5677, -1.3531]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.48027387261390686\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5231, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.3757, 3.1194, 4.1255],\n",
      "        [7.0458, 2.6854, 4.0504],\n",
      "        [7.1513, 2.8817, 3.9493],\n",
      "        [7.1979, 2.6090, 4.0741],\n",
      "        [7.0459, 2.8064, 4.2768],\n",
      "        [7.0940, 2.7523, 3.8466]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.2344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2417,  6.3545, -1.3377],\n",
      "        [-5.1502,  6.2514, -1.4269],\n",
      "        [-5.0491,  6.4181, -1.2521],\n",
      "        [-4.9776,  6.5921, -1.0661],\n",
      "        [-5.2982,  6.2313, -1.3985],\n",
      "        [-5.2815,  6.5283, -1.2152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.3757,  3.1194,  4.1255, -5.2417,  6.3545, -1.3377],\n",
      "        [ 7.0458,  2.6854,  4.0504, -5.1502,  6.2514, -1.4269],\n",
      "        [ 7.1513,  2.8817,  3.9493, -5.0491,  6.4181, -1.2521],\n",
      "        [ 7.1979,  2.6090,  4.0741, -4.9776,  6.5921, -1.0661],\n",
      "        [ 7.0459,  2.8064,  4.2768, -5.2982,  6.2313, -1.3985],\n",
      "        [ 7.0940,  2.7523,  3.8466, -5.2815,  6.5283, -1.2152]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4933028221130371\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.0583, 2.6723, 4.1408],\n",
      "        [7.0927, 2.3926, 3.8537],\n",
      "        [7.0070, 2.8843, 4.2000],\n",
      "        [7.0071, 2.8996, 4.0442],\n",
      "        [7.1298, 2.6506, 4.0674],\n",
      "        [7.2568, 2.7607, 4.3501]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.2228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2477,  6.7044, -0.8962],\n",
      "        [-5.3594,  6.5762, -1.4103],\n",
      "        [-5.3872,  6.5830, -1.3456],\n",
      "        [-4.9843,  6.9352, -1.6420],\n",
      "        [-5.3714,  6.6641, -1.3553],\n",
      "        [-5.2233,  6.4864, -1.4444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.0583,  2.6723,  4.1408, -5.2477,  6.7044, -0.8962],\n",
      "        [ 7.0927,  2.3926,  3.8537, -5.3594,  6.5762, -1.4103],\n",
      "        [ 7.0070,  2.8843,  4.2000, -5.3872,  6.5830, -1.3456],\n",
      "        [ 7.0071,  2.8996,  4.0442, -4.9843,  6.9352, -1.6420],\n",
      "        [ 7.1298,  2.6506,  4.0674, -5.3714,  6.6641, -1.3553],\n",
      "        [ 7.2568,  2.7607,  4.3501, -5.2233,  6.4864, -1.4444]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.48348718881607056\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0492, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.2128, 2.6796, 4.0520],\n",
      "        [7.1919, 2.7015, 3.8704],\n",
      "        [7.2886, 2.8277, 4.0671],\n",
      "        [7.4381, 2.7796, 4.0279],\n",
      "        [7.2437, 2.9898, 4.0045],\n",
      "        [7.2562, 2.9402, 4.0709]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.5215, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.1630,  6.2942, -1.2273],\n",
      "        [-5.5434,  6.4120, -1.2882],\n",
      "        [-5.2952,  6.5772, -1.2499],\n",
      "        [-5.3580,  6.7632, -1.3089],\n",
      "        [-5.1981,  6.8927, -1.3994],\n",
      "        [-5.1787,  6.5267, -1.4022]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.2128,  2.6796,  4.0520, -5.1630,  6.2942, -1.2273],\n",
      "        [ 7.1919,  2.7015,  3.8704, -5.5434,  6.4120, -1.2882],\n",
      "        [ 7.2886,  2.8277,  4.0671, -5.2952,  6.5772, -1.2499],\n",
      "        [ 7.4381,  2.7796,  4.0279, -5.3580,  6.7632, -1.3089],\n",
      "        [ 7.2437,  2.9898,  4.0045, -5.1981,  6.8927, -1.3994],\n",
      "        [ 7.2562,  2.9402,  4.0709, -5.1787,  6.5267, -1.4022]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4810783565044403\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.4171, 2.9075, 4.0592],\n",
      "        [7.0971, 2.5885, 4.2385],\n",
      "        [7.4789, 2.4835, 4.2440],\n",
      "        [7.1478, 2.7523, 4.2604],\n",
      "        [7.2677, 2.5976, 4.1887],\n",
      "        [7.0607, 3.0852, 3.6879]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.2710, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.2420,  6.7060, -1.3808],\n",
      "        [-5.4073,  6.8247, -1.3271],\n",
      "        [-5.3221,  6.7166, -1.1463],\n",
      "        [-5.2353,  6.4404, -1.2841],\n",
      "        [-5.4262,  6.3835, -1.4171],\n",
      "        [-5.3107,  6.6172, -1.2417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.4171,  2.9075,  4.0592, -5.2420,  6.7060, -1.3808],\n",
      "        [ 7.0971,  2.5885,  4.2385, -5.4073,  6.8247, -1.3271],\n",
      "        [ 7.4789,  2.4835,  4.2440, -5.3221,  6.7166, -1.1463],\n",
      "        [ 7.1478,  2.7523,  4.2604, -5.2353,  6.4404, -1.2841],\n",
      "        [ 7.2677,  2.5976,  4.1887, -5.4262,  6.3835, -1.4171],\n",
      "        [ 7.0607,  3.0852,  3.6879, -5.3107,  6.6172, -1.2417]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.4968642294406891\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.0408, 2.5271, 4.0951],\n",
      "        [7.4262, 2.7248, 4.0060],\n",
      "        [6.9770, 2.5714, 4.0923],\n",
      "        [7.3431, 2.8250, 4.1161],\n",
      "        [7.3145, 2.7346, 4.1209],\n",
      "        [7.2963, 2.9279, 3.8534]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3714, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5771,  6.4586, -1.1734],\n",
      "        [-5.4566,  6.6655, -1.1769],\n",
      "        [-5.3655,  6.5993, -1.3036],\n",
      "        [-5.2349,  6.6017, -1.4677],\n",
      "        [-5.3784,  6.6986, -1.3162],\n",
      "        [-5.6318,  6.8135, -1.4535]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.0408,  2.5271,  4.0951, -5.5771,  6.4586, -1.1734],\n",
      "        [ 7.4262,  2.7248,  4.0060, -5.4566,  6.6655, -1.1769],\n",
      "        [ 6.9770,  2.5714,  4.0923, -5.3655,  6.5993, -1.3036],\n",
      "        [ 7.3431,  2.8250,  4.1161, -5.2349,  6.6017, -1.4677],\n",
      "        [ 7.3145,  2.7346,  4.1209, -5.3784,  6.6986, -1.3162],\n",
      "        [ 7.2963,  2.9279,  3.8534, -5.6318,  6.8135, -1.4535]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.48230409622192383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.4315, 2.6361, 4.2921],\n",
      "        [7.5273, 2.8545, 4.4320],\n",
      "        [7.0708, 2.9165, 4.1080],\n",
      "        [7.1377, 2.7861, 4.1848],\n",
      "        [7.4460, 2.7156, 4.2623],\n",
      "        [7.4927, 2.9042, 4.3091]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.6391, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3543,  6.6400, -1.0707],\n",
      "        [-5.2133,  6.7202, -1.2504],\n",
      "        [-5.4285,  6.4850, -1.4818],\n",
      "        [-5.0960,  6.3428, -1.3420],\n",
      "        [-5.4143,  6.7837, -1.1284],\n",
      "        [-5.2295,  6.6862, -1.2515]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.4315,  2.6361,  4.2921, -5.3543,  6.6400, -1.0707],\n",
      "        [ 7.5273,  2.8545,  4.4320, -5.2133,  6.7202, -1.2504],\n",
      "        [ 7.0708,  2.9165,  4.1080, -5.4285,  6.4850, -1.4818],\n",
      "        [ 7.1377,  2.7861,  4.1848, -5.0960,  6.3428, -1.3420],\n",
      "        [ 7.4460,  2.7156,  4.2623, -5.4143,  6.7837, -1.1284],\n",
      "        [ 7.4927,  2.9042,  4.3091, -5.2295,  6.6862, -1.2515]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.5000242590904236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5921, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.1973, 2.9679, 4.2723],\n",
      "        [7.0820, 2.3897, 4.1541],\n",
      "        [7.2421, 3.0852, 3.9093],\n",
      "        [7.2862, 2.8745, 4.2553],\n",
      "        [7.3157, 2.8379, 4.1355],\n",
      "        [7.1106, 2.7822, 4.0068]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.3728, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.3371,  6.7531, -1.3665],\n",
      "        [-5.4936,  6.6110, -1.3625],\n",
      "        [-5.3842,  6.7855, -1.3166],\n",
      "        [-5.5124,  6.7963, -1.4470],\n",
      "        [-5.5350,  6.8306, -1.2095],\n",
      "        [-5.4527,  6.6297, -1.3027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.1973,  2.9679,  4.2723, -5.3371,  6.7531, -1.3665],\n",
      "        [ 7.0820,  2.3897,  4.1541, -5.4936,  6.6110, -1.3625],\n",
      "        [ 7.2421,  3.0852,  3.9093, -5.3842,  6.7855, -1.3166],\n",
      "        [ 7.2862,  2.8745,  4.2553, -5.5124,  6.7963, -1.4470],\n",
      "        [ 7.3157,  2.8379,  4.1355, -5.5350,  6.8306, -1.2095],\n",
      "        [ 7.1106,  2.7822,  4.0068, -5.4527,  6.6297, -1.3027]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.49782463908195496\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.5949, 2.9028, 4.3707],\n",
      "        [7.4385, 2.9561, 4.0958],\n",
      "        [7.5209, 3.0383, 4.2510],\n",
      "        [7.3656, 2.7238, 4.1843],\n",
      "        [7.4415, 2.7116, 4.1480],\n",
      "        [7.4091, 2.7063, 4.4236]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.2435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6200,  6.7384, -1.3644],\n",
      "        [-5.5287,  6.7396, -1.3965],\n",
      "        [-5.4122,  6.6899, -1.4207],\n",
      "        [-5.7017,  6.5293, -1.3862],\n",
      "        [-5.5792,  6.8333, -1.3067],\n",
      "        [-5.4441,  6.6424, -1.2745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.5949,  2.9028,  4.3707, -5.6200,  6.7384, -1.3644],\n",
      "        [ 7.4385,  2.9561,  4.0958, -5.5287,  6.7396, -1.3965],\n",
      "        [ 7.5209,  3.0383,  4.2510, -5.4122,  6.6899, -1.4207],\n",
      "        [ 7.3656,  2.7238,  4.1843, -5.7017,  6.5293, -1.3862],\n",
      "        [ 7.4415,  2.7116,  4.1480, -5.5792,  6.8333, -1.3067],\n",
      "        [ 7.4091,  2.7063,  4.4236, -5.4441,  6.6424, -1.2745]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5149561762809753\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.3799, 2.9673, 4.3965],\n",
      "        [7.5973, 2.9732, 4.3964],\n",
      "        [7.6216, 2.7876, 4.4721],\n",
      "        [7.2598, 2.8523, 4.3383],\n",
      "        [7.3556, 2.7109, 4.1591],\n",
      "        [7.6150, 2.6833, 4.3565]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.7462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5910,  6.6015, -1.3691],\n",
      "        [-5.3489,  6.6582, -1.3932],\n",
      "        [-5.4386,  6.6449, -1.5388],\n",
      "        [-5.5640,  6.5768, -1.4698],\n",
      "        [-5.4788,  6.8707, -1.2603],\n",
      "        [-5.3006,  6.8010, -1.3023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.3799,  2.9673,  4.3965, -5.5910,  6.6015, -1.3691],\n",
      "        [ 7.5973,  2.9732,  4.3964, -5.3489,  6.6582, -1.3932],\n",
      "        [ 7.6216,  2.7876,  4.4721, -5.4386,  6.6449, -1.5388],\n",
      "        [ 7.2598,  2.8523,  4.3383, -5.5640,  6.5768, -1.4698],\n",
      "        [ 7.3556,  2.7109,  4.1591, -5.4788,  6.8707, -1.2603],\n",
      "        [ 7.6150,  2.6833,  4.3565, -5.3006,  6.8010, -1.3023]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5076302886009216\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4151, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.5472, 2.8487, 4.0944],\n",
      "        [7.4074, 2.8547, 4.3751],\n",
      "        [7.2904, 2.7602, 4.1997],\n",
      "        [7.8049, 2.7586, 4.2719],\n",
      "        [7.6584, 2.8198, 4.1483],\n",
      "        [7.5120, 2.8712, 4.3178]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.1026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.4989,  6.6269, -1.5168],\n",
      "        [-5.6031,  6.9007, -1.3934],\n",
      "        [-5.4495,  6.5873, -1.2951],\n",
      "        [-5.3278,  6.4849, -1.3136],\n",
      "        [-5.5305,  6.7669, -1.5494],\n",
      "        [-5.5224,  6.7444, -1.3390]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.5472,  2.8487,  4.0944, -5.4989,  6.6269, -1.5168],\n",
      "        [ 7.4074,  2.8547,  4.3751, -5.6031,  6.9007, -1.3934],\n",
      "        [ 7.2904,  2.7602,  4.1997, -5.4495,  6.5873, -1.2951],\n",
      "        [ 7.8049,  2.7586,  4.2719, -5.3278,  6.4849, -1.3136],\n",
      "        [ 7.6584,  2.8198,  4.1483, -5.5305,  6.7669, -1.5494],\n",
      "        [ 7.5120,  2.8712,  4.3178, -5.5224,  6.7444, -1.3390]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5051639676094055\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.4049, 2.8261, 4.3642],\n",
      "        [7.7670, 3.1565, 4.1589],\n",
      "        [7.5044, 3.1040, 4.5884],\n",
      "        [7.5139, 2.9262, 4.4900],\n",
      "        [7.4573, 2.8204, 4.2918],\n",
      "        [7.6885, 2.8781, 4.3357]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.2765, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5655,  6.8514, -1.2938],\n",
      "        [-5.2948,  6.9649, -1.4037],\n",
      "        [-5.5229,  6.8063, -1.7868],\n",
      "        [-5.5313,  6.9463, -1.3439],\n",
      "        [-5.2692,  6.7952, -1.1925],\n",
      "        [-5.3662,  6.7429, -1.1276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.4049,  2.8261,  4.3642, -5.5655,  6.8514, -1.2938],\n",
      "        [ 7.7670,  3.1565,  4.1589, -5.2948,  6.9649, -1.4037],\n",
      "        [ 7.5044,  3.1040,  4.5884, -5.5229,  6.8063, -1.7868],\n",
      "        [ 7.5139,  2.9262,  4.4900, -5.5313,  6.9463, -1.3439],\n",
      "        [ 7.4573,  2.8204,  4.2918, -5.2692,  6.7952, -1.1925],\n",
      "        [ 7.6885,  2.8781,  4.3357, -5.3662,  6.7429, -1.1276]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5099279284477234\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.5523, 2.8079, 4.4079],\n",
      "        [7.4771, 2.8985, 4.3860],\n",
      "        [7.3716, 2.7684, 4.4903],\n",
      "        [7.3692, 2.6558, 4.4045],\n",
      "        [7.1941, 2.9918, 4.1858],\n",
      "        [7.3813, 2.8430, 4.2330]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.5991, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5935,  6.8637, -1.3706],\n",
      "        [-5.7326,  7.0613, -1.4629],\n",
      "        [-5.6835,  6.7973, -1.3702],\n",
      "        [-5.5231,  7.0039, -1.3292],\n",
      "        [-5.4413,  6.4187, -1.2791],\n",
      "        [-5.6127,  6.8284, -1.6927]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.5523,  2.8079,  4.4079, -5.5935,  6.8637, -1.3706],\n",
      "        [ 7.4771,  2.8985,  4.3860, -5.7326,  7.0613, -1.4629],\n",
      "        [ 7.3716,  2.7684,  4.4903, -5.6835,  6.7973, -1.3702],\n",
      "        [ 7.3692,  2.6558,  4.4045, -5.5231,  7.0039, -1.3292],\n",
      "        [ 7.1941,  2.9918,  4.1858, -5.4413,  6.4187, -1.2791],\n",
      "        [ 7.3813,  2.8430,  4.2330, -5.6127,  6.8284, -1.6927]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5162954330444336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.5048, 2.9077, 4.2144],\n",
      "        [7.5643, 2.9338, 4.2049],\n",
      "        [7.5810, 3.0939, 4.3647],\n",
      "        [7.4769, 3.1895, 4.1867],\n",
      "        [7.6762, 3.1173, 4.2308],\n",
      "        [7.5657, 2.9385, 4.4467]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7129, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6197,  6.8298, -1.2786],\n",
      "        [-5.6153,  7.2871, -1.4954],\n",
      "        [-5.5958,  7.0489, -1.3394],\n",
      "        [-5.5529,  6.6228, -1.4476],\n",
      "        [-5.6881,  6.9182, -1.2549],\n",
      "        [-5.3941,  6.9661, -1.5318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.5048,  2.9077,  4.2144, -5.6197,  6.8298, -1.2786],\n",
      "        [ 7.5643,  2.9338,  4.2049, -5.6153,  7.2871, -1.4954],\n",
      "        [ 7.5810,  3.0939,  4.3647, -5.5958,  7.0489, -1.3394],\n",
      "        [ 7.4769,  3.1895,  4.1867, -5.5529,  6.6228, -1.4476],\n",
      "        [ 7.6762,  3.1173,  4.2308, -5.6881,  6.9182, -1.2549],\n",
      "        [ 7.5657,  2.9385,  4.4467, -5.3941,  6.9661, -1.5318]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.5116162300109863\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6598, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.7914, 2.8037, 4.0934],\n",
      "        [7.6103, 2.8173, 4.1805],\n",
      "        [7.7271, 3.0789, 4.3556],\n",
      "        [7.5897, 3.0435, 4.4325],\n",
      "        [7.7282, 3.0554, 4.2687],\n",
      "        [7.4793, 2.6256, 4.4616]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.5508, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5483,  6.9712, -1.3863],\n",
      "        [-5.8678,  6.9386, -1.4850],\n",
      "        [-5.6383,  6.8091, -1.1941],\n",
      "        [-5.6247,  6.7692, -1.5230],\n",
      "        [-5.7707,  6.7230, -1.2303],\n",
      "        [-5.3191,  6.7137, -1.2342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.7914,  2.8037,  4.0934, -5.5483,  6.9712, -1.3863],\n",
      "        [ 7.6103,  2.8173,  4.1805, -5.8678,  6.9386, -1.4850],\n",
      "        [ 7.7271,  3.0789,  4.3556, -5.6383,  6.8091, -1.1941],\n",
      "        [ 7.5897,  3.0435,  4.4325, -5.6247,  6.7692, -1.5230],\n",
      "        [ 7.7282,  3.0554,  4.2687, -5.7707,  6.7230, -1.2303],\n",
      "        [ 7.4793,  2.6256,  4.4616, -5.3191,  6.7137, -1.2342]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5186556577682495\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3089, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.6443, 2.5778, 4.2621],\n",
      "        [7.9031, 2.8656, 4.2068],\n",
      "        [7.5760, 3.0012, 4.8362],\n",
      "        [7.4936, 2.8375, 4.2147],\n",
      "        [7.4962, 2.9921, 4.5093],\n",
      "        [7.7341, 2.9434, 4.4190]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.3446, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7959,  6.6150, -1.2849],\n",
      "        [-5.6782,  6.8074, -1.3206],\n",
      "        [-5.4168,  6.6178, -1.5334],\n",
      "        [-5.6528,  6.9682, -1.4554],\n",
      "        [-5.6168,  6.6804, -1.6293],\n",
      "        [-5.4607,  6.7559, -1.5013]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.6443,  2.5778,  4.2621, -5.7959,  6.6150, -1.2849],\n",
      "        [ 7.9031,  2.8656,  4.2068, -5.6782,  6.8074, -1.3206],\n",
      "        [ 7.5760,  3.0012,  4.8362, -5.4168,  6.6178, -1.5334],\n",
      "        [ 7.4936,  2.8375,  4.2147, -5.6528,  6.9682, -1.4554],\n",
      "        [ 7.4962,  2.9921,  4.5093, -5.6168,  6.6804, -1.6293],\n",
      "        [ 7.7341,  2.9434,  4.4190, -5.4607,  6.7559, -1.5013]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5134475231170654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.8817, 3.0014, 4.3815],\n",
      "        [7.7922, 2.9809, 4.2687],\n",
      "        [7.7901, 3.3976, 4.0288],\n",
      "        [7.7082, 2.9216, 4.4098],\n",
      "        [7.5664, 2.8543, 4.3703],\n",
      "        [7.4691, 3.0838, 4.5744]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.1377, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6287,  6.9713, -1.4833],\n",
      "        [-5.9085,  6.9207, -1.2282],\n",
      "        [-5.6415,  6.8566, -1.4998],\n",
      "        [-5.5117,  7.2374, -1.5278],\n",
      "        [-5.6871,  6.5373, -1.3916],\n",
      "        [-5.8037,  6.6305, -1.5214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.8817,  3.0014,  4.3815, -5.6287,  6.9713, -1.4833],\n",
      "        [ 7.7922,  2.9809,  4.2687, -5.9085,  6.9207, -1.2282],\n",
      "        [ 7.7901,  3.3976,  4.0288, -5.6415,  6.8566, -1.4998],\n",
      "        [ 7.7082,  2.9216,  4.4098, -5.5117,  7.2374, -1.5278],\n",
      "        [ 7.5664,  2.8543,  4.3703, -5.6871,  6.5373, -1.3916],\n",
      "        [ 7.4691,  3.0838,  4.5744, -5.8037,  6.6305, -1.5214]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.531524658203125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.7345, 3.0459, 4.5115],\n",
      "        [7.5619, 2.8752, 4.3198],\n",
      "        [7.7358, 3.0036, 4.3537],\n",
      "        [7.6091, 3.1096, 4.3907],\n",
      "        [7.6891, 3.1501, 4.3410],\n",
      "        [7.7422, 2.9312, 4.1267]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7424, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6667,  6.8643, -1.4562],\n",
      "        [-5.4498,  6.9945, -1.5672],\n",
      "        [-5.4698,  7.1620, -1.2925],\n",
      "        [-5.6408,  6.8369, -1.4574],\n",
      "        [-5.6089,  7.1943, -1.6517],\n",
      "        [-5.7381,  7.1280, -1.6894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.7345,  3.0459,  4.5115, -5.6667,  6.8643, -1.4562],\n",
      "        [ 7.5619,  2.8752,  4.3198, -5.4498,  6.9945, -1.5672],\n",
      "        [ 7.7358,  3.0036,  4.3537, -5.4698,  7.1620, -1.2925],\n",
      "        [ 7.6091,  3.1096,  4.3907, -5.6408,  6.8369, -1.4574],\n",
      "        [ 7.6891,  3.1501,  4.3410, -5.6089,  7.1943, -1.6517],\n",
      "        [ 7.7422,  2.9312,  4.1267, -5.7381,  7.1280, -1.6894]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5294389724731445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.8472, 2.9707, 4.3478],\n",
      "        [7.9281, 3.0430, 4.5553],\n",
      "        [7.8529, 2.7215, 4.3388],\n",
      "        [7.6092, 3.0195, 4.3968],\n",
      "        [7.6673, 3.1977, 4.3812],\n",
      "        [7.7733, 2.9011, 4.3269]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.0133, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7906,  7.2398, -1.5014],\n",
      "        [-5.9267,  7.1271, -1.3742],\n",
      "        [-5.6722,  6.9788, -1.5198],\n",
      "        [-5.8828,  7.0553, -1.4919],\n",
      "        [-5.6430,  6.9682, -1.8465],\n",
      "        [-5.6799,  7.2517, -1.3362]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.8472,  2.9707,  4.3478, -5.7906,  7.2398, -1.5014],\n",
      "        [ 7.9281,  3.0430,  4.5553, -5.9267,  7.1271, -1.3742],\n",
      "        [ 7.8529,  2.7215,  4.3388, -5.6722,  6.9788, -1.5198],\n",
      "        [ 7.6092,  3.0195,  4.3968, -5.8828,  7.0553, -1.4919],\n",
      "        [ 7.6673,  3.1977,  4.3812, -5.6430,  6.9682, -1.8465],\n",
      "        [ 7.7733,  2.9011,  4.3269, -5.6799,  7.2517, -1.3362]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5355616807937622\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.7588, 3.0374, 4.3750],\n",
      "        [7.7417, 2.8977, 4.5015],\n",
      "        [7.6894, 3.1111, 4.5957],\n",
      "        [7.8418, 2.9735, 4.5601],\n",
      "        [7.7818, 3.1318, 4.7369],\n",
      "        [7.6960, 3.0022, 4.6048]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.5649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6874,  7.0625, -1.1564],\n",
      "        [-5.7055,  6.9689, -1.6821],\n",
      "        [-5.7165,  6.7716, -1.5192],\n",
      "        [-5.6979,  6.8421, -1.6639],\n",
      "        [-5.6871,  6.9465, -1.4751],\n",
      "        [-5.6042,  6.6977, -1.6987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.7588,  3.0374,  4.3750, -5.6874,  7.0625, -1.1564],\n",
      "        [ 7.7417,  2.8977,  4.5015, -5.7055,  6.9689, -1.6821],\n",
      "        [ 7.6894,  3.1111,  4.5957, -5.7165,  6.7716, -1.5192],\n",
      "        [ 7.8418,  2.9735,  4.5601, -5.6979,  6.8421, -1.6639],\n",
      "        [ 7.7818,  3.1318,  4.7369, -5.6871,  6.9465, -1.4751],\n",
      "        [ 7.6960,  3.0022,  4.6048, -5.6042,  6.6977, -1.6987]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5301460027694702\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.5928, 3.1321, 4.6264],\n",
      "        [7.4143, 2.8886, 4.3827],\n",
      "        [7.8301, 3.1159, 4.4686],\n",
      "        [7.6626, 3.1633, 4.2832],\n",
      "        [7.6825, 3.1963, 4.3790],\n",
      "        [7.9240, 3.0033, 4.4189]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.3480, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.6348,  7.1640, -1.6530],\n",
      "        [-5.7516,  7.0357, -1.5310],\n",
      "        [-6.0291,  7.2294, -1.3846],\n",
      "        [-5.6778,  7.1971, -1.5235],\n",
      "        [-5.4362,  7.0079, -1.2612],\n",
      "        [-5.6983,  7.0441, -1.5474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.5928,  3.1321,  4.6264, -5.6348,  7.1640, -1.6530],\n",
      "        [ 7.4143,  2.8886,  4.3827, -5.7516,  7.0357, -1.5310],\n",
      "        [ 7.8301,  3.1159,  4.4686, -6.0291,  7.2294, -1.3846],\n",
      "        [ 7.6626,  3.1633,  4.2832, -5.6778,  7.1971, -1.5235],\n",
      "        [ 7.6825,  3.1963,  4.3790, -5.4362,  7.0079, -1.2612],\n",
      "        [ 7.9240,  3.0033,  4.4189, -5.6983,  7.0441, -1.5474]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.533570408821106\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9069, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.8405, 2.8633, 4.6784],\n",
      "        [7.5842, 3.2657, 4.3416],\n",
      "        [7.7074, 3.2516, 4.3929],\n",
      "        [7.7907, 3.2338, 4.6252],\n",
      "        [7.9225, 2.8695, 4.5557],\n",
      "        [7.6885, 3.0718, 4.6302]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.4386, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.5617,  7.0818, -1.4301],\n",
      "        [-5.7131,  6.9222, -1.3310],\n",
      "        [-5.8840,  7.1944, -1.5142],\n",
      "        [-5.7947,  7.0834, -1.5130],\n",
      "        [-5.9265,  6.9768, -1.4119],\n",
      "        [-6.1010,  7.1424, -1.4917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.8405,  2.8633,  4.6784, -5.5617,  7.0818, -1.4301],\n",
      "        [ 7.5842,  3.2657,  4.3416, -5.7131,  6.9222, -1.3310],\n",
      "        [ 7.7074,  3.2516,  4.3929, -5.8840,  7.1944, -1.5142],\n",
      "        [ 7.7907,  3.2338,  4.6252, -5.7947,  7.0834, -1.5130],\n",
      "        [ 7.9225,  2.8695,  4.5557, -5.9265,  6.9768, -1.4119],\n",
      "        [ 7.6885,  3.0718,  4.6302, -6.1010,  7.1424, -1.4917]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5377501249313354\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5651, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.0207, 3.0320, 4.6016],\n",
      "        [7.7556, 3.0242, 4.5443],\n",
      "        [7.8912, 3.3602, 4.5554],\n",
      "        [7.9987, 3.3110, 4.4659],\n",
      "        [7.7846, 2.9385, 4.6750],\n",
      "        [7.6763, 3.0208, 4.7263]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.4033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7718,  7.1696, -1.4692],\n",
      "        [-5.7517,  7.1569, -1.6537],\n",
      "        [-5.9105,  7.0979, -1.6646],\n",
      "        [-5.8600,  7.0814, -1.6018],\n",
      "        [-5.8711,  7.3163, -1.5816],\n",
      "        [-5.5883,  6.9731, -1.6457]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.0207,  3.0320,  4.6016, -5.7718,  7.1696, -1.4692],\n",
      "        [ 7.7556,  3.0242,  4.5443, -5.7517,  7.1569, -1.6537],\n",
      "        [ 7.8912,  3.3602,  4.5554, -5.9105,  7.0979, -1.6646],\n",
      "        [ 7.9987,  3.3110,  4.4659, -5.8600,  7.0814, -1.6018],\n",
      "        [ 7.7846,  2.9385,  4.6750, -5.8711,  7.3163, -1.5816],\n",
      "        [ 7.6763,  3.0208,  4.7263, -5.5883,  6.9731, -1.6457]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5474221110343933\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2940, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.7897, 3.2251, 4.4089],\n",
      "        [7.8892, 2.8575, 4.5671],\n",
      "        [7.8341, 3.2325, 4.2956],\n",
      "        [7.7342, 2.9329, 4.5508],\n",
      "        [7.9103, 3.2872, 4.5681],\n",
      "        [7.8839, 2.9751, 4.4191]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.8134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7776,  7.0699, -1.6508],\n",
      "        [-5.7640,  6.9014, -1.4965],\n",
      "        [-5.8846,  7.1290, -1.5560],\n",
      "        [-5.7014,  6.8829, -1.7703],\n",
      "        [-5.8316,  7.2743, -1.5414],\n",
      "        [-5.9875,  7.0609, -1.5551]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.7897,  3.2251,  4.4089, -5.7776,  7.0699, -1.6508],\n",
      "        [ 7.8892,  2.8575,  4.5671, -5.7640,  6.9014, -1.4965],\n",
      "        [ 7.8341,  3.2325,  4.2956, -5.8846,  7.1290, -1.5560],\n",
      "        [ 7.7342,  2.9329,  4.5508, -5.7014,  6.8829, -1.7703],\n",
      "        [ 7.9103,  3.2872,  4.5681, -5.8316,  7.2743, -1.5414],\n",
      "        [ 7.8839,  2.9751,  4.4191, -5.9875,  7.0609, -1.5551]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5373978018760681\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2966, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.6726, 3.3092, 4.6205],\n",
      "        [7.9861, 3.1344, 4.5500],\n",
      "        [7.5519, 2.8449, 4.7239],\n",
      "        [7.8924, 3.2714, 4.9025],\n",
      "        [7.9337, 2.9705, 4.6140],\n",
      "        [7.8572, 3.4593, 4.5378]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.6128, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7722,  6.9584, -1.6335],\n",
      "        [-5.7976,  6.9027, -1.5336],\n",
      "        [-5.8467,  7.1735, -1.7282],\n",
      "        [-5.8688,  7.0873, -1.6148],\n",
      "        [-5.7767,  7.0233, -1.5760],\n",
      "        [-6.0335,  7.2554, -1.6146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.6726,  3.3092,  4.6205, -5.7722,  6.9584, -1.6335],\n",
      "        [ 7.9861,  3.1344,  4.5500, -5.7976,  6.9027, -1.5336],\n",
      "        [ 7.5519,  2.8449,  4.7239, -5.8467,  7.1735, -1.7282],\n",
      "        [ 7.8924,  3.2714,  4.9025, -5.8688,  7.0873, -1.6148],\n",
      "        [ 7.9337,  2.9705,  4.6140, -5.7767,  7.0233, -1.5760],\n",
      "        [ 7.8572,  3.4593,  4.5378, -6.0335,  7.2554, -1.6146]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5379267930984497\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.0533, 3.3165, 4.6427],\n",
      "        [7.5569, 2.8839, 4.4519],\n",
      "        [7.8653, 3.2569, 4.3389],\n",
      "        [8.0664, 3.3784, 4.8497],\n",
      "        [8.2241, 3.3199, 4.6864],\n",
      "        [7.8096, 2.9993, 4.4960]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.6825, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8130,  7.2566, -1.7592],\n",
      "        [-5.7820,  7.5190, -1.6801],\n",
      "        [-5.7861,  7.2039, -1.7049],\n",
      "        [-5.8707,  7.4097, -1.4187],\n",
      "        [-5.6460,  7.2591, -1.6726],\n",
      "        [-5.8384,  7.0164, -1.6332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.0533,  3.3165,  4.6427, -5.8130,  7.2566, -1.7592],\n",
      "        [ 7.5569,  2.8839,  4.4519, -5.7820,  7.5190, -1.6801],\n",
      "        [ 7.8653,  3.2569,  4.3389, -5.7861,  7.2039, -1.7049],\n",
      "        [ 8.0664,  3.3784,  4.8497, -5.8707,  7.4097, -1.4187],\n",
      "        [ 8.2241,  3.3199,  4.6864, -5.6460,  7.2591, -1.6726],\n",
      "        [ 7.8096,  2.9993,  4.4960, -5.8384,  7.0164, -1.6332]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5556585788726807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8066, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.9078, 3.0360, 4.4656],\n",
      "        [7.9382, 3.2074, 4.7912],\n",
      "        [7.9789, 3.0288, 4.7127],\n",
      "        [8.2422, 3.3340, 4.6333],\n",
      "        [7.8748, 3.4792, 4.6752],\n",
      "        [7.9179, 3.3553, 4.8970]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.4819, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9114,  7.1089, -1.4933],\n",
      "        [-6.1187,  7.3769, -1.7161],\n",
      "        [-6.3063,  7.0151, -1.4931],\n",
      "        [-5.8934,  7.1857, -1.4916],\n",
      "        [-5.9662,  7.1487, -1.7005],\n",
      "        [-5.6968,  7.4278, -1.5428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.9078,  3.0360,  4.4656, -5.9114,  7.1089, -1.4933],\n",
      "        [ 7.9382,  3.2074,  4.7912, -6.1187,  7.3769, -1.7161],\n",
      "        [ 7.9789,  3.0288,  4.7127, -6.3063,  7.0151, -1.4931],\n",
      "        [ 8.2422,  3.3340,  4.6333, -5.8934,  7.1857, -1.4916],\n",
      "        [ 7.8748,  3.4792,  4.6752, -5.9662,  7.1487, -1.7005],\n",
      "        [ 7.9179,  3.3553,  4.8970, -5.6968,  7.4278, -1.5428]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5432088375091553\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0385, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.9777, 3.3189, 4.4503],\n",
      "        [8.1397, 2.9710, 4.7628],\n",
      "        [8.1378, 2.8829, 4.5911],\n",
      "        [7.9224, 3.1694, 4.5452],\n",
      "        [7.9495, 3.1970, 4.4336],\n",
      "        [7.9945, 3.0049, 4.6383]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.5690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0720,  7.3033, -1.6282],\n",
      "        [-5.7811,  7.3891, -1.3750],\n",
      "        [-6.0212,  7.3912, -1.8214],\n",
      "        [-5.9544,  7.3235, -1.5791],\n",
      "        [-5.9521,  7.1902, -1.6008],\n",
      "        [-5.7939,  7.4803, -1.5550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.9777,  3.3189,  4.4503, -6.0720,  7.3033, -1.6282],\n",
      "        [ 8.1397,  2.9710,  4.7628, -5.7811,  7.3891, -1.3750],\n",
      "        [ 8.1378,  2.8829,  4.5911, -6.0212,  7.3912, -1.8214],\n",
      "        [ 7.9224,  3.1694,  4.5452, -5.9544,  7.3235, -1.5791],\n",
      "        [ 7.9495,  3.1970,  4.4336, -5.9521,  7.1902, -1.6008],\n",
      "        [ 7.9945,  3.0049,  4.6383, -5.7939,  7.4803, -1.5550]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.5530727505683899\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1103, 3.0751, 4.6589],\n",
      "        [8.1688, 3.0808, 4.5334],\n",
      "        [8.0513, 2.6807, 4.7159],\n",
      "        [7.9602, 3.0839, 4.5523],\n",
      "        [7.9662, 3.0955, 4.7329],\n",
      "        [7.9598, 3.0720, 4.5838]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1867, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0299,  7.2921, -1.5642],\n",
      "        [-6.0528,  7.3035, -1.9093],\n",
      "        [-5.7840,  6.9589, -1.6524],\n",
      "        [-5.9278,  6.9459, -1.5333],\n",
      "        [-5.8052,  7.1624, -1.7804],\n",
      "        [-5.9282,  7.2125, -1.5315]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1103,  3.0751,  4.6589, -6.0299,  7.2921, -1.5642],\n",
      "        [ 8.1688,  3.0808,  4.5334, -6.0528,  7.3035, -1.9093],\n",
      "        [ 8.0513,  2.6807,  4.7159, -5.7840,  6.9589, -1.6524],\n",
      "        [ 7.9602,  3.0839,  4.5523, -5.9278,  6.9459, -1.5333],\n",
      "        [ 7.9662,  3.0955,  4.7329, -5.8052,  7.1624, -1.7804],\n",
      "        [ 7.9598,  3.0720,  4.5838, -5.9282,  7.2125, -1.5315]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5589399933815002\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1555, 3.1316, 4.7046],\n",
      "        [8.0540, 3.1489, 4.5053],\n",
      "        [7.8446, 3.2302, 4.6639],\n",
      "        [7.9602, 2.8838, 4.5132],\n",
      "        [8.1112, 3.2489, 4.8097],\n",
      "        [7.9923, 3.1682, 4.7061]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.8812, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9557,  7.0601, -1.5666],\n",
      "        [-6.0102,  7.0508, -1.5534],\n",
      "        [-5.9616,  7.3466, -1.5547],\n",
      "        [-6.0290,  7.2017, -1.6660],\n",
      "        [-5.8103,  7.5926, -1.5809],\n",
      "        [-5.9541,  7.1373, -1.5646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1555,  3.1316,  4.7046, -5.9557,  7.0601, -1.5666],\n",
      "        [ 8.0540,  3.1489,  4.5053, -6.0102,  7.0508, -1.5534],\n",
      "        [ 7.8446,  3.2302,  4.6639, -5.9616,  7.3466, -1.5547],\n",
      "        [ 7.9602,  2.8838,  4.5132, -6.0290,  7.2017, -1.6660],\n",
      "        [ 8.1112,  3.2489,  4.8097, -5.8103,  7.5926, -1.5809],\n",
      "        [ 7.9923,  3.1682,  4.7061, -5.9541,  7.1373, -1.5646]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5583498477935791\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.0656, 3.2374, 4.6517],\n",
      "        [7.9932, 3.4413, 4.6954],\n",
      "        [8.0438, 3.3894, 4.6004],\n",
      "        [8.0530, 3.2606, 4.8683],\n",
      "        [8.1379, 3.3261, 4.8034],\n",
      "        [8.0952, 3.2760, 4.6495]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7406, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.8778,  7.2647, -1.8493],\n",
      "        [-6.0302,  7.2367, -1.5272],\n",
      "        [-6.1363,  7.4458, -1.8158],\n",
      "        [-5.9387,  7.3216, -1.5385],\n",
      "        [-6.0144,  7.5257, -1.6018],\n",
      "        [-5.8953,  7.2054, -1.7900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.0656,  3.2374,  4.6517, -5.8778,  7.2647, -1.8493],\n",
      "        [ 7.9932,  3.4413,  4.6954, -6.0302,  7.2367, -1.5272],\n",
      "        [ 8.0438,  3.3894,  4.6004, -6.1363,  7.4458, -1.8158],\n",
      "        [ 8.0530,  3.2606,  4.8683, -5.9387,  7.3216, -1.5385],\n",
      "        [ 8.1379,  3.3261,  4.8034, -6.0144,  7.5257, -1.6018],\n",
      "        [ 8.0952,  3.2760,  4.6495, -5.8953,  7.2054, -1.7900]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5584053993225098\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3551, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1995, 3.0882, 4.6389],\n",
      "        [7.7884, 3.1356, 4.7451],\n",
      "        [8.2905, 3.4874, 4.6966],\n",
      "        [8.0678, 3.0270, 4.5911],\n",
      "        [8.1197, 3.1982, 4.8986],\n",
      "        [7.9579, 2.9983, 4.7510]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.4866, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9759,  7.3601, -1.7947],\n",
      "        [-6.2237,  7.6318, -1.5383],\n",
      "        [-6.1421,  7.1998, -1.6257],\n",
      "        [-6.0561,  7.4426, -1.6488],\n",
      "        [-6.1822,  7.0529, -1.6430],\n",
      "        [-5.9044,  7.6226, -1.5156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1995,  3.0882,  4.6389, -5.9759,  7.3601, -1.7947],\n",
      "        [ 7.7884,  3.1356,  4.7451, -6.2237,  7.6318, -1.5383],\n",
      "        [ 8.2905,  3.4874,  4.6966, -6.1421,  7.1998, -1.6257],\n",
      "        [ 8.0678,  3.0270,  4.5911, -6.0561,  7.4426, -1.6488],\n",
      "        [ 8.1197,  3.1982,  4.8986, -6.1822,  7.0529, -1.6430],\n",
      "        [ 7.9579,  2.9983,  4.7510, -5.9044,  7.6226, -1.5156]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.563481867313385\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.2042, 3.2105, 4.8375],\n",
      "        [8.4097, 3.3186, 4.9416],\n",
      "        [8.1192, 3.3790, 4.7654],\n",
      "        [8.1909, 3.0675, 4.4566],\n",
      "        [8.0964, 3.2681, 4.6270],\n",
      "        [7.9187, 3.2512, 4.8851]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.6571, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0355,  7.5100, -1.9036],\n",
      "        [-6.3627,  7.5674, -1.5911],\n",
      "        [-6.1615,  7.6572, -1.6081],\n",
      "        [-6.3169,  7.5955, -1.7069],\n",
      "        [-5.9190,  7.2664, -1.5915],\n",
      "        [-6.0631,  7.4866, -1.7576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.2042,  3.2105,  4.8375, -6.0355,  7.5100, -1.9036],\n",
      "        [ 8.4097,  3.3186,  4.9416, -6.3627,  7.5674, -1.5911],\n",
      "        [ 8.1192,  3.3790,  4.7654, -6.1615,  7.6572, -1.6081],\n",
      "        [ 8.1909,  3.0675,  4.4566, -6.3169,  7.5955, -1.7069],\n",
      "        [ 8.0964,  3.2681,  4.6270, -5.9190,  7.2664, -1.5915],\n",
      "        [ 7.9187,  3.2512,  4.8851, -6.0631,  7.4866, -1.7576]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5725904107093811\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[7.9121, 3.4464, 4.9454],\n",
      "        [8.1620, 3.0694, 4.9152],\n",
      "        [8.1934, 3.1278, 4.7442],\n",
      "        [8.2830, 3.3478, 4.7426],\n",
      "        [8.1683, 3.1116, 4.5938],\n",
      "        [8.0742, 3.1686, 4.6628]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.5652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7806,  7.1750, -1.6700],\n",
      "        [-6.1189,  7.6372, -1.8650],\n",
      "        [-5.9304,  7.1552, -1.7126],\n",
      "        [-6.2253,  7.9175, -1.5970],\n",
      "        [-5.9747,  7.4827, -1.6869],\n",
      "        [-6.0004,  7.3321, -1.6201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 7.9121,  3.4464,  4.9454, -5.7806,  7.1750, -1.6700],\n",
      "        [ 8.1620,  3.0694,  4.9152, -6.1189,  7.6372, -1.8650],\n",
      "        [ 8.1934,  3.1278,  4.7442, -5.9304,  7.1552, -1.7126],\n",
      "        [ 8.2830,  3.3478,  4.7426, -6.2253,  7.9175, -1.5970],\n",
      "        [ 8.1683,  3.1116,  4.5938, -5.9747,  7.4827, -1.6869],\n",
      "        [ 8.0742,  3.1686,  4.6628, -6.0004,  7.3321, -1.6201]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5605657696723938\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1818, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.2243, 3.4488, 4.8894],\n",
      "        [8.3118, 3.3139, 4.8088],\n",
      "        [8.2126, 3.2238, 4.7438],\n",
      "        [8.0753, 3.2428, 4.6596],\n",
      "        [8.3044, 3.0816, 4.7495],\n",
      "        [7.8413, 3.2042, 5.1511]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.3901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.2402,  7.6646, -1.7527],\n",
      "        [-6.0179,  7.4724, -1.8400],\n",
      "        [-6.0474,  7.5030, -1.7918],\n",
      "        [-6.1844,  7.5620, -1.6308],\n",
      "        [-6.1680,  7.5248, -1.5446],\n",
      "        [-6.1838,  7.4263, -1.5764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.2243,  3.4488,  4.8894, -6.2402,  7.6646, -1.7527],\n",
      "        [ 8.3118,  3.3139,  4.8088, -6.0179,  7.4724, -1.8400],\n",
      "        [ 8.2126,  3.2238,  4.7438, -6.0474,  7.5030, -1.7918],\n",
      "        [ 8.0753,  3.2428,  4.6596, -6.1844,  7.5620, -1.6308],\n",
      "        [ 8.3044,  3.0816,  4.7495, -6.1680,  7.5248, -1.5446],\n",
      "        [ 7.8413,  3.2042,  5.1511, -6.1838,  7.4263, -1.5764]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.5816639065742493\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1452, 3.0812, 4.6433],\n",
      "        [8.1866, 3.2273, 4.8599],\n",
      "        [7.9937, 3.2368, 4.7951],\n",
      "        [8.5749, 3.3355, 4.5890],\n",
      "        [7.9435, 3.3766, 4.6307],\n",
      "        [8.1320, 3.3877, 4.6414]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.5152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0583,  7.3064, -1.6683],\n",
      "        [-6.2936,  7.5577, -1.8525],\n",
      "        [-5.9501,  7.2783, -1.8723],\n",
      "        [-6.0633,  7.2123, -1.7613],\n",
      "        [-6.0472,  7.7873, -1.5834],\n",
      "        [-6.0318,  7.3997, -1.8449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1452,  3.0812,  4.6433, -6.0583,  7.3064, -1.6683],\n",
      "        [ 8.1866,  3.2273,  4.8599, -6.2936,  7.5577, -1.8525],\n",
      "        [ 7.9937,  3.2368,  4.7951, -5.9501,  7.2783, -1.8723],\n",
      "        [ 8.5749,  3.3355,  4.5890, -6.0633,  7.2123, -1.7613],\n",
      "        [ 7.9435,  3.3766,  4.6307, -6.0472,  7.7873, -1.5834],\n",
      "        [ 8.1320,  3.3877,  4.6414, -6.0318,  7.3997, -1.8449]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5632337927818298\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1076, 3.3830, 4.6987],\n",
      "        [8.1481, 3.1519, 4.8729],\n",
      "        [8.5743, 3.1897, 5.1274],\n",
      "        [8.3171, 3.3399, 4.8822],\n",
      "        [8.2583, 3.3449, 5.0244],\n",
      "        [8.2834, 3.3628, 4.8855]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.7339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0843,  7.4494, -1.7696],\n",
      "        [-6.0488,  7.5551, -1.7080],\n",
      "        [-6.1124,  7.2519, -1.6814],\n",
      "        [-6.0213,  7.6110, -1.8040],\n",
      "        [-5.9027,  7.6020, -1.6271],\n",
      "        [-6.3527,  7.5778, -1.8338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1076,  3.3830,  4.6987, -6.0843,  7.4494, -1.7696],\n",
      "        [ 8.1481,  3.1519,  4.8729, -6.0488,  7.5551, -1.7080],\n",
      "        [ 8.5743,  3.1897,  5.1274, -6.1124,  7.2519, -1.6814],\n",
      "        [ 8.3171,  3.3399,  4.8822, -6.0213,  7.6110, -1.8040],\n",
      "        [ 8.2583,  3.3449,  5.0244, -5.9027,  7.6020, -1.6271],\n",
      "        [ 8.2834,  3.3628,  4.8855, -6.3527,  7.5778, -1.8338]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.569263756275177\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5764, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.3634, 3.1616, 4.7621],\n",
      "        [8.0424, 3.4145, 4.8805],\n",
      "        [8.4369, 3.2887, 4.6206],\n",
      "        [8.1174, 3.2716, 4.9045],\n",
      "        [8.0939, 3.3313, 4.8613],\n",
      "        [8.2800, 3.3112, 4.9363]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.6697, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.3041,  7.4582, -1.9147],\n",
      "        [-6.2052,  7.3348, -1.6895],\n",
      "        [-6.1615,  7.5239, -1.5895],\n",
      "        [-5.9752,  7.8578, -1.9120],\n",
      "        [-6.0319,  7.5116, -1.8863],\n",
      "        [-6.2201,  7.5370, -1.8375]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.3634,  3.1616,  4.7621, -6.3041,  7.4582, -1.9147],\n",
      "        [ 8.0424,  3.4145,  4.8805, -6.2052,  7.3348, -1.6895],\n",
      "        [ 8.4369,  3.2887,  4.6206, -6.1615,  7.5239, -1.5895],\n",
      "        [ 8.1174,  3.2716,  4.9045, -5.9752,  7.8578, -1.9120],\n",
      "        [ 8.0939,  3.3313,  4.8613, -6.0319,  7.5116, -1.8863],\n",
      "        [ 8.2800,  3.3112,  4.9363, -6.2201,  7.5370, -1.8375]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5797927975654602\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9826, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.1173, 3.5014, 4.8474],\n",
      "        [8.3405, 3.2747, 4.8820],\n",
      "        [8.3069, 3.2165, 4.6685],\n",
      "        [8.2679, 3.4347, 4.7117],\n",
      "        [8.3794, 3.2599, 5.1947],\n",
      "        [8.4078, 3.4290, 5.0610]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.4954, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.5060,  7.6902, -1.7847],\n",
      "        [-6.3163,  7.6776, -1.7872],\n",
      "        [-6.3266,  7.5601, -1.6024],\n",
      "        [-6.2818,  7.3922, -2.0586],\n",
      "        [-6.1222,  7.5578, -1.5493],\n",
      "        [-6.0160,  7.5823, -1.5194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.1173,  3.5014,  4.8474, -6.5060,  7.6902, -1.7847],\n",
      "        [ 8.3405,  3.2747,  4.8820, -6.3163,  7.6776, -1.7872],\n",
      "        [ 8.3069,  3.2165,  4.6685, -6.3266,  7.5601, -1.6024],\n",
      "        [ 8.2679,  3.4347,  4.7117, -6.2818,  7.3922, -2.0586],\n",
      "        [ 8.3794,  3.2599,  5.1947, -6.1222,  7.5578, -1.5493],\n",
      "        [ 8.4078,  3.4290,  5.0610, -6.0160,  7.5823, -1.5194]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5829191207885742\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.4000, 3.5335, 4.8538],\n",
      "        [8.1670, 3.4318, 5.2377],\n",
      "        [8.6072, 3.7319, 4.5633],\n",
      "        [8.0812, 3.4497, 4.9187],\n",
      "        [8.6030, 3.4855, 4.8958],\n",
      "        [8.3956, 3.4398, 4.9619]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.9648, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.0208,  7.2637, -1.6432],\n",
      "        [-6.2812,  7.4227, -1.8525],\n",
      "        [-6.3619,  7.5959, -1.6910],\n",
      "        [-6.2484,  7.4423, -1.6613],\n",
      "        [-6.4007,  7.7660, -1.7479],\n",
      "        [-6.3362,  7.3362, -1.8903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.4000,  3.5335,  4.8538, -6.0208,  7.2637, -1.6432],\n",
      "        [ 8.1670,  3.4318,  5.2377, -6.2812,  7.4227, -1.8525],\n",
      "        [ 8.6072,  3.7319,  4.5633, -6.3619,  7.5959, -1.6910],\n",
      "        [ 8.0812,  3.4497,  4.9187, -6.2484,  7.4423, -1.6613],\n",
      "        [ 8.6030,  3.4855,  4.8958, -6.4007,  7.7660, -1.7479],\n",
      "        [ 8.3956,  3.4398,  4.9619, -6.3362,  7.3362, -1.8903]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5811288952827454\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.3483, 3.0201, 4.9577],\n",
      "        [8.3297, 3.2310, 4.8686],\n",
      "        [8.5331, 3.5625, 4.8258],\n",
      "        [8.4194, 3.4190, 4.7428],\n",
      "        [8.2905, 3.3776, 4.8017],\n",
      "        [8.4024, 3.3634, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7489, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.1607,  7.3770, -1.8597],\n",
      "        [-6.2610,  7.8570, -1.7248],\n",
      "        [-6.1712,  7.7984, -1.8081],\n",
      "        [-6.2780,  7.4055, -1.9981],\n",
      "        [-6.2979,  7.6087, -1.7602],\n",
      "        [-6.2346,  7.7315, -1.8263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.3483,  3.0201,  4.9577, -6.1607,  7.3770, -1.8597],\n",
      "        [ 8.3297,  3.2310,  4.8686, -6.2610,  7.8570, -1.7248],\n",
      "        [ 8.5331,  3.5625,  4.8258, -6.1712,  7.7984, -1.8081],\n",
      "        [ 8.4194,  3.4190,  4.7428, -6.2780,  7.4055, -1.9981],\n",
      "        [ 8.2905,  3.3776,  4.8017, -6.2979,  7.6087, -1.7602],\n",
      "        [ 8.4024,  3.3634,  4.9169, -6.2346,  7.7315, -1.8263]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5804949998855591\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.2495, 3.0806, 4.8584],\n",
      "        [8.5982, 3.5774, 4.9772],\n",
      "        [8.5873, 3.2618, 4.7548],\n",
      "        [8.3953, 3.5078, 4.7721],\n",
      "        [8.5878, 3.4922, 4.8133],\n",
      "        [8.4372, 3.3083, 4.8472]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.7859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.9097,  7.7436, -1.8573],\n",
      "        [-6.1958,  7.1814, -1.6570],\n",
      "        [-6.2782,  7.4373, -1.6648],\n",
      "        [-6.5393,  7.8002, -1.9280],\n",
      "        [-6.3389,  7.6384, -2.0725],\n",
      "        [-6.0639,  7.7804, -1.5618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.2495,  3.0806,  4.8584, -5.9097,  7.7436, -1.8573],\n",
      "        [ 8.5982,  3.5774,  4.9772, -6.1958,  7.1814, -1.6570],\n",
      "        [ 8.5873,  3.2618,  4.7548, -6.2782,  7.4373, -1.6648],\n",
      "        [ 8.3953,  3.5078,  4.7721, -6.5393,  7.8002, -1.9280],\n",
      "        [ 8.5878,  3.4922,  4.8133, -6.3389,  7.6384, -2.0725],\n",
      "        [ 8.4372,  3.3083,  4.8472, -6.0639,  7.7804, -1.5618]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.5784471035003662\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.2413, 3.5929, 4.8334],\n",
      "        [8.3750, 3.4678, 4.9543],\n",
      "        [8.4294, 3.5411, 4.7810],\n",
      "        [8.3884, 3.4962, 5.2478],\n",
      "        [8.4338, 3.1817, 4.9398],\n",
      "        [8.4235, 3.3679, 4.8402]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.6619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4730,  7.7916, -1.6170],\n",
      "        [-6.3171,  7.6528, -1.9404],\n",
      "        [-6.1620,  7.5380, -1.7488],\n",
      "        [-6.3134,  7.8736, -2.0820],\n",
      "        [-6.1008,  7.6906, -1.5422],\n",
      "        [-6.4215,  7.8107, -1.8442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.2413,  3.5929,  4.8334, -6.4730,  7.7916, -1.6170],\n",
      "        [ 8.3750,  3.4678,  4.9543, -6.3171,  7.6528, -1.9404],\n",
      "        [ 8.4294,  3.5411,  4.7810, -6.1620,  7.5380, -1.7488],\n",
      "        [ 8.3884,  3.4962,  5.2478, -6.3134,  7.8736, -2.0820],\n",
      "        [ 8.4338,  3.1817,  4.9398, -6.1008,  7.6906, -1.5422],\n",
      "        [ 8.4235,  3.3679,  4.8402, -6.4215,  7.8107, -1.8442]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5897619128227234\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3732, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.2717, 3.5597, 4.9049],\n",
      "        [8.3755, 3.5846, 5.0659],\n",
      "        [8.3102, 3.6825, 4.6605],\n",
      "        [8.5459, 3.4120, 4.9646],\n",
      "        [8.3137, 3.3443, 4.9422],\n",
      "        [8.4000, 3.5819, 5.1231]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.5335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.2876,  7.2206, -2.0395],\n",
      "        [-6.1789,  7.5060, -1.7940],\n",
      "        [-6.4798,  7.3333, -2.1825],\n",
      "        [-6.4182,  7.8719, -1.6409],\n",
      "        [-6.3477,  7.7493, -2.0103],\n",
      "        [-6.1820,  7.6155, -1.7822]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.2717,  3.5597,  4.9049, -6.2876,  7.2206, -2.0395],\n",
      "        [ 8.3755,  3.5846,  5.0659, -6.1789,  7.5060, -1.7940],\n",
      "        [ 8.3102,  3.6825,  4.6605, -6.4798,  7.3333, -2.1825],\n",
      "        [ 8.5459,  3.4120,  4.9646, -6.4182,  7.8719, -1.6409],\n",
      "        [ 8.3137,  3.3443,  4.9422, -6.3477,  7.7493, -2.0103],\n",
      "        [ 8.4000,  3.5819,  5.1231, -6.1820,  7.6155, -1.7822]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5834395885467529\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.5009, 3.4399, 4.7425],\n",
      "        [8.2795, 3.6517, 4.9299],\n",
      "        [8.2742, 3.4154, 4.7053],\n",
      "        [8.6496, 3.5594, 5.0331],\n",
      "        [8.2741, 3.3531, 4.8560],\n",
      "        [8.4478, 3.0995, 4.7720]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.9474, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4934,  7.6637, -2.1065],\n",
      "        [-5.9275,  7.5347, -1.7277],\n",
      "        [-6.2712,  7.7229, -1.9983],\n",
      "        [-6.3849,  7.8427, -1.8215],\n",
      "        [-6.2882,  7.7745, -1.8824],\n",
      "        [-6.1307,  7.3088, -1.7073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.5009,  3.4399,  4.7425, -6.4934,  7.6637, -2.1065],\n",
      "        [ 8.2795,  3.6517,  4.9299, -5.9275,  7.5347, -1.7277],\n",
      "        [ 8.2742,  3.4154,  4.7053, -6.2712,  7.7229, -1.9983],\n",
      "        [ 8.6496,  3.5594,  5.0331, -6.3849,  7.8427, -1.8215],\n",
      "        [ 8.2741,  3.3531,  4.8560, -6.2882,  7.7745, -1.8824],\n",
      "        [ 8.4478,  3.0995,  4.7720, -6.1307,  7.3088, -1.7073]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5949218273162842\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3091, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.4922, 3.0631, 4.9942],\n",
      "        [8.3864, 3.4311, 5.0661],\n",
      "        [8.3263, 3.5054, 4.8769],\n",
      "        [8.4538, 3.4647, 4.8892],\n",
      "        [8.6438, 3.5621, 5.0605],\n",
      "        [8.6631, 3.4201, 4.8208]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2828, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.1347,  7.6183, -1.8482],\n",
      "        [-6.3672,  7.4909, -1.9203],\n",
      "        [-6.3958,  7.5041, -1.6420],\n",
      "        [-6.3583,  7.8506, -1.9366],\n",
      "        [-6.3863,  7.6834, -1.6380],\n",
      "        [-6.5015,  7.8523, -1.6074]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.4922,  3.0631,  4.9942, -6.1347,  7.6183, -1.8482],\n",
      "        [ 8.3864,  3.4311,  5.0661, -6.3672,  7.4909, -1.9203],\n",
      "        [ 8.3263,  3.5054,  4.8769, -6.3958,  7.5041, -1.6420],\n",
      "        [ 8.4538,  3.4647,  4.8892, -6.3583,  7.8506, -1.9366],\n",
      "        [ 8.6438,  3.5621,  5.0605, -6.3863,  7.6834, -1.6380],\n",
      "        [ 8.6631,  3.4201,  4.8208, -6.5015,  7.8523, -1.6074]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5913538932800293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6115, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.4047, 3.3786, 5.1407],\n",
      "        [8.5482, 3.1827, 5.0937],\n",
      "        [8.6793, 3.5901, 4.7194],\n",
      "        [8.4456, 3.5962, 5.0044],\n",
      "        [8.4442, 3.2231, 4.8975],\n",
      "        [8.2395, 3.3349, 4.7477]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.3265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4245,  7.7195, -1.7547],\n",
      "        [-6.5389,  7.7505, -1.8235],\n",
      "        [-6.1941,  7.8213, -1.9956],\n",
      "        [-6.5176,  7.7916, -1.7879],\n",
      "        [-6.4574,  7.7134, -2.1784],\n",
      "        [-6.4072,  7.8608, -1.8796]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.4047,  3.3786,  5.1407, -6.4245,  7.7195, -1.7547],\n",
      "        [ 8.5482,  3.1827,  5.0937, -6.5389,  7.7505, -1.8235],\n",
      "        [ 8.6793,  3.5901,  4.7194, -6.1941,  7.8213, -1.9956],\n",
      "        [ 8.4456,  3.5962,  5.0044, -6.5176,  7.7916, -1.7879],\n",
      "        [ 8.4442,  3.2231,  4.8975, -6.4574,  7.7134, -2.1784],\n",
      "        [ 8.2395,  3.3349,  4.7477, -6.4072,  7.8608, -1.8796]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5999431610107422\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6445, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.4135, 3.4405, 5.1786],\n",
      "        [8.5617, 3.4104, 4.9906],\n",
      "        [8.4323, 3.3371, 4.7705],\n",
      "        [8.3467, 3.6513, 4.6607],\n",
      "        [8.8015, 3.6061, 4.9524],\n",
      "        [8.7124, 3.2734, 5.0150]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.3027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.1814,  7.3895, -1.8636],\n",
      "        [-6.3754,  7.9704, -2.0061],\n",
      "        [-6.3759,  8.0513, -2.0174],\n",
      "        [-6.6896,  7.6111, -2.1361],\n",
      "        [-6.5380,  7.6591, -2.1421],\n",
      "        [-6.4907,  7.7952, -1.8159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.4135,  3.4405,  5.1786, -6.1814,  7.3895, -1.8636],\n",
      "        [ 8.5617,  3.4104,  4.9906, -6.3754,  7.9704, -2.0061],\n",
      "        [ 8.4323,  3.3371,  4.7705, -6.3759,  8.0513, -2.0174],\n",
      "        [ 8.3467,  3.6513,  4.6607, -6.6896,  7.6111, -2.1361],\n",
      "        [ 8.8015,  3.6061,  4.9524, -6.5380,  7.6591, -2.1421],\n",
      "        [ 8.7124,  3.2734,  5.0150, -6.4907,  7.7952, -1.8159]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5950782895088196\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.6806, 3.5115, 4.8463],\n",
      "        [8.5449, 3.3331, 4.9962],\n",
      "        [8.4871, 3.8558, 4.4700],\n",
      "        [8.6093, 3.4463, 5.0965],\n",
      "        [8.7574, 3.5804, 4.9855],\n",
      "        [8.3665, 3.2426, 4.8006]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.5324, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.3547,  7.8426, -2.0807],\n",
      "        [-6.4318,  7.8191, -1.9120],\n",
      "        [-6.1445,  8.0550, -2.0047],\n",
      "        [-6.6083,  7.8117, -1.8499],\n",
      "        [-6.4996,  7.9731, -1.9011],\n",
      "        [-6.3955,  7.7088, -1.9479]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.6806,  3.5115,  4.8463, -6.3547,  7.8426, -2.0807],\n",
      "        [ 8.5449,  3.3331,  4.9962, -6.4318,  7.8191, -1.9120],\n",
      "        [ 8.4871,  3.8558,  4.4700, -6.1445,  8.0550, -2.0047],\n",
      "        [ 8.6093,  3.4463,  5.0965, -6.6083,  7.8117, -1.8499],\n",
      "        [ 8.7574,  3.5804,  4.9855, -6.4996,  7.9731, -1.9011],\n",
      "        [ 8.3665,  3.2426,  4.8006, -6.3955,  7.7088, -1.9479]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6062086224555969\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2842, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.4560, 3.1501, 5.0505],\n",
      "        [8.5520, 3.5366, 5.1407],\n",
      "        [8.6231, 3.5542, 5.1566],\n",
      "        [8.7337, 3.7480, 4.9136],\n",
      "        [8.4257, 3.6364, 5.0380],\n",
      "        [8.6512, 3.4931, 5.0445]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.8000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4466,  7.6200, -1.7335],\n",
      "        [-6.6089,  7.8281, -2.1189],\n",
      "        [-6.4882,  7.8372, -2.0004],\n",
      "        [-6.4231,  7.6015, -2.0334],\n",
      "        [-6.3883,  7.7759, -2.0694],\n",
      "        [-6.5209,  7.8815, -1.9277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.4560,  3.1501,  5.0505, -6.4466,  7.6200, -1.7335],\n",
      "        [ 8.5520,  3.5366,  5.1407, -6.6089,  7.8281, -2.1189],\n",
      "        [ 8.6231,  3.5542,  5.1566, -6.4882,  7.8372, -2.0004],\n",
      "        [ 8.7337,  3.7480,  4.9136, -6.4231,  7.6015, -2.0334],\n",
      "        [ 8.4257,  3.6364,  5.0380, -6.3883,  7.7759, -2.0694],\n",
      "        [ 8.6512,  3.4931,  5.0445, -6.5209,  7.8815, -1.9277]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.5972458124160767\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.7427, 3.5617, 5.0040],\n",
      "        [8.3475, 3.1259, 5.0241],\n",
      "        [8.2864, 3.7183, 5.1073],\n",
      "        [8.8349, 3.6880, 5.0842],\n",
      "        [8.6212, 3.4064, 4.9345],\n",
      "        [8.5189, 3.5730, 5.1344]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.5495,  7.5598, -1.8050],\n",
      "        [-6.5106,  7.6667, -1.8787],\n",
      "        [-6.6343,  7.7609, -1.8594],\n",
      "        [-6.7499,  7.9015, -1.9900],\n",
      "        [-6.3898,  7.7842, -1.8611],\n",
      "        [-6.4417,  8.0035, -1.9032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.7427,  3.5617,  5.0040, -6.5495,  7.5598, -1.8050],\n",
      "        [ 8.3475,  3.1259,  5.0241, -6.5106,  7.6667, -1.8787],\n",
      "        [ 8.2864,  3.7183,  5.1073, -6.6343,  7.7609, -1.8594],\n",
      "        [ 8.8349,  3.6880,  5.0842, -6.7499,  7.9015, -1.9900],\n",
      "        [ 8.6212,  3.4064,  4.9345, -6.3898,  7.7842, -1.8611],\n",
      "        [ 8.5189,  3.5730,  5.1344, -6.4417,  8.0035, -1.9032]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6106088161468506\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0192, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.6097, 3.5830, 5.1713],\n",
      "        [8.7203, 3.6086, 4.8615],\n",
      "        [8.5504, 3.2733, 5.0279],\n",
      "        [8.7025, 3.3603, 4.7743],\n",
      "        [8.7537, 3.8012, 5.0736],\n",
      "        [8.6178, 3.4148, 5.0821]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.8285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.1396,  7.7465, -1.7004],\n",
      "        [-6.3259,  7.8054, -1.9161],\n",
      "        [-6.3624,  7.6945, -2.1032],\n",
      "        [-6.5729,  8.1286, -1.8550],\n",
      "        [-6.5097,  7.6851, -1.8759],\n",
      "        [-6.4906,  7.5988, -1.7304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.6097,  3.5830,  5.1713, -6.1396,  7.7465, -1.7004],\n",
      "        [ 8.7203,  3.6086,  4.8615, -6.3259,  7.8054, -1.9161],\n",
      "        [ 8.5504,  3.2733,  5.0279, -6.3624,  7.6945, -2.1032],\n",
      "        [ 8.7025,  3.3603,  4.7743, -6.5729,  8.1286, -1.8550],\n",
      "        [ 8.7537,  3.8012,  5.0736, -6.5097,  7.6851, -1.8759],\n",
      "        [ 8.6178,  3.4148,  5.0821, -6.4906,  7.5988, -1.7304]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6083913445472717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7798, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.8599, 3.7379, 5.1656],\n",
      "        [8.7906, 3.3394, 4.9726],\n",
      "        [8.6094, 3.5756, 5.1913],\n",
      "        [8.6041, 3.4387, 4.8697],\n",
      "        [8.6347, 3.3238, 5.0881],\n",
      "        [8.5684, 3.2418, 4.8765]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.3714, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.3275,  8.2307, -2.1794],\n",
      "        [-6.5645,  7.7845, -1.9073],\n",
      "        [-6.5182,  7.8985, -1.7481],\n",
      "        [-6.1102,  8.1161, -1.7740],\n",
      "        [-6.3607,  7.8750, -1.9477],\n",
      "        [-6.6467,  7.7955, -2.0186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.8599,  3.7379,  5.1656, -6.3275,  8.2307, -2.1794],\n",
      "        [ 8.7906,  3.3394,  4.9726, -6.5645,  7.7845, -1.9073],\n",
      "        [ 8.6094,  3.5756,  5.1913, -6.5182,  7.8985, -1.7481],\n",
      "        [ 8.6041,  3.4387,  4.8697, -6.1102,  8.1161, -1.7740],\n",
      "        [ 8.6347,  3.3238,  5.0881, -6.3607,  7.8750, -1.9477],\n",
      "        [ 8.5684,  3.2418,  4.8765, -6.6467,  7.7955, -2.0186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6284278631210327\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7308, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.7022, 3.5503, 4.9605],\n",
      "        [8.4041, 3.5875, 5.3713],\n",
      "        [8.8664, 3.6383, 5.1364],\n",
      "        [8.7002, 3.3682, 5.0738],\n",
      "        [8.5815, 3.6021, 5.0057],\n",
      "        [8.6624, 3.6398, 5.0162]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.9026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.6405,  7.9760, -1.8283],\n",
      "        [-6.4038,  7.7851, -1.8253],\n",
      "        [-6.7478,  8.0816, -1.7616],\n",
      "        [-6.6437,  8.0436, -1.7244],\n",
      "        [-6.6064,  7.9661, -1.9832],\n",
      "        [-6.7358,  8.1599, -1.9952]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.7022,  3.5503,  4.9605, -6.6405,  7.9760, -1.8283],\n",
      "        [ 8.4041,  3.5875,  5.3713, -6.4038,  7.7851, -1.8253],\n",
      "        [ 8.8664,  3.6383,  5.1364, -6.7478,  8.0816, -1.7616],\n",
      "        [ 8.7002,  3.3682,  5.0738, -6.6437,  8.0436, -1.7244],\n",
      "        [ 8.5815,  3.6021,  5.0057, -6.6064,  7.9661, -1.9832],\n",
      "        [ 8.6624,  3.6398,  5.0162, -6.7358,  8.1599, -1.9952]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6164003014564514\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2865, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.7367, 3.4105, 4.9925],\n",
      "        [8.6519, 3.6466, 5.0483],\n",
      "        [8.7252, 3.7812, 5.4133],\n",
      "        [8.5057, 3.4996, 5.2865],\n",
      "        [8.6272, 3.6162, 4.9796],\n",
      "        [8.9740, 3.4010, 5.0499]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.6208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4058,  7.5132, -1.8593],\n",
      "        [-6.5527,  7.8531, -1.9073],\n",
      "        [-6.7833,  7.9280, -1.6569],\n",
      "        [-6.7109,  7.9640, -1.7414],\n",
      "        [-6.5100,  7.9740, -1.8589],\n",
      "        [-6.6257,  8.0628, -2.1162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.7367,  3.4105,  4.9925, -6.4058,  7.5132, -1.8593],\n",
      "        [ 8.6519,  3.6466,  5.0483, -6.5527,  7.8531, -1.9073],\n",
      "        [ 8.7252,  3.7812,  5.4133, -6.7833,  7.9280, -1.6569],\n",
      "        [ 8.5057,  3.4996,  5.2865, -6.7109,  7.9640, -1.7414],\n",
      "        [ 8.6272,  3.6162,  4.9796, -6.5100,  7.9740, -1.8589],\n",
      "        [ 8.9740,  3.4010,  5.0499, -6.6257,  8.0628, -2.1162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6081107258796692\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3432, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.0124, 3.6981, 5.0783],\n",
      "        [8.7233, 3.7172, 5.4254],\n",
      "        [8.7892, 3.3947, 5.1999],\n",
      "        [8.5927, 3.2873, 5.3204],\n",
      "        [8.6466, 3.4379, 5.1059],\n",
      "        [8.6296, 3.6632, 4.9803]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7504,  8.0825, -2.1455],\n",
      "        [-6.4152,  7.9722, -1.9707],\n",
      "        [-6.5570,  7.7321, -1.7964],\n",
      "        [-6.4414,  8.0955, -2.0758],\n",
      "        [-6.5799,  8.1277, -1.9325],\n",
      "        [-6.7416,  8.0430, -2.0360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.0124,  3.6981,  5.0783, -6.7504,  8.0825, -2.1455],\n",
      "        [ 8.7233,  3.7172,  5.4254, -6.4152,  7.9722, -1.9707],\n",
      "        [ 8.7892,  3.3947,  5.1999, -6.5570,  7.7321, -1.7964],\n",
      "        [ 8.5927,  3.2873,  5.3204, -6.4414,  8.0955, -2.0758],\n",
      "        [ 8.6466,  3.4379,  5.1059, -6.5799,  8.1277, -1.9325],\n",
      "        [ 8.6296,  3.6632,  4.9803, -6.7416,  8.0430, -2.0360]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6349141001701355\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.6559, 3.3566, 5.1663],\n",
      "        [8.7655, 3.5588, 5.2275],\n",
      "        [8.6868, 3.7188, 4.9619],\n",
      "        [8.8802, 3.9023, 5.2893],\n",
      "        [8.8982, 3.2307, 5.2119],\n",
      "        [8.7024, 3.3128, 4.9352]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.6369,  7.6543, -2.1976],\n",
      "        [-6.6149,  7.7691, -1.9625],\n",
      "        [-6.5375,  8.1765, -2.0115],\n",
      "        [-6.4560,  8.1015, -2.0965],\n",
      "        [-6.6606,  8.0573, -2.0185],\n",
      "        [-6.2653,  7.9008, -1.9147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.6559,  3.3566,  5.1663, -6.6369,  7.6543, -2.1976],\n",
      "        [ 8.7655,  3.5588,  5.2275, -6.6149,  7.7691, -1.9625],\n",
      "        [ 8.6868,  3.7188,  4.9619, -6.5375,  8.1765, -2.0115],\n",
      "        [ 8.8802,  3.9023,  5.2893, -6.4560,  8.1015, -2.0965],\n",
      "        [ 8.8982,  3.2307,  5.2119, -6.6606,  8.0573, -2.0185],\n",
      "        [ 8.7024,  3.3128,  4.9352, -6.2653,  7.9008, -1.9147]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6151617765426636\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.6922, 3.5155, 5.3406],\n",
      "        [8.6167, 3.5521, 4.9173],\n",
      "        [8.6864, 3.6829, 5.1177],\n",
      "        [8.8436, 3.8156, 5.1988],\n",
      "        [8.6833, 3.4672, 5.3262],\n",
      "        [9.0750, 3.4188, 5.1128]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1050, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.5511,  7.7486, -1.7733],\n",
      "        [-6.6114,  7.7775, -1.7553],\n",
      "        [-6.5935,  7.8443, -1.9735],\n",
      "        [-6.6468,  7.9350, -1.9850],\n",
      "        [-6.6321,  8.2894, -1.8480],\n",
      "        [-6.8675,  8.1281, -2.1590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.6922,  3.5155,  5.3406, -6.5511,  7.7486, -1.7733],\n",
      "        [ 8.6167,  3.5521,  4.9173, -6.6114,  7.7775, -1.7553],\n",
      "        [ 8.6864,  3.6829,  5.1177, -6.5935,  7.8443, -1.9735],\n",
      "        [ 8.8436,  3.8156,  5.1988, -6.6468,  7.9350, -1.9850],\n",
      "        [ 8.6833,  3.4672,  5.3262, -6.6321,  8.2894, -1.8480],\n",
      "        [ 9.0750,  3.4188,  5.1128, -6.8675,  8.1281, -2.1590]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.621506929397583\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7367, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.8257, 3.8478, 4.9810],\n",
      "        [8.5406, 3.4164, 5.0221],\n",
      "        [8.8862, 3.9118, 5.1844],\n",
      "        [8.9077, 3.8054, 4.9892],\n",
      "        [8.6016, 3.9877, 5.2632],\n",
      "        [8.8427, 3.8809, 5.0823]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.8528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.4487,  7.9492, -2.0963],\n",
      "        [-6.6229,  7.7358, -1.8298],\n",
      "        [-6.7643,  8.1678, -1.9567],\n",
      "        [-6.8099,  8.0281, -2.1390],\n",
      "        [-6.4343,  8.0849, -1.9106],\n",
      "        [-6.7268,  7.8676, -1.9186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.8257,  3.8478,  4.9810, -6.4487,  7.9492, -2.0963],\n",
      "        [ 8.5406,  3.4164,  5.0221, -6.6229,  7.7358, -1.8298],\n",
      "        [ 8.8862,  3.9118,  5.1844, -6.7643,  8.1678, -1.9567],\n",
      "        [ 8.9077,  3.8054,  4.9892, -6.8099,  8.0281, -2.1390],\n",
      "        [ 8.6016,  3.9877,  5.2632, -6.4343,  8.0849, -1.9106],\n",
      "        [ 8.8427,  3.8809,  5.0823, -6.7268,  7.8676, -1.9186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6242609620094299\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.0760, 3.7142, 5.1827],\n",
      "        [9.1029, 3.6615, 5.2493],\n",
      "        [9.0159, 3.7244, 5.3999],\n",
      "        [8.9983, 3.8896, 5.4365],\n",
      "        [8.7715, 3.4690, 5.4451],\n",
      "        [8.7982, 3.3993, 5.2876]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7260, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7059,  8.2819, -2.1047],\n",
      "        [-6.5354,  7.9222, -1.8236],\n",
      "        [-6.6656,  8.1223, -2.2477],\n",
      "        [-6.9872,  7.9922, -1.8862],\n",
      "        [-6.4338,  7.6886, -2.0776],\n",
      "        [-6.4674,  8.0285, -1.8105]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.0760,  3.7142,  5.1827, -6.7059,  8.2819, -2.1047],\n",
      "        [ 9.1029,  3.6615,  5.2493, -6.5354,  7.9222, -1.8236],\n",
      "        [ 9.0159,  3.7244,  5.3999, -6.6656,  8.1223, -2.2477],\n",
      "        [ 8.9983,  3.8896,  5.4365, -6.9872,  7.9922, -1.8862],\n",
      "        [ 8.7715,  3.4690,  5.4451, -6.4338,  7.6886, -2.0776],\n",
      "        [ 8.7982,  3.3993,  5.2876, -6.4674,  8.0285, -1.8105]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6433888077735901\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6356, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.6925, 3.9240, 5.3888],\n",
      "        [8.9298, 3.8261, 5.0730],\n",
      "        [9.0150, 3.6842, 5.4649],\n",
      "        [8.9262, 3.8083, 5.1418],\n",
      "        [8.8033, 4.0540, 5.1854],\n",
      "        [8.9418, 3.8509, 5.1510]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.3387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7523,  8.1718, -2.2133],\n",
      "        [-6.5364,  8.3023, -2.1547],\n",
      "        [-6.8304,  7.8998, -1.9960],\n",
      "        [-6.3834,  8.1760, -1.9840],\n",
      "        [-6.4555,  8.0301, -2.1384],\n",
      "        [-6.8059,  8.3748, -1.9477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.6925,  3.9240,  5.3888, -6.7523,  8.1718, -2.2133],\n",
      "        [ 8.9298,  3.8261,  5.0730, -6.5364,  8.3023, -2.1547],\n",
      "        [ 9.0150,  3.6842,  5.4649, -6.8304,  7.8998, -1.9960],\n",
      "        [ 8.9262,  3.8083,  5.1418, -6.3834,  8.1760, -1.9840],\n",
      "        [ 8.8033,  4.0540,  5.1854, -6.4555,  8.0301, -2.1384],\n",
      "        [ 8.9418,  3.8509,  5.1510, -6.8059,  8.3748, -1.9477]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6376657485961914\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4019, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9268, 3.7127, 5.3214],\n",
      "        [8.9599, 4.0176, 5.3560],\n",
      "        [8.8947, 3.7614, 5.0424],\n",
      "        [9.0068, 3.8314, 4.9041],\n",
      "        [8.8510, 3.4825, 5.2929],\n",
      "        [8.9591, 3.5132, 5.0667]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.0703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7676,  8.1191, -2.1344],\n",
      "        [-6.8973,  8.0871, -2.0007],\n",
      "        [-6.5519,  7.9631, -1.9347],\n",
      "        [-6.9108,  8.2301, -2.1369],\n",
      "        [-6.7854,  8.3044, -2.0589],\n",
      "        [-6.5094,  8.1473, -2.0772]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9268,  3.7127,  5.3214, -6.7676,  8.1191, -2.1344],\n",
      "        [ 8.9599,  4.0176,  5.3560, -6.8973,  8.0871, -2.0007],\n",
      "        [ 8.8947,  3.7614,  5.0424, -6.5519,  7.9631, -1.9347],\n",
      "        [ 9.0068,  3.8314,  4.9041, -6.9108,  8.2301, -2.1369],\n",
      "        [ 8.8510,  3.4825,  5.2929, -6.7854,  8.3044, -2.0589],\n",
      "        [ 8.9591,  3.5132,  5.0667, -6.5094,  8.1473, -2.0772]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6410820484161377\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9834, 3.9228, 5.3813],\n",
      "        [8.9288, 3.4685, 5.3681],\n",
      "        [9.0177, 3.7955, 5.3051],\n",
      "        [8.8397, 3.6566, 5.2249],\n",
      "        [8.8585, 3.5635, 5.6011],\n",
      "        [8.7648, 3.7039, 5.1970]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.1584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7886,  8.1234, -2.1966],\n",
      "        [-6.7609,  8.2858, -2.0712],\n",
      "        [-7.0344,  8.1142, -2.1063],\n",
      "        [-6.8096,  7.9845, -1.9486],\n",
      "        [-6.8243,  8.1082, -2.0985],\n",
      "        [-6.7412,  7.8076, -2.0122]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9834,  3.9228,  5.3813, -6.7886,  8.1234, -2.1966],\n",
      "        [ 8.9288,  3.4685,  5.3681, -6.7609,  8.2858, -2.0712],\n",
      "        [ 9.0177,  3.7955,  5.3051, -7.0344,  8.1142, -2.1063],\n",
      "        [ 8.8397,  3.6566,  5.2249, -6.8096,  7.9845, -1.9486],\n",
      "        [ 8.8585,  3.5635,  5.6011, -6.8243,  8.1082, -2.0985],\n",
      "        [ 8.7648,  3.7039,  5.1970, -6.7412,  7.8076, -2.0122]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6473920941352844\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2704, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.8642, 3.7152, 5.3754],\n",
      "        [8.7436, 3.8064, 5.0238],\n",
      "        [8.8379, 4.2190, 5.3371],\n",
      "        [8.8897, 4.0828, 5.4018],\n",
      "        [8.9560, 3.7090, 5.2766],\n",
      "        [9.0723, 3.8451, 5.1713]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.8821, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7046,  7.9279, -1.9237],\n",
      "        [-6.8694,  8.2686, -2.0035],\n",
      "        [-6.5026,  8.0666, -2.3564],\n",
      "        [-6.8109,  8.2428, -2.0449],\n",
      "        [-6.8219,  8.1933, -2.2280],\n",
      "        [-6.7789,  8.1047, -2.3303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.8642,  3.7152,  5.3754, -6.7046,  7.9279, -1.9237],\n",
      "        [ 8.7436,  3.8064,  5.0238, -6.8694,  8.2686, -2.0035],\n",
      "        [ 8.8379,  4.2190,  5.3371, -6.5026,  8.0666, -2.3564],\n",
      "        [ 8.8897,  4.0828,  5.4018, -6.8109,  8.2428, -2.0449],\n",
      "        [ 8.9560,  3.7090,  5.2766, -6.8219,  8.1933, -2.2280],\n",
      "        [ 9.0723,  3.8451,  5.1713, -6.7789,  8.1047, -2.3303]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6372088193893433\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8161, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9251, 3.5698, 5.3639],\n",
      "        [8.9815, 3.7326, 5.2879],\n",
      "        [9.1198, 3.6241, 5.3308],\n",
      "        [8.9129, 3.5424, 5.2695],\n",
      "        [9.1688, 3.8597, 5.2633],\n",
      "        [9.0919, 3.5944, 5.3288]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.6618, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.9602,  8.2601, -2.1091],\n",
      "        [-6.7863,  8.2549, -2.1030],\n",
      "        [-6.8778,  8.2449, -2.0490],\n",
      "        [-6.7648,  7.8945, -2.3035],\n",
      "        [-6.5640,  7.9515, -1.9754],\n",
      "        [-6.7735,  8.2588, -2.1329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9251,  3.5698,  5.3639, -6.9602,  8.2601, -2.1091],\n",
      "        [ 8.9815,  3.7326,  5.2879, -6.7863,  8.2549, -2.1030],\n",
      "        [ 9.1198,  3.6241,  5.3308, -6.8778,  8.2449, -2.0490],\n",
      "        [ 8.9129,  3.5424,  5.2695, -6.7648,  7.8945, -2.3035],\n",
      "        [ 9.1688,  3.8597,  5.2633, -6.5640,  7.9515, -1.9754],\n",
      "        [ 9.0919,  3.5944,  5.3288, -6.7735,  8.2588, -2.1329]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6459252834320068\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.2768, 4.0222, 5.5111],\n",
      "        [8.7582, 3.7836, 5.2429],\n",
      "        [8.8543, 3.9646, 5.3714],\n",
      "        [9.0545, 3.6971, 5.2114],\n",
      "        [8.6669, 3.9001, 5.2890],\n",
      "        [9.0222, 3.8121, 5.4216]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3196, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8417,  7.8398, -2.2825],\n",
      "        [-6.7258,  8.0593, -2.1243],\n",
      "        [-6.9425,  8.2842, -2.0947],\n",
      "        [-6.7900,  8.2259, -1.9980],\n",
      "        [-6.8420,  8.1711, -1.9358],\n",
      "        [-6.7730,  7.9299, -2.0730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.2768,  4.0222,  5.5111, -6.8417,  7.8398, -2.2825],\n",
      "        [ 8.7582,  3.7836,  5.2429, -6.7258,  8.0593, -2.1243],\n",
      "        [ 8.8543,  3.9646,  5.3714, -6.9425,  8.2842, -2.0947],\n",
      "        [ 9.0545,  3.6971,  5.2114, -6.7900,  8.2259, -1.9980],\n",
      "        [ 8.6669,  3.9001,  5.2890, -6.8420,  8.1711, -1.9358],\n",
      "        [ 9.0222,  3.8121,  5.4216, -6.7730,  7.9299, -2.0730]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6589770317077637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9361, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9367, 3.7629, 5.4087],\n",
      "        [8.6328, 3.6857, 5.2777],\n",
      "        [9.0416, 3.6359, 5.3589],\n",
      "        [9.0674, 3.8509, 5.3725],\n",
      "        [8.9509, 3.6730, 5.7690],\n",
      "        [8.9445, 3.7629, 5.2739]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3687, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.0109,  8.4663, -2.2038],\n",
      "        [-7.0955,  8.2964, -1.9590],\n",
      "        [-6.7891,  8.0715, -2.2774],\n",
      "        [-6.9311,  8.1182, -2.1639],\n",
      "        [-7.0380,  8.1233, -2.4750],\n",
      "        [-6.7073,  8.2813, -2.2601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9367,  3.7629,  5.4087, -7.0109,  8.4663, -2.2038],\n",
      "        [ 8.6328,  3.6857,  5.2777, -7.0955,  8.2964, -1.9590],\n",
      "        [ 9.0416,  3.6359,  5.3589, -6.7891,  8.0715, -2.2774],\n",
      "        [ 9.0674,  3.8509,  5.3725, -6.9311,  8.1182, -2.1639],\n",
      "        [ 8.9509,  3.6730,  5.7690, -7.0380,  8.1233, -2.4750],\n",
      "        [ 8.9445,  3.7629,  5.2739, -6.7073,  8.2813, -2.2601]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.654032289981842\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9124, 3.9306, 5.4638],\n",
      "        [9.0786, 3.6059, 5.5190],\n",
      "        [9.3612, 3.9351, 5.3062],\n",
      "        [8.8840, 3.8550, 5.4162],\n",
      "        [8.9379, 4.0351, 5.4376],\n",
      "        [9.0400, 3.8866, 5.4681]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.8922, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8339,  8.3738, -2.1870],\n",
      "        [-6.7099,  8.2598, -2.0206],\n",
      "        [-6.8816,  8.1365, -2.3662],\n",
      "        [-6.8218,  8.4764, -2.3284],\n",
      "        [-6.6780,  8.4161, -2.2494],\n",
      "        [-6.9279,  8.4785, -2.2565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9124,  3.9306,  5.4638, -6.8339,  8.3738, -2.1870],\n",
      "        [ 9.0786,  3.6059,  5.5190, -6.7099,  8.2598, -2.0206],\n",
      "        [ 9.3612,  3.9351,  5.3062, -6.8816,  8.1365, -2.3662],\n",
      "        [ 8.8840,  3.8550,  5.4162, -6.8218,  8.4764, -2.3284],\n",
      "        [ 8.9379,  4.0351,  5.4376, -6.6780,  8.4161, -2.2494],\n",
      "        [ 9.0400,  3.8866,  5.4681, -6.9279,  8.4785, -2.2565]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6533493995666504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.0861, 3.9873, 5.2309],\n",
      "        [9.3850, 3.6314, 5.5203],\n",
      "        [9.1280, 3.9878, 5.6257],\n",
      "        [8.9325, 3.7426, 5.2111],\n",
      "        [9.0763, 3.5641, 5.5969],\n",
      "        [8.9913, 3.8118, 5.5774]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7914,  7.9256, -2.3798],\n",
      "        [-6.8365,  8.5389, -2.1859],\n",
      "        [-6.9359,  8.3860, -2.1013],\n",
      "        [-6.4571,  8.0632, -2.0763],\n",
      "        [-6.8494,  8.3371, -2.0987],\n",
      "        [-6.8758,  8.2580, -2.1603]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.0861,  3.9873,  5.2309, -6.7914,  7.9256, -2.3798],\n",
      "        [ 9.3850,  3.6314,  5.5203, -6.8365,  8.5389, -2.1859],\n",
      "        [ 9.1280,  3.9878,  5.6257, -6.9359,  8.3860, -2.1013],\n",
      "        [ 8.9325,  3.7426,  5.2111, -6.4571,  8.0632, -2.0763],\n",
      "        [ 9.0763,  3.5641,  5.5969, -6.8494,  8.3371, -2.0987],\n",
      "        [ 8.9913,  3.8118,  5.5774, -6.8758,  8.2580, -2.1603]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6485188007354736\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8808, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.9091, 3.8118, 5.4480],\n",
      "        [9.1013, 4.0234, 5.6018],\n",
      "        [9.2904, 4.1295, 5.5221],\n",
      "        [9.0061, 3.9376, 5.5465],\n",
      "        [8.9345, 3.6567, 5.2946],\n",
      "        [9.1055, 3.8586, 5.6612]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.8062, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.1247,  8.4897, -2.3624],\n",
      "        [-6.8780,  8.4023, -2.0706],\n",
      "        [-6.6829,  8.3102, -2.3264],\n",
      "        [-6.7974,  8.1826, -2.4604],\n",
      "        [-6.6562,  8.3473, -2.2780],\n",
      "        [-6.9214,  8.2764, -2.2873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.9091,  3.8118,  5.4480, -7.1247,  8.4897, -2.3624],\n",
      "        [ 9.1013,  4.0234,  5.6018, -6.8780,  8.4023, -2.0706],\n",
      "        [ 9.2904,  4.1295,  5.5221, -6.6829,  8.3102, -2.3264],\n",
      "        [ 9.0061,  3.9376,  5.5465, -6.7974,  8.1826, -2.4604],\n",
      "        [ 8.9345,  3.6567,  5.2946, -6.6562,  8.3473, -2.2780],\n",
      "        [ 9.1055,  3.8586,  5.6612, -6.9214,  8.2764, -2.2873]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6580385565757751\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6663, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.1608, 3.8238, 5.5144],\n",
      "        [8.9207, 3.4762, 5.4681],\n",
      "        [9.0351, 3.9968, 5.2381],\n",
      "        [8.9287, 3.8981, 5.4365],\n",
      "        [9.0574, 3.9775, 5.2195],\n",
      "        [8.9200, 3.6443, 5.5810]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.0144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7205,  8.5047, -1.9811],\n",
      "        [-7.0838,  8.2279, -2.2602],\n",
      "        [-7.3227,  8.4771, -2.2548],\n",
      "        [-7.0618,  8.2201, -2.1539],\n",
      "        [-7.1452,  8.1922, -1.8942],\n",
      "        [-7.0472,  8.3759, -2.3685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.1608,  3.8238,  5.5144, -6.7205,  8.5047, -1.9811],\n",
      "        [ 8.9207,  3.4762,  5.4681, -7.0838,  8.2279, -2.2602],\n",
      "        [ 9.0351,  3.9968,  5.2381, -7.3227,  8.4771, -2.2548],\n",
      "        [ 8.9287,  3.8981,  5.4365, -7.0618,  8.2201, -2.1539],\n",
      "        [ 9.0574,  3.9775,  5.2195, -7.1452,  8.1922, -1.8942],\n",
      "        [ 8.9200,  3.6443,  5.5810, -7.0472,  8.3759, -2.3685]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6626425981521606\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.2682, 3.9436, 5.4552],\n",
      "        [9.3060, 3.9262, 5.5046],\n",
      "        [9.0244, 3.8969, 5.6234],\n",
      "        [9.1370, 3.8375, 5.4334],\n",
      "        [9.3129, 4.0214, 5.7123],\n",
      "        [9.1274, 3.8625, 5.4007]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4388, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8653,  8.3175, -1.9140],\n",
      "        [-6.9263,  8.0725, -2.3648],\n",
      "        [-6.7078,  8.3086, -2.2558],\n",
      "        [-6.8434,  8.1181, -2.3181],\n",
      "        [-6.6669,  8.4752, -2.4643],\n",
      "        [-6.9876,  8.5463, -2.3636]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.2682,  3.9436,  5.4552, -6.8653,  8.3175, -1.9140],\n",
      "        [ 9.3060,  3.9262,  5.5046, -6.9263,  8.0725, -2.3648],\n",
      "        [ 9.0244,  3.8969,  5.6234, -6.7078,  8.3086, -2.2558],\n",
      "        [ 9.1370,  3.8375,  5.4334, -6.8434,  8.1181, -2.3181],\n",
      "        [ 9.3129,  4.0214,  5.7123, -6.6669,  8.4752, -2.4643],\n",
      "        [ 9.1274,  3.8625,  5.4007, -6.9876,  8.5463, -2.3636]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6653531193733215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7069, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.1751, 4.0241, 5.6579],\n",
      "        [9.0175, 3.9896, 5.4707],\n",
      "        [9.2303, 4.2490, 5.5929],\n",
      "        [9.2379, 3.8509, 5.4628],\n",
      "        [9.2312, 4.1683, 5.5673],\n",
      "        [9.1673, 3.9690, 5.7026]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3996, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8199,  8.4575, -2.2885],\n",
      "        [-6.7858,  7.9715, -2.3123],\n",
      "        [-6.8507,  8.1681, -2.4114],\n",
      "        [-7.2037,  8.5732, -2.1532],\n",
      "        [-6.9240,  8.4611, -2.1852],\n",
      "        [-6.9344,  8.3133, -2.3660]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.1751,  4.0241,  5.6579, -6.8199,  8.4575, -2.2885],\n",
      "        [ 9.0175,  3.9896,  5.4707, -6.7858,  7.9715, -2.3123],\n",
      "        [ 9.2303,  4.2490,  5.5929, -6.8507,  8.1681, -2.4114],\n",
      "        [ 9.2379,  3.8509,  5.4628, -7.2037,  8.5732, -2.1532],\n",
      "        [ 9.2312,  4.1683,  5.5673, -6.9240,  8.4611, -2.1852],\n",
      "        [ 9.1673,  3.9690,  5.7026, -6.9344,  8.3133, -2.3660]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6707773804664612\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.3669, 3.7588, 5.3726],\n",
      "        [9.1744, 4.1016, 5.5747],\n",
      "        [9.2075, 3.8866, 5.4796],\n",
      "        [9.0864, 4.0360, 5.4864],\n",
      "        [9.3836, 3.8362, 5.4505],\n",
      "        [8.9533, 3.8926, 5.4468]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2627, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7371,  8.2485, -2.3335],\n",
      "        [-6.9248,  8.4687, -2.1772],\n",
      "        [-6.9280,  8.6714, -2.1654],\n",
      "        [-6.6214,  8.3778, -2.2470],\n",
      "        [-6.9624,  8.3089, -2.1438],\n",
      "        [-7.0523,  8.3976, -2.4821]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.3669,  3.7588,  5.3726, -6.7371,  8.2485, -2.3335],\n",
      "        [ 9.1744,  4.1016,  5.5747, -6.9248,  8.4687, -2.1772],\n",
      "        [ 9.2075,  3.8866,  5.4796, -6.9280,  8.6714, -2.1654],\n",
      "        [ 9.0864,  4.0360,  5.4864, -6.6214,  8.3778, -2.2470],\n",
      "        [ 9.3836,  3.8362,  5.4505, -6.9624,  8.3089, -2.1438],\n",
      "        [ 8.9533,  3.8926,  5.4468, -7.0523,  8.3976, -2.4821]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6643595099449158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.2586, 4.0325, 5.5280],\n",
      "        [9.2429, 3.7425, 5.2676],\n",
      "        [9.1943, 3.7366, 5.5129],\n",
      "        [9.2541, 3.9743, 5.2539],\n",
      "        [9.2334, 3.9861, 5.6661],\n",
      "        [9.0723, 4.0319, 5.7132]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5689, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.1640,  8.6012, -2.0606],\n",
      "        [-6.9971,  8.4936, -2.1680],\n",
      "        [-6.9391,  8.2956, -2.3117],\n",
      "        [-7.0541,  8.2539, -2.3314],\n",
      "        [-7.1012,  8.3988, -2.1484],\n",
      "        [-6.6732,  8.1643, -2.0189]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.2586,  4.0325,  5.5280, -7.1640,  8.6012, -2.0606],\n",
      "        [ 9.2429,  3.7425,  5.2676, -6.9971,  8.4936, -2.1680],\n",
      "        [ 9.1943,  3.7366,  5.5129, -6.9391,  8.2956, -2.3117],\n",
      "        [ 9.2541,  3.9743,  5.2539, -7.0541,  8.2539, -2.3314],\n",
      "        [ 9.2334,  3.9861,  5.6661, -7.1012,  8.3988, -2.1484],\n",
      "        [ 9.0723,  4.0319,  5.7132, -6.6732,  8.1643, -2.0189]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6769640445709229\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.3497, 4.1072, 5.5166],\n",
      "        [9.4625, 3.6811, 5.3430],\n",
      "        [8.9397, 4.0877, 5.2986],\n",
      "        [9.0152, 3.6616, 5.7673],\n",
      "        [9.0792, 3.9297, 5.3801],\n",
      "        [9.3795, 4.0560, 5.5683]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.2750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.7327,  8.4583, -2.1964],\n",
      "        [-6.9348,  8.4747, -2.5435],\n",
      "        [-7.0963,  8.2008, -1.8808],\n",
      "        [-6.9054,  8.3951, -2.3636],\n",
      "        [-7.3634,  8.3870, -2.4499],\n",
      "        [-6.9815,  8.5458, -2.3041]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.3497,  4.1072,  5.5166, -6.7327,  8.4583, -2.1964],\n",
      "        [ 9.4625,  3.6811,  5.3430, -6.9348,  8.4747, -2.5435],\n",
      "        [ 8.9397,  4.0877,  5.2986, -7.0963,  8.2008, -1.8808],\n",
      "        [ 9.0152,  3.6616,  5.7673, -6.9054,  8.3951, -2.3636],\n",
      "        [ 9.0792,  3.9297,  5.3801, -7.3634,  8.3870, -2.4499],\n",
      "        [ 9.3795,  4.0560,  5.5683, -6.9815,  8.5458, -2.3041]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6742709279060364\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8040, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.3677, 3.5588, 5.3173],\n",
      "        [9.1141, 3.6311, 5.5965],\n",
      "        [9.3506, 3.9812, 5.6037],\n",
      "        [9.4298, 3.7594, 5.3456],\n",
      "        [9.2969, 4.1771, 5.7729],\n",
      "        [9.3281, 4.0374, 5.5568]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.4769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.9816,  8.3236, -2.3092],\n",
      "        [-6.8476,  8.6000, -2.1921],\n",
      "        [-7.1316,  8.3502, -2.0613],\n",
      "        [-6.7938,  8.3229, -2.4695],\n",
      "        [-7.1357,  8.4539, -2.0913],\n",
      "        [-6.8480,  8.5039, -2.3459]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.3677,  3.5588,  5.3173, -6.9816,  8.3236, -2.3092],\n",
      "        [ 9.1141,  3.6311,  5.5965, -6.8476,  8.6000, -2.1921],\n",
      "        [ 9.3506,  3.9812,  5.6037, -7.1316,  8.3502, -2.0613],\n",
      "        [ 9.4298,  3.7594,  5.3456, -6.7938,  8.3229, -2.4695],\n",
      "        [ 9.2969,  4.1771,  5.7729, -7.1357,  8.4539, -2.0913],\n",
      "        [ 9.3281,  4.0374,  5.5568, -6.8480,  8.5039, -2.3459]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6662132143974304\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.0293, 4.1295, 5.4565],\n",
      "        [9.1038, 4.0082, 5.3800],\n",
      "        [9.3411, 4.1434, 5.3899],\n",
      "        [9.3570, 3.9539, 5.6328],\n",
      "        [9.2597, 4.0759, 5.5061],\n",
      "        [9.4133, 3.9972, 5.5795]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.8101, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.1830,  8.4029, -2.4935],\n",
      "        [-7.1375,  8.4465, -2.5262],\n",
      "        [-7.0768,  8.1859, -2.1685],\n",
      "        [-7.0769,  8.4725, -2.3924],\n",
      "        [-7.0754,  8.6900, -2.3887],\n",
      "        [-6.9862,  8.7042, -2.4119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.0293,  4.1295,  5.4565, -7.1830,  8.4029, -2.4935],\n",
      "        [ 9.1038,  4.0082,  5.3800, -7.1375,  8.4465, -2.5262],\n",
      "        [ 9.3411,  4.1434,  5.3899, -7.0768,  8.1859, -2.1685],\n",
      "        [ 9.3570,  3.9539,  5.6328, -7.0769,  8.4725, -2.3924],\n",
      "        [ 9.2597,  4.0759,  5.5061, -7.0754,  8.6900, -2.3887],\n",
      "        [ 9.4133,  3.9972,  5.5795, -6.9862,  8.7042, -2.4119]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6691370010375977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[8.8854, 3.9678, 5.5437],\n",
      "        [9.3969, 4.1624, 5.6712],\n",
      "        [9.5622, 3.9728, 5.5428],\n",
      "        [9.3455, 4.0460, 5.4932],\n",
      "        [8.9876, 4.1433, 5.5317],\n",
      "        [9.2839, 4.2177, 5.5226]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.0649,  8.4756, -2.3037],\n",
      "        [-6.9059,  8.4439, -2.4733],\n",
      "        [-7.1361,  8.1361, -2.2371],\n",
      "        [-6.9753,  8.5435, -2.0722],\n",
      "        [-7.0190,  8.3457, -2.2581],\n",
      "        [-7.0833,  8.5536, -2.6234]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 8.8854,  3.9678,  5.5437, -7.0649,  8.4756, -2.3037],\n",
      "        [ 9.3969,  4.1624,  5.6712, -6.9059,  8.4439, -2.4733],\n",
      "        [ 9.5622,  3.9728,  5.5428, -7.1361,  8.1361, -2.2371],\n",
      "        [ 9.3455,  4.0460,  5.4932, -6.9753,  8.5435, -2.0722],\n",
      "        [ 8.9876,  4.1433,  5.5317, -7.0190,  8.3457, -2.2581],\n",
      "        [ 9.2839,  4.2177,  5.5226, -7.0833,  8.5536, -2.6234]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6642614006996155\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1762, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.5937, 3.9125, 5.8351],\n",
      "        [9.4230, 3.9414, 5.5635],\n",
      "        [9.4668, 4.0558, 5.7115],\n",
      "        [9.4473, 3.9933, 5.6468],\n",
      "        [9.2385, 4.0409, 5.5549],\n",
      "        [9.2017, 4.1691, 5.4296]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.8889, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.2643,  8.5835, -2.4924],\n",
      "        [-6.7550,  8.5132, -2.0717],\n",
      "        [-6.8446,  8.3319, -2.3832],\n",
      "        [-7.0677,  8.3007, -2.4151],\n",
      "        [-6.9426,  8.2558, -2.2599],\n",
      "        [-6.5573,  8.4690, -2.5343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5937,  3.9125,  5.8351, -7.2643,  8.5835, -2.4924],\n",
      "        [ 9.4230,  3.9414,  5.5635, -6.7550,  8.5132, -2.0717],\n",
      "        [ 9.4668,  4.0558,  5.7115, -6.8446,  8.3319, -2.3832],\n",
      "        [ 9.4473,  3.9933,  5.6468, -7.0677,  8.3007, -2.4151],\n",
      "        [ 9.2385,  4.0409,  5.5549, -6.9426,  8.2558, -2.2599],\n",
      "        [ 9.2017,  4.1691,  5.4296, -6.5573,  8.4690, -2.5343]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6979441046714783\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4885, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.3383, 3.8478, 5.3548],\n",
      "        [9.3720, 4.0710, 5.6361],\n",
      "        [9.2725, 3.9095, 5.6940],\n",
      "        [9.6453, 4.2411, 5.5034],\n",
      "        [9.4788, 3.8183, 5.6834],\n",
      "        [9.4530, 3.8135, 5.5181]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.9396,  8.5681, -2.1896],\n",
      "        [-7.1202,  8.5616, -2.6750],\n",
      "        [-7.2070,  8.3539, -2.4762],\n",
      "        [-6.9274,  8.6550, -2.5110],\n",
      "        [-7.1520,  8.5967, -2.4683],\n",
      "        [-6.8911,  8.3259, -2.4643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.3383,  3.8478,  5.3548, -6.9396,  8.5681, -2.1896],\n",
      "        [ 9.3720,  4.0710,  5.6361, -7.1202,  8.5616, -2.6750],\n",
      "        [ 9.2725,  3.9095,  5.6940, -7.2070,  8.3539, -2.4762],\n",
      "        [ 9.6453,  4.2411,  5.5034, -6.9274,  8.6550, -2.5110],\n",
      "        [ 9.4788,  3.8183,  5.6834, -7.1520,  8.5967, -2.4683],\n",
      "        [ 9.4530,  3.8135,  5.5181, -6.8911,  8.3259, -2.4643]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6737571358680725\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3214, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.4811, 4.0041, 5.6069],\n",
      "        [9.3068, 3.7459, 5.4902],\n",
      "        [9.2290, 4.2026, 5.4832],\n",
      "        [9.1309, 3.7326, 5.3837],\n",
      "        [9.1925, 3.9809, 5.7323],\n",
      "        [9.5070, 3.7473, 5.8303]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.0458,  8.4200, -2.4112],\n",
      "        [-6.8456,  8.6374, -2.4001],\n",
      "        [-7.2216,  8.6167, -2.4980],\n",
      "        [-6.9729,  8.3877, -2.3706],\n",
      "        [-7.2488,  8.3594, -2.4706],\n",
      "        [-7.0584,  8.7016, -2.4527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.4811,  4.0041,  5.6069, -7.0458,  8.4200, -2.4112],\n",
      "        [ 9.3068,  3.7459,  5.4902, -6.8456,  8.6374, -2.4001],\n",
      "        [ 9.2290,  4.2026,  5.4832, -7.2216,  8.6167, -2.4980],\n",
      "        [ 9.1309,  3.7326,  5.3837, -6.9729,  8.3877, -2.3706],\n",
      "        [ 9.1925,  3.9809,  5.7323, -7.2488,  8.3594, -2.4706],\n",
      "        [ 9.5070,  3.7473,  5.8303, -7.0584,  8.7016, -2.4527]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6860113143920898\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7850, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.4169, 3.9951, 5.4464],\n",
      "        [9.8787, 4.1034, 5.8140],\n",
      "        [9.3777, 4.2126, 5.6754],\n",
      "        [9.4474, 3.8979, 5.6236],\n",
      "        [9.5522, 4.1458, 5.5047],\n",
      "        [9.8400, 4.2734, 5.6067]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.5279, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.9107,  8.4590, -2.5579],\n",
      "        [-7.3212,  8.5596, -2.5803],\n",
      "        [-7.3380,  8.7363, -2.5968],\n",
      "        [-7.1655,  8.6046, -2.5411],\n",
      "        [-7.0687,  8.5183, -2.3240],\n",
      "        [-7.2743,  8.5013, -2.0950]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.4169,  3.9951,  5.4464, -6.9107,  8.4590, -2.5579],\n",
      "        [ 9.8787,  4.1034,  5.8140, -7.3212,  8.5596, -2.5803],\n",
      "        [ 9.3777,  4.2126,  5.6754, -7.3380,  8.7363, -2.5968],\n",
      "        [ 9.4474,  3.8979,  5.6236, -7.1655,  8.6046, -2.5411],\n",
      "        [ 9.5522,  4.1458,  5.5047, -7.0687,  8.5183, -2.3240],\n",
      "        [ 9.8400,  4.2734,  5.6067, -7.2743,  8.5013, -2.0950]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.680130660533905\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8683, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.4831, 3.5680, 5.7373],\n",
      "        [9.4105, 3.9753, 5.8103],\n",
      "        [9.6176, 4.1671, 5.6473],\n",
      "        [9.3184, 3.7360, 5.6695],\n",
      "        [9.5209, 3.9619, 5.8053],\n",
      "        [9.5016, 3.9283, 5.6852]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.6852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3012,  8.4383, -2.8308],\n",
      "        [-7.4214,  8.4850, -2.4583],\n",
      "        [-7.1590,  8.5639, -2.3400],\n",
      "        [-7.2808,  8.4051, -2.3811],\n",
      "        [-7.2406,  8.7427, -2.3977],\n",
      "        [-6.9992,  8.4625, -2.5430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.4831,  3.5680,  5.7373, -7.3012,  8.4383, -2.8308],\n",
      "        [ 9.4105,  3.9753,  5.8103, -7.4214,  8.4850, -2.4583],\n",
      "        [ 9.6176,  4.1671,  5.6473, -7.1590,  8.5639, -2.3400],\n",
      "        [ 9.3184,  3.7360,  5.6695, -7.2808,  8.4051, -2.3811],\n",
      "        [ 9.5209,  3.9619,  5.8053, -7.2406,  8.7427, -2.3977],\n",
      "        [ 9.5016,  3.9283,  5.6852, -6.9992,  8.4625, -2.5430]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.6897462606430054\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1856, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.5358, 3.9461, 5.7076],\n",
      "        [9.4130, 4.0535, 5.6407],\n",
      "        [9.4265, 4.0624, 5.5868],\n",
      "        [9.4147, 3.8903, 5.6282],\n",
      "        [9.4824, 4.1647, 6.0035],\n",
      "        [9.2702, 3.8335, 5.6279]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.3388, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.2114,  8.5195, -2.3513],\n",
      "        [-7.3776,  8.6565, -2.5785],\n",
      "        [-7.4333,  8.6382, -2.4591],\n",
      "        [-7.1491,  8.7463, -2.5022],\n",
      "        [-6.5182,  8.4786, -2.2134],\n",
      "        [-7.1429,  8.5003, -2.4267]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5358,  3.9461,  5.7076, -7.2114,  8.5195, -2.3513],\n",
      "        [ 9.4130,  4.0535,  5.6407, -7.3776,  8.6565, -2.5785],\n",
      "        [ 9.4265,  4.0624,  5.5868, -7.4333,  8.6382, -2.4591],\n",
      "        [ 9.4147,  3.8903,  5.6282, -7.1491,  8.7463, -2.5022],\n",
      "        [ 9.4824,  4.1647,  6.0035, -6.5182,  8.4786, -2.2134],\n",
      "        [ 9.2702,  3.8335,  5.6279, -7.1429,  8.5003, -2.4267]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6940375566482544\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8869, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.5095, 4.1328, 5.4173],\n",
      "        [9.4874, 3.7815, 5.6713],\n",
      "        [9.3003, 3.8532, 5.3353],\n",
      "        [9.6906, 4.1709, 5.8569],\n",
      "        [9.2552, 4.0866, 5.3885],\n",
      "        [9.3213, 4.1714, 5.7042]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.5235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.1328,  8.6236, -2.4562],\n",
      "        [-6.9995,  8.5072, -2.4827],\n",
      "        [-7.1903,  8.6279, -2.3139],\n",
      "        [-7.0813,  8.6640, -2.3964],\n",
      "        [-7.4124,  8.8103, -2.3859],\n",
      "        [-7.1777,  8.6431, -2.6203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5095,  4.1328,  5.4173, -7.1328,  8.6236, -2.4562],\n",
      "        [ 9.4874,  3.7815,  5.6713, -6.9995,  8.5072, -2.4827],\n",
      "        [ 9.3003,  3.8532,  5.3353, -7.1903,  8.6279, -2.3139],\n",
      "        [ 9.6906,  4.1709,  5.8569, -7.0813,  8.6640, -2.3964],\n",
      "        [ 9.2552,  4.0866,  5.3885, -7.4124,  8.8103, -2.3859],\n",
      "        [ 9.3213,  4.1714,  5.7042, -7.1777,  8.6431, -2.6203]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6900715827941895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9939, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.1950, 4.0992, 5.6105],\n",
      "        [9.6434, 4.0439, 5.4371],\n",
      "        [9.6679, 4.1814, 5.7622],\n",
      "        [9.4171, 4.1569, 5.8646],\n",
      "        [9.4355, 3.9871, 5.7926],\n",
      "        [9.7070, 3.9952, 5.9113]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.2091,  8.7751, -2.6299],\n",
      "        [-7.2088,  8.5617, -2.4488],\n",
      "        [-7.0225,  8.8046, -2.3832],\n",
      "        [-7.3988,  8.5991, -2.2210],\n",
      "        [-7.0788,  8.5800, -2.5024],\n",
      "        [-7.1815,  8.4521, -2.6088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.1950,  4.0992,  5.6105, -7.2091,  8.7751, -2.6299],\n",
      "        [ 9.6434,  4.0439,  5.4371, -7.2088,  8.5617, -2.4488],\n",
      "        [ 9.6679,  4.1814,  5.7622, -7.0225,  8.8046, -2.3832],\n",
      "        [ 9.4171,  4.1569,  5.8646, -7.3988,  8.5991, -2.2210],\n",
      "        [ 9.4355,  3.9871,  5.7926, -7.0788,  8.5800, -2.5024],\n",
      "        [ 9.7070,  3.9952,  5.9113, -7.1815,  8.4521, -2.6088]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6879954934120178\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8073, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.4214, 4.0231, 5.5945],\n",
      "        [9.7813, 4.0485, 6.1894],\n",
      "        [9.4113, 3.9723, 5.7840],\n",
      "        [9.5862, 4.2093, 5.6749],\n",
      "        [9.1993, 4.0407, 5.8987],\n",
      "        [9.2984, 3.7919, 5.4937]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9187, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3172,  8.5604, -2.7984],\n",
      "        [-7.0856,  8.7897, -2.4478],\n",
      "        [-7.5362,  8.7149, -2.4501],\n",
      "        [-7.1262,  9.0071, -2.5418],\n",
      "        [-7.2717,  8.6424, -2.5348],\n",
      "        [-7.0521,  8.4732, -2.3402]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.4214,  4.0231,  5.5945, -7.3172,  8.5604, -2.7984],\n",
      "        [ 9.7813,  4.0485,  6.1894, -7.0856,  8.7897, -2.4478],\n",
      "        [ 9.4113,  3.9723,  5.7840, -7.5362,  8.7149, -2.4501],\n",
      "        [ 9.5862,  4.2093,  5.6749, -7.1262,  9.0071, -2.5418],\n",
      "        [ 9.1993,  4.0407,  5.8987, -7.2717,  8.6424, -2.5348],\n",
      "        [ 9.2984,  3.7919,  5.4937, -7.0521,  8.4732, -2.3402]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.6933221817016602\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9501, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.2966, 4.3358, 5.5944],\n",
      "        [9.5586, 4.0304, 5.8569],\n",
      "        [9.4127, 4.1079, 5.9469],\n",
      "        [9.6578, 4.4289, 5.7286],\n",
      "        [9.4576, 4.2159, 5.7094],\n",
      "        [9.6430, 4.0987, 5.7705]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.6839, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8573,  8.2560, -2.3923],\n",
      "        [-7.4355,  8.6764, -2.6454],\n",
      "        [-7.2920,  8.8561, -2.3812],\n",
      "        [-7.2429,  8.7085, -2.7397],\n",
      "        [-7.3892,  8.5472, -2.5928],\n",
      "        [-7.1495,  8.7422, -2.5899]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.2966,  4.3358,  5.5944, -6.8573,  8.2560, -2.3923],\n",
      "        [ 9.5586,  4.0304,  5.8569, -7.4355,  8.6764, -2.6454],\n",
      "        [ 9.4127,  4.1079,  5.9469, -7.2920,  8.8561, -2.3812],\n",
      "        [ 9.6578,  4.4289,  5.7286, -7.2429,  8.7085, -2.7397],\n",
      "        [ 9.4576,  4.2159,  5.7094, -7.3892,  8.5472, -2.5928],\n",
      "        [ 9.6430,  4.0987,  5.7705, -7.1495,  8.7422, -2.5899]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.682129442691803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.5191, 4.0566, 5.8784],\n",
      "        [9.6172, 3.8595, 5.3499],\n",
      "        [9.5955, 3.8992, 5.5901],\n",
      "        [9.3229, 4.0328, 5.8604],\n",
      "        [9.3909, 4.2657, 6.0219],\n",
      "        [9.4702, 4.1516, 5.8774]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.5640, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3120,  8.9579, -2.7057],\n",
      "        [-7.0805,  8.5066, -2.2649],\n",
      "        [-7.1706,  8.4120, -2.6644],\n",
      "        [-7.3987,  8.6600, -2.5298],\n",
      "        [-7.4124,  8.7612, -2.4232],\n",
      "        [-7.2973,  8.6037, -2.4666]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5191,  4.0566,  5.8784, -7.3120,  8.9579, -2.7057],\n",
      "        [ 9.6172,  3.8595,  5.3499, -7.0805,  8.5066, -2.2649],\n",
      "        [ 9.5955,  3.8992,  5.5901, -7.1706,  8.4120, -2.6644],\n",
      "        [ 9.3229,  4.0328,  5.8604, -7.3987,  8.6600, -2.5298],\n",
      "        [ 9.3909,  4.2657,  6.0219, -7.4124,  8.7612, -2.4232],\n",
      "        [ 9.4702,  4.1516,  5.8774, -7.2973,  8.6037, -2.4666]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7096202969551086\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.4475, 4.4598, 5.7251],\n",
      "        [9.3904, 4.0992, 5.6114],\n",
      "        [9.5668, 4.1349, 5.9225],\n",
      "        [9.2041, 4.2759, 5.4710],\n",
      "        [9.4442, 4.0898, 5.9382],\n",
      "        [9.8475, 4.0691, 5.7710]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.8318, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.4223,  8.7474, -2.5875],\n",
      "        [-7.3372,  8.7190, -2.5582],\n",
      "        [-7.0804,  8.8143, -2.5928],\n",
      "        [-7.3049,  8.8354, -2.4398],\n",
      "        [-7.1880,  8.8135, -2.3872],\n",
      "        [-7.1903,  9.1155, -2.2405]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.4475,  4.4598,  5.7251, -7.4223,  8.7474, -2.5875],\n",
      "        [ 9.3904,  4.0992,  5.6114, -7.3372,  8.7190, -2.5582],\n",
      "        [ 9.5668,  4.1349,  5.9225, -7.0804,  8.8143, -2.5928],\n",
      "        [ 9.2041,  4.2759,  5.4710, -7.3049,  8.8354, -2.4398],\n",
      "        [ 9.4442,  4.0898,  5.9382, -7.1880,  8.8135, -2.3872],\n",
      "        [ 9.8475,  4.0691,  5.7710, -7.1903,  9.1155, -2.2405]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.7066841721534729\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9577, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.3998, 4.1404, 5.8787],\n",
      "        [9.7519, 4.4040, 5.7173],\n",
      "        [9.6475, 4.0621, 5.9011],\n",
      "        [9.7444, 3.9629, 5.8084],\n",
      "        [9.5805, 3.9946, 5.8905],\n",
      "        [9.4868, 4.2593, 5.6273]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.0556, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.5137,  8.6824, -2.5221],\n",
      "        [-7.2725,  8.7997, -2.3156],\n",
      "        [-7.0845,  8.5703, -2.5766],\n",
      "        [-7.3944,  8.8815, -2.6094],\n",
      "        [-7.3513,  8.8527, -2.5492],\n",
      "        [-7.4548,  8.6744, -2.4683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.3998,  4.1404,  5.8787, -7.5137,  8.6824, -2.5221],\n",
      "        [ 9.7519,  4.4040,  5.7173, -7.2725,  8.7997, -2.3156],\n",
      "        [ 9.6475,  4.0621,  5.9011, -7.0845,  8.5703, -2.5766],\n",
      "        [ 9.7444,  3.9629,  5.8084, -7.3944,  8.8815, -2.6094],\n",
      "        [ 9.5805,  3.9946,  5.8905, -7.3513,  8.8527, -2.5492],\n",
      "        [ 9.4868,  4.2593,  5.6273, -7.4548,  8.6744, -2.4683]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.705518364906311\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9352, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.7710, 4.3146, 5.7293],\n",
      "        [9.3946, 3.8921, 5.7826],\n",
      "        [9.3412, 3.8325, 5.7958],\n",
      "        [9.4439, 4.1349, 5.6429],\n",
      "        [9.9686, 4.1711, 6.0215],\n",
      "        [9.8421, 4.4324, 5.7705]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.4208,  8.4230, -2.6479],\n",
      "        [-7.4479,  8.7965, -2.7198],\n",
      "        [-7.5240,  8.9076, -2.5556],\n",
      "        [-7.4604,  8.9772, -2.5656],\n",
      "        [-7.4806,  8.6719, -2.6184],\n",
      "        [-7.1718,  8.6953, -2.5975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.7710,  4.3146,  5.7293, -7.4208,  8.4230, -2.6479],\n",
      "        [ 9.3946,  3.8921,  5.7826, -7.4479,  8.7965, -2.7198],\n",
      "        [ 9.3412,  3.8325,  5.7958, -7.5240,  8.9076, -2.5556],\n",
      "        [ 9.4439,  4.1349,  5.6429, -7.4604,  8.9772, -2.5656],\n",
      "        [ 9.9686,  4.1711,  6.0215, -7.4806,  8.6719, -2.6184],\n",
      "        [ 9.8421,  4.4324,  5.7705, -7.1718,  8.6953, -2.5975]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7121400833129883\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3904, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.6317, 4.0346, 5.4748],\n",
      "        [9.2880, 4.3946, 6.0337],\n",
      "        [9.5322, 3.9611, 6.0798],\n",
      "        [9.4728, 4.2590, 5.6059],\n",
      "        [9.4327, 4.2908, 5.7338],\n",
      "        [9.6650, 3.9737, 5.8000]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.9485, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.0781,  8.8203, -2.5873],\n",
      "        [-7.1934,  8.8011, -2.5592],\n",
      "        [-7.3695,  8.6944, -2.6177],\n",
      "        [-7.4292,  8.9345, -2.4529],\n",
      "        [-7.3340,  8.7173, -2.5749],\n",
      "        [-7.4777,  8.8633, -2.5557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.6317,  4.0346,  5.4748, -7.0781,  8.8203, -2.5873],\n",
      "        [ 9.2880,  4.3946,  6.0337, -7.1934,  8.8011, -2.5592],\n",
      "        [ 9.5322,  3.9611,  6.0798, -7.3695,  8.6944, -2.6177],\n",
      "        [ 9.4728,  4.2590,  5.6059, -7.4292,  8.9345, -2.4529],\n",
      "        [ 9.4327,  4.2908,  5.7338, -7.3340,  8.7173, -2.5749],\n",
      "        [ 9.6650,  3.9737,  5.8000, -7.4777,  8.8633, -2.5557]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7007331848144531\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3429, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9268,  4.1356,  5.8732],\n",
      "        [ 9.4351,  4.0824,  5.7264],\n",
      "        [ 9.5585,  4.1986,  5.8667],\n",
      "        [ 9.7234,  4.1239,  5.9609],\n",
      "        [10.0295,  4.0490,  5.8082],\n",
      "        [ 9.8044,  4.4350,  5.7924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.6968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3798,  8.8728, -2.8127],\n",
      "        [-7.2776,  8.8571, -2.6876],\n",
      "        [-7.1138,  9.0308, -2.6466],\n",
      "        [-7.5298,  8.7695, -2.6417],\n",
      "        [-7.5290,  8.6879, -2.8962],\n",
      "        [-7.3874,  8.5880, -2.6716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9268,  4.1356,  5.8732, -7.3798,  8.8728, -2.8127],\n",
      "        [ 9.4351,  4.0824,  5.7264, -7.2776,  8.8571, -2.6876],\n",
      "        [ 9.5585,  4.1986,  5.8667, -7.1138,  9.0308, -2.6466],\n",
      "        [ 9.7234,  4.1239,  5.9609, -7.5298,  8.7695, -2.6417],\n",
      "        [10.0295,  4.0490,  5.8082, -7.5290,  8.6879, -2.8962],\n",
      "        [ 9.8044,  4.4350,  5.7924, -7.3874,  8.5880, -2.6716]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7260180711746216\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4113, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.6147, 4.1977, 5.8000],\n",
      "        [9.4084, 3.9754, 6.0471],\n",
      "        [9.8220, 4.2785, 5.8914],\n",
      "        [9.6614, 4.1534, 5.8481],\n",
      "        [9.7772, 4.2646, 5.9871],\n",
      "        [9.7512, 4.2516, 5.9346]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3254,  9.0321, -2.5783],\n",
      "        [-7.3061,  8.9026, -2.7157],\n",
      "        [-7.2363,  8.6058, -2.6288],\n",
      "        [-7.1140,  8.3769, -2.4273],\n",
      "        [-7.5758,  8.8792, -2.5217],\n",
      "        [-7.1499,  8.7031, -2.7958]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.6147,  4.1977,  5.8000, -7.3254,  9.0321, -2.5783],\n",
      "        [ 9.4084,  3.9754,  6.0471, -7.3061,  8.9026, -2.7157],\n",
      "        [ 9.8220,  4.2785,  5.8914, -7.2363,  8.6058, -2.6288],\n",
      "        [ 9.6614,  4.1534,  5.8481, -7.1140,  8.3769, -2.4273],\n",
      "        [ 9.7772,  4.2646,  5.9871, -7.5758,  8.8792, -2.5217],\n",
      "        [ 9.7512,  4.2516,  5.9346, -7.1499,  8.7031, -2.7958]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7163270711898804\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5959, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.6981, 4.3940, 5.8873],\n",
      "        [9.6425, 4.3476, 5.8676],\n",
      "        [9.5795, 4.2403, 5.8168],\n",
      "        [9.8381, 4.5133, 5.7487],\n",
      "        [9.6296, 4.0661, 5.5442],\n",
      "        [9.5525, 4.2922, 5.8226]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.8347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.2542,  8.9302, -2.8562],\n",
      "        [-7.4059,  8.9269, -2.7741],\n",
      "        [-7.4431,  9.0980, -2.6809],\n",
      "        [-7.7383,  8.7073, -2.7346],\n",
      "        [-7.5188,  9.0598, -2.5986],\n",
      "        [-7.3808,  8.5216, -2.4947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.6981,  4.3940,  5.8873, -7.2542,  8.9302, -2.8562],\n",
      "        [ 9.6425,  4.3476,  5.8676, -7.4059,  8.9269, -2.7741],\n",
      "        [ 9.5795,  4.2403,  5.8168, -7.4431,  9.0980, -2.6809],\n",
      "        [ 9.8381,  4.5133,  5.7487, -7.7383,  8.7073, -2.7346],\n",
      "        [ 9.6296,  4.0661,  5.5442, -7.5188,  9.0598, -2.5986],\n",
      "        [ 9.5525,  4.2922,  5.8226, -7.3808,  8.5216, -2.4947]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7222862839698792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7593, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.7732, 4.3151, 5.7733],\n",
      "        [9.7453, 4.3652, 5.9503],\n",
      "        [9.8445, 4.3977, 5.9995],\n",
      "        [9.9392, 4.1822, 5.8393],\n",
      "        [9.7671, 3.9362, 5.8875],\n",
      "        [9.6584, 4.1185, 5.7483]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.8204, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.4999,  8.8643, -2.7917],\n",
      "        [-7.3578,  8.9022, -2.6083],\n",
      "        [-7.6454,  8.7280, -2.5225],\n",
      "        [-7.5404,  8.8695, -2.8530],\n",
      "        [-7.5652,  9.0141, -2.5654],\n",
      "        [-7.5902,  8.7823, -2.2433]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.7732,  4.3151,  5.7733, -7.4999,  8.8643, -2.7917],\n",
      "        [ 9.7453,  4.3652,  5.9503, -7.3578,  8.9022, -2.6083],\n",
      "        [ 9.8445,  4.3977,  5.9995, -7.6454,  8.7280, -2.5225],\n",
      "        [ 9.9392,  4.1822,  5.8393, -7.5404,  8.8695, -2.8530],\n",
      "        [ 9.7671,  3.9362,  5.8875, -7.5652,  9.0141, -2.5654],\n",
      "        [ 9.6584,  4.1185,  5.7483, -7.5902,  8.7823, -2.2433]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.7235301733016968\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6425, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.5974, 4.3983, 5.8997],\n",
      "        [9.6907, 4.0609, 5.9992],\n",
      "        [9.4295, 4.1710, 5.4361],\n",
      "        [9.6560, 4.4748, 6.0318],\n",
      "        [9.8987, 4.6122, 5.8633],\n",
      "        [9.6200, 4.3660, 5.8512]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.3576, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.3026,  8.7895, -2.6403],\n",
      "        [-7.1561,  8.7779, -2.7400],\n",
      "        [-7.3149,  8.7385, -2.6237],\n",
      "        [-7.4770,  8.7608, -2.7425],\n",
      "        [-7.4705,  8.9039, -2.8012],\n",
      "        [-7.6382,  9.1100, -2.7052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5974,  4.3983,  5.8997, -7.3026,  8.7895, -2.6403],\n",
      "        [ 9.6907,  4.0609,  5.9992, -7.1561,  8.7779, -2.7400],\n",
      "        [ 9.4295,  4.1710,  5.4361, -7.3149,  8.7385, -2.6237],\n",
      "        [ 9.6560,  4.4748,  6.0318, -7.4770,  8.7608, -2.7425],\n",
      "        [ 9.8987,  4.6122,  5.8633, -7.4705,  8.9039, -2.8012],\n",
      "        [ 9.6200,  4.3660,  5.8512, -7.6382,  9.1100, -2.7052]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7181896567344666\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.8934,  4.0263,  5.8359],\n",
      "        [ 9.7402,  4.2214,  5.9666],\n",
      "        [ 9.8206,  4.4742,  6.1632],\n",
      "        [ 9.8024,  4.5121,  5.7855],\n",
      "        [ 9.9052,  4.5746,  6.1105],\n",
      "        [10.0026,  4.3340,  6.1073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(3.7850, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.6835,  9.3047, -2.6844],\n",
      "        [-7.8083,  8.8325, -2.5832],\n",
      "        [-7.4629,  8.8273, -2.9873],\n",
      "        [-7.1776,  8.7326, -2.5640],\n",
      "        [-7.6546,  9.1080, -2.6676],\n",
      "        [-7.8114,  8.5777, -2.3177]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.8934,  4.0263,  5.8359, -7.6835,  9.3047, -2.6844],\n",
      "        [ 9.7402,  4.2214,  5.9666, -7.8083,  8.8325, -2.5832],\n",
      "        [ 9.8206,  4.4742,  6.1632, -7.4629,  8.8273, -2.9873],\n",
      "        [ 9.8024,  4.5121,  5.7855, -7.1776,  8.7326, -2.5640],\n",
      "        [ 9.9052,  4.5746,  6.1105, -7.6546,  9.1080, -2.6676],\n",
      "        [10.0026,  4.3340,  6.1073, -7.8114,  8.5777, -2.3177]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7348878979682922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6103, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.8955,  4.3971,  6.0083],\n",
      "        [ 9.6300,  4.3859,  6.1502],\n",
      "        [ 9.8502,  4.2771,  6.2778],\n",
      "        [10.0539,  4.4916,  5.7215],\n",
      "        [ 9.7111,  4.4751,  5.7675],\n",
      "        [ 9.9649,  4.3980,  6.0657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.3396, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.5749,  8.9199, -2.6975],\n",
      "        [-7.6131,  9.0326, -2.4761],\n",
      "        [-7.3789,  8.9972, -2.3913],\n",
      "        [-7.5839,  8.7287, -2.5370],\n",
      "        [-7.6398,  8.9970, -2.7676],\n",
      "        [-7.8616,  8.9728, -2.8389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.8955,  4.3971,  6.0083, -7.5749,  8.9199, -2.6975],\n",
      "        [ 9.6300,  4.3859,  6.1502, -7.6131,  9.0326, -2.4761],\n",
      "        [ 9.8502,  4.2771,  6.2778, -7.3789,  8.9972, -2.3913],\n",
      "        [10.0539,  4.4916,  5.7215, -7.5839,  8.7287, -2.5370],\n",
      "        [ 9.7111,  4.4751,  5.7675, -7.6398,  8.9970, -2.7676],\n",
      "        [ 9.9649,  4.3980,  6.0657, -7.8616,  8.9728, -2.8389]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7366890907287598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4567, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.8884,  4.3691,  6.1765],\n",
      "        [ 9.8191,  4.5356,  5.9200],\n",
      "        [10.0673,  4.2234,  5.8378],\n",
      "        [ 9.7053,  4.3867,  5.8062],\n",
      "        [10.0579,  4.5982,  6.2064],\n",
      "        [10.0544,  4.5889,  5.8736]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.4391, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.4219,  9.0554, -2.6109],\n",
      "        [-7.3922,  8.7648, -2.6988],\n",
      "        [-7.4272,  8.9733, -2.8583],\n",
      "        [-7.4642,  9.0832, -2.4748],\n",
      "        [-7.6026,  8.7942, -2.8654],\n",
      "        [-7.5455,  8.9513, -2.7783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.8884,  4.3691,  6.1765, -7.4219,  9.0554, -2.6109],\n",
      "        [ 9.8191,  4.5356,  5.9200, -7.3922,  8.7648, -2.6988],\n",
      "        [10.0673,  4.2234,  5.8378, -7.4272,  8.9733, -2.8583],\n",
      "        [ 9.7053,  4.3867,  5.8062, -7.4642,  9.0832, -2.4748],\n",
      "        [10.0579,  4.5982,  6.2064, -7.6026,  8.7942, -2.8654],\n",
      "        [10.0544,  4.5889,  5.8736, -7.5455,  8.9513, -2.7783]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7403365969657898\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.7158,  4.4038,  5.8102],\n",
      "        [ 9.6711,  4.1725,  5.9396],\n",
      "        [10.0453,  4.6334,  6.0399],\n",
      "        [ 9.7182,  4.6182,  5.9218],\n",
      "        [ 9.7170,  4.2554,  5.8998],\n",
      "        [ 9.6675,  4.1699,  5.8257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.4162, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.6426,  9.0841, -3.0314],\n",
      "        [-7.4597,  8.8197, -2.8463],\n",
      "        [-7.5153,  8.9743, -2.4774],\n",
      "        [-7.5105,  9.0172, -2.7651],\n",
      "        [-7.3907,  9.0887, -2.4820],\n",
      "        [-7.5317,  9.0375, -2.6430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.7158,  4.4038,  5.8102, -7.6426,  9.0841, -3.0314],\n",
      "        [ 9.6711,  4.1725,  5.9396, -7.4597,  8.8197, -2.8463],\n",
      "        [10.0453,  4.6334,  6.0399, -7.5153,  8.9743, -2.4774],\n",
      "        [ 9.7182,  4.6182,  5.9218, -7.5105,  9.0172, -2.7651],\n",
      "        [ 9.7170,  4.2554,  5.8998, -7.3907,  9.0887, -2.4820],\n",
      "        [ 9.6675,  4.1699,  5.8257, -7.5317,  9.0375, -2.6430]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7317682504653931\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[9.6895, 4.3889, 5.7482],\n",
      "        [9.9222, 3.9745, 5.7635],\n",
      "        [9.8089, 4.2846, 5.9754],\n",
      "        [9.6803, 4.6464, 5.9226],\n",
      "        [9.9581, 4.3656, 5.9920],\n",
      "        [9.8075, 4.1701, 6.0440]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3774, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.5987,  9.1258, -2.7069],\n",
      "        [-7.6630,  9.1156, -2.5657],\n",
      "        [-7.3797,  8.8922, -2.5477],\n",
      "        [-7.6126,  9.0420, -2.2868],\n",
      "        [-7.2934,  8.8229, -2.4692],\n",
      "        [-7.4481,  8.9039, -2.4873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.6895,  4.3889,  5.7482, -7.5987,  9.1258, -2.7069],\n",
      "        [ 9.9222,  3.9745,  5.7635, -7.6630,  9.1156, -2.5657],\n",
      "        [ 9.8089,  4.2846,  5.9754, -7.3797,  8.8922, -2.5477],\n",
      "        [ 9.6803,  4.6464,  5.9226, -7.6126,  9.0420, -2.2868],\n",
      "        [ 9.9581,  4.3656,  5.9920, -7.2934,  8.8229, -2.4692],\n",
      "        [ 9.8075,  4.1701,  6.0440, -7.4481,  8.9039, -2.4873]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7288367748260498\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9060, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.7132,  4.1137,  6.2194],\n",
      "        [10.0534,  4.4040,  5.9400],\n",
      "        [ 9.8184,  4.5399,  6.0627],\n",
      "        [ 9.8431,  4.3753,  5.9885],\n",
      "        [ 9.6567,  4.2546,  5.8555],\n",
      "        [ 9.6435,  4.2983,  5.7322]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3965, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.5135,  8.8497, -2.5084],\n",
      "        [-7.4474,  8.8522, -2.9865],\n",
      "        [-7.3683,  9.1181, -2.7954],\n",
      "        [-7.4028,  9.0720, -2.7416],\n",
      "        [-7.3392,  9.0900, -2.6064],\n",
      "        [-7.4060,  8.9197, -2.7849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.7132,  4.1137,  6.2194, -7.5135,  8.8497, -2.5084],\n",
      "        [10.0534,  4.4040,  5.9400, -7.4474,  8.8522, -2.9865],\n",
      "        [ 9.8184,  4.5399,  6.0627, -7.3683,  9.1181, -2.7954],\n",
      "        [ 9.8431,  4.3753,  5.9885, -7.4028,  9.0720, -2.7416],\n",
      "        [ 9.6567,  4.2546,  5.8555, -7.3392,  9.0900, -2.6064],\n",
      "        [ 9.6435,  4.2983,  5.7322, -7.4060,  8.9197, -2.7849]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.732046902179718\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.8545,  4.0980,  5.9736],\n",
      "        [ 9.9294,  4.4225,  6.1864],\n",
      "        [ 9.6896,  4.2592,  5.9905],\n",
      "        [10.1362,  4.5008,  5.9002],\n",
      "        [ 9.7477,  4.1724,  5.9605],\n",
      "        [ 9.6827,  4.3928,  5.7279]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7552,  9.0371, -2.6520],\n",
      "        [-7.6361,  9.0524, -2.5972],\n",
      "        [-7.4233,  9.0329, -2.8759],\n",
      "        [-7.5980,  9.0360, -2.6804],\n",
      "        [-7.1948,  9.1123, -3.0444],\n",
      "        [-7.5655,  8.9307, -3.0452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.8545,  4.0980,  5.9736, -7.7552,  9.0371, -2.6520],\n",
      "        [ 9.9294,  4.4225,  6.1864, -7.6361,  9.0524, -2.5972],\n",
      "        [ 9.6896,  4.2592,  5.9905, -7.4233,  9.0329, -2.8759],\n",
      "        [10.1362,  4.5008,  5.9002, -7.5980,  9.0360, -2.6804],\n",
      "        [ 9.7477,  4.1724,  5.9605, -7.1948,  9.1123, -3.0444],\n",
      "        [ 9.6827,  4.3928,  5.7279, -7.5655,  8.9307, -3.0452]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7375080585479736\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8601, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.8342,  4.3437,  5.7874],\n",
      "        [ 9.9943,  4.1340,  5.7810],\n",
      "        [ 9.8156,  4.3191,  6.1169],\n",
      "        [ 9.5099,  4.4952,  6.0143],\n",
      "        [10.0490,  4.5613,  6.2310],\n",
      "        [10.0134,  4.1162,  5.7536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.5662, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.9253,  9.0605, -2.5026],\n",
      "        [-7.6945,  9.0943, -2.7939],\n",
      "        [-7.7550,  9.3721, -2.6912],\n",
      "        [-7.4980,  9.0024, -2.7553],\n",
      "        [-7.5206,  9.3125, -2.6533],\n",
      "        [-7.7640,  9.1895, -2.5566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.8342,  4.3437,  5.7874, -7.9253,  9.0605, -2.5026],\n",
      "        [ 9.9943,  4.1340,  5.7810, -7.6945,  9.0943, -2.7939],\n",
      "        [ 9.8156,  4.3191,  6.1169, -7.7550,  9.3721, -2.6912],\n",
      "        [ 9.5099,  4.4952,  6.0143, -7.4980,  9.0024, -2.7553],\n",
      "        [10.0490,  4.5613,  6.2310, -7.5206,  9.3125, -2.6533],\n",
      "        [10.0134,  4.1162,  5.7536, -7.7640,  9.1895, -2.5566]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7377579212188721\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.5225,  4.5218,  5.6135],\n",
      "        [10.1110,  4.3145,  6.2470],\n",
      "        [ 9.8681,  4.2073,  6.0568],\n",
      "        [10.0483,  4.3698,  5.9798],\n",
      "        [ 9.9610,  4.2784,  6.1287],\n",
      "        [10.0887,  4.2009,  6.2216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.1142, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.8839,  9.2463, -2.9242],\n",
      "        [-7.8370,  9.0100, -2.5972],\n",
      "        [-7.4233,  9.3583, -2.7888],\n",
      "        [-7.7761,  9.2383, -2.8909],\n",
      "        [-7.7205,  9.1916, -2.6975],\n",
      "        [-7.8810,  9.2199, -2.8874]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.5225,  4.5218,  5.6135, -7.8839,  9.2463, -2.9242],\n",
      "        [10.1110,  4.3145,  6.2470, -7.8370,  9.0100, -2.5972],\n",
      "        [ 9.8681,  4.2073,  6.0568, -7.4233,  9.3583, -2.7888],\n",
      "        [10.0483,  4.3698,  5.9798, -7.7761,  9.2383, -2.8909],\n",
      "        [ 9.9610,  4.2784,  6.1287, -7.7205,  9.1916, -2.6975],\n",
      "        [10.0887,  4.2009,  6.2216, -7.8810,  9.2199, -2.8874]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7298244833946228\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6928, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.7489,  4.1922,  6.0730],\n",
      "        [ 9.9826,  4.4393,  6.2523],\n",
      "        [ 9.7276,  4.3634,  6.5781],\n",
      "        [ 9.8993,  4.3979,  6.0394],\n",
      "        [ 9.8800,  4.2700,  6.3224],\n",
      "        [10.1529,  4.3483,  6.1766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.9822,  9.5484, -2.8035],\n",
      "        [-7.4642,  8.8558, -2.8392],\n",
      "        [-7.5859,  9.0529, -2.7863],\n",
      "        [-7.6923,  9.2696, -2.6889],\n",
      "        [-7.6569,  8.6072, -2.6579],\n",
      "        [-7.4528,  9.2310, -2.6102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.7489,  4.1922,  6.0730, -7.9822,  9.5484, -2.8035],\n",
      "        [ 9.9826,  4.4393,  6.2523, -7.4642,  8.8558, -2.8392],\n",
      "        [ 9.7276,  4.3634,  6.5781, -7.5859,  9.0529, -2.7863],\n",
      "        [ 9.8993,  4.3979,  6.0394, -7.6923,  9.2696, -2.6889],\n",
      "        [ 9.8800,  4.2700,  6.3224, -7.6569,  8.6072, -2.6579],\n",
      "        [10.1529,  4.3483,  6.1766, -7.4528,  9.2310, -2.6102]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7496932744979858\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7626, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9819,  4.5808,  6.2437],\n",
      "        [ 9.5956,  4.3391,  5.9887],\n",
      "        [ 9.9164,  4.3264,  6.3222],\n",
      "        [10.0157,  4.5733,  5.9122],\n",
      "        [10.1045,  4.3914,  5.9053],\n",
      "        [ 9.9404,  4.2169,  5.7686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.6345, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.6206,  9.2320, -2.6779],\n",
      "        [-7.7382,  9.3200, -2.7546],\n",
      "        [-7.6056,  9.1518, -2.3968],\n",
      "        [-7.8534,  9.3152, -2.5778],\n",
      "        [-7.8386,  9.1483, -2.8099],\n",
      "        [-7.9330,  8.9683, -2.8342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9819,  4.5808,  6.2437, -7.6206,  9.2320, -2.6779],\n",
      "        [ 9.5956,  4.3391,  5.9887, -7.7382,  9.3200, -2.7546],\n",
      "        [ 9.9164,  4.3264,  6.3222, -7.6056,  9.1518, -2.3968],\n",
      "        [10.0157,  4.5733,  5.9122, -7.8534,  9.3152, -2.5778],\n",
      "        [10.1045,  4.3914,  5.9053, -7.8386,  9.1483, -2.8099],\n",
      "        [ 9.9404,  4.2169,  5.7686, -7.9330,  8.9683, -2.8342]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7566719055175781\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0680,  4.4264,  5.7685],\n",
      "        [ 9.9573,  4.6998,  6.1816],\n",
      "        [ 9.7109,  4.6514,  6.0466],\n",
      "        [10.3058,  4.6667,  5.9926],\n",
      "        [10.0334,  4.1641,  6.0578],\n",
      "        [ 9.8593,  4.2631,  6.1601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2768, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.8781,  9.3803, -2.6125],\n",
      "        [-7.8224,  9.1023, -2.6508],\n",
      "        [-7.5555,  9.1499, -2.4658],\n",
      "        [-7.8371,  9.2629, -2.9189],\n",
      "        [-7.7782,  9.2583, -2.8473],\n",
      "        [-7.8314,  8.9880, -2.2791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0680,  4.4264,  5.7685, -7.8781,  9.3803, -2.6125],\n",
      "        [ 9.9573,  4.6998,  6.1816, -7.8224,  9.1023, -2.6508],\n",
      "        [ 9.7109,  4.6514,  6.0466, -7.5555,  9.1499, -2.4658],\n",
      "        [10.3058,  4.6667,  5.9926, -7.8371,  9.2629, -2.9189],\n",
      "        [10.0334,  4.1641,  6.0578, -7.7782,  9.2583, -2.8473],\n",
      "        [ 9.8593,  4.2631,  6.1601, -7.8314,  8.9880, -2.2791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7524550557136536\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9102,  4.5389,  6.2697],\n",
      "        [10.2809,  4.1005,  6.1326],\n",
      "        [10.0189,  4.3903,  6.2046],\n",
      "        [ 9.8855,  4.5859,  5.9101],\n",
      "        [ 9.6876,  4.5025,  6.2446],\n",
      "        [ 9.7995,  4.3871,  6.1427]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7201, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0667,  9.2250, -2.8742],\n",
      "        [-7.8604,  9.1534, -2.7118],\n",
      "        [-7.8060,  9.2340, -2.6856],\n",
      "        [-7.4462,  9.2885, -2.5363],\n",
      "        [-7.6643,  9.1136, -3.0103],\n",
      "        [-7.6679,  9.1509, -2.5395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9102,  4.5389,  6.2697, -8.0667,  9.2250, -2.8742],\n",
      "        [10.2809,  4.1005,  6.1326, -7.8604,  9.1534, -2.7118],\n",
      "        [10.0189,  4.3903,  6.2046, -7.8060,  9.2340, -2.6856],\n",
      "        [ 9.8855,  4.5859,  5.9101, -7.4462,  9.2885, -2.5363],\n",
      "        [ 9.6876,  4.5025,  6.2446, -7.6643,  9.1136, -3.0103],\n",
      "        [ 9.7995,  4.3871,  6.1427, -7.6679,  9.1509, -2.5395]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.7614975571632385\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9371,  4.2866,  6.3485],\n",
      "        [ 9.8589,  4.5410,  5.9919],\n",
      "        [ 9.8516,  4.5903,  5.9308],\n",
      "        [10.1264,  4.6243,  6.0905],\n",
      "        [ 9.9573,  4.5733,  6.3119],\n",
      "        [10.1102,  4.8722,  6.0990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.8137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.9647,  9.2978, -2.6510],\n",
      "        [-7.6067,  9.1619, -2.9675],\n",
      "        [-7.5849,  9.2009, -3.0305],\n",
      "        [-7.7905,  8.8821, -2.9437],\n",
      "        [-7.9154,  9.3316, -2.6929],\n",
      "        [-7.6437,  9.2618, -2.7500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9371,  4.2866,  6.3485, -7.9647,  9.2978, -2.6510],\n",
      "        [ 9.8589,  4.5410,  5.9919, -7.6067,  9.1619, -2.9675],\n",
      "        [ 9.8516,  4.5903,  5.9308, -7.5849,  9.2009, -3.0305],\n",
      "        [10.1264,  4.6243,  6.0905, -7.7905,  8.8821, -2.9437],\n",
      "        [ 9.9573,  4.5733,  6.3119, -7.9154,  9.3316, -2.6929],\n",
      "        [10.1102,  4.8722,  6.0990, -7.6437,  9.2618, -2.7500]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7609041333198547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5945, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1069,  4.6481,  5.9322],\n",
      "        [ 9.9798,  4.2921,  6.2146],\n",
      "        [10.1631,  4.5928,  6.4173],\n",
      "        [10.0173,  4.6017,  6.0056],\n",
      "        [ 9.9841,  4.3375,  6.0395],\n",
      "        [ 9.8154,  4.5416,  6.4010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7419,  9.2847, -2.7246],\n",
      "        [-7.5762,  9.0671, -2.5162],\n",
      "        [-7.5450,  9.1916, -3.0322],\n",
      "        [-7.9076,  9.2285, -2.8111],\n",
      "        [-8.1118,  9.1756, -3.1249],\n",
      "        [-7.6828,  9.2110, -2.5684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1069,  4.6481,  5.9322, -7.7419,  9.2847, -2.7246],\n",
      "        [ 9.9798,  4.2921,  6.2146, -7.5762,  9.0671, -2.5162],\n",
      "        [10.1631,  4.5928,  6.4173, -7.5450,  9.1916, -3.0322],\n",
      "        [10.0173,  4.6017,  6.0056, -7.9076,  9.2285, -2.8111],\n",
      "        [ 9.9841,  4.3375,  6.0395, -8.1118,  9.1756, -3.1249],\n",
      "        [ 9.8154,  4.5416,  6.4010, -7.6828,  9.2110, -2.5684]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7589081525802612\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6887, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1181,  4.1658,  6.0132],\n",
      "        [10.1796,  4.3478,  6.1793],\n",
      "        [10.4104,  4.6686,  5.9479],\n",
      "        [10.2627,  4.3408,  6.2472],\n",
      "        [ 9.8733,  4.3590,  6.1073],\n",
      "        [ 9.8201,  4.6212,  6.1235]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.3721, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0027,  9.2324, -2.8665],\n",
      "        [-7.5845,  9.2092, -2.9725],\n",
      "        [-7.9158,  9.1454, -2.5652],\n",
      "        [-7.8542,  9.2406, -2.9447],\n",
      "        [-7.7876,  9.0710, -2.9529],\n",
      "        [-7.5102,  9.3314, -3.0351]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1181,  4.1658,  6.0132, -8.0027,  9.2324, -2.8665],\n",
      "        [10.1796,  4.3478,  6.1793, -7.5845,  9.2092, -2.9725],\n",
      "        [10.4104,  4.6686,  5.9479, -7.9158,  9.1454, -2.5652],\n",
      "        [10.2627,  4.3408,  6.2472, -7.8542,  9.2406, -2.9447],\n",
      "        [ 9.8733,  4.3590,  6.1073, -7.7876,  9.0710, -2.9529],\n",
      "        [ 9.8201,  4.6212,  6.1235, -7.5102,  9.3314, -3.0351]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7590808272361755\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4309, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0752,  4.7293,  6.2608],\n",
      "        [ 9.7905,  4.8666,  5.9225],\n",
      "        [10.0837,  4.6329,  6.4882],\n",
      "        [ 9.7970,  4.5526,  6.3618],\n",
      "        [ 9.9811,  4.4470,  5.8436],\n",
      "        [10.0709,  4.4765,  6.1509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.0923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7701,  9.1666, -2.9629],\n",
      "        [-7.9626,  9.4761, -2.8691],\n",
      "        [-7.5691,  9.2395, -2.8583],\n",
      "        [-8.0483,  9.3217, -2.9907],\n",
      "        [-7.7972,  9.1520, -2.8321],\n",
      "        [-7.7904,  9.2606, -3.1439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0752,  4.7293,  6.2608, -7.7701,  9.1666, -2.9629],\n",
      "        [ 9.7905,  4.8666,  5.9225, -7.9626,  9.4761, -2.8691],\n",
      "        [10.0837,  4.6329,  6.4882, -7.5691,  9.2395, -2.8583],\n",
      "        [ 9.7970,  4.5526,  6.3618, -8.0483,  9.3217, -2.9907],\n",
      "        [ 9.9811,  4.4470,  5.8436, -7.7972,  9.1520, -2.8321],\n",
      "        [10.0709,  4.4765,  6.1509, -7.7904,  9.2606, -3.1439]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7668485641479492\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0296,  4.2019,  6.1408],\n",
      "        [10.2894,  4.4244,  6.5302],\n",
      "        [10.4442,  4.4376,  6.3909],\n",
      "        [10.1045,  4.6884,  6.2307],\n",
      "        [10.0812,  4.4310,  6.3341],\n",
      "        [10.1090,  4.4619,  6.3128]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.5622, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.5845,  8.9581, -2.8972],\n",
      "        [-7.4147,  9.1113, -3.0723],\n",
      "        [-7.8998,  9.0974, -2.9044],\n",
      "        [-7.5023,  9.1437, -3.1077],\n",
      "        [-7.5971,  9.2410, -2.9436],\n",
      "        [-7.5419,  9.1096, -2.7548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0296,  4.2019,  6.1408, -7.5845,  8.9581, -2.8972],\n",
      "        [10.2894,  4.4244,  6.5302, -7.4147,  9.1113, -3.0723],\n",
      "        [10.4442,  4.4376,  6.3909, -7.8998,  9.0974, -2.9044],\n",
      "        [10.1045,  4.6884,  6.2307, -7.5023,  9.1437, -3.1077],\n",
      "        [10.0812,  4.4310,  6.3341, -7.5971,  9.2410, -2.9436],\n",
      "        [10.1090,  4.4619,  6.3128, -7.5419,  9.1096, -2.7548]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7515658736228943\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9696, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9377,  4.5722,  5.9951],\n",
      "        [10.3370,  4.6491,  6.1463],\n",
      "        [10.3639,  4.6965,  6.1292],\n",
      "        [ 9.9421,  4.2550,  5.8870],\n",
      "        [10.2259,  4.3100,  6.3149],\n",
      "        [ 9.9821,  4.4286,  6.2497]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.5701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.6597,  9.0035, -2.8557],\n",
      "        [-7.9798,  9.3466, -2.7054],\n",
      "        [-7.5284,  9.3902, -3.0505],\n",
      "        [-7.8790,  9.5623, -3.2276],\n",
      "        [-7.9030,  9.4000, -2.9413],\n",
      "        [-8.0515,  9.2009, -3.0449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9377,  4.5722,  5.9951, -7.6597,  9.0035, -2.8557],\n",
      "        [10.3370,  4.6491,  6.1463, -7.9798,  9.3466, -2.7054],\n",
      "        [10.3639,  4.6965,  6.1292, -7.5284,  9.3902, -3.0505],\n",
      "        [ 9.9421,  4.2550,  5.8870, -7.8790,  9.5623, -3.2276],\n",
      "        [10.2259,  4.3100,  6.3149, -7.9030,  9.4000, -2.9413],\n",
      "        [ 9.9821,  4.4286,  6.2497, -8.0515,  9.2009, -3.0449]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7513967752456665\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0071,  4.6600,  6.1581],\n",
      "        [10.0053,  4.5736,  6.2140],\n",
      "        [10.2117,  4.5086,  6.2267],\n",
      "        [10.3462,  4.7926,  6.1161],\n",
      "        [10.3314,  4.4855,  6.1971],\n",
      "        [10.2096,  4.5546,  6.4357]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.8915,  9.6739, -3.1107],\n",
      "        [-7.9108,  9.1805, -3.2240],\n",
      "        [-7.9056,  9.0902, -3.0177],\n",
      "        [-7.8936,  9.2877, -2.6714],\n",
      "        [-7.3549,  9.0760, -2.9416],\n",
      "        [-8.0294,  9.1231, -3.0440]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0071,  4.6600,  6.1581, -7.8915,  9.6739, -3.1107],\n",
      "        [10.0053,  4.5736,  6.2140, -7.9108,  9.1805, -3.2240],\n",
      "        [10.2117,  4.5086,  6.2267, -7.9056,  9.0902, -3.0177],\n",
      "        [10.3462,  4.7926,  6.1161, -7.8936,  9.2877, -2.6714],\n",
      "        [10.3314,  4.4855,  6.1971, -7.3549,  9.0760, -2.9416],\n",
      "        [10.2096,  4.5546,  6.4357, -8.0294,  9.1231, -3.0440]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.7725898027420044\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1537,  4.9059,  6.2239],\n",
      "        [ 9.9719,  4.3718,  6.1374],\n",
      "        [10.2053,  4.5566,  5.9869],\n",
      "        [10.2180,  4.3909,  6.2026],\n",
      "        [10.4198,  4.4720,  6.5079],\n",
      "        [ 9.8701,  4.3915,  6.2913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7671, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7181,  9.4234, -2.9288],\n",
      "        [-7.7518,  9.4364, -3.0562],\n",
      "        [-7.8438,  9.3697, -3.0834],\n",
      "        [-7.7529,  9.2596, -2.8137],\n",
      "        [-7.8402,  9.1784, -2.8476],\n",
      "        [-7.5751,  9.3606, -2.8961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1537,  4.9059,  6.2239, -7.7181,  9.4234, -2.9288],\n",
      "        [ 9.9719,  4.3718,  6.1374, -7.7518,  9.4364, -3.0562],\n",
      "        [10.2053,  4.5566,  5.9869, -7.8438,  9.3697, -3.0834],\n",
      "        [10.2180,  4.3909,  6.2026, -7.7529,  9.2596, -2.8137],\n",
      "        [10.4198,  4.4720,  6.5079, -7.8402,  9.1784, -2.8476],\n",
      "        [ 9.8701,  4.3915,  6.2913, -7.5751,  9.3606, -2.8961]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7757807970046997\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1718,  4.5253,  6.3470],\n",
      "        [10.0508,  4.7905,  6.3532],\n",
      "        [ 9.7620,  4.6408,  6.3354],\n",
      "        [10.2370,  4.8232,  6.0379],\n",
      "        [10.1020,  4.7196,  6.1197],\n",
      "        [10.0722,  4.8395,  6.2016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.6003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.8702,  9.2999, -2.9969],\n",
      "        [-7.6675,  9.0856, -2.9764],\n",
      "        [-7.6756,  9.2595, -3.1021],\n",
      "        [-8.0066,  9.1536, -2.8812],\n",
      "        [-8.0029,  9.5288, -3.1186],\n",
      "        [-7.6943,  9.1546, -2.6238]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1718,  4.5253,  6.3470, -7.8702,  9.2999, -2.9969],\n",
      "        [10.0508,  4.7905,  6.3532, -7.6675,  9.0856, -2.9764],\n",
      "        [ 9.7620,  4.6408,  6.3354, -7.6756,  9.2595, -3.1021],\n",
      "        [10.2370,  4.8232,  6.0379, -8.0066,  9.1536, -2.8812],\n",
      "        [10.1020,  4.7196,  6.1197, -8.0029,  9.5288, -3.1186],\n",
      "        [10.0722,  4.8395,  6.2016, -7.6943,  9.1546, -2.6238]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.775668203830719\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0956,  4.5153,  6.0585],\n",
      "        [10.2114,  4.5664,  6.3837],\n",
      "        [10.1565,  4.5345,  6.3346],\n",
      "        [10.0977,  4.4896,  6.6491],\n",
      "        [10.1258,  4.6115,  6.3727],\n",
      "        [10.0727,  4.4995,  6.2201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.5637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.8124,  9.3020, -3.0506],\n",
      "        [-8.0658,  9.6156, -2.9918],\n",
      "        [-7.8348,  9.2344, -3.1179],\n",
      "        [-7.7444,  9.5784, -2.9811],\n",
      "        [-7.6316,  9.4083, -3.0591],\n",
      "        [-8.0323,  9.1662, -3.1350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0956,  4.5153,  6.0585, -7.8124,  9.3020, -3.0506],\n",
      "        [10.2114,  4.5664,  6.3837, -8.0658,  9.6156, -2.9918],\n",
      "        [10.1565,  4.5345,  6.3346, -7.8348,  9.2344, -3.1179],\n",
      "        [10.0977,  4.4896,  6.6491, -7.7444,  9.5784, -2.9811],\n",
      "        [10.1258,  4.6115,  6.3727, -7.6316,  9.4083, -3.0591],\n",
      "        [10.0727,  4.4995,  6.2201, -8.0323,  9.1662, -3.1350]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7664791345596313\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0824,  4.6958,  6.3245],\n",
      "        [ 9.9318,  4.6921,  6.1825],\n",
      "        [10.0578,  4.5370,  6.0649],\n",
      "        [10.1191,  4.6078,  6.5349],\n",
      "        [10.2349,  4.5259,  6.2544],\n",
      "        [10.1999,  4.7836,  6.4832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.1943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1330,  9.4664, -3.1803],\n",
      "        [-7.8265,  9.1765, -2.7247],\n",
      "        [-7.9333,  9.1095, -2.9954],\n",
      "        [-8.0419,  9.5831, -3.0307],\n",
      "        [-7.8499,  9.2861, -2.8459],\n",
      "        [-7.4461,  9.3133, -3.3262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0824,  4.6958,  6.3245, -8.1330,  9.4664, -3.1803],\n",
      "        [ 9.9318,  4.6921,  6.1825, -7.8265,  9.1765, -2.7247],\n",
      "        [10.0578,  4.5370,  6.0649, -7.9333,  9.1095, -2.9954],\n",
      "        [10.1191,  4.6078,  6.5349, -8.0419,  9.5831, -3.0307],\n",
      "        [10.2349,  4.5259,  6.2544, -7.8499,  9.2861, -2.8459],\n",
      "        [10.1999,  4.7836,  6.4832, -7.4461,  9.3133, -3.3262]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7816236019134521\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2645, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0997,  4.4563,  6.4699],\n",
      "        [10.2528,  4.7893,  6.0655],\n",
      "        [10.1641,  4.5658,  6.1750],\n",
      "        [10.0072,  4.6767,  5.8110],\n",
      "        [10.3496,  4.4505,  6.4809],\n",
      "        [10.0734,  4.8014,  6.1561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7772, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.9139,  9.4459, -2.9248],\n",
      "        [-7.7758,  9.3690, -3.0347],\n",
      "        [-7.9472,  9.3663, -2.9557],\n",
      "        [-7.9439,  9.3455, -3.1337],\n",
      "        [-7.9026,  9.3330, -2.6843],\n",
      "        [-7.9224,  9.4153, -3.0384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0997,  4.4563,  6.4699, -7.9139,  9.4459, -2.9248],\n",
      "        [10.2528,  4.7893,  6.0655, -7.7758,  9.3690, -3.0347],\n",
      "        [10.1641,  4.5658,  6.1750, -7.9472,  9.3663, -2.9557],\n",
      "        [10.0072,  4.6767,  5.8110, -7.9439,  9.3455, -3.1337],\n",
      "        [10.3496,  4.4505,  6.4809, -7.9026,  9.3330, -2.6843],\n",
      "        [10.0734,  4.8014,  6.1561, -7.9224,  9.4153, -3.0384]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7794027924537659\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.4389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1956,  4.4687,  6.0088],\n",
      "        [10.1703,  4.8567,  6.1648],\n",
      "        [10.1954,  4.9279,  6.2819],\n",
      "        [10.1025,  4.6041,  6.4198],\n",
      "        [10.2874,  5.0416,  5.8821],\n",
      "        [10.4175,  4.6298,  6.3655]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.8888, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.6118,  9.1481, -2.9744],\n",
      "        [-8.1086,  9.4851, -2.9262],\n",
      "        [-8.1486,  9.3401, -2.7914],\n",
      "        [-8.1842,  9.1203, -3.1740],\n",
      "        [-8.0213,  9.2544, -2.9441],\n",
      "        [-8.2126,  9.6504, -3.1471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1956,  4.4687,  6.0088, -7.6118,  9.1481, -2.9744],\n",
      "        [10.1703,  4.8567,  6.1648, -8.1086,  9.4851, -2.9262],\n",
      "        [10.1954,  4.9279,  6.2819, -8.1486,  9.3401, -2.7914],\n",
      "        [10.1025,  4.6041,  6.4198, -8.1842,  9.1203, -3.1740],\n",
      "        [10.2874,  5.0416,  5.8821, -8.0213,  9.2544, -2.9441],\n",
      "        [10.4175,  4.6298,  6.3655, -8.2126,  9.6504, -3.1471]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7646565437316895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6756, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1157,  4.4006,  6.3755],\n",
      "        [10.1568,  4.8077,  6.3379],\n",
      "        [10.2406,  4.4990,  6.3456],\n",
      "        [10.4132,  4.3632,  6.5808],\n",
      "        [10.1091,  5.0253,  6.2407],\n",
      "        [10.0871,  4.2769,  6.5581]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.0164, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0302,  9.7054, -3.2812],\n",
      "        [-8.1279,  9.7907, -3.1423],\n",
      "        [-8.1141,  9.4726, -2.9586],\n",
      "        [-7.9229,  9.6534, -2.9599],\n",
      "        [-7.9238,  9.1989, -3.1131],\n",
      "        [-7.9850,  9.4562, -3.2748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1157,  4.4006,  6.3755, -8.0302,  9.7054, -3.2812],\n",
      "        [10.1568,  4.8077,  6.3379, -8.1279,  9.7907, -3.1423],\n",
      "        [10.2406,  4.4990,  6.3456, -8.1141,  9.4726, -2.9586],\n",
      "        [10.4132,  4.3632,  6.5808, -7.9229,  9.6534, -2.9599],\n",
      "        [10.1091,  5.0253,  6.2407, -7.9238,  9.1989, -3.1131],\n",
      "        [10.0871,  4.2769,  6.5581, -7.9850,  9.4562, -3.2748]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.7848023176193237\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5257, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 9.9425,  4.6657,  6.3307],\n",
      "        [10.1727,  4.6496,  6.1366],\n",
      "        [10.4117,  4.5610,  6.2597],\n",
      "        [10.0844,  4.7668,  6.4278],\n",
      "        [10.3730,  4.8320,  6.5488],\n",
      "        [10.1786,  4.5742,  6.2642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.0523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1916,  9.3434, -3.2110],\n",
      "        [-7.9237,  9.4006, -3.0279],\n",
      "        [-7.7132,  9.6453, -2.9175],\n",
      "        [-7.8679,  9.4235, -3.0249],\n",
      "        [-7.9975,  9.6112, -2.9272],\n",
      "        [-8.1852,  9.4360, -3.0339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 9.9425,  4.6657,  6.3307, -8.1916,  9.3434, -3.2110],\n",
      "        [10.1727,  4.6496,  6.1366, -7.9237,  9.4006, -3.0279],\n",
      "        [10.4117,  4.5610,  6.2597, -7.7132,  9.6453, -2.9175],\n",
      "        [10.0844,  4.7668,  6.4278, -7.8679,  9.4235, -3.0249],\n",
      "        [10.3730,  4.8320,  6.5488, -7.9975,  9.6112, -2.9272],\n",
      "        [10.1786,  4.5742,  6.2642, -8.1852,  9.4360, -3.0339]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7780342102050781\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5792, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.2188,  4.8402,  6.1580],\n",
      "        [10.0996,  4.5793,  6.5004],\n",
      "        [10.2806,  4.7290,  6.1676],\n",
      "        [10.2092,  4.5749,  6.4159],\n",
      "        [10.5660,  4.6928,  6.6073],\n",
      "        [10.3441,  4.4990,  6.2025]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5709, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1520,  9.3930, -2.8930],\n",
      "        [-8.1326,  9.8245, -3.1613],\n",
      "        [-8.1937,  9.4288, -3.1978],\n",
      "        [-8.0084,  9.4808, -3.2337],\n",
      "        [-8.0491,  9.3597, -2.8628],\n",
      "        [-7.9594,  9.4006, -2.9949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.2188,  4.8402,  6.1580, -8.1520,  9.3930, -2.8930],\n",
      "        [10.0996,  4.5793,  6.5004, -8.1326,  9.8245, -3.1613],\n",
      "        [10.2806,  4.7290,  6.1676, -8.1937,  9.4288, -3.1978],\n",
      "        [10.2092,  4.5749,  6.4159, -8.0084,  9.4808, -3.2337],\n",
      "        [10.5660,  4.6928,  6.6073, -8.0491,  9.3597, -2.8628],\n",
      "        [10.3441,  4.4990,  6.2025, -7.9594,  9.4006, -2.9949]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7847378849983215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6541, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.0921,  4.5451,  6.3006],\n",
      "        [10.3233,  4.3207,  6.2131],\n",
      "        [10.4429,  4.8732,  6.5264],\n",
      "        [10.2895,  4.6047,  6.2805],\n",
      "        [10.1849,  4.7315,  6.1453],\n",
      "        [10.2442,  4.6279,  6.0785]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.9600, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7255,  9.3725, -3.1530],\n",
      "        [-7.8646,  9.6804, -3.1822],\n",
      "        [-8.0922,  9.5752, -3.2583],\n",
      "        [-7.8025,  9.4131, -2.9004],\n",
      "        [-8.2766,  9.3922, -3.0927],\n",
      "        [-8.0971,  9.1553, -2.8494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.0921,  4.5451,  6.3006, -7.7255,  9.3725, -3.1530],\n",
      "        [10.3233,  4.3207,  6.2131, -7.8646,  9.6804, -3.1822],\n",
      "        [10.4429,  4.8732,  6.5264, -8.0922,  9.5752, -3.2583],\n",
      "        [10.2895,  4.6047,  6.2805, -7.8025,  9.4131, -2.9004],\n",
      "        [10.1849,  4.7315,  6.1453, -8.2766,  9.3922, -3.0927],\n",
      "        [10.2442,  4.6279,  6.0785, -8.0971,  9.1553, -2.8494]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7764233946800232\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7246, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.3371,  4.6162,  6.1566],\n",
      "        [ 9.7255,  4.4214,  5.8412],\n",
      "        [10.0456,  4.7283,  6.5011],\n",
      "        [10.3461,  4.5672,  6.3939],\n",
      "        [10.4031,  4.7460,  6.1914],\n",
      "        [10.3448,  4.3633,  6.2560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.0416, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0745,  9.1497, -3.1059],\n",
      "        [-8.2887,  9.4686, -2.9819],\n",
      "        [-8.0590,  9.4739, -2.9108],\n",
      "        [-8.0810,  9.3923, -3.1205],\n",
      "        [-7.7143,  9.5006, -3.3593],\n",
      "        [-8.1001,  9.4949, -3.1591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.3371,  4.6162,  6.1566, -8.0745,  9.1497, -3.1059],\n",
      "        [ 9.7255,  4.4214,  5.8412, -8.2887,  9.4686, -2.9819],\n",
      "        [10.0456,  4.7283,  6.5011, -8.0590,  9.4739, -2.9108],\n",
      "        [10.3461,  4.5672,  6.3939, -8.0810,  9.3923, -3.1205],\n",
      "        [10.4031,  4.7460,  6.1914, -7.7143,  9.5006, -3.3593],\n",
      "        [10.3448,  4.3633,  6.2560, -8.1001,  9.4949, -3.1591]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7833134531974792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.4285,  4.8039,  6.4973],\n",
      "        [10.5356,  4.4937,  6.0895],\n",
      "        [10.2504,  4.7380,  6.3156],\n",
      "        [10.6373,  4.6239,  6.2777],\n",
      "        [10.3347,  4.9016,  6.4649],\n",
      "        [10.6650,  4.9994,  6.4246]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.6298, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.9102,  9.6196, -3.0414],\n",
      "        [-8.1895,  9.5748, -2.8965],\n",
      "        [-8.2426,  9.4507, -3.1376],\n",
      "        [-7.9547,  9.4854, -3.3098],\n",
      "        [-7.6829,  9.4326, -3.4141],\n",
      "        [-8.3479,  9.6834, -3.0931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.4285,  4.8039,  6.4973, -7.9102,  9.6196, -3.0414],\n",
      "        [10.5356,  4.4937,  6.0895, -8.1895,  9.5748, -2.8965],\n",
      "        [10.2504,  4.7380,  6.3156, -8.2426,  9.4507, -3.1376],\n",
      "        [10.6373,  4.6239,  6.2777, -7.9547,  9.4854, -3.3098],\n",
      "        [10.3347,  4.9016,  6.4649, -7.6829,  9.4326, -3.4141],\n",
      "        [10.6650,  4.9994,  6.4246, -8.3479,  9.6834, -3.0931]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8016587495803833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9792, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5678,  4.7637,  6.3815],\n",
      "        [10.1291,  4.7201,  6.4148],\n",
      "        [10.4941,  4.8810,  6.1312],\n",
      "        [10.0813,  4.9457,  6.4353],\n",
      "        [10.7502,  4.5685,  6.2343],\n",
      "        [10.0874,  4.7870,  6.7320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.8169, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.4993,  9.4823, -3.3357],\n",
      "        [-8.0783,  9.6906, -3.2887],\n",
      "        [-7.8797,  9.3738, -3.1747],\n",
      "        [-7.9271,  9.6433, -3.1415],\n",
      "        [-8.0242,  9.5379, -2.6797],\n",
      "        [-8.1632,  9.4995, -3.1601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5678,  4.7637,  6.3815, -7.4993,  9.4823, -3.3357],\n",
      "        [10.1291,  4.7201,  6.4148, -8.0783,  9.6906, -3.2887],\n",
      "        [10.4941,  4.8810,  6.1312, -7.8797,  9.3738, -3.1747],\n",
      "        [10.0813,  4.9457,  6.4353, -7.9271,  9.6433, -3.1415],\n",
      "        [10.7502,  4.5685,  6.2343, -8.0242,  9.5379, -2.6797],\n",
      "        [10.0874,  4.7870,  6.7320, -8.1632,  9.4995, -3.1601]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7976319789886475\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6907,  4.6531,  6.2344],\n",
      "        [10.6696,  4.7797,  6.6466],\n",
      "        [10.5042,  4.8792,  6.5396],\n",
      "        [10.0219,  4.7538,  6.2573],\n",
      "        [10.4381,  4.8799,  6.5497],\n",
      "        [10.7477,  4.8694,  6.3123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.8841, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2034,  9.6477, -3.0341],\n",
      "        [-7.7972,  9.4057, -2.9540],\n",
      "        [-7.8049,  9.2846, -2.9588],\n",
      "        [-8.2483,  9.6156, -3.1851],\n",
      "        [-8.2574,  9.4381, -3.0414],\n",
      "        [-8.1173,  9.3940, -3.1293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6907,  4.6531,  6.2344, -8.2034,  9.6477, -3.0341],\n",
      "        [10.6696,  4.7797,  6.6466, -7.7972,  9.4057, -2.9540],\n",
      "        [10.5042,  4.8792,  6.5396, -7.8049,  9.2846, -2.9588],\n",
      "        [10.0219,  4.7538,  6.2573, -8.2483,  9.6156, -3.1851],\n",
      "        [10.4381,  4.8799,  6.5497, -8.2574,  9.4381, -3.0414],\n",
      "        [10.7477,  4.8694,  6.3123, -8.1173,  9.3940, -3.1293]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8075751662254333\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6415, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5017,  4.9242,  6.3574],\n",
      "        [10.4452,  4.7404,  6.1804],\n",
      "        [10.7521,  4.6863,  6.5532],\n",
      "        [10.2913,  4.6851,  6.4061],\n",
      "        [10.6960,  4.8499,  6.6416],\n",
      "        [10.5082,  4.8443,  6.4115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3605,  9.5742, -3.2964],\n",
      "        [-7.8889,  9.7928, -3.3339],\n",
      "        [-8.0974,  9.1355, -3.2030],\n",
      "        [-7.8579,  9.7008, -3.2424],\n",
      "        [-8.2222,  9.3919, -3.1993],\n",
      "        [-8.0129,  9.5073, -3.1163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5017,  4.9242,  6.3574, -8.3605,  9.5742, -3.2964],\n",
      "        [10.4452,  4.7404,  6.1804, -7.8889,  9.7928, -3.3339],\n",
      "        [10.7521,  4.6863,  6.5532, -8.0974,  9.1355, -3.2030],\n",
      "        [10.2913,  4.6851,  6.4061, -7.8579,  9.7008, -3.2424],\n",
      "        [10.6960,  4.8499,  6.6416, -8.2222,  9.3919, -3.1993],\n",
      "        [10.5082,  4.8443,  6.4115, -8.0129,  9.5073, -3.1163]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8097702860832214\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.1816,  4.5043,  6.2297],\n",
      "        [10.5538,  4.7155,  6.4313],\n",
      "        [10.3942,  4.6116,  6.5822],\n",
      "        [10.4708,  4.5471,  6.3342],\n",
      "        [10.5100,  4.8150,  6.1516],\n",
      "        [10.4381,  4.6628,  6.3020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.8857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-7.7977,  9.8504, -3.3058],\n",
      "        [-8.0954,  9.2406, -3.2449],\n",
      "        [-8.2575,  9.4177, -3.4371],\n",
      "        [-8.1634,  9.4988, -3.0383],\n",
      "        [-8.0188,  9.6688, -3.0336],\n",
      "        [-8.0727,  9.7307, -3.2702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.1816,  4.5043,  6.2297, -7.7977,  9.8504, -3.3058],\n",
      "        [10.5538,  4.7155,  6.4313, -8.0954,  9.2406, -3.2449],\n",
      "        [10.3942,  4.6116,  6.5822, -8.2575,  9.4177, -3.4371],\n",
      "        [10.4708,  4.5471,  6.3342, -8.1634,  9.4988, -3.0383],\n",
      "        [10.5100,  4.8150,  6.1516, -8.0188,  9.6688, -3.0336],\n",
      "        [10.4381,  4.6628,  6.3020, -8.0727,  9.7307, -3.2702]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.7891354560852051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6240, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.4864,  4.9360,  6.4162],\n",
      "        [10.4333,  4.8732,  6.5696],\n",
      "        [10.7070,  4.4692,  5.8712],\n",
      "        [ 9.9973,  4.8150,  6.4814],\n",
      "        [10.3114,  4.8090,  6.6421],\n",
      "        [10.2918,  4.9466,  6.2014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.9506, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0377,  9.8414, -3.1575],\n",
      "        [-8.0189,  9.4589, -3.3813],\n",
      "        [-8.1790,  9.8635, -3.3813],\n",
      "        [-8.2176,  9.8592, -3.0255],\n",
      "        [-8.1495,  9.6748, -3.1210],\n",
      "        [-8.0801,  9.4581, -3.0161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.4864,  4.9360,  6.4162, -8.0377,  9.8414, -3.1575],\n",
      "        [10.4333,  4.8732,  6.5696, -8.0189,  9.4589, -3.3813],\n",
      "        [10.7070,  4.4692,  5.8712, -8.1790,  9.8635, -3.3813],\n",
      "        [ 9.9973,  4.8150,  6.4814, -8.2176,  9.8592, -3.0255],\n",
      "        [10.3114,  4.8090,  6.6421, -8.1495,  9.6748, -3.1210],\n",
      "        [10.2918,  4.9466,  6.2014, -8.0801,  9.4581, -3.0161]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8113569021224976\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9583, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6929,  4.9692,  6.4989],\n",
      "        [10.5804,  4.8209,  6.5440],\n",
      "        [10.6402,  4.6688,  6.5726],\n",
      "        [10.7094,  4.8370,  6.8959],\n",
      "        [10.2548,  4.7030,  6.5261],\n",
      "        [10.4980,  4.8506,  6.4419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.8513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1473,  9.3580, -3.1595],\n",
      "        [-7.8152,  9.5826, -2.9163],\n",
      "        [-7.9989,  9.7828, -3.2279],\n",
      "        [-8.0116,  9.6689, -3.1939],\n",
      "        [-8.2583,  9.5845, -3.1298],\n",
      "        [-8.0976,  9.4867, -3.1859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6929,  4.9692,  6.4989, -8.1473,  9.3580, -3.1595],\n",
      "        [10.5804,  4.8209,  6.5440, -7.8152,  9.5826, -2.9163],\n",
      "        [10.6402,  4.6688,  6.5726, -7.9989,  9.7828, -3.2279],\n",
      "        [10.7094,  4.8370,  6.8959, -8.0116,  9.6689, -3.1939],\n",
      "        [10.2548,  4.7030,  6.5261, -8.2583,  9.5845, -3.1298],\n",
      "        [10.4980,  4.8506,  6.4419, -8.0976,  9.4867, -3.1859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8151518106460571\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9541, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.9025,  4.7442,  6.5832],\n",
      "        [10.5412,  4.8136,  6.3301],\n",
      "        [10.6333,  4.7293,  6.3215],\n",
      "        [10.4904,  4.6780,  6.4747],\n",
      "        [10.8409,  4.6789,  6.7465],\n",
      "        [10.3809,  4.7659,  6.3480]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3223,  9.4643, -3.2076],\n",
      "        [-8.4669,  9.9078, -3.3884],\n",
      "        [-8.2650,  9.7870, -3.2628],\n",
      "        [-8.1168,  9.6783, -3.2858],\n",
      "        [-7.9785,  9.5821, -3.1429],\n",
      "        [-8.1079,  9.6197, -2.9794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.9025,  4.7442,  6.5832, -8.3223,  9.4643, -3.2076],\n",
      "        [10.5412,  4.8136,  6.3301, -8.4669,  9.9078, -3.3884],\n",
      "        [10.6333,  4.7293,  6.3215, -8.2650,  9.7870, -3.2628],\n",
      "        [10.4904,  4.6780,  6.4747, -8.1168,  9.6783, -3.2858],\n",
      "        [10.8409,  4.6789,  6.7465, -7.9785,  9.5821, -3.1429],\n",
      "        [10.3809,  4.7659,  6.3480, -8.1079,  9.6197, -2.9794]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.825915515422821\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4732, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6546,  4.9360,  6.3806],\n",
      "        [10.5365,  4.6538,  6.3070],\n",
      "        [10.3225,  4.9120,  6.5603],\n",
      "        [10.2369,  4.6281,  6.4231],\n",
      "        [10.5446,  4.7273,  6.5672],\n",
      "        [10.6789,  4.6882,  6.3586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9105, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3044,  9.4294, -3.1612],\n",
      "        [-7.8319,  9.5644, -3.4934],\n",
      "        [-8.1910,  9.7069, -3.3506],\n",
      "        [-8.3030,  9.4635, -3.1870],\n",
      "        [-8.5162,  9.5106, -3.0919],\n",
      "        [-8.4313,  9.9766, -3.2779]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6546,  4.9360,  6.3806, -8.3044,  9.4294, -3.1612],\n",
      "        [10.5365,  4.6538,  6.3070, -7.8319,  9.5644, -3.4934],\n",
      "        [10.3225,  4.9120,  6.5603, -8.1910,  9.7069, -3.3506],\n",
      "        [10.2369,  4.6281,  6.4231, -8.3030,  9.4635, -3.1870],\n",
      "        [10.5446,  4.7273,  6.5672, -8.5162,  9.5106, -3.0919],\n",
      "        [10.6789,  4.6882,  6.3586, -8.4313,  9.9766, -3.2779]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8149195313453674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9546, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5393,  4.8639,  6.4854],\n",
      "        [10.5082,  4.8311,  6.1910],\n",
      "        [10.7217,  5.1090,  6.5732],\n",
      "        [10.6449,  4.8237,  6.5097],\n",
      "        [10.3111,  4.8719,  6.3119],\n",
      "        [10.7309,  4.9892,  6.4909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3046, 10.1486, -3.1127],\n",
      "        [-8.3979,  9.9340, -3.3216],\n",
      "        [-7.8484,  9.6782, -3.3208],\n",
      "        [-8.2036,  9.9910, -3.1668],\n",
      "        [-8.1712,  9.7776, -3.2478],\n",
      "        [-8.4712,  9.7180, -3.5019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5393,  4.8639,  6.4854, -8.3046, 10.1486, -3.1127],\n",
      "        [10.5082,  4.8311,  6.1910, -8.3979,  9.9340, -3.3216],\n",
      "        [10.7217,  5.1090,  6.5732, -7.8484,  9.6782, -3.3208],\n",
      "        [10.6449,  4.8237,  6.5097, -8.2036,  9.9910, -3.1668],\n",
      "        [10.3111,  4.8719,  6.3119, -8.1712,  9.7776, -3.2478],\n",
      "        [10.7309,  4.9892,  6.4909, -8.4712,  9.7180, -3.5019]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8238974809646606\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7902,  4.8918,  6.3407],\n",
      "        [10.8018,  4.7878,  6.6030],\n",
      "        [10.1125,  4.6902,  6.8323],\n",
      "        [10.4958,  4.5758,  6.6159],\n",
      "        [10.7198,  5.1960,  6.4580],\n",
      "        [10.5698,  4.9224,  6.3240]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.9096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2398,  9.7275, -3.5074],\n",
      "        [-8.3284,  9.7011, -3.1214],\n",
      "        [-8.0010,  9.4964, -3.0819],\n",
      "        [-8.2437,  9.6644, -3.2557],\n",
      "        [-8.4235,  9.6611, -3.2637],\n",
      "        [-8.1643,  9.8783, -3.3762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7902,  4.8918,  6.3407, -8.2398,  9.7275, -3.5074],\n",
      "        [10.8018,  4.7878,  6.6030, -8.3284,  9.7011, -3.1214],\n",
      "        [10.1125,  4.6902,  6.8323, -8.0010,  9.4964, -3.0819],\n",
      "        [10.4958,  4.5758,  6.6159, -8.2437,  9.6644, -3.2557],\n",
      "        [10.7198,  5.1960,  6.4580, -8.4235,  9.6611, -3.2637],\n",
      "        [10.5698,  4.9224,  6.3240, -8.1643,  9.8783, -3.3762]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8241233825683594\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9433, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7538,  4.9977,  6.5210],\n",
      "        [10.6743,  4.8259,  6.4388],\n",
      "        [10.6725,  4.8402,  6.7094],\n",
      "        [10.4598,  4.6727,  6.5700],\n",
      "        [10.8832,  5.0379,  6.5112],\n",
      "        [10.5611,  4.8724,  6.8745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.0285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.0981,  9.6189, -3.3029],\n",
      "        [-8.1485,  9.6964, -3.0626],\n",
      "        [-8.4975,  9.5378, -3.2967],\n",
      "        [-8.2875,  9.8432, -3.3095],\n",
      "        [-7.8643,  9.4047, -2.8828],\n",
      "        [-8.2808,  9.6640, -3.1877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7538,  4.9977,  6.5210, -8.0981,  9.6189, -3.3029],\n",
      "        [10.6743,  4.8259,  6.4388, -8.1485,  9.6964, -3.0626],\n",
      "        [10.6725,  4.8402,  6.7094, -8.4975,  9.5378, -3.2967],\n",
      "        [10.4598,  4.6727,  6.5700, -8.2875,  9.8432, -3.3095],\n",
      "        [10.8832,  5.0379,  6.5112, -7.8643,  9.4047, -2.8828],\n",
      "        [10.5611,  4.8724,  6.8745, -8.2808,  9.6640, -3.1877]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8247206211090088\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6793, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.4296,  4.9696,  6.4097],\n",
      "        [10.7633,  4.9904,  6.5331],\n",
      "        [10.6393,  5.0298,  6.4385],\n",
      "        [10.8221,  5.0908,  6.8706],\n",
      "        [10.6102,  4.8926,  6.7402],\n",
      "        [10.6175,  4.7537,  6.5959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.9319, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1781,  9.4622, -3.4174],\n",
      "        [-8.2863,  9.6024, -3.2102],\n",
      "        [-8.1800,  9.8071, -3.1631],\n",
      "        [-8.1304,  9.6074, -3.4960],\n",
      "        [-8.0246,  9.4867, -3.3797],\n",
      "        [-8.1824,  9.7687, -3.2673]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.4296,  4.9696,  6.4097, -8.1781,  9.4622, -3.4174],\n",
      "        [10.7633,  4.9904,  6.5331, -8.2863,  9.6024, -3.2102],\n",
      "        [10.6393,  5.0298,  6.4385, -8.1800,  9.8071, -3.1631],\n",
      "        [10.8221,  5.0908,  6.8706, -8.1304,  9.6074, -3.4960],\n",
      "        [10.6102,  4.8926,  6.7402, -8.0246,  9.4867, -3.3797],\n",
      "        [10.6175,  4.7537,  6.5959, -8.1824,  9.7687, -3.2673]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8107557892799377\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5618, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5270,  4.8801,  6.6915],\n",
      "        [10.8932,  4.9410,  6.3637],\n",
      "        [10.6109,  4.9225,  6.3111],\n",
      "        [11.0280,  5.2423,  6.8539],\n",
      "        [10.7917,  5.0291,  6.6418],\n",
      "        [10.6036,  4.8817,  6.5785]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1943,  9.6065, -3.3847],\n",
      "        [-8.3140,  9.8810, -3.4043],\n",
      "        [-8.0755,  9.5014, -3.3283],\n",
      "        [-8.1648,  9.6637, -2.9836],\n",
      "        [-8.0758,  9.8165, -3.5293],\n",
      "        [-8.4023,  9.6471, -3.1799]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5270,  4.8801,  6.6915, -8.1943,  9.6065, -3.3847],\n",
      "        [10.8932,  4.9410,  6.3637, -8.3140,  9.8810, -3.4043],\n",
      "        [10.6109,  4.9225,  6.3111, -8.0755,  9.5014, -3.3283],\n",
      "        [11.0280,  5.2423,  6.8539, -8.1648,  9.6637, -2.9836],\n",
      "        [10.7917,  5.0291,  6.6418, -8.0758,  9.8165, -3.5293],\n",
      "        [10.6036,  4.8817,  6.5785, -8.4023,  9.6471, -3.1799]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.822304368019104\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7009,  4.9847,  6.5302],\n",
      "        [10.7736,  4.7011,  6.7589],\n",
      "        [10.7233,  4.9877,  6.4786],\n",
      "        [10.5696,  4.8454,  6.5979],\n",
      "        [10.6149,  4.9052,  6.5590],\n",
      "        [10.8655,  4.8696,  6.6108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.1308, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1980,  9.5553, -3.4252],\n",
      "        [-8.3860,  9.8485, -3.5022],\n",
      "        [-8.2824,  9.9305, -3.3991],\n",
      "        [-8.3223,  9.8554, -3.5112],\n",
      "        [-8.4249,  9.5887, -3.2080],\n",
      "        [-8.0637,  9.4866, -3.0348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7009,  4.9847,  6.5302, -8.1980,  9.5553, -3.4252],\n",
      "        [10.7736,  4.7011,  6.7589, -8.3860,  9.8485, -3.5022],\n",
      "        [10.7233,  4.9877,  6.4786, -8.2824,  9.9305, -3.3991],\n",
      "        [10.5696,  4.8454,  6.5979, -8.3223,  9.8554, -3.5112],\n",
      "        [10.6149,  4.9052,  6.5590, -8.4249,  9.5887, -3.2080],\n",
      "        [10.8655,  4.8696,  6.6108, -8.0637,  9.4866, -3.0348]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8255304098129272\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5780, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6945,  4.6739,  6.8356],\n",
      "        [10.6029,  4.8284,  6.5215],\n",
      "        [10.7983,  4.6921,  6.3903],\n",
      "        [10.5728,  5.0781,  6.7537],\n",
      "        [10.6264,  4.9422,  6.3854],\n",
      "        [10.5636,  4.8077,  6.7319]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3873, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.1361,  9.6562, -3.4360],\n",
      "        [-8.4155,  9.5800, -3.3864],\n",
      "        [-8.3856,  9.6290, -3.2182],\n",
      "        [-8.0702,  9.7675, -3.1413],\n",
      "        [-8.5334,  9.6733, -3.4560],\n",
      "        [-8.4823,  9.6235, -3.1634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6945,  4.6739,  6.8356, -8.1361,  9.6562, -3.4360],\n",
      "        [10.6029,  4.8284,  6.5215, -8.4155,  9.5800, -3.3864],\n",
      "        [10.7983,  4.6921,  6.3903, -8.3856,  9.6290, -3.2182],\n",
      "        [10.5728,  5.0781,  6.7537, -8.0702,  9.7675, -3.1413],\n",
      "        [10.6264,  4.9422,  6.3854, -8.5334,  9.6733, -3.4560],\n",
      "        [10.5636,  4.8077,  6.7319, -8.4823,  9.6235, -3.1634]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8301423788070679\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3723, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5048,  4.8038,  6.3916],\n",
      "        [10.8285,  4.8617,  6.6492],\n",
      "        [10.5525,  4.5684,  6.5083],\n",
      "        [10.7844,  5.0747,  6.7089],\n",
      "        [10.7555,  4.7015,  6.5398],\n",
      "        [10.7228,  4.8949,  6.6683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2559,  9.5086, -3.3348],\n",
      "        [-8.4005,  9.8304, -3.4921],\n",
      "        [-8.4165,  9.8403, -3.2654],\n",
      "        [-8.1132,  9.6762, -3.2008],\n",
      "        [-8.1239,  9.4006, -3.4332],\n",
      "        [-8.4538,  9.7581, -3.2275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5048,  4.8038,  6.3916, -8.2559,  9.5086, -3.3348],\n",
      "        [10.8285,  4.8617,  6.6492, -8.4005,  9.8304, -3.4921],\n",
      "        [10.5525,  4.5684,  6.5083, -8.4165,  9.8403, -3.2654],\n",
      "        [10.7844,  5.0747,  6.7089, -8.1132,  9.6762, -3.2008],\n",
      "        [10.7555,  4.7015,  6.5398, -8.1239,  9.4006, -3.4332],\n",
      "        [10.7228,  4.8949,  6.6683, -8.4538,  9.7581, -3.2275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8144720196723938\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.4005,  5.1678,  6.3411],\n",
      "        [10.8081,  4.9628,  6.7549],\n",
      "        [10.5462,  4.8126,  6.6321],\n",
      "        [10.8447,  4.9401,  6.4175],\n",
      "        [10.5980,  4.8596,  6.4661],\n",
      "        [10.6707,  5.0204,  6.8263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.2082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2771, 10.1194, -3.4142],\n",
      "        [-8.3360,  9.6828, -3.0117],\n",
      "        [-7.9544, 10.0869, -3.3301],\n",
      "        [-8.2560,  9.9306, -3.6725],\n",
      "        [-8.3766, 10.0450, -3.3763],\n",
      "        [-8.3259, 10.0864, -3.1757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.4005,  5.1678,  6.3411, -8.2771, 10.1194, -3.4142],\n",
      "        [10.8081,  4.9628,  6.7549, -8.3360,  9.6828, -3.0117],\n",
      "        [10.5462,  4.8126,  6.6321, -7.9544, 10.0869, -3.3301],\n",
      "        [10.8447,  4.9401,  6.4175, -8.2560,  9.9306, -3.6725],\n",
      "        [10.5980,  4.8596,  6.4661, -8.3766, 10.0450, -3.3763],\n",
      "        [10.6707,  5.0204,  6.8263, -8.3259, 10.0864, -3.1757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8245452642440796\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3895, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7224,  4.8294,  6.9418],\n",
      "        [10.8396,  4.9175,  6.6230],\n",
      "        [10.6300,  5.4431,  6.7032],\n",
      "        [10.6569,  4.8647,  6.8988],\n",
      "        [10.7803,  4.6352,  6.3970],\n",
      "        [10.7370,  5.0484,  6.7464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.0085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2270,  9.3423, -3.5337],\n",
      "        [-8.1554,  9.8832, -3.0701],\n",
      "        [-8.3766,  9.7660, -3.0797],\n",
      "        [-8.5373,  9.5124, -3.4279],\n",
      "        [-8.5630,  9.2572, -3.4831],\n",
      "        [-8.2085,  9.5129, -3.6397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7224,  4.8294,  6.9418, -8.2270,  9.3423, -3.5337],\n",
      "        [10.8396,  4.9175,  6.6230, -8.1554,  9.8832, -3.0701],\n",
      "        [10.6300,  5.4431,  6.7032, -8.3766,  9.7660, -3.0797],\n",
      "        [10.6569,  4.8647,  6.8988, -8.5373,  9.5124, -3.4279],\n",
      "        [10.7803,  4.6352,  6.3970, -8.5630,  9.2572, -3.4831],\n",
      "        [10.7370,  5.0484,  6.7464, -8.2085,  9.5129, -3.6397]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8338949084281921\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3989, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.4545,  4.6471,  6.5874],\n",
      "        [11.0030,  5.0294,  6.5240],\n",
      "        [10.6455,  5.0695,  6.4599],\n",
      "        [10.6351,  5.3275,  6.7374],\n",
      "        [10.2569,  4.9843,  6.4708],\n",
      "        [10.9380,  4.9544,  6.8583]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.1589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.4556,  9.7103, -3.4584],\n",
      "        [-8.5246,  9.7875, -3.0494],\n",
      "        [-8.4892,  9.7765, -3.3283],\n",
      "        [-8.2076,  9.7419, -3.3156],\n",
      "        [-8.1486,  9.5738, -3.2924],\n",
      "        [-8.2234,  9.9436, -3.6272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.4545,  4.6471,  6.5874, -8.4556,  9.7103, -3.4584],\n",
      "        [11.0030,  5.0294,  6.5240, -8.5246,  9.7875, -3.0494],\n",
      "        [10.6455,  5.0695,  6.4599, -8.4892,  9.7765, -3.3283],\n",
      "        [10.6351,  5.3275,  6.7374, -8.2076,  9.7419, -3.3156],\n",
      "        [10.2569,  4.9843,  6.4708, -8.1486,  9.5738, -3.2924],\n",
      "        [10.9380,  4.9544,  6.8583, -8.2234,  9.9436, -3.6272]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8233017325401306\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2683, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7842,  5.0666,  6.8080],\n",
      "        [10.4456,  4.6566,  6.7633],\n",
      "        [10.8334,  4.8426,  6.4531],\n",
      "        [10.8106,  4.8366,  6.7460],\n",
      "        [10.8187,  4.8246,  6.6837],\n",
      "        [10.7489,  5.0674,  6.6257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3892,  9.9125, -3.2779],\n",
      "        [-8.0499,  9.9710, -3.6182],\n",
      "        [-8.2430,  9.7288, -3.2439],\n",
      "        [-8.4487,  9.9428, -3.5235],\n",
      "        [-8.1401,  9.7229, -3.4054],\n",
      "        [-8.4608,  9.7209, -3.3129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7842,  5.0666,  6.8080, -8.3892,  9.9125, -3.2779],\n",
      "        [10.4456,  4.6566,  6.7633, -8.0499,  9.9710, -3.6182],\n",
      "        [10.8334,  4.8426,  6.4531, -8.2430,  9.7288, -3.2439],\n",
      "        [10.8106,  4.8366,  6.7460, -8.4487,  9.9428, -3.5235],\n",
      "        [10.8187,  4.8246,  6.6837, -8.1401,  9.7229, -3.4054],\n",
      "        [10.7489,  5.0674,  6.6257, -8.4608,  9.7209, -3.3129]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8464252352714539\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.5871,  4.7810,  6.9951],\n",
      "        [10.6534,  5.0054,  6.4559],\n",
      "        [10.9726,  4.9407,  6.7759],\n",
      "        [10.6958,  5.1193,  7.0292],\n",
      "        [10.7994,  4.8640,  6.7677],\n",
      "        [10.7968,  5.0478,  6.5369]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.1980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3670,  9.8314, -3.3943],\n",
      "        [-8.7889,  9.8283, -3.1738],\n",
      "        [-8.5200,  9.8913, -3.4009],\n",
      "        [-8.2222,  9.5992, -3.1026],\n",
      "        [-7.9385,  9.8019, -3.4729],\n",
      "        [-8.3224, 10.0502, -3.4713]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.5871,  4.7810,  6.9951, -8.3670,  9.8314, -3.3943],\n",
      "        [10.6534,  5.0054,  6.4559, -8.7889,  9.8283, -3.1738],\n",
      "        [10.9726,  4.9407,  6.7759, -8.5200,  9.8913, -3.4009],\n",
      "        [10.6958,  5.1193,  7.0292, -8.2222,  9.5992, -3.1026],\n",
      "        [10.7994,  4.8640,  6.7677, -7.9385,  9.8019, -3.4729],\n",
      "        [10.7968,  5.0478,  6.5369, -8.3224, 10.0502, -3.4713]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8404343128204346\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6310,  4.8958,  6.6689],\n",
      "        [10.8684,  5.0972,  6.9539],\n",
      "        [10.8362,  5.1469,  6.9039],\n",
      "        [11.1083,  5.0847,  6.7150],\n",
      "        [10.4788,  5.1946,  6.7917],\n",
      "        [10.4166,  4.6887,  6.7870]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.4318, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.4007,  9.6182, -3.3421],\n",
      "        [-8.4773,  9.6835, -3.4445],\n",
      "        [-8.1034,  9.9609, -3.4797],\n",
      "        [-8.4445,  9.9224, -3.5105],\n",
      "        [-8.2348,  9.8364, -3.7363],\n",
      "        [-8.4982,  9.8442, -3.3367]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6310,  4.8958,  6.6689, -8.4007,  9.6182, -3.3421],\n",
      "        [10.8684,  5.0972,  6.9539, -8.4773,  9.6835, -3.4445],\n",
      "        [10.8362,  5.1469,  6.9039, -8.1034,  9.9609, -3.4797],\n",
      "        [11.1083,  5.0847,  6.7150, -8.4445,  9.9224, -3.5105],\n",
      "        [10.4788,  5.1946,  6.7917, -8.2348,  9.8364, -3.7363],\n",
      "        [10.4166,  4.6887,  6.7870, -8.4982,  9.8442, -3.3367]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8331599831581116\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6095,  4.5347,  6.8203],\n",
      "        [10.5361,  4.8449,  6.2163],\n",
      "        [10.6109,  4.9613,  6.6048],\n",
      "        [10.6158,  5.1322,  6.5280],\n",
      "        [10.8945,  4.8804,  6.7443],\n",
      "        [11.2131,  5.3483,  6.7068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1312, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3165,  9.6502, -3.6263],\n",
      "        [-8.3340, 10.0796, -3.5439],\n",
      "        [-8.4296,  9.8803, -3.0962],\n",
      "        [-8.4777, 10.1616, -3.3662],\n",
      "        [-8.2314,  9.7210, -3.5064],\n",
      "        [-8.3630,  9.5224, -3.4142]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6095,  4.5347,  6.8203, -8.3165,  9.6502, -3.6263],\n",
      "        [10.5361,  4.8449,  6.2163, -8.3340, 10.0796, -3.5439],\n",
      "        [10.6109,  4.9613,  6.6048, -8.4296,  9.8803, -3.0962],\n",
      "        [10.6158,  5.1322,  6.5280, -8.4777, 10.1616, -3.3662],\n",
      "        [10.8945,  4.8804,  6.7443, -8.2314,  9.7210, -3.5064],\n",
      "        [11.2131,  5.3483,  6.7068, -8.3630,  9.5224, -3.4142]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8328685164451599\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7966, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.8598,  5.0530,  6.6300],\n",
      "        [10.8090,  4.9932,  6.9734],\n",
      "        [10.3817,  5.0980,  6.4200],\n",
      "        [11.1010,  4.9935,  6.9080],\n",
      "        [10.7676,  4.9618,  6.4405],\n",
      "        [10.5192,  4.7707,  6.7828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.1041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3768,  9.7742, -3.2555],\n",
      "        [-8.4078,  9.9863, -3.7344],\n",
      "        [-8.7473, 10.0022, -3.2026],\n",
      "        [-8.2401,  9.4440, -3.5454],\n",
      "        [-8.2871,  9.9036, -3.6891],\n",
      "        [-8.4267, 10.0756, -3.3083]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.8598,  5.0530,  6.6300, -8.3768,  9.7742, -3.2555],\n",
      "        [10.8090,  4.9932,  6.9734, -8.4078,  9.9863, -3.7344],\n",
      "        [10.3817,  5.0980,  6.4200, -8.7473, 10.0022, -3.2026],\n",
      "        [11.1010,  4.9935,  6.9080, -8.2401,  9.4440, -3.5454],\n",
      "        [10.7676,  4.9618,  6.4405, -8.2871,  9.9036, -3.6891],\n",
      "        [10.5192,  4.7707,  6.7828, -8.4267, 10.0756, -3.3083]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8445714116096497\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6407,  4.8502,  6.5802],\n",
      "        [10.8673,  5.0347,  6.6358],\n",
      "        [11.0331,  5.0555,  6.8252],\n",
      "        [10.9755,  4.9451,  6.9419],\n",
      "        [10.5601,  5.0641,  6.7065],\n",
      "        [10.8743,  4.9078,  6.9108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6372, 10.0827, -3.3366],\n",
      "        [-8.7777, 10.0367, -3.2472],\n",
      "        [-8.4262, 10.1705, -3.5079],\n",
      "        [-8.3420,  9.8483, -3.4689],\n",
      "        [-8.7570,  9.9721, -3.3952],\n",
      "        [-8.2419,  9.6748, -3.1764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6407,  4.8502,  6.5802, -8.6372, 10.0827, -3.3366],\n",
      "        [10.8673,  5.0347,  6.6358, -8.7777, 10.0367, -3.2472],\n",
      "        [11.0331,  5.0555,  6.8252, -8.4262, 10.1705, -3.5079],\n",
      "        [10.9755,  4.9451,  6.9419, -8.3420,  9.8483, -3.4689],\n",
      "        [10.5601,  5.0641,  6.7065, -8.7570,  9.9721, -3.3952],\n",
      "        [10.8743,  4.9078,  6.9108, -8.2419,  9.6748, -3.1764]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.842630922794342\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.9753,  5.0977,  6.8224],\n",
      "        [10.7674,  4.8062,  6.6766],\n",
      "        [10.9874,  5.0645,  6.6297],\n",
      "        [10.5979,  4.6411,  6.6160],\n",
      "        [11.2421,  5.1806,  6.7101],\n",
      "        [10.7676,  4.8111,  6.8417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5371, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.4403,  9.6858, -3.2021],\n",
      "        [-8.2398,  9.8908, -3.3804],\n",
      "        [-8.3707, 10.1735, -3.3857],\n",
      "        [-8.3455,  9.7053, -3.3144],\n",
      "        [-8.3591,  9.8594, -3.2435],\n",
      "        [-8.3403,  9.9125, -3.1774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.9753,  5.0977,  6.8224, -8.4403,  9.6858, -3.2021],\n",
      "        [10.7674,  4.8062,  6.6766, -8.2398,  9.8908, -3.3804],\n",
      "        [10.9874,  5.0645,  6.6297, -8.3707, 10.1735, -3.3857],\n",
      "        [10.5979,  4.6411,  6.6160, -8.3455,  9.7053, -3.3144],\n",
      "        [11.2421,  5.1806,  6.7101, -8.3591,  9.8594, -3.2435],\n",
      "        [10.7676,  4.8111,  6.8417, -8.3403,  9.9125, -3.1774]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8538457155227661\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3099, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0178,  5.1012,  6.7905],\n",
      "        [10.9867,  5.0922,  6.6473],\n",
      "        [10.8337,  4.8380,  6.8931],\n",
      "        [10.4382,  4.7085,  6.6612],\n",
      "        [10.8273,  5.0740,  6.9731],\n",
      "        [10.9411,  5.2056,  6.8620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.1638, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5380, 10.0155, -3.6692],\n",
      "        [-8.2295,  9.7725, -3.4761],\n",
      "        [-8.4414,  9.9862, -3.5929],\n",
      "        [-8.4533,  9.8046, -3.6544],\n",
      "        [-8.3807,  9.6883, -3.6231],\n",
      "        [-8.0511,  9.7417, -3.3244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0178,  5.1012,  6.7905, -8.5380, 10.0155, -3.6692],\n",
      "        [10.9867,  5.0922,  6.6473, -8.2295,  9.7725, -3.4761],\n",
      "        [10.8337,  4.8380,  6.8931, -8.4414,  9.9862, -3.5929],\n",
      "        [10.4382,  4.7085,  6.6612, -8.4533,  9.8046, -3.6544],\n",
      "        [10.8273,  5.0740,  6.9731, -8.3807,  9.6883, -3.6231],\n",
      "        [10.9411,  5.2056,  6.8620, -8.0511,  9.7417, -3.3244]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8633754253387451\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.7839,  5.1944,  6.5828],\n",
      "        [10.6586,  5.1833,  6.7560],\n",
      "        [11.0054,  4.9231,  6.8530],\n",
      "        [10.6779,  4.7905,  6.7536],\n",
      "        [10.9574,  5.2049,  6.5901],\n",
      "        [10.6227,  5.3339,  6.3873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5531,  9.7332, -3.3207],\n",
      "        [-8.3044,  9.9438, -3.5529],\n",
      "        [-8.3475,  9.6911, -3.2376],\n",
      "        [-8.7203, 10.1087, -3.6819],\n",
      "        [-8.4549, 10.1347, -3.5113],\n",
      "        [-8.7296,  9.9521, -3.4245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.7839,  5.1944,  6.5828, -8.5531,  9.7332, -3.3207],\n",
      "        [10.6586,  5.1833,  6.7560, -8.3044,  9.9438, -3.5529],\n",
      "        [11.0054,  4.9231,  6.8530, -8.3475,  9.6911, -3.2376],\n",
      "        [10.6779,  4.7905,  6.7536, -8.7203, 10.1087, -3.6819],\n",
      "        [10.9574,  5.2049,  6.5901, -8.4549, 10.1347, -3.5113],\n",
      "        [10.6227,  5.3339,  6.3873, -8.7296,  9.9521, -3.4245]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8468337059020996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9648, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.6849,  4.9001,  7.1164],\n",
      "        [10.4976,  4.9499,  6.8967],\n",
      "        [10.8636,  5.1601,  6.8992],\n",
      "        [10.9829,  5.1161,  6.8032],\n",
      "        [10.8438,  4.7072,  6.8221],\n",
      "        [11.0233,  4.9757,  6.7385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3884, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3290, 10.0207, -3.3208],\n",
      "        [-8.6193, 10.0587, -3.4839],\n",
      "        [-8.5834, 10.0297, -3.3810],\n",
      "        [-8.6570,  9.9325, -3.3504],\n",
      "        [-8.6983,  9.7283, -3.4384],\n",
      "        [-8.4527,  9.8987, -3.6484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.6849,  4.9001,  7.1164, -8.3290, 10.0207, -3.3208],\n",
      "        [10.4976,  4.9499,  6.8967, -8.6193, 10.0587, -3.4839],\n",
      "        [10.8636,  5.1601,  6.8992, -8.5834, 10.0297, -3.3810],\n",
      "        [10.9829,  5.1161,  6.8032, -8.6570,  9.9325, -3.3504],\n",
      "        [10.8438,  4.7072,  6.8221, -8.6983,  9.7283, -3.4384],\n",
      "        [11.0233,  4.9757,  6.7385, -8.4527,  9.8987, -3.6484]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8546895980834961\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.9141,  4.8714,  6.5741],\n",
      "        [10.7330,  4.9981,  6.7221],\n",
      "        [10.4556,  5.0956,  6.5705],\n",
      "        [10.9083,  5.3012,  6.6438],\n",
      "        [11.0499,  5.0377,  6.5412],\n",
      "        [10.7796,  4.8575,  6.8071]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4555, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3997,  9.8924, -3.4261],\n",
      "        [-8.3830, 10.1066, -3.4269],\n",
      "        [-8.4330,  9.8324, -3.7368],\n",
      "        [-8.6304,  9.8415, -3.2748],\n",
      "        [-8.3057,  9.8470, -3.6051],\n",
      "        [-8.8032,  9.7476, -3.3135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.9141,  4.8714,  6.5741, -8.3997,  9.8924, -3.4261],\n",
      "        [10.7330,  4.9981,  6.7221, -8.3830, 10.1066, -3.4269],\n",
      "        [10.4556,  5.0956,  6.5705, -8.4330,  9.8324, -3.7368],\n",
      "        [10.9083,  5.3012,  6.6438, -8.6304,  9.8415, -3.2748],\n",
      "        [11.0499,  5.0377,  6.5412, -8.3057,  9.8470, -3.6051],\n",
      "        [10.7796,  4.8575,  6.8071, -8.8032,  9.7476, -3.3135]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8491769433021545\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0276, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0009,  5.2608,  6.9585],\n",
      "        [10.6685,  4.4631,  6.6492],\n",
      "        [10.9264,  5.1235,  6.8691],\n",
      "        [10.6006,  5.2335,  6.5935],\n",
      "        [10.7799,  5.1682,  6.6388],\n",
      "        [10.8992,  4.8579,  6.9820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3938, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5538,  9.9386, -3.4712],\n",
      "        [-8.7356, 10.0267, -3.4851],\n",
      "        [-8.4359,  9.7851, -3.7588],\n",
      "        [-8.6266, 10.2351, -3.6294],\n",
      "        [-8.6135, 10.0266, -3.4992],\n",
      "        [-8.2518,  9.7737, -3.5537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0009,  5.2608,  6.9585, -8.5538,  9.9386, -3.4712],\n",
      "        [10.6685,  4.4631,  6.6492, -8.7356, 10.0267, -3.4851],\n",
      "        [10.9264,  5.1235,  6.8691, -8.4359,  9.7851, -3.7588],\n",
      "        [10.6006,  5.2335,  6.5935, -8.6266, 10.2351, -3.6294],\n",
      "        [10.7799,  5.1682,  6.6388, -8.6135, 10.0266, -3.4992],\n",
      "        [10.8992,  4.8579,  6.9820, -8.2518,  9.7737, -3.5537]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8692392706871033\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9457, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.8978,  4.9978,  6.7581],\n",
      "        [10.8544,  5.2220,  6.6555],\n",
      "        [10.8391,  5.4351,  6.8518],\n",
      "        [11.0327,  5.1192,  6.7773],\n",
      "        [11.1574,  4.9948,  6.7609],\n",
      "        [10.9375,  4.8784,  6.7020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.7115, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.4111,  9.8512, -3.5856],\n",
      "        [-8.7028, 10.2529, -3.7053],\n",
      "        [-8.3128,  9.8793, -3.7894],\n",
      "        [-8.8292,  9.9867, -3.3687],\n",
      "        [-8.5948, 10.2368, -3.5938],\n",
      "        [-8.5938, 10.1170, -3.3862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.8978,  4.9978,  6.7581, -8.4111,  9.8512, -3.5856],\n",
      "        [10.8544,  5.2220,  6.6555, -8.7028, 10.2529, -3.7053],\n",
      "        [10.8391,  5.4351,  6.8518, -8.3128,  9.8793, -3.7894],\n",
      "        [11.0327,  5.1192,  6.7773, -8.8292,  9.9867, -3.3687],\n",
      "        [11.1574,  4.9948,  6.7609, -8.5948, 10.2368, -3.5938],\n",
      "        [10.9375,  4.8784,  6.7020, -8.5938, 10.1170, -3.3862]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.855846643447876\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.2328,  4.9657,  6.4966],\n",
      "        [10.8261,  5.1447,  7.0956],\n",
      "        [10.8868,  5.4810,  6.8515],\n",
      "        [11.3222,  5.0237,  6.8429],\n",
      "        [10.9242,  5.1177,  6.5224],\n",
      "        [11.2334,  5.2860,  6.8137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5521, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.2795, 10.1353, -3.4652],\n",
      "        [-8.7506, 10.1431, -3.6727],\n",
      "        [-8.5301,  9.8597, -3.3343],\n",
      "        [-8.6801,  9.9639, -3.8231],\n",
      "        [-8.8724, 10.2008, -3.5508],\n",
      "        [-8.4653,  9.7005, -3.3832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.2328,  4.9657,  6.4966, -8.2795, 10.1353, -3.4652],\n",
      "        [10.8261,  5.1447,  7.0956, -8.7506, 10.1431, -3.6727],\n",
      "        [10.8868,  5.4810,  6.8515, -8.5301,  9.8597, -3.3343],\n",
      "        [11.3222,  5.0237,  6.8429, -8.6801,  9.9639, -3.8231],\n",
      "        [10.9242,  5.1177,  6.5224, -8.8724, 10.2008, -3.5508],\n",
      "        [11.2334,  5.2860,  6.8137, -8.4653,  9.7005, -3.3832]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8631917238235474\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0236, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.1484,  5.1195,  7.0591],\n",
      "        [10.9587,  5.3965,  6.9392],\n",
      "        [11.1458,  5.2369,  7.0469],\n",
      "        [10.9492,  5.2843,  6.7737],\n",
      "        [10.8607,  5.2943,  6.7400],\n",
      "        [10.8883,  4.9670,  6.4656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.8645, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6581,  9.9825, -3.6645],\n",
      "        [-8.5967,  9.6602, -3.5449],\n",
      "        [-8.5608,  9.8161, -3.8470],\n",
      "        [-8.4739, 10.1624, -3.7566],\n",
      "        [-8.3608,  9.8486, -3.7919],\n",
      "        [-8.6107, 10.3596, -3.9576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.1484,  5.1195,  7.0591, -8.6581,  9.9825, -3.6645],\n",
      "        [10.9587,  5.3965,  6.9392, -8.5967,  9.6602, -3.5449],\n",
      "        [11.1458,  5.2369,  7.0469, -8.5608,  9.8161, -3.8470],\n",
      "        [10.9492,  5.2843,  6.7737, -8.4739, 10.1624, -3.7566],\n",
      "        [10.8607,  5.2943,  6.7400, -8.3608,  9.8486, -3.7919],\n",
      "        [10.8883,  4.9670,  6.4656, -8.6107, 10.3596, -3.9576]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8794474601745605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7070, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0626,  5.1752,  6.9270],\n",
      "        [11.0148,  5.2851,  6.9201],\n",
      "        [10.9627,  5.2794,  6.7477],\n",
      "        [11.0577,  5.2818,  6.6921],\n",
      "        [11.2845,  5.2265,  6.8644],\n",
      "        [11.0916,  5.4172,  7.0157]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.6569, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3528,  9.8705, -3.2735],\n",
      "        [-8.7594, 10.0197, -3.6258],\n",
      "        [-8.6348, 10.0070, -3.6216],\n",
      "        [-8.3719,  9.8471, -3.7986],\n",
      "        [-8.4564, 10.0561, -3.5568],\n",
      "        [-8.7552, 10.1747, -3.9192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0626,  5.1752,  6.9270, -8.3528,  9.8705, -3.2735],\n",
      "        [11.0148,  5.2851,  6.9201, -8.7594, 10.0197, -3.6258],\n",
      "        [10.9627,  5.2794,  6.7477, -8.6348, 10.0070, -3.6216],\n",
      "        [11.0577,  5.2818,  6.6921, -8.3719,  9.8471, -3.7986],\n",
      "        [11.2845,  5.2265,  6.8644, -8.4564, 10.0561, -3.5568],\n",
      "        [11.0916,  5.4172,  7.0157, -8.7552, 10.1747, -3.9192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8674158453941345\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0622,  5.5604,  6.8012],\n",
      "        [11.1056,  5.1551,  6.8555],\n",
      "        [11.3593,  5.1649,  6.9784],\n",
      "        [10.8224,  5.0160,  6.5223],\n",
      "        [10.9312,  5.0669,  6.6886],\n",
      "        [11.1363,  5.0761,  6.9533]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.9116, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.4800,  9.8623, -3.6550],\n",
      "        [-8.4510, 10.2987, -3.5666],\n",
      "        [-8.5999,  9.6046, -3.6996],\n",
      "        [-8.6487, 10.0198, -3.7850],\n",
      "        [-9.1697,  9.9181, -3.9525],\n",
      "        [-8.4804, 10.0267, -3.9247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0622,  5.5604,  6.8012, -8.4800,  9.8623, -3.6550],\n",
      "        [11.1056,  5.1551,  6.8555, -8.4510, 10.2987, -3.5666],\n",
      "        [11.3593,  5.1649,  6.9784, -8.5999,  9.6046, -3.6996],\n",
      "        [10.8224,  5.0160,  6.5223, -8.6487, 10.0198, -3.7850],\n",
      "        [10.9312,  5.0669,  6.6886, -9.1697,  9.9181, -3.9525],\n",
      "        [11.1363,  5.0761,  6.9533, -8.4804, 10.0267, -3.9247]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8728371858596802\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7076, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0579,  5.1315,  6.7101],\n",
      "        [11.0717,  5.2917,  6.9265],\n",
      "        [11.2222,  5.1899,  7.2090],\n",
      "        [10.9024,  5.1276,  6.9008],\n",
      "        [10.9188,  5.3195,  6.8144],\n",
      "        [10.9394,  5.0550,  7.0087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6140,  9.9788, -3.7778],\n",
      "        [-8.3932, 10.1433, -3.8811],\n",
      "        [-8.7389,  9.9856, -3.4623],\n",
      "        [-8.4422, 10.0349, -3.6224],\n",
      "        [-8.7161, 10.1092, -3.8524],\n",
      "        [-8.7432, 10.0514, -3.7049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0579,  5.1315,  6.7101, -8.6140,  9.9788, -3.7778],\n",
      "        [11.0717,  5.2917,  6.9265, -8.3932, 10.1433, -3.8811],\n",
      "        [11.2222,  5.1899,  7.2090, -8.7389,  9.9856, -3.4623],\n",
      "        [10.9024,  5.1276,  6.9008, -8.4422, 10.0349, -3.6224],\n",
      "        [10.9188,  5.3195,  6.8144, -8.7161, 10.1092, -3.8524],\n",
      "        [10.9394,  5.0550,  7.0087, -8.7432, 10.0514, -3.7049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8700042366981506\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0891,  5.5005,  6.7128],\n",
      "        [10.9529,  5.1324,  6.6324],\n",
      "        [11.0966,  5.0998,  6.6042],\n",
      "        [11.1631,  4.9159,  6.9940],\n",
      "        [10.3833,  5.1667,  6.8187],\n",
      "        [11.1408,  5.0935,  6.9258]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.7995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5730,  9.9528, -3.6078],\n",
      "        [-8.3209,  9.6520, -3.5166],\n",
      "        [-8.5710,  9.9112, -3.4635],\n",
      "        [-8.7496, 10.0969, -3.4145],\n",
      "        [-8.6863, 10.5352, -3.8745],\n",
      "        [-8.5665, 10.1465, -3.7623]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0891,  5.5005,  6.7128, -8.5730,  9.9528, -3.6078],\n",
      "        [10.9529,  5.1324,  6.6324, -8.3209,  9.6520, -3.5166],\n",
      "        [11.0966,  5.0998,  6.6042, -8.5710,  9.9112, -3.4635],\n",
      "        [11.1631,  4.9159,  6.9940, -8.7496, 10.0969, -3.4145],\n",
      "        [10.3833,  5.1667,  6.8187, -8.6863, 10.5352, -3.8745],\n",
      "        [11.1408,  5.0935,  6.9258, -8.5665, 10.1465, -3.7623]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8744989633560181\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6607, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3752,  5.1763,  6.8354],\n",
      "        [11.0338,  4.9571,  6.9714],\n",
      "        [11.1171,  5.4177,  7.1081],\n",
      "        [10.6988,  4.8760,  6.8112],\n",
      "        [11.1099,  5.2984,  7.1415],\n",
      "        [11.2889,  5.1632,  6.9605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.6823, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8651, 10.2487, -3.9288],\n",
      "        [-8.9436, 10.3170, -3.7195],\n",
      "        [-8.7556, 10.3553, -3.8104],\n",
      "        [-8.4695, 10.2788, -3.7888],\n",
      "        [-8.6463, 10.1191, -3.6693],\n",
      "        [-8.7952, 10.3812, -3.6913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3752,  5.1763,  6.8354, -8.8651, 10.2487, -3.9288],\n",
      "        [11.0338,  4.9571,  6.9714, -8.9436, 10.3170, -3.7195],\n",
      "        [11.1171,  5.4177,  7.1081, -8.7556, 10.3553, -3.8104],\n",
      "        [10.6988,  4.8760,  6.8112, -8.4695, 10.2788, -3.7888],\n",
      "        [11.1099,  5.2984,  7.1415, -8.6463, 10.1191, -3.6693],\n",
      "        [11.2889,  5.1632,  6.9605, -8.7952, 10.3812, -3.6913]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.893349289894104\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.1667,  5.1491,  7.0397],\n",
      "        [11.0373,  5.5018,  7.0226],\n",
      "        [10.9286,  5.1995,  6.8339],\n",
      "        [11.2080,  5.0573,  7.0158],\n",
      "        [10.9998,  5.2081,  7.3621],\n",
      "        [11.2913,  5.2396,  6.7798]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.7806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9288, 10.1627, -3.5696],\n",
      "        [-8.6930, 10.1121, -4.0220],\n",
      "        [-8.8645, 10.1282, -3.8703],\n",
      "        [-8.8357, 10.1301, -3.7591],\n",
      "        [-8.5627, 10.4319, -3.5414],\n",
      "        [-8.6425, 10.0151, -3.9707]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.1667,  5.1491,  7.0397, -8.9288, 10.1627, -3.5696],\n",
      "        [11.0373,  5.5018,  7.0226, -8.6930, 10.1121, -4.0220],\n",
      "        [10.9286,  5.1995,  6.8339, -8.8645, 10.1282, -3.8703],\n",
      "        [11.2080,  5.0573,  7.0158, -8.8357, 10.1301, -3.7591],\n",
      "        [10.9998,  5.2081,  7.3621, -8.5627, 10.4319, -3.5414],\n",
      "        [11.2913,  5.2396,  6.7798, -8.6425, 10.0151, -3.9707]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8894119262695312\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6257, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0741,  5.2181,  7.1173],\n",
      "        [10.7908,  4.9947,  7.1155],\n",
      "        [11.0748,  5.1224,  7.0193],\n",
      "        [10.8407,  5.0504,  6.7723],\n",
      "        [11.0985,  5.2989,  6.9498],\n",
      "        [11.1548,  5.5660,  6.9555]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2467, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8732, 10.0251, -3.4961],\n",
      "        [-8.8090,  9.9817, -3.7802],\n",
      "        [-8.6327, 10.1861, -3.8290],\n",
      "        [-9.0564, 10.1824, -3.8725],\n",
      "        [-8.2990, 10.2420, -3.6215],\n",
      "        [-8.3493, 10.3243, -3.9040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0741,  5.2181,  7.1173, -8.8732, 10.0251, -3.4961],\n",
      "        [10.7908,  4.9947,  7.1155, -8.8090,  9.9817, -3.7802],\n",
      "        [11.0748,  5.1224,  7.0193, -8.6327, 10.1861, -3.8290],\n",
      "        [10.8407,  5.0504,  6.7723, -9.0564, 10.1824, -3.8725],\n",
      "        [11.0985,  5.2989,  6.9498, -8.2990, 10.2420, -3.6215],\n",
      "        [11.1548,  5.5660,  6.9555, -8.3493, 10.3243, -3.9040]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8864355087280273\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9936, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3145,  5.1783,  6.9769],\n",
      "        [11.1149,  5.1789,  7.0550],\n",
      "        [10.9195,  5.0960,  6.8210],\n",
      "        [11.1504,  5.3823,  7.2226],\n",
      "        [10.9851,  5.2665,  7.1020],\n",
      "        [10.8845,  5.1208,  6.8480]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5556, 10.0470, -3.6380],\n",
      "        [-8.6824, 10.3029, -4.1308],\n",
      "        [-8.8263, 10.0422, -3.5714],\n",
      "        [-8.6445, 10.1650, -3.5473],\n",
      "        [-8.9365,  9.9162, -3.7503],\n",
      "        [-8.7809, 10.2476, -3.5540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3145,  5.1783,  6.9769, -8.5556, 10.0470, -3.6380],\n",
      "        [11.1149,  5.1789,  7.0550, -8.6824, 10.3029, -4.1308],\n",
      "        [10.9195,  5.0960,  6.8210, -8.8263, 10.0422, -3.5714],\n",
      "        [11.1504,  5.3823,  7.2226, -8.6445, 10.1650, -3.5473],\n",
      "        [10.9851,  5.2665,  7.1020, -8.9365,  9.9162, -3.7503],\n",
      "        [10.8845,  5.1208,  6.8480, -8.7809, 10.2476, -3.5540]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8881354331970215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9692, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0403,  4.9626,  7.0361],\n",
      "        [10.8695,  5.2545,  6.6288],\n",
      "        [11.0091,  5.4314,  6.7905],\n",
      "        [11.0683,  5.3657,  6.9839],\n",
      "        [11.3955,  5.4203,  7.1143],\n",
      "        [11.1670,  5.2566,  7.0997]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6179, 10.2677, -3.9424],\n",
      "        [-8.8148, 10.2908, -3.6432],\n",
      "        [-8.8283, 10.1674, -3.7224],\n",
      "        [-8.5025, 10.0502, -4.0715],\n",
      "        [-8.5414, 10.3879, -3.3924],\n",
      "        [-8.4200, 10.2788, -3.9881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0403,  4.9626,  7.0361, -8.6179, 10.2677, -3.9424],\n",
      "        [10.8695,  5.2545,  6.6288, -8.8148, 10.2908, -3.6432],\n",
      "        [11.0091,  5.4314,  6.7905, -8.8283, 10.1674, -3.7224],\n",
      "        [11.0683,  5.3657,  6.9839, -8.5025, 10.0502, -4.0715],\n",
      "        [11.3955,  5.4203,  7.1143, -8.5414, 10.3879, -3.3924],\n",
      "        [11.1670,  5.2566,  7.0997, -8.4200, 10.2788, -3.9881]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8839280009269714\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0809,  5.0558,  6.9708],\n",
      "        [10.9375,  5.1418,  6.8010],\n",
      "        [11.2411,  5.2335,  6.8611],\n",
      "        [11.2459,  5.2960,  6.9147],\n",
      "        [11.2545,  5.2590,  6.5074],\n",
      "        [10.8539,  5.0770,  7.0855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1172, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6445, 10.1354, -3.6520],\n",
      "        [-8.5047, 10.2023, -3.8965],\n",
      "        [-8.4831, 10.2951, -3.6164],\n",
      "        [-9.0150, 10.4497, -3.7513],\n",
      "        [-8.7837, 10.1751, -3.7929],\n",
      "        [-8.8368, 10.4416, -3.5689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0809,  5.0558,  6.9708, -8.6445, 10.1354, -3.6520],\n",
      "        [10.9375,  5.1418,  6.8010, -8.5047, 10.2023, -3.8965],\n",
      "        [11.2411,  5.2335,  6.8611, -8.4831, 10.2951, -3.6164],\n",
      "        [11.2459,  5.2960,  6.9147, -9.0150, 10.4497, -3.7513],\n",
      "        [11.2545,  5.2590,  6.5074, -8.7837, 10.1751, -3.7929],\n",
      "        [10.8539,  5.0770,  7.0855, -8.8368, 10.4416, -3.5689]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.8824734091758728\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2818, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.2939,  5.1399,  7.2220],\n",
      "        [10.6046,  5.2883,  6.5497],\n",
      "        [11.2653,  5.3380,  7.0367],\n",
      "        [11.2453,  5.0951,  6.9011],\n",
      "        [11.3049,  5.3709,  6.7962],\n",
      "        [11.0689,  5.5510,  7.2410]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8713,  9.9837, -3.5909],\n",
      "        [-8.5462, 10.1390, -3.8841],\n",
      "        [-8.7508, 10.4028, -3.6878],\n",
      "        [-8.4511, 10.2959, -3.9173],\n",
      "        [-9.0247, 10.3876, -3.6630],\n",
      "        [-8.6332, 10.3756, -3.7180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.2939,  5.1399,  7.2220, -8.8713,  9.9837, -3.5909],\n",
      "        [10.6046,  5.2883,  6.5497, -8.5462, 10.1390, -3.8841],\n",
      "        [11.2653,  5.3380,  7.0367, -8.7508, 10.4028, -3.6878],\n",
      "        [11.2453,  5.0951,  6.9011, -8.4511, 10.2959, -3.9173],\n",
      "        [11.3049,  5.3709,  6.7962, -9.0247, 10.3876, -3.6630],\n",
      "        [11.0689,  5.5510,  7.2410, -8.6332, 10.3756, -3.7180]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8974956274032593\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[10.9887,  5.4542,  6.9379],\n",
      "        [11.3151,  5.3506,  7.0933],\n",
      "        [11.1581,  5.1941,  6.8435],\n",
      "        [11.2072,  5.2804,  6.9138],\n",
      "        [10.9768,  5.3385,  7.0315],\n",
      "        [11.2693,  5.1548,  7.0911]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.1472, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8366, 10.1174, -3.6121],\n",
      "        [-8.8387, 10.2866, -3.9311],\n",
      "        [-8.8968, 10.2971, -3.5519],\n",
      "        [-8.6128, 10.3807, -3.7519],\n",
      "        [-8.8506, 10.1706, -3.7296],\n",
      "        [-8.3687, 10.1002, -3.7416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[10.9887,  5.4542,  6.9379, -8.8366, 10.1174, -3.6121],\n",
      "        [11.3151,  5.3506,  7.0933, -8.8387, 10.2866, -3.9311],\n",
      "        [11.1581,  5.1941,  6.8435, -8.8968, 10.2971, -3.5519],\n",
      "        [11.2072,  5.2804,  6.9138, -8.6128, 10.3807, -3.7519],\n",
      "        [10.9768,  5.3385,  7.0315, -8.8506, 10.1706, -3.7296],\n",
      "        [11.2693,  5.1548,  7.0911, -8.3687, 10.1002, -3.7416]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8867068290710449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9291, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0466,  5.3605,  7.0058],\n",
      "        [11.5982,  5.4855,  7.1356],\n",
      "        [11.2786,  4.9254,  6.8896],\n",
      "        [11.1715,  5.4820,  6.6098],\n",
      "        [10.7843,  5.0238,  6.8845],\n",
      "        [11.1049,  5.3259,  7.2576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.6920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3460, 10.0474, -3.9600],\n",
      "        [-8.5282, 10.3780, -3.6998],\n",
      "        [-8.5895, 10.2750, -3.7717],\n",
      "        [-8.6416,  9.9706, -3.5191],\n",
      "        [-9.0370, 10.1916, -3.6727],\n",
      "        [-8.6820, 10.6803, -3.9449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0466,  5.3605,  7.0058, -8.3460, 10.0474, -3.9600],\n",
      "        [11.5982,  5.4855,  7.1356, -8.5282, 10.3780, -3.6998],\n",
      "        [11.2786,  4.9254,  6.8896, -8.5895, 10.2750, -3.7717],\n",
      "        [11.1715,  5.4820,  6.6098, -8.6416,  9.9706, -3.5191],\n",
      "        [10.7843,  5.0238,  6.8845, -9.0370, 10.1916, -3.6727],\n",
      "        [11.1049,  5.3259,  7.2576, -8.6820, 10.6803, -3.9449]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8838453888893127\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.4228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.2557,  5.2178,  7.0902],\n",
      "        [11.3065,  5.2574,  6.9485],\n",
      "        [11.4273,  5.8161,  7.1031],\n",
      "        [11.1346,  5.0241,  7.3949],\n",
      "        [11.2166,  5.3698,  6.9975],\n",
      "        [11.0583,  5.4755,  6.9650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2187, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6453, 10.3153, -3.9651],\n",
      "        [-8.8760, 10.3535, -3.8798],\n",
      "        [-8.6866, 10.3047, -3.5659],\n",
      "        [-8.9216,  9.9911, -3.8433],\n",
      "        [-8.7605, 10.3079, -3.6983],\n",
      "        [-8.6554, 10.1742, -3.9011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.2557,  5.2178,  7.0902, -8.6453, 10.3153, -3.9651],\n",
      "        [11.3065,  5.2574,  6.9485, -8.8760, 10.3535, -3.8798],\n",
      "        [11.4273,  5.8161,  7.1031, -8.6866, 10.3047, -3.5659],\n",
      "        [11.1346,  5.0241,  7.3949, -8.9216,  9.9911, -3.8433],\n",
      "        [11.2166,  5.3698,  6.9975, -8.7605, 10.3079, -3.6983],\n",
      "        [11.0583,  5.4755,  6.9650, -8.6554, 10.1742, -3.9011]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8997806906700134\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4563,  5.5045,  6.9843],\n",
      "        [11.2936,  5.7094,  7.3514],\n",
      "        [11.1862,  5.5381,  6.7901],\n",
      "        [11.1166,  5.4137,  7.4162],\n",
      "        [11.3494,  5.7061,  7.1687],\n",
      "        [11.2402,  5.2546,  7.1854]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.5126, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6516, 10.2530, -3.6595],\n",
      "        [-8.8065, 10.1404, -3.5745],\n",
      "        [-8.5248, 10.5142, -3.9295],\n",
      "        [-8.9781, 10.2461, -3.9022],\n",
      "        [-8.7249, 10.3958, -3.6187],\n",
      "        [-8.9805, 10.1416, -3.5944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4563,  5.5045,  6.9843, -8.6516, 10.2530, -3.6595],\n",
      "        [11.2936,  5.7094,  7.3514, -8.8065, 10.1404, -3.5745],\n",
      "        [11.1862,  5.5381,  6.7901, -8.5248, 10.5142, -3.9295],\n",
      "        [11.1166,  5.4137,  7.4162, -8.9781, 10.2461, -3.9022],\n",
      "        [11.3494,  5.7061,  7.1687, -8.7249, 10.3958, -3.6187],\n",
      "        [11.2402,  5.2546,  7.1854, -8.9805, 10.1416, -3.5944]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9058331847190857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4950,  5.2778,  7.0904],\n",
      "        [11.0191,  5.3830,  7.1395],\n",
      "        [11.4877,  5.3081,  7.1265],\n",
      "        [11.0415,  5.1525,  7.3428],\n",
      "        [11.1303,  5.2840,  7.2643],\n",
      "        [11.3100,  5.2919,  7.0190]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.0123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.5972, 10.0930, -3.5382],\n",
      "        [-8.9919, 10.2945, -3.8100],\n",
      "        [-8.5877, 10.3441, -3.8412],\n",
      "        [-8.9097, 10.1296, -3.4922],\n",
      "        [-8.7399, 10.3284, -3.7945],\n",
      "        [-8.5687,  9.9261, -3.8503]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4950,  5.2778,  7.0904, -8.5972, 10.0930, -3.5382],\n",
      "        [11.0191,  5.3830,  7.1395, -8.9919, 10.2945, -3.8100],\n",
      "        [11.4877,  5.3081,  7.1265, -8.5877, 10.3441, -3.8412],\n",
      "        [11.0415,  5.1525,  7.3428, -8.9097, 10.1296, -3.4922],\n",
      "        [11.1303,  5.2840,  7.2643, -8.7399, 10.3284, -3.7945],\n",
      "        [11.3100,  5.2919,  7.0190, -8.5687,  9.9261, -3.8503]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9037312865257263\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9535, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.1794,  5.4446,  7.2880],\n",
      "        [11.2237,  5.3359,  7.2486],\n",
      "        [10.9684,  5.5080,  7.0359],\n",
      "        [11.6428,  5.4986,  7.1167],\n",
      "        [11.1894,  5.4195,  6.9399],\n",
      "        [11.4736,  5.3985,  7.3228]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.8278, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0611, 10.1287, -3.6349],\n",
      "        [-8.7726, 10.4740, -3.7637],\n",
      "        [-8.8520, 10.1700, -3.5965],\n",
      "        [-8.6656, 10.2722, -3.4992],\n",
      "        [-8.7533, 10.5733, -3.6667],\n",
      "        [-8.7676, 10.6041, -4.0229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.1794,  5.4446,  7.2880, -9.0611, 10.1287, -3.6349],\n",
      "        [11.2237,  5.3359,  7.2486, -8.7726, 10.4740, -3.7637],\n",
      "        [10.9684,  5.5080,  7.0359, -8.8520, 10.1700, -3.5965],\n",
      "        [11.6428,  5.4986,  7.1167, -8.6656, 10.2722, -3.4992],\n",
      "        [11.1894,  5.4195,  6.9399, -8.7533, 10.5733, -3.6667],\n",
      "        [11.4736,  5.3985,  7.3228, -8.7676, 10.6041, -4.0229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9075533151626587\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4423, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4561,  5.0667,  7.1625],\n",
      "        [10.9233,  5.4172,  6.5834],\n",
      "        [11.2575,  5.3364,  7.1272],\n",
      "        [11.3423,  5.8198,  6.9891],\n",
      "        [11.2376,  5.3571,  7.1702],\n",
      "        [11.0938,  5.1234,  7.1904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8675, 10.3153, -3.9659],\n",
      "        [-8.8187, 10.0580, -3.8764],\n",
      "        [-8.9375, 10.1731, -3.6633],\n",
      "        [-8.6952, 10.2245, -3.9320],\n",
      "        [-8.8266, 10.4927, -3.9928],\n",
      "        [-8.9613, 10.4149, -3.9256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4561,  5.0667,  7.1625, -8.8675, 10.3153, -3.9659],\n",
      "        [10.9233,  5.4172,  6.5834, -8.8187, 10.0580, -3.8764],\n",
      "        [11.2575,  5.3364,  7.1272, -8.9375, 10.1731, -3.6633],\n",
      "        [11.3423,  5.8198,  6.9891, -8.6952, 10.2245, -3.9320],\n",
      "        [11.2376,  5.3571,  7.1702, -8.8266, 10.4927, -3.9928],\n",
      "        [11.0938,  5.1234,  7.1904, -8.9613, 10.4149, -3.9256]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9117187261581421\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3664, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3574,  5.2144,  7.2598],\n",
      "        [11.2709,  5.4101,  7.0443],\n",
      "        [11.0094,  5.3055,  7.1869],\n",
      "        [11.1238,  5.4410,  7.2875],\n",
      "        [11.3531,  5.1523,  7.3839],\n",
      "        [10.9602,  5.1727,  7.1630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.6460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6654, 10.0434, -3.7392],\n",
      "        [-8.4509, 10.3042, -3.8440],\n",
      "        [-8.9507, 10.5193, -3.8532],\n",
      "        [-8.4726, 10.0514, -3.6663],\n",
      "        [-8.5596, 10.3827, -4.1875],\n",
      "        [-8.9140, 10.3153, -3.6109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3574,  5.2144,  7.2598, -8.6654, 10.0434, -3.7392],\n",
      "        [11.2709,  5.4101,  7.0443, -8.4509, 10.3042, -3.8440],\n",
      "        [11.0094,  5.3055,  7.1869, -8.9507, 10.5193, -3.8532],\n",
      "        [11.1238,  5.4410,  7.2875, -8.4726, 10.0514, -3.6663],\n",
      "        [11.3531,  5.1523,  7.3839, -8.5596, 10.3827, -4.1875],\n",
      "        [10.9602,  5.1727,  7.1630, -8.9140, 10.3153, -3.6109]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.905238926410675\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9987, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.1119,  5.4634,  7.2440],\n",
      "        [11.4455,  5.2976,  7.3214],\n",
      "        [11.2112,  5.3117,  7.3052],\n",
      "        [11.2762,  5.3268,  7.0860],\n",
      "        [11.5539,  5.4280,  7.0839],\n",
      "        [11.2662,  5.5182,  7.3163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.8079, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.7986, 10.5932, -3.8112],\n",
      "        [-8.8306, 10.5383, -4.0556],\n",
      "        [-8.8183, 10.6219, -3.7662],\n",
      "        [-9.1411, 10.4150, -4.0438],\n",
      "        [-8.7047, 10.3814, -3.8797],\n",
      "        [-8.8099, 10.4075, -3.7511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.1119,  5.4634,  7.2440, -8.7986, 10.5932, -3.8112],\n",
      "        [11.4455,  5.2976,  7.3214, -8.8306, 10.5383, -4.0556],\n",
      "        [11.2112,  5.3117,  7.3052, -8.8183, 10.6219, -3.7662],\n",
      "        [11.2762,  5.3268,  7.0860, -9.1411, 10.4150, -4.0438],\n",
      "        [11.5539,  5.4280,  7.0839, -8.7047, 10.3814, -3.8797],\n",
      "        [11.2662,  5.5182,  7.3163, -8.8099, 10.4075, -3.7511]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9109606742858887\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4041,  5.2265,  6.9176],\n",
      "        [11.0492,  5.1118,  7.0239],\n",
      "        [11.3039,  5.3993,  7.3243],\n",
      "        [11.3231,  5.7877,  7.0791],\n",
      "        [11.3742,  5.6133,  7.3687],\n",
      "        [11.0543,  5.4697,  7.1014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.0962, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.3515, 10.0850, -3.8925],\n",
      "        [-9.0982, 10.2477, -3.9452],\n",
      "        [-9.1750,  9.9495, -3.9441],\n",
      "        [-8.7075, 10.5261, -4.1464],\n",
      "        [-8.5310, 10.1178, -3.7473],\n",
      "        [-8.6779, 10.1079, -3.8771]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4041,  5.2265,  6.9176, -8.3515, 10.0850, -3.8925],\n",
      "        [11.0492,  5.1118,  7.0239, -9.0982, 10.2477, -3.9452],\n",
      "        [11.3039,  5.3993,  7.3243, -9.1750,  9.9495, -3.9441],\n",
      "        [11.3231,  5.7877,  7.0791, -8.7075, 10.5261, -4.1464],\n",
      "        [11.3742,  5.6133,  7.3687, -8.5310, 10.1178, -3.7473],\n",
      "        [11.0543,  5.4697,  7.1014, -8.6779, 10.1079, -3.8771]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.8972737193107605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9548, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3136,  5.3816,  7.3707],\n",
      "        [11.2173,  5.6458,  6.9762],\n",
      "        [11.3418,  5.5024,  7.4098],\n",
      "        [11.3496,  5.4331,  7.0098],\n",
      "        [11.2791,  5.4462,  7.2574],\n",
      "        [11.1890,  5.4947,  7.1039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9262, 10.4029, -4.1672],\n",
      "        [-8.8973, 10.2515, -4.2233],\n",
      "        [-8.7176, 10.0808, -3.9038],\n",
      "        [-9.4557, 10.2686, -4.1186],\n",
      "        [-8.9586, 10.1745, -3.6829],\n",
      "        [-8.8089, 10.1780, -3.9394]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3136,  5.3816,  7.3707, -8.9262, 10.4029, -4.1672],\n",
      "        [11.2173,  5.6458,  6.9762, -8.8973, 10.2515, -4.2233],\n",
      "        [11.3418,  5.5024,  7.4098, -8.7176, 10.0808, -3.9038],\n",
      "        [11.3496,  5.4331,  7.0098, -9.4557, 10.2686, -4.1186],\n",
      "        [11.2791,  5.4462,  7.2574, -8.9586, 10.1745, -3.6829],\n",
      "        [11.1890,  5.4947,  7.1039, -8.8089, 10.1780, -3.9394]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9213467240333557\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.5670,  5.4439,  7.4056],\n",
      "        [11.3540,  5.2830,  7.2467],\n",
      "        [11.4194,  5.3798,  6.8338],\n",
      "        [11.4568,  5.3864,  7.2401],\n",
      "        [11.3177,  5.5394,  7.1876],\n",
      "        [11.1718,  5.1852,  7.1040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.1720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.8941, 10.1987, -4.0419],\n",
      "        [-8.7965, 10.0019, -3.9455],\n",
      "        [-9.0697, 10.6248, -4.0341],\n",
      "        [-9.0241, 10.4265, -3.8706],\n",
      "        [-8.7974, 10.1682, -3.8268],\n",
      "        [-9.0000, 10.2569, -3.9335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.5670,  5.4439,  7.4056, -8.8941, 10.1987, -4.0419],\n",
      "        [11.3540,  5.2830,  7.2467, -8.7965, 10.0019, -3.9455],\n",
      "        [11.4194,  5.3798,  6.8338, -9.0697, 10.6248, -4.0341],\n",
      "        [11.4568,  5.3864,  7.2401, -9.0241, 10.4265, -3.8706],\n",
      "        [11.3177,  5.5394,  7.1876, -8.7974, 10.1682, -3.8268],\n",
      "        [11.1718,  5.1852,  7.1040, -9.0000, 10.2569, -3.9335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9278919696807861\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7040, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4326,  5.3521,  7.3082],\n",
      "        [11.2425,  5.7893,  7.0191],\n",
      "        [11.3843,  5.8668,  7.0935],\n",
      "        [11.4295,  4.9395,  7.0093],\n",
      "        [11.2019,  5.1551,  6.9804],\n",
      "        [11.2292,  5.2663,  7.1904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2697, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9734, 10.4675, -3.8189],\n",
      "        [-9.0125, 10.3714, -3.8481],\n",
      "        [-8.9922, 10.7560, -3.7081],\n",
      "        [-8.8831, 10.3728, -3.6790],\n",
      "        [-9.0363, 10.1615, -3.8719],\n",
      "        [-9.2164, 10.8158, -3.9061]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4326,  5.3521,  7.3082, -8.9734, 10.4675, -3.8189],\n",
      "        [11.2425,  5.7893,  7.0191, -9.0125, 10.3714, -3.8481],\n",
      "        [11.3843,  5.8668,  7.0935, -8.9922, 10.7560, -3.7081],\n",
      "        [11.4295,  4.9395,  7.0093, -8.8831, 10.3728, -3.6790],\n",
      "        [11.2019,  5.1551,  6.9804, -9.0363, 10.1615, -3.8719],\n",
      "        [11.2292,  5.2663,  7.1904, -9.2164, 10.8158, -3.9061]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9247371554374695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4503,  5.7143,  7.1230],\n",
      "        [11.2303,  5.6283,  7.0501],\n",
      "        [11.4267,  5.5130,  7.2011],\n",
      "        [11.3804,  5.8107,  6.8831],\n",
      "        [11.6157,  5.4681,  7.1674],\n",
      "        [11.5301,  5.5331,  7.0897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3832, 10.2103, -4.1834],\n",
      "        [-9.1676, 10.4574, -4.1615],\n",
      "        [-9.3136, 10.4955, -4.1178],\n",
      "        [-8.7494, 10.4035, -3.7686],\n",
      "        [-9.0472, 10.6736, -3.9028],\n",
      "        [-9.3069, 10.3668, -4.0940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4503,  5.7143,  7.1230, -9.3832, 10.2103, -4.1834],\n",
      "        [11.2303,  5.6283,  7.0501, -9.1676, 10.4574, -4.1615],\n",
      "        [11.4267,  5.5130,  7.2011, -9.3136, 10.4955, -4.1178],\n",
      "        [11.3804,  5.8107,  6.8831, -8.7494, 10.4035, -3.7686],\n",
      "        [11.6157,  5.4681,  7.1674, -9.0472, 10.6736, -3.9028],\n",
      "        [11.5301,  5.5331,  7.0897, -9.3069, 10.3668, -4.0940]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9290875792503357\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8747, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.0587,  5.3621,  7.1216],\n",
      "        [11.4148,  5.3724,  7.3323],\n",
      "        [11.1156,  5.4858,  7.3334],\n",
      "        [11.3493,  5.5444,  7.2542],\n",
      "        [10.7904,  5.6742,  6.9014],\n",
      "        [10.9843,  5.3565,  6.7986]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.7501, 10.2423, -3.6605],\n",
      "        [-8.7842, 10.4708, -3.8862],\n",
      "        [-9.0422, 10.3484, -4.2699],\n",
      "        [-9.2257, 10.2501, -4.0372],\n",
      "        [-9.2148, 10.7713, -4.0919],\n",
      "        [-8.4810, 10.0043, -3.7751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.0587,  5.3621,  7.1216, -8.7501, 10.2423, -3.6605],\n",
      "        [11.4148,  5.3724,  7.3323, -8.7842, 10.4708, -3.8862],\n",
      "        [11.1156,  5.4858,  7.3334, -9.0422, 10.3484, -4.2699],\n",
      "        [11.3493,  5.5444,  7.2542, -9.2257, 10.2501, -4.0372],\n",
      "        [10.7904,  5.6742,  6.9014, -9.2148, 10.7713, -4.0919],\n",
      "        [10.9843,  5.3565,  6.7986, -8.4810, 10.0043, -3.7751]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9018574357032776\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.8306,  5.8381,  7.3215],\n",
      "        [11.3080,  5.5236,  7.2662],\n",
      "        [11.8240,  5.5147,  7.4992],\n",
      "        [11.5448,  5.6000,  7.1459],\n",
      "        [11.7571,  5.3594,  7.0026],\n",
      "        [11.4742,  5.7035,  6.9799]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.6336, 10.7207, -3.8952],\n",
      "        [-9.0742, 10.7694, -4.0229],\n",
      "        [-8.7881, 10.1223, -3.6797],\n",
      "        [-9.3194, 10.5093, -4.0676],\n",
      "        [-8.9797, 10.8768, -3.7475],\n",
      "        [-8.9081, 10.6420, -3.9914]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.8306,  5.8381,  7.3215, -8.6336, 10.7207, -3.8952],\n",
      "        [11.3080,  5.5236,  7.2662, -9.0742, 10.7694, -4.0229],\n",
      "        [11.8240,  5.5147,  7.4992, -8.7881, 10.1223, -3.6797],\n",
      "        [11.5448,  5.6000,  7.1459, -9.3194, 10.5093, -4.0676],\n",
      "        [11.7571,  5.3594,  7.0026, -8.9797, 10.8768, -3.7475],\n",
      "        [11.4742,  5.7035,  6.9799, -8.9081, 10.6420, -3.9914]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9462361335754395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3471,  5.3480,  7.2852],\n",
      "        [11.0144,  5.6314,  7.0544],\n",
      "        [11.2501,  5.4564,  7.0931],\n",
      "        [11.4610,  5.3352,  7.6371],\n",
      "        [11.3164,  5.4190,  7.3145],\n",
      "        [11.3181,  5.4258,  7.4116]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.9706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0005, 10.5778, -4.0595],\n",
      "        [-8.5719, 10.0880, -3.8013],\n",
      "        [-8.9269, 10.4170, -3.7607],\n",
      "        [-9.0785, 10.3841, -3.8576],\n",
      "        [-8.9891, 10.5929, -4.2292],\n",
      "        [-8.8106, 10.3019, -4.1226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3471,  5.3480,  7.2852, -9.0005, 10.5778, -4.0595],\n",
      "        [11.0144,  5.6314,  7.0544, -8.5719, 10.0880, -3.8013],\n",
      "        [11.2501,  5.4564,  7.0931, -8.9269, 10.4170, -3.7607],\n",
      "        [11.4610,  5.3352,  7.6371, -9.0785, 10.3841, -3.8576],\n",
      "        [11.3164,  5.4190,  7.3145, -8.9891, 10.5929, -4.2292],\n",
      "        [11.3181,  5.4258,  7.4116, -8.8106, 10.3019, -4.1226]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9269989132881165\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.1490,  5.4537,  7.4706],\n",
      "        [11.4198,  5.2799,  6.9511],\n",
      "        [11.4028,  5.1918,  7.4515],\n",
      "        [11.1648,  5.7134,  7.2890],\n",
      "        [11.5179,  5.6603,  7.3764],\n",
      "        [11.3473,  5.2477,  7.2511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.7769, 10.1276, -4.1376],\n",
      "        [-9.0861, 10.3568, -3.6267],\n",
      "        [-8.9690, 10.3158, -4.1024],\n",
      "        [-8.9622, 10.0709, -3.9294],\n",
      "        [-8.7440, 10.6115, -3.8965],\n",
      "        [-8.7469,  9.8871, -3.9688]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.1490,  5.4537,  7.4706, -8.7769, 10.1276, -4.1376],\n",
      "        [11.4198,  5.2799,  6.9511, -9.0861, 10.3568, -3.6267],\n",
      "        [11.4028,  5.1918,  7.4515, -8.9690, 10.3158, -4.1024],\n",
      "        [11.1648,  5.7134,  7.2890, -8.9622, 10.0709, -3.9294],\n",
      "        [11.5179,  5.6603,  7.3764, -8.7440, 10.6115, -3.8965],\n",
      "        [11.3473,  5.2477,  7.2511, -8.7469,  9.8871, -3.9688]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.91706383228302\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3860,  5.5748,  7.3087],\n",
      "        [11.6021,  5.7860,  7.4468],\n",
      "        [11.3904,  5.3250,  6.9551],\n",
      "        [11.4651,  5.5101,  7.3397],\n",
      "        [11.4607,  5.4323,  7.3560],\n",
      "        [11.3618,  5.5766,  7.2867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.1433, 10.1051, -3.8015],\n",
      "        [-9.4309, 10.4890, -4.0762],\n",
      "        [-9.0707, 10.5422, -4.1693],\n",
      "        [-8.8579, 10.3114, -4.2538],\n",
      "        [-8.8517, 10.3562, -4.0421],\n",
      "        [-9.2446, 10.3508, -4.1722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3860,  5.5748,  7.3087, -9.1433, 10.1051, -3.8015],\n",
      "        [11.6021,  5.7860,  7.4468, -9.4309, 10.4890, -4.0762],\n",
      "        [11.3904,  5.3250,  6.9551, -9.0707, 10.5422, -4.1693],\n",
      "        [11.4651,  5.5101,  7.3397, -8.8579, 10.3114, -4.2538],\n",
      "        [11.4607,  5.4323,  7.3560, -8.8517, 10.3562, -4.0421],\n",
      "        [11.3618,  5.5766,  7.2867, -9.2446, 10.3508, -4.1722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9261730909347534\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4002,  5.3273,  7.2865],\n",
      "        [11.6853,  5.4070,  7.6194],\n",
      "        [11.7796,  5.5993,  7.2656],\n",
      "        [11.2220,  5.7336,  7.1938],\n",
      "        [11.3236,  5.7326,  7.2311],\n",
      "        [11.5863,  5.7854,  7.0723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.7903, 10.3260, -3.9818],\n",
      "        [-8.6306, 10.5108, -3.8363],\n",
      "        [-9.1512, 10.3946, -3.8795],\n",
      "        [-9.0893, 10.4629, -4.0495],\n",
      "        [-8.9243, 10.7277, -3.9905],\n",
      "        [-8.9163, 10.7644, -3.8592]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4002,  5.3273,  7.2865, -8.7903, 10.3260, -3.9818],\n",
      "        [11.6853,  5.4070,  7.6194, -8.6306, 10.5108, -3.8363],\n",
      "        [11.7796,  5.5993,  7.2656, -9.1512, 10.3946, -3.8795],\n",
      "        [11.2220,  5.7336,  7.1938, -9.0893, 10.4629, -4.0495],\n",
      "        [11.3236,  5.7326,  7.2311, -8.9243, 10.7277, -3.9905],\n",
      "        [11.5863,  5.7854,  7.0723, -8.9163, 10.7644, -3.8592]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9233357906341553\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4781,  5.5329,  7.4217],\n",
      "        [11.6264,  5.5907,  7.5048],\n",
      "        [11.1986,  5.2385,  7.2949],\n",
      "        [11.5024,  5.6950,  7.3712],\n",
      "        [11.3594,  5.3274,  7.2534],\n",
      "        [11.1926,  5.4144,  7.2476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9231, 10.4463, -4.0845],\n",
      "        [-9.3383, 10.5914, -3.9529],\n",
      "        [-9.0891, 10.6698, -4.2974],\n",
      "        [-9.3450, 10.7017, -4.0340],\n",
      "        [-8.7096, 10.1282, -4.1536],\n",
      "        [-8.7816, 10.4232, -3.9191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4781,  5.5329,  7.4217, -8.9231, 10.4463, -4.0845],\n",
      "        [11.6264,  5.5907,  7.5048, -9.3383, 10.5914, -3.9529],\n",
      "        [11.1986,  5.2385,  7.2949, -9.0891, 10.6698, -4.2974],\n",
      "        [11.5024,  5.6950,  7.3712, -9.3450, 10.7017, -4.0340],\n",
      "        [11.3594,  5.3274,  7.2534, -8.7096, 10.1282, -4.1536],\n",
      "        [11.1926,  5.4144,  7.2476, -8.7816, 10.4232, -3.9191]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9365471005439758\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0311, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.2149,  5.1305,  7.0942],\n",
      "        [11.8232,  5.6494,  7.4053],\n",
      "        [11.5266,  5.6827,  7.2067],\n",
      "        [11.4421,  5.4445,  7.2861],\n",
      "        [11.4821,  5.7159,  7.3968],\n",
      "        [11.5940,  5.4223,  7.3215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4203, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9372, 10.4077, -4.1029],\n",
      "        [-8.9691, 11.0709, -4.0638],\n",
      "        [-9.1940, 10.5281, -4.0586],\n",
      "        [-8.8399, 10.2816, -3.7059],\n",
      "        [-8.8525, 10.6176, -3.9902],\n",
      "        [-8.8976, 10.4818, -3.9501]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.2149,  5.1305,  7.0942, -8.9372, 10.4077, -4.1029],\n",
      "        [11.8232,  5.6494,  7.4053, -8.9691, 11.0709, -4.0638],\n",
      "        [11.5266,  5.6827,  7.2067, -9.1940, 10.5281, -4.0586],\n",
      "        [11.4421,  5.4445,  7.2861, -8.8399, 10.2816, -3.7059],\n",
      "        [11.4821,  5.7159,  7.3968, -8.8525, 10.6176, -3.9902],\n",
      "        [11.5940,  5.4223,  7.3215, -8.8976, 10.4818, -3.9501]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9150685667991638\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7183,  5.4376,  7.2582],\n",
      "        [11.0980,  5.6737,  7.2999],\n",
      "        [11.1064,  5.3972,  7.3950],\n",
      "        [11.4496,  5.6806,  7.2152],\n",
      "        [11.7311,  5.4748,  7.2209],\n",
      "        [11.4750,  5.2688,  7.2768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.3668, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2371, 10.9721, -4.2205],\n",
      "        [-9.0276, 10.6122, -4.0265],\n",
      "        [-9.1399, 10.6998, -3.9350],\n",
      "        [-8.9307, 10.4801, -4.1827],\n",
      "        [-9.0502, 10.4662, -3.9779],\n",
      "        [-8.9176, 10.4355, -4.3059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7183,  5.4376,  7.2582, -9.2371, 10.9721, -4.2205],\n",
      "        [11.0980,  5.6737,  7.2999, -9.0276, 10.6122, -4.0265],\n",
      "        [11.1064,  5.3972,  7.3950, -9.1399, 10.6998, -3.9350],\n",
      "        [11.4496,  5.6806,  7.2152, -8.9307, 10.4801, -4.1827],\n",
      "        [11.7311,  5.4748,  7.2209, -9.0502, 10.4662, -3.9779],\n",
      "        [11.4750,  5.2688,  7.2768, -8.9176, 10.4355, -4.3059]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9539118409156799\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0357, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3936,  5.2850,  7.2298],\n",
      "        [11.4036,  5.7174,  7.2737],\n",
      "        [11.6135,  5.3576,  7.2777],\n",
      "        [11.5383,  5.5462,  7.6166],\n",
      "        [11.5263,  5.5335,  7.4211],\n",
      "        [11.5109,  5.7092,  7.5347]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.0733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.1902, 10.6652, -4.0331],\n",
      "        [-9.1053, 10.5247, -4.0467],\n",
      "        [-8.7487, 10.1741, -3.5815],\n",
      "        [-9.2357, 10.4820, -3.9584],\n",
      "        [-9.1347, 10.6493, -4.2751],\n",
      "        [-8.9851, 10.2364, -4.0648]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3936,  5.2850,  7.2298, -9.1902, 10.6652, -4.0331],\n",
      "        [11.4036,  5.7174,  7.2737, -9.1053, 10.5247, -4.0467],\n",
      "        [11.6135,  5.3576,  7.2777, -8.7487, 10.1741, -3.5815],\n",
      "        [11.5383,  5.5462,  7.6166, -9.2357, 10.4820, -3.9584],\n",
      "        [11.5263,  5.5335,  7.4211, -9.1347, 10.6493, -4.2751],\n",
      "        [11.5109,  5.7092,  7.5347, -8.9851, 10.2364, -4.0648]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.934619128704071\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7274,  5.7346,  7.4420],\n",
      "        [11.5439,  5.6476,  6.9046],\n",
      "        [11.5664,  5.7299,  7.3329],\n",
      "        [11.6758,  5.7250,  7.2173],\n",
      "        [11.3607,  5.6294,  7.1609],\n",
      "        [11.4655,  5.4906,  7.2768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0875, 10.6799, -4.1495],\n",
      "        [-9.1967, 10.5444, -3.7606],\n",
      "        [-9.0049, 10.6597, -4.4658],\n",
      "        [-9.0053, 10.5418, -3.7230],\n",
      "        [-9.0463, 10.9276, -4.1196],\n",
      "        [-9.0610, 10.5604, -3.9970]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7274,  5.7346,  7.4420, -9.0875, 10.6799, -4.1495],\n",
      "        [11.5439,  5.6476,  6.9046, -9.1967, 10.5444, -3.7606],\n",
      "        [11.5664,  5.7299,  7.3329, -9.0049, 10.6597, -4.4658],\n",
      "        [11.6758,  5.7250,  7.2173, -9.0053, 10.5418, -3.7230],\n",
      "        [11.3607,  5.6294,  7.1609, -9.0463, 10.9276, -4.1196],\n",
      "        [11.4655,  5.4906,  7.2768, -9.0610, 10.5604, -3.9970]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9567091464996338\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6905, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4837,  5.8896,  7.5555],\n",
      "        [11.8652,  5.5160,  7.4299],\n",
      "        [11.2574,  5.5308,  7.3476],\n",
      "        [11.6817,  5.8122,  7.6234],\n",
      "        [11.5719,  5.8077,  7.4039],\n",
      "        [11.6293,  5.3630,  7.3677]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4983, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.1999, 10.7670, -4.1343],\n",
      "        [-9.1690, 10.5321, -4.2268],\n",
      "        [-9.2946, 10.6603, -3.8752],\n",
      "        [-9.5660, 10.6372, -4.1416],\n",
      "        [-8.9826, 10.1811, -4.2487],\n",
      "        [-9.1869, 10.8221, -3.8794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4837,  5.8896,  7.5555, -9.1999, 10.7670, -4.1343],\n",
      "        [11.8652,  5.5160,  7.4299, -9.1690, 10.5321, -4.2268],\n",
      "        [11.2574,  5.5308,  7.3476, -9.2946, 10.6603, -3.8752],\n",
      "        [11.6817,  5.8122,  7.6234, -9.5660, 10.6372, -4.1416],\n",
      "        [11.5719,  5.8077,  7.4039, -8.9826, 10.1811, -4.2487],\n",
      "        [11.6293,  5.3630,  7.3677, -9.1869, 10.8221, -3.8794]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9565967917442322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0958, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6670,  5.5631,  7.4454],\n",
      "        [11.1992,  5.6692,  7.2740],\n",
      "        [11.9227,  5.1081,  7.6705],\n",
      "        [11.3495,  5.6885,  7.5498],\n",
      "        [11.3924,  5.7609,  7.6350],\n",
      "        [11.3437,  5.8982,  7.1234]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9482, 10.2897, -4.2107],\n",
      "        [-9.4629, 10.7579, -4.0888],\n",
      "        [-9.0318, 10.5162, -4.0875],\n",
      "        [-9.1840, 10.3507, -4.0474],\n",
      "        [-9.1151, 10.7828, -3.8857],\n",
      "        [-9.3228, 10.6940, -3.9364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6670,  5.5631,  7.4454, -8.9482, 10.2897, -4.2107],\n",
      "        [11.1992,  5.6692,  7.2740, -9.4629, 10.7579, -4.0888],\n",
      "        [11.9227,  5.1081,  7.6705, -9.0318, 10.5162, -4.0875],\n",
      "        [11.3495,  5.6885,  7.5498, -9.1840, 10.3507, -4.0474],\n",
      "        [11.3924,  5.7609,  7.6350, -9.1151, 10.7828, -3.8857],\n",
      "        [11.3437,  5.8982,  7.1234, -9.3228, 10.6940, -3.9364]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9461562633514404\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4117, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7187,  5.9345,  7.4230],\n",
      "        [11.6673,  5.3638,  7.4730],\n",
      "        [11.1783,  5.8441,  7.0689],\n",
      "        [11.5826,  5.5187,  7.4407],\n",
      "        [11.5185,  5.4366,  7.0424],\n",
      "        [11.4231,  5.5407,  7.1424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0970, 10.6265, -4.3249],\n",
      "        [-9.0564, 10.4834, -4.2201],\n",
      "        [-9.5063, 10.4318, -4.2052],\n",
      "        [-9.0685, 10.5131, -4.4009],\n",
      "        [-9.0821, 10.4498, -4.2164],\n",
      "        [-9.4791, 10.5778, -4.2325]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7187,  5.9345,  7.4230, -9.0970, 10.6265, -4.3249],\n",
      "        [11.6673,  5.3638,  7.4730, -9.0564, 10.4834, -4.2201],\n",
      "        [11.1783,  5.8441,  7.0689, -9.5063, 10.4318, -4.2052],\n",
      "        [11.5826,  5.5187,  7.4407, -9.0685, 10.5131, -4.4009],\n",
      "        [11.5185,  5.4366,  7.0424, -9.0821, 10.4498, -4.2164],\n",
      "        [11.4231,  5.5407,  7.1424, -9.4791, 10.5778, -4.2325]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.960560142993927\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3749, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7472,  5.7978,  7.6550],\n",
      "        [11.6172,  5.5201,  7.2381],\n",
      "        [11.6085,  5.8756,  7.2555],\n",
      "        [11.5629,  5.6643,  7.5083],\n",
      "        [11.6937,  5.8111,  7.3471],\n",
      "        [11.7755,  5.6303,  7.5902]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9535, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2790, 10.6700, -4.2227],\n",
      "        [-9.2568, 10.5165, -3.7057],\n",
      "        [-8.7859, 10.6144, -3.8133],\n",
      "        [-9.1893, 10.4066, -4.1043],\n",
      "        [-9.0318, 10.2956, -4.1067],\n",
      "        [-9.0303, 10.1895, -4.3275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7472,  5.7978,  7.6550, -9.2790, 10.6700, -4.2227],\n",
      "        [11.6172,  5.5201,  7.2381, -9.2568, 10.5165, -3.7057],\n",
      "        [11.6085,  5.8756,  7.2555, -8.7859, 10.6144, -3.8133],\n",
      "        [11.5629,  5.6643,  7.5083, -9.1893, 10.4066, -4.1043],\n",
      "        [11.6937,  5.8111,  7.3471, -9.0318, 10.2956, -4.1067],\n",
      "        [11.7755,  5.6303,  7.5902, -9.0303, 10.1895, -4.3275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9686557650566101\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4670, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4914,  5.7609,  7.1448],\n",
      "        [11.7500,  5.5863,  7.1831],\n",
      "        [11.6880,  5.9084,  7.5592],\n",
      "        [11.6456,  5.6844,  7.7366],\n",
      "        [11.4566,  5.6237,  7.4641],\n",
      "        [11.5770,  5.8928,  7.1574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.4284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0451, 10.5299, -3.8784],\n",
      "        [-9.2672, 11.0351, -4.0262],\n",
      "        [-9.0136, 10.4215, -3.9184],\n",
      "        [-9.1069, 10.4269, -4.2750],\n",
      "        [-9.2093, 10.3099, -4.1419],\n",
      "        [-9.1140, 10.3683, -3.9916]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4914,  5.7609,  7.1448, -9.0451, 10.5299, -3.8784],\n",
      "        [11.7500,  5.5863,  7.1831, -9.2672, 11.0351, -4.0262],\n",
      "        [11.6880,  5.9084,  7.5592, -9.0136, 10.4215, -3.9184],\n",
      "        [11.6456,  5.6844,  7.7366, -9.1069, 10.4269, -4.2750],\n",
      "        [11.4566,  5.6237,  7.4641, -9.2093, 10.3099, -4.1419],\n",
      "        [11.5770,  5.8928,  7.1574, -9.1140, 10.3683, -3.9916]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9408336877822876\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9579,  5.5802,  7.6318],\n",
      "        [11.3881,  5.5267,  7.2550],\n",
      "        [11.9699,  5.7075,  7.4488],\n",
      "        [11.4361,  5.6746,  7.1750],\n",
      "        [11.3281,  5.3998,  7.5880],\n",
      "        [11.1794,  5.4064,  7.1512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2193, 10.7276, -4.1838],\n",
      "        [-9.2552, 10.2747, -4.2299],\n",
      "        [-9.1683, 10.6209, -4.2621],\n",
      "        [-9.1191, 10.3125, -3.7364],\n",
      "        [-9.4975, 10.7806, -4.4958],\n",
      "        [-9.0150, 10.6309, -4.3795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9579,  5.5802,  7.6318, -9.2193, 10.7276, -4.1838],\n",
      "        [11.3881,  5.5267,  7.2550, -9.2552, 10.2747, -4.2299],\n",
      "        [11.9699,  5.7075,  7.4488, -9.1683, 10.6209, -4.2621],\n",
      "        [11.4361,  5.6746,  7.1750, -9.1191, 10.3125, -3.7364],\n",
      "        [11.3281,  5.3998,  7.5880, -9.4975, 10.7806, -4.4958],\n",
      "        [11.1794,  5.4064,  7.1512, -9.0150, 10.6309, -4.3795]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9737155437469482\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6718,  5.9004,  7.3596],\n",
      "        [11.3319,  5.5642,  7.3414],\n",
      "        [11.6035,  6.0800,  7.5896],\n",
      "        [11.8020,  5.9702,  7.1894],\n",
      "        [11.6292,  5.2875,  7.1719],\n",
      "        [11.5615,  5.4008,  7.3294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2713, 10.5578, -3.8967],\n",
      "        [-9.0768, 10.6881, -4.4849],\n",
      "        [-9.2305, 10.3901, -4.2363],\n",
      "        [-9.1041, 10.6020, -4.2450],\n",
      "        [-9.0552, 10.6304, -4.5083],\n",
      "        [-9.1290, 10.4107, -4.3498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6718,  5.9004,  7.3596, -9.2713, 10.5578, -3.8967],\n",
      "        [11.3319,  5.5642,  7.3414, -9.0768, 10.6881, -4.4849],\n",
      "        [11.6035,  6.0800,  7.5896, -9.2305, 10.3901, -4.2363],\n",
      "        [11.8020,  5.9702,  7.1894, -9.1041, 10.6020, -4.2450],\n",
      "        [11.6292,  5.2875,  7.1719, -9.0552, 10.6304, -4.5083],\n",
      "        [11.5615,  5.4008,  7.3294, -9.1290, 10.4107, -4.3498]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.958717942237854\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3086, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3539,  5.8560,  7.2662],\n",
      "        [11.6896,  5.4047,  7.3946],\n",
      "        [11.3243,  5.5233,  7.4091],\n",
      "        [11.8088,  5.8024,  7.3297],\n",
      "        [11.5239,  5.8283,  7.3977],\n",
      "        [11.6696,  5.6241,  7.3532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2907, 10.9728, -4.1630],\n",
      "        [-9.2557, 10.9685, -4.4646],\n",
      "        [-9.3379, 10.5951, -4.4146],\n",
      "        [-8.8743, 10.5608, -4.2143],\n",
      "        [-9.3536, 10.7376, -4.2880],\n",
      "        [-9.2651, 10.9155, -4.1137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3539,  5.8560,  7.2662, -9.2907, 10.9728, -4.1630],\n",
      "        [11.6896,  5.4047,  7.3946, -9.2557, 10.9685, -4.4646],\n",
      "        [11.3243,  5.5233,  7.4091, -9.3379, 10.5951, -4.4146],\n",
      "        [11.8088,  5.8024,  7.3297, -8.8743, 10.5608, -4.2143],\n",
      "        [11.5239,  5.8283,  7.3977, -9.3536, 10.7376, -4.2880],\n",
      "        [11.6696,  5.6241,  7.3532, -9.2651, 10.9155, -4.1137]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9539746642112732\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4563,  5.9606,  7.6411],\n",
      "        [11.6014,  5.6702,  7.6124],\n",
      "        [11.6625,  5.5862,  7.3023],\n",
      "        [11.4166,  5.7519,  7.5246],\n",
      "        [11.6566,  5.4593,  7.3592],\n",
      "        [11.7012,  5.6249,  7.1513]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.5070, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2922, 10.5116, -3.9823],\n",
      "        [-9.3865, 10.3593, -4.1465],\n",
      "        [-9.3946, 10.8834, -4.1513],\n",
      "        [-9.0236, 10.8857, -4.1247],\n",
      "        [-9.2278, 10.7802, -4.3505],\n",
      "        [-9.1777, 10.8676, -4.2941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4563,  5.9606,  7.6411, -9.2922, 10.5116, -3.9823],\n",
      "        [11.6014,  5.6702,  7.6124, -9.3865, 10.3593, -4.1465],\n",
      "        [11.6625,  5.5862,  7.3023, -9.3946, 10.8834, -4.1513],\n",
      "        [11.4166,  5.7519,  7.5246, -9.0236, 10.8857, -4.1247],\n",
      "        [11.6566,  5.4593,  7.3592, -9.2278, 10.7802, -4.3505],\n",
      "        [11.7012,  5.6249,  7.1513, -9.1777, 10.8676, -4.2941]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9602506160736084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0311, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.5972,  5.7372,  7.4156],\n",
      "        [11.9223,  5.6842,  7.5787],\n",
      "        [11.8082,  5.5921,  7.2413],\n",
      "        [11.4334,  5.9295,  7.0880],\n",
      "        [11.9320,  5.6828,  7.3651],\n",
      "        [11.4371,  5.5833,  7.4242]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7533, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.1842, 10.9962, -4.3755],\n",
      "        [-9.2701, 10.8047, -4.3554],\n",
      "        [-8.9630, 10.8792, -4.3731],\n",
      "        [-9.4620, 10.8224, -4.1804],\n",
      "        [-9.0601, 10.8845, -4.1968],\n",
      "        [-9.3047, 10.7308, -4.0974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.5972,  5.7372,  7.4156, -9.1842, 10.9962, -4.3755],\n",
      "        [11.9223,  5.6842,  7.5787, -9.2701, 10.8047, -4.3554],\n",
      "        [11.8082,  5.5921,  7.2413, -8.9630, 10.8792, -4.3731],\n",
      "        [11.4334,  5.9295,  7.0880, -9.4620, 10.8224, -4.1804],\n",
      "        [11.9320,  5.6828,  7.3651, -9.0601, 10.8845, -4.1968],\n",
      "        [11.4371,  5.5833,  7.4242, -9.3047, 10.7308, -4.0974]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9656453132629395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.5386,  5.5621,  7.6303],\n",
      "        [11.6421,  6.0291,  7.3894],\n",
      "        [11.7775,  5.6259,  7.3813],\n",
      "        [11.5166,  5.6993,  7.6726],\n",
      "        [11.6199,  5.7822,  7.4623],\n",
      "        [11.4001,  5.6654,  7.5544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.5367, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.0367, 10.8044, -4.4182],\n",
      "        [-9.1280, 10.8840, -4.4237],\n",
      "        [-9.1257, 10.1878, -4.0236],\n",
      "        [-9.3200, 10.2263, -4.3316],\n",
      "        [-9.4424, 11.1312, -4.4744],\n",
      "        [-9.3940, 10.8331, -4.1441]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.5386,  5.5621,  7.6303, -9.0367, 10.8044, -4.4182],\n",
      "        [11.6421,  6.0291,  7.3894, -9.1280, 10.8840, -4.4237],\n",
      "        [11.7775,  5.6259,  7.3813, -9.1257, 10.1878, -4.0236],\n",
      "        [11.5166,  5.6993,  7.6726, -9.3200, 10.2263, -4.3316],\n",
      "        [11.6199,  5.7822,  7.4623, -9.4424, 11.1312, -4.4744],\n",
      "        [11.4001,  5.6654,  7.5544, -9.3940, 10.8331, -4.1441]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9624638557434082\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6434,  5.5521,  7.5067],\n",
      "        [11.6899,  5.7723,  7.4319],\n",
      "        [11.6719,  5.7061,  7.4098],\n",
      "        [11.6815,  6.0083,  7.4236],\n",
      "        [11.9539,  5.4412,  7.4244],\n",
      "        [11.5526,  5.3741,  7.4724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.8876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-8.9918, 11.0593, -3.9773],\n",
      "        [-9.1226, 10.9603, -4.6155],\n",
      "        [-9.3453, 10.8651, -4.2800],\n",
      "        [-9.3699, 10.7201, -4.2527],\n",
      "        [-9.0954, 10.6427, -4.2801],\n",
      "        [-9.2799, 10.6766, -4.2204]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6434,  5.5521,  7.5067, -8.9918, 11.0593, -3.9773],\n",
      "        [11.6899,  5.7723,  7.4319, -9.1226, 10.9603, -4.6155],\n",
      "        [11.6719,  5.7061,  7.4098, -9.3453, 10.8651, -4.2800],\n",
      "        [11.6815,  6.0083,  7.4236, -9.3699, 10.7201, -4.2527],\n",
      "        [11.9539,  5.4412,  7.4244, -9.0954, 10.6427, -4.2801],\n",
      "        [11.5526,  5.3741,  7.4724, -9.2799, 10.6766, -4.2204]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9647786021232605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6408,  5.8297,  7.3271],\n",
      "        [11.3551,  5.7939,  7.1206],\n",
      "        [11.6938,  5.7584,  7.0826],\n",
      "        [11.6713,  5.7281,  7.7115],\n",
      "        [11.5423,  5.8723,  7.5266],\n",
      "        [11.9271,  5.6934,  7.3274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1154, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2303, 10.5974, -4.6679],\n",
      "        [-9.4005, 10.8141, -4.2917],\n",
      "        [-9.2189, 10.6558, -3.9359],\n",
      "        [-9.4816, 10.9348, -4.3318],\n",
      "        [-9.2808, 10.6382, -4.4095],\n",
      "        [-9.2365, 10.4866, -4.1695]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6408,  5.8297,  7.3271, -9.2303, 10.5974, -4.6679],\n",
      "        [11.3551,  5.7939,  7.1206, -9.4005, 10.8141, -4.2917],\n",
      "        [11.6938,  5.7584,  7.0826, -9.2189, 10.6558, -3.9359],\n",
      "        [11.6713,  5.7281,  7.7115, -9.4816, 10.9348, -4.3318],\n",
      "        [11.5423,  5.8723,  7.5266, -9.2808, 10.6382, -4.4095],\n",
      "        [11.9271,  5.6934,  7.3274, -9.2365, 10.4866, -4.1695]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9638575315475464\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0426, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.3958,  5.3815,  7.6358],\n",
      "        [11.9626,  5.7543,  7.4646],\n",
      "        [11.8195,  5.7090,  7.2792],\n",
      "        [11.8139,  5.7198,  7.8094],\n",
      "        [11.9858,  5.9457,  7.4567],\n",
      "        [11.8554,  5.7015,  7.6544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3153, 10.7713, -4.2063],\n",
      "        [-9.0249, 10.5219, -3.9187],\n",
      "        [-9.6070, 10.7088, -4.2302],\n",
      "        [-9.5498, 10.7354, -4.1777],\n",
      "        [-9.2081, 10.6260, -4.2303],\n",
      "        [-9.4044, 10.8477, -4.1820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.3958,  5.3815,  7.6358, -9.3153, 10.7713, -4.2063],\n",
      "        [11.9626,  5.7543,  7.4646, -9.0249, 10.5219, -3.9187],\n",
      "        [11.8195,  5.7090,  7.2792, -9.6070, 10.7088, -4.2302],\n",
      "        [11.8139,  5.7198,  7.8094, -9.5498, 10.7354, -4.1777],\n",
      "        [11.9858,  5.9457,  7.4567, -9.2081, 10.6260, -4.2303],\n",
      "        [11.8554,  5.7015,  7.6544, -9.4044, 10.8477, -4.1820]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9595375061035156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7292, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9067,  5.7401,  7.6410],\n",
      "        [11.8191,  5.8070,  7.6444],\n",
      "        [11.8571,  5.9513,  7.7098],\n",
      "        [11.4731,  5.9671,  7.4453],\n",
      "        [11.7431,  5.7642,  7.3824],\n",
      "        [11.6136,  5.8270,  7.5830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.3916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5770, 10.5890, -3.9821],\n",
      "        [-8.9341, 10.6795, -4.2767],\n",
      "        [-9.3839, 10.8450, -3.9512],\n",
      "        [-9.0905, 10.5379, -4.3344],\n",
      "        [-9.1962, 10.7454, -4.3406],\n",
      "        [-9.2350, 10.9881, -4.6158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9067,  5.7401,  7.6410, -9.5770, 10.5890, -3.9821],\n",
      "        [11.8191,  5.8070,  7.6444, -8.9341, 10.6795, -4.2767],\n",
      "        [11.8571,  5.9513,  7.7098, -9.3839, 10.8450, -3.9512],\n",
      "        [11.4731,  5.9671,  7.4453, -9.0905, 10.5379, -4.3344],\n",
      "        [11.7431,  5.7642,  7.3824, -9.1962, 10.7454, -4.3406],\n",
      "        [11.6136,  5.8270,  7.5830, -9.2350, 10.9881, -4.6158]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9816875457763672\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9179,  5.9861,  7.7637],\n",
      "        [11.6522,  5.6575,  7.6891],\n",
      "        [11.7756,  5.7752,  7.7586],\n",
      "        [11.7807,  5.6788,  7.3370],\n",
      "        [11.8639,  5.7528,  7.1473],\n",
      "        [11.8301,  5.7504,  7.2590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3730, 10.6984, -4.0802],\n",
      "        [-9.3132, 10.7999, -4.4468],\n",
      "        [-9.1804, 11.1179, -4.6471],\n",
      "        [-9.1550, 10.6907, -4.2147],\n",
      "        [-9.2166, 10.7056, -4.3215],\n",
      "        [-9.4109, 10.7284, -4.0030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9179,  5.9861,  7.7637, -9.3730, 10.6984, -4.0802],\n",
      "        [11.6522,  5.6575,  7.6891, -9.3132, 10.7999, -4.4468],\n",
      "        [11.7756,  5.7752,  7.7586, -9.1804, 11.1179, -4.6471],\n",
      "        [11.7807,  5.6788,  7.3370, -9.1550, 10.6907, -4.2147],\n",
      "        [11.8639,  5.7528,  7.1473, -9.2166, 10.7056, -4.3215],\n",
      "        [11.8301,  5.7504,  7.2590, -9.4109, 10.7284, -4.0030]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9883502125740051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6294,  5.6588,  7.7694],\n",
      "        [11.9264,  5.9720,  7.3848],\n",
      "        [11.8355,  5.9598,  7.6337],\n",
      "        [11.7494,  5.5187,  7.4227],\n",
      "        [11.6684,  5.6420,  7.5038],\n",
      "        [12.1237,  5.9173,  7.6258]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.6200, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5904, 11.1771, -4.4022],\n",
      "        [-9.1096, 11.0554, -4.5065],\n",
      "        [-9.1414, 11.0928, -4.6349],\n",
      "        [-9.0515, 10.9485, -4.2678],\n",
      "        [-9.1959, 10.7800, -4.4231],\n",
      "        [-9.6802, 11.0565, -4.4162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6294,  5.6588,  7.7694, -9.5904, 11.1771, -4.4022],\n",
      "        [11.9264,  5.9720,  7.3848, -9.1096, 11.0554, -4.5065],\n",
      "        [11.8355,  5.9598,  7.6337, -9.1414, 11.0928, -4.6349],\n",
      "        [11.7494,  5.5187,  7.4227, -9.0515, 10.9485, -4.2678],\n",
      "        [11.6684,  5.6420,  7.5038, -9.1959, 10.7800, -4.4231],\n",
      "        [12.1237,  5.9173,  7.6258, -9.6802, 11.0565, -4.4162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9874228835105896\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0776, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7188,  5.6005,  7.2868],\n",
      "        [11.7144,  5.8444,  7.5336],\n",
      "        [11.6625,  5.6172,  7.5869],\n",
      "        [11.9045,  5.7988,  7.6725],\n",
      "        [11.6982,  5.6946,  7.4126],\n",
      "        [11.6644,  5.5985,  7.7207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3961, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2165, 10.5220, -4.5029],\n",
      "        [-9.4002, 10.6853, -3.9652],\n",
      "        [-9.3470, 10.8595, -4.6249],\n",
      "        [-9.0348, 10.7280, -4.4966],\n",
      "        [-9.4439, 10.6144, -4.2973],\n",
      "        [-9.4216, 10.9518, -4.4956]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7188,  5.6005,  7.2868, -9.2165, 10.5220, -4.5029],\n",
      "        [11.7144,  5.8444,  7.5336, -9.4002, 10.6853, -3.9652],\n",
      "        [11.6625,  5.6172,  7.5869, -9.3470, 10.8595, -4.6249],\n",
      "        [11.9045,  5.7988,  7.6725, -9.0348, 10.7280, -4.4966],\n",
      "        [11.6982,  5.6946,  7.4126, -9.4439, 10.6144, -4.2973],\n",
      "        [11.6644,  5.5985,  7.7207, -9.4216, 10.9518, -4.4956]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9636215567588806\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5861, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6660,  5.7325,  7.4800],\n",
      "        [11.7073,  5.4315,  8.0138],\n",
      "        [11.6268,  5.6822,  7.2220],\n",
      "        [11.8047,  6.0930,  7.7897],\n",
      "        [11.8627,  6.0187,  7.4693],\n",
      "        [11.9425,  5.9247,  7.6959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2441, 10.8482, -4.2685],\n",
      "        [-9.4370, 10.8135, -4.3729],\n",
      "        [-9.2302, 10.9877, -4.3077],\n",
      "        [-8.9119, 10.9043, -4.2907],\n",
      "        [-9.0659, 10.3740, -4.3779],\n",
      "        [-9.3598, 10.6227, -4.3009]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6660,  5.7325,  7.4800, -9.2441, 10.8482, -4.2685],\n",
      "        [11.7073,  5.4315,  8.0138, -9.4370, 10.8135, -4.3729],\n",
      "        [11.6268,  5.6822,  7.2220, -9.2302, 10.9877, -4.3077],\n",
      "        [11.8047,  6.0930,  7.7897, -8.9119, 10.9043, -4.2907],\n",
      "        [11.8627,  6.0187,  7.4693, -9.0659, 10.3740, -4.3779],\n",
      "        [11.9425,  5.9247,  7.6959, -9.3598, 10.6227, -4.3009]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9732592105865479\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9221,  5.7801,  7.4563],\n",
      "        [11.8485,  5.7543,  7.6875],\n",
      "        [11.7227,  5.8868,  7.4495],\n",
      "        [11.8094,  5.9688,  7.6053],\n",
      "        [12.1020,  6.0476,  7.7150],\n",
      "        [11.7046,  5.8031,  7.5605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5491, 10.7640, -4.3575],\n",
      "        [-9.3322, 11.1136, -4.5049],\n",
      "        [-9.1891, 10.6261, -4.4739],\n",
      "        [-9.0334, 10.6055, -4.3662],\n",
      "        [-9.4217, 11.0296, -4.5137],\n",
      "        [-9.1036, 10.8001, -4.2766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9221,  5.7801,  7.4563, -9.5491, 10.7640, -4.3575],\n",
      "        [11.8485,  5.7543,  7.6875, -9.3322, 11.1136, -4.5049],\n",
      "        [11.7227,  5.8868,  7.4495, -9.1891, 10.6261, -4.4739],\n",
      "        [11.8094,  5.9688,  7.6053, -9.0334, 10.6055, -4.3662],\n",
      "        [12.1020,  6.0476,  7.7150, -9.4217, 11.0296, -4.5137],\n",
      "        [11.7046,  5.8031,  7.5605, -9.1036, 10.8001, -4.2766]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9858912229537964\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7001,  5.9541,  7.9230],\n",
      "        [11.8384,  5.8566,  7.3274],\n",
      "        [11.7852,  6.2304,  7.8889],\n",
      "        [11.2647,  5.7788,  7.5100],\n",
      "        [11.8413,  6.0321,  7.6076],\n",
      "        [12.0925,  5.8723,  7.8780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.2445, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2442, 10.7468, -4.2374],\n",
      "        [-9.3265, 10.9459, -3.9814],\n",
      "        [-9.2613, 10.6303, -4.4119],\n",
      "        [-9.2846, 10.7128, -4.3862],\n",
      "        [-9.6644, 10.9747, -4.2572],\n",
      "        [-9.6474, 11.0283, -4.6592]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7001,  5.9541,  7.9230, -9.2442, 10.7468, -4.2374],\n",
      "        [11.8384,  5.8566,  7.3274, -9.3265, 10.9459, -3.9814],\n",
      "        [11.7852,  6.2304,  7.8889, -9.2613, 10.6303, -4.4119],\n",
      "        [11.2647,  5.7788,  7.5100, -9.2846, 10.7128, -4.3862],\n",
      "        [11.8413,  6.0321,  7.6076, -9.6644, 10.9747, -4.2572],\n",
      "        [12.0925,  5.8723,  7.8780, -9.6474, 11.0283, -4.6592]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9875597357749939\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.8585,  5.7435,  7.2253],\n",
      "        [11.8908,  5.5902,  7.7352],\n",
      "        [12.1455,  5.7604,  7.6936],\n",
      "        [11.9617,  6.0756,  7.5553],\n",
      "        [11.8088,  6.0571,  7.6074],\n",
      "        [11.5934,  5.6874,  7.7558]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.5274, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2268, 11.0534, -4.4873],\n",
      "        [-9.1120, 10.8235, -4.2927],\n",
      "        [-9.4595, 10.9412, -4.3500],\n",
      "        [-9.5157, 11.0320, -4.6644],\n",
      "        [-9.4150, 10.9776, -4.5373],\n",
      "        [-9.2668, 10.5512, -4.5258]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.8585,  5.7435,  7.2253, -9.2268, 11.0534, -4.4873],\n",
      "        [11.8908,  5.5902,  7.7352, -9.1120, 10.8235, -4.2927],\n",
      "        [12.1455,  5.7604,  7.6936, -9.4595, 10.9412, -4.3500],\n",
      "        [11.9617,  6.0756,  7.5553, -9.5157, 11.0320, -4.6644],\n",
      "        [11.8088,  6.0571,  7.6074, -9.4150, 10.9776, -4.5373],\n",
      "        [11.5934,  5.6874,  7.7558, -9.2668, 10.5512, -4.5258]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9799177646636963\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7692, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6561,  5.7938,  7.4493],\n",
      "        [11.8426,  5.6063,  7.6581],\n",
      "        [11.6250,  6.1456,  7.6328],\n",
      "        [11.9362,  5.9868,  7.5817],\n",
      "        [11.7324,  5.9464,  7.2268],\n",
      "        [11.6189,  6.0146,  7.6928]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.6826, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8156, 10.9878, -4.5859],\n",
      "        [-9.2914, 10.7557, -4.4873],\n",
      "        [-9.3633, 11.0426, -4.1613],\n",
      "        [-9.4613, 11.0888, -4.4653],\n",
      "        [-9.3172, 10.7314, -4.1891],\n",
      "        [-9.4406, 10.8041, -4.1788]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6561,  5.7938,  7.4493, -9.8156, 10.9878, -4.5859],\n",
      "        [11.8426,  5.6063,  7.6581, -9.2914, 10.7557, -4.4873],\n",
      "        [11.6250,  6.1456,  7.6328, -9.3633, 11.0426, -4.1613],\n",
      "        [11.9362,  5.9868,  7.5817, -9.4613, 11.0888, -4.4653],\n",
      "        [11.7324,  5.9464,  7.2268, -9.3172, 10.7314, -4.1891],\n",
      "        [11.6189,  6.0146,  7.6928, -9.4406, 10.8041, -4.1788]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-0.9872353076934814\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6856,  5.8854,  7.5402],\n",
      "        [11.6631,  5.6159,  7.6794],\n",
      "        [11.8376,  5.6358,  7.9128],\n",
      "        [11.7789,  5.9389,  7.6760],\n",
      "        [11.8000,  5.7342,  7.7280],\n",
      "        [11.5995,  5.8450,  7.3423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3830, 10.9354, -4.7370],\n",
      "        [-9.5459, 11.0802, -4.5841],\n",
      "        [-9.5295, 10.8520, -4.5193],\n",
      "        [-9.5062, 11.0396, -4.4305],\n",
      "        [-9.2428, 10.7710, -4.3450],\n",
      "        [-9.6826, 10.8775, -4.1590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6856,  5.8854,  7.5402, -9.3830, 10.9354, -4.7370],\n",
      "        [11.6631,  5.6159,  7.6794, -9.5459, 11.0802, -4.5841],\n",
      "        [11.8376,  5.6358,  7.9128, -9.5295, 10.8520, -4.5193],\n",
      "        [11.7789,  5.9389,  7.6760, -9.5062, 11.0396, -4.4305],\n",
      "        [11.8000,  5.7342,  7.7280, -9.2428, 10.7710, -4.3450],\n",
      "        [11.5995,  5.8450,  7.3423, -9.6826, 10.8775, -4.1590]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9863796234130859\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9177,  6.2208,  7.6755],\n",
      "        [12.0498,  5.9356,  7.5228],\n",
      "        [12.0124,  5.9380,  7.9360],\n",
      "        [11.8902,  6.0213,  7.4473],\n",
      "        [11.9084,  6.0496,  7.6753],\n",
      "        [11.8643,  5.8471,  7.6679]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6264, 11.0096, -4.4136],\n",
      "        [-9.1530, 11.0523, -4.5781],\n",
      "        [-9.2743, 10.6354, -4.6590],\n",
      "        [-9.6946, 10.9791, -4.4947],\n",
      "        [-9.4233, 10.8375, -4.4539],\n",
      "        [-9.6684, 10.7877, -4.4213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9177,  6.2208,  7.6755, -9.6264, 11.0096, -4.4136],\n",
      "        [12.0498,  5.9356,  7.5228, -9.1530, 11.0523, -4.5781],\n",
      "        [12.0124,  5.9380,  7.9360, -9.2743, 10.6354, -4.6590],\n",
      "        [11.8902,  6.0213,  7.4473, -9.6946, 10.9791, -4.4947],\n",
      "        [11.9084,  6.0496,  7.6753, -9.4233, 10.8375, -4.4539],\n",
      "        [11.8643,  5.8471,  7.6679, -9.6684, 10.7877, -4.4213]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0053811073303223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9571, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.6724,  6.1078,  7.9400],\n",
      "        [11.9637,  5.7655,  7.6634],\n",
      "        [12.1646,  6.1606,  7.5632],\n",
      "        [11.9099,  5.8340,  7.7456],\n",
      "        [11.6788,  6.0450,  7.6101],\n",
      "        [11.7689,  5.9329,  7.4095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1517, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2374, 11.0450, -4.4451],\n",
      "        [-9.2645, 11.0503, -4.7136],\n",
      "        [-9.1205, 10.8067, -4.6565],\n",
      "        [-9.6333, 10.8236, -4.3325],\n",
      "        [-9.3398, 10.9401, -4.5432],\n",
      "        [-9.4025, 11.2658, -4.3764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.6724,  6.1078,  7.9400, -9.2374, 11.0450, -4.4451],\n",
      "        [11.9637,  5.7655,  7.6634, -9.2645, 11.0503, -4.7136],\n",
      "        [12.1646,  6.1606,  7.5632, -9.1205, 10.8067, -4.6565],\n",
      "        [11.9099,  5.8340,  7.7456, -9.6333, 10.8236, -4.3325],\n",
      "        [11.6788,  6.0450,  7.6101, -9.3398, 10.9401, -4.5432],\n",
      "        [11.7689,  5.9329,  7.4095, -9.4025, 11.2658, -4.3764]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9981358647346497\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9729,  5.9346,  7.7127],\n",
      "        [11.8029,  5.8265,  7.7684],\n",
      "        [11.8712,  6.1029,  7.5162],\n",
      "        [11.7226,  5.7158,  7.6746],\n",
      "        [11.8219,  5.8279,  7.8168],\n",
      "        [11.9763,  5.6531,  7.5521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3449, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.4859, 10.9954, -4.2360],\n",
      "        [-9.3951, 10.9913, -4.5414],\n",
      "        [-9.4361, 10.6669, -4.2447],\n",
      "        [-9.5089, 10.8812, -4.4827],\n",
      "        [-8.9977, 10.8472, -4.3343],\n",
      "        [-9.3860, 11.4264, -4.4342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9729,  5.9346,  7.7127, -9.4859, 10.9954, -4.2360],\n",
      "        [11.8029,  5.8265,  7.7684, -9.3951, 10.9913, -4.5414],\n",
      "        [11.8712,  6.1029,  7.5162, -9.4361, 10.6669, -4.2447],\n",
      "        [11.7226,  5.7158,  7.6746, -9.5089, 10.8812, -4.4827],\n",
      "        [11.8219,  5.8279,  7.8168, -8.9977, 10.8472, -4.3343],\n",
      "        [11.9763,  5.6531,  7.5521, -9.3860, 11.4264, -4.4342]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0027384757995605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5958, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7791,  6.0207,  8.0127],\n",
      "        [11.9784,  6.1222,  7.6556],\n",
      "        [11.9696,  5.9333,  7.4717],\n",
      "        [11.7315,  6.0190,  7.8874],\n",
      "        [11.9914,  5.7220,  7.8743],\n",
      "        [11.3348,  6.0135,  7.6642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5755, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3358, 10.9735, -4.1174],\n",
      "        [-9.4525, 11.1098, -4.4335],\n",
      "        [-9.3313, 11.1697, -4.5475],\n",
      "        [-9.1867, 11.1589, -4.3047],\n",
      "        [-9.5771, 11.0698, -4.5403],\n",
      "        [-9.3324, 10.7920, -4.2499]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7791,  6.0207,  8.0127, -9.3358, 10.9735, -4.1174],\n",
      "        [11.9784,  6.1222,  7.6556, -9.4525, 11.1098, -4.4335],\n",
      "        [11.9696,  5.9333,  7.4717, -9.3313, 11.1697, -4.5475],\n",
      "        [11.7315,  6.0190,  7.8874, -9.1867, 11.1589, -4.3047],\n",
      "        [11.9914,  5.7220,  7.8743, -9.5771, 11.0698, -4.5403],\n",
      "        [11.3348,  6.0135,  7.6642, -9.3324, 10.7920, -4.2499]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0022062063217163\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4684, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.8870,  5.9334,  7.6842],\n",
      "        [11.8454,  5.8239,  7.3237],\n",
      "        [11.7927,  5.8029,  7.4048],\n",
      "        [12.1494,  6.1266,  8.0510],\n",
      "        [11.7321,  5.7316,  7.4259],\n",
      "        [12.0689,  5.8921,  7.7247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.6986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.2085, 10.6590, -4.1750],\n",
      "        [-9.6927, 10.8864, -4.6064],\n",
      "        [-9.5393, 10.9510, -4.6783],\n",
      "        [-9.5986, 11.2484, -4.2347],\n",
      "        [-9.7491, 11.0675, -4.7429],\n",
      "        [-9.2606, 10.8551, -4.1633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.8870,  5.9334,  7.6842, -9.2085, 10.6590, -4.1750],\n",
      "        [11.8454,  5.8239,  7.3237, -9.6927, 10.8864, -4.6064],\n",
      "        [11.7927,  5.8029,  7.4048, -9.5393, 10.9510, -4.6783],\n",
      "        [12.1494,  6.1266,  8.0510, -9.5986, 11.2484, -4.2347],\n",
      "        [11.7321,  5.7316,  7.4259, -9.7491, 11.0675, -4.7429],\n",
      "        [12.0689,  5.8921,  7.7247, -9.2606, 10.8551, -4.1633]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9908735752105713\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0119, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1384,  5.6682,  7.7101],\n",
      "        [11.5567,  5.6490,  7.7652],\n",
      "        [11.8009,  6.0219,  7.8500],\n",
      "        [12.1795,  5.9549,  8.1291],\n",
      "        [12.2176,  5.9021,  7.6766],\n",
      "        [11.8706,  6.1335,  7.6254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.2197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.9787, 11.0219, -4.4537],\n",
      "        [-9.5344, 10.7511, -4.3965],\n",
      "        [-9.3952, 11.1373, -4.6117],\n",
      "        [-9.5543, 10.9458, -4.7222],\n",
      "        [-9.6333, 10.6761, -4.3702],\n",
      "        [-9.4302, 11.0259, -4.5270]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.1384,  5.6682,  7.7101, -9.9787, 11.0219, -4.4537],\n",
      "        [11.5567,  5.6490,  7.7652, -9.5344, 10.7511, -4.3965],\n",
      "        [11.8009,  6.0219,  7.8500, -9.3952, 11.1373, -4.6117],\n",
      "        [12.1795,  5.9549,  8.1291, -9.5543, 10.9458, -4.7222],\n",
      "        [12.2176,  5.9021,  7.6766, -9.6333, 10.6761, -4.3702],\n",
      "        [11.8706,  6.1335,  7.6254, -9.4302, 11.0259, -4.5270]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.01519775390625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.4581,  5.4576,  7.1314],\n",
      "        [12.0463,  5.4562,  7.5567],\n",
      "        [11.9665,  5.8356,  7.3997],\n",
      "        [11.7933,  5.6774,  7.5395],\n",
      "        [11.6639,  5.7664,  7.6733],\n",
      "        [12.0580,  6.1294,  7.3702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.4843, 11.0160, -4.5496],\n",
      "        [-9.7655, 11.0278, -4.3694],\n",
      "        [-9.4927, 11.3092, -4.6069],\n",
      "        [-9.7066, 11.1353, -4.5555],\n",
      "        [-9.4042, 10.3459, -4.2718],\n",
      "        [-9.5119, 11.0723, -4.5517]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.4581,  5.4576,  7.1314, -9.4843, 11.0160, -4.5496],\n",
      "        [12.0463,  5.4562,  7.5567, -9.7655, 11.0278, -4.3694],\n",
      "        [11.9665,  5.8356,  7.3997, -9.4927, 11.3092, -4.6069],\n",
      "        [11.7933,  5.6774,  7.5395, -9.7066, 11.1353, -4.5555],\n",
      "        [11.6639,  5.7664,  7.6733, -9.4042, 10.3459, -4.2718],\n",
      "        [12.0580,  6.1294,  7.3702, -9.5119, 11.0723, -4.5517]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-0.9693955779075623\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6960, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2383,  5.9606,  7.4976],\n",
      "        [12.0498,  5.7913,  7.7427],\n",
      "        [12.0341,  5.9955,  7.7475],\n",
      "        [12.1839,  6.1689,  7.9416],\n",
      "        [12.2725,  6.0299,  7.7943],\n",
      "        [11.7427,  5.7994,  7.9214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1430, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5978, 11.3884, -4.4047],\n",
      "        [-9.1869, 10.9717, -4.3360],\n",
      "        [-9.3698, 10.7516, -4.4705],\n",
      "        [-9.5146, 10.8422, -4.6750],\n",
      "        [-9.7818, 10.7585, -4.3316],\n",
      "        [-9.5790, 10.9989, -4.7037]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.2383,  5.9606,  7.4976, -9.5978, 11.3884, -4.4047],\n",
      "        [12.0498,  5.7913,  7.7427, -9.1869, 10.9717, -4.3360],\n",
      "        [12.0341,  5.9955,  7.7475, -9.3698, 10.7516, -4.4705],\n",
      "        [12.1839,  6.1689,  7.9416, -9.5146, 10.8422, -4.6750],\n",
      "        [12.2725,  6.0299,  7.7943, -9.7818, 10.7585, -4.3316],\n",
      "        [11.7427,  5.7994,  7.9214, -9.5790, 10.9989, -4.7037]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0190256834030151\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6543, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9070,  6.2746,  7.8580],\n",
      "        [12.2259,  6.0671,  7.9911],\n",
      "        [11.8371,  6.2962,  7.4898],\n",
      "        [11.6058,  6.3802,  7.7005],\n",
      "        [11.9293,  5.9491,  7.8222],\n",
      "        [11.8915,  6.0329,  7.8552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.3797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7610, 10.9823, -4.6185],\n",
      "        [-9.3511, 11.0968, -4.2881],\n",
      "        [-9.3261, 11.1117, -4.4585],\n",
      "        [-9.1288, 11.1108, -4.3717],\n",
      "        [-9.3786, 11.0268, -4.3372],\n",
      "        [-9.5501, 10.8281, -4.5024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9070,  6.2746,  7.8580, -9.7610, 10.9823, -4.6185],\n",
      "        [12.2259,  6.0671,  7.9911, -9.3511, 11.0968, -4.2881],\n",
      "        [11.8371,  6.2962,  7.4898, -9.3261, 11.1117, -4.4585],\n",
      "        [11.6058,  6.3802,  7.7005, -9.1288, 11.1108, -4.3717],\n",
      "        [11.9293,  5.9491,  7.8222, -9.3786, 11.0268, -4.3372],\n",
      "        [11.8915,  6.0329,  7.8552, -9.5501, 10.8281, -4.5024]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.018083930015564\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9453, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2481,  5.8977,  7.4482],\n",
      "        [11.8072,  6.0100,  7.9012],\n",
      "        [11.7439,  5.9883,  7.9808],\n",
      "        [11.8075,  6.0478,  7.9102],\n",
      "        [11.9537,  6.1322,  7.5596],\n",
      "        [11.9285,  5.9946,  7.9889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6652, 10.6792, -4.4642],\n",
      "        [-9.7229, 11.0907, -4.8592],\n",
      "        [-9.7808, 11.3284, -4.6809],\n",
      "        [-9.5981, 10.9017, -4.1822],\n",
      "        [-9.2797, 10.8901, -4.2718],\n",
      "        [-9.4721, 11.2223, -4.4921]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.2481,  5.8977,  7.4482, -9.6652, 10.6792, -4.4642],\n",
      "        [11.8072,  6.0100,  7.9012, -9.7229, 11.0907, -4.8592],\n",
      "        [11.7439,  5.9883,  7.9808, -9.7808, 11.3284, -4.6809],\n",
      "        [11.8075,  6.0478,  7.9102, -9.5981, 10.9017, -4.1822],\n",
      "        [11.9537,  6.1322,  7.5596, -9.2797, 10.8901, -4.2718],\n",
      "        [11.9285,  5.9946,  7.9889, -9.4721, 11.2223, -4.4921]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.008406400680542\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3343, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.0893,  5.9755,  7.8912],\n",
      "        [11.5986,  6.0542,  7.9023],\n",
      "        [11.9192,  5.9018,  7.4096],\n",
      "        [11.7672,  6.0836,  7.4759],\n",
      "        [12.0280,  6.0055,  7.7153],\n",
      "        [11.7912,  6.0122,  7.7318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.7825, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3593, 11.1728, -4.5572],\n",
      "        [-9.7325, 11.2245, -4.5188],\n",
      "        [-9.7100, 11.1686, -4.3660],\n",
      "        [-9.4604, 11.0696, -4.4614],\n",
      "        [-9.9187, 11.4505, -4.8522],\n",
      "        [-9.5267, 11.0708, -4.2714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.0893,  5.9755,  7.8912, -9.3593, 11.1728, -4.5572],\n",
      "        [11.5986,  6.0542,  7.9023, -9.7325, 11.2245, -4.5188],\n",
      "        [11.9192,  5.9018,  7.4096, -9.7100, 11.1686, -4.3660],\n",
      "        [11.7672,  6.0836,  7.4759, -9.4604, 11.0696, -4.4614],\n",
      "        [12.0280,  6.0055,  7.7153, -9.9187, 11.4505, -4.8522],\n",
      "        [11.7912,  6.0122,  7.7318, -9.5267, 11.0708, -4.2714]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0198556184768677\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7546, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1551,  5.9276,  7.6568],\n",
      "        [12.0768,  6.1411,  7.9893],\n",
      "        [11.9854,  6.0012,  8.0431],\n",
      "        [12.1225,  6.2057,  7.9289],\n",
      "        [12.1370,  6.0613,  7.8484],\n",
      "        [12.0460,  6.1166,  7.9632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.7425, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.4874, 11.0248, -4.5521],\n",
      "        [-9.3341, 11.0579, -4.8760],\n",
      "        [-9.5442, 11.1186, -4.3123],\n",
      "        [-9.3544, 11.1950, -4.5523],\n",
      "        [-9.6428, 11.2081, -4.4204],\n",
      "        [-9.5254, 11.0385, -4.6783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.1551,  5.9276,  7.6568, -9.4874, 11.0248, -4.5521],\n",
      "        [12.0768,  6.1411,  7.9893, -9.3341, 11.0579, -4.8760],\n",
      "        [11.9854,  6.0012,  8.0431, -9.5442, 11.1186, -4.3123],\n",
      "        [12.1225,  6.2057,  7.9289, -9.3544, 11.1950, -4.5523],\n",
      "        [12.1370,  6.0613,  7.8484, -9.6428, 11.2081, -4.4204],\n",
      "        [12.0460,  6.1166,  7.9632, -9.5254, 11.0385, -4.6783]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0157274007797241\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7097, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.5935,  6.0380,  7.6854],\n",
      "        [11.8166,  5.7763,  7.7196],\n",
      "        [11.8402,  5.9241,  7.6157],\n",
      "        [11.9935,  5.6506,  7.9615],\n",
      "        [12.4534,  6.0188,  7.8915],\n",
      "        [11.7819,  6.1983,  7.7656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4260, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5175, 11.2843, -4.4080],\n",
      "        [-9.4318, 10.8609, -4.5424],\n",
      "        [-9.5512, 10.9023, -4.7255],\n",
      "        [-9.5369, 11.0966, -4.4997],\n",
      "        [-9.3099, 10.8804, -4.3561],\n",
      "        [-9.1908, 10.9937, -4.6848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.5935,  6.0380,  7.6854, -9.5175, 11.2843, -4.4080],\n",
      "        [11.8166,  5.7763,  7.7196, -9.4318, 10.8609, -4.5424],\n",
      "        [11.8402,  5.9241,  7.6157, -9.5512, 10.9023, -4.7255],\n",
      "        [11.9935,  5.6506,  7.9615, -9.5369, 11.0966, -4.4997],\n",
      "        [12.4534,  6.0188,  7.8915, -9.3099, 10.8804, -4.3561],\n",
      "        [11.7819,  6.1983,  7.7656, -9.1908, 10.9937, -4.6848]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0031715631484985\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7086, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1520,  6.1054,  7.8830],\n",
      "        [11.9239,  6.0983,  7.8385],\n",
      "        [12.0180,  6.2557,  7.6993],\n",
      "        [11.8344,  5.9160,  7.8072],\n",
      "        [12.1059,  5.8170,  8.0587],\n",
      "        [12.0628,  6.0490,  7.9150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5706, 10.9978, -4.7397],\n",
      "        [-9.5762, 11.3284, -5.0117],\n",
      "        [-9.4930, 10.7103, -4.6153],\n",
      "        [-9.3548, 11.1820, -4.8832],\n",
      "        [-9.4694, 11.0666, -4.4646],\n",
      "        [-9.7478, 11.0947, -4.4752]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.1520,  6.1054,  7.8830, -9.5706, 10.9978, -4.7397],\n",
      "        [11.9239,  6.0983,  7.8385, -9.5762, 11.3284, -5.0117],\n",
      "        [12.0180,  6.2557,  7.6993, -9.4930, 10.7103, -4.6153],\n",
      "        [11.8344,  5.9160,  7.8072, -9.3548, 11.1820, -4.8832],\n",
      "        [12.1059,  5.8170,  8.0587, -9.4694, 11.0666, -4.4646],\n",
      "        [12.0628,  6.0490,  7.9150, -9.7478, 11.0947, -4.4752]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0265769958496094\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.7388,  5.9205,  7.7852],\n",
      "        [11.9573,  5.7851,  7.6905],\n",
      "        [11.9450,  5.9789,  7.7742],\n",
      "        [12.1617,  6.1694,  7.7351],\n",
      "        [12.0616,  6.1558,  7.8241],\n",
      "        [11.9351,  6.2230,  8.0115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6541, 10.9184, -4.3094],\n",
      "        [-9.1440, 11.1699, -4.4750],\n",
      "        [-9.7722, 11.0916, -4.7035],\n",
      "        [-9.5950, 11.0158, -4.7604],\n",
      "        [-9.6051, 10.9156, -4.7112],\n",
      "        [-9.7336, 11.0994, -4.6038]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.7388,  5.9205,  7.7852, -9.6541, 10.9184, -4.3094],\n",
      "        [11.9573,  5.7851,  7.6905, -9.1440, 11.1699, -4.4750],\n",
      "        [11.9450,  5.9789,  7.7742, -9.7722, 11.0916, -4.7035],\n",
      "        [12.1617,  6.1694,  7.7351, -9.5950, 11.0158, -4.7604],\n",
      "        [12.0616,  6.1558,  7.8241, -9.6051, 10.9156, -4.7112],\n",
      "        [11.9351,  6.2230,  8.0115, -9.7336, 11.0994, -4.6038]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0057716369628906\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.8487,  6.0106,  7.8479],\n",
      "        [11.8952,  5.9912,  8.1179],\n",
      "        [11.8771,  6.1807,  7.8129],\n",
      "        [12.0067,  6.2430,  7.7619],\n",
      "        [12.1704,  6.1433,  7.9026],\n",
      "        [11.8998,  5.6988,  7.8712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6350, 11.0417, -4.9250],\n",
      "        [-9.6328, 11.2470, -4.7734],\n",
      "        [-9.7821, 11.0701, -4.4754],\n",
      "        [-9.4820, 10.8282, -4.5115],\n",
      "        [-9.3633, 10.9444, -4.6228],\n",
      "        [-9.8113, 10.8447, -4.6766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.8487,  6.0106,  7.8479, -9.6350, 11.0417, -4.9250],\n",
      "        [11.8952,  5.9912,  8.1179, -9.6328, 11.2470, -4.7734],\n",
      "        [11.8771,  6.1807,  7.8129, -9.7821, 11.0701, -4.4754],\n",
      "        [12.0067,  6.2430,  7.7619, -9.4820, 10.8282, -4.5115],\n",
      "        [12.1704,  6.1433,  7.9026, -9.3633, 10.9444, -4.6228],\n",
      "        [11.8998,  5.6988,  7.8712, -9.8113, 10.8447, -4.6766]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.018066644668579\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0346, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2060,  6.0254,  7.8004],\n",
      "        [12.4402,  6.1584,  7.7332],\n",
      "        [12.1612,  5.9503,  8.0805],\n",
      "        [11.8660,  5.9392,  7.7745],\n",
      "        [12.1646,  6.0563,  8.0007],\n",
      "        [12.0108,  6.1704,  7.8594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.4223,  11.1480,  -4.3739],\n",
      "        [-10.0142,  11.3289,  -4.7235],\n",
      "        [ -9.3918,  10.9988,  -4.5014],\n",
      "        [ -9.4338,  11.2677,  -4.6493],\n",
      "        [ -9.8952,  11.1158,  -4.7440],\n",
      "        [ -9.4962,  11.3020,  -5.0076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.2060,   6.0254,   7.8004,  -9.4223,  11.1480,  -4.3739],\n",
      "        [ 12.4402,   6.1584,   7.7332, -10.0142,  11.3289,  -4.7235],\n",
      "        [ 12.1612,   5.9503,   8.0805,  -9.3918,  10.9988,  -4.5014],\n",
      "        [ 11.8660,   5.9392,   7.7745,  -9.4338,  11.2677,  -4.6493],\n",
      "        [ 12.1646,   6.0563,   8.0007,  -9.8952,  11.1158,  -4.7440],\n",
      "        [ 12.0108,   6.1704,   7.8594,  -9.4962,  11.3020,  -5.0076]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0257796049118042\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9470, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1045,  5.9776,  7.6942],\n",
      "        [11.8682,  6.2984,  7.5342],\n",
      "        [11.6842,  6.3319,  8.0217],\n",
      "        [11.6898,  5.9465,  7.5401],\n",
      "        [12.1010,  5.9750,  7.6911],\n",
      "        [11.9263,  5.8739,  7.7818]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.6868,  11.0793,  -4.7292],\n",
      "        [ -9.6611,  11.2502,  -4.8528],\n",
      "        [ -9.2496,  10.9383,  -4.6447],\n",
      "        [-10.0370,  10.8983,  -5.1908],\n",
      "        [ -9.6801,  11.2445,  -4.9105],\n",
      "        [ -9.5207,  10.9669,  -4.5839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.1045,   5.9776,   7.6942,  -9.6868,  11.0793,  -4.7292],\n",
      "        [ 11.8682,   6.2984,   7.5342,  -9.6611,  11.2502,  -4.8528],\n",
      "        [ 11.6842,   6.3319,   8.0217,  -9.2496,  10.9383,  -4.6447],\n",
      "        [ 11.6898,   5.9465,   7.5401, -10.0370,  10.8983,  -5.1908],\n",
      "        [ 12.1010,   5.9750,   7.6911,  -9.6801,  11.2445,  -4.9105],\n",
      "        [ 11.9263,   5.8739,   7.7818,  -9.5207,  10.9669,  -4.5839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.024228572845459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1271,  6.3562,  8.1291],\n",
      "        [12.3707,  6.0193,  7.7357],\n",
      "        [12.1215,  6.2716,  7.6420],\n",
      "        [12.2490,  6.0618,  7.7126],\n",
      "        [12.0618,  6.4340,  7.7848],\n",
      "        [12.0206,  5.9670,  8.1241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5287, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3603, 10.9311, -4.4464],\n",
      "        [-9.7352, 11.5059, -4.5491],\n",
      "        [-9.8569, 11.2581, -4.5796],\n",
      "        [-9.7477, 10.9400, -4.6966],\n",
      "        [-9.5386, 11.0766, -4.9582],\n",
      "        [-9.6660, 11.4558, -4.8809]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.1271,  6.3562,  8.1291, -9.3603, 10.9311, -4.4464],\n",
      "        [12.3707,  6.0193,  7.7357, -9.7352, 11.5059, -4.5491],\n",
      "        [12.1215,  6.2716,  7.6420, -9.8569, 11.2581, -4.5796],\n",
      "        [12.2490,  6.0618,  7.7126, -9.7477, 10.9400, -4.6966],\n",
      "        [12.0618,  6.4340,  7.7848, -9.5386, 11.0766, -4.9582],\n",
      "        [12.0206,  5.9670,  8.1241, -9.6660, 11.4558, -4.8809]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0328606367111206\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6596, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2789,  6.0834,  8.1927],\n",
      "        [12.0864,  6.3157,  8.0473],\n",
      "        [12.2577,  6.4052,  7.7538],\n",
      "        [12.1714,  6.0048,  7.8962],\n",
      "        [12.1659,  5.9510,  7.5659],\n",
      "        [11.9009,  6.2763,  7.8002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6702, 10.8642, -4.7880],\n",
      "        [-9.7014, 11.2272, -4.4430],\n",
      "        [-9.8183, 11.1892, -4.6429],\n",
      "        [-9.5427, 11.6345, -4.8740],\n",
      "        [-9.5341, 10.9977, -4.7996],\n",
      "        [-9.5306, 11.0940, -4.8597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.2789,  6.0834,  8.1927, -9.6702, 10.8642, -4.7880],\n",
      "        [12.0864,  6.3157,  8.0473, -9.7014, 11.2272, -4.4430],\n",
      "        [12.2577,  6.4052,  7.7538, -9.8183, 11.1892, -4.6429],\n",
      "        [12.1714,  6.0048,  7.8962, -9.5427, 11.6345, -4.8740],\n",
      "        [12.1659,  5.9510,  7.5659, -9.5341, 10.9977, -4.7996],\n",
      "        [11.9009,  6.2763,  7.8002, -9.5306, 11.0940, -4.8597]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0418213605880737\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8109, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1533,  5.9968,  7.6524],\n",
      "        [12.1678,  6.2404,  7.4953],\n",
      "        [12.4671,  6.3386,  7.8428],\n",
      "        [12.3061,  6.2882,  7.6349],\n",
      "        [11.9616,  6.1209,  7.8743],\n",
      "        [12.2394,  5.8717,  8.0423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7880, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3514, 10.9708, -4.8152],\n",
      "        [-9.9001, 10.9506, -4.7750],\n",
      "        [-9.4458, 11.3617, -4.9601],\n",
      "        [-9.8337, 11.0970, -4.4338],\n",
      "        [-9.8022, 11.2082, -5.0126],\n",
      "        [-9.6682, 11.1382, -4.7464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.1533,  5.9968,  7.6524, -9.3514, 10.9708, -4.8152],\n",
      "        [12.1678,  6.2404,  7.4953, -9.9001, 10.9506, -4.7750],\n",
      "        [12.4671,  6.3386,  7.8428, -9.4458, 11.3617, -4.9601],\n",
      "        [12.3061,  6.2882,  7.6349, -9.8337, 11.0970, -4.4338],\n",
      "        [11.9616,  6.1209,  7.8743, -9.8022, 11.2082, -5.0126],\n",
      "        [12.2394,  5.8717,  8.0423, -9.6682, 11.1382, -4.7464]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.021214246749878\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5922,  6.2615,  7.8999],\n",
      "        [12.2728,  6.1098,  7.9933],\n",
      "        [11.8658,  5.8800,  7.9657],\n",
      "        [12.0366,  6.0056,  8.0963],\n",
      "        [12.2413,  5.8623,  7.8849],\n",
      "        [11.7221,  6.0584,  8.0151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.9728, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7674, 11.0449, -4.4850],\n",
      "        [-9.8406, 11.1843, -4.7416],\n",
      "        [-9.5780, 11.0498, -4.4245],\n",
      "        [-9.5839, 11.5346, -4.7507],\n",
      "        [-9.5045, 11.5261, -4.7026],\n",
      "        [-9.9406, 11.2688, -4.5192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.5922,  6.2615,  7.8999, -9.7674, 11.0449, -4.4850],\n",
      "        [12.2728,  6.1098,  7.9933, -9.8406, 11.1843, -4.7416],\n",
      "        [11.8658,  5.8800,  7.9657, -9.5780, 11.0498, -4.4245],\n",
      "        [12.0366,  6.0056,  8.0963, -9.5839, 11.5346, -4.7507],\n",
      "        [12.2413,  5.8623,  7.8849, -9.5045, 11.5261, -4.7026],\n",
      "        [11.7221,  6.0584,  8.0151, -9.9406, 11.2688, -4.5192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0516942739486694\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4030, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5122,  6.0591,  7.5555],\n",
      "        [12.2191,  6.1315,  7.8031],\n",
      "        [12.2839,  5.9974,  8.3203],\n",
      "        [11.8536,  6.0432,  7.9528],\n",
      "        [12.1735,  6.1304,  8.0760],\n",
      "        [11.7898,  6.0769,  7.8640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.6632, 11.0021, -4.8003],\n",
      "        [-9.6285, 11.1258, -4.7328],\n",
      "        [-9.7408, 10.9729, -4.5562],\n",
      "        [-9.5747, 11.2050, -4.9112],\n",
      "        [-9.8197, 11.4668, -4.7428],\n",
      "        [-9.5299, 11.3119, -4.4587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.5122,  6.0591,  7.5555, -9.6632, 11.0021, -4.8003],\n",
      "        [12.2191,  6.1315,  7.8031, -9.6285, 11.1258, -4.7328],\n",
      "        [12.2839,  5.9974,  8.3203, -9.7408, 10.9729, -4.5562],\n",
      "        [11.8536,  6.0432,  7.9528, -9.5747, 11.2050, -4.9112],\n",
      "        [12.1735,  6.1304,  8.0760, -9.8197, 11.4668, -4.7428],\n",
      "        [11.7898,  6.0769,  7.8640, -9.5299, 11.3119, -4.4587]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0380839109420776\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7185, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2997,  6.0629,  8.2335],\n",
      "        [12.1901,  6.2288,  8.2158],\n",
      "        [12.2849,  6.5074,  7.8199],\n",
      "        [11.9506,  5.9554,  7.7004],\n",
      "        [11.9795,  6.0556,  8.0401],\n",
      "        [11.8260,  6.0599,  7.6353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.4290, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.6551,  11.4302,  -4.5105],\n",
      "        [ -9.7296,  11.3522,  -4.8750],\n",
      "        [-10.0138,  11.4514,  -4.7941],\n",
      "        [ -9.7203,  11.0715,  -4.4603],\n",
      "        [ -9.9755,  11.2875,  -4.7391],\n",
      "        [ -9.7201,  11.0674,  -4.4846]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.2997,   6.0629,   8.2335,  -9.6551,  11.4302,  -4.5105],\n",
      "        [ 12.1901,   6.2288,   8.2158,  -9.7296,  11.3522,  -4.8750],\n",
      "        [ 12.2849,   6.5074,   7.8199, -10.0138,  11.4514,  -4.7941],\n",
      "        [ 11.9506,   5.9554,   7.7004,  -9.7203,  11.0715,  -4.4603],\n",
      "        [ 11.9795,   6.0556,   8.0401,  -9.9755,  11.2875,  -4.7391],\n",
      "        [ 11.8260,   6.0599,   7.6353,  -9.7201,  11.0674,  -4.4846]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0535454750061035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4772, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4524,  5.8654,  7.7138],\n",
      "        [12.4293,  6.4660,  8.0282],\n",
      "        [12.1495,  6.3631,  7.6501],\n",
      "        [12.5953,  6.3427,  7.9557],\n",
      "        [12.2103,  5.9169,  8.0899],\n",
      "        [12.3243,  5.9900,  8.0443]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8877, 11.5263, -4.8525],\n",
      "        [-9.5316, 11.2644, -4.4617],\n",
      "        [-9.7557, 10.9741, -4.4002],\n",
      "        [-9.7263, 10.7449, -4.5329],\n",
      "        [-9.3978, 11.1199, -4.4979],\n",
      "        [-9.5955, 11.4479, -4.8399]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.4524,  5.8654,  7.7138, -9.8877, 11.5263, -4.8525],\n",
      "        [12.4293,  6.4660,  8.0282, -9.5316, 11.2644, -4.4617],\n",
      "        [12.1495,  6.3631,  7.6501, -9.7557, 10.9741, -4.4002],\n",
      "        [12.5953,  6.3427,  7.9557, -9.7263, 10.7449, -4.5329],\n",
      "        [12.2103,  5.9169,  8.0899, -9.3978, 11.1199, -4.4979],\n",
      "        [12.3243,  5.9900,  8.0443, -9.5955, 11.4479, -4.8399]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0507721900939941\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3532,  6.0694,  7.6779],\n",
      "        [12.2235,  6.2255,  7.8229],\n",
      "        [11.7247,  5.9913,  7.8040],\n",
      "        [12.2526,  6.2567,  7.7375],\n",
      "        [12.1112,  5.9926,  7.8934],\n",
      "        [11.9121,  6.3345,  7.6083]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.3652, 11.0377, -4.6557],\n",
      "        [-9.7500, 11.3920, -4.6109],\n",
      "        [-9.7016, 11.2551, -4.8693],\n",
      "        [-9.7896, 10.7378, -4.7578],\n",
      "        [-9.3065, 11.0932, -4.7099],\n",
      "        [-9.7417, 11.1762, -4.6509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.3532,  6.0694,  7.6779, -9.3652, 11.0377, -4.6557],\n",
      "        [12.2235,  6.2255,  7.8229, -9.7500, 11.3920, -4.6109],\n",
      "        [11.7247,  5.9913,  7.8040, -9.7016, 11.2551, -4.8693],\n",
      "        [12.2526,  6.2567,  7.7375, -9.7896, 10.7378, -4.7578],\n",
      "        [12.1112,  5.9926,  7.8934, -9.3065, 11.0932, -4.7099],\n",
      "        [11.9121,  6.3345,  7.6083, -9.7417, 11.1762, -4.6509]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0334445238113403\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.0648,  6.2104,  7.7441],\n",
      "        [12.3375,  5.9989,  7.8136],\n",
      "        [12.1120,  6.3113,  7.9527],\n",
      "        [12.1871,  6.2943,  7.6780],\n",
      "        [11.9239,  6.1219,  8.0503],\n",
      "        [12.3464,  6.3189,  7.9976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.0805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.5525, 11.4950, -4.6747],\n",
      "        [-9.9271, 11.2145, -4.8071],\n",
      "        [-9.7538, 11.4441, -4.8682],\n",
      "        [-9.8150, 11.1567, -4.4377],\n",
      "        [-9.3073, 11.1347, -4.5271],\n",
      "        [-9.6903, 11.2147, -4.7910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.0648,  6.2104,  7.7441, -9.5525, 11.4950, -4.6747],\n",
      "        [12.3375,  5.9989,  7.8136, -9.9271, 11.2145, -4.8071],\n",
      "        [12.1120,  6.3113,  7.9527, -9.7538, 11.4441, -4.8682],\n",
      "        [12.1871,  6.2943,  7.6780, -9.8150, 11.1567, -4.4377],\n",
      "        [11.9239,  6.1219,  8.0503, -9.3073, 11.1347, -4.5271],\n",
      "        [12.3464,  6.3189,  7.9976, -9.6903, 11.2147, -4.7910]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0379489660263062\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3842, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.0313,  6.1692,  7.9100],\n",
      "        [12.0546,  6.2747,  8.0566],\n",
      "        [12.5548,  5.8669,  7.9855],\n",
      "        [11.9727,  6.0068,  7.8853],\n",
      "        [12.1800,  6.3692,  8.1826],\n",
      "        [12.0680,  6.4768,  7.9967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.2019, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8393, 11.0662, -4.6736],\n",
      "        [-9.8788, 11.5129, -4.9049],\n",
      "        [-9.9277, 11.5382, -5.0044],\n",
      "        [-9.8411, 11.3612, -4.7184],\n",
      "        [-9.9209, 11.4089, -4.8464],\n",
      "        [-9.7976, 11.2264, -5.0726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.0313,  6.1692,  7.9100, -9.8393, 11.0662, -4.6736],\n",
      "        [12.0546,  6.2747,  8.0566, -9.8788, 11.5129, -4.9049],\n",
      "        [12.5548,  5.8669,  7.9855, -9.9277, 11.5382, -5.0044],\n",
      "        [11.9727,  6.0068,  7.8853, -9.8411, 11.3612, -4.7184],\n",
      "        [12.1800,  6.3692,  8.1826, -9.9209, 11.4089, -4.8464],\n",
      "        [12.0680,  6.4768,  7.9967, -9.7976, 11.2264, -5.0726]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0379705429077148\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1723,  6.2011,  8.0201],\n",
      "        [12.2566,  6.1816,  8.0874],\n",
      "        [12.1392,  6.2055,  8.0871],\n",
      "        [12.0046,  6.3531,  7.9019],\n",
      "        [12.3888,  6.1437,  7.6733],\n",
      "        [12.4113,  6.3282,  7.8853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.4249,  11.0315,  -4.6800],\n",
      "        [-10.0374,  11.3016,  -4.8014],\n",
      "        [ -9.4457,  11.2192,  -4.2736],\n",
      "        [-10.1414,  11.5674,  -4.7695],\n",
      "        [ -9.7727,  11.0517,  -4.9908],\n",
      "        [ -9.6763,  10.8715,  -5.1649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.1723,   6.2011,   8.0201,  -9.4249,  11.0315,  -4.6800],\n",
      "        [ 12.2566,   6.1816,   8.0874, -10.0374,  11.3016,  -4.8014],\n",
      "        [ 12.1392,   6.2055,   8.0871,  -9.4457,  11.2192,  -4.2736],\n",
      "        [ 12.0046,   6.3531,   7.9019, -10.1414,  11.5674,  -4.7695],\n",
      "        [ 12.3888,   6.1437,   7.6733,  -9.7727,  11.0517,  -4.9908],\n",
      "        [ 12.4113,   6.3282,   7.8853,  -9.6763,  10.8715,  -5.1649]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0403414964675903\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7485, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3054,  6.1656,  8.0153],\n",
      "        [12.4859,  6.4059,  7.7372],\n",
      "        [12.6512,  6.4048,  7.9606],\n",
      "        [12.3404,  6.5167,  8.0553],\n",
      "        [12.1875,  6.1966,  7.9995],\n",
      "        [12.5228,  6.2256,  7.8855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9551, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7452, 11.2353, -4.8376],\n",
      "        [-9.8152, 11.1894, -4.7569],\n",
      "        [-9.5358, 11.1454, -4.8048],\n",
      "        [-9.6769, 11.4703, -5.0452],\n",
      "        [-9.4198, 10.8356, -4.8476],\n",
      "        [-9.5362, 10.8614, -4.6542]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.3054,  6.1656,  8.0153, -9.7452, 11.2353, -4.8376],\n",
      "        [12.4859,  6.4059,  7.7372, -9.8152, 11.1894, -4.7569],\n",
      "        [12.6512,  6.4048,  7.9606, -9.5358, 11.1454, -4.8048],\n",
      "        [12.3404,  6.5167,  8.0553, -9.6769, 11.4703, -5.0452],\n",
      "        [12.1875,  6.1966,  7.9995, -9.4198, 10.8356, -4.8476],\n",
      "        [12.5228,  6.2256,  7.8855, -9.5362, 10.8614, -4.6542]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0537523031234741\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9544,  6.0814,  7.9145],\n",
      "        [12.5710,  6.1458,  7.7703],\n",
      "        [12.2172,  6.2675,  8.0901],\n",
      "        [12.3229,  6.1298,  7.9185],\n",
      "        [11.9452,  5.9651,  7.9092],\n",
      "        [12.5031,  6.3295,  8.0177]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.7793, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.8202, 11.2928, -4.5940],\n",
      "        [-9.7296, 11.6111, -4.9167],\n",
      "        [-9.7086, 11.1110, -4.7238],\n",
      "        [-9.8581, 11.3074, -4.6773],\n",
      "        [-9.7944, 11.3842, -4.8122],\n",
      "        [-9.7346, 11.2398, -4.9168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[11.9544,  6.0814,  7.9145, -9.8202, 11.2928, -4.5940],\n",
      "        [12.5710,  6.1458,  7.7703, -9.7296, 11.6111, -4.9167],\n",
      "        [12.2172,  6.2675,  8.0901, -9.7086, 11.1110, -4.7238],\n",
      "        [12.3229,  6.1298,  7.9185, -9.8581, 11.3074, -4.6773],\n",
      "        [11.9452,  5.9651,  7.9092, -9.7944, 11.3842, -4.8122],\n",
      "        [12.5031,  6.3295,  8.0177, -9.7346, 11.2398, -4.9168]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0393285751342773\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4124, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[11.9312,  6.6482,  8.0534],\n",
      "        [12.4472,  6.0429,  7.6407],\n",
      "        [12.4107,  5.9337,  7.8709],\n",
      "        [12.3429,  6.5652,  7.8955],\n",
      "        [12.1686,  6.0842,  8.0125],\n",
      "        [11.8868,  6.2886,  8.0570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.8616,  11.4127,  -4.8816],\n",
      "        [ -9.6546,  11.2685,  -4.8154],\n",
      "        [ -9.9736,  11.7131,  -4.8939],\n",
      "        [ -9.6993,  11.0623,  -4.6039],\n",
      "        [ -9.7897,  11.4624,  -4.7543],\n",
      "        [-10.0059,  11.1676,  -4.6286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 11.9312,   6.6482,   8.0534,  -9.8616,  11.4127,  -4.8816],\n",
      "        [ 12.4472,   6.0429,   7.6407,  -9.6546,  11.2685,  -4.8154],\n",
      "        [ 12.4107,   5.9337,   7.8709,  -9.9736,  11.7131,  -4.8939],\n",
      "        [ 12.3429,   6.5652,   7.8955,  -9.6993,  11.0623,  -4.6039],\n",
      "        [ 12.1686,   6.0842,   8.0125,  -9.7897,  11.4624,  -4.7543],\n",
      "        [ 11.8868,   6.2886,   8.0570, -10.0059,  11.1676,  -4.6286]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0544281005859375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3645,  6.2503,  7.8481],\n",
      "        [12.4126,  6.0825,  8.1287],\n",
      "        [12.0307,  6.0997,  8.3440],\n",
      "        [12.3525,  6.3346,  7.6248],\n",
      "        [11.7478,  6.1222,  8.5097],\n",
      "        [12.3741,  6.3160,  8.4163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0030, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7231, 11.2454, -5.0557],\n",
      "        [-9.8467, 11.4064, -4.6971],\n",
      "        [-9.6025, 10.6564, -5.0426],\n",
      "        [-9.7453, 11.3546, -4.9687],\n",
      "        [-9.8161, 11.2482, -5.0918],\n",
      "        [-9.8280, 11.5782, -4.7957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.3645,  6.2503,  7.8481, -9.7231, 11.2454, -5.0557],\n",
      "        [12.4126,  6.0825,  8.1287, -9.8467, 11.4064, -4.6971],\n",
      "        [12.0307,  6.0997,  8.3440, -9.6025, 10.6564, -5.0426],\n",
      "        [12.3525,  6.3346,  7.6248, -9.7453, 11.3546, -4.9687],\n",
      "        [11.7478,  6.1222,  8.5097, -9.8161, 11.2482, -5.0918],\n",
      "        [12.3741,  6.3160,  8.4163, -9.8280, 11.5782, -4.7957]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0559601783752441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5308, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3065,  6.0561,  7.9406],\n",
      "        [12.2747,  6.3118,  8.0225],\n",
      "        [12.5629,  6.2047,  7.9910],\n",
      "        [12.5738,  6.6726,  7.8606],\n",
      "        [12.0703,  6.1536,  7.9176],\n",
      "        [12.2394,  6.0796,  7.8299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.3286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.6989,  11.7382,  -4.9429],\n",
      "        [-10.0462,  11.5068,  -4.7455],\n",
      "        [ -9.7829,  11.2606,  -4.7034],\n",
      "        [ -9.7022,  11.9495,  -5.1149],\n",
      "        [ -9.9097,  11.5525,  -5.1711],\n",
      "        [ -9.7182,  11.7025,  -4.7383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.3065,   6.0561,   7.9406,  -9.6989,  11.7382,  -4.9429],\n",
      "        [ 12.2747,   6.3118,   8.0225, -10.0462,  11.5068,  -4.7455],\n",
      "        [ 12.5629,   6.2047,   7.9910,  -9.7829,  11.2606,  -4.7034],\n",
      "        [ 12.5738,   6.6726,   7.8606,  -9.7022,  11.9495,  -5.1149],\n",
      "        [ 12.0703,   6.1536,   7.9176,  -9.9097,  11.5525,  -5.1711],\n",
      "        [ 12.2394,   6.0796,   7.8299,  -9.7182,  11.7025,  -4.7383]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0615198612213135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4392,  6.5843,  7.7363],\n",
      "        [12.5269,  6.2253,  7.6623],\n",
      "        [12.0984,  6.2811,  8.3155],\n",
      "        [12.1647,  6.2143,  8.1928],\n",
      "        [12.1692,  6.3665,  8.2407],\n",
      "        [12.4133,  6.3228,  7.8781]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.9268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.4792, 11.0571, -4.7696],\n",
      "        [-9.8721, 11.6163, -4.7939],\n",
      "        [-9.9815, 11.4208, -5.0407],\n",
      "        [-9.8709, 11.4084, -4.9899],\n",
      "        [-9.8149, 11.5667, -4.6174],\n",
      "        [-9.8293, 11.1355, -4.7358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.4392,  6.5843,  7.7363, -9.4792, 11.0571, -4.7696],\n",
      "        [12.5269,  6.2253,  7.6623, -9.8721, 11.6163, -4.7939],\n",
      "        [12.0984,  6.2811,  8.3155, -9.9815, 11.4208, -5.0407],\n",
      "        [12.1647,  6.2143,  8.1928, -9.8709, 11.4084, -4.9899],\n",
      "        [12.1692,  6.3665,  8.2407, -9.8149, 11.5667, -4.6174],\n",
      "        [12.4133,  6.3228,  7.8781, -9.8293, 11.1355, -4.7358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.053412914276123\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7086, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3496,  6.3135,  8.3429],\n",
      "        [12.2049,  6.3719,  7.5375],\n",
      "        [11.8509,  5.9986,  8.0111],\n",
      "        [12.1596,  6.4649,  7.9966],\n",
      "        [11.8952,  6.2558,  7.7630],\n",
      "        [12.4385,  6.3025,  7.9886]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.6953,  11.2935,  -4.6291],\n",
      "        [ -9.5173,  11.5171,  -5.1570],\n",
      "        [ -9.7992,  11.4039,  -4.8848],\n",
      "        [ -9.8663,  11.3028,  -4.8823],\n",
      "        [-10.0254,  11.2579,  -4.6944],\n",
      "        [ -9.8713,  11.6558,  -4.9988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.3496,   6.3135,   8.3429,  -9.6953,  11.2935,  -4.6291],\n",
      "        [ 12.2049,   6.3719,   7.5375,  -9.5173,  11.5171,  -5.1570],\n",
      "        [ 11.8509,   5.9986,   8.0111,  -9.7992,  11.4039,  -4.8848],\n",
      "        [ 12.1596,   6.4649,   7.9966,  -9.8663,  11.3028,  -4.8823],\n",
      "        [ 11.8952,   6.2558,   7.7630, -10.0254,  11.2579,  -4.6944],\n",
      "        [ 12.4385,   6.3025,   7.9886,  -9.8713,  11.6558,  -4.9988]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0686007738113403\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0315, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4606,  6.5327,  8.3902],\n",
      "        [12.3642,  6.2587,  8.0387],\n",
      "        [12.4596,  6.3088,  7.5860],\n",
      "        [12.5638,  6.3029,  7.8592],\n",
      "        [12.4144,  6.0163,  7.8923],\n",
      "        [12.1617,  5.8434,  7.8795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.8415,  11.1465,  -4.8675],\n",
      "        [ -9.5385,  11.5298,  -5.2017],\n",
      "        [ -9.7299,  11.5671,  -4.9284],\n",
      "        [-10.1056,  11.4206,  -4.6800],\n",
      "        [ -9.8053,  11.1323,  -5.1175],\n",
      "        [ -9.8541,  11.4096,  -5.0491]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.4606,   6.5327,   8.3902,  -9.8415,  11.1465,  -4.8675],\n",
      "        [ 12.3642,   6.2587,   8.0387,  -9.5385,  11.5298,  -5.2017],\n",
      "        [ 12.4596,   6.3088,   7.5860,  -9.7299,  11.5671,  -4.9284],\n",
      "        [ 12.5638,   6.3029,   7.8592, -10.1056,  11.4206,  -4.6800],\n",
      "        [ 12.4144,   6.0163,   7.8923,  -9.8053,  11.1323,  -5.1175],\n",
      "        [ 12.1617,   5.8434,   7.8795,  -9.8541,  11.4096,  -5.0491]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0782501697540283\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(5.0080, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3336,  6.2235,  7.8926],\n",
      "        [12.1431,  6.3263,  7.7148],\n",
      "        [11.9949,  6.2856,  7.8399],\n",
      "        [12.2828,  6.3109,  8.2710],\n",
      "        [12.1647,  6.7526,  7.7705],\n",
      "        [12.2418,  5.9483,  8.2616]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.1456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7723, 11.6173, -4.7738],\n",
      "        [-9.8036, 11.3538, -4.7021],\n",
      "        [-9.6015, 11.2407, -4.9012],\n",
      "        [-9.7316, 11.3010, -4.7172],\n",
      "        [-9.7818, 10.8863, -4.7501],\n",
      "        [-9.7495, 11.1935, -4.7374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.3336,  6.2235,  7.8926, -9.7723, 11.6173, -4.7738],\n",
      "        [12.1431,  6.3263,  7.7148, -9.8036, 11.3538, -4.7021],\n",
      "        [11.9949,  6.2856,  7.8399, -9.6015, 11.2407, -4.9012],\n",
      "        [12.2828,  6.3109,  8.2710, -9.7316, 11.3010, -4.7172],\n",
      "        [12.1647,  6.7526,  7.7705, -9.7818, 10.8863, -4.7501],\n",
      "        [12.2418,  5.9483,  8.2616, -9.7495, 11.1935, -4.7374]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.064330816268921\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6072,  6.2500,  8.4894],\n",
      "        [12.4980,  6.3237,  8.2447],\n",
      "        [12.2010,  6.3082,  8.0152],\n",
      "        [12.4429,  6.3103,  8.2631],\n",
      "        [12.4588,  6.4481,  7.9003],\n",
      "        [12.4898,  6.2304,  7.3643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.8616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-9.7979, 11.3364, -4.9950],\n",
      "        [-9.6949, 11.4215, -4.8467],\n",
      "        [-9.9896, 11.0287, -5.1049],\n",
      "        [-9.8314, 11.4283, -4.7245],\n",
      "        [-9.8778, 11.5842, -4.9477],\n",
      "        [-9.9591, 11.4869, -4.8086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[12.6072,  6.2500,  8.4894, -9.7979, 11.3364, -4.9950],\n",
      "        [12.4980,  6.3237,  8.2447, -9.6949, 11.4215, -4.8467],\n",
      "        [12.2010,  6.3082,  8.0152, -9.9896, 11.0287, -5.1049],\n",
      "        [12.4429,  6.3103,  8.2631, -9.8314, 11.4283, -4.7245],\n",
      "        [12.4588,  6.4481,  7.9003, -9.8778, 11.5842, -4.9477],\n",
      "        [12.4898,  6.2304,  7.3643, -9.9591, 11.4869, -4.8086]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0866901874542236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7572,  6.4257,  8.2050],\n",
      "        [12.4464,  6.6300,  8.1450],\n",
      "        [12.2399,  6.3037,  8.2731],\n",
      "        [12.5275,  6.3379,  7.9051],\n",
      "        [12.5911,  6.2781,  8.0512],\n",
      "        [12.3025,  6.4616,  7.7751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.2296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.9928,  11.5666,  -5.0698],\n",
      "        [-10.0514,  11.3797,  -5.0242],\n",
      "        [ -9.7317,  11.5374,  -4.7173],\n",
      "        [ -9.6526,  11.4655,  -4.9002],\n",
      "        [-10.0090,  11.4208,  -5.0455],\n",
      "        [ -9.7584,  11.3388,  -5.0297]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7572,   6.4257,   8.2050,  -9.9928,  11.5666,  -5.0698],\n",
      "        [ 12.4464,   6.6300,   8.1450, -10.0514,  11.3797,  -5.0242],\n",
      "        [ 12.2399,   6.3037,   8.2731,  -9.7317,  11.5374,  -4.7173],\n",
      "        [ 12.5275,   6.3379,   7.9051,  -9.6526,  11.4655,  -4.9002],\n",
      "        [ 12.5911,   6.2781,   8.0512, -10.0090,  11.4208,  -5.0455],\n",
      "        [ 12.3025,   6.4616,   7.7751,  -9.7584,  11.3388,  -5.0297]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0948724746704102\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SequenceClassifierOutput(loss=tensor(2.1635, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6796,  6.5182,  7.6915],\n",
      "        [12.3274,  6.1942,  8.0975],\n",
      "        [12.2663,  6.2886,  8.5487],\n",
      "        [12.6867,  6.5717,  8.0763],\n",
      "        [12.1473,  6.1393,  8.2180],\n",
      "        [12.4162,  6.1292,  7.8614]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.8656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1342,  11.4824,  -4.7724],\n",
      "        [-10.0207,  11.4140,  -4.9038],\n",
      "        [ -9.9299,  11.6493,  -5.0340],\n",
      "        [ -9.9699,  11.5804,  -4.7958],\n",
      "        [-10.0550,  11.5610,  -5.0897],\n",
      "        [ -9.9365,  11.4404,  -5.0773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6796,   6.5182,   7.6915, -10.1342,  11.4824,  -4.7724],\n",
      "        [ 12.3274,   6.1942,   8.0975, -10.0207,  11.4140,  -4.9038],\n",
      "        [ 12.2663,   6.2886,   8.5487,  -9.9299,  11.6493,  -5.0340],\n",
      "        [ 12.6867,   6.5717,   8.0763,  -9.9699,  11.5804,  -4.7958],\n",
      "        [ 12.1473,   6.1393,   8.2180, -10.0550,  11.5610,  -5.0897],\n",
      "        [ 12.4162,   6.1292,   7.8614,  -9.9365,  11.4404,  -5.0773]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.080195426940918\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7317, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2400,  6.1399,  8.0236],\n",
      "        [12.0191,  6.4733,  8.2180],\n",
      "        [12.3864,  6.3211,  8.3522],\n",
      "        [12.2967,  6.4898,  7.8160],\n",
      "        [12.4583,  6.3525,  8.1218],\n",
      "        [12.2903,  6.4871,  7.9827]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.4461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.8324,  11.3965,  -5.1055],\n",
      "        [ -9.8330,  11.7151,  -4.9517],\n",
      "        [-10.3135,  11.7158,  -4.8851],\n",
      "        [ -9.3254,  10.8652,  -5.0052],\n",
      "        [-10.1316,  11.4270,  -4.8465],\n",
      "        [-10.1687,  11.5152,  -5.1563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.2400,   6.1399,   8.0236,  -9.8324,  11.3965,  -5.1055],\n",
      "        [ 12.0191,   6.4733,   8.2180,  -9.8330,  11.7151,  -4.9517],\n",
      "        [ 12.3864,   6.3211,   8.3522, -10.3135,  11.7158,  -4.8851],\n",
      "        [ 12.2967,   6.4898,   7.8160,  -9.3254,  10.8652,  -5.0052],\n",
      "        [ 12.4583,   6.3525,   8.1218, -10.1316,  11.4270,  -4.8465],\n",
      "        [ 12.2903,   6.4871,   7.9827, -10.1687,  11.5152,  -5.1563]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0651521682739258\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6003,  6.4463,  8.1542],\n",
      "        [12.9683,  6.6536,  8.1481],\n",
      "        [12.4703,  6.5565,  8.3536],\n",
      "        [12.4160,  6.2126,  7.9510],\n",
      "        [12.6186,  6.4433,  8.5000],\n",
      "        [11.8136,  6.3488,  8.3078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0032,  11.7628,  -5.0150],\n",
      "        [ -9.8572,  11.2514,  -4.8474],\n",
      "        [ -9.8508,  11.2333,  -5.1680],\n",
      "        [-10.0388,  11.4873,  -5.2396],\n",
      "        [-10.2945,  11.2024,  -5.0827],\n",
      "        [-10.1108,  11.3897,  -5.1058]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6003,   6.4463,   8.1542, -10.0032,  11.7628,  -5.0150],\n",
      "        [ 12.9683,   6.6536,   8.1481,  -9.8572,  11.2514,  -4.8474],\n",
      "        [ 12.4703,   6.5565,   8.3536,  -9.8508,  11.2333,  -5.1680],\n",
      "        [ 12.4160,   6.2126,   7.9510, -10.0388,  11.4873,  -5.2396],\n",
      "        [ 12.6186,   6.4433,   8.5000, -10.2945,  11.2024,  -5.0827],\n",
      "        [ 11.8136,   6.3488,   8.3078, -10.1108,  11.3897,  -5.1058]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0936938524246216\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4322,  6.4274,  8.1774],\n",
      "        [12.2976,  6.3404,  8.2626],\n",
      "        [12.4854,  6.2550,  8.0194],\n",
      "        [12.6595,  6.2162,  8.4621],\n",
      "        [12.1727,  6.5281,  8.1637],\n",
      "        [12.3222,  6.4785,  8.0400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1489,  11.5408,  -5.1985],\n",
      "        [ -9.8171,  11.3473,  -5.0151],\n",
      "        [ -9.5354,  11.5210,  -4.9682],\n",
      "        [ -9.8628,  11.6211,  -5.0376],\n",
      "        [-10.2551,  11.4884,  -5.0476],\n",
      "        [ -9.8112,  11.3302,  -4.8976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.4322,   6.4274,   8.1774, -10.1489,  11.5408,  -5.1985],\n",
      "        [ 12.2976,   6.3404,   8.2626,  -9.8171,  11.3473,  -5.0151],\n",
      "        [ 12.4854,   6.2550,   8.0194,  -9.5354,  11.5210,  -4.9682],\n",
      "        [ 12.6595,   6.2162,   8.4621,  -9.8628,  11.6211,  -5.0376],\n",
      "        [ 12.1727,   6.5281,   8.1637, -10.2551,  11.4884,  -5.0476],\n",
      "        [ 12.3222,   6.4785,   8.0400,  -9.8112,  11.3302,  -4.8976]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0883636474609375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5542,  6.4029,  8.3149],\n",
      "        [12.1817,  6.1691,  8.4131],\n",
      "        [12.5630,  6.3644,  8.2065],\n",
      "        [12.3450,  6.4130,  7.9894],\n",
      "        [12.5564,  6.2705,  8.3350],\n",
      "        [12.3022,  6.3761,  8.1220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.2052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0350,  11.4278,  -5.0565],\n",
      "        [ -9.7643,  11.4361,  -4.4470],\n",
      "        [ -9.6470,  11.6474,  -4.8360],\n",
      "        [ -9.8963,  11.1280,  -4.9487],\n",
      "        [ -9.9852,  11.1965,  -5.0680],\n",
      "        [ -9.9872,  11.7248,  -5.3610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5542,   6.4029,   8.3149, -10.0350,  11.4278,  -5.0565],\n",
      "        [ 12.1817,   6.1691,   8.4131,  -9.7643,  11.4361,  -4.4470],\n",
      "        [ 12.5630,   6.3644,   8.2065,  -9.6470,  11.6474,  -4.8360],\n",
      "        [ 12.3450,   6.4130,   7.9894,  -9.8963,  11.1280,  -4.9487],\n",
      "        [ 12.5564,   6.2705,   8.3350,  -9.9852,  11.1965,  -5.0680],\n",
      "        [ 12.3022,   6.3761,   8.1220,  -9.9872,  11.7248,  -5.3610]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.092068076133728\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4434,  6.4101,  8.1139],\n",
      "        [12.3059,  6.4080,  8.1791],\n",
      "        [12.2288,  6.4730,  7.9547],\n",
      "        [12.5182,  6.4864,  8.0567],\n",
      "        [12.5804,  6.3519,  7.9828],\n",
      "        [12.6815,  6.5772,  8.3108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.6579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1028,  11.5172,  -5.0207],\n",
      "        [-10.0166,  11.5118,  -5.2765],\n",
      "        [ -9.7521,  11.3973,  -5.2664],\n",
      "        [ -9.9318,  11.6665,  -4.9255],\n",
      "        [ -9.9225,  10.9342,  -5.2467],\n",
      "        [ -9.9499,  11.2279,  -5.5010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.4434,   6.4101,   8.1139, -10.1028,  11.5172,  -5.0207],\n",
      "        [ 12.3059,   6.4080,   8.1791, -10.0166,  11.5118,  -5.2765],\n",
      "        [ 12.2288,   6.4730,   7.9547,  -9.7521,  11.3973,  -5.2664],\n",
      "        [ 12.5182,   6.4864,   8.0567,  -9.9318,  11.6665,  -4.9255],\n",
      "        [ 12.5804,   6.3519,   7.9828,  -9.9225,  10.9342,  -5.2467],\n",
      "        [ 12.6815,   6.5772,   8.3108,  -9.9499,  11.2279,  -5.5010]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0862590074539185\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6282,  6.7349,  8.0145],\n",
      "        [12.2505,  6.3644,  8.0308],\n",
      "        [12.3050,  6.6810,  8.1006],\n",
      "        [12.4018,  6.6171,  8.4273],\n",
      "        [12.3349,  6.1365,  7.7794],\n",
      "        [12.4454,  6.7721,  8.0942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2463, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2461,  11.6354,  -4.9266],\n",
      "        [-10.0411,  11.5562,  -5.3102],\n",
      "        [ -9.9559,  11.5618,  -4.9102],\n",
      "        [ -9.9635,  11.4441,  -5.1705],\n",
      "        [-10.1611,  11.6434,  -5.1792],\n",
      "        [-10.0426,  11.5978,  -5.2882]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6282,   6.7349,   8.0145, -10.2461,  11.6354,  -4.9266],\n",
      "        [ 12.2505,   6.3644,   8.0308, -10.0411,  11.5562,  -5.3102],\n",
      "        [ 12.3050,   6.6810,   8.1006,  -9.9559,  11.5618,  -4.9102],\n",
      "        [ 12.4018,   6.6171,   8.4273,  -9.9635,  11.4441,  -5.1705],\n",
      "        [ 12.3349,   6.1365,   7.7794, -10.1611,  11.6434,  -5.1792],\n",
      "        [ 12.4454,   6.7721,   8.0942, -10.0426,  11.5978,  -5.2882]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.098732829093933\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7252, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6270,  6.5693,  8.2330],\n",
      "        [12.5923,  6.3405,  8.3082],\n",
      "        [12.3463,  6.2954,  8.4067],\n",
      "        [12.6006,  6.4508,  8.5270],\n",
      "        [12.5468,  6.3813,  8.2068],\n",
      "        [12.6227,  6.8125,  8.3318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.2940, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.5349,  11.5506,  -5.0966],\n",
      "        [ -9.6539,  11.1990,  -4.8514],\n",
      "        [-10.1866,  11.7378,  -4.7552],\n",
      "        [ -9.7078,  11.5916,  -4.9022],\n",
      "        [ -9.9460,  11.5812,  -4.7810],\n",
      "        [ -9.7833,  11.4880,  -5.0356]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6270,   6.5693,   8.2330,  -9.5349,  11.5506,  -5.0966],\n",
      "        [ 12.5923,   6.3405,   8.3082,  -9.6539,  11.1990,  -4.8514],\n",
      "        [ 12.3463,   6.2954,   8.4067, -10.1866,  11.7378,  -4.7552],\n",
      "        [ 12.6006,   6.4508,   8.5270,  -9.7078,  11.5916,  -4.9022],\n",
      "        [ 12.5468,   6.3813,   8.2068,  -9.9460,  11.5812,  -4.7810],\n",
      "        [ 12.6227,   6.8125,   8.3318,  -9.7833,  11.4880,  -5.0356]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0921376943588257\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8139, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7172,  6.5718,  8.0592],\n",
      "        [12.4033,  6.3979,  8.0976],\n",
      "        [12.2307,  6.3516,  8.1605],\n",
      "        [12.1332,  6.7668,  8.6491],\n",
      "        [12.4546,  6.2314,  7.9151],\n",
      "        [12.6764,  6.2033,  7.9650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.1972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0021,  11.5413,  -5.1152],\n",
      "        [ -9.8161,  11.8458,  -4.9865],\n",
      "        [-10.1897,  11.2078,  -4.8027],\n",
      "        [ -9.8844,  11.6369,  -5.3508],\n",
      "        [-10.1162,  11.6975,  -4.8058],\n",
      "        [-10.1716,  11.3161,  -5.0385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7172,   6.5718,   8.0592, -10.0021,  11.5413,  -5.1152],\n",
      "        [ 12.4033,   6.3979,   8.0976,  -9.8161,  11.8458,  -4.9865],\n",
      "        [ 12.2307,   6.3516,   8.1605, -10.1897,  11.2078,  -4.8027],\n",
      "        [ 12.1332,   6.7668,   8.6491,  -9.8844,  11.6369,  -5.3508],\n",
      "        [ 12.4546,   6.2314,   7.9151, -10.1162,  11.6975,  -4.8058],\n",
      "        [ 12.6764,   6.2033,   7.9650, -10.1716,  11.3161,  -5.0385]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.098259687423706\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7289,  6.4030,  8.2576],\n",
      "        [12.1865,  6.3937,  8.2477],\n",
      "        [12.6600,  6.1969,  7.9279],\n",
      "        [12.7207,  6.1627,  7.8832],\n",
      "        [12.3819,  6.7788,  7.9853],\n",
      "        [12.3459,  6.2780,  8.0381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6361, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.6968,  11.8477,  -5.2760],\n",
      "        [-10.0142,  11.2982,  -5.2523],\n",
      "        [ -9.7816,  11.6993,  -5.0491],\n",
      "        [-10.4712,  11.6348,  -5.4660],\n",
      "        [ -9.8474,  11.4409,  -5.0411],\n",
      "        [ -9.7299,  11.2878,  -5.1473]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7289,   6.4030,   8.2576,  -9.6968,  11.8477,  -5.2760],\n",
      "        [ 12.1865,   6.3937,   8.2477, -10.0142,  11.2982,  -5.2523],\n",
      "        [ 12.6600,   6.1969,   7.9279,  -9.7816,  11.6993,  -5.0491],\n",
      "        [ 12.7207,   6.1627,   7.8832, -10.4712,  11.6348,  -5.4660],\n",
      "        [ 12.3819,   6.7788,   7.9853,  -9.8474,  11.4409,  -5.0411],\n",
      "        [ 12.3459,   6.2780,   8.0381,  -9.7299,  11.2878,  -5.1473]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1038224697113037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6715,  6.6641,  8.2398],\n",
      "        [12.2125,  6.5064,  8.2010],\n",
      "        [12.6373,  6.3555,  7.8711],\n",
      "        [12.3641,  6.4819,  8.2419],\n",
      "        [12.8000,  6.4680,  8.1243],\n",
      "        [12.3364,  6.4060,  8.3335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.7307,  11.3490,  -5.3038],\n",
      "        [-10.2319,  11.7508,  -5.2170],\n",
      "        [ -9.9429,  11.7809,  -5.0697],\n",
      "        [ -9.9240,  11.5403,  -4.7475],\n",
      "        [ -9.9106,  11.3088,  -4.7063],\n",
      "        [-10.2816,  11.7435,  -5.1663]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6715,   6.6641,   8.2398,  -9.7307,  11.3490,  -5.3038],\n",
      "        [ 12.2125,   6.5064,   8.2010, -10.2319,  11.7508,  -5.2170],\n",
      "        [ 12.6373,   6.3555,   7.8711,  -9.9429,  11.7809,  -5.0697],\n",
      "        [ 12.3641,   6.4819,   8.2419,  -9.9240,  11.5403,  -4.7475],\n",
      "        [ 12.8000,   6.4680,   8.1243,  -9.9106,  11.3088,  -4.7063],\n",
      "        [ 12.3364,   6.4060,   8.3335, -10.2816,  11.7435,  -5.1663]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0979446172714233\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2285,  6.2084,  8.1452],\n",
      "        [12.6539,  6.2224,  8.0541],\n",
      "        [12.5814,  6.4438,  8.4341],\n",
      "        [12.4568,  6.5490,  8.3272],\n",
      "        [12.3712,  6.2484,  8.0821],\n",
      "        [12.6214,  6.6660,  8.3919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.7840, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1161,  11.6256,  -5.0474],\n",
      "        [ -9.9497,  12.0240,  -4.9955],\n",
      "        [-10.1587,  11.8178,  -5.0259],\n",
      "        [-10.2051,  11.5031,  -5.1825],\n",
      "        [-10.3746,  11.8598,  -4.8315],\n",
      "        [ -9.8049,  11.5486,  -5.1341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.2285,   6.2084,   8.1452, -10.1161,  11.6256,  -5.0474],\n",
      "        [ 12.6539,   6.2224,   8.0541,  -9.9497,  12.0240,  -4.9955],\n",
      "        [ 12.5814,   6.4438,   8.4341, -10.1587,  11.8178,  -5.0259],\n",
      "        [ 12.4568,   6.5490,   8.3272, -10.2051,  11.5031,  -5.1825],\n",
      "        [ 12.3712,   6.2484,   8.0821, -10.3746,  11.8598,  -4.8315],\n",
      "        [ 12.6214,   6.6660,   8.3919,  -9.8049,  11.5486,  -5.1341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.0832853317260742\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6863, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7388,  6.2570,  8.6226],\n",
      "        [12.6434,  6.5663,  8.6459],\n",
      "        [12.5456,  6.5667,  8.3896],\n",
      "        [12.1024,  6.1868,  8.5650],\n",
      "        [12.1746,  6.4227,  8.2539],\n",
      "        [12.8854,  6.4720,  8.1317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.7748, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.9950,  11.4671,  -4.8497],\n",
      "        [ -9.5344,  11.1031,  -4.9762],\n",
      "        [-10.0843,  11.5522,  -5.1082],\n",
      "        [-10.1936,  11.4621,  -5.2726],\n",
      "        [ -9.8873,  11.6238,  -5.4370],\n",
      "        [ -9.8739,  11.6078,  -5.1563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7388,   6.2570,   8.6226,  -9.9950,  11.4671,  -4.8497],\n",
      "        [ 12.6434,   6.5663,   8.6459,  -9.5344,  11.1031,  -4.9762],\n",
      "        [ 12.5456,   6.5667,   8.3896, -10.0843,  11.5522,  -5.1082],\n",
      "        [ 12.1024,   6.1868,   8.5650, -10.1936,  11.4621,  -5.2726],\n",
      "        [ 12.1746,   6.4227,   8.2539,  -9.8873,  11.6238,  -5.4370],\n",
      "        [ 12.8854,   6.4720,   8.1317,  -9.8739,  11.6078,  -5.1563]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1087671518325806\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3811, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7719,  6.4948,  8.3430],\n",
      "        [12.2043,  6.6898,  8.1958],\n",
      "        [12.6270,  6.4551,  8.0907],\n",
      "        [12.6399,  6.1695,  8.1139],\n",
      "        [12.3071,  6.5619,  8.2783],\n",
      "        [12.2218,  6.4207,  8.3111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.6750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0418,  11.6701,  -5.2605],\n",
      "        [-10.0821,  11.1265,  -4.7178],\n",
      "        [ -9.6119,  11.4129,  -4.8768],\n",
      "        [-10.0957,  11.7003,  -5.0050],\n",
      "        [-10.1656,  11.7239,  -5.0856],\n",
      "        [ -9.5610,  11.6395,  -5.0791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7719,   6.4948,   8.3430, -10.0418,  11.6701,  -5.2605],\n",
      "        [ 12.2043,   6.6898,   8.1958, -10.0821,  11.1265,  -4.7178],\n",
      "        [ 12.6270,   6.4551,   8.0907,  -9.6119,  11.4129,  -4.8768],\n",
      "        [ 12.6399,   6.1695,   8.1139, -10.0957,  11.7003,  -5.0050],\n",
      "        [ 12.3071,   6.5619,   8.2783, -10.1656,  11.7239,  -5.0856],\n",
      "        [ 12.2218,   6.4207,   8.3111,  -9.5610,  11.6395,  -5.0791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1134432554244995\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7361, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.3019,  6.6206,  8.4626],\n",
      "        [12.7951,  6.6708,  8.4826],\n",
      "        [12.9148,  6.6733,  8.4828],\n",
      "        [12.5986,  6.7709,  8.2901],\n",
      "        [12.3573,  6.3982,  8.1650],\n",
      "        [12.2083,  6.3801,  8.1594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1455,  11.1159,  -5.0066],\n",
      "        [-10.0476,  11.4153,  -4.9753],\n",
      "        [-10.1622,  11.8600,  -5.3077],\n",
      "        [-10.1712,  11.6080,  -5.2569],\n",
      "        [ -9.9057,  11.6098,  -5.2956],\n",
      "        [-10.0230,  11.7834,  -4.8812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.3019,   6.6206,   8.4626, -10.1455,  11.1159,  -5.0066],\n",
      "        [ 12.7951,   6.6708,   8.4826, -10.0476,  11.4153,  -4.9753],\n",
      "        [ 12.9148,   6.6733,   8.4828, -10.1622,  11.8600,  -5.3077],\n",
      "        [ 12.5986,   6.7709,   8.2901, -10.1712,  11.6080,  -5.2569],\n",
      "        [ 12.3573,   6.3982,   8.1650,  -9.9057,  11.6098,  -5.2956],\n",
      "        [ 12.2083,   6.3801,   8.1594, -10.0230,  11.7834,  -4.8812]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.0931577682495117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4189,  6.3500,  8.0759],\n",
      "        [12.2872,  6.5861,  8.0864],\n",
      "        [12.5788,  6.0733,  8.3031],\n",
      "        [12.6928,  6.6439,  8.3936],\n",
      "        [12.2539,  6.1854,  8.3130],\n",
      "        [12.8565,  6.7526,  8.6148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.1647, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1216,  11.8101,  -5.0747],\n",
      "        [-10.3275,  11.7014,  -5.2414],\n",
      "        [ -9.8585,  11.3029,  -5.1582],\n",
      "        [ -9.9782,  11.2742,  -5.1471],\n",
      "        [-10.1063,  11.8151,  -5.2947],\n",
      "        [ -9.8210,  11.8786,  -5.4774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.4189,   6.3500,   8.0759, -10.1216,  11.8101,  -5.0747],\n",
      "        [ 12.2872,   6.5861,   8.0864, -10.3275,  11.7014,  -5.2414],\n",
      "        [ 12.5788,   6.0733,   8.3031,  -9.8585,  11.3029,  -5.1582],\n",
      "        [ 12.6928,   6.6439,   8.3936,  -9.9782,  11.2742,  -5.1471],\n",
      "        [ 12.2539,   6.1854,   8.3130, -10.1063,  11.8151,  -5.2947],\n",
      "        [ 12.8565,   6.7526,   8.6148,  -9.8210,  11.8786,  -5.4774]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.096289038658142\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5164,  6.6960,  8.1963],\n",
      "        [12.3836,  6.5130,  7.8510],\n",
      "        [12.3673,  6.4302,  8.2793],\n",
      "        [12.4862,  6.5002,  8.4783],\n",
      "        [12.6508,  6.2486,  8.4797],\n",
      "        [12.5045,  6.2278,  8.4461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.1947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0023,  11.6188,  -5.1165],\n",
      "        [-10.0866,  11.5647,  -5.0013],\n",
      "        [ -9.8037,  11.6417,  -5.0640],\n",
      "        [-10.1262,  11.3551,  -5.3825],\n",
      "        [-10.1242,  11.5626,  -4.9490],\n",
      "        [-10.4186,  11.8183,  -5.1642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5164,   6.6960,   8.1963, -10.0023,  11.6188,  -5.1165],\n",
      "        [ 12.3836,   6.5130,   7.8510, -10.0866,  11.5647,  -5.0013],\n",
      "        [ 12.3673,   6.4302,   8.2793,  -9.8037,  11.6417,  -5.0640],\n",
      "        [ 12.4862,   6.5002,   8.4783, -10.1262,  11.3551,  -5.3825],\n",
      "        [ 12.6508,   6.2486,   8.4797, -10.1242,  11.5626,  -4.9490],\n",
      "        [ 12.5045,   6.2278,   8.4461, -10.4186,  11.8183,  -5.1642]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1034811735153198\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1028, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6653,  6.4446,  8.5588],\n",
      "        [12.8859,  6.7627,  8.4632],\n",
      "        [12.2626,  6.2278,  8.2740],\n",
      "        [12.2433,  6.3611,  8.1508],\n",
      "        [12.8335,  6.5764,  8.4138],\n",
      "        [12.7265,  6.7351,  8.3835]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.5595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.7911,  11.4548,  -4.8139],\n",
      "        [-10.3131,  11.7630,  -4.9728],\n",
      "        [-10.0561,  11.5062,  -5.1147],\n",
      "        [-10.2858,  11.9064,  -5.1941],\n",
      "        [-10.0355,  11.6639,  -5.3649],\n",
      "        [-10.2114,  11.8861,  -5.4934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6653,   6.4446,   8.5588,  -9.7911,  11.4548,  -4.8139],\n",
      "        [ 12.8859,   6.7627,   8.4632, -10.3131,  11.7630,  -4.9728],\n",
      "        [ 12.2626,   6.2278,   8.2740, -10.0561,  11.5062,  -5.1147],\n",
      "        [ 12.2433,   6.3611,   8.1508, -10.2858,  11.9064,  -5.1941],\n",
      "        [ 12.8335,   6.5764,   8.4138, -10.0355,  11.6639,  -5.3649],\n",
      "        [ 12.7265,   6.7351,   8.3835, -10.2114,  11.8861,  -5.4934]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1074005365371704\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7786, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5478,  6.6166,  8.1947],\n",
      "        [12.7299,  6.5061,  8.3223],\n",
      "        [12.5660,  6.1778,  8.3241],\n",
      "        [12.6376,  6.4827,  8.5054],\n",
      "        [12.7586,  6.7305,  8.3037],\n",
      "        [12.5925,  6.4452,  7.8801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4364, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3707,  12.4444,  -5.4953],\n",
      "        [ -9.8669,  11.2747,  -5.4412],\n",
      "        [ -9.9003,  11.8906,  -5.4286],\n",
      "        [-10.3004,  11.6104,  -5.0719],\n",
      "        [ -9.9605,  11.6389,  -5.4824],\n",
      "        [-10.2047,  11.8820,  -5.0866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5478,   6.6166,   8.1947, -10.3707,  12.4444,  -5.4953],\n",
      "        [ 12.7299,   6.5061,   8.3223,  -9.8669,  11.2747,  -5.4412],\n",
      "        [ 12.5660,   6.1778,   8.3241,  -9.9003,  11.8906,  -5.4286],\n",
      "        [ 12.6376,   6.4827,   8.5054, -10.3004,  11.6104,  -5.0719],\n",
      "        [ 12.7586,   6.7305,   8.3037,  -9.9605,  11.6389,  -5.4824],\n",
      "        [ 12.5925,   6.4452,   7.8801, -10.2047,  11.8820,  -5.0866]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1264371871948242\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5928,  6.7621,  8.0983],\n",
      "        [12.6135,  6.6965,  8.4246],\n",
      "        [12.5831,  6.4559,  8.2009],\n",
      "        [12.5394,  6.5161,  8.4089],\n",
      "        [12.6271,  6.5003,  8.5374],\n",
      "        [12.5359,  6.6243,  8.2103]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0367,  11.7972,  -5.0717],\n",
      "        [ -9.8361,  11.1845,  -5.1211],\n",
      "        [-10.4767,  11.4974,  -5.0482],\n",
      "        [-10.2297,  11.7336,  -5.3621],\n",
      "        [ -9.7934,  11.5962,  -5.0904],\n",
      "        [-10.2359,  11.7929,  -5.1972]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5928,   6.7621,   8.0983, -10.0367,  11.7972,  -5.0717],\n",
      "        [ 12.6135,   6.6965,   8.4246,  -9.8361,  11.1845,  -5.1211],\n",
      "        [ 12.5831,   6.4559,   8.2009, -10.4767,  11.4974,  -5.0482],\n",
      "        [ 12.5394,   6.5161,   8.4089, -10.2297,  11.7336,  -5.3621],\n",
      "        [ 12.6271,   6.5003,   8.5374,  -9.7934,  11.5962,  -5.0904],\n",
      "        [ 12.5359,   6.6243,   8.2103, -10.2359,  11.7929,  -5.1972]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1099656820297241\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5585,  6.6025,  8.4146],\n",
      "        [12.7254,  6.4837,  8.0659],\n",
      "        [12.6433,  6.5770,  8.1110],\n",
      "        [12.4062,  6.1999,  8.1321],\n",
      "        [12.5555,  6.9823,  8.1576],\n",
      "        [12.1214,  6.3113,  8.0344]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4081, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0765,  11.8665,  -5.1721],\n",
      "        [-10.0657,  11.6738,  -5.4476],\n",
      "        [-10.0653,  12.1208,  -5.1860],\n",
      "        [-10.1030,  11.5392,  -5.5333],\n",
      "        [-10.0337,  11.7724,  -5.1079],\n",
      "        [-10.4546,  11.5566,  -5.3147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5585,   6.6025,   8.4146, -10.0765,  11.8665,  -5.1721],\n",
      "        [ 12.7254,   6.4837,   8.0659, -10.0657,  11.6738,  -5.4476],\n",
      "        [ 12.6433,   6.5770,   8.1110, -10.0653,  12.1208,  -5.1860],\n",
      "        [ 12.4062,   6.1999,   8.1321, -10.1030,  11.5392,  -5.5333],\n",
      "        [ 12.5555,   6.9823,   8.1576, -10.0337,  11.7724,  -5.1079],\n",
      "        [ 12.1214,   6.3113,   8.0344, -10.4546,  11.5566,  -5.3147]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.117632269859314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9037, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5172,  6.7034,  8.4023],\n",
      "        [12.4414,  6.8399,  8.2141],\n",
      "        [12.4252,  6.6904,  8.2211],\n",
      "        [12.2226,  6.4064,  8.5216],\n",
      "        [12.6144,  6.8618,  8.3809],\n",
      "        [12.5695,  6.7967,  8.4104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9712, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2982,  11.8468,  -5.0006],\n",
      "        [-10.2792,  11.7541,  -5.0439],\n",
      "        [ -9.9050,  11.3997,  -5.0512],\n",
      "        [-10.2142,  11.4598,  -5.2243],\n",
      "        [-10.2064,  11.6960,  -5.3648],\n",
      "        [-10.2949,  11.7705,  -5.2819]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5172,   6.7034,   8.4023, -10.2982,  11.8468,  -5.0006],\n",
      "        [ 12.4414,   6.8399,   8.2141, -10.2792,  11.7541,  -5.0439],\n",
      "        [ 12.4252,   6.6904,   8.2211,  -9.9050,  11.3997,  -5.0512],\n",
      "        [ 12.2226,   6.4064,   8.5216, -10.2142,  11.4598,  -5.2243],\n",
      "        [ 12.6144,   6.8618,   8.3809, -10.2064,  11.6960,  -5.3648],\n",
      "        [ 12.5695,   6.7967,   8.4104, -10.2949,  11.7705,  -5.2819]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1197855472564697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.4485,  6.3651,  8.4353],\n",
      "        [12.6095,  6.6308,  8.4281],\n",
      "        [12.7121,  6.3488,  8.2125],\n",
      "        [12.4753,  6.7853,  8.2026],\n",
      "        [12.5707,  6.5292,  8.2865],\n",
      "        [12.4925,  6.3729,  8.4829]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.3174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3847,  11.9509,  -5.3794],\n",
      "        [-10.3612,  11.5559,  -5.3992],\n",
      "        [-10.1076,  11.5992,  -5.0807],\n",
      "        [-10.3053,  11.7557,  -5.2950],\n",
      "        [-10.0781,  11.9092,  -5.4703],\n",
      "        [-10.0813,  11.7929,  -5.2954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.4485,   6.3651,   8.4353, -10.3847,  11.9509,  -5.3794],\n",
      "        [ 12.6095,   6.6308,   8.4281, -10.3612,  11.5559,  -5.3992],\n",
      "        [ 12.7121,   6.3488,   8.2125, -10.1076,  11.5992,  -5.0807],\n",
      "        [ 12.4753,   6.7853,   8.2026, -10.3053,  11.7557,  -5.2950],\n",
      "        [ 12.5707,   6.5292,   8.2865, -10.0781,  11.9092,  -5.4703],\n",
      "        [ 12.4925,   6.3729,   8.4829, -10.0813,  11.7929,  -5.2954]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1196675300598145\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0760, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5050,  6.5734,  8.6336],\n",
      "        [12.7399,  6.3708,  8.4030],\n",
      "        [12.7616,  6.6473,  8.3426],\n",
      "        [12.3312,  6.5603,  8.4084],\n",
      "        [12.8721,  6.4537,  8.4222],\n",
      "        [12.3934,  6.6418,  8.1836]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4675,  11.8967,  -5.4558],\n",
      "        [-10.0145,  11.7980,  -5.4688],\n",
      "        [-10.1555,  11.2685,  -5.3938],\n",
      "        [-10.0509,  11.7229,  -5.2921],\n",
      "        [-10.2020,  11.4458,  -4.9274],\n",
      "        [ -9.9875,  11.5003,  -5.3165]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5050,   6.5734,   8.6336, -10.4675,  11.8967,  -5.4558],\n",
      "        [ 12.7399,   6.3708,   8.4030, -10.0145,  11.7980,  -5.4688],\n",
      "        [ 12.7616,   6.6473,   8.3426, -10.1555,  11.2685,  -5.3938],\n",
      "        [ 12.3312,   6.5603,   8.4084, -10.0509,  11.7229,  -5.2921],\n",
      "        [ 12.8721,   6.4537,   8.4222, -10.2020,  11.4458,  -4.9274],\n",
      "        [ 12.3934,   6.6418,   8.1836,  -9.9875,  11.5003,  -5.3165]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1309915781021118\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.2460,  6.6745,  8.2782],\n",
      "        [12.9375,  6.9714,  8.2943],\n",
      "        [12.4981,  6.6414,  8.0913],\n",
      "        [12.9756,  6.7663,  8.1187],\n",
      "        [12.2441,  6.6129,  8.2909],\n",
      "        [12.9442,  6.3962,  8.5566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.8798, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1759,  11.6098,  -5.2717],\n",
      "        [-10.0126,  11.8458,  -5.2221],\n",
      "        [ -9.9031,  11.7315,  -5.3404],\n",
      "        [-10.2536,  12.0165,  -5.0968],\n",
      "        [-10.2973,  11.9142,  -5.1093],\n",
      "        [-10.1203,  11.9960,  -5.4633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.2460,   6.6745,   8.2782, -10.1759,  11.6098,  -5.2717],\n",
      "        [ 12.9375,   6.9714,   8.2943, -10.0126,  11.8458,  -5.2221],\n",
      "        [ 12.4981,   6.6414,   8.0913,  -9.9031,  11.7315,  -5.3404],\n",
      "        [ 12.9756,   6.7663,   8.1187, -10.2536,  12.0165,  -5.0968],\n",
      "        [ 12.2441,   6.6129,   8.2909, -10.2973,  11.9142,  -5.1093],\n",
      "        [ 12.9442,   6.3962,   8.5566, -10.1203,  11.9960,  -5.4633]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.104893684387207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4858, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5164,  6.3534,  8.3690],\n",
      "        [12.5544,  6.5420,  8.1079],\n",
      "        [12.9292,  6.5369,  8.4001],\n",
      "        [12.7446,  6.2846,  8.5265],\n",
      "        [12.9282,  6.7970,  8.4997],\n",
      "        [12.8687,  6.6097,  8.3689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9402, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1555,  11.5059,  -5.2671],\n",
      "        [-10.3400,  11.4948,  -5.2343],\n",
      "        [-10.2629,  11.8914,  -5.3479],\n",
      "        [-10.2573,  11.8643,  -5.2848],\n",
      "        [-10.1293,  11.6964,  -5.6677],\n",
      "        [-10.0012,  11.5911,  -5.1309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5164,   6.3534,   8.3690, -10.1555,  11.5059,  -5.2671],\n",
      "        [ 12.5544,   6.5420,   8.1079, -10.3400,  11.4948,  -5.2343],\n",
      "        [ 12.9292,   6.5369,   8.4001, -10.2629,  11.8914,  -5.3479],\n",
      "        [ 12.7446,   6.2846,   8.5265, -10.2573,  11.8643,  -5.2848],\n",
      "        [ 12.9282,   6.7970,   8.4997, -10.1293,  11.6964,  -5.6677],\n",
      "        [ 12.8687,   6.6097,   8.3689, -10.0012,  11.5911,  -5.1309]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1108285188674927\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7729,  6.6072,  8.3103],\n",
      "        [12.4688,  6.4743,  8.4095],\n",
      "        [12.7301,  6.7650,  8.2952],\n",
      "        [12.7647,  6.2589,  8.3623],\n",
      "        [12.5611,  6.6457,  8.5562],\n",
      "        [12.8408,  6.4841,  8.2753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3266,  11.6229,  -5.3431],\n",
      "        [-10.2098,  12.1389,  -5.3847],\n",
      "        [-10.1992,  11.6006,  -5.3835],\n",
      "        [ -9.9430,  11.5724,  -5.2553],\n",
      "        [-10.2568,  11.8835,  -5.0300],\n",
      "        [-10.3607,  11.7854,  -5.3419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7729,   6.6072,   8.3103, -10.3266,  11.6229,  -5.3431],\n",
      "        [ 12.4688,   6.4743,   8.4095, -10.2098,  12.1389,  -5.3847],\n",
      "        [ 12.7301,   6.7650,   8.2952, -10.1992,  11.6006,  -5.3835],\n",
      "        [ 12.7647,   6.2589,   8.3623,  -9.9430,  11.5724,  -5.2553],\n",
      "        [ 12.5611,   6.6457,   8.5562, -10.2568,  11.8835,  -5.0300],\n",
      "        [ 12.8408,   6.4841,   8.2753, -10.3607,  11.7854,  -5.3419]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1274611949920654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3687, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7715,  6.9185,  8.2933],\n",
      "        [12.4264,  6.3505,  8.0264],\n",
      "        [12.5485,  6.6910,  8.1733],\n",
      "        [12.8213,  6.7454,  8.6771],\n",
      "        [12.8656,  6.8576,  8.6358],\n",
      "        [12.1969,  6.3436,  8.4654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.3094, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4014,  11.7884,  -5.2929],\n",
      "        [-10.1023,  11.6767,  -5.2567],\n",
      "        [-10.0495,  11.5546,  -5.2765],\n",
      "        [-10.2835,  11.1669,  -5.2063],\n",
      "        [-10.3211,  11.7562,  -5.1581],\n",
      "        [-10.3611,  11.8841,  -5.0896]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7715,   6.9185,   8.2933, -10.4014,  11.7884,  -5.2929],\n",
      "        [ 12.4264,   6.3505,   8.0264, -10.1023,  11.6767,  -5.2567],\n",
      "        [ 12.5485,   6.6910,   8.1733, -10.0495,  11.5546,  -5.2765],\n",
      "        [ 12.8213,   6.7454,   8.6771, -10.2835,  11.1669,  -5.2063],\n",
      "        [ 12.8656,   6.8576,   8.6358, -10.3211,  11.7562,  -5.1581],\n",
      "        [ 12.1969,   6.3436,   8.4654, -10.3611,  11.8841,  -5.0896]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1355966329574585\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1272, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9200,  6.6127,  8.4846],\n",
      "        [12.6594,  6.5717,  8.3758],\n",
      "        [13.0781,  6.4888,  8.4967],\n",
      "        [12.5189,  6.6435,  8.5155],\n",
      "        [12.6559,  6.7284,  8.4309],\n",
      "        [12.4888,  6.6939,  8.3355]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7618,  12.0090,  -5.3005],\n",
      "        [ -9.9348,  11.9464,  -5.1209],\n",
      "        [-10.3098,  12.1137,  -5.2472],\n",
      "        [-10.1225,  11.8255,  -5.3563],\n",
      "        [-10.2207,  11.7769,  -5.0911],\n",
      "        [-10.1747,  11.8585,  -5.2312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9200,   6.6127,   8.4846, -10.7618,  12.0090,  -5.3005],\n",
      "        [ 12.6594,   6.5717,   8.3758,  -9.9348,  11.9464,  -5.1209],\n",
      "        [ 13.0781,   6.4888,   8.4967, -10.3098,  12.1137,  -5.2472],\n",
      "        [ 12.5189,   6.6435,   8.5155, -10.1225,  11.8255,  -5.3563],\n",
      "        [ 12.6559,   6.7284,   8.4309, -10.2207,  11.7769,  -5.0911],\n",
      "        [ 12.4888,   6.6939,   8.3355, -10.1747,  11.8585,  -5.2312]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.151143193244934\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8094, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9397,  6.7373,  8.3284],\n",
      "        [12.6421,  6.5682,  8.1291],\n",
      "        [12.9428,  7.0386,  8.1767],\n",
      "        [12.6738,  6.6916,  8.3317],\n",
      "        [12.8566,  6.9520,  8.2910],\n",
      "        [12.3533,  6.6199,  8.4671]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9252, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6263,  12.0287,  -5.3587],\n",
      "        [-10.4597,  11.7100,  -5.4546],\n",
      "        [-10.0938,  11.6535,  -5.1533],\n",
      "        [-10.0316,  11.9302,  -5.3069],\n",
      "        [-10.1347,  11.7859,  -5.6486],\n",
      "        [-10.4823,  11.9653,  -5.6037]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9397,   6.7373,   8.3284, -10.6263,  12.0287,  -5.3587],\n",
      "        [ 12.6421,   6.5682,   8.1291, -10.4597,  11.7100,  -5.4546],\n",
      "        [ 12.9428,   7.0386,   8.1767, -10.0938,  11.6535,  -5.1533],\n",
      "        [ 12.6738,   6.6916,   8.3317, -10.0316,  11.9302,  -5.3069],\n",
      "        [ 12.8566,   6.9520,   8.2910, -10.1347,  11.7859,  -5.6486],\n",
      "        [ 12.3533,   6.6199,   8.4671, -10.4823,  11.9653,  -5.6037]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.149090051651001\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.8886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0252,  6.6729,  8.3681],\n",
      "        [12.7631,  6.5614,  8.4837],\n",
      "        [12.7358,  6.4525,  8.4127],\n",
      "        [12.6191,  6.4296,  8.4121],\n",
      "        [12.6790,  6.6409,  8.4789],\n",
      "        [13.0019,  6.4858,  8.1816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.6227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.9197,  12.0078,  -5.2405],\n",
      "        [-10.3175,  11.9208,  -5.5458],\n",
      "        [-10.1500,  11.7215,  -5.2391],\n",
      "        [-10.1023,  11.0344,  -5.1301],\n",
      "        [-10.2452,  11.7084,  -5.3083],\n",
      "        [-10.0736,  11.6255,  -5.1063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0252,   6.6729,   8.3681,  -9.9197,  12.0078,  -5.2405],\n",
      "        [ 12.7631,   6.5614,   8.4837, -10.3175,  11.9208,  -5.5458],\n",
      "        [ 12.7358,   6.4525,   8.4127, -10.1500,  11.7215,  -5.2391],\n",
      "        [ 12.6191,   6.4296,   8.4121, -10.1023,  11.0344,  -5.1301],\n",
      "        [ 12.6790,   6.6409,   8.4789, -10.2452,  11.7084,  -5.3083],\n",
      "        [ 13.0019,   6.4858,   8.1816, -10.0736,  11.6255,  -5.1063]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1415798664093018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7369, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6320,  6.5274,  8.2883],\n",
      "        [12.5792,  6.5878,  8.5831],\n",
      "        [12.5310,  6.5204,  8.2717],\n",
      "        [12.4114,  6.4606,  8.4137],\n",
      "        [12.7259,  7.0264,  8.5006],\n",
      "        [12.7311,  6.9033,  8.4171]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.5288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2884,  11.6098,  -5.2503],\n",
      "        [-10.2299,  12.1932,  -5.7195],\n",
      "        [-10.2883,  11.8027,  -5.2583],\n",
      "        [-10.5165,  11.7101,  -5.3308],\n",
      "        [-10.4664,  12.0673,  -5.4052],\n",
      "        [-10.2649,  11.2277,  -5.3865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6320,   6.5274,   8.2883, -10.2884,  11.6098,  -5.2503],\n",
      "        [ 12.5792,   6.5878,   8.5831, -10.2299,  12.1932,  -5.7195],\n",
      "        [ 12.5310,   6.5204,   8.2717, -10.2883,  11.8027,  -5.2583],\n",
      "        [ 12.4114,   6.4606,   8.4137, -10.5165,  11.7101,  -5.3308],\n",
      "        [ 12.7259,   7.0264,   8.5006, -10.4664,  12.0673,  -5.4052],\n",
      "        [ 12.7311,   6.9033,   8.4171, -10.2649,  11.2277,  -5.3865]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1231517791748047\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7984,  6.3875,  8.6147],\n",
      "        [12.5481,  6.4745,  8.2560],\n",
      "        [13.0744,  6.9014,  8.6492],\n",
      "        [12.8894,  6.6674,  8.5154],\n",
      "        [12.9596,  6.6147,  8.5054],\n",
      "        [12.3274,  6.9047,  8.6896]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.8548, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2868,  11.6715,  -5.3031],\n",
      "        [-10.4630,  11.7540,  -5.3954],\n",
      "        [-10.3729,  11.8174,  -4.8808],\n",
      "        [-10.5285,  11.6115,  -5.4562],\n",
      "        [ -9.9949,  11.5688,  -5.5507],\n",
      "        [-10.3689,  11.3780,  -4.8917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7984,   6.3875,   8.6147, -10.2868,  11.6715,  -5.3031],\n",
      "        [ 12.5481,   6.4745,   8.2560, -10.4630,  11.7540,  -5.3954],\n",
      "        [ 13.0744,   6.9014,   8.6492, -10.3729,  11.8174,  -4.8808],\n",
      "        [ 12.8894,   6.6674,   8.5154, -10.5285,  11.6115,  -5.4562],\n",
      "        [ 12.9596,   6.6147,   8.5054,  -9.9949,  11.5688,  -5.5507],\n",
      "        [ 12.3274,   6.9047,   8.6896, -10.3689,  11.3780,  -4.8917]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.137396216392517\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7168, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.1681,  7.0049,  8.3420],\n",
      "        [12.5733,  6.6545,  8.2728],\n",
      "        [12.9042,  6.8786,  8.2289],\n",
      "        [13.1068,  6.6042,  8.6770],\n",
      "        [12.7539,  6.6600,  8.3321],\n",
      "        [12.7245,  6.6285,  8.5231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.2223, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3263,  11.9586,  -5.4614],\n",
      "        [ -9.9415,  11.4892,  -5.1904],\n",
      "        [-10.2033,  11.4246,  -5.3545],\n",
      "        [-10.3865,  11.5829,  -5.1318],\n",
      "        [-10.4110,  12.0087,  -5.6888],\n",
      "        [-10.3216,  11.6523,  -5.4169]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.1681,   7.0049,   8.3420, -10.3263,  11.9586,  -5.4614],\n",
      "        [ 12.5733,   6.6545,   8.2728,  -9.9415,  11.4892,  -5.1904],\n",
      "        [ 12.9042,   6.8786,   8.2289, -10.2033,  11.4246,  -5.3545],\n",
      "        [ 13.1068,   6.6042,   8.6770, -10.3865,  11.5829,  -5.1318],\n",
      "        [ 12.7539,   6.6600,   8.3321, -10.4110,  12.0087,  -5.6888],\n",
      "        [ 12.7245,   6.6285,   8.5231, -10.3216,  11.6523,  -5.4169]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1242269277572632\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9371, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8832,  6.6623,  8.5610],\n",
      "        [12.6352,  6.6715,  8.3044],\n",
      "        [12.5218,  6.6082,  8.5907],\n",
      "        [12.4375,  6.4493,  8.6504],\n",
      "        [12.6580,  6.9176,  8.4220],\n",
      "        [12.5627,  7.0561,  8.4873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2308,  11.6605,  -5.2348],\n",
      "        [-10.0623,  11.3831,  -5.2902],\n",
      "        [-10.4253,  11.8865,  -5.4111],\n",
      "        [-10.0584,  11.3597,  -5.0611],\n",
      "        [-10.6566,  11.8495,  -5.4415],\n",
      "        [-10.1658,  11.7347,  -5.6209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8832,   6.6623,   8.5610, -10.2308,  11.6605,  -5.2348],\n",
      "        [ 12.6352,   6.6715,   8.3044, -10.0623,  11.3831,  -5.2902],\n",
      "        [ 12.5218,   6.6082,   8.5907, -10.4253,  11.8865,  -5.4111],\n",
      "        [ 12.4375,   6.4493,   8.6504, -10.0584,  11.3597,  -5.0611],\n",
      "        [ 12.6580,   6.9176,   8.4220, -10.6566,  11.8495,  -5.4415],\n",
      "        [ 12.5627,   7.0561,   8.4873, -10.1658,  11.7347,  -5.6209]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.142848014831543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7549,  6.5170,  8.4910],\n",
      "        [12.9562,  6.7642,  8.8002],\n",
      "        [13.2173,  6.5573,  8.4934],\n",
      "        [12.8337,  6.8061,  8.4711],\n",
      "        [12.8122,  6.7597,  8.3451],\n",
      "        [12.6911,  6.6266,  8.3306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.6452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3721,  11.7546,  -5.5983],\n",
      "        [-10.3627,  11.9036,  -5.6121],\n",
      "        [-10.2604,  12.2131,  -5.5763],\n",
      "        [-10.4206,  11.9337,  -5.3867],\n",
      "        [-10.5272,  11.9635,  -5.4266],\n",
      "        [-10.4853,  11.7681,  -5.1656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7549,   6.5170,   8.4910, -10.3721,  11.7546,  -5.5983],\n",
      "        [ 12.9562,   6.7642,   8.8002, -10.3627,  11.9036,  -5.6121],\n",
      "        [ 13.2173,   6.5573,   8.4934, -10.2604,  12.2131,  -5.5763],\n",
      "        [ 12.8337,   6.8061,   8.4711, -10.4206,  11.9337,  -5.3867],\n",
      "        [ 12.8122,   6.7597,   8.3451, -10.5272,  11.9635,  -5.4266],\n",
      "        [ 12.6911,   6.6266,   8.3306, -10.4853,  11.7681,  -5.1656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1412949562072754\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5955,  6.8361,  8.2974],\n",
      "        [12.9163,  6.6057,  8.5394],\n",
      "        [13.0839,  6.9614,  8.6634],\n",
      "        [13.0023,  6.5604,  8.4226],\n",
      "        [12.7522,  6.4490,  8.9700],\n",
      "        [12.9813,  6.8070,  8.3851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.8189, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4338,  12.0763,  -5.5196],\n",
      "        [-10.4920,  12.2891,  -5.7477],\n",
      "        [-10.0434,  11.9639,  -5.2019],\n",
      "        [ -9.9713,  11.6789,  -5.2822],\n",
      "        [-10.4154,  11.7582,  -5.7320],\n",
      "        [-10.2684,  12.0401,  -5.5697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5955,   6.8361,   8.2974, -10.4338,  12.0763,  -5.5196],\n",
      "        [ 12.9163,   6.6057,   8.5394, -10.4920,  12.2891,  -5.7477],\n",
      "        [ 13.0839,   6.9614,   8.6634, -10.0434,  11.9639,  -5.2019],\n",
      "        [ 13.0023,   6.5604,   8.4226,  -9.9713,  11.6789,  -5.2822],\n",
      "        [ 12.7522,   6.4490,   8.9700, -10.4154,  11.7582,  -5.7320],\n",
      "        [ 12.9813,   6.8070,   8.3851, -10.2684,  12.0401,  -5.5697]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1418712139129639\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0119, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7655,  6.4067,  8.3975],\n",
      "        [12.8747,  6.8084,  8.4815],\n",
      "        [12.3661,  6.5886,  8.4197],\n",
      "        [12.9318,  6.9692,  8.5810],\n",
      "        [12.4833,  6.6807,  8.5562],\n",
      "        [12.5178,  6.8025,  8.4389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6324,  11.5640,  -5.5487],\n",
      "        [-10.3283,  12.1240,  -5.6363],\n",
      "        [-10.3836,  11.9401,  -5.4805],\n",
      "        [-10.0506,  11.8084,  -5.3615],\n",
      "        [-10.6262,  11.9646,  -5.5206],\n",
      "        [-10.6279,  12.0002,  -5.4221]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7655,   6.4067,   8.3975, -10.6324,  11.5640,  -5.5487],\n",
      "        [ 12.8747,   6.8084,   8.4815, -10.3283,  12.1240,  -5.6363],\n",
      "        [ 12.3661,   6.5886,   8.4197, -10.3836,  11.9401,  -5.4805],\n",
      "        [ 12.9318,   6.9692,   8.5810, -10.0506,  11.8084,  -5.3615],\n",
      "        [ 12.4833,   6.6807,   8.5562, -10.6262,  11.9646,  -5.5206],\n",
      "        [ 12.5178,   6.8025,   8.4389, -10.6279,  12.0002,  -5.4221]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.139434814453125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4171, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6983,  7.0304,  8.3611],\n",
      "        [12.7590,  6.7960,  8.2894],\n",
      "        [12.9865,  6.7850,  8.6928],\n",
      "        [12.5823,  6.8081,  8.3096],\n",
      "        [12.6454,  6.6474,  8.3944],\n",
      "        [12.9704,  6.7141,  8.4993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.9328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4440,  11.5171,  -5.2577],\n",
      "        [-10.3221,  11.7384,  -5.5486],\n",
      "        [-10.3379,  11.9022,  -5.3415],\n",
      "        [-10.5417,  12.1250,  -5.3144],\n",
      "        [-10.5787,  11.7405,  -5.5946],\n",
      "        [-10.4107,  12.1390,  -5.5129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6983,   7.0304,   8.3611, -10.4440,  11.5171,  -5.2577],\n",
      "        [ 12.7590,   6.7960,   8.2894, -10.3221,  11.7384,  -5.5486],\n",
      "        [ 12.9865,   6.7850,   8.6928, -10.3379,  11.9022,  -5.3415],\n",
      "        [ 12.5823,   6.8081,   8.3096, -10.5417,  12.1250,  -5.3144],\n",
      "        [ 12.6454,   6.6474,   8.3944, -10.5787,  11.7405,  -5.5946],\n",
      "        [ 12.9704,   6.7141,   8.4993, -10.4107,  12.1390,  -5.5129]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1401643753051758\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8137,  6.8160,  8.3844],\n",
      "        [12.8855,  6.5563,  8.4780],\n",
      "        [12.9565,  6.5739,  8.4448],\n",
      "        [12.6441,  6.6997,  8.5422],\n",
      "        [12.6572,  6.6064,  8.5110],\n",
      "        [12.9143,  6.6465,  8.4726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.6619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4413,  12.0948,  -5.6500],\n",
      "        [-10.5539,  11.6683,  -5.4529],\n",
      "        [ -9.9680,  12.0672,  -5.2613],\n",
      "        [-10.0575,  11.6534,  -5.6446],\n",
      "        [-10.0174,  11.8314,  -5.7610],\n",
      "        [-10.6031,  11.3589,  -5.4619]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8137,   6.8160,   8.3844, -10.4413,  12.0948,  -5.6500],\n",
      "        [ 12.8855,   6.5563,   8.4780, -10.5539,  11.6683,  -5.4529],\n",
      "        [ 12.9565,   6.5739,   8.4448,  -9.9680,  12.0672,  -5.2613],\n",
      "        [ 12.6441,   6.6997,   8.5422, -10.0575,  11.6534,  -5.6446],\n",
      "        [ 12.6572,   6.6064,   8.5110, -10.0174,  11.8314,  -5.7610],\n",
      "        [ 12.9143,   6.6465,   8.4726, -10.6031,  11.3589,  -5.4619]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1549508571624756\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9314,  6.6358,  8.7653],\n",
      "        [12.8023,  6.7856,  8.5483],\n",
      "        [13.2088,  6.7657,  8.6127],\n",
      "        [13.0866,  6.9235,  8.4851],\n",
      "        [12.6714,  6.9623,  8.7441],\n",
      "        [12.7984,  6.6727,  8.1753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3103, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3512,  11.7382,  -5.3850],\n",
      "        [-10.6070,  11.7384,  -5.2768],\n",
      "        [-10.3279,  11.9750,  -5.5623],\n",
      "        [-10.3138,  11.6855,  -5.7320],\n",
      "        [-10.0556,  11.4417,  -5.3260],\n",
      "        [-10.2051,  12.0040,  -5.4093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9314,   6.6358,   8.7653, -10.3512,  11.7382,  -5.3850],\n",
      "        [ 12.8023,   6.7856,   8.5483, -10.6070,  11.7384,  -5.2768],\n",
      "        [ 13.2088,   6.7657,   8.6127, -10.3279,  11.9750,  -5.5623],\n",
      "        [ 13.0866,   6.9235,   8.4851, -10.3138,  11.6855,  -5.7320],\n",
      "        [ 12.6714,   6.9623,   8.7441, -10.0556,  11.4417,  -5.3260],\n",
      "        [ 12.7984,   6.6727,   8.1753, -10.2051,  12.0040,  -5.4093]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1578326225280762\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9674, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6505,  6.4937,  8.4698],\n",
      "        [12.7455,  6.8736,  8.9026],\n",
      "        [12.6224,  6.6106,  8.3903],\n",
      "        [12.5382,  6.8617,  8.4223],\n",
      "        [12.7746,  6.7091,  8.5769],\n",
      "        [12.5745,  6.5996,  8.6272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7390, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2229,  12.0404,  -5.4864],\n",
      "        [-10.2625,  12.1686,  -5.4032],\n",
      "        [-10.5478,  11.8354,  -5.4089],\n",
      "        [-10.1005,  11.5997,  -5.2351],\n",
      "        [-10.2608,  12.1549,  -5.0747],\n",
      "        [-10.5889,  11.8939,  -5.4423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6505,   6.4937,   8.4698, -10.2229,  12.0404,  -5.4864],\n",
      "        [ 12.7455,   6.8736,   8.9026, -10.2625,  12.1686,  -5.4032],\n",
      "        [ 12.6224,   6.6106,   8.3903, -10.5478,  11.8354,  -5.4089],\n",
      "        [ 12.5382,   6.8617,   8.4223, -10.1005,  11.5997,  -5.2351],\n",
      "        [ 12.7746,   6.7091,   8.5769, -10.2608,  12.1549,  -5.0747],\n",
      "        [ 12.5745,   6.5996,   8.6272, -10.5889,  11.8939,  -5.4423]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1431611776351929\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.5894,  6.7373,  8.9186],\n",
      "        [12.3142,  6.4648,  8.5330],\n",
      "        [12.7144,  6.8106,  8.3201],\n",
      "        [12.7874,  6.6707,  8.6372],\n",
      "        [12.8281,  6.8767,  8.6023],\n",
      "        [12.7060,  6.7719,  8.5264]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2437, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4078,  12.0063,  -5.7252],\n",
      "        [-10.3629,  12.0831,  -5.3772],\n",
      "        [-10.5548,  11.7671,  -5.2053],\n",
      "        [-10.3452,  11.6871,  -5.6754],\n",
      "        [-10.3322,  11.8702,  -5.7384],\n",
      "        [-10.0435,  12.0021,  -5.5893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.5894,   6.7373,   8.9186, -10.4078,  12.0063,  -5.7252],\n",
      "        [ 12.3142,   6.4648,   8.5330, -10.3629,  12.0831,  -5.3772],\n",
      "        [ 12.7144,   6.8106,   8.3201, -10.5548,  11.7671,  -5.2053],\n",
      "        [ 12.7874,   6.6707,   8.6372, -10.3452,  11.6871,  -5.6754],\n",
      "        [ 12.8281,   6.8767,   8.6023, -10.3322,  11.8702,  -5.7384],\n",
      "        [ 12.7060,   6.7719,   8.5264, -10.0435,  12.0021,  -5.5893]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1602957248687744\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7939,  6.6789,  8.6797],\n",
      "        [13.1112,  6.8403,  8.3937],\n",
      "        [12.9698,  6.7344,  8.6622],\n",
      "        [12.7780,  6.7362,  8.0742],\n",
      "        [12.9152,  6.7271,  8.7614],\n",
      "        [12.5510,  6.7641,  8.6537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8685, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6156,  11.8671,  -5.8368],\n",
      "        [-10.5595,  12.0349,  -5.6356],\n",
      "        [-10.3457,  11.9562,  -5.4916],\n",
      "        [-10.4935,  12.0728,  -5.6325],\n",
      "        [-10.4622,  11.8672,  -5.5904],\n",
      "        [-10.7250,  11.7523,  -5.5131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7939,   6.6789,   8.6797, -10.6156,  11.8671,  -5.8368],\n",
      "        [ 13.1112,   6.8403,   8.3937, -10.5595,  12.0349,  -5.6356],\n",
      "        [ 12.9698,   6.7344,   8.6622, -10.3457,  11.9562,  -5.4916],\n",
      "        [ 12.7780,   6.7362,   8.0742, -10.4935,  12.0728,  -5.6325],\n",
      "        [ 12.9152,   6.7271,   8.7614, -10.4622,  11.8672,  -5.5904],\n",
      "        [ 12.5510,   6.7641,   8.6537, -10.7250,  11.7523,  -5.5131]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1627053022384644\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9788, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7296,  7.0673,  8.6849],\n",
      "        [12.6916,  6.1549,  8.1909],\n",
      "        [12.8920,  7.0285,  8.3993],\n",
      "        [12.8682,  6.7462,  8.6582],\n",
      "        [13.3161,  6.9450,  8.1306],\n",
      "        [12.8521,  6.8773,  8.6406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5216,  12.0964,  -5.3318],\n",
      "        [-10.4257,  12.1511,  -5.5209],\n",
      "        [-10.4901,  11.8532,  -5.6541],\n",
      "        [-10.3486,  12.1244,  -5.4720],\n",
      "        [-10.1965,  11.9746,  -5.3201],\n",
      "        [-10.6757,  11.7254,  -5.2806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7296,   7.0673,   8.6849, -10.5216,  12.0964,  -5.3318],\n",
      "        [ 12.6916,   6.1549,   8.1909, -10.4257,  12.1511,  -5.5209],\n",
      "        [ 12.8920,   7.0285,   8.3993, -10.4901,  11.8532,  -5.6541],\n",
      "        [ 12.8682,   6.7462,   8.6582, -10.3486,  12.1244,  -5.4720],\n",
      "        [ 13.3161,   6.9450,   8.1306, -10.1965,  11.9746,  -5.3201],\n",
      "        [ 12.8521,   6.8773,   8.6406, -10.6757,  11.7254,  -5.2806]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1660292148590088\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7109,  6.7914,  8.6427],\n",
      "        [13.0377,  6.4565,  8.8108],\n",
      "        [12.8063,  7.1077,  8.4852],\n",
      "        [12.7875,  6.6864,  8.2674],\n",
      "        [12.7852,  7.1607,  8.5462],\n",
      "        [12.8192,  6.7654,  8.7134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2718, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5814,  11.9235,  -5.8336],\n",
      "        [ -9.9868,  11.9463,  -5.4863],\n",
      "        [-10.3337,  11.8297,  -5.6425],\n",
      "        [-10.4716,  11.8955,  -5.5107],\n",
      "        [-10.3791,  11.8418,  -5.5128],\n",
      "        [-10.7208,  12.1035,  -5.6890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7109,   6.7914,   8.6427, -10.5814,  11.9235,  -5.8336],\n",
      "        [ 13.0377,   6.4565,   8.8108,  -9.9868,  11.9463,  -5.4863],\n",
      "        [ 12.8063,   7.1077,   8.4852, -10.3337,  11.8297,  -5.6425],\n",
      "        [ 12.7875,   6.6864,   8.2674, -10.4716,  11.8955,  -5.5107],\n",
      "        [ 12.7852,   7.1607,   8.5462, -10.3791,  11.8418,  -5.5128],\n",
      "        [ 12.8192,   6.7654,   8.7134, -10.7208,  12.1035,  -5.6890]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.162373661994934\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8746,  6.7074,  8.4777],\n",
      "        [13.0791,  6.9199,  8.8394],\n",
      "        [12.8553,  6.7625,  8.5294],\n",
      "        [12.8792,  6.9432,  8.9202],\n",
      "        [13.1483,  7.1225,  8.8921],\n",
      "        [12.9505,  6.7854,  8.6665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.1586, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3490,  11.8158,  -5.3815],\n",
      "        [-10.2313,  11.6289,  -5.2936],\n",
      "        [-10.5600,  11.9612,  -5.5302],\n",
      "        [-10.6187,  12.3804,  -5.7531],\n",
      "        [-10.6602,  11.4716,  -5.5918],\n",
      "        [-10.8946,  12.0541,  -5.3788]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8746,   6.7074,   8.4777, -10.3490,  11.8158,  -5.3815],\n",
      "        [ 13.0791,   6.9199,   8.8394, -10.2313,  11.6289,  -5.2936],\n",
      "        [ 12.8553,   6.7625,   8.5294, -10.5600,  11.9612,  -5.5302],\n",
      "        [ 12.8792,   6.9432,   8.9202, -10.6187,  12.3804,  -5.7531],\n",
      "        [ 13.1483,   7.1225,   8.8921, -10.6602,  11.4716,  -5.5918],\n",
      "        [ 12.9505,   6.7854,   8.6665, -10.8946,  12.0541,  -5.3788]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1552177667617798\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8573, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0338,  6.7774,  8.6940],\n",
      "        [12.9182,  6.7474,  8.7204],\n",
      "        [12.7017,  7.1518,  8.5307],\n",
      "        [13.1901,  6.7920,  8.4891],\n",
      "        [13.0806,  6.9042,  8.5332],\n",
      "        [12.7144,  6.9906,  8.7249]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.1878,  11.7178,  -5.6833],\n",
      "        [-10.5290,  11.9019,  -5.6068],\n",
      "        [-10.2601,  12.1664,  -5.5987],\n",
      "        [-10.3425,  12.0782,  -5.6816],\n",
      "        [-10.1781,  11.8942,  -5.5922],\n",
      "        [-10.7664,  11.9824,  -5.7205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0338,   6.7774,   8.6940, -10.1878,  11.7178,  -5.6833],\n",
      "        [ 12.9182,   6.7474,   8.7204, -10.5290,  11.9019,  -5.6068],\n",
      "        [ 12.7017,   7.1518,   8.5307, -10.2601,  12.1664,  -5.5987],\n",
      "        [ 13.1901,   6.7920,   8.4891, -10.3425,  12.0782,  -5.6816],\n",
      "        [ 13.0806,   6.9042,   8.5332, -10.1781,  11.8942,  -5.5922],\n",
      "        [ 12.7144,   6.9906,   8.7249, -10.7664,  11.9824,  -5.7205]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1660077571868896\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7294, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8625,  7.0203,  8.6298],\n",
      "        [12.5755,  6.7607,  8.5209],\n",
      "        [12.6283,  6.7718,  8.5020],\n",
      "        [12.9333,  6.8278,  8.6468],\n",
      "        [12.9040,  6.6493,  8.8439],\n",
      "        [12.8762,  6.7859,  8.4538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.1677, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ -9.9321,  12.0465,  -5.5219],\n",
      "        [-10.3180,  11.6462,  -5.3906],\n",
      "        [-10.5204,  12.1184,  -5.4882],\n",
      "        [-10.4951,  12.0788,  -5.7070],\n",
      "        [-10.4433,  11.8622,  -5.4950],\n",
      "        [-10.3188,  12.1745,  -5.5561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8625,   7.0203,   8.6298,  -9.9321,  12.0465,  -5.5219],\n",
      "        [ 12.5755,   6.7607,   8.5209, -10.3180,  11.6462,  -5.3906],\n",
      "        [ 12.6283,   6.7718,   8.5020, -10.5204,  12.1184,  -5.4882],\n",
      "        [ 12.9333,   6.8278,   8.6468, -10.4951,  12.0788,  -5.7070],\n",
      "        [ 12.9040,   6.6493,   8.8439, -10.4433,  11.8622,  -5.4950],\n",
      "        [ 12.8762,   6.7859,   8.4538, -10.3188,  12.1745,  -5.5561]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1633418798446655\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7222, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8348,  6.8945,  8.7912],\n",
      "        [12.8856,  6.6484,  8.4840],\n",
      "        [12.7535,  6.6479,  8.3811],\n",
      "        [12.4966,  6.5886,  8.3639],\n",
      "        [12.8768,  6.6222,  8.8140],\n",
      "        [12.8696,  7.0143,  8.9139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.0597,  11.8416,  -5.5489],\n",
      "        [-10.5509,  12.0403,  -5.6493],\n",
      "        [-10.1471,  11.7748,  -5.7179],\n",
      "        [-10.4376,  12.0585,  -5.5985],\n",
      "        [-10.2628,  12.1165,  -5.7289],\n",
      "        [-10.3977,  12.0390,  -5.6718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8348,   6.8945,   8.7912, -10.0597,  11.8416,  -5.5489],\n",
      "        [ 12.8856,   6.6484,   8.4840, -10.5509,  12.0403,  -5.6493],\n",
      "        [ 12.7535,   6.6479,   8.3811, -10.1471,  11.7748,  -5.7179],\n",
      "        [ 12.4966,   6.5886,   8.3639, -10.4376,  12.0585,  -5.5985],\n",
      "        [ 12.8768,   6.6222,   8.8140, -10.2628,  12.1165,  -5.7289],\n",
      "        [ 12.8696,   7.0143,   8.9139, -10.3977,  12.0390,  -5.6718]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1639808416366577\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8507,  6.6011,  8.5875],\n",
      "        [12.7540,  6.7962,  8.7416],\n",
      "        [12.6477,  7.1254,  8.8254],\n",
      "        [12.9087,  6.7431,  8.6738],\n",
      "        [12.7901,  6.8830,  8.8041],\n",
      "        [12.8784,  6.7524,  8.5687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4048,  12.0807,  -5.7467],\n",
      "        [-10.7060,  12.0294,  -5.5834],\n",
      "        [-10.3780,  12.2781,  -5.6097],\n",
      "        [-10.5048,  11.8693,  -5.6979],\n",
      "        [-10.3324,  11.8323,  -5.4817],\n",
      "        [-10.2675,  11.8713,  -5.7097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8507,   6.6011,   8.5875, -10.4048,  12.0807,  -5.7467],\n",
      "        [ 12.7540,   6.7962,   8.7416, -10.7060,  12.0294,  -5.5834],\n",
      "        [ 12.6477,   7.1254,   8.8254, -10.3780,  12.2781,  -5.6097],\n",
      "        [ 12.9087,   6.7431,   8.6738, -10.5048,  11.8693,  -5.6979],\n",
      "        [ 12.7901,   6.8830,   8.8041, -10.3324,  11.8323,  -5.4817],\n",
      "        [ 12.8784,   6.7524,   8.5687, -10.2675,  11.8713,  -5.7097]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1664645671844482\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7922, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9308,  6.8733,  8.5648],\n",
      "        [12.9668,  6.9770,  8.7186],\n",
      "        [13.2499,  6.4649,  8.6214],\n",
      "        [13.0097,  7.2036,  8.9472],\n",
      "        [13.1686,  6.9555,  8.4259],\n",
      "        [12.8761,  7.0618,  8.7002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3583,  12.0337,  -5.7039],\n",
      "        [-10.5394,  11.9624,  -5.3548],\n",
      "        [-10.7145,  12.1153,  -5.8600],\n",
      "        [-10.5223,  12.1496,  -5.7162],\n",
      "        [-10.4363,  12.2292,  -5.4950],\n",
      "        [-10.2386,  12.1304,  -5.6097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9308,   6.8733,   8.5648, -10.3583,  12.0337,  -5.7039],\n",
      "        [ 12.9668,   6.9770,   8.7186, -10.5394,  11.9624,  -5.3548],\n",
      "        [ 13.2499,   6.4649,   8.6214, -10.7145,  12.1153,  -5.8600],\n",
      "        [ 13.0097,   7.2036,   8.9472, -10.5223,  12.1496,  -5.7162],\n",
      "        [ 13.1686,   6.9555,   8.4259, -10.4363,  12.2292,  -5.4950],\n",
      "        [ 12.8761,   7.0618,   8.7002, -10.2386,  12.1304,  -5.6097]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1715186834335327\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7471,  6.8785,  8.5807],\n",
      "        [13.0462,  6.6106,  8.6898],\n",
      "        [12.5967,  6.9124,  8.2951],\n",
      "        [12.9512,  7.1636,  8.4616],\n",
      "        [13.3196,  6.9673,  8.8064],\n",
      "        [12.7877,  7.1193,  8.7191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6002,  12.1165,  -5.6981],\n",
      "        [-10.5326,  12.1626,  -5.0571],\n",
      "        [-10.1968,  12.0758,  -5.4226],\n",
      "        [-10.1603,  12.1839,  -5.7723],\n",
      "        [-10.5944,  11.8219,  -5.4730],\n",
      "        [-10.3426,  11.9780,  -5.5219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7471,   6.8785,   8.5807, -10.6002,  12.1165,  -5.6981],\n",
      "        [ 13.0462,   6.6106,   8.6898, -10.5326,  12.1626,  -5.0571],\n",
      "        [ 12.5967,   6.9124,   8.2951, -10.1968,  12.0758,  -5.4226],\n",
      "        [ 12.9512,   7.1636,   8.4616, -10.1603,  12.1839,  -5.7723],\n",
      "        [ 13.3196,   6.9673,   8.8064, -10.5944,  11.8219,  -5.4730],\n",
      "        [ 12.7877,   7.1193,   8.7191, -10.3426,  11.9780,  -5.5219]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1712405681610107\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0507, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9626,  6.7910,  8.4137],\n",
      "        [12.9212,  6.9470,  8.6728],\n",
      "        [13.4352,  7.3469,  8.6199],\n",
      "        [13.0879,  6.8305,  8.5810],\n",
      "        [13.1567,  6.9375,  8.8443],\n",
      "        [12.7246,  7.3175,  8.3605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.5962, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5428,  12.1042,  -5.6490],\n",
      "        [-10.6786,  12.1439,  -5.5070],\n",
      "        [-10.1504,  11.8314,  -5.7253],\n",
      "        [-10.4599,  11.8163,  -5.4632],\n",
      "        [-10.3319,  12.2302,  -5.6295],\n",
      "        [-10.3116,  12.0364,  -5.8305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9626,   6.7910,   8.4137, -10.5428,  12.1042,  -5.6490],\n",
      "        [ 12.9212,   6.9470,   8.6728, -10.6786,  12.1439,  -5.5070],\n",
      "        [ 13.4352,   7.3469,   8.6199, -10.1504,  11.8314,  -5.7253],\n",
      "        [ 13.0879,   6.8305,   8.5810, -10.4599,  11.8163,  -5.4632],\n",
      "        [ 13.1567,   6.9375,   8.8443, -10.3319,  12.2302,  -5.6295],\n",
      "        [ 12.7246,   7.3175,   8.3605, -10.3116,  12.0364,  -5.8305]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1726744174957275\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1362, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0610,  6.9262,  8.5687],\n",
      "        [12.5764,  7.0710,  8.6022],\n",
      "        [13.2417,  6.9333,  8.7556],\n",
      "        [13.1240,  6.6740,  8.9294],\n",
      "        [12.9629,  6.6852,  8.6834],\n",
      "        [12.9383,  6.6815,  8.6506]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9167,  12.0532,  -5.9765],\n",
      "        [-10.6195,  11.7632,  -5.6029],\n",
      "        [-10.2671,  12.0622,  -5.6011],\n",
      "        [-10.7041,  12.0308,  -5.5970],\n",
      "        [-10.1437,  11.8910,  -5.3849],\n",
      "        [-10.7826,  12.0331,  -5.5930]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0610,   6.9262,   8.5687, -10.9167,  12.0532,  -5.9765],\n",
      "        [ 12.5764,   7.0710,   8.6022, -10.6195,  11.7632,  -5.6029],\n",
      "        [ 13.2417,   6.9333,   8.7556, -10.2671,  12.0622,  -5.6011],\n",
      "        [ 13.1240,   6.6740,   8.9294, -10.7041,  12.0308,  -5.5970],\n",
      "        [ 12.9629,   6.6852,   8.6834, -10.1437,  11.8910,  -5.3849],\n",
      "        [ 12.9383,   6.6815,   8.6506, -10.7826,  12.0331,  -5.5930]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1896487474441528\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0198, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8662,  6.8411,  9.0421],\n",
      "        [12.8235,  6.8836,  8.9936],\n",
      "        [12.7815,  6.8199,  8.5575],\n",
      "        [13.1944,  6.9616,  8.6984],\n",
      "        [12.7497,  6.6804,  8.5674],\n",
      "        [12.9416,  7.1611,  8.4350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3761,  12.0159,  -5.8391],\n",
      "        [-10.1656,  12.1742,  -5.5117],\n",
      "        [-10.6715,  11.8082,  -5.5479],\n",
      "        [-10.4364,  12.3035,  -5.5529],\n",
      "        [-10.5056,  11.8895,  -5.8863],\n",
      "        [-10.5458,  11.7838,  -5.8296]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8662,   6.8411,   9.0421, -10.3761,  12.0159,  -5.8391],\n",
      "        [ 12.8235,   6.8836,   8.9936, -10.1656,  12.1742,  -5.5117],\n",
      "        [ 12.7815,   6.8199,   8.5575, -10.6715,  11.8082,  -5.5479],\n",
      "        [ 13.1944,   6.9616,   8.6984, -10.4364,  12.3035,  -5.5529],\n",
      "        [ 12.7497,   6.6804,   8.5674, -10.5056,  11.8895,  -5.8863],\n",
      "        [ 12.9416,   7.1611,   8.4350, -10.5458,  11.7838,  -5.8296]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1848849058151245\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0524, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8210,  6.7668,  8.9247],\n",
      "        [12.7552,  6.6893,  8.4409],\n",
      "        [13.0497,  6.8416,  8.6762],\n",
      "        [13.0569,  7.1008,  8.7340],\n",
      "        [12.9560,  7.1790,  8.4524],\n",
      "        [12.9468,  6.9908,  8.4795]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.5823, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7586,  12.2859,  -5.8029],\n",
      "        [-10.4737,  12.3279,  -5.6643],\n",
      "        [-10.2718,  11.7260,  -5.7469],\n",
      "        [ -9.9351,  12.0852,  -5.5097],\n",
      "        [-10.5514,  12.0214,  -5.8253],\n",
      "        [-10.4445,  12.0047,  -5.7985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8210,   6.7668,   8.9247, -10.7586,  12.2859,  -5.8029],\n",
      "        [ 12.7552,   6.6893,   8.4409, -10.4737,  12.3279,  -5.6643],\n",
      "        [ 13.0497,   6.8416,   8.6762, -10.2718,  11.7260,  -5.7469],\n",
      "        [ 13.0569,   7.1008,   8.7340,  -9.9351,  12.0852,  -5.5097],\n",
      "        [ 12.9560,   7.1790,   8.4524, -10.5514,  12.0214,  -5.8253],\n",
      "        [ 12.9468,   6.9908,   8.4795, -10.4445,  12.0047,  -5.7985]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1900875568389893\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0073, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0877,  6.9895,  8.3539],\n",
      "        [12.9442,  6.9172,  9.0112],\n",
      "        [12.7569,  6.8423,  8.7839],\n",
      "        [13.2064,  7.0925,  8.6732],\n",
      "        [12.9189,  6.9824,  8.8198],\n",
      "        [12.9494,  6.6805,  8.7077]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.1970, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5992,  12.3167,  -5.5955],\n",
      "        [-10.6076,  12.1028,  -5.6720],\n",
      "        [-10.2919,  11.8595,  -5.9207],\n",
      "        [-10.4146,  12.0077,  -5.5876],\n",
      "        [-10.3113,  11.9773,  -5.7340],\n",
      "        [-10.5218,  12.0268,  -5.3634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0877,   6.9895,   8.3539, -10.5992,  12.3167,  -5.5955],\n",
      "        [ 12.9442,   6.9172,   9.0112, -10.6076,  12.1028,  -5.6720],\n",
      "        [ 12.7569,   6.8423,   8.7839, -10.2919,  11.8595,  -5.9207],\n",
      "        [ 13.2064,   7.0925,   8.6732, -10.4146,  12.0077,  -5.5876],\n",
      "        [ 12.9189,   6.9824,   8.8198, -10.3113,  11.9773,  -5.7340],\n",
      "        [ 12.9494,   6.6805,   8.7077, -10.5218,  12.0268,  -5.3634]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.18553626537323\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8598,  6.9761,  8.6937],\n",
      "        [12.7321,  6.9304,  8.7943],\n",
      "        [12.9056,  6.9603,  8.6731],\n",
      "        [13.3206,  7.0075,  8.4637],\n",
      "        [12.7818,  7.3010,  8.3148],\n",
      "        [13.1278,  6.9609,  8.7464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3124, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4083,  12.0883,  -5.6948],\n",
      "        [-10.2969,  12.0762,  -5.9176],\n",
      "        [-10.4202,  12.3356,  -5.8693],\n",
      "        [-10.6639,  12.0179,  -6.1186],\n",
      "        [-10.2678,  12.2628,  -5.7454],\n",
      "        [-10.6898,  12.1017,  -5.5567]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8598,   6.9761,   8.6937, -10.4083,  12.0883,  -5.6948],\n",
      "        [ 12.7321,   6.9304,   8.7943, -10.2969,  12.0762,  -5.9176],\n",
      "        [ 12.9056,   6.9603,   8.6731, -10.4202,  12.3356,  -5.8693],\n",
      "        [ 13.3206,   7.0075,   8.4637, -10.6639,  12.0179,  -6.1186],\n",
      "        [ 12.7818,   7.3010,   8.3148, -10.2678,  12.2628,  -5.7454],\n",
      "        [ 13.1278,   6.9609,   8.7464, -10.6898,  12.1017,  -5.5567]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.180649995803833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5238, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0141,  6.7476,  8.5000],\n",
      "        [12.9074,  6.9047,  8.4636],\n",
      "        [13.1743,  6.8685,  8.7583],\n",
      "        [12.7581,  7.0909,  8.8318],\n",
      "        [12.9703,  7.1147,  8.8133],\n",
      "        [13.1570,  6.9238,  8.5519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5433,  12.0446,  -5.8683],\n",
      "        [-10.7976,  12.1013,  -5.6982],\n",
      "        [-10.8925,  11.9690,  -5.8356],\n",
      "        [-10.4830,  12.1944,  -5.8263],\n",
      "        [-10.8694,  12.2584,  -5.7107],\n",
      "        [-10.2588,  11.7913,  -5.9094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0141,   6.7476,   8.5000, -10.5433,  12.0446,  -5.8683],\n",
      "        [ 12.9074,   6.9047,   8.4636, -10.7976,  12.1013,  -5.6982],\n",
      "        [ 13.1743,   6.8685,   8.7583, -10.8925,  11.9690,  -5.8356],\n",
      "        [ 12.7581,   7.0909,   8.8318, -10.4830,  12.1944,  -5.8263],\n",
      "        [ 12.9703,   7.1147,   8.8133, -10.8694,  12.2584,  -5.7107],\n",
      "        [ 13.1570,   6.9238,   8.5519, -10.2588,  11.7913,  -5.9094]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1810435056686401\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4340,  7.0460,  8.6057],\n",
      "        [12.9189,  6.9262,  8.8010],\n",
      "        [12.9941,  7.0225,  8.7363],\n",
      "        [13.2849,  7.0980,  8.7810],\n",
      "        [13.4408,  7.1937,  8.9259],\n",
      "        [13.2317,  6.8347,  8.7547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.5879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.2361,  12.0588,  -5.6637],\n",
      "        [-10.4847,  11.6934,  -5.5007],\n",
      "        [-10.4422,  12.1477,  -5.6843],\n",
      "        [-10.7904,  12.3892,  -6.0548],\n",
      "        [-10.7978,  12.3088,  -5.6191],\n",
      "        [-10.7113,  11.9868,  -5.5354]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4340,   7.0460,   8.6057, -10.2361,  12.0588,  -5.6637],\n",
      "        [ 12.9189,   6.9262,   8.8010, -10.4847,  11.6934,  -5.5007],\n",
      "        [ 12.9941,   7.0225,   8.7363, -10.4422,  12.1477,  -5.6843],\n",
      "        [ 13.2849,   7.0980,   8.7810, -10.7904,  12.3892,  -6.0548],\n",
      "        [ 13.4408,   7.1937,   8.9259, -10.7978,  12.3088,  -5.6191],\n",
      "        [ 13.2317,   6.8347,   8.7547, -10.7113,  11.9868,  -5.5354]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1978915929794312\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7256, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.7440,  6.8981,  8.6153],\n",
      "        [12.9932,  7.4520,  8.8985],\n",
      "        [13.3630,  7.2078,  9.0082],\n",
      "        [13.0367,  7.1880,  8.7167],\n",
      "        [13.0652,  7.2803,  8.4934],\n",
      "        [13.1931,  7.0659,  8.7696]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1196, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5462,  12.2973,  -5.7451],\n",
      "        [-10.5964,  12.2379,  -5.9565],\n",
      "        [-10.8541,  12.4613,  -5.9715],\n",
      "        [-10.8820,  12.0005,  -5.8319],\n",
      "        [-10.6140,  12.2470,  -5.9563],\n",
      "        [-10.4680,  12.3475,  -5.7428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.7440,   6.8981,   8.6153, -10.5462,  12.2973,  -5.7451],\n",
      "        [ 12.9932,   7.4520,   8.8985, -10.5964,  12.2379,  -5.9565],\n",
      "        [ 13.3630,   7.2078,   9.0082, -10.8541,  12.4613,  -5.9715],\n",
      "        [ 13.0367,   7.1880,   8.7167, -10.8820,  12.0005,  -5.8319],\n",
      "        [ 13.0652,   7.2803,   8.4934, -10.6140,  12.2470,  -5.9563],\n",
      "        [ 13.1931,   7.0659,   8.7696, -10.4680,  12.3475,  -5.7428]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1817129850387573\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4899, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8906,  6.6822,  8.7315],\n",
      "        [13.3350,  7.1442,  8.8378],\n",
      "        [12.8753,  6.6048,  8.3877],\n",
      "        [13.1611,  7.1283,  8.7168],\n",
      "        [13.0207,  6.6257,  8.3312],\n",
      "        [12.8786,  7.2105,  9.0983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6119,  12.1517,  -5.8139],\n",
      "        [-10.4133,  11.7388,  -5.6772],\n",
      "        [-10.9285,  12.1065,  -5.8285],\n",
      "        [-10.5108,  12.5936,  -5.4877],\n",
      "        [-10.4723,  12.6774,  -5.7011],\n",
      "        [-10.3698,  12.5595,  -5.5697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8906,   6.6822,   8.7315, -10.6119,  12.1517,  -5.8139],\n",
      "        [ 13.3350,   7.1442,   8.8378, -10.4133,  11.7388,  -5.6772],\n",
      "        [ 12.8753,   6.6048,   8.3877, -10.9285,  12.1065,  -5.8285],\n",
      "        [ 13.1611,   7.1283,   8.7168, -10.5108,  12.5936,  -5.4877],\n",
      "        [ 13.0207,   6.6257,   8.3312, -10.4723,  12.6774,  -5.7011],\n",
      "        [ 12.8786,   7.2105,   9.0983, -10.3698,  12.5595,  -5.5697]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.186467170715332\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0053,  6.9064,  8.7730],\n",
      "        [13.0223,  6.7305,  8.4252],\n",
      "        [12.8102,  7.0898,  8.4789],\n",
      "        [13.5003,  7.1697,  8.7545],\n",
      "        [13.2829,  6.7656,  8.5770],\n",
      "        [12.7682,  6.9623,  8.1803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6586,  12.4686,  -5.5635],\n",
      "        [-10.6254,  11.9735,  -5.5180],\n",
      "        [-10.4798,  11.7597,  -5.9102],\n",
      "        [-10.5033,  12.1137,  -5.6362],\n",
      "        [-10.3895,  12.0554,  -5.7418],\n",
      "        [ -9.9713,  11.9396,  -5.6375]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0053,   6.9064,   8.7730, -10.6586,  12.4686,  -5.5635],\n",
      "        [ 13.0223,   6.7305,   8.4252, -10.6254,  11.9735,  -5.5180],\n",
      "        [ 12.8102,   7.0898,   8.4789, -10.4798,  11.7597,  -5.9102],\n",
      "        [ 13.5003,   7.1697,   8.7545, -10.5033,  12.1137,  -5.6362],\n",
      "        [ 13.2829,   6.7656,   8.5770, -10.3895,  12.0554,  -5.7418],\n",
      "        [ 12.7682,   6.9623,   8.1803,  -9.9713,  11.9396,  -5.6375]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2000603675842285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6392, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8009,  6.8704,  8.9034],\n",
      "        [12.7773,  6.9432,  8.9203],\n",
      "        [12.8026,  6.9146,  8.5450],\n",
      "        [13.0284,  7.1972,  8.8594],\n",
      "        [13.5330,  6.9357,  8.7933],\n",
      "        [13.3552,  7.1362,  8.7694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.4777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7013,  12.0446,  -5.6785],\n",
      "        [-10.5278,  11.9777,  -5.7240],\n",
      "        [-10.3765,  11.9840,  -5.4976],\n",
      "        [-10.2487,  12.3107,  -5.6908],\n",
      "        [-10.5932,  12.1966,  -6.1219],\n",
      "        [-10.5993,  12.1863,  -5.8826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8009,   6.8704,   8.9034, -10.7013,  12.0446,  -5.6785],\n",
      "        [ 12.7773,   6.9432,   8.9203, -10.5278,  11.9777,  -5.7240],\n",
      "        [ 12.8026,   6.9146,   8.5450, -10.3765,  11.9840,  -5.4976],\n",
      "        [ 13.0284,   7.1972,   8.8594, -10.2487,  12.3107,  -5.6908],\n",
      "        [ 13.5330,   6.9357,   8.7933, -10.5932,  12.1966,  -6.1219],\n",
      "        [ 13.3552,   7.1362,   8.7694, -10.5993,  12.1863,  -5.8826]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1904606819152832\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7672, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6622,  7.3818,  8.6180],\n",
      "        [13.0436,  7.0545,  8.8598],\n",
      "        [13.0832,  7.4823,  8.9362],\n",
      "        [12.8005,  7.2667,  8.8662],\n",
      "        [13.3315,  6.9719,  8.4875],\n",
      "        [12.8285,  6.9221,  8.6905]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2132, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5437,  11.9510,  -5.5526],\n",
      "        [-10.8441,  12.2777,  -6.0746],\n",
      "        [-11.0419,  12.5815,  -6.2009],\n",
      "        [-10.9178,  12.5312,  -5.8546],\n",
      "        [-10.9029,  12.5822,  -5.7712],\n",
      "        [-10.2562,  11.9708,  -5.6166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6622,   7.3818,   8.6180, -10.5437,  11.9510,  -5.5526],\n",
      "        [ 13.0436,   7.0545,   8.8598, -10.8441,  12.2777,  -6.0746],\n",
      "        [ 13.0832,   7.4823,   8.9362, -11.0419,  12.5815,  -6.2009],\n",
      "        [ 12.8005,   7.2667,   8.8662, -10.9178,  12.5312,  -5.8546],\n",
      "        [ 13.3315,   6.9719,   8.4875, -10.9029,  12.5822,  -5.7712],\n",
      "        [ 12.8285,   6.9221,   8.6905, -10.2562,  11.9708,  -5.6166]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.2168235778808594\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9408,  7.4551,  9.0183],\n",
      "        [12.8550,  6.8985,  8.8136],\n",
      "        [13.0927,  7.2593,  8.7441],\n",
      "        [12.8177,  6.9565,  8.9436],\n",
      "        [12.8761,  6.9134,  8.5800],\n",
      "        [12.6423,  6.9800,  8.6040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8117,  12.0220,  -5.6454],\n",
      "        [-10.3521,  12.4623,  -5.6979],\n",
      "        [-10.9516,  12.3052,  -5.7727],\n",
      "        [-10.9205,  12.4726,  -5.9706],\n",
      "        [-10.8711,  12.4775,  -5.8971],\n",
      "        [-10.9263,  12.1554,  -5.6750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9408,   7.4551,   9.0183, -10.8117,  12.0220,  -5.6454],\n",
      "        [ 12.8550,   6.8985,   8.8136, -10.3521,  12.4623,  -5.6979],\n",
      "        [ 13.0927,   7.2593,   8.7441, -10.9516,  12.3052,  -5.7727],\n",
      "        [ 12.8177,   6.9565,   8.9436, -10.9205,  12.4726,  -5.9706],\n",
      "        [ 12.8761,   6.9134,   8.5800, -10.8711,  12.4775,  -5.8971],\n",
      "        [ 12.6423,   6.9800,   8.6040, -10.9263,  12.1554,  -5.6750]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2093150615692139\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0443,  6.8735,  8.7740],\n",
      "        [13.0919,  6.9104,  8.9127],\n",
      "        [13.2184,  7.0195,  8.4359],\n",
      "        [13.1718,  6.9014,  9.0586],\n",
      "        [12.9629,  6.7220,  8.8713],\n",
      "        [13.0994,  7.1487,  8.8463]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6266,  12.3110,  -5.8295],\n",
      "        [-10.6756,  12.2716,  -5.7510],\n",
      "        [-10.5385,  11.9520,  -5.6372],\n",
      "        [-10.4247,  12.4151,  -5.8917],\n",
      "        [-10.5428,  12.1512,  -5.9641],\n",
      "        [-10.8125,  12.4993,  -5.7435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0443,   6.8735,   8.7740, -10.6266,  12.3110,  -5.8295],\n",
      "        [ 13.0919,   6.9104,   8.9127, -10.6756,  12.2716,  -5.7510],\n",
      "        [ 13.2184,   7.0195,   8.4359, -10.5385,  11.9520,  -5.6372],\n",
      "        [ 13.1718,   6.9014,   9.0586, -10.4247,  12.4151,  -5.8917],\n",
      "        [ 12.9629,   6.7220,   8.8713, -10.5428,  12.1512,  -5.9641],\n",
      "        [ 13.0994,   7.1487,   8.8463, -10.8125,  12.4993,  -5.7435]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2026361227035522\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6967, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6730,  6.9864,  8.8783],\n",
      "        [13.1444,  7.1785,  8.5119],\n",
      "        [13.4644,  6.8686,  8.8182],\n",
      "        [12.6925,  6.8825,  8.5777],\n",
      "        [13.0918,  7.0752,  8.7963],\n",
      "        [13.0187,  6.9841,  8.7083]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5541, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7851,  12.4073,  -5.9115],\n",
      "        [-10.7606,  12.1159,  -6.0066],\n",
      "        [-10.7728,  12.8064,  -5.6537],\n",
      "        [-10.4713,  11.8820,  -5.6894],\n",
      "        [-10.6538,  12.5158,  -6.1068],\n",
      "        [-10.9095,  12.1945,  -5.9335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6730,   6.9864,   8.8783, -10.7851,  12.4073,  -5.9115],\n",
      "        [ 13.1444,   7.1785,   8.5119, -10.7606,  12.1159,  -6.0066],\n",
      "        [ 13.4644,   6.8686,   8.8182, -10.7728,  12.8064,  -5.6537],\n",
      "        [ 12.6925,   6.8825,   8.5777, -10.4713,  11.8820,  -5.6894],\n",
      "        [ 13.0918,   7.0752,   8.7963, -10.6538,  12.5158,  -6.1068],\n",
      "        [ 13.0187,   6.9841,   8.7083, -10.9095,  12.1945,  -5.9335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.1991918087005615\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.8463,  6.8946,  8.6597],\n",
      "        [12.7085,  6.6212,  8.5216],\n",
      "        [13.1302,  6.6665,  8.9214],\n",
      "        [13.2512,  6.8666,  8.9962],\n",
      "        [13.4888,  7.1824,  9.0910],\n",
      "        [13.2751,  6.4920,  8.9485]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3647, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6688,  12.2403,  -5.6860],\n",
      "        [-10.7014,  12.4967,  -5.7807],\n",
      "        [-10.7769,  12.1668,  -6.0828],\n",
      "        [-10.5381,  12.3177,  -5.7507],\n",
      "        [-10.5283,  12.0447,  -5.6340],\n",
      "        [-10.8122,  12.4024,  -5.8790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.8463,   6.8946,   8.6597, -10.6688,  12.2403,  -5.6860],\n",
      "        [ 12.7085,   6.6212,   8.5216, -10.7014,  12.4967,  -5.7807],\n",
      "        [ 13.1302,   6.6665,   8.9214, -10.7769,  12.1668,  -6.0828],\n",
      "        [ 13.2512,   6.8666,   8.9962, -10.5381,  12.3177,  -5.7507],\n",
      "        [ 13.4888,   7.1824,   9.0910, -10.5283,  12.0447,  -5.6340],\n",
      "        [ 13.2751,   6.4920,   8.9485, -10.8122,  12.4024,  -5.8790]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.192878007888794\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4204,  6.8449,  8.9231],\n",
      "        [12.9634,  7.2037,  9.2389],\n",
      "        [13.4427,  6.9022,  8.7744],\n",
      "        [12.9823,  7.1045,  8.5930],\n",
      "        [12.9893,  7.2281,  8.8941],\n",
      "        [13.3154,  6.7919,  8.9843]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.5298, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7049,  12.2907,  -5.7859],\n",
      "        [-10.6159,  12.0558,  -5.8141],\n",
      "        [-10.4022,  12.3785,  -5.7818],\n",
      "        [-10.5279,  12.1862,  -6.0249],\n",
      "        [-10.9900,  12.6939,  -5.9118],\n",
      "        [-10.9269,  12.5081,  -5.9161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4204,   6.8449,   8.9231, -10.7049,  12.2907,  -5.7859],\n",
      "        [ 12.9634,   7.2037,   9.2389, -10.6159,  12.0558,  -5.8141],\n",
      "        [ 13.4427,   6.9022,   8.7744, -10.4022,  12.3785,  -5.7818],\n",
      "        [ 12.9823,   7.1045,   8.5930, -10.5279,  12.1862,  -6.0249],\n",
      "        [ 12.9893,   7.2281,   8.8941, -10.9900,  12.6939,  -5.9118],\n",
      "        [ 13.3154,   6.7919,   8.9843, -10.9269,  12.5081,  -5.9161]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2222096920013428\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2107,  7.0281,  9.1535],\n",
      "        [13.2600,  7.1545,  9.1818],\n",
      "        [12.9617,  7.3558,  8.7366],\n",
      "        [13.1289,  7.3446,  9.0822],\n",
      "        [13.1648,  7.1663,  8.5425],\n",
      "        [13.3501,  7.2210,  8.6258]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.0757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4602,  12.1092,  -5.8032],\n",
      "        [-10.8725,  12.0032,  -6.1502],\n",
      "        [-10.6009,  12.0326,  -5.7782],\n",
      "        [-10.5947,  12.0690,  -5.9298],\n",
      "        [-10.5321,  12.1594,  -5.8360],\n",
      "        [-10.9565,  12.7206,  -5.9727]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2107,   7.0281,   9.1535, -10.4602,  12.1092,  -5.8032],\n",
      "        [ 13.2600,   7.1545,   9.1818, -10.8725,  12.0032,  -6.1502],\n",
      "        [ 12.9617,   7.3558,   8.7366, -10.6009,  12.0326,  -5.7782],\n",
      "        [ 13.1289,   7.3446,   9.0822, -10.5947,  12.0690,  -5.9298],\n",
      "        [ 13.1648,   7.1663,   8.5425, -10.5321,  12.1594,  -5.8360],\n",
      "        [ 13.3501,   7.2210,   8.6258, -10.9565,  12.7206,  -5.9727]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.217397689819336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7780, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.1811,  7.3850,  8.7862],\n",
      "        [13.1483,  7.0367,  9.0509],\n",
      "        [12.9785,  6.9155,  8.6332],\n",
      "        [13.1110,  7.1528,  8.9959],\n",
      "        [13.0732,  7.3806,  8.7651],\n",
      "        [13.1932,  7.1296,  8.6648]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7425,  11.7126,  -5.8830],\n",
      "        [-10.7532,  11.8843,  -5.9430],\n",
      "        [-10.7226,  12.0678,  -5.5539],\n",
      "        [-10.6529,  12.3786,  -6.1635],\n",
      "        [-10.7222,  11.8473,  -5.9049],\n",
      "        [-10.6547,  11.9435,  -5.8634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.1811,   7.3850,   8.7862, -10.7425,  11.7126,  -5.8830],\n",
      "        [ 13.1483,   7.0367,   9.0509, -10.7532,  11.8843,  -5.9430],\n",
      "        [ 12.9785,   6.9155,   8.6332, -10.7226,  12.0678,  -5.5539],\n",
      "        [ 13.1110,   7.1528,   8.9959, -10.6529,  12.3786,  -6.1635],\n",
      "        [ 13.0732,   7.3806,   8.7651, -10.7222,  11.8473,  -5.9049],\n",
      "        [ 13.1932,   7.1296,   8.6648, -10.6547,  11.9435,  -5.8634]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2106047868728638\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5521, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0117,  7.2503,  8.6869],\n",
      "        [13.3247,  7.0867,  8.6552],\n",
      "        [13.2621,  7.0553,  9.0265],\n",
      "        [13.2272,  7.1748,  8.6496],\n",
      "        [13.2976,  7.2662,  8.8449],\n",
      "        [12.9155,  7.0985,  8.8401]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6482,  12.2625,  -5.6533],\n",
      "        [-10.7230,  12.5171,  -6.1651],\n",
      "        [-10.8695,  12.0618,  -5.9468],\n",
      "        [-10.6553,  12.2743,  -5.7316],\n",
      "        [-10.9536,  12.3776,  -5.8465],\n",
      "        [-11.1435,  12.4929,  -5.9971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0117,   7.2503,   8.6869, -10.6482,  12.2625,  -5.6533],\n",
      "        [ 13.3247,   7.0867,   8.6552, -10.7230,  12.5171,  -6.1651],\n",
      "        [ 13.2621,   7.0553,   9.0265, -10.8695,  12.0618,  -5.9468],\n",
      "        [ 13.2272,   7.1748,   8.6496, -10.6553,  12.2743,  -5.7316],\n",
      "        [ 13.2976,   7.2662,   8.8449, -10.9536,  12.3776,  -5.8465],\n",
      "        [ 12.9155,   7.0985,   8.8401, -11.1435,  12.4929,  -5.9971]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.207458257675171\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2487,  7.0815,  9.0174],\n",
      "        [13.1383,  7.1541,  9.0894],\n",
      "        [12.9914,  6.9722,  8.8156],\n",
      "        [13.3404,  7.0141,  8.6610],\n",
      "        [13.1703,  7.2186,  8.9515],\n",
      "        [13.4121,  7.3919,  8.8629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3246, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.3324,  11.8326,  -5.8046],\n",
      "        [-10.7327,  12.5164,  -5.7550],\n",
      "        [-10.7602,  12.3609,  -6.0607],\n",
      "        [-10.7684,  12.3566,  -6.1074],\n",
      "        [-11.0174,  12.3946,  -6.0639],\n",
      "        [-10.6210,  12.3026,  -5.8514]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2487,   7.0815,   9.0174, -10.3324,  11.8326,  -5.8046],\n",
      "        [ 13.1383,   7.1541,   9.0894, -10.7327,  12.5164,  -5.7550],\n",
      "        [ 12.9914,   6.9722,   8.8156, -10.7602,  12.3609,  -6.0607],\n",
      "        [ 13.3404,   7.0141,   8.6610, -10.7684,  12.3566,  -6.1074],\n",
      "        [ 13.1703,   7.2186,   8.9515, -11.0174,  12.3946,  -6.0639],\n",
      "        [ 13.4121,   7.3919,   8.8629, -10.6210,  12.3026,  -5.8514]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2115020751953125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2092,  7.2036,  9.1329],\n",
      "        [12.9065,  6.9811,  8.2221],\n",
      "        [13.2090,  6.9033,  9.0211],\n",
      "        [13.0884,  7.1086,  9.0041],\n",
      "        [13.2734,  7.1984,  9.0238],\n",
      "        [13.4859,  6.9855,  8.8137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1577, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9118,  12.3495,  -5.7636],\n",
      "        [-11.0266,  12.0023,  -5.5807],\n",
      "        [-10.5089,  11.9787,  -6.1879],\n",
      "        [-10.9526,  12.4375,  -6.2085],\n",
      "        [-10.8026,  12.3274,  -5.7672],\n",
      "        [-10.5510,  12.2272,  -5.6665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2092,   7.2036,   9.1329, -10.9118,  12.3495,  -5.7636],\n",
      "        [ 12.9065,   6.9811,   8.2221, -11.0266,  12.0023,  -5.5807],\n",
      "        [ 13.2090,   6.9033,   9.0211, -10.5089,  11.9787,  -6.1879],\n",
      "        [ 13.0884,   7.1086,   9.0041, -10.9526,  12.4375,  -6.2085],\n",
      "        [ 13.2734,   7.1984,   9.0238, -10.8026,  12.3274,  -5.7672],\n",
      "        [ 13.4859,   6.9855,   8.8137, -10.5510,  12.2272,  -5.6665]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2331647872924805\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9808, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2330,  7.3851,  8.7804],\n",
      "        [12.9008,  6.7702,  8.9773],\n",
      "        [13.1630,  7.1994,  8.8787],\n",
      "        [13.0084,  7.1030,  9.3422],\n",
      "        [13.2779,  7.2435,  8.9716],\n",
      "        [13.1433,  7.2303,  8.8335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6736, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.4034,  12.3971,  -5.8707],\n",
      "        [-10.6072,  12.3209,  -6.0730],\n",
      "        [-10.3762,  12.4557,  -6.1134],\n",
      "        [-10.9977,  12.1691,  -5.9358],\n",
      "        [-10.8982,  12.2368,  -5.8593],\n",
      "        [-10.6418,  12.2610,  -5.9688]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2330,   7.3851,   8.7804, -10.4034,  12.3971,  -5.8707],\n",
      "        [ 12.9008,   6.7702,   8.9773, -10.6072,  12.3209,  -6.0730],\n",
      "        [ 13.1630,   7.1994,   8.8787, -10.3762,  12.4557,  -6.1134],\n",
      "        [ 13.0084,   7.1030,   9.3422, -10.9977,  12.1691,  -5.9358],\n",
      "        [ 13.2779,   7.2435,   8.9716, -10.8982,  12.2368,  -5.8593],\n",
      "        [ 13.1433,   7.2303,   8.8335, -10.6418,  12.2610,  -5.9688]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.222196340560913\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.1721,  6.7556,  8.1728],\n",
      "        [13.1428,  6.9443,  9.0051],\n",
      "        [13.5640,  7.0980,  9.0235],\n",
      "        [13.0511,  6.9790,  8.6437],\n",
      "        [13.3661,  7.1549,  8.9495],\n",
      "        [13.2776,  7.3054,  8.9826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.6897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9914,  11.9994,  -5.9588],\n",
      "        [-11.0588,  12.4133,  -5.8536],\n",
      "        [-11.1141,  12.5112,  -5.8431],\n",
      "        [-10.7292,  12.2748,  -5.8039],\n",
      "        [-11.0547,  12.4688,  -6.0923],\n",
      "        [-10.6002,  12.1706,  -5.5048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.1721,   6.7556,   8.1728, -10.9914,  11.9994,  -5.9588],\n",
      "        [ 13.1428,   6.9443,   9.0051, -11.0588,  12.4133,  -5.8536],\n",
      "        [ 13.5640,   7.0980,   9.0235, -11.1141,  12.5112,  -5.8431],\n",
      "        [ 13.0511,   6.9790,   8.6437, -10.7292,  12.2748,  -5.8039],\n",
      "        [ 13.3661,   7.1549,   8.9495, -11.0547,  12.4688,  -6.0923],\n",
      "        [ 13.2776,   7.3054,   8.9826, -10.6002,  12.1706,  -5.5048]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.1983891725540161\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7354, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5494,  7.5453,  8.8348],\n",
      "        [13.1632,  7.1368,  8.9728],\n",
      "        [13.0590,  7.2265,  8.7390],\n",
      "        [13.5407,  7.2184,  9.0451],\n",
      "        [13.2037,  7.3072,  9.0690],\n",
      "        [13.4378,  7.1569,  8.8458]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4054, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7811,  12.2248,  -5.7614],\n",
      "        [-10.7733,  12.4181,  -6.0514],\n",
      "        [-10.6714,  12.1297,  -5.8416],\n",
      "        [-10.9011,  12.6397,  -6.0572],\n",
      "        [-10.6934,  12.3517,  -5.6682],\n",
      "        [-11.0249,  12.3835,  -6.1610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5494,   7.5453,   8.8348, -10.7811,  12.2248,  -5.7614],\n",
      "        [ 13.1632,   7.1368,   8.9728, -10.7733,  12.4181,  -6.0514],\n",
      "        [ 13.0590,   7.2265,   8.7390, -10.6714,  12.1297,  -5.8416],\n",
      "        [ 13.5407,   7.2184,   9.0451, -10.9011,  12.6397,  -6.0572],\n",
      "        [ 13.2037,   7.3072,   9.0690, -10.6934,  12.3517,  -5.6682],\n",
      "        [ 13.4378,   7.1569,   8.8458, -11.0249,  12.3835,  -6.1610]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2406195402145386\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3420,  7.0315,  9.0749],\n",
      "        [13.5290,  7.2822,  9.1270],\n",
      "        [13.4564,  7.0515,  8.8840],\n",
      "        [13.1499,  7.1568,  9.0250],\n",
      "        [13.4519,  7.3302,  9.1889],\n",
      "        [12.9913,  7.0915,  8.8026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9491,  12.4870,  -6.0840],\n",
      "        [-10.8020,  12.2771,  -5.7957],\n",
      "        [-10.9079,  12.2315,  -6.0789],\n",
      "        [-10.6073,  12.4617,  -5.8600],\n",
      "        [-10.5480,  12.2178,  -6.1570],\n",
      "        [-10.8587,  12.0194,  -5.8978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3420,   7.0315,   9.0749, -10.9491,  12.4870,  -6.0840],\n",
      "        [ 13.5290,   7.2822,   9.1270, -10.8020,  12.2771,  -5.7957],\n",
      "        [ 13.4564,   7.0515,   8.8840, -10.9079,  12.2315,  -6.0789],\n",
      "        [ 13.1499,   7.1568,   9.0250, -10.6073,  12.4617,  -5.8600],\n",
      "        [ 13.4519,   7.3302,   9.1889, -10.5480,  12.2178,  -6.1570],\n",
      "        [ 12.9913,   7.0915,   8.8026, -10.8587,  12.0194,  -5.8978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.242241621017456\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.6910,  6.6478,  8.7540],\n",
      "        [13.0757,  7.1714,  8.8727],\n",
      "        [12.9830,  7.2486,  8.9514],\n",
      "        [13.3412,  7.2403,  8.7693],\n",
      "        [13.0837,  6.7413,  8.7624],\n",
      "        [13.4084,  7.0707,  8.9333]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.7404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9039,  12.4132,  -5.7109],\n",
      "        [-10.9017,  12.0755,  -5.5513],\n",
      "        [-10.6636,  12.1102,  -6.1392],\n",
      "        [-10.5775,  11.5817,  -5.6520],\n",
      "        [-10.7303,  12.4848,  -5.8134],\n",
      "        [-10.7212,  12.4945,  -5.8532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.6910,   6.6478,   8.7540, -10.9039,  12.4132,  -5.7109],\n",
      "        [ 13.0757,   7.1714,   8.8727, -10.9017,  12.0755,  -5.5513],\n",
      "        [ 12.9830,   7.2486,   8.9514, -10.6636,  12.1102,  -6.1392],\n",
      "        [ 13.3412,   7.2403,   8.7693, -10.5775,  11.5817,  -5.6520],\n",
      "        [ 13.0837,   6.7413,   8.7624, -10.7303,  12.4848,  -5.8134],\n",
      "        [ 13.4084,   7.0707,   8.9333, -10.7212,  12.4945,  -5.8532]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2012673616409302\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3244,  7.1246,  9.1220],\n",
      "        [13.3859,  7.4944,  9.0555],\n",
      "        [13.4015,  7.2376,  8.8978],\n",
      "        [13.4691,  7.3773,  9.2518],\n",
      "        [13.2934,  7.3137,  8.8506],\n",
      "        [13.0330,  7.0393,  8.6126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.7620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8243,  12.2977,  -5.6853],\n",
      "        [-10.5828,  12.1004,  -6.1175],\n",
      "        [-10.6428,  12.3172,  -5.9989],\n",
      "        [-10.8874,  12.3352,  -5.7998],\n",
      "        [-10.4870,  12.3598,  -5.8677],\n",
      "        [-10.9689,  12.2433,  -6.1580]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3244,   7.1246,   9.1220, -10.8243,  12.2977,  -5.6853],\n",
      "        [ 13.3859,   7.4944,   9.0555, -10.5828,  12.1004,  -6.1175],\n",
      "        [ 13.4015,   7.2376,   8.8978, -10.6428,  12.3172,  -5.9989],\n",
      "        [ 13.4691,   7.3773,   9.2518, -10.8874,  12.3352,  -5.7998],\n",
      "        [ 13.2934,   7.3137,   8.8506, -10.4870,  12.3598,  -5.8677],\n",
      "        [ 13.0330,   7.0393,   8.6126, -10.9689,  12.2433,  -6.1580]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2376590967178345\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3694,  7.3303,  9.1076],\n",
      "        [13.2081,  7.2413,  8.8118],\n",
      "        [13.1084,  7.2816,  8.7702],\n",
      "        [13.5635,  6.9691,  8.8047],\n",
      "        [13.1148,  7.4258,  8.9151],\n",
      "        [13.1831,  7.6284,  9.0708]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.5145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8494,  12.4267,  -5.9237],\n",
      "        [-10.9925,  12.3131,  -6.0110],\n",
      "        [-10.9428,  12.1810,  -5.9780],\n",
      "        [-10.7953,  12.4735,  -6.0103],\n",
      "        [-10.8967,  11.9613,  -5.9545],\n",
      "        [-11.2476,  12.2549,  -6.1973]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3694,   7.3303,   9.1076, -10.8494,  12.4267,  -5.9237],\n",
      "        [ 13.2081,   7.2413,   8.8118, -10.9925,  12.3131,  -6.0110],\n",
      "        [ 13.1084,   7.2816,   8.7702, -10.9428,  12.1810,  -5.9780],\n",
      "        [ 13.5635,   6.9691,   8.8047, -10.7953,  12.4735,  -6.0103],\n",
      "        [ 13.1148,   7.4258,   8.9151, -10.8967,  11.9613,  -5.9545],\n",
      "        [ 13.1831,   7.6284,   9.0708, -11.2476,  12.2549,  -6.1973]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2470341920852661\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[12.9929,  7.2562,  8.9791],\n",
      "        [13.2215,  7.0306,  9.2372],\n",
      "        [13.5213,  7.1133,  9.1466],\n",
      "        [13.2261,  6.7493,  8.8478],\n",
      "        [13.0036,  6.8969,  8.9174],\n",
      "        [13.4269,  7.6591,  9.1554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.9534, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7639,  12.4675,  -6.3201],\n",
      "        [-11.0499,  12.4857,  -6.1350],\n",
      "        [-11.0123,  12.4128,  -6.2171],\n",
      "        [-10.9766,  12.3282,  -6.1069],\n",
      "        [-10.9634,  12.1091,  -5.8531],\n",
      "        [-11.1589,  12.3022,  -6.3288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 12.9929,   7.2562,   8.9791, -10.7639,  12.4675,  -6.3201],\n",
      "        [ 13.2215,   7.0306,   9.2372, -11.0499,  12.4857,  -6.1350],\n",
      "        [ 13.5213,   7.1133,   9.1466, -11.0123,  12.4128,  -6.2171],\n",
      "        [ 13.2261,   6.7493,   8.8478, -10.9766,  12.3282,  -6.1069],\n",
      "        [ 13.0036,   6.8969,   8.9174, -10.9634,  12.1091,  -5.8531],\n",
      "        [ 13.4269,   7.6591,   9.1554, -11.1589,  12.3022,  -6.3288]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.2322442531585693\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7694, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7670,  7.3777,  8.9230],\n",
      "        [13.3654,  7.0034,  8.8270],\n",
      "        [13.1818,  7.4932,  9.0176],\n",
      "        [13.2827,  7.4116,  9.1727],\n",
      "        [13.3494,  7.2838,  8.8091],\n",
      "        [13.6292,  7.2019,  8.9640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5858,  12.2805,  -5.6695],\n",
      "        [-11.1139,  12.6192,  -6.0590],\n",
      "        [-10.9919,  12.2695,  -5.8140],\n",
      "        [-11.1238,  12.2459,  -5.8697],\n",
      "        [-10.9885,  12.5555,  -5.7217],\n",
      "        [-11.1239,  12.3396,  -5.7995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7670,   7.3777,   8.9230, -10.5858,  12.2805,  -5.6695],\n",
      "        [ 13.3654,   7.0034,   8.8270, -11.1139,  12.6192,  -6.0590],\n",
      "        [ 13.1818,   7.4932,   9.0176, -10.9919,  12.2695,  -5.8140],\n",
      "        [ 13.2827,   7.4116,   9.1727, -11.1238,  12.2459,  -5.8697],\n",
      "        [ 13.3494,   7.2838,   8.8091, -10.9885,  12.5555,  -5.7217],\n",
      "        [ 13.6292,   7.2019,   8.9640, -11.1239,  12.3396,  -5.7995]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2502193450927734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0520, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4262,  7.4160,  8.9958],\n",
      "        [13.0645,  7.0967,  9.1744],\n",
      "        [13.5544,  7.7281,  9.2788],\n",
      "        [13.5052,  7.3698,  8.7935],\n",
      "        [13.2793,  7.4917,  9.2381],\n",
      "        [12.9544,  7.2386,  8.8502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.6104, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8139,  12.5398,  -6.1730],\n",
      "        [-10.7124,  12.3566,  -5.9299],\n",
      "        [-10.5215,  12.7639,  -5.9897],\n",
      "        [-11.1100,  12.4547,  -6.5047],\n",
      "        [-10.4630,  12.6508,  -6.1518],\n",
      "        [-10.9428,  12.2971,  -6.2742]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4262,   7.4160,   8.9958, -10.8139,  12.5398,  -6.1730],\n",
      "        [ 13.0645,   7.0967,   9.1744, -10.7124,  12.3566,  -5.9299],\n",
      "        [ 13.5544,   7.7281,   9.2788, -10.5215,  12.7639,  -5.9897],\n",
      "        [ 13.5052,   7.3698,   8.7935, -11.1100,  12.4547,  -6.5047],\n",
      "        [ 13.2793,   7.4917,   9.2381, -10.4630,  12.6508,  -6.1518],\n",
      "        [ 12.9544,   7.2386,   8.8502, -10.9428,  12.2971,  -6.2742]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2530007362365723\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8125, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4360,  7.4864,  9.2170],\n",
      "        [13.2090,  7.4697,  8.9622],\n",
      "        [13.4100,  6.9515,  8.8263],\n",
      "        [13.5107,  7.3924,  9.2197],\n",
      "        [13.1625,  7.0793,  8.6178],\n",
      "        [13.2846,  6.9901,  9.1200]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.6158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8823,  12.4138,  -5.9123],\n",
      "        [-10.7846,  12.6938,  -5.9390],\n",
      "        [-11.1126,  12.6061,  -6.0897],\n",
      "        [-10.6011,  12.2223,  -5.6737],\n",
      "        [-10.6390,  11.9780,  -6.0267],\n",
      "        [-10.7832,  12.7732,  -5.9157]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4360,   7.4864,   9.2170, -10.8823,  12.4138,  -5.9123],\n",
      "        [ 13.2090,   7.4697,   8.9622, -10.7846,  12.6938,  -5.9390],\n",
      "        [ 13.4100,   6.9515,   8.8263, -11.1126,  12.6061,  -6.0897],\n",
      "        [ 13.5107,   7.3924,   9.2197, -10.6011,  12.2223,  -5.6737],\n",
      "        [ 13.1625,   7.0793,   8.6178, -10.6390,  11.9780,  -6.0267],\n",
      "        [ 13.2846,   6.9901,   9.1200, -10.7832,  12.7732,  -5.9157]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.257851243019104\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2109,  7.2588,  9.1112],\n",
      "        [13.2349,  7.3956,  9.2106],\n",
      "        [13.6120,  7.2769,  9.1415],\n",
      "        [13.4880,  7.4062,  9.1676],\n",
      "        [12.9927,  7.2947,  9.4003],\n",
      "        [13.2157,  7.1485,  9.4065]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.0906, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7668,  12.3687,  -6.2059],\n",
      "        [-10.6660,  12.5371,  -5.7120],\n",
      "        [-10.8752,  12.7957,  -6.1524],\n",
      "        [-10.6620,  12.1816,  -6.1701],\n",
      "        [-10.9614,  12.4228,  -6.2967],\n",
      "        [-11.1282,  12.4823,  -6.1018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2109,   7.2588,   9.1112, -10.7668,  12.3687,  -6.2059],\n",
      "        [ 13.2349,   7.3956,   9.2106, -10.6660,  12.5371,  -5.7120],\n",
      "        [ 13.6120,   7.2769,   9.1415, -10.8752,  12.7957,  -6.1524],\n",
      "        [ 13.4880,   7.4062,   9.1676, -10.6620,  12.1816,  -6.1701],\n",
      "        [ 12.9927,   7.2947,   9.4003, -10.9614,  12.4228,  -6.2967],\n",
      "        [ 13.2157,   7.1485,   9.4065, -11.1282,  12.4823,  -6.1018]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2440786361694336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5613, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5187,  7.4634,  9.2395],\n",
      "        [13.3878,  6.8707,  9.1700],\n",
      "        [13.2687,  7.1990,  9.0431],\n",
      "        [13.4224,  7.1151,  8.9033],\n",
      "        [13.5192,  7.2776,  9.3491],\n",
      "        [12.8328,  7.3779,  8.9949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7037, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8635,  12.0673,  -5.5334],\n",
      "        [-11.3001,  12.5854,  -5.7500],\n",
      "        [-10.6108,  11.9768,  -5.7716],\n",
      "        [-10.7555,  12.5466,  -6.1968],\n",
      "        [-10.6923,  12.5185,  -6.2623],\n",
      "        [-10.8573,  12.3590,  -5.9830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5187,   7.4634,   9.2395, -10.8635,  12.0673,  -5.5334],\n",
      "        [ 13.3878,   6.8707,   9.1700, -11.3001,  12.5854,  -5.7500],\n",
      "        [ 13.2687,   7.1990,   9.0431, -10.6108,  11.9768,  -5.7716],\n",
      "        [ 13.4224,   7.1151,   8.9033, -10.7555,  12.5466,  -6.1968],\n",
      "        [ 13.5192,   7.2776,   9.3491, -10.6923,  12.5185,  -6.2623],\n",
      "        [ 12.8328,   7.3779,   8.9949, -10.8573,  12.3590,  -5.9830]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2534239292144775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.0758,  6.9176,  9.0643],\n",
      "        [13.3162,  7.2538,  8.9712],\n",
      "        [12.9734,  7.1355,  9.0608],\n",
      "        [13.4821,  7.0788,  9.0501],\n",
      "        [13.1999,  7.4171,  8.9532],\n",
      "        [13.1791,  7.0938,  9.2262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0572,  12.5515,  -6.0489],\n",
      "        [-10.7624,  12.2240,  -6.3301],\n",
      "        [-10.5504,  12.2335,  -5.9831],\n",
      "        [-11.0335,  12.5075,  -6.0298],\n",
      "        [-11.0321,  12.3947,  -5.8841],\n",
      "        [-10.9804,  12.8780,  -6.0314]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.0758,   6.9176,   9.0643, -11.0572,  12.5515,  -6.0489],\n",
      "        [ 13.3162,   7.2538,   8.9712, -10.7624,  12.2240,  -6.3301],\n",
      "        [ 12.9734,   7.1355,   9.0608, -10.5504,  12.2335,  -5.9831],\n",
      "        [ 13.4821,   7.0788,   9.0501, -11.0335,  12.5075,  -6.0298],\n",
      "        [ 13.1999,   7.4171,   8.9532, -11.0321,  12.3947,  -5.8841],\n",
      "        [ 13.1791,   7.0938,   9.2262, -10.9804,  12.8780,  -6.0314]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.2411150932312012\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7838, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3351,  7.3959,  9.0190],\n",
      "        [13.3360,  7.5573,  8.6542],\n",
      "        [13.5319,  7.4099,  8.9226],\n",
      "        [13.0716,  7.5353,  9.1925],\n",
      "        [13.8681,  7.3385,  9.0087],\n",
      "        [13.3334,  7.3846,  8.9286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0988,  12.4591,  -6.0961],\n",
      "        [-11.1342,  12.7433,  -6.1266],\n",
      "        [-10.9134,  12.1661,  -6.2458],\n",
      "        [-10.8656,  12.2340,  -6.0167],\n",
      "        [-11.0168,  12.5143,  -6.2882],\n",
      "        [-11.0298,  12.2899,  -6.1226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3351,   7.3959,   9.0190, -11.0988,  12.4591,  -6.0961],\n",
      "        [ 13.3360,   7.5573,   8.6542, -11.1342,  12.7433,  -6.1266],\n",
      "        [ 13.5319,   7.4099,   8.9226, -10.9134,  12.1661,  -6.2458],\n",
      "        [ 13.0716,   7.5353,   9.1925, -10.8656,  12.2340,  -6.0167],\n",
      "        [ 13.8681,   7.3385,   9.0087, -11.0168,  12.5143,  -6.2882],\n",
      "        [ 13.3334,   7.3846,   8.9286, -11.0298,  12.2899,  -6.1226]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2563356161117554\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7737,  7.3701,  9.2009],\n",
      "        [13.6698,  7.2335,  8.9884],\n",
      "        [13.5634,  7.3568,  9.3765],\n",
      "        [13.1189,  7.1987,  8.8687],\n",
      "        [13.4168,  7.6279,  8.9231],\n",
      "        [13.6278,  7.5125,  9.2034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8155, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.6547,  12.3468,  -6.0437],\n",
      "        [-10.9719,  12.4270,  -5.8049],\n",
      "        [-10.8296,  12.8316,  -6.1339],\n",
      "        [-11.0515,  12.5931,  -6.2646],\n",
      "        [-11.0153,  12.6051,  -6.4185],\n",
      "        [-10.9518,  12.3303,  -5.4941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7737,   7.3701,   9.2009, -10.6547,  12.3468,  -6.0437],\n",
      "        [ 13.6698,   7.2335,   8.9884, -10.9719,  12.4270,  -5.8049],\n",
      "        [ 13.5634,   7.3568,   9.3765, -10.8296,  12.8316,  -6.1339],\n",
      "        [ 13.1189,   7.1987,   8.8687, -11.0515,  12.5931,  -6.2646],\n",
      "        [ 13.4168,   7.6279,   8.9231, -11.0153,  12.6051,  -6.4185],\n",
      "        [ 13.6278,   7.5125,   9.2034, -10.9518,  12.3303,  -5.4941]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2679927349090576\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8374, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7384,  7.4721,  9.1171],\n",
      "        [13.5162,  7.3515,  9.3098],\n",
      "        [13.6278,  7.2627,  9.1171],\n",
      "        [13.6179,  7.5664,  8.7809],\n",
      "        [13.2465,  7.2129,  9.4689],\n",
      "        [13.6398,  7.3084,  9.0383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9039,  12.6675,  -6.0623],\n",
      "        [-10.9738,  12.6999,  -6.2611],\n",
      "        [-11.1589,  12.5932,  -6.4824],\n",
      "        [-10.9906,  12.3870,  -6.2846],\n",
      "        [-10.8743,  12.3114,  -6.2708],\n",
      "        [-11.0147,  12.4799,  -5.9888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7384,   7.4721,   9.1171, -10.9039,  12.6675,  -6.0623],\n",
      "        [ 13.5162,   7.3515,   9.3098, -10.9738,  12.6999,  -6.2611],\n",
      "        [ 13.6278,   7.2627,   9.1171, -11.1589,  12.5932,  -6.4824],\n",
      "        [ 13.6179,   7.5664,   8.7809, -10.9906,  12.3870,  -6.2846],\n",
      "        [ 13.2465,   7.2129,   9.4689, -10.8743,  12.3114,  -6.2708],\n",
      "        [ 13.6398,   7.3084,   9.0383, -11.0147,  12.4799,  -5.9888]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2764941453933716\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7370, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4555,  7.0820,  9.2984],\n",
      "        [13.3174,  7.2379,  8.9680],\n",
      "        [13.6501,  7.1548,  8.7432],\n",
      "        [13.7703,  7.7082,  9.0933],\n",
      "        [13.3106,  7.6845,  8.6894],\n",
      "        [13.2384,  7.4934,  8.8635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.0710, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2200,  12.6647,  -6.3138],\n",
      "        [-10.8137,  12.5639,  -6.1139],\n",
      "        [-10.7494,  12.6254,  -6.3013],\n",
      "        [-10.6161,  12.3627,  -6.0572],\n",
      "        [-11.1198,  12.2535,  -6.2643],\n",
      "        [-11.0149,  12.5369,  -6.1150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4555,   7.0820,   9.2984, -11.2200,  12.6647,  -6.3138],\n",
      "        [ 13.3174,   7.2379,   8.9680, -10.8137,  12.5639,  -6.1139],\n",
      "        [ 13.6501,   7.1548,   8.7432, -10.7494,  12.6254,  -6.3013],\n",
      "        [ 13.7703,   7.7082,   9.0933, -10.6161,  12.3627,  -6.0572],\n",
      "        [ 13.3106,   7.6845,   8.6894, -11.1198,  12.2535,  -6.2643],\n",
      "        [ 13.2384,   7.4934,   8.8635, -11.0149,  12.5369,  -6.1150]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2728008031845093\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4570,  7.2281,  8.8011],\n",
      "        [13.7701,  7.3272,  8.8610],\n",
      "        [13.4763,  7.5230,  8.7914],\n",
      "        [13.8145,  7.3116,  8.9159],\n",
      "        [13.0127,  7.1696,  9.0250],\n",
      "        [13.0263,  7.2662,  8.8768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8608,  12.6264,  -6.2752],\n",
      "        [-10.6654,  12.5628,  -6.0356],\n",
      "        [-11.2142,  12.4065,  -6.3970],\n",
      "        [-11.0697,  12.5837,  -6.4214],\n",
      "        [-11.0803,  12.7167,  -5.8296],\n",
      "        [-10.9857,  12.3070,  -6.2352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4570,   7.2281,   8.8011, -10.8608,  12.6264,  -6.2752],\n",
      "        [ 13.7701,   7.3272,   8.8610, -10.6654,  12.5628,  -6.0356],\n",
      "        [ 13.4763,   7.5230,   8.7914, -11.2142,  12.4065,  -6.3970],\n",
      "        [ 13.8145,   7.3116,   8.9159, -11.0697,  12.5837,  -6.4214],\n",
      "        [ 13.0127,   7.1696,   9.0250, -11.0803,  12.7167,  -5.8296],\n",
      "        [ 13.0263,   7.2662,   8.8768, -10.9857,  12.3070,  -6.2352]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2563167810440063\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2229,  7.4367,  9.1377],\n",
      "        [13.5453,  7.1916,  8.9857],\n",
      "        [13.5625,  7.2488,  9.5441],\n",
      "        [13.5323,  7.4143,  9.1027],\n",
      "        [13.7449,  7.4151,  9.3862],\n",
      "        [13.5075,  7.1548,  9.0669]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8178,  12.6114,  -6.3690],\n",
      "        [-11.4232,  12.0879,  -6.2811],\n",
      "        [-11.2554,  12.6231,  -6.3246],\n",
      "        [-11.2792,  12.7144,  -6.4142],\n",
      "        [-10.7557,  12.2772,  -6.2773],\n",
      "        [-11.0506,  12.7274,  -5.9609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2229,   7.4367,   9.1377, -10.8178,  12.6114,  -6.3690],\n",
      "        [ 13.5453,   7.1916,   8.9857, -11.4232,  12.0879,  -6.2811],\n",
      "        [ 13.5625,   7.2488,   9.5441, -11.2554,  12.6231,  -6.3246],\n",
      "        [ 13.5323,   7.4143,   9.1027, -11.2792,  12.7144,  -6.4142],\n",
      "        [ 13.7449,   7.4151,   9.3862, -10.7557,  12.2772,  -6.2773],\n",
      "        [ 13.5075,   7.1548,   9.0669, -11.0506,  12.7274,  -5.9609]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.2603883743286133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6063,  7.5071,  8.9898],\n",
      "        [13.6550,  7.4268,  9.2530],\n",
      "        [13.4960,  7.2139,  9.3477],\n",
      "        [13.4320,  7.5423,  8.9667],\n",
      "        [13.2955,  7.0505,  8.9795],\n",
      "        [13.2336,  7.2606,  8.5273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6434, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.7498,  12.7558,  -6.4608],\n",
      "        [-10.7614,  12.8482,  -6.4713],\n",
      "        [-11.0152,  12.4282,  -6.4681],\n",
      "        [-10.5861,  12.3729,  -6.1859],\n",
      "        [-11.1563,  12.4950,  -5.9799],\n",
      "        [-11.2280,  12.4126,  -5.8361]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6063,   7.5071,   8.9898, -10.7498,  12.7558,  -6.4608],\n",
      "        [ 13.6550,   7.4268,   9.2530, -10.7614,  12.8482,  -6.4713],\n",
      "        [ 13.4960,   7.2139,   9.3477, -11.0152,  12.4282,  -6.4681],\n",
      "        [ 13.4320,   7.5423,   8.9667, -10.5861,  12.3729,  -6.1859],\n",
      "        [ 13.2955,   7.0505,   8.9795, -11.1563,  12.4950,  -5.9799],\n",
      "        [ 13.2336,   7.2606,   8.5273, -11.2280,  12.4126,  -5.8361]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2742819786071777\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1225, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3375,  7.1819,  8.8048],\n",
      "        [13.5855,  7.4192,  9.1266],\n",
      "        [13.4948,  7.1751,  9.3680],\n",
      "        [13.2868,  7.0907,  9.1248],\n",
      "        [13.7657,  7.3403,  9.3114],\n",
      "        [13.3411,  7.3165,  8.8806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.5718,  12.5687,  -6.3447],\n",
      "        [-10.9090,  12.3441,  -6.0692],\n",
      "        [-11.1337,  12.7996,  -6.3184],\n",
      "        [-11.0767,  12.5621,  -6.0568],\n",
      "        [-11.1150,  12.6612,  -6.1185],\n",
      "        [-11.3424,  12.3871,  -6.6621]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3375,   7.1819,   8.8048, -10.5718,  12.5687,  -6.3447],\n",
      "        [ 13.5855,   7.4192,   9.1266, -10.9090,  12.3441,  -6.0692],\n",
      "        [ 13.4948,   7.1751,   9.3680, -11.1337,  12.7996,  -6.3184],\n",
      "        [ 13.2868,   7.0907,   9.1248, -11.0767,  12.5621,  -6.0568],\n",
      "        [ 13.7657,   7.3403,   9.3114, -11.1150,  12.6612,  -6.1185],\n",
      "        [ 13.3411,   7.3165,   8.8806, -11.3424,  12.3871,  -6.6621]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2488473653793335\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7894, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2725,  7.3164,  9.3298],\n",
      "        [13.5591,  7.4762,  9.2672],\n",
      "        [13.7211,  7.6039,  9.2730],\n",
      "        [13.6810,  7.7949,  9.2459],\n",
      "        [13.7122,  7.7431,  9.0002],\n",
      "        [13.1325,  7.2872,  9.1741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9298,  12.3450,  -6.2130],\n",
      "        [-10.9583,  12.1454,  -6.0188],\n",
      "        [-11.2080,  12.4730,  -6.1237],\n",
      "        [-10.8056,  12.6550,  -6.2061],\n",
      "        [-10.9458,  12.4911,  -6.2458],\n",
      "        [-11.0225,  12.4359,  -6.1956]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2725,   7.3164,   9.3298, -10.9298,  12.3450,  -6.2130],\n",
      "        [ 13.5591,   7.4762,   9.2672, -10.9583,  12.1454,  -6.0188],\n",
      "        [ 13.7211,   7.6039,   9.2730, -11.2080,  12.4730,  -6.1237],\n",
      "        [ 13.6810,   7.7949,   9.2459, -10.8056,  12.6550,  -6.2061],\n",
      "        [ 13.7122,   7.7431,   9.0002, -10.9458,  12.4911,  -6.2458],\n",
      "        [ 13.1325,   7.2872,   9.1741, -11.0225,  12.4359,  -6.1956]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.263585090637207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.1778,  6.8348,  9.0832],\n",
      "        [13.3391,  7.4515,  8.9617],\n",
      "        [13.5409,  7.4606,  8.8991],\n",
      "        [13.5306,  7.1228,  9.5319],\n",
      "        [13.5634,  7.3397,  9.1217],\n",
      "        [13.4530,  7.3065,  9.1536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.8879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0968,  12.5456,  -6.4766],\n",
      "        [-10.6737,  11.9032,  -6.1032],\n",
      "        [-11.2941,  12.4188,  -5.9754],\n",
      "        [-10.9295,  12.6178,  -6.2941],\n",
      "        [-11.0855,  12.5924,  -6.2497],\n",
      "        [-11.1204,  12.5059,  -6.0665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.1778,   6.8348,   9.0832, -11.0968,  12.5456,  -6.4766],\n",
      "        [ 13.3391,   7.4515,   8.9617, -10.6737,  11.9032,  -6.1032],\n",
      "        [ 13.5409,   7.4606,   8.8991, -11.2941,  12.4188,  -5.9754],\n",
      "        [ 13.5306,   7.1228,   9.5319, -10.9295,  12.6178,  -6.2941],\n",
      "        [ 13.5634,   7.3397,   9.1217, -11.0855,  12.5924,  -6.2497],\n",
      "        [ 13.4530,   7.3065,   9.1536, -11.1204,  12.5059,  -6.0665]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2554926872253418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7824, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5659,  7.7718,  9.2215],\n",
      "        [13.6025,  7.3094,  9.1738],\n",
      "        [13.8860,  7.5715,  9.2464],\n",
      "        [13.1408,  7.0567,  9.0235],\n",
      "        [13.2460,  7.3834,  9.0005],\n",
      "        [13.6189,  7.3578,  9.0830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8549, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0065,  12.5180,  -6.1997],\n",
      "        [-11.2416,  12.6053,  -6.4246],\n",
      "        [-11.0130,  12.4278,  -5.6989],\n",
      "        [-10.8096,  12.4730,  -6.1736],\n",
      "        [-11.3543,  12.7721,  -6.3828],\n",
      "        [-10.7812,  12.4683,  -6.4289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5659,   7.7718,   9.2215, -11.0065,  12.5180,  -6.1997],\n",
      "        [ 13.6025,   7.3094,   9.1738, -11.2416,  12.6053,  -6.4246],\n",
      "        [ 13.8860,   7.5715,   9.2464, -11.0130,  12.4278,  -5.6989],\n",
      "        [ 13.1408,   7.0567,   9.0235, -10.8096,  12.4730,  -6.1736],\n",
      "        [ 13.2460,   7.3834,   9.0005, -11.3543,  12.7721,  -6.3828],\n",
      "        [ 13.6189,   7.3578,   9.0830, -10.7812,  12.4683,  -6.4289]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2837748527526855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6326,  7.8362,  9.5788],\n",
      "        [13.7580,  7.2848,  9.0633],\n",
      "        [13.4072,  7.5868,  9.0752],\n",
      "        [13.6775,  7.6016,  8.9923],\n",
      "        [13.6599,  7.2892,  8.8214],\n",
      "        [13.6310,  7.0192,  8.8627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0393,  12.2003,  -6.2236],\n",
      "        [-10.6323,  12.5220,  -6.4303],\n",
      "        [-10.9109,  12.6729,  -6.2393],\n",
      "        [-11.1617,  12.7472,  -6.2744],\n",
      "        [-10.5481,  12.7046,  -6.4158],\n",
      "        [-11.1534,  12.3453,  -6.1219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6326,   7.8362,   9.5788, -11.0393,  12.2003,  -6.2236],\n",
      "        [ 13.7580,   7.2848,   9.0633, -10.6323,  12.5220,  -6.4303],\n",
      "        [ 13.4072,   7.5868,   9.0752, -10.9109,  12.6729,  -6.2393],\n",
      "        [ 13.6775,   7.6016,   8.9923, -11.1617,  12.7472,  -6.2744],\n",
      "        [ 13.6599,   7.2892,   8.8214, -10.5481,  12.7046,  -6.4158],\n",
      "        [ 13.6310,   7.0192,   8.8627, -11.1534,  12.3453,  -6.1219]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.292298674583435\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7759, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8874,  7.8286,  9.4912],\n",
      "        [13.8240,  7.7115,  8.9909],\n",
      "        [13.5400,  7.1632,  9.3403],\n",
      "        [13.7503,  7.6438,  9.1679],\n",
      "        [13.6831,  7.4742,  9.1105],\n",
      "        [13.1037,  7.5640,  8.7597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1379, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3130,  12.5366,  -6.4447],\n",
      "        [-11.2525,  12.5020,  -6.5485],\n",
      "        [-10.7735,  12.5423,  -6.6742],\n",
      "        [-10.7687,  12.4697,  -6.2171],\n",
      "        [-11.2943,  12.5102,  -6.1176],\n",
      "        [-11.4301,  12.7107,  -6.2100]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8874,   7.8286,   9.4912, -11.3130,  12.5366,  -6.4447],\n",
      "        [ 13.8240,   7.7115,   8.9909, -11.2525,  12.5020,  -6.5485],\n",
      "        [ 13.5400,   7.1632,   9.3403, -10.7735,  12.5423,  -6.6742],\n",
      "        [ 13.7503,   7.6438,   9.1679, -10.7687,  12.4697,  -6.2171],\n",
      "        [ 13.6831,   7.4742,   9.1105, -11.2943,  12.5102,  -6.1176],\n",
      "        [ 13.1037,   7.5640,   8.7597, -11.4301,  12.7107,  -6.2100]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3117363452911377\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.2166,  7.1852,  9.2014],\n",
      "        [12.8953,  7.3277,  8.8092],\n",
      "        [13.4171,  7.2545,  8.9724],\n",
      "        [13.3152,  7.4008,  9.3863],\n",
      "        [13.8211,  7.3689,  9.1447],\n",
      "        [13.4975,  7.7010,  9.4402]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.2887, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.9515,  12.3295,  -6.2503],\n",
      "        [-10.9684,  12.5120,  -6.5296],\n",
      "        [-11.1653,  12.6274,  -6.4531],\n",
      "        [-10.8913,  12.6133,  -6.2894],\n",
      "        [-11.2021,  13.0666,  -6.0607],\n",
      "        [-11.3291,  12.4029,  -6.5090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.2166,   7.1852,   9.2014, -10.9515,  12.3295,  -6.2503],\n",
      "        [ 12.8953,   7.3277,   8.8092, -10.9684,  12.5120,  -6.5296],\n",
      "        [ 13.4171,   7.2545,   8.9724, -11.1653,  12.6274,  -6.4531],\n",
      "        [ 13.3152,   7.4008,   9.3863, -10.8913,  12.6133,  -6.2894],\n",
      "        [ 13.8211,   7.3689,   9.1447, -11.2021,  13.0666,  -6.0607],\n",
      "        [ 13.4975,   7.7010,   9.4402, -11.3291,  12.4029,  -6.5090]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2605247497558594\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9577, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5069,  7.2910,  9.2666],\n",
      "        [12.9288,  7.5785,  9.4645],\n",
      "        [13.2690,  7.2796,  9.1377],\n",
      "        [13.6484,  7.7463,  9.1825],\n",
      "        [13.6046,  7.5770,  9.1393],\n",
      "        [13.7618,  7.4759,  9.1887]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.6166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0888,  12.6837,  -6.3542],\n",
      "        [-11.0422,  12.5374,  -6.6027],\n",
      "        [-11.1004,  12.7479,  -6.6021],\n",
      "        [-10.9883,  12.2749,  -6.1867],\n",
      "        [-11.3011,  12.2193,  -6.4212],\n",
      "        [-11.0009,  12.5629,  -5.9554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5069,   7.2910,   9.2666, -11.0888,  12.6837,  -6.3542],\n",
      "        [ 12.9288,   7.5785,   9.4645, -11.0422,  12.5374,  -6.6027],\n",
      "        [ 13.2690,   7.2796,   9.1377, -11.1004,  12.7479,  -6.6021],\n",
      "        [ 13.6484,   7.7463,   9.1825, -10.9883,  12.2749,  -6.1867],\n",
      "        [ 13.6046,   7.5770,   9.1393, -11.3011,  12.2193,  -6.4212],\n",
      "        [ 13.7618,   7.4759,   9.1887, -11.0009,  12.5629,  -5.9554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2842884063720703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7702, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4665,  7.4134,  9.3125],\n",
      "        [13.2895,  7.5358,  9.2037],\n",
      "        [13.4870,  7.6829,  9.0659],\n",
      "        [13.7654,  7.4348,  9.2058],\n",
      "        [13.4711,  7.5201,  9.1700],\n",
      "        [13.5941,  7.2054,  9.1293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2762,  12.5140,  -5.9878],\n",
      "        [-11.2997,  12.8532,  -6.5627],\n",
      "        [-10.9547,  12.5076,  -6.0755],\n",
      "        [-10.8244,  12.0339,  -6.0001],\n",
      "        [-11.2124,  12.5548,  -6.2716],\n",
      "        [-10.5941,  12.2699,  -6.3007]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4665,   7.4134,   9.3125, -11.2762,  12.5140,  -5.9878],\n",
      "        [ 13.2895,   7.5358,   9.2037, -11.2997,  12.8532,  -6.5627],\n",
      "        [ 13.4870,   7.6829,   9.0659, -10.9547,  12.5076,  -6.0755],\n",
      "        [ 13.7654,   7.4348,   9.2058, -10.8244,  12.0339,  -6.0001],\n",
      "        [ 13.4711,   7.5201,   9.1700, -11.2124,  12.5548,  -6.2716],\n",
      "        [ 13.5941,   7.2054,   9.1293, -10.5941,  12.2699,  -6.3007]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2837570905685425\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0684, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4608,  7.7122,  9.2464],\n",
      "        [13.0806,  7.5932,  8.8240],\n",
      "        [13.7765,  7.5893,  9.0477],\n",
      "        [13.2843,  7.2487,  8.8668],\n",
      "        [13.4406,  7.4798,  9.1820],\n",
      "        [13.6814,  7.3618,  9.2163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2170, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3766,  12.6699,  -6.5049],\n",
      "        [-10.6639,  12.6273,  -6.6401],\n",
      "        [-11.0156,  12.6936,  -6.4527],\n",
      "        [-11.1857,  12.6223,  -6.4507],\n",
      "        [-11.1702,  12.4653,  -5.9073],\n",
      "        [-11.2608,  12.4461,  -6.2104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4608,   7.7122,   9.2464, -11.3766,  12.6699,  -6.5049],\n",
      "        [ 13.0806,   7.5932,   8.8240, -10.6639,  12.6273,  -6.6401],\n",
      "        [ 13.7765,   7.5893,   9.0477, -11.0156,  12.6936,  -6.4527],\n",
      "        [ 13.2843,   7.2487,   8.8668, -11.1857,  12.6223,  -6.4507],\n",
      "        [ 13.4406,   7.4798,   9.1820, -11.1702,  12.4653,  -5.9073],\n",
      "        [ 13.6814,   7.3618,   9.2163, -11.2608,  12.4461,  -6.2104]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2953325510025024\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1203, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6421,  7.8452,  9.6115],\n",
      "        [13.8604,  7.7267,  9.4061],\n",
      "        [13.7109,  7.5455,  9.0445],\n",
      "        [13.4951,  7.2981,  8.9199],\n",
      "        [14.0151,  7.6857,  9.5351],\n",
      "        [13.7877,  7.4811,  9.3402]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1300,  12.5586,  -6.3856],\n",
      "        [-10.8977,  12.4099,  -6.2439],\n",
      "        [-10.7915,  12.3054,  -6.2386],\n",
      "        [-11.0719,  12.6388,  -6.3185],\n",
      "        [-11.0301,  12.4007,  -6.3857],\n",
      "        [-10.8399,  12.5588,  -6.6215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6421,   7.8452,   9.6115, -11.1300,  12.5586,  -6.3856],\n",
      "        [ 13.8604,   7.7267,   9.4061, -10.8977,  12.4099,  -6.2439],\n",
      "        [ 13.7109,   7.5455,   9.0445, -10.7915,  12.3054,  -6.2386],\n",
      "        [ 13.4951,   7.2981,   8.9199, -11.0719,  12.6388,  -6.3185],\n",
      "        [ 14.0151,   7.6857,   9.5351, -11.0301,  12.4007,  -6.3857],\n",
      "        [ 13.7877,   7.4811,   9.3402, -10.8399,  12.5588,  -6.6215]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.307532787322998\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4378, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5723,  7.4326,  9.3442],\n",
      "        [13.3555,  7.7466,  9.3336],\n",
      "        [13.6623,  7.3910,  9.2489],\n",
      "        [13.6023,  7.5393,  9.1764],\n",
      "        [13.5031,  7.2032,  9.6580],\n",
      "        [13.7530,  7.6703,  9.7324]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.8667, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0606,  12.5993,  -6.4914],\n",
      "        [-11.2093,  12.9909,  -6.3201],\n",
      "        [-11.3778,  12.5260,  -5.9521],\n",
      "        [-11.0651,  12.4778,  -6.2516],\n",
      "        [-11.1020,  12.8762,  -6.5525],\n",
      "        [-11.0128,  12.8805,  -6.3575]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5723,   7.4326,   9.3442, -11.0606,  12.5993,  -6.4914],\n",
      "        [ 13.3555,   7.7466,   9.3336, -11.2093,  12.9909,  -6.3201],\n",
      "        [ 13.6623,   7.3910,   9.2489, -11.3778,  12.5260,  -5.9521],\n",
      "        [ 13.6023,   7.5393,   9.1764, -11.0651,  12.4778,  -6.2516],\n",
      "        [ 13.5031,   7.2032,   9.6580, -11.1020,  12.8762,  -6.5525],\n",
      "        [ 13.7530,   7.6703,   9.7324, -11.0128,  12.8805,  -6.3575]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2930759191513062\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5474,  7.5548,  9.2188],\n",
      "        [13.3560,  7.3158,  9.2065],\n",
      "        [13.4333,  7.5905,  9.5600],\n",
      "        [13.0967,  7.1853,  8.8907],\n",
      "        [13.5654,  7.3034,  8.9953],\n",
      "        [13.6281,  7.5564,  9.1643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8224, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0635,  12.5330,  -6.1812],\n",
      "        [-10.9601,  12.5333,  -6.3867],\n",
      "        [-11.1873,  12.7126,  -6.0678],\n",
      "        [-10.9219,  12.7367,  -6.0998],\n",
      "        [-10.6513,  12.6782,  -6.1745],\n",
      "        [-10.9690,  12.6003,  -6.6341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5474,   7.5548,   9.2188, -11.0635,  12.5330,  -6.1812],\n",
      "        [ 13.3560,   7.3158,   9.2065, -10.9601,  12.5333,  -6.3867],\n",
      "        [ 13.4333,   7.5905,   9.5600, -11.1873,  12.7126,  -6.0678],\n",
      "        [ 13.0967,   7.1853,   8.8907, -10.9219,  12.7367,  -6.0998],\n",
      "        [ 13.5654,   7.3034,   8.9953, -10.6513,  12.6782,  -6.1745],\n",
      "        [ 13.6281,   7.5564,   9.1643, -10.9690,  12.6003,  -6.6341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2880018949508667\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7802, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4484,  7.4065,  9.2223],\n",
      "        [13.7509,  7.4956,  9.1351],\n",
      "        [13.5432,  7.3906,  9.3739],\n",
      "        [13.2864,  7.4637,  9.0689],\n",
      "        [13.4910,  7.2854,  9.3025],\n",
      "        [13.5805,  7.4889,  9.3317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3596,  12.3941,  -6.5273],\n",
      "        [-11.3889,  12.8667,  -6.4626],\n",
      "        [-11.3022,  12.5339,  -5.9684],\n",
      "        [-11.3735,  12.6915,  -6.3974],\n",
      "        [-11.1150,  12.4900,  -6.6197],\n",
      "        [-11.0700,  12.4986,  -6.0046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4484,   7.4065,   9.2223, -11.3596,  12.3941,  -6.5273],\n",
      "        [ 13.7509,   7.4956,   9.1351, -11.3889,  12.8667,  -6.4626],\n",
      "        [ 13.5432,   7.3906,   9.3739, -11.3022,  12.5339,  -5.9684],\n",
      "        [ 13.2864,   7.4637,   9.0689, -11.3735,  12.6915,  -6.3974],\n",
      "        [ 13.4910,   7.2854,   9.3025, -11.1150,  12.4900,  -6.6197],\n",
      "        [ 13.5805,   7.4889,   9.3317, -11.0700,  12.4986,  -6.0046]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2878364324569702\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0102, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9325,  7.8133,  9.4614],\n",
      "        [13.6237,  7.4982,  9.4241],\n",
      "        [13.5530,  7.4060,  9.1011],\n",
      "        [13.7096,  7.6738,  9.3904],\n",
      "        [13.6459,  7.6761,  9.1930],\n",
      "        [13.4995,  7.5096,  9.3221]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.1144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0539,  12.6799,  -6.2004],\n",
      "        [-11.3257,  12.7059,  -6.4509],\n",
      "        [-11.4143,  12.9466,  -6.4112],\n",
      "        [-11.0641,  12.2459,  -6.3455],\n",
      "        [-11.0226,  12.6778,  -6.6747],\n",
      "        [-11.0831,  12.5878,  -6.3185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9325,   7.8133,   9.4614, -11.0539,  12.6799,  -6.2004],\n",
      "        [ 13.6237,   7.4982,   9.4241, -11.3257,  12.7059,  -6.4509],\n",
      "        [ 13.5530,   7.4060,   9.1011, -11.4143,  12.9466,  -6.4112],\n",
      "        [ 13.7096,   7.6738,   9.3904, -11.0641,  12.2459,  -6.3455],\n",
      "        [ 13.6459,   7.6761,   9.1930, -11.0226,  12.6778,  -6.6747],\n",
      "        [ 13.4995,   7.5096,   9.3221, -11.0831,  12.5878,  -6.3185]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3163830041885376\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6432,  7.4016,  9.6641],\n",
      "        [13.6394,  7.4057,  9.0185],\n",
      "        [13.7592,  7.3700,  9.0918],\n",
      "        [13.6273,  7.2815,  9.3068],\n",
      "        [13.6788,  7.1278,  8.9779],\n",
      "        [13.6103,  7.7251,  9.5082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0292, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4225,  12.5106,  -6.4184],\n",
      "        [-11.4002,  12.9263,  -6.4933],\n",
      "        [-11.3866,  12.5356,  -6.2655],\n",
      "        [-11.2067,  12.9013,  -6.5579],\n",
      "        [-11.1517,  13.0073,  -6.4555],\n",
      "        [-11.0945,  12.7240,  -6.5040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6432,   7.4016,   9.6641, -11.4225,  12.5106,  -6.4184],\n",
      "        [ 13.6394,   7.4057,   9.0185, -11.4002,  12.9263,  -6.4933],\n",
      "        [ 13.7592,   7.3700,   9.0918, -11.3866,  12.5356,  -6.2655],\n",
      "        [ 13.6273,   7.2815,   9.3068, -11.2067,  12.9013,  -6.5579],\n",
      "        [ 13.6788,   7.1278,   8.9779, -11.1517,  13.0073,  -6.4555],\n",
      "        [ 13.6103,   7.7251,   9.5082, -11.0945,  12.7240,  -6.5040]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.310299038887024\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5099, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8056,  7.5774,  9.3702],\n",
      "        [13.5777,  7.7662,  9.2508],\n",
      "        [13.8398,  7.5372,  9.1442],\n",
      "        [13.4365,  7.4748,  9.4684],\n",
      "        [13.3343,  7.0306,  9.3960],\n",
      "        [13.6254,  7.4272,  9.4036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0040, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6835,  12.7238,  -6.5477],\n",
      "        [-11.1520,  12.7550,  -6.3055],\n",
      "        [-11.3925,  12.5518,  -6.3685],\n",
      "        [-11.3048,  12.8710,  -6.4859],\n",
      "        [-11.0903,  12.8028,  -6.2733],\n",
      "        [-10.7278,  12.8756,  -6.2512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8056,   7.5774,   9.3702, -11.6835,  12.7238,  -6.5477],\n",
      "        [ 13.5777,   7.7662,   9.2508, -11.1520,  12.7550,  -6.3055],\n",
      "        [ 13.8398,   7.5372,   9.1442, -11.3925,  12.5518,  -6.3685],\n",
      "        [ 13.4365,   7.4748,   9.4684, -11.3048,  12.8710,  -6.4859],\n",
      "        [ 13.3343,   7.0306,   9.3960, -11.0903,  12.8028,  -6.2733],\n",
      "        [ 13.6254,   7.4272,   9.4036, -10.7278,  12.8756,  -6.2512]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3207426071166992\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4639,  7.2769,  9.2052],\n",
      "        [13.5763,  7.6684,  9.2487],\n",
      "        [13.7580,  7.6961,  9.2219],\n",
      "        [13.8022,  7.5528,  9.2810],\n",
      "        [14.0547,  7.7055,  9.4377],\n",
      "        [13.6289,  7.4112,  9.2344]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.3008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-10.8881,  12.6764,  -6.2051],\n",
      "        [-11.1559,  12.7412,  -6.6594],\n",
      "        [-11.2277,  12.6283,  -6.3283],\n",
      "        [-11.4140,  12.7093,  -6.5792],\n",
      "        [-11.0554,  12.7559,  -6.5392],\n",
      "        [-11.4408,  13.1728,  -6.6598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4639,   7.2769,   9.2052, -10.8881,  12.6764,  -6.2051],\n",
      "        [ 13.5763,   7.6684,   9.2487, -11.1559,  12.7412,  -6.6594],\n",
      "        [ 13.7580,   7.6961,   9.2219, -11.2277,  12.6283,  -6.3283],\n",
      "        [ 13.8022,   7.5528,   9.2810, -11.4140,  12.7093,  -6.5792],\n",
      "        [ 14.0547,   7.7055,   9.4377, -11.0554,  12.7559,  -6.5392],\n",
      "        [ 13.6289,   7.4112,   9.2344, -11.4408,  13.1728,  -6.6598]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2844865322113037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9639,  7.7718,  9.3103],\n",
      "        [13.6382,  7.2679,  9.2508],\n",
      "        [13.5762,  7.4159,  9.0741],\n",
      "        [13.3821,  7.6882,  9.2278],\n",
      "        [13.8326,  7.5053,  9.2778],\n",
      "        [13.6859,  7.6097,  9.5062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2789, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7737,  12.8341,  -6.5096],\n",
      "        [-11.0474,  12.6128,  -6.2731],\n",
      "        [-10.5187,  12.6760,  -6.3070],\n",
      "        [-11.3091,  12.4182,  -6.4053],\n",
      "        [-11.0481,  12.9499,  -6.7347],\n",
      "        [-11.3177,  12.4006,  -6.5849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9639,   7.7718,   9.3103, -11.7737,  12.8341,  -6.5096],\n",
      "        [ 13.6382,   7.2679,   9.2508, -11.0474,  12.6128,  -6.2731],\n",
      "        [ 13.5762,   7.4159,   9.0741, -10.5187,  12.6760,  -6.3070],\n",
      "        [ 13.3821,   7.6882,   9.2278, -11.3091,  12.4182,  -6.4053],\n",
      "        [ 13.8326,   7.5053,   9.2778, -11.0481,  12.9499,  -6.7347],\n",
      "        [ 13.6859,   7.6097,   9.5062, -11.3177,  12.4006,  -6.5849]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3325395584106445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9590, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6941,  7.5063,  8.7916],\n",
      "        [13.7563,  7.1455,  9.3223],\n",
      "        [13.4416,  7.5645,  9.5086],\n",
      "        [13.5180,  7.1760,  9.1160],\n",
      "        [13.2782,  7.4731,  9.3072],\n",
      "        [13.6985,  7.4363,  9.2220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.1560, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2461,  12.7802,  -6.4371],\n",
      "        [-11.0333,  12.8204,  -6.5689],\n",
      "        [-11.2781,  12.7650,  -6.3159],\n",
      "        [-11.2009,  12.3937,  -6.4936],\n",
      "        [-11.3365,  12.8519,  -6.4771],\n",
      "        [-11.2438,  12.5098,  -6.2579]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6941,   7.5063,   8.7916, -11.2461,  12.7802,  -6.4371],\n",
      "        [ 13.7563,   7.1455,   9.3223, -11.0333,  12.8204,  -6.5689],\n",
      "        [ 13.4416,   7.5645,   9.5086, -11.2781,  12.7650,  -6.3159],\n",
      "        [ 13.5180,   7.1760,   9.1160, -11.2009,  12.3937,  -6.4936],\n",
      "        [ 13.2782,   7.4731,   9.3072, -11.3365,  12.8519,  -6.4771],\n",
      "        [ 13.6985,   7.4363,   9.2220, -11.2438,  12.5098,  -6.2579]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2961366176605225\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5174,  7.6159,  9.2404],\n",
      "        [13.9746,  7.3750,  9.2559],\n",
      "        [13.6702,  7.3687,  9.1878],\n",
      "        [13.2900,  7.3714,  9.3113],\n",
      "        [13.6348,  7.6728,  9.3639],\n",
      "        [13.6586,  7.5153,  9.0090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3117,  12.5026,  -6.1299],\n",
      "        [-11.5656,  12.5277,  -6.8835],\n",
      "        [-11.3206,  12.7941,  -6.2384],\n",
      "        [-11.0859,  12.6074,  -6.6775],\n",
      "        [-11.2829,  13.0645,  -6.5846],\n",
      "        [-11.4055,  13.2548,  -6.6450]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5174,   7.6159,   9.2404, -11.3117,  12.5026,  -6.1299],\n",
      "        [ 13.9746,   7.3750,   9.2559, -11.5656,  12.5277,  -6.8835],\n",
      "        [ 13.6702,   7.3687,   9.1878, -11.3206,  12.7941,  -6.2384],\n",
      "        [ 13.2900,   7.3714,   9.3113, -11.0859,  12.6074,  -6.6775],\n",
      "        [ 13.6348,   7.6728,   9.3639, -11.2829,  13.0645,  -6.5846],\n",
      "        [ 13.6586,   7.5153,   9.0090, -11.4055,  13.2548,  -6.6450]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2977300882339478\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7869, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5981,  7.5751,  9.3843],\n",
      "        [13.5665,  7.6674,  9.1452],\n",
      "        [13.6376,  7.5976,  9.7234],\n",
      "        [13.3464,  7.7291,  9.1460],\n",
      "        [13.8861,  8.0253,  9.2985],\n",
      "        [13.9789,  7.4569,  9.2755]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5021, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1556,  12.5809,  -6.4815],\n",
      "        [-11.4049,  13.0334,  -6.5939],\n",
      "        [-11.4334,  12.7298,  -6.4947],\n",
      "        [-11.1492,  12.8876,  -6.4321],\n",
      "        [-11.4276,  12.7314,  -6.7431],\n",
      "        [-11.5852,  13.0095,  -6.6036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5981,   7.5751,   9.3843, -11.1556,  12.5809,  -6.4815],\n",
      "        [ 13.5665,   7.6674,   9.1452, -11.4049,  13.0334,  -6.5939],\n",
      "        [ 13.6376,   7.5976,   9.7234, -11.4334,  12.7298,  -6.4947],\n",
      "        [ 13.3464,   7.7291,   9.1460, -11.1492,  12.8876,  -6.4321],\n",
      "        [ 13.8861,   8.0253,   9.2985, -11.4276,  12.7314,  -6.7431],\n",
      "        [ 13.9789,   7.4569,   9.2755, -11.5852,  13.0095,  -6.6036]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3063350915908813\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0873, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8281,  7.5139,  9.5364],\n",
      "        [13.8815,  7.6657,  9.2486],\n",
      "        [13.9710,  7.8174,  9.2545],\n",
      "        [13.3277,  7.4876,  9.5321],\n",
      "        [13.5892,  7.4617,  9.5393],\n",
      "        [13.7801,  7.3499,  9.1534]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1503,  13.0370,  -6.6185],\n",
      "        [-11.3268,  12.7757,  -6.4285],\n",
      "        [-11.1089,  12.6491,  -6.3831],\n",
      "        [-10.9582,  12.6657,  -6.4806],\n",
      "        [-11.2681,  12.5609,  -6.5527],\n",
      "        [-11.0860,  12.9091,  -6.3131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8281,   7.5139,   9.5364, -11.1503,  13.0370,  -6.6185],\n",
      "        [ 13.8815,   7.6657,   9.2486, -11.3268,  12.7757,  -6.4285],\n",
      "        [ 13.9710,   7.8174,   9.2545, -11.1089,  12.6491,  -6.3831],\n",
      "        [ 13.3277,   7.4876,   9.5321, -10.9582,  12.6657,  -6.4806],\n",
      "        [ 13.5892,   7.4617,   9.5393, -11.2681,  12.5609,  -6.5527],\n",
      "        [ 13.7801,   7.3499,   9.1534, -11.0860,  12.9091,  -6.3131]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3278058767318726\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3119,  7.2641,  9.4147],\n",
      "        [14.2248,  7.9807,  9.4671],\n",
      "        [13.7704,  7.8925,  9.1017],\n",
      "        [13.8123,  7.5866,  9.4601],\n",
      "        [13.8038,  7.7075,  8.9895],\n",
      "        [13.0774,  7.5824,  9.1840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2178, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0488,  12.7214,  -6.5485],\n",
      "        [-11.2361,  12.7616,  -6.7420],\n",
      "        [-11.4373,  12.4727,  -6.6606],\n",
      "        [-11.3344,  12.6988,  -6.5600],\n",
      "        [-11.3453,  13.2052,  -6.5326],\n",
      "        [-11.5794,  13.1280,  -6.7536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3119,   7.2641,   9.4147, -11.0488,  12.7214,  -6.5485],\n",
      "        [ 14.2248,   7.9807,   9.4671, -11.2361,  12.7616,  -6.7420],\n",
      "        [ 13.7704,   7.8925,   9.1017, -11.4373,  12.4727,  -6.6606],\n",
      "        [ 13.8123,   7.5866,   9.4601, -11.3344,  12.6988,  -6.5600],\n",
      "        [ 13.8038,   7.7075,   8.9895, -11.3453,  13.2052,  -6.5326],\n",
      "        [ 13.0774,   7.5824,   9.1840, -11.5794,  13.1280,  -6.7536]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.2951165437698364\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5142,  7.6833,  9.3189],\n",
      "        [14.0671,  7.3707,  9.4236],\n",
      "        [13.8266,  7.5413,  9.5111],\n",
      "        [13.3469,  7.4722,  9.1178],\n",
      "        [14.0168,  7.9547,  9.1671],\n",
      "        [13.2905,  7.8049,  9.2939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.8476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2827,  12.6060,  -6.6418],\n",
      "        [-10.8598,  12.8020,  -6.7763],\n",
      "        [-11.1832,  12.8759,  -6.6940],\n",
      "        [-11.2577,  12.4700,  -6.2631],\n",
      "        [-11.0963,  12.6522,  -6.7834],\n",
      "        [-11.3215,  12.8707,  -6.6335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5142,   7.6833,   9.3189, -11.2827,  12.6060,  -6.6418],\n",
      "        [ 14.0671,   7.3707,   9.4236, -10.8598,  12.8020,  -6.7763],\n",
      "        [ 13.8266,   7.5413,   9.5111, -11.1832,  12.8759,  -6.6940],\n",
      "        [ 13.3469,   7.4722,   9.1178, -11.2577,  12.4700,  -6.2631],\n",
      "        [ 14.0168,   7.9547,   9.1671, -11.0963,  12.6522,  -6.7834],\n",
      "        [ 13.2905,   7.8049,   9.2939, -11.3215,  12.8707,  -6.6335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.309323787689209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5536, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8652,  7.6426,  9.2640],\n",
      "        [13.6538,  7.5661,  9.6188],\n",
      "        [13.6633,  7.4486,  9.2659],\n",
      "        [13.6847,  7.5832,  9.3572],\n",
      "        [13.9649,  7.5225,  9.7895],\n",
      "        [13.7636,  7.5393,  9.5287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4008,  13.2178,  -6.7190],\n",
      "        [-11.1346,  13.1624,  -6.5280],\n",
      "        [-11.0592,  12.8922,  -6.3496],\n",
      "        [-11.5140,  13.0164,  -6.4765],\n",
      "        [-11.2036,  12.6288,  -6.5285],\n",
      "        [-10.9857,  12.4796,  -6.1269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8652,   7.6426,   9.2640, -11.4008,  13.2178,  -6.7190],\n",
      "        [ 13.6538,   7.5661,   9.6188, -11.1346,  13.1624,  -6.5280],\n",
      "        [ 13.6633,   7.4486,   9.2659, -11.0592,  12.8922,  -6.3496],\n",
      "        [ 13.6847,   7.5832,   9.3572, -11.5140,  13.0164,  -6.4765],\n",
      "        [ 13.9649,   7.5225,   9.7895, -11.2036,  12.6288,  -6.5285],\n",
      "        [ 13.7636,   7.5393,   9.5287, -10.9857,  12.4796,  -6.1269]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3343204259872437\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6381,  7.7352,  9.0903],\n",
      "        [13.8696,  7.7652,  9.3146],\n",
      "        [13.5642,  7.5036,  9.1964],\n",
      "        [13.4941,  7.5213,  9.4205],\n",
      "        [13.6355,  7.2882,  8.9857],\n",
      "        [13.7524,  7.8497,  9.2769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9598, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4922,  12.4450,  -6.6872],\n",
      "        [-11.4178,  12.8402,  -6.5457],\n",
      "        [-11.0125,  12.7359,  -6.6695],\n",
      "        [-11.2695,  13.0643,  -7.0222],\n",
      "        [-11.2631,  13.0714,  -6.6079],\n",
      "        [-11.1249,  12.6145,  -6.3068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6381,   7.7352,   9.0903, -11.4922,  12.4450,  -6.6872],\n",
      "        [ 13.8696,   7.7652,   9.3146, -11.4178,  12.8402,  -6.5457],\n",
      "        [ 13.5642,   7.5036,   9.1964, -11.0125,  12.7359,  -6.6695],\n",
      "        [ 13.4941,   7.5213,   9.4205, -11.2695,  13.0643,  -7.0222],\n",
      "        [ 13.6355,   7.2882,   8.9857, -11.2631,  13.0714,  -6.6079],\n",
      "        [ 13.7524,   7.8497,   9.2769, -11.1249,  12.6145,  -6.3068]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.310849905014038\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5564,  7.5724,  9.4111],\n",
      "        [13.7663,  7.5362,  9.3888],\n",
      "        [13.9219,  7.8774,  9.6774],\n",
      "        [14.1026,  7.2681,  9.1543],\n",
      "        [13.8575,  7.4776,  9.5699],\n",
      "        [13.6355,  7.9575,  9.4959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.0946,  12.6028,  -6.4205],\n",
      "        [-11.3161,  13.0941,  -6.5071],\n",
      "        [-11.6310,  13.1829,  -6.5026],\n",
      "        [-11.3125,  12.7390,  -6.2148],\n",
      "        [-11.1637,  12.6154,  -6.3527],\n",
      "        [-11.2534,  12.8459,  -6.6122]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5564,   7.5724,   9.4111, -11.0946,  12.6028,  -6.4205],\n",
      "        [ 13.7663,   7.5362,   9.3888, -11.3161,  13.0941,  -6.5071],\n",
      "        [ 13.9219,   7.8774,   9.6774, -11.6310,  13.1829,  -6.5026],\n",
      "        [ 14.1026,   7.2681,   9.1543, -11.3125,  12.7390,  -6.2148],\n",
      "        [ 13.8575,   7.4776,   9.5699, -11.1637,  12.6154,  -6.3527],\n",
      "        [ 13.6355,   7.9575,   9.4959, -11.2534,  12.8459,  -6.6122]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3092925548553467\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9409,  7.8020,  9.6391],\n",
      "        [13.9624,  7.6762,  9.2730],\n",
      "        [13.4706,  7.5084,  9.0218],\n",
      "        [13.6862,  7.6497,  9.0875],\n",
      "        [14.0531,  7.8636,  9.5303],\n",
      "        [13.7758,  7.8244,  9.3631]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1708,  12.5769,  -6.6853],\n",
      "        [-11.0458,  12.7973,  -7.0209],\n",
      "        [-11.3739,  12.7486,  -6.6723],\n",
      "        [-11.4549,  12.6865,  -6.3295],\n",
      "        [-11.3626,  12.8512,  -6.7492],\n",
      "        [-11.1891,  12.4462,  -6.3181]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9409,   7.8020,   9.6391, -11.1708,  12.5769,  -6.6853],\n",
      "        [ 13.9624,   7.6762,   9.2730, -11.0458,  12.7973,  -7.0209],\n",
      "        [ 13.4706,   7.5084,   9.0218, -11.3739,  12.7486,  -6.6723],\n",
      "        [ 13.6862,   7.6497,   9.0875, -11.4549,  12.6865,  -6.3295],\n",
      "        [ 14.0531,   7.8636,   9.5303, -11.3626,  12.8512,  -6.7492],\n",
      "        [ 13.7758,   7.8244,   9.3631, -11.1891,  12.4462,  -6.3181]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3363558053970337\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6109, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.5651,  7.4133,  9.5424],\n",
      "        [14.0525,  7.5751,  9.2919],\n",
      "        [14.0858,  7.7224,  9.2710],\n",
      "        [14.0750,  7.7504,  9.4615],\n",
      "        [14.0399,  7.8778,  9.6940],\n",
      "        [13.8737,  7.4868,  9.2611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3886,  12.7398,  -6.5924],\n",
      "        [-11.5175,  12.8758,  -6.4667],\n",
      "        [-11.3247,  12.9835,  -6.6196],\n",
      "        [-11.5607,  12.7040,  -6.5384],\n",
      "        [-11.3276,  12.8881,  -6.9478],\n",
      "        [-11.3619,  12.9329,  -6.3564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.5651,   7.4133,   9.5424, -11.3886,  12.7398,  -6.5924],\n",
      "        [ 14.0525,   7.5751,   9.2919, -11.5175,  12.8758,  -6.4667],\n",
      "        [ 14.0858,   7.7224,   9.2710, -11.3247,  12.9835,  -6.6196],\n",
      "        [ 14.0750,   7.7504,   9.4615, -11.5607,  12.7040,  -6.5384],\n",
      "        [ 14.0399,   7.8778,   9.6940, -11.3276,  12.8881,  -6.9478],\n",
      "        [ 13.8737,   7.4868,   9.2611, -11.3619,  12.9329,  -6.3564]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.320770502090454\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.4034,  7.8664,  9.2062],\n",
      "        [13.7204,  7.6691,  9.1881],\n",
      "        [13.8454,  7.6237,  9.4581],\n",
      "        [13.7560,  7.4388,  9.6347],\n",
      "        [13.7812,  7.7263,  9.4303],\n",
      "        [13.5393,  7.9005,  9.2819]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3656,  12.2340,  -6.7287],\n",
      "        [-11.4862,  12.8250,  -6.8646],\n",
      "        [-11.5450,  12.8653,  -6.6208],\n",
      "        [-11.2417,  12.5540,  -6.8085],\n",
      "        [-11.4391,  12.8574,  -6.9092],\n",
      "        [-11.3327,  12.5829,  -6.6031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.4034,   7.8664,   9.2062, -11.3656,  12.2340,  -6.7287],\n",
      "        [ 13.7204,   7.6691,   9.1881, -11.4862,  12.8250,  -6.8646],\n",
      "        [ 13.8454,   7.6237,   9.4581, -11.5450,  12.8653,  -6.6208],\n",
      "        [ 13.7560,   7.4388,   9.6347, -11.2417,  12.5540,  -6.8085],\n",
      "        [ 13.7812,   7.7263,   9.4303, -11.4391,  12.8574,  -6.9092],\n",
      "        [ 13.5393,   7.9005,   9.2819, -11.3327,  12.5829,  -6.6031]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3051584959030151\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8793,  7.6856,  9.4946],\n",
      "        [13.6362,  7.8201,  9.3340],\n",
      "        [13.5573,  7.6195,  9.2616],\n",
      "        [13.6078,  7.2949,  8.9656],\n",
      "        [13.6545,  7.6193,  9.6649],\n",
      "        [13.9588,  7.7557,  9.8958]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4215,  12.5637,  -6.5326],\n",
      "        [-11.3858,  12.4447,  -6.8200],\n",
      "        [-10.8537,  12.8146,  -6.6484],\n",
      "        [-11.3160,  13.1265,  -6.3819],\n",
      "        [-11.2097,  12.6094,  -6.7337],\n",
      "        [-11.1115,  13.1326,  -6.5825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8793,   7.6856,   9.4946, -11.4215,  12.5637,  -6.5326],\n",
      "        [ 13.6362,   7.8201,   9.3340, -11.3858,  12.4447,  -6.8200],\n",
      "        [ 13.5573,   7.6195,   9.2616, -10.8537,  12.8146,  -6.6484],\n",
      "        [ 13.6078,   7.2949,   8.9656, -11.3160,  13.1265,  -6.3819],\n",
      "        [ 13.6545,   7.6193,   9.6649, -11.2097,  12.6094,  -6.7337],\n",
      "        [ 13.9588,   7.7557,   9.8958, -11.1115,  13.1326,  -6.5825]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3334705829620361\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9505, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8234,  7.5519,  9.4725],\n",
      "        [13.8600,  7.9603,  9.5594],\n",
      "        [13.8753,  7.7351,  9.4872],\n",
      "        [13.8063,  7.3262,  9.3548],\n",
      "        [13.8818,  7.7115,  9.4553],\n",
      "        [13.2793,  7.8104,  9.2196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.3916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3663,  13.0230,  -6.6886],\n",
      "        [-11.3516,  12.9693,  -6.5856],\n",
      "        [-11.6141,  13.0896,  -6.4788],\n",
      "        [-11.6734,  12.8411,  -7.0052],\n",
      "        [-11.4033,  12.7613,  -6.4632],\n",
      "        [-11.2744,  12.9826,  -6.3644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8234,   7.5519,   9.4725, -11.3663,  13.0230,  -6.6886],\n",
      "        [ 13.8600,   7.9603,   9.5594, -11.3516,  12.9693,  -6.5856],\n",
      "        [ 13.8753,   7.7351,   9.4872, -11.6141,  13.0896,  -6.4788],\n",
      "        [ 13.8063,   7.3262,   9.3548, -11.6734,  12.8411,  -7.0052],\n",
      "        [ 13.8818,   7.7115,   9.4553, -11.4033,  12.7613,  -6.4632],\n",
      "        [ 13.2793,   7.8104,   9.2196, -11.2744,  12.9826,  -6.3644]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3383879661560059\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7283, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.3674,  7.1786,  9.2704],\n",
      "        [13.7921,  7.6997,  9.3937],\n",
      "        [13.9383,  7.6554,  9.4956],\n",
      "        [13.8682,  7.4572,  9.5507],\n",
      "        [13.5094,  7.5681,  9.3680],\n",
      "        [13.8573,  7.7112,  9.5834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6786, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3766,  12.8571,  -6.9508],\n",
      "        [-11.4931,  13.1473,  -6.8288],\n",
      "        [-11.5284,  13.0568,  -6.6157],\n",
      "        [-11.5606,  12.9662,  -6.5582],\n",
      "        [-11.4699,  12.7749,  -6.7755],\n",
      "        [-11.5255,  13.2281,  -6.8273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.3674,   7.1786,   9.2704, -11.3766,  12.8571,  -6.9508],\n",
      "        [ 13.7921,   7.6997,   9.3937, -11.4931,  13.1473,  -6.8288],\n",
      "        [ 13.9383,   7.6554,   9.4956, -11.5284,  13.0568,  -6.6157],\n",
      "        [ 13.8682,   7.4572,   9.5507, -11.5606,  12.9662,  -6.5582],\n",
      "        [ 13.5094,   7.5681,   9.3680, -11.4699,  12.7749,  -6.7755],\n",
      "        [ 13.8573,   7.7112,   9.5834, -11.5255,  13.2281,  -6.8273]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3108140230178833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6591,  7.5716,  9.2470],\n",
      "        [13.8927,  7.8670,  9.3476],\n",
      "        [13.9456,  7.9832,  9.5964],\n",
      "        [13.9059,  7.8950,  9.3089],\n",
      "        [13.8637,  7.6690,  9.4056],\n",
      "        [13.9471,  7.5957,  9.1899]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3399,  13.0431,  -6.9714],\n",
      "        [-11.4190,  12.5969,  -6.5462],\n",
      "        [-11.2550,  12.8252,  -6.8439],\n",
      "        [-11.1942,  12.5527,  -6.5203],\n",
      "        [-11.3889,  12.4090,  -6.3409],\n",
      "        [-11.5117,  13.1722,  -6.6385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6591,   7.5716,   9.2470, -11.3399,  13.0431,  -6.9714],\n",
      "        [ 13.8927,   7.8670,   9.3476, -11.4190,  12.5969,  -6.5462],\n",
      "        [ 13.9456,   7.9832,   9.5964, -11.2550,  12.8252,  -6.8439],\n",
      "        [ 13.9059,   7.8950,   9.3089, -11.1942,  12.5527,  -6.5203],\n",
      "        [ 13.8637,   7.6690,   9.4056, -11.3889,  12.4090,  -6.3409],\n",
      "        [ 13.9471,   7.5957,   9.1899, -11.5117,  13.1722,  -6.6385]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3305561542510986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9731,  7.9502,  9.5026],\n",
      "        [13.7247,  7.7246,  9.4584],\n",
      "        [13.9161,  7.8029,  9.3940],\n",
      "        [14.0260,  7.8290,  9.2767],\n",
      "        [14.0459,  7.6331,  9.5432],\n",
      "        [13.6567,  8.1080,  9.3938]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3532, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.5870,  12.5374,  -6.8871],\n",
      "        [-11.4466,  13.0058,  -6.6003],\n",
      "        [-11.5449,  12.9776,  -6.6054],\n",
      "        [-11.6356,  12.8575,  -6.9269],\n",
      "        [-11.6593,  12.9896,  -6.6617],\n",
      "        [-11.4978,  13.0287,  -7.1083]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9731,   7.9502,   9.5026, -11.5870,  12.5374,  -6.8871],\n",
      "        [ 13.7247,   7.7246,   9.4584, -11.4466,  13.0058,  -6.6003],\n",
      "        [ 13.9161,   7.8029,   9.3940, -11.5449,  12.9776,  -6.6054],\n",
      "        [ 14.0260,   7.8290,   9.2767, -11.6356,  12.8575,  -6.9269],\n",
      "        [ 14.0459,   7.6331,   9.5432, -11.6593,  12.9896,  -6.6617],\n",
      "        [ 13.6567,   8.1080,   9.3938, -11.4978,  13.0287,  -7.1083]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3493428230285645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7215,  7.9456,  9.4544],\n",
      "        [14.1086,  7.7486,  9.6411],\n",
      "        [13.5987,  7.6253,  9.1780],\n",
      "        [13.9720,  8.1649,  9.5575],\n",
      "        [14.2053,  7.9500,  9.5308],\n",
      "        [14.1215,  7.6603,  9.5813]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6954,  13.0277,  -6.7389],\n",
      "        [-11.7309,  13.0338,  -6.4650],\n",
      "        [-11.5350,  12.8842,  -6.7901],\n",
      "        [-11.3604,  12.8523,  -6.6571],\n",
      "        [-11.4211,  13.4443,  -6.8763],\n",
      "        [-11.5065,  12.8700,  -6.9992]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7215,   7.9456,   9.4544, -11.6954,  13.0277,  -6.7389],\n",
      "        [ 14.1086,   7.7486,   9.6411, -11.7309,  13.0338,  -6.4650],\n",
      "        [ 13.5987,   7.6253,   9.1780, -11.5350,  12.8842,  -6.7901],\n",
      "        [ 13.9720,   8.1649,   9.5575, -11.3604,  12.8523,  -6.6571],\n",
      "        [ 14.2053,   7.9500,   9.5308, -11.4211,  13.4443,  -6.8763],\n",
      "        [ 14.1215,   7.6603,   9.5813, -11.5065,  12.8700,  -6.9992]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.349212408065796\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9598,  7.9514,  8.9821],\n",
      "        [13.5399,  7.6862,  9.5506],\n",
      "        [13.7242,  7.3887,  9.5807],\n",
      "        [14.2744,  7.9876,  9.5833],\n",
      "        [14.0230,  7.3412,  9.5004],\n",
      "        [13.7586,  7.5219,  9.4352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.1015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1533,  12.8718,  -6.7265],\n",
      "        [-11.2971,  12.5224,  -6.1939],\n",
      "        [-11.3901,  12.5548,  -6.6294],\n",
      "        [-11.2395,  12.5117,  -6.6470],\n",
      "        [-11.4678,  13.0741,  -6.5002],\n",
      "        [-10.9859,  12.6441,  -6.7401]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9598,   7.9514,   8.9821, -11.1533,  12.8718,  -6.7265],\n",
      "        [ 13.5399,   7.6862,   9.5506, -11.2971,  12.5224,  -6.1939],\n",
      "        [ 13.7242,   7.3887,   9.5807, -11.3901,  12.5548,  -6.6294],\n",
      "        [ 14.2744,   7.9876,   9.5833, -11.2395,  12.5117,  -6.6470],\n",
      "        [ 14.0230,   7.3412,   9.5004, -11.4678,  13.0741,  -6.5002],\n",
      "        [ 13.7586,   7.5219,   9.4352, -10.9859,  12.6441,  -6.7401]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3346091508865356\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4274, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9122,  7.6741,  9.5649],\n",
      "        [13.6474,  7.8674,  9.5488],\n",
      "        [13.9667,  7.8423,  9.4843],\n",
      "        [13.7600,  7.9602,  9.7027],\n",
      "        [13.8244,  7.6913,  9.1948],\n",
      "        [13.7161,  7.5352,  9.5868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4658, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1859,  13.0501,  -6.4962],\n",
      "        [-11.5783,  13.0591,  -6.8109],\n",
      "        [-11.1653,  12.7383,  -6.8717],\n",
      "        [-11.3781,  12.8371,  -6.9835],\n",
      "        [-11.3089,  13.0234,  -6.6309],\n",
      "        [-11.2707,  12.8060,  -6.2609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9122,   7.6741,   9.5649, -11.1859,  13.0501,  -6.4962],\n",
      "        [ 13.6474,   7.8674,   9.5488, -11.5783,  13.0591,  -6.8109],\n",
      "        [ 13.9667,   7.8423,   9.4843, -11.1653,  12.7383,  -6.8717],\n",
      "        [ 13.7600,   7.9602,   9.7027, -11.3781,  12.8371,  -6.9835],\n",
      "        [ 13.8244,   7.6913,   9.1948, -11.3089,  13.0234,  -6.6309],\n",
      "        [ 13.7161,   7.5352,   9.5868, -11.2707,  12.8060,  -6.2609]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3469642400741577\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8257,  7.5964,  9.3625],\n",
      "        [13.6602,  7.5823,  9.0277],\n",
      "        [13.5553,  7.1734,  9.4880],\n",
      "        [13.7259,  7.8270,  9.1624],\n",
      "        [14.0380,  7.8114,  9.7294],\n",
      "        [13.9086,  7.7454,  9.4685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8354,  13.1535,  -6.9278],\n",
      "        [-11.5148,  12.7283,  -6.6012],\n",
      "        [-11.2191,  13.1777,  -6.6524],\n",
      "        [-11.4408,  12.6056,  -6.3755],\n",
      "        [-11.4608,  12.7926,  -6.9411],\n",
      "        [-11.2451,  12.6574,  -6.5975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8257,   7.5964,   9.3625, -11.8354,  13.1535,  -6.9278],\n",
      "        [ 13.6602,   7.5823,   9.0277, -11.5148,  12.7283,  -6.6012],\n",
      "        [ 13.5553,   7.1734,   9.4880, -11.2191,  13.1777,  -6.6524],\n",
      "        [ 13.7259,   7.8270,   9.1624, -11.4408,  12.6056,  -6.3755],\n",
      "        [ 14.0380,   7.8114,   9.7294, -11.4608,  12.7926,  -6.9411],\n",
      "        [ 13.9086,   7.7454,   9.4685, -11.2451,  12.6574,  -6.5975]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3537119626998901\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.1116, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8773,  7.7842,  9.5619],\n",
      "        [13.9628,  7.5049,  9.5354],\n",
      "        [13.8733,  7.6988,  9.3856],\n",
      "        [14.1800,  7.7800,  9.6860],\n",
      "        [13.9840,  7.9386,  9.9036],\n",
      "        [14.4542,  7.8674,  9.5230]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.3478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.5057,  12.9971,  -6.8050],\n",
      "        [-11.5301,  12.7407,  -6.5806],\n",
      "        [-11.1306,  12.6072,  -6.6428],\n",
      "        [-11.1535,  12.7671,  -6.7018],\n",
      "        [-11.4359,  13.0878,  -6.6418],\n",
      "        [-11.2512,  12.8180,  -6.2891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8773,   7.7842,   9.5619, -11.5057,  12.9971,  -6.8050],\n",
      "        [ 13.9628,   7.5049,   9.5354, -11.5301,  12.7407,  -6.5806],\n",
      "        [ 13.8733,   7.6988,   9.3856, -11.1306,  12.6072,  -6.6428],\n",
      "        [ 14.1800,   7.7800,   9.6860, -11.1535,  12.7671,  -6.7018],\n",
      "        [ 13.9840,   7.9386,   9.9036, -11.4359,  13.0878,  -6.6418],\n",
      "        [ 14.4542,   7.8674,   9.5230, -11.2512,  12.8180,  -6.2891]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3555312156677246\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.0376,  7.9224,  9.2393],\n",
      "        [13.9647,  7.7473,  9.8362],\n",
      "        [14.0666,  7.7301,  9.3766],\n",
      "        [13.9579,  8.2109,  9.6007],\n",
      "        [13.6918,  7.4015,  9.5364],\n",
      "        [14.1946,  8.0599,  9.5306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2965, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3418,  12.6565,  -6.5778],\n",
      "        [-11.3914,  12.7811,  -6.4450],\n",
      "        [-11.2591,  12.8025,  -6.4443],\n",
      "        [-11.5452,  12.8976,  -6.8236],\n",
      "        [-11.2228,  12.6696,  -6.7195],\n",
      "        [-11.3207,  12.6774,  -6.8733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.0376,   7.9224,   9.2393, -11.3418,  12.6565,  -6.5778],\n",
      "        [ 13.9647,   7.7473,   9.8362, -11.3914,  12.7811,  -6.4450],\n",
      "        [ 14.0666,   7.7301,   9.3766, -11.2591,  12.8025,  -6.4443],\n",
      "        [ 13.9579,   8.2109,   9.6007, -11.5452,  12.8976,  -6.8236],\n",
      "        [ 13.6918,   7.4015,   9.5364, -11.2228,  12.6696,  -6.7195],\n",
      "        [ 14.1946,   8.0599,   9.5306, -11.3207,  12.6774,  -6.8733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3449807167053223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2139, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9717,  7.8634,  9.5319],\n",
      "        [13.6981,  7.4648,  9.5392],\n",
      "        [13.7559,  7.4479,  9.1997],\n",
      "        [13.6952,  7.8148,  9.7418],\n",
      "        [13.8123,  7.4068,  9.2835],\n",
      "        [13.8483,  7.8868,  9.5347]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.5769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3582,  13.0791,  -6.9635],\n",
      "        [-11.6296,  13.0347,  -6.5311],\n",
      "        [-11.3131,  12.9160,  -6.7451],\n",
      "        [-11.5433,  13.1840,  -6.8694],\n",
      "        [-11.5251,  13.0833,  -6.6019],\n",
      "        [-11.4067,  13.0536,  -6.6978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9717,   7.8634,   9.5319, -11.3582,  13.0791,  -6.9635],\n",
      "        [ 13.6981,   7.4648,   9.5392, -11.6296,  13.0347,  -6.5311],\n",
      "        [ 13.7559,   7.4479,   9.1997, -11.3131,  12.9160,  -6.7451],\n",
      "        [ 13.6952,   7.8148,   9.7418, -11.5433,  13.1840,  -6.8694],\n",
      "        [ 13.8123,   7.4068,   9.2835, -11.5251,  13.0833,  -6.6019],\n",
      "        [ 13.8483,   7.8868,   9.5347, -11.4067,  13.0536,  -6.6978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3614777326583862\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7737, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6740,  7.9810,  9.6397],\n",
      "        [13.9857,  7.9453,  9.4934],\n",
      "        [13.9995,  7.7996,  9.4133],\n",
      "        [13.4433,  7.7679,  9.5908],\n",
      "        [13.9401,  7.8772,  9.4089],\n",
      "        [13.4332,  7.6478,  9.7292]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6767, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3507,  12.4923,  -7.0006],\n",
      "        [-11.2038,  13.2146,  -6.6536],\n",
      "        [-11.2329,  13.1187,  -6.4430],\n",
      "        [-11.3780,  13.0147,  -6.9833],\n",
      "        [-11.2523,  12.5234,  -6.7015],\n",
      "        [-11.5497,  13.3319,  -6.9330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6740,   7.9810,   9.6397, -11.3507,  12.4923,  -7.0006],\n",
      "        [ 13.9857,   7.9453,   9.4934, -11.2038,  13.2146,  -6.6536],\n",
      "        [ 13.9995,   7.7996,   9.4133, -11.2329,  13.1187,  -6.4430],\n",
      "        [ 13.4433,   7.7679,   9.5908, -11.3780,  13.0147,  -6.9833],\n",
      "        [ 13.9401,   7.8772,   9.4089, -11.2523,  12.5234,  -6.7015],\n",
      "        [ 13.4332,   7.6478,   9.7292, -11.5497,  13.3319,  -6.9330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.34556245803833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7626,  7.8745,  9.6173],\n",
      "        [14.0169,  7.7434,  9.6077],\n",
      "        [13.6927,  7.9120,  9.5603],\n",
      "        [13.7098,  7.8182,  9.6343],\n",
      "        [13.6202,  8.0719,  9.7504],\n",
      "        [14.3141,  7.9872,  9.4381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3711, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.3458,  12.7841,  -6.7683],\n",
      "        [-11.3149,  12.8894,  -7.0461],\n",
      "        [-11.4689,  12.9674,  -6.7005],\n",
      "        [-11.4049,  13.2538,  -7.0105],\n",
      "        [-11.3675,  12.8092,  -6.6169],\n",
      "        [-11.5952,  13.3319,  -6.7746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7626,   7.8745,   9.6173, -11.3458,  12.7841,  -6.7683],\n",
      "        [ 14.0169,   7.7434,   9.6077, -11.3149,  12.8894,  -7.0461],\n",
      "        [ 13.6927,   7.9120,   9.5603, -11.4689,  12.9674,  -6.7005],\n",
      "        [ 13.7098,   7.8182,   9.6343, -11.4049,  13.2538,  -7.0105],\n",
      "        [ 13.6202,   8.0719,   9.7504, -11.3675,  12.8092,  -6.6169],\n",
      "        [ 14.3141,   7.9872,   9.4381, -11.5952,  13.3319,  -6.7746]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3507839441299438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9411, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8548,  7.7170,  9.4398],\n",
      "        [13.9385,  8.0939,  9.7649],\n",
      "        [14.3000,  7.7387,  9.6015],\n",
      "        [13.7521,  8.0361,  9.7404],\n",
      "        [13.9661,  7.3964,  9.2718],\n",
      "        [13.6425,  8.0704,  9.3868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4837,  13.1186,  -6.5018],\n",
      "        [-11.5538,  13.1457,  -6.7805],\n",
      "        [-11.5417,  12.8541,  -6.8951],\n",
      "        [-11.5438,  13.2369,  -6.7198],\n",
      "        [-11.5629,  13.1617,  -6.5950],\n",
      "        [-11.4895,  13.0900,  -7.0020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8548,   7.7170,   9.4398, -11.4837,  13.1186,  -6.5018],\n",
      "        [ 13.9385,   8.0939,   9.7649, -11.5538,  13.1457,  -6.7805],\n",
      "        [ 14.3000,   7.7387,   9.6015, -11.5417,  12.8541,  -6.8951],\n",
      "        [ 13.7521,   8.0361,   9.7404, -11.5438,  13.2369,  -6.7198],\n",
      "        [ 13.9661,   7.3964,   9.2718, -11.5629,  13.1617,  -6.5950],\n",
      "        [ 13.6425,   8.0704,   9.3868, -11.4895,  13.0900,  -7.0020]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3539737462997437\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0485, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4519,  7.7511,  9.9472],\n",
      "        [13.9653,  8.0659,  9.5427],\n",
      "        [13.6171,  7.6562,  9.2837],\n",
      "        [14.1752,  7.7707,  9.8046],\n",
      "        [13.9343,  7.7984,  9.6012],\n",
      "        [13.7413,  7.8455,  9.6832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7267,  12.8224,  -6.5761],\n",
      "        [-11.3016,  12.6561,  -6.5905],\n",
      "        [-11.6221,  12.6205,  -6.4752],\n",
      "        [-11.5049,  12.7513,  -6.8035],\n",
      "        [-11.7040,  13.0824,  -6.7557],\n",
      "        [-11.5820,  13.1727,  -7.0764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4519,   7.7511,   9.9472, -11.7267,  12.8224,  -6.5761],\n",
      "        [ 13.9653,   8.0659,   9.5427, -11.3016,  12.6561,  -6.5905],\n",
      "        [ 13.6171,   7.6562,   9.2837, -11.6221,  12.6205,  -6.4752],\n",
      "        [ 14.1752,   7.7707,   9.8046, -11.5049,  12.7513,  -6.8035],\n",
      "        [ 13.9343,   7.7984,   9.6012, -11.7040,  13.0824,  -6.7557],\n",
      "        [ 13.7413,   7.8455,   9.6832, -11.5820,  13.1727,  -7.0764]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3896727561950684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9940, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7246,  7.7925,  9.1409],\n",
      "        [13.6977,  8.0224,  9.6451],\n",
      "        [13.8856,  7.6780,  9.7457],\n",
      "        [13.7925,  7.7864,  9.3178],\n",
      "        [13.8964,  7.7841,  9.3528],\n",
      "        [13.7781,  7.9078,  9.4512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6198,  13.0227,  -6.9853],\n",
      "        [-11.7017,  13.3114,  -7.0272],\n",
      "        [-11.5473,  13.1162,  -6.8947],\n",
      "        [-11.3522,  13.3157,  -7.0110],\n",
      "        [-11.6418,  13.3378,  -6.8321],\n",
      "        [-11.5630,  12.9940,  -7.1482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7246,   7.7925,   9.1409, -11.6198,  13.0227,  -6.9853],\n",
      "        [ 13.6977,   8.0224,   9.6451, -11.7017,  13.3114,  -7.0272],\n",
      "        [ 13.8856,   7.6780,   9.7457, -11.5473,  13.1162,  -6.8947],\n",
      "        [ 13.7925,   7.7864,   9.3178, -11.3522,  13.3157,  -7.0110],\n",
      "        [ 13.8964,   7.7841,   9.3528, -11.6418,  13.3378,  -6.8321],\n",
      "        [ 13.7781,   7.9078,   9.4512, -11.5630,  12.9940,  -7.1482]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3483715057373047\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7160, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8562,  8.2956,  9.7121],\n",
      "        [13.9671,  7.9426,  9.6407],\n",
      "        [13.7209,  7.5773,  9.2481],\n",
      "        [13.4994,  7.8285,  9.5405],\n",
      "        [13.9548,  7.8969,  9.6378],\n",
      "        [14.0407,  8.0429,  9.6603]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6749,  12.9096,  -6.4890],\n",
      "        [-11.5109,  13.1905,  -6.5962],\n",
      "        [-11.5700,  13.2962,  -6.8708],\n",
      "        [-11.4394,  12.7488,  -6.7825],\n",
      "        [-11.8594,  13.0399,  -6.8421],\n",
      "        [-11.3676,  13.1461,  -6.9046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8562,   8.2956,   9.7121, -11.6749,  12.9096,  -6.4890],\n",
      "        [ 13.9671,   7.9426,   9.6407, -11.5109,  13.1905,  -6.5962],\n",
      "        [ 13.7209,   7.5773,   9.2481, -11.5700,  13.2962,  -6.8708],\n",
      "        [ 13.4994,   7.8285,   9.5405, -11.4394,  12.7488,  -6.7825],\n",
      "        [ 13.9548,   7.8969,   9.6378, -11.8594,  13.0399,  -6.8421],\n",
      "        [ 14.0407,   8.0429,   9.6603, -11.3676,  13.1461,  -6.9046]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3718451261520386\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8486,  7.8724,  9.2968],\n",
      "        [14.1903,  7.5903,  9.5207],\n",
      "        [14.1143,  7.8786,  9.6431],\n",
      "        [13.8224,  7.8369,  9.5663],\n",
      "        [14.2226,  7.8191,  9.5227],\n",
      "        [14.2087,  7.7885,  9.2890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4317, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4399,  13.0190,  -6.8634],\n",
      "        [-11.2190,  12.8570,  -6.6127],\n",
      "        [-11.5087,  12.7709,  -6.8461],\n",
      "        [-11.3401,  13.0297,  -6.6229],\n",
      "        [-11.8102,  12.8827,  -7.0816],\n",
      "        [-11.4004,  13.3130,  -7.0894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8486,   7.8724,   9.2968, -11.4399,  13.0190,  -6.8634],\n",
      "        [ 14.1903,   7.5903,   9.5207, -11.2190,  12.8570,  -6.6127],\n",
      "        [ 14.1143,   7.8786,   9.6431, -11.5087,  12.7709,  -6.8461],\n",
      "        [ 13.8224,   7.8369,   9.5663, -11.3401,  13.0297,  -6.6229],\n",
      "        [ 14.2226,   7.8191,   9.5227, -11.8102,  12.8827,  -7.0816],\n",
      "        [ 14.2087,   7.7885,   9.2890, -11.4004,  13.3130,  -7.0894]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3560148477554321\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2137,  8.0012,  9.5691],\n",
      "        [14.0004,  7.8968,  9.7197],\n",
      "        [14.1727,  7.9995,  9.5220],\n",
      "        [14.2361,  7.7978,  9.2726],\n",
      "        [13.7627,  7.8133,  9.2602],\n",
      "        [14.0233,  7.7556,  9.8570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6465,  13.3436,  -6.6198],\n",
      "        [-11.2988,  12.8276,  -6.7003],\n",
      "        [-11.3746,  12.7468,  -6.8569],\n",
      "        [-11.3404,  13.0473,  -6.8198],\n",
      "        [-11.4976,  13.0762,  -7.0046],\n",
      "        [-11.6618,  12.9022,  -6.8724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2137,   8.0012,   9.5691, -11.6465,  13.3436,  -6.6198],\n",
      "        [ 14.0004,   7.8968,   9.7197, -11.2988,  12.8276,  -6.7003],\n",
      "        [ 14.1727,   7.9995,   9.5220, -11.3746,  12.7468,  -6.8569],\n",
      "        [ 14.2361,   7.7978,   9.2726, -11.3404,  13.0473,  -6.8198],\n",
      "        [ 13.7627,   7.8133,   9.2602, -11.4976,  13.0762,  -7.0046],\n",
      "        [ 14.0233,   7.7556,   9.8570, -11.6618,  12.9022,  -6.8724]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3867769241333008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8543, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.6463,  7.8450,  9.3318],\n",
      "        [14.4417,  8.2459,  9.8598],\n",
      "        [13.6208,  7.7063,  9.4605],\n",
      "        [13.8627,  7.9005,  9.8007],\n",
      "        [13.6289,  7.9812,  9.3979],\n",
      "        [14.1189,  8.1242,  9.4266]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4751, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2295,  13.1570,  -6.6784],\n",
      "        [-11.5029,  12.9332,  -6.8334],\n",
      "        [-11.2537,  12.9440,  -7.0094],\n",
      "        [-11.4503,  12.9079,  -6.8655],\n",
      "        [-11.2969,  12.7266,  -6.8879],\n",
      "        [-11.5155,  13.4430,  -6.9216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.6463,   7.8450,   9.3318, -11.2295,  13.1570,  -6.6784],\n",
      "        [ 14.4417,   8.2459,   9.8598, -11.5029,  12.9332,  -6.8334],\n",
      "        [ 13.6208,   7.7063,   9.4605, -11.2537,  12.9440,  -7.0094],\n",
      "        [ 13.8627,   7.9005,   9.8007, -11.4503,  12.9079,  -6.8655],\n",
      "        [ 13.6289,   7.9812,   9.3979, -11.2969,  12.7266,  -6.8879],\n",
      "        [ 14.1189,   8.1242,   9.4266, -11.5155,  13.4430,  -6.9216]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3484723567962646\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6737, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1177,  8.0184,  9.2806],\n",
      "        [13.9166,  7.8194,  9.4388],\n",
      "        [13.8628,  7.6769,  9.6812],\n",
      "        [14.1477,  7.8909, 10.0884],\n",
      "        [13.7455,  8.1513,  9.6924],\n",
      "        [14.0732,  8.1849,  9.5578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2888, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6836,  13.1027,  -7.0123],\n",
      "        [-11.4797,  13.0787,  -6.8452],\n",
      "        [-11.3451,  13.2131,  -6.8381],\n",
      "        [-11.4405,  12.7942,  -7.1994],\n",
      "        [-11.3571,  13.0242,  -6.9241],\n",
      "        [-11.9310,  12.3154,  -6.4637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1177,   8.0184,   9.2806, -11.6836,  13.1027,  -7.0123],\n",
      "        [ 13.9166,   7.8194,   9.4388, -11.4797,  13.0787,  -6.8452],\n",
      "        [ 13.8628,   7.6769,   9.6812, -11.3451,  13.2131,  -6.8381],\n",
      "        [ 14.1477,   7.8909,  10.0884, -11.4405,  12.7942,  -7.1994],\n",
      "        [ 13.7455,   8.1513,   9.6924, -11.3571,  13.0242,  -6.9241],\n",
      "        [ 14.0732,   8.1849,   9.5578, -11.9310,  12.3154,  -6.4637]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3768171072006226\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1602,  7.9731,  9.3366],\n",
      "        [14.0236,  7.7273,  9.7098],\n",
      "        [13.7140,  7.9829,  9.6391],\n",
      "        [14.2023,  7.9752,  9.7781],\n",
      "        [14.0772,  8.0558,  9.5553],\n",
      "        [13.9841,  8.0578,  9.8254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.1904,  13.1808,  -6.5874],\n",
      "        [-11.4017,  13.0309,  -7.0697],\n",
      "        [-11.3588,  13.1990,  -7.0890],\n",
      "        [-11.6009,  13.1549,  -7.0247],\n",
      "        [-11.5265,  13.0862,  -7.0664],\n",
      "        [-11.5553,  13.1536,  -6.8823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1602,   7.9731,   9.3366, -11.1904,  13.1808,  -6.5874],\n",
      "        [ 14.0236,   7.7273,   9.7098, -11.4017,  13.0309,  -7.0697],\n",
      "        [ 13.7140,   7.9829,   9.6391, -11.3588,  13.1990,  -7.0890],\n",
      "        [ 14.2023,   7.9752,   9.7781, -11.6009,  13.1549,  -7.0247],\n",
      "        [ 14.0772,   8.0558,   9.5553, -11.5265,  13.0862,  -7.0664],\n",
      "        [ 13.9841,   8.0578,   9.8254, -11.5553,  13.1536,  -6.8823]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3700358867645264\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8380, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4137,  8.1571,  9.6725],\n",
      "        [13.8885,  8.1711,  9.7244],\n",
      "        [14.1995,  8.1780,  9.2287],\n",
      "        [13.8083,  8.3255, 10.0338],\n",
      "        [14.0941,  7.8207,  9.5283],\n",
      "        [13.8209,  8.0932,  9.9008]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.2661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4808,  13.0291,  -7.0099],\n",
      "        [-11.6611,  12.8796,  -6.8475],\n",
      "        [-11.8984,  13.1577,  -6.6765],\n",
      "        [-11.9806,  13.2440,  -7.0462],\n",
      "        [-11.5436,  12.6937,  -6.7837],\n",
      "        [-11.8773,  12.8786,  -6.8624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4137,   8.1571,   9.6725, -11.4808,  13.0291,  -7.0099],\n",
      "        [ 13.8885,   8.1711,   9.7244, -11.6611,  12.8796,  -6.8475],\n",
      "        [ 14.1995,   8.1780,   9.2287, -11.8984,  13.1577,  -6.6765],\n",
      "        [ 13.8083,   8.3255,  10.0338, -11.9806,  13.2440,  -7.0462],\n",
      "        [ 14.0941,   7.8207,   9.5283, -11.5436,  12.6937,  -6.7837],\n",
      "        [ 13.8209,   8.0932,   9.9008, -11.8773,  12.8786,  -6.8624]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3973569869995117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0842, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1537,  8.0701,  9.6198],\n",
      "        [14.0982,  7.8421,  9.3816],\n",
      "        [13.7585,  7.9600,  9.4092],\n",
      "        [14.1701,  7.7852,  9.9524],\n",
      "        [13.8900,  7.7245,  9.8464],\n",
      "        [14.2884,  7.7831,  9.3297]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4190,  13.0427,  -7.1894],\n",
      "        [-10.8826,  13.0432,  -7.1899],\n",
      "        [-11.4341,  13.2453,  -6.4714],\n",
      "        [-11.5050,  13.2290,  -7.3334],\n",
      "        [-11.5507,  12.8344,  -7.2420],\n",
      "        [-11.2970,  12.6967,  -6.9581]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1537,   8.0701,   9.6198, -11.4190,  13.0427,  -7.1894],\n",
      "        [ 14.0982,   7.8421,   9.3816, -10.8826,  13.0432,  -7.1899],\n",
      "        [ 13.7585,   7.9600,   9.4092, -11.4341,  13.2453,  -6.4714],\n",
      "        [ 14.1701,   7.7852,   9.9524, -11.5050,  13.2290,  -7.3334],\n",
      "        [ 13.8900,   7.7245,   9.8464, -11.5507,  12.8344,  -7.2420],\n",
      "        [ 14.2884,   7.7831,   9.3297, -11.2970,  12.6967,  -6.9581]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.386675238609314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.7469,  8.2093,  9.7082],\n",
      "        [14.1065,  7.9126,  9.7225],\n",
      "        [14.1057,  7.9009,  9.5342],\n",
      "        [14.0305,  8.1889, 10.0633],\n",
      "        [14.0634,  8.0503,  9.7307],\n",
      "        [14.1480,  7.5376, 10.1477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8433,  13.4270,  -7.1674],\n",
      "        [-11.6307,  12.9923,  -6.8818],\n",
      "        [-11.4272,  13.0244,  -6.7234],\n",
      "        [-11.4927,  13.3330,  -7.3436],\n",
      "        [-11.9978,  13.0670,  -7.1775],\n",
      "        [-11.4634,  13.0738,  -6.8612]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.7469,   8.2093,   9.7082, -11.8433,  13.4270,  -7.1674],\n",
      "        [ 14.1065,   7.9126,   9.7225, -11.6307,  12.9923,  -6.8818],\n",
      "        [ 14.1057,   7.9009,   9.5342, -11.4272,  13.0244,  -6.7234],\n",
      "        [ 14.0305,   8.1889,  10.0633, -11.4927,  13.3330,  -7.3436],\n",
      "        [ 14.0634,   8.0503,   9.7307, -11.9978,  13.0670,  -7.1775],\n",
      "        [ 14.1480,   7.5376,  10.1477, -11.4634,  13.0738,  -6.8612]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3910099267959595\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3797,  8.1449,  9.5608],\n",
      "        [13.8212,  8.3133,  9.5774],\n",
      "        [14.2155,  7.8553,  9.4665],\n",
      "        [13.9472,  7.8174,  9.4357],\n",
      "        [14.0116,  8.0261,  9.7709],\n",
      "        [13.5714,  8.0150,  9.5640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7159, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7305,  13.2846,  -7.0665],\n",
      "        [-11.6060,  13.0411,  -6.5358],\n",
      "        [-11.3277,  12.6283,  -6.6720],\n",
      "        [-11.8145,  13.4335,  -7.0607],\n",
      "        [-11.6688,  12.9331,  -6.7047],\n",
      "        [-11.9819,  12.8243,  -7.1138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3797,   8.1449,   9.5608, -11.7305,  13.2846,  -7.0665],\n",
      "        [ 13.8212,   8.3133,   9.5774, -11.6060,  13.0411,  -6.5358],\n",
      "        [ 14.2155,   7.8553,   9.4665, -11.3277,  12.6283,  -6.6720],\n",
      "        [ 13.9472,   7.8174,   9.4357, -11.8145,  13.4335,  -7.0607],\n",
      "        [ 14.0116,   8.0261,   9.7709, -11.6688,  12.9331,  -6.7047],\n",
      "        [ 13.5714,   8.0150,   9.5640, -11.9819,  12.8243,  -7.1138]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4046883583068848\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4547, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2989,  7.8932,  9.3751],\n",
      "        [14.2743,  7.9145,  9.7252],\n",
      "        [14.0916,  7.9599,  9.8368],\n",
      "        [13.8551,  7.6521,  9.8215],\n",
      "        [14.0149,  7.9177,  9.8433],\n",
      "        [14.1707,  7.9894,  9.9921]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8507,  13.4908,  -6.9078],\n",
      "        [-11.4711,  13.3378,  -7.2040],\n",
      "        [-11.4201,  13.2803,  -7.2064],\n",
      "        [-11.4442,  12.9372,  -6.7272],\n",
      "        [-11.5667,  13.4057,  -6.8024],\n",
      "        [-11.6664,  12.9620,  -6.8152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2989,   7.8932,   9.3751, -11.8507,  13.4908,  -6.9078],\n",
      "        [ 14.2743,   7.9145,   9.7252, -11.4711,  13.3378,  -7.2040],\n",
      "        [ 14.0916,   7.9599,   9.8368, -11.4201,  13.2803,  -7.2064],\n",
      "        [ 13.8551,   7.6521,   9.8215, -11.4442,  12.9372,  -6.7272],\n",
      "        [ 14.0149,   7.9177,   9.8433, -11.5667,  13.4057,  -6.8024],\n",
      "        [ 14.1707,   7.9894,   9.9921, -11.6664,  12.9620,  -6.8152]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3981001377105713\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1133,  7.9608,  9.8656],\n",
      "        [14.0426,  7.8669,  9.7885],\n",
      "        [14.2889,  7.9640,  9.5719],\n",
      "        [13.8091,  7.6681,  9.5741],\n",
      "        [13.4928,  7.8370,  9.5694],\n",
      "        [14.2638,  8.4913,  9.6683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6011,  13.0849,  -6.9879],\n",
      "        [-11.5685,  12.8862,  -6.7061],\n",
      "        [-11.5284,  13.2577,  -6.9441],\n",
      "        [-11.8145,  13.3629,  -7.0764],\n",
      "        [-11.7313,  13.1927,  -7.0050],\n",
      "        [-11.3558,  12.8228,  -6.7508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1133,   7.9608,   9.8656, -11.6011,  13.0849,  -6.9879],\n",
      "        [ 14.0426,   7.8669,   9.7885, -11.5685,  12.8862,  -6.7061],\n",
      "        [ 14.2889,   7.9640,   9.5719, -11.5284,  13.2577,  -6.9441],\n",
      "        [ 13.8091,   7.6681,   9.5741, -11.8145,  13.3629,  -7.0764],\n",
      "        [ 13.4928,   7.8370,   9.5694, -11.7313,  13.1927,  -7.0050],\n",
      "        [ 14.2638,   8.4913,   9.6683, -11.3558,  12.8228,  -6.7508]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3955453634262085\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.0420,  7.6087,  9.4671],\n",
      "        [13.7505,  7.8547,  9.5718],\n",
      "        [14.1420,  7.9758,  9.5369],\n",
      "        [13.9739,  8.0418,  9.6993],\n",
      "        [14.0460,  8.1699,  9.7156],\n",
      "        [14.1395,  7.8393,  9.5724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2766, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8272,  13.1165,  -6.8178],\n",
      "        [-11.5947,  12.8373,  -6.8607],\n",
      "        [-11.6836,  13.0365,  -7.1192],\n",
      "        [-11.4432,  13.1428,  -7.1420],\n",
      "        [-11.7828,  13.3380,  -6.7199],\n",
      "        [-11.7316,  13.1745,  -6.9906]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.0420,   7.6087,   9.4671, -11.8272,  13.1165,  -6.8178],\n",
      "        [ 13.7505,   7.8547,   9.5718, -11.5947,  12.8373,  -6.8607],\n",
      "        [ 14.1420,   7.9758,   9.5369, -11.6836,  13.0365,  -7.1192],\n",
      "        [ 13.9739,   8.0418,   9.6993, -11.4432,  13.1428,  -7.1420],\n",
      "        [ 14.0460,   8.1699,   9.7156, -11.7828,  13.3380,  -6.7199],\n",
      "        [ 14.1395,   7.8393,   9.5724, -11.7316,  13.1745,  -6.9906]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3803365230560303\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8313,  8.3522,  9.7228],\n",
      "        [14.1876,  7.8704,  9.9825],\n",
      "        [13.7580,  7.9770,  9.5105],\n",
      "        [13.9977,  8.0703,  9.9403],\n",
      "        [14.2605,  8.0031,  9.6700],\n",
      "        [14.5125,  8.4862,  9.6932]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4790, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.5491,  13.1655,  -7.0502],\n",
      "        [-11.6760,  12.7470,  -6.5216],\n",
      "        [-11.8077,  12.8427,  -6.7770],\n",
      "        [-11.3801,  12.8187,  -7.0320],\n",
      "        [-12.0040,  13.2955,  -7.2627],\n",
      "        [-11.3378,  12.9002,  -6.6439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8313,   8.3522,   9.7228, -11.5491,  13.1655,  -7.0502],\n",
      "        [ 14.1876,   7.8704,   9.9825, -11.6760,  12.7470,  -6.5216],\n",
      "        [ 13.7580,   7.9770,   9.5105, -11.8077,  12.8427,  -6.7770],\n",
      "        [ 13.9977,   8.0703,   9.9403, -11.3801,  12.8187,  -7.0320],\n",
      "        [ 14.2605,   8.0031,   9.6700, -12.0040,  13.2955,  -7.2627],\n",
      "        [ 14.5125,   8.4862,   9.6932, -11.3378,  12.9002,  -6.6439]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3903734683990479\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1031,  8.0375,  9.7113],\n",
      "        [14.1741,  7.7480,  9.6716],\n",
      "        [14.2872,  8.0581,  9.6016],\n",
      "        [14.1866,  7.7088,  9.6936],\n",
      "        [14.5873,  8.1715,  9.9997],\n",
      "        [14.1815,  8.1145,  9.6472]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8059, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7892,  13.3966,  -7.2275],\n",
      "        [-11.7443,  12.9898,  -6.9140],\n",
      "        [-11.8087,  13.0640,  -6.9790],\n",
      "        [-11.7350,  13.5797,  -7.3463],\n",
      "        [-11.5993,  13.0922,  -7.1300],\n",
      "        [-11.5338,  13.1943,  -7.0378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1031,   8.0375,   9.7113, -11.7892,  13.3966,  -7.2275],\n",
      "        [ 14.1741,   7.7480,   9.6716, -11.7443,  12.9898,  -6.9140],\n",
      "        [ 14.2872,   8.0581,   9.6016, -11.8087,  13.0640,  -6.9790],\n",
      "        [ 14.1866,   7.7088,   9.6936, -11.7350,  13.5797,  -7.3463],\n",
      "        [ 14.5873,   8.1715,   9.9997, -11.5993,  13.0922,  -7.1300],\n",
      "        [ 14.1815,   8.1145,   9.6472, -11.5338,  13.1943,  -7.0378]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4055994749069214\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0457, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1553,  7.9886,  9.5855],\n",
      "        [13.9763,  8.0382,  9.5157],\n",
      "        [13.8285,  7.5458,  9.4717],\n",
      "        [14.4743,  8.1056, 10.1273],\n",
      "        [13.8532,  7.8346,  9.5533],\n",
      "        [13.9023,  7.8953,  9.7117]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.4542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6739,  12.9433,  -6.9466],\n",
      "        [-11.6942,  13.0478,  -7.0752],\n",
      "        [-11.6027,  12.8866,  -7.2142],\n",
      "        [-11.4364,  13.1184,  -6.8648],\n",
      "        [-11.7282,  13.1102,  -6.9882],\n",
      "        [-11.6036,  13.3052,  -7.1840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1553,   7.9886,   9.5855, -11.6739,  12.9433,  -6.9466],\n",
      "        [ 13.9763,   8.0382,   9.5157, -11.6942,  13.0478,  -7.0752],\n",
      "        [ 13.8285,   7.5458,   9.4717, -11.6027,  12.8866,  -7.2142],\n",
      "        [ 14.4743,   8.1056,  10.1273, -11.4364,  13.1184,  -6.8648],\n",
      "        [ 13.8532,   7.8346,   9.5533, -11.7282,  13.1102,  -6.9882],\n",
      "        [ 13.9023,   7.8953,   9.7117, -11.6036,  13.3052,  -7.1840]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.3915096521377563\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8151, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9858,  7.9769,  9.4710],\n",
      "        [14.5640,  8.3030, 10.0364],\n",
      "        [14.0876,  7.9161,  9.3986],\n",
      "        [14.4635,  8.0358,  9.9161],\n",
      "        [14.1868,  8.2185,  9.3064],\n",
      "        [13.9883,  8.0004,  9.5098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9237, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7515,  12.6832,  -6.9408],\n",
      "        [-11.7204,  13.0889,  -6.9948],\n",
      "        [-11.5071,  12.7582,  -6.7921],\n",
      "        [-11.5591,  12.8396,  -6.7412],\n",
      "        [-11.6021,  13.0533,  -6.9365],\n",
      "        [-11.6474,  12.7560,  -7.1538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9858,   7.9769,   9.4710, -11.7515,  12.6832,  -6.9408],\n",
      "        [ 14.5640,   8.3030,  10.0364, -11.7204,  13.0889,  -6.9948],\n",
      "        [ 14.0876,   7.9161,   9.3986, -11.5071,  12.7582,  -6.7921],\n",
      "        [ 14.4635,   8.0358,   9.9161, -11.5591,  12.8396,  -6.7412],\n",
      "        [ 14.1868,   8.2185,   9.3064, -11.6021,  13.0533,  -6.9365],\n",
      "        [ 13.9883,   8.0004,   9.5098, -11.6474,  12.7560,  -7.1538]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.3792095184326172\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6220,  8.2763,  9.7325],\n",
      "        [14.3840,  8.3142,  9.8821],\n",
      "        [14.2909,  8.0539,  9.6299],\n",
      "        [14.2036,  7.8366,  9.7090],\n",
      "        [14.1449,  8.2059,  9.4940],\n",
      "        [14.2542,  8.0657,  9.6463]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9217,  13.5003,  -7.0788],\n",
      "        [-11.5141,  13.4951,  -6.9753],\n",
      "        [-11.5834,  13.0169,  -7.1482],\n",
      "        [-11.6253,  12.7352,  -6.7297],\n",
      "        [-11.8692,  12.9722,  -6.8071],\n",
      "        [-11.8915,  13.4934,  -7.2526]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6220,   8.2763,   9.7325, -11.9217,  13.5003,  -7.0788],\n",
      "        [ 14.3840,   8.3142,   9.8821, -11.5141,  13.4951,  -6.9753],\n",
      "        [ 14.2909,   8.0539,   9.6299, -11.5834,  13.0169,  -7.1482],\n",
      "        [ 14.2036,   7.8366,   9.7090, -11.6253,  12.7352,  -6.7297],\n",
      "        [ 14.1449,   8.2059,   9.4940, -11.8692,  12.9722,  -6.8071],\n",
      "        [ 14.2542,   8.0657,   9.6463, -11.8915,  13.4934,  -7.2526]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4343172311782837\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.0768,  8.2098, 10.1948],\n",
      "        [13.9163,  7.8267,  9.4327],\n",
      "        [14.1698,  8.1355,  9.8417],\n",
      "        [14.1194,  8.2072,  9.6523],\n",
      "        [14.1098,  8.3035, 10.0613],\n",
      "        [14.1117,  7.8344,  9.8150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.2961,  13.0015,  -7.1497],\n",
      "        [-11.6322,  13.3747,  -7.1007],\n",
      "        [-11.4481,  13.2288,  -7.3128],\n",
      "        [-11.6477,  13.2504,  -7.0603],\n",
      "        [-11.9831,  13.4571,  -7.2082],\n",
      "        [-11.7650,  13.0959,  -7.0374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.0768,   8.2098,  10.1948, -11.2961,  13.0015,  -7.1497],\n",
      "        [ 13.9163,   7.8267,   9.4327, -11.6322,  13.3747,  -7.1007],\n",
      "        [ 14.1698,   8.1355,   9.8417, -11.4481,  13.2288,  -7.3128],\n",
      "        [ 14.1194,   8.2072,   9.6523, -11.6477,  13.2504,  -7.0603],\n",
      "        [ 14.1098,   8.3035,  10.0613, -11.9831,  13.4571,  -7.2082],\n",
      "        [ 14.1117,   7.8344,   9.8150, -11.7650,  13.0959,  -7.0374]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4078059196472168\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3873, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2156,  8.2401,  9.5950],\n",
      "        [14.0659,  8.1230, 10.0507],\n",
      "        [14.1546,  8.4918,  9.6262],\n",
      "        [14.1335,  8.0490, 10.1301],\n",
      "        [14.4980,  8.2513,  9.9439],\n",
      "        [14.2876,  8.1276,  9.9136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5126, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6259,  13.1575,  -7.0944],\n",
      "        [-11.7432,  13.0320,  -7.0480],\n",
      "        [-11.7208,  13.4228,  -6.9688],\n",
      "        [-11.8416,  13.5420,  -6.7591],\n",
      "        [-11.4518,  13.2032,  -7.0031],\n",
      "        [-12.0120,  13.5235,  -7.2907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2156,   8.2401,   9.5950, -11.6259,  13.1575,  -7.0944],\n",
      "        [ 14.0659,   8.1230,  10.0507, -11.7432,  13.0320,  -7.0480],\n",
      "        [ 14.1546,   8.4918,   9.6262, -11.7208,  13.4228,  -6.9688],\n",
      "        [ 14.1335,   8.0490,  10.1301, -11.8416,  13.5420,  -6.7591],\n",
      "        [ 14.4980,   8.2513,   9.9439, -11.4518,  13.2032,  -7.0031],\n",
      "        [ 14.2876,   8.1276,   9.9136, -12.0120,  13.5235,  -7.2907]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4057713747024536\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8979,  7.8212,  9.8401],\n",
      "        [13.7244,  7.6040,  9.8554],\n",
      "        [14.0616,  8.0629,  9.8351],\n",
      "        [14.1747,  7.9078,  9.6444],\n",
      "        [14.4038,  8.2377, 10.0182],\n",
      "        [14.2586,  7.8794,  9.7753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8426,  13.4780,  -7.1685],\n",
      "        [-11.6036,  13.4116,  -6.8362],\n",
      "        [-11.5319,  12.8680,  -7.1895],\n",
      "        [-11.5572,  12.8755,  -6.6730],\n",
      "        [-11.4431,  12.9874,  -7.0775],\n",
      "        [-11.4486,  13.4129,  -6.7731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8979,   7.8212,   9.8401, -11.8426,  13.4780,  -7.1685],\n",
      "        [ 13.7244,   7.6040,   9.8554, -11.6036,  13.4116,  -6.8362],\n",
      "        [ 14.0616,   8.0629,   9.8351, -11.5319,  12.8680,  -7.1895],\n",
      "        [ 14.1747,   7.9078,   9.6444, -11.5572,  12.8755,  -6.6730],\n",
      "        [ 14.4038,   8.2377,  10.0182, -11.4431,  12.9874,  -7.0775],\n",
      "        [ 14.2586,   7.8794,   9.7753, -11.4486,  13.4129,  -6.7731]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4051717519760132\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1913,  8.1316,  9.8939],\n",
      "        [14.3954,  8.1142,  9.9592],\n",
      "        [14.1412,  7.9826,  9.8508],\n",
      "        [13.9867,  8.1295,  9.6490],\n",
      "        [13.9733,  8.2763,  9.9756],\n",
      "        [14.2992,  8.1834,  9.7438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7467,  13.2290,  -7.0769],\n",
      "        [-11.4083,  13.0545,  -6.6857],\n",
      "        [-11.7442,  13.1199,  -7.0238],\n",
      "        [-11.6033,  13.3023,  -6.8890],\n",
      "        [-11.9491,  13.3210,  -7.0026],\n",
      "        [-11.7581,  13.3709,  -7.2959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1913,   8.1316,   9.8939, -11.7467,  13.2290,  -7.0769],\n",
      "        [ 14.3954,   8.1142,   9.9592, -11.4083,  13.0545,  -6.6857],\n",
      "        [ 14.1412,   7.9826,   9.8508, -11.7442,  13.1199,  -7.0238],\n",
      "        [ 13.9867,   8.1295,   9.6490, -11.6033,  13.3023,  -6.8890],\n",
      "        [ 13.9733,   8.2763,   9.9756, -11.9491,  13.3210,  -7.0026],\n",
      "        [ 14.2992,   8.1834,   9.7438, -11.7581,  13.3709,  -7.2959]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4161274433135986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3196,  7.8714,  9.5596],\n",
      "        [14.1288,  7.9772,  9.6357],\n",
      "        [14.1361,  8.2768,  9.6366],\n",
      "        [14.4332,  7.9433,  9.5630],\n",
      "        [14.0950,  7.9683,  9.7682],\n",
      "        [13.8245,  7.8083,  9.4767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0103, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6577,  13.5444,  -6.8919],\n",
      "        [-12.1628,  13.3730,  -7.1064],\n",
      "        [-11.5181,  13.1479,  -7.1303],\n",
      "        [-11.7692,  13.4517,  -6.9178],\n",
      "        [-11.7486,  13.6329,  -7.1791],\n",
      "        [-11.9434,  13.2163,  -7.1989]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3196,   7.8714,   9.5596, -11.6577,  13.5444,  -6.8919],\n",
      "        [ 14.1288,   7.9772,   9.6357, -12.1628,  13.3730,  -7.1064],\n",
      "        [ 14.1361,   8.2768,   9.6366, -11.5181,  13.1479,  -7.1303],\n",
      "        [ 14.4332,   7.9433,   9.5630, -11.7692,  13.4517,  -6.9178],\n",
      "        [ 14.0950,   7.9683,   9.7682, -11.7486,  13.6329,  -7.1791],\n",
      "        [ 13.8245,   7.8083,   9.4767, -11.9434,  13.2163,  -7.1989]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.4114047288894653\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4498, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4131,  8.4676,  9.9572],\n",
      "        [13.9295,  8.0497,  9.7729],\n",
      "        [14.0272,  7.9726,  9.7472],\n",
      "        [14.3907,  7.9293,  9.7279],\n",
      "        [14.0834,  8.0776,  9.6341],\n",
      "        [14.0451,  7.9517,  9.4823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.5041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4022,  13.2692,  -7.1966],\n",
      "        [-11.7602,  13.0299,  -6.5526],\n",
      "        [-11.4032,  13.0038,  -6.9752],\n",
      "        [-11.6790,  13.1430,  -7.2439],\n",
      "        [-12.0570,  13.3547,  -7.1112],\n",
      "        [-11.8791,  13.1028,  -7.2753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4131,   8.4676,   9.9572, -11.4022,  13.2692,  -7.1966],\n",
      "        [ 13.9295,   8.0497,   9.7729, -11.7602,  13.0299,  -6.5526],\n",
      "        [ 14.0272,   7.9726,   9.7472, -11.4032,  13.0038,  -6.9752],\n",
      "        [ 14.3907,   7.9293,   9.7279, -11.6790,  13.1430,  -7.2439],\n",
      "        [ 14.0834,   8.0776,   9.6341, -12.0570,  13.3547,  -7.1112],\n",
      "        [ 14.0451,   7.9517,   9.4823, -11.8791,  13.1028,  -7.2753]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4291605949401855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7067, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1213,  8.0223,  9.8410],\n",
      "        [13.9758,  8.0389,  9.9038],\n",
      "        [13.8420,  7.9293,  9.4923],\n",
      "        [14.0196,  7.9184,  9.6353],\n",
      "        [13.7777,  8.0224,  9.5992],\n",
      "        [14.4143,  8.4070,  9.9646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1298, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4480,  13.3504,  -7.3684],\n",
      "        [-12.2415,  13.6875,  -7.3435],\n",
      "        [-11.9748,  13.2445,  -6.8118],\n",
      "        [-12.0097,  13.4928,  -7.2396],\n",
      "        [-12.1234,  13.2064,  -7.0965],\n",
      "        [-11.5803,  13.3666,  -7.2396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1213,   8.0223,   9.8410, -11.4480,  13.3504,  -7.3684],\n",
      "        [ 13.9758,   8.0389,   9.9038, -12.2415,  13.6875,  -7.3435],\n",
      "        [ 13.8420,   7.9293,   9.4923, -11.9748,  13.2445,  -6.8118],\n",
      "        [ 14.0196,   7.9184,   9.6353, -12.0097,  13.4928,  -7.2396],\n",
      "        [ 13.7777,   8.0224,   9.5992, -12.1234,  13.2064,  -7.0965],\n",
      "        [ 14.4143,   8.4070,   9.9646, -11.5803,  13.3666,  -7.2396]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4128491878509521\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0687, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9053,  7.6964,  9.6203],\n",
      "        [14.4132,  8.3163, 10.1421],\n",
      "        [14.2781,  8.2558,  9.7916],\n",
      "        [14.3328,  8.3537, 10.0836],\n",
      "        [14.5814,  8.0920,  9.8383],\n",
      "        [14.4038,  8.3311,  9.7937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.3148, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6531,  13.1858,  -7.1510],\n",
      "        [-11.6287,  13.7057,  -7.4220],\n",
      "        [-11.9180,  13.3241,  -7.2328],\n",
      "        [-11.9515,  13.2148,  -6.9137],\n",
      "        [-11.5842,  13.2540,  -7.3916],\n",
      "        [-11.9137,  13.3986,  -6.9465]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9053,   7.6964,   9.6203, -11.6531,  13.1858,  -7.1510],\n",
      "        [ 14.4132,   8.3163,  10.1421, -11.6287,  13.7057,  -7.4220],\n",
      "        [ 14.2781,   8.2558,   9.7916, -11.9180,  13.3241,  -7.2328],\n",
      "        [ 14.3328,   8.3537,  10.0836, -11.9515,  13.2148,  -6.9137],\n",
      "        [ 14.5814,   8.0920,   9.8383, -11.5842,  13.2540,  -7.3916],\n",
      "        [ 14.4038,   8.3311,   9.7937, -11.9137,  13.3986,  -6.9465]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.393004059791565\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7959, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.0888,  7.9622,  9.7494],\n",
      "        [13.8261,  7.9785,  9.9280],\n",
      "        [14.0022,  8.2156, 10.0151],\n",
      "        [14.3011,  8.2628,  9.6371],\n",
      "        [14.1299,  7.9079,  9.8067],\n",
      "        [14.0164,  8.0870,  9.7304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8056,  13.2878,  -7.4134],\n",
      "        [-11.6288,  13.3337,  -7.1233],\n",
      "        [-11.4734,  13.1334,  -6.8356],\n",
      "        [-11.9836,  13.4483,  -7.0969],\n",
      "        [-12.0310,  13.5617,  -7.3731],\n",
      "        [-11.3904,  13.1960,  -7.0859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.0888,   7.9622,   9.7494, -11.8056,  13.2878,  -7.4134],\n",
      "        [ 13.8261,   7.9785,   9.9280, -11.6288,  13.3337,  -7.1233],\n",
      "        [ 14.0022,   8.2156,  10.0151, -11.4734,  13.1334,  -6.8356],\n",
      "        [ 14.3011,   8.2628,   9.6371, -11.9836,  13.4483,  -7.0969],\n",
      "        [ 14.1299,   7.9079,   9.8067, -12.0310,  13.5617,  -7.3731],\n",
      "        [ 14.0164,   8.0870,   9.7304, -11.3904,  13.1960,  -7.0859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4149620532989502\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6492, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2653,  8.0433,  9.8206],\n",
      "        [14.7165,  8.3165, 10.0210],\n",
      "        [14.5381,  8.3967, 10.1525],\n",
      "        [14.3032,  7.8557,  9.6977],\n",
      "        [14.3559,  8.0328,  9.8667],\n",
      "        [14.7034,  8.0658,  9.9665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1387,  13.1132,  -7.2410],\n",
      "        [-11.9739,  13.4723,  -6.9341],\n",
      "        [-11.7385,  13.2660,  -6.8676],\n",
      "        [-11.9663,  13.4096,  -7.2302],\n",
      "        [-11.8335,  13.0882,  -6.9550],\n",
      "        [-11.4268,  13.5800,  -7.2728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2653,   8.0433,   9.8206, -12.1387,  13.1132,  -7.2410],\n",
      "        [ 14.7165,   8.3165,  10.0210, -11.9739,  13.4723,  -6.9341],\n",
      "        [ 14.5381,   8.3967,  10.1525, -11.7385,  13.2660,  -6.8676],\n",
      "        [ 14.3032,   7.8557,   9.6977, -11.9663,  13.4096,  -7.2302],\n",
      "        [ 14.3559,   8.0328,   9.8667, -11.8335,  13.0882,  -6.9550],\n",
      "        [ 14.7034,   8.0658,   9.9665, -11.4268,  13.5800,  -7.2728]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4262006282806396\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7951, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5817,  8.2832,  9.9613],\n",
      "        [14.2624,  8.3197,  9.9804],\n",
      "        [14.1970,  8.1687, 10.0711],\n",
      "        [14.2827,  8.6449,  9.9351],\n",
      "        [14.1805,  8.0341,  9.7574],\n",
      "        [14.0729,  7.9551,  9.5710]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9797,  13.3593,  -7.3904],\n",
      "        [-12.0208,  13.5160,  -7.1501],\n",
      "        [-12.1050,  13.4915,  -7.4176],\n",
      "        [-11.4602,  12.8882,  -6.7291],\n",
      "        [-11.7808,  13.3984,  -7.0651],\n",
      "        [-11.9267,  13.1160,  -7.0276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5817,   8.2832,   9.9613, -11.9797,  13.3593,  -7.3904],\n",
      "        [ 14.2624,   8.3197,   9.9804, -12.0208,  13.5160,  -7.1501],\n",
      "        [ 14.1970,   8.1687,  10.0711, -12.1050,  13.4915,  -7.4176],\n",
      "        [ 14.2827,   8.6449,   9.9351, -11.4602,  12.8882,  -6.7291],\n",
      "        [ 14.1805,   8.0341,   9.7574, -11.7808,  13.3984,  -7.0651],\n",
      "        [ 14.0729,   7.9551,   9.5710, -11.9267,  13.1160,  -7.0276]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.4496427774429321\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7195, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.8971,  8.0647,  9.8630],\n",
      "        [14.2467,  8.1496,  9.7696],\n",
      "        [14.3983,  8.3301, 10.0449],\n",
      "        [13.9715,  8.1256,  9.9597],\n",
      "        [14.4740,  8.2959, 10.0343],\n",
      "        [14.6314,  8.0570,  9.8910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2521, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9861,  13.6218,  -7.2803],\n",
      "        [-11.7855,  13.4282,  -7.4975],\n",
      "        [-12.3240,  13.6262,  -7.1665],\n",
      "        [-12.0168,  13.4644,  -7.3939],\n",
      "        [-11.8174,  13.2258,  -7.0871],\n",
      "        [-11.8952,  13.2978,  -7.6068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.8971,   8.0647,   9.8630, -11.9861,  13.6218,  -7.2803],\n",
      "        [ 14.2467,   8.1496,   9.7696, -11.7855,  13.4282,  -7.4975],\n",
      "        [ 14.3983,   8.3301,  10.0449, -12.3240,  13.6262,  -7.1665],\n",
      "        [ 13.9715,   8.1256,   9.9597, -12.0168,  13.4644,  -7.3939],\n",
      "        [ 14.4740,   8.2959,  10.0343, -11.8174,  13.2258,  -7.0871],\n",
      "        [ 14.6314,   8.0570,   9.8910, -11.8952,  13.2978,  -7.6068]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4232969284057617\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3379,  8.2861,  9.6794],\n",
      "        [14.0914,  8.1332,  9.7834],\n",
      "        [14.2073,  8.0557,  9.7518],\n",
      "        [14.2656,  8.0191,  9.7955],\n",
      "        [14.4541,  8.2833,  9.7527],\n",
      "        [14.1757,  8.3273,  9.7092]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8868,  13.4252,  -7.1515],\n",
      "        [-11.7162,  13.0512,  -7.2082],\n",
      "        [-11.5344,  13.3959,  -6.9442],\n",
      "        [-11.9002,  13.1712,  -7.1865],\n",
      "        [-11.7230,  13.2561,  -7.4886],\n",
      "        [-12.2502,  13.8038,  -7.1569]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3379,   8.2861,   9.6794, -11.8868,  13.4252,  -7.1515],\n",
      "        [ 14.0914,   8.1332,   9.7834, -11.7162,  13.0512,  -7.2082],\n",
      "        [ 14.2073,   8.0557,   9.7518, -11.5344,  13.3959,  -6.9442],\n",
      "        [ 14.2656,   8.0191,   9.7955, -11.9002,  13.1712,  -7.1865],\n",
      "        [ 14.4541,   8.2833,   9.7527, -11.7230,  13.2561,  -7.4886],\n",
      "        [ 14.1757,   8.3273,   9.7092, -12.2502,  13.8038,  -7.1569]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4324392080307007\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1752,  8.0114,  9.6550],\n",
      "        [14.1057,  8.1426,  9.8710],\n",
      "        [13.8597,  8.1716, 10.1399],\n",
      "        [14.3301,  8.4500, 10.1240],\n",
      "        [14.5850,  8.2176, 10.1440],\n",
      "        [14.2084,  7.9601, 10.1632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7395,  12.8421,  -6.9388],\n",
      "        [-11.6840,  13.4808,  -7.1568],\n",
      "        [-11.5942,  12.9369,  -6.8132],\n",
      "        [-12.0695,  13.2230,  -7.1435],\n",
      "        [-12.0104,  13.1051,  -6.6783],\n",
      "        [-11.8589,  13.2025,  -7.0745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1752,   8.0114,   9.6550, -11.7395,  12.8421,  -6.9388],\n",
      "        [ 14.1057,   8.1426,   9.8710, -11.6840,  13.4808,  -7.1568],\n",
      "        [ 13.8597,   8.1716,  10.1399, -11.5942,  12.9369,  -6.8132],\n",
      "        [ 14.3301,   8.4500,  10.1240, -12.0695,  13.2230,  -7.1435],\n",
      "        [ 14.5850,   8.2176,  10.1440, -12.0104,  13.1051,  -6.6783],\n",
      "        [ 14.2084,   7.9601,  10.1632, -11.8589,  13.2025,  -7.0745]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4070169925689697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4386,  8.4276,  9.8985],\n",
      "        [14.3246,  8.5180, 10.0509],\n",
      "        [14.2013,  8.2188,  9.8792],\n",
      "        [13.8616,  8.0585, 10.1118],\n",
      "        [14.0784,  8.2500, 10.0690],\n",
      "        [14.4272,  8.2529,  9.8390]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0814,  13.4951,  -7.2169],\n",
      "        [-11.6492,  13.0662,  -6.8400],\n",
      "        [-11.9893,  13.7074,  -7.1829],\n",
      "        [-11.7238,  13.4704,  -7.1292],\n",
      "        [-12.1536,  13.5756,  -7.1955],\n",
      "        [-11.9398,  13.5639,  -7.3461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4386,   8.4276,   9.8985, -12.0814,  13.4951,  -7.2169],\n",
      "        [ 14.3246,   8.5180,  10.0509, -11.6492,  13.0662,  -6.8400],\n",
      "        [ 14.2013,   8.2188,   9.8792, -11.9893,  13.7074,  -7.1829],\n",
      "        [ 13.8616,   8.0585,  10.1118, -11.7238,  13.4704,  -7.1292],\n",
      "        [ 14.0784,   8.2500,  10.0690, -12.1536,  13.5756,  -7.1955],\n",
      "        [ 14.4272,   8.2529,   9.8390, -11.9398,  13.5639,  -7.3461]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4511709213256836\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9090,  8.3127,  9.7812],\n",
      "        [14.2229,  8.4008,  9.8709],\n",
      "        [14.0946,  8.0435, 10.1300],\n",
      "        [14.4669,  8.3916,  9.9187],\n",
      "        [14.1702,  8.2286,  9.8456],\n",
      "        [14.6249,  8.1598,  9.7562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4743,  12.7896,  -7.1440],\n",
      "        [-12.0746,  13.2572,  -7.4159],\n",
      "        [-12.1036,  13.4615,  -7.1929],\n",
      "        [-11.8360,  13.0752,  -7.2590],\n",
      "        [-12.0889,  13.5229,  -7.1212],\n",
      "        [-11.6972,  13.3046,  -7.4427]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9090,   8.3127,   9.7812, -11.4743,  12.7896,  -7.1440],\n",
      "        [ 14.2229,   8.4008,   9.8709, -12.0746,  13.2572,  -7.4159],\n",
      "        [ 14.0946,   8.0435,  10.1300, -12.1036,  13.4615,  -7.1929],\n",
      "        [ 14.4669,   8.3916,   9.9187, -11.8360,  13.0752,  -7.2590],\n",
      "        [ 14.1702,   8.2286,   9.8456, -12.0889,  13.5229,  -7.1212],\n",
      "        [ 14.6249,   8.1598,   9.7562, -11.6972,  13.3046,  -7.4427]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4035717248916626\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[13.9845,  8.0078, 10.1423],\n",
      "        [14.4635,  8.3724,  9.8788],\n",
      "        [14.0928,  8.0805, 10.1914],\n",
      "        [14.4274,  8.1059,  9.8049],\n",
      "        [14.5942,  8.0375,  9.5178],\n",
      "        [14.3291,  8.0003,  9.7429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7370, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6627,  13.2138,  -7.0338],\n",
      "        [-12.0017,  13.5133,  -7.0099],\n",
      "        [-12.0413,  13.0255,  -7.0125],\n",
      "        [-11.8266,  13.5332,  -7.0721],\n",
      "        [-11.9688,  13.8935,  -7.3825],\n",
      "        [-11.8559,  13.2691,  -7.3662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 13.9845,   8.0078,  10.1423, -11.6627,  13.2138,  -7.0338],\n",
      "        [ 14.4635,   8.3724,   9.8788, -12.0017,  13.5133,  -7.0099],\n",
      "        [ 14.0928,   8.0805,  10.1914, -12.0413,  13.0255,  -7.0125],\n",
      "        [ 14.4274,   8.1059,   9.8049, -11.8266,  13.5332,  -7.0721],\n",
      "        [ 14.5942,   8.0375,   9.5178, -11.9688,  13.8935,  -7.3825],\n",
      "        [ 14.3291,   8.0003,   9.7429, -11.8559,  13.2691,  -7.3662]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.4223449230194092\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9535, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3049,  8.2044,  9.8491],\n",
      "        [14.3129,  8.1570,  9.5990],\n",
      "        [13.9779,  8.1493,  9.7324],\n",
      "        [14.5110,  8.2422,  9.8863],\n",
      "        [14.0874,  8.6129,  9.9055],\n",
      "        [14.3081,  7.8600, 10.1874]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4384,  13.6378,  -6.9447],\n",
      "        [-12.0530,  13.7109,  -7.3817],\n",
      "        [-11.6676,  13.4748,  -7.0475],\n",
      "        [-11.8127,  13.3920,  -7.1377],\n",
      "        [-12.0925,  13.5731,  -7.0549],\n",
      "        [-11.7719,  13.5793,  -7.5321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3049,   8.2044,   9.8491, -11.4384,  13.6378,  -6.9447],\n",
      "        [ 14.3129,   8.1570,   9.5990, -12.0530,  13.7109,  -7.3817],\n",
      "        [ 13.9779,   8.1493,   9.7324, -11.6676,  13.4748,  -7.0475],\n",
      "        [ 14.5110,   8.2422,   9.8863, -11.8127,  13.3920,  -7.1377],\n",
      "        [ 14.0874,   8.6129,   9.9055, -12.0925,  13.5731,  -7.0549],\n",
      "        [ 14.3081,   7.8600,  10.1874, -11.7719,  13.5793,  -7.5321]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4336845874786377\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5506, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.0120,  7.8674,  9.6839],\n",
      "        [14.6816,  8.4958,  9.6162],\n",
      "        [14.1938,  8.0299,  9.8511],\n",
      "        [14.1142,  7.7684,  9.9152],\n",
      "        [13.9764,  8.3613,  9.5711],\n",
      "        [14.3458,  8.0697, 10.3431]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.6342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9185,  13.4580,  -7.3350],\n",
      "        [-11.7150,  13.8380,  -7.4212],\n",
      "        [-11.6536,  13.5573,  -7.1619],\n",
      "        [-11.7486,  13.4573,  -7.2765],\n",
      "        [-12.0406,  13.3610,  -7.0735],\n",
      "        [-11.7259,  13.3228,  -6.8770]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.0120,   7.8674,   9.6839, -11.9185,  13.4580,  -7.3350],\n",
      "        [ 14.6816,   8.4958,   9.6162, -11.7150,  13.8380,  -7.4212],\n",
      "        [ 14.1938,   8.0299,   9.8511, -11.6536,  13.5573,  -7.1619],\n",
      "        [ 14.1142,   7.7684,   9.9152, -11.7486,  13.4573,  -7.2765],\n",
      "        [ 13.9764,   8.3613,   9.5711, -12.0406,  13.3610,  -7.0735],\n",
      "        [ 14.3458,   8.0697,  10.3431, -11.7259,  13.3228,  -6.8770]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4217426776885986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5022,  8.3969,  9.7477],\n",
      "        [14.0510,  8.2553, 10.0520],\n",
      "        [14.0082,  8.1695,  9.7485],\n",
      "        [14.0913,  8.0368,  9.8912],\n",
      "        [14.5088,  8.1159,  9.9044],\n",
      "        [14.0568,  8.2428,  9.8075]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8906,  13.4116,  -7.3005],\n",
      "        [-12.1373,  13.6239,  -7.0741],\n",
      "        [-11.7649,  13.4464,  -7.3288],\n",
      "        [-12.0191,  13.5321,  -7.4109],\n",
      "        [-11.6691,  13.5682,  -7.5624],\n",
      "        [-11.8713,  13.6739,  -7.2751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5022,   8.3969,   9.7477, -11.8906,  13.4116,  -7.3005],\n",
      "        [ 14.0510,   8.2553,  10.0520, -12.1373,  13.6239,  -7.0741],\n",
      "        [ 14.0082,   8.1695,   9.7485, -11.7649,  13.4464,  -7.3288],\n",
      "        [ 14.0913,   8.0368,   9.8912, -12.0191,  13.5321,  -7.4109],\n",
      "        [ 14.5088,   8.1159,   9.9044, -11.6691,  13.5682,  -7.5624],\n",
      "        [ 14.0568,   8.2428,   9.8075, -11.8713,  13.6739,  -7.2751]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4492353200912476\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.1923,  8.3402, 10.1314],\n",
      "        [14.2955,  8.3452,  9.9700],\n",
      "        [14.2828,  8.3298,  9.9892],\n",
      "        [14.2411,  7.8482, 10.2183],\n",
      "        [14.6844,  8.5119, 10.1970],\n",
      "        [13.9465,  7.9462, 10.1119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.2913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4856,  13.1724,  -6.9972],\n",
      "        [-11.7179,  13.1668,  -7.1999],\n",
      "        [-12.1921,  13.4274,  -7.1404],\n",
      "        [-12.0010,  13.7216,  -7.3450],\n",
      "        [-12.2183,  13.6675,  -7.4152],\n",
      "        [-12.0012,  13.2164,  -7.3120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.1923,   8.3402,  10.1314, -11.4856,  13.1724,  -6.9972],\n",
      "        [ 14.2955,   8.3452,   9.9700, -11.7179,  13.1668,  -7.1999],\n",
      "        [ 14.2828,   8.3298,   9.9892, -12.1921,  13.4274,  -7.1404],\n",
      "        [ 14.2411,   7.8482,  10.2183, -12.0010,  13.7216,  -7.3450],\n",
      "        [ 14.6844,   8.5119,  10.1970, -12.2183,  13.6675,  -7.4152],\n",
      "        [ 13.9465,   7.9462,  10.1119, -12.0012,  13.2164,  -7.3120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.43438720703125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4675, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2446,  8.2996, 10.1877],\n",
      "        [14.1457,  7.9536,  9.7272],\n",
      "        [14.2552,  8.5309,  9.8139],\n",
      "        [14.2108,  8.3985, 10.1169],\n",
      "        [14.3783,  8.1785, 10.0067],\n",
      "        [14.2325,  8.1253,  9.6798]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.8816, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8665,  13.6266,  -7.1327],\n",
      "        [-11.7213,  13.1736,  -7.3530],\n",
      "        [-11.9324,  13.6342,  -7.1846],\n",
      "        [-11.9362,  13.3989,  -7.3392],\n",
      "        [-12.2211,  13.3596,  -7.1471],\n",
      "        [-12.1107,  13.7761,  -7.5595]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2446,   8.2996,  10.1877, -11.8665,  13.6266,  -7.1327],\n",
      "        [ 14.1457,   7.9536,   9.7272, -11.7213,  13.1736,  -7.3530],\n",
      "        [ 14.2552,   8.5309,   9.8139, -11.9324,  13.6342,  -7.1846],\n",
      "        [ 14.2108,   8.3985,  10.1169, -11.9362,  13.3989,  -7.3392],\n",
      "        [ 14.3783,   8.1785,  10.0067, -12.2211,  13.3596,  -7.1471],\n",
      "        [ 14.2325,   8.1253,   9.6798, -12.1107,  13.7761,  -7.5595]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4541468620300293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0373, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4242,  8.1279,  9.9741],\n",
      "        [14.3250,  8.0560, 10.1232],\n",
      "        [14.2560,  8.2555, 10.0245],\n",
      "        [14.2841,  8.2743, 10.1182],\n",
      "        [14.2227,  8.4440, 10.2678],\n",
      "        [14.6980,  8.6213, 10.0857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2541,  13.2902,  -7.3234],\n",
      "        [-11.9134,  13.3472,  -7.3110],\n",
      "        [-11.8836,  13.3639,  -7.3203],\n",
      "        [-11.8154,  13.2893,  -7.5503],\n",
      "        [-11.7086,  13.4209,  -7.1042],\n",
      "        [-11.6125,  13.2951,  -7.4674]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4242,   8.1279,   9.9741, -12.2541,  13.2902,  -7.3234],\n",
      "        [ 14.3250,   8.0560,  10.1232, -11.9134,  13.3472,  -7.3110],\n",
      "        [ 14.2560,   8.2555,  10.0245, -11.8836,  13.3639,  -7.3203],\n",
      "        [ 14.2841,   8.2743,  10.1182, -11.8154,  13.2893,  -7.5503],\n",
      "        [ 14.2227,   8.4440,  10.2678, -11.7086,  13.4209,  -7.1042],\n",
      "        [ 14.6980,   8.6213,  10.0857, -11.6125,  13.2951,  -7.4674]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.454722285270691\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7550, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3736,  7.9917, 10.0546],\n",
      "        [14.3064,  7.9891,  9.8530],\n",
      "        [14.3794,  8.1232,  9.9410],\n",
      "        [14.2280,  7.8874,  9.6031],\n",
      "        [14.9381,  8.1880, 10.0578],\n",
      "        [14.5026,  7.7344, 10.1756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8512,  13.2390,  -7.4420],\n",
      "        [-12.0722,  13.4586,  -7.3956],\n",
      "        [-11.8563,  13.4100,  -7.1493],\n",
      "        [-12.1453,  13.7314,  -7.2340],\n",
      "        [-11.8837,  13.2957,  -7.2618],\n",
      "        [-11.9700,  13.3857,  -7.2178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3736,   7.9917,  10.0546, -11.8512,  13.2390,  -7.4420],\n",
      "        [ 14.3064,   7.9891,   9.8530, -12.0722,  13.4586,  -7.3956],\n",
      "        [ 14.3794,   8.1232,   9.9410, -11.8563,  13.4100,  -7.1493],\n",
      "        [ 14.2280,   7.8874,   9.6031, -12.1453,  13.7314,  -7.2340],\n",
      "        [ 14.9381,   8.1880,  10.0578, -11.8837,  13.2957,  -7.2618],\n",
      "        [ 14.5026,   7.7344,  10.1756, -11.9700,  13.3857,  -7.2178]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4471511840820312\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3317,  8.0571, 10.1293],\n",
      "        [14.4509,  8.4952, 10.0139],\n",
      "        [14.6272,  8.2401,  9.9168],\n",
      "        [14.6586,  8.6455, 10.3588],\n",
      "        [14.6928,  8.4825, 10.1847],\n",
      "        [14.2656,  8.2385,  9.9334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9199,  13.1513,  -7.5770],\n",
      "        [-12.0404,  13.5736,  -7.6808],\n",
      "        [-11.8535,  13.4337,  -7.2031],\n",
      "        [-11.6502,  13.3494,  -7.1147],\n",
      "        [-11.9320,  13.1115,  -7.1979],\n",
      "        [-12.0556,  13.3249,  -7.5628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3317,   8.0571,  10.1293, -11.9199,  13.1513,  -7.5770],\n",
      "        [ 14.4509,   8.4952,  10.0139, -12.0404,  13.5736,  -7.6808],\n",
      "        [ 14.6272,   8.2401,   9.9168, -11.8535,  13.4337,  -7.2031],\n",
      "        [ 14.6586,   8.6455,  10.3588, -11.6502,  13.3494,  -7.1147],\n",
      "        [ 14.6928,   8.4825,  10.1847, -11.9320,  13.1115,  -7.1979],\n",
      "        [ 14.2656,   8.2385,   9.9334, -12.0556,  13.3249,  -7.5628]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4502191543579102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5888,  8.0352,  9.9846],\n",
      "        [14.0566,  7.8510, 10.0585],\n",
      "        [13.8882,  8.1294,  9.6425],\n",
      "        [14.0517,  8.0577,  9.8701],\n",
      "        [14.4053,  8.3609,  9.8473],\n",
      "        [14.4213,  8.1823, 10.0697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0610, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8153,  13.6124,  -7.3634],\n",
      "        [-11.6520,  13.4698,  -7.4376],\n",
      "        [-11.8726,  13.2803,  -7.0536],\n",
      "        [-12.3623,  13.8021,  -7.6427],\n",
      "        [-11.6472,  13.0135,  -7.1376],\n",
      "        [-11.7858,  13.4209,  -7.2312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5888,   8.0352,   9.9846, -11.8153,  13.6124,  -7.3634],\n",
      "        [ 14.0566,   7.8510,  10.0585, -11.6520,  13.4698,  -7.4376],\n",
      "        [ 13.8882,   8.1294,   9.6425, -11.8726,  13.2803,  -7.0536],\n",
      "        [ 14.0517,   8.0577,   9.8701, -12.3623,  13.8021,  -7.6427],\n",
      "        [ 14.4053,   8.3609,   9.8473, -11.6472,  13.0135,  -7.1376],\n",
      "        [ 14.4213,   8.1823,  10.0697, -11.7858,  13.4209,  -7.2312]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.461409568786621\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3776,  8.2227,  9.9690],\n",
      "        [13.9874,  7.9376,  9.6416],\n",
      "        [14.5319,  8.1260, 10.0517],\n",
      "        [14.6534,  8.3206, 10.0616],\n",
      "        [14.5072,  8.3409, 10.0546],\n",
      "        [14.5070,  8.3080,  9.7846]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0659,  13.7224,  -7.4257],\n",
      "        [-11.6065,  13.3775,  -7.7330],\n",
      "        [-11.6012,  13.6825,  -7.3537],\n",
      "        [-12.0671,  13.6927,  -7.1172],\n",
      "        [-11.7037,  13.3523,  -7.4254],\n",
      "        [-12.1630,  13.5347,  -7.2035]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3776,   8.2227,   9.9690, -12.0659,  13.7224,  -7.4257],\n",
      "        [ 13.9874,   7.9376,   9.6416, -11.6065,  13.3775,  -7.7330],\n",
      "        [ 14.5319,   8.1260,  10.0517, -11.6012,  13.6825,  -7.3537],\n",
      "        [ 14.6534,   8.3206,  10.0616, -12.0671,  13.6927,  -7.1172],\n",
      "        [ 14.5072,   8.3409,  10.0546, -11.7037,  13.3523,  -7.4254],\n",
      "        [ 14.5070,   8.3080,   9.7846, -12.1630,  13.5347,  -7.2035]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4638574123382568\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3709,  8.1933, 10.0063],\n",
      "        [14.5485,  8.3639,  9.9759],\n",
      "        [14.5089,  8.3548, 10.1495],\n",
      "        [14.5151,  8.4220, 10.2758],\n",
      "        [14.2866,  7.8784, 10.1013],\n",
      "        [14.5174,  8.7560, 10.2879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.1184, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2090,  13.8402,  -7.4196],\n",
      "        [-11.8656,  13.6278,  -7.4673],\n",
      "        [-11.5195,  13.2462,  -7.8405],\n",
      "        [-11.9923,  13.4692,  -7.5859],\n",
      "        [-11.9765,  13.1552,  -6.8684],\n",
      "        [-11.6497,  13.4947,  -7.5018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3709,   8.1933,  10.0063, -12.2090,  13.8402,  -7.4196],\n",
      "        [ 14.5485,   8.3639,   9.9759, -11.8656,  13.6278,  -7.4673],\n",
      "        [ 14.5089,   8.3548,  10.1495, -11.5195,  13.2462,  -7.8405],\n",
      "        [ 14.5151,   8.4220,  10.2758, -11.9923,  13.4692,  -7.5859],\n",
      "        [ 14.2866,   7.8784,  10.1013, -11.9765,  13.1552,  -6.8684],\n",
      "        [ 14.5174,   8.7560,  10.2879, -11.6497,  13.4947,  -7.5018]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4695894718170166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7850, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5666,  8.4221, 10.2376],\n",
      "        [14.2677,  8.4564, 10.0142],\n",
      "        [14.5648,  8.5643, 10.3615],\n",
      "        [14.3985,  8.6117, 10.0862],\n",
      "        [14.7096,  8.5034,  9.9678],\n",
      "        [14.4595,  8.1693, 10.0724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0768,  13.6712,  -7.2179],\n",
      "        [-11.7125,  13.3138,  -7.7407],\n",
      "        [-12.1350,  13.5300,  -7.3800],\n",
      "        [-12.0729,  13.5063,  -7.1214],\n",
      "        [-12.0770,  13.7820,  -7.3040],\n",
      "        [-12.1491,  13.5296,  -7.2435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5666,   8.4221,  10.2376, -12.0768,  13.6712,  -7.2179],\n",
      "        [ 14.2677,   8.4564,  10.0142, -11.7125,  13.3138,  -7.7407],\n",
      "        [ 14.5648,   8.5643,  10.3615, -12.1350,  13.5300,  -7.3800],\n",
      "        [ 14.3985,   8.6117,  10.0862, -12.0729,  13.5063,  -7.1214],\n",
      "        [ 14.7096,   8.5034,   9.9678, -12.0770,  13.7820,  -7.3040],\n",
      "        [ 14.4595,   8.1693,  10.0724, -12.1491,  13.5296,  -7.2435]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.4805330038070679\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2790, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4102,  8.4613, 10.2412],\n",
      "        [14.3252,  8.4398,  9.6173],\n",
      "        [14.2676,  8.7070, 10.3586],\n",
      "        [14.1493,  8.5463,  9.6319],\n",
      "        [14.5359,  8.0740,  9.8190],\n",
      "        [14.2228,  8.2079,  9.8673]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2996, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.4540,  13.4626,  -7.6339],\n",
      "        [-12.4786,  13.9787,  -7.3484],\n",
      "        [-12.0201,  13.5654,  -7.4117],\n",
      "        [-11.9799,  13.4102,  -7.5672],\n",
      "        [-11.7303,  13.5595,  -7.3251],\n",
      "        [-12.0274,  13.8680,  -7.3670]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4102,   8.4613,  10.2412, -11.4540,  13.4626,  -7.6339],\n",
      "        [ 14.3252,   8.4398,   9.6173, -12.4786,  13.9787,  -7.3484],\n",
      "        [ 14.2676,   8.7070,  10.3586, -12.0201,  13.5654,  -7.4117],\n",
      "        [ 14.1493,   8.5463,   9.6319, -11.9799,  13.4102,  -7.5672],\n",
      "        [ 14.5359,   8.0740,   9.8190, -11.7303,  13.5595,  -7.3251],\n",
      "        [ 14.2228,   8.2079,   9.8673, -12.0274,  13.8680,  -7.3670]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4657337665557861\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8051,  8.4827, 10.2368],\n",
      "        [14.4024,  8.1484, 10.0052],\n",
      "        [14.7861,  8.5682, 10.3351],\n",
      "        [14.5169,  8.1074,  9.8152],\n",
      "        [14.4793,  8.4480, 10.1049],\n",
      "        [14.3622,  8.3275, 10.3602]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9091,  13.4237,  -7.4523],\n",
      "        [-12.1018,  13.5524,  -7.1190],\n",
      "        [-11.9574,  13.8710,  -7.8705],\n",
      "        [-11.8263,  13.0819,  -7.4082],\n",
      "        [-12.1745,  13.5063,  -7.5416],\n",
      "        [-11.7284,  13.1558,  -7.1531]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8051,   8.4827,  10.2368, -11.9091,  13.4237,  -7.4523],\n",
      "        [ 14.4024,   8.1484,  10.0052, -12.1018,  13.5524,  -7.1190],\n",
      "        [ 14.7861,   8.5682,  10.3351, -11.9574,  13.8710,  -7.8705],\n",
      "        [ 14.5169,   8.1074,   9.8152, -11.8263,  13.0819,  -7.4082],\n",
      "        [ 14.4793,   8.4480,  10.1049, -12.1745,  13.5063,  -7.5416],\n",
      "        [ 14.3622,   8.3275,  10.3602, -11.7284,  13.1558,  -7.1531]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4866423606872559\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3509,  8.0942, 10.0422],\n",
      "        [14.1957,  8.1971, 10.0549],\n",
      "        [14.2070,  8.2067, 10.2948],\n",
      "        [14.5226,  8.1837,  9.9824],\n",
      "        [14.3013,  8.4739,  9.9679],\n",
      "        [13.9418,  8.0142,  9.8418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9716, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0994,  13.7956,  -7.3355],\n",
      "        [-11.8031,  13.0755,  -7.2407],\n",
      "        [-12.2321,  13.5808,  -7.3048],\n",
      "        [-12.1844,  13.4666,  -7.3598],\n",
      "        [-11.9112,  13.4649,  -7.2090],\n",
      "        [-12.1383,  13.7861,  -7.7048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3509,   8.0942,  10.0422, -12.0994,  13.7956,  -7.3355],\n",
      "        [ 14.1957,   8.1971,  10.0549, -11.8031,  13.0755,  -7.2407],\n",
      "        [ 14.2070,   8.2067,  10.2948, -12.2321,  13.5808,  -7.3048],\n",
      "        [ 14.5226,   8.1837,   9.9824, -12.1844,  13.4666,  -7.3598],\n",
      "        [ 14.3013,   8.4739,   9.9679, -11.9112,  13.4649,  -7.2090],\n",
      "        [ 13.9418,   8.0142,   9.8418, -12.1383,  13.7861,  -7.7048]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.468306303024292\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7585, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2103,  8.0553,  9.7423],\n",
      "        [14.2107,  8.6169, 10.0161],\n",
      "        [14.1552,  8.2018, 10.0312],\n",
      "        [14.3729,  8.6182,  9.7608],\n",
      "        [14.5577,  8.3471, 10.0418],\n",
      "        [14.6073,  8.5506, 10.0545]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.6087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3216,  13.5221,  -7.4165],\n",
      "        [-12.3507,  13.6154,  -7.1039],\n",
      "        [-11.8969,  13.3409,  -7.4764],\n",
      "        [-11.7687,  13.4814,  -7.2752],\n",
      "        [-11.9474,  13.2236,  -7.2609],\n",
      "        [-11.7470,  13.6351,  -7.1139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2103,   8.0553,   9.7423, -12.3216,  13.5221,  -7.4165],\n",
      "        [ 14.2107,   8.6169,  10.0161, -12.3507,  13.6154,  -7.1039],\n",
      "        [ 14.1552,   8.2018,  10.0312, -11.8969,  13.3409,  -7.4764],\n",
      "        [ 14.3729,   8.6182,   9.7608, -11.7687,  13.4814,  -7.2752],\n",
      "        [ 14.5577,   8.3471,  10.0418, -11.9474,  13.2236,  -7.2609],\n",
      "        [ 14.6073,   8.5506,  10.0545, -11.7470,  13.6351,  -7.1139]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4542828798294067\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6606,  8.2713, 10.0329],\n",
      "        [14.3483,  8.2066, 10.1115],\n",
      "        [14.4504,  8.2977,  9.8180],\n",
      "        [14.1750,  7.7690, 10.2305],\n",
      "        [14.2404,  8.1783,  9.3815],\n",
      "        [14.5910,  8.4723, 10.1786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3619,  13.5875,  -7.3698],\n",
      "        [-12.1224,  13.6211,  -7.5439],\n",
      "        [-12.0553,  13.5192,  -7.1729],\n",
      "        [-12.1214,  13.5063,  -7.2616],\n",
      "        [-11.9762,  13.5357,  -7.2906],\n",
      "        [-12.1400,  13.3488,  -7.5215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6606,   8.2713,  10.0329, -12.3619,  13.5875,  -7.3698],\n",
      "        [ 14.3483,   8.2066,  10.1115, -12.1224,  13.6211,  -7.5439],\n",
      "        [ 14.4504,   8.2977,   9.8180, -12.0553,  13.5192,  -7.1729],\n",
      "        [ 14.1750,   7.7690,  10.2305, -12.1214,  13.5063,  -7.2616],\n",
      "        [ 14.2404,   8.1783,   9.3815, -11.9762,  13.5357,  -7.2906],\n",
      "        [ 14.5910,   8.4723,  10.1786, -12.1400,  13.3488,  -7.5215]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.484827995300293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0514, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5015,  8.2166, 10.2875],\n",
      "        [14.8953,  8.3699, 10.3175],\n",
      "        [14.1799,  8.2634, 10.2028],\n",
      "        [14.1118,  8.4112,  9.9726],\n",
      "        [14.2514,  8.0461,  9.8358],\n",
      "        [14.1972,  8.6347, 10.1351]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.3028, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0222,  13.8951,  -7.2118],\n",
      "        [-11.9843,  13.4708,  -7.5938],\n",
      "        [-12.2442,  13.7608,  -7.3539],\n",
      "        [-12.2385,  13.6690,  -7.9326],\n",
      "        [-12.2168,  13.9633,  -7.5541],\n",
      "        [-12.0502,  13.5021,  -7.4186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5015,   8.2166,  10.2875, -12.0222,  13.8951,  -7.2118],\n",
      "        [ 14.8953,   8.3699,  10.3175, -11.9843,  13.4708,  -7.5938],\n",
      "        [ 14.1799,   8.2634,  10.2028, -12.2442,  13.7608,  -7.3539],\n",
      "        [ 14.1118,   8.4112,   9.9726, -12.2385,  13.6690,  -7.9326],\n",
      "        [ 14.2514,   8.0461,   9.8358, -12.2168,  13.9633,  -7.5541],\n",
      "        [ 14.1972,   8.6347,  10.1351, -12.0502,  13.5021,  -7.4186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.484740138053894\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5995,  8.3956, 10.4395],\n",
      "        [14.6759,  8.6409, 10.4168],\n",
      "        [14.3495,  8.3421, 10.0295],\n",
      "        [14.3575,  8.5526,  9.8198],\n",
      "        [14.1930,  8.3544, 10.2638],\n",
      "        [14.2430,  8.2531, 10.5103]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.7830,  13.4188,  -7.9249],\n",
      "        [-12.3247,  13.4040,  -7.4036],\n",
      "        [-11.5175,  13.6110,  -7.2567],\n",
      "        [-12.0147,  13.4470,  -7.0127],\n",
      "        [-11.8880,  13.5407,  -7.3926],\n",
      "        [-12.2682,  13.5935,  -7.4178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5995,   8.3956,  10.4395, -11.7830,  13.4188,  -7.9249],\n",
      "        [ 14.6759,   8.6409,  10.4168, -12.3247,  13.4040,  -7.4036],\n",
      "        [ 14.3495,   8.3421,  10.0295, -11.5175,  13.6110,  -7.2567],\n",
      "        [ 14.3575,   8.5526,   9.8198, -12.0147,  13.4470,  -7.0127],\n",
      "        [ 14.1930,   8.3544,  10.2638, -11.8880,  13.5407,  -7.3926],\n",
      "        [ 14.2430,   8.2531,  10.5103, -12.2682,  13.5935,  -7.4178]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4896349906921387\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6593,  8.0951, 10.2431],\n",
      "        [14.8256,  8.5522,  9.9383],\n",
      "        [14.7596,  8.4322,  9.9964],\n",
      "        [14.2879,  8.3659, 10.0295],\n",
      "        [14.6661,  8.5418, 10.2409],\n",
      "        [14.5930,  8.4439,  9.8526]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1410,  13.6220,  -7.5376],\n",
      "        [-12.3116,  13.5018,  -7.6002],\n",
      "        [-12.3525,  13.6343,  -7.3560],\n",
      "        [-12.1590,  13.5033,  -7.5209],\n",
      "        [-12.0861,  13.7457,  -7.0781],\n",
      "        [-12.2851,  13.5496,  -7.4155]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6593,   8.0951,  10.2431, -12.1410,  13.6220,  -7.5376],\n",
      "        [ 14.8256,   8.5522,   9.9383, -12.3116,  13.5018,  -7.6002],\n",
      "        [ 14.7596,   8.4322,   9.9964, -12.3525,  13.6343,  -7.3560],\n",
      "        [ 14.2879,   8.3659,  10.0295, -12.1590,  13.5033,  -7.5209],\n",
      "        [ 14.6661,   8.5418,  10.2409, -12.0861,  13.7457,  -7.0781],\n",
      "        [ 14.5930,   8.4439,   9.8526, -12.2851,  13.5496,  -7.4155]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4888280630111694\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7695, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4410,  8.4097, 10.3670],\n",
      "        [14.5778,  8.4310, 10.2205],\n",
      "        [14.5184,  8.3779, 10.1643],\n",
      "        [14.5634,  8.4248,  9.7011],\n",
      "        [14.4812,  8.5069,  9.9860],\n",
      "        [14.4865,  7.9942,  9.9694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.5910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.6386,  13.6051,  -7.4723],\n",
      "        [-12.2729,  13.7267,  -7.5986],\n",
      "        [-12.0159,  13.6790,  -7.6738],\n",
      "        [-11.9703,  13.3847,  -7.1334],\n",
      "        [-12.1598,  13.5610,  -7.4712],\n",
      "        [-12.3161,  13.5547,  -7.6159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4410,   8.4097,  10.3670, -11.6386,  13.6051,  -7.4723],\n",
      "        [ 14.5778,   8.4310,  10.2205, -12.2729,  13.7267,  -7.5986],\n",
      "        [ 14.5184,   8.3779,  10.1643, -12.0159,  13.6790,  -7.6738],\n",
      "        [ 14.5634,   8.4248,   9.7011, -11.9703,  13.3847,  -7.1334],\n",
      "        [ 14.4812,   8.5069,   9.9860, -12.1598,  13.5610,  -7.4712],\n",
      "        [ 14.4865,   7.9942,   9.9694, -12.3161,  13.5547,  -7.6159]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4808297157287598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0394, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5225,  8.5686, 10.2341],\n",
      "        [14.0750,  8.5321,  9.6793],\n",
      "        [14.5620,  8.3059, 10.1410],\n",
      "        [14.4196,  8.6219, 10.0631],\n",
      "        [14.1524,  8.2281, 10.1637],\n",
      "        [14.2483,  8.3406, 10.1415]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2953, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8846,  13.6514,  -7.1194],\n",
      "        [-11.7878,  13.7664,  -7.5338],\n",
      "        [-11.8119,  13.5317,  -7.3562],\n",
      "        [-11.9397,  13.7640,  -7.4554],\n",
      "        [-11.8580,  13.6100,  -7.4182],\n",
      "        [-12.3002,  13.3339,  -7.6199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5225,   8.5686,  10.2341, -11.8846,  13.6514,  -7.1194],\n",
      "        [ 14.0750,   8.5321,   9.6793, -11.7878,  13.7664,  -7.5338],\n",
      "        [ 14.5620,   8.3059,  10.1410, -11.8119,  13.5317,  -7.3562],\n",
      "        [ 14.4196,   8.6219,  10.0631, -11.9397,  13.7640,  -7.4554],\n",
      "        [ 14.1524,   8.2281,  10.1637, -11.8580,  13.6100,  -7.4182],\n",
      "        [ 14.2483,   8.3406,  10.1415, -12.3002,  13.3339,  -7.6199]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4854553937911987\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3625,  8.2577,  9.8802],\n",
      "        [14.3195,  8.6702, 10.2510],\n",
      "        [14.5273,  8.5893, 10.0454],\n",
      "        [14.5011,  8.7978, 10.0304],\n",
      "        [14.3221,  8.5872, 10.0316],\n",
      "        [14.5788,  8.5513, 10.1407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9078, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3035,  13.5544,  -7.4409],\n",
      "        [-12.0953,  13.5082,  -7.4395],\n",
      "        [-11.9529,  13.5207,  -7.1632],\n",
      "        [-12.2377,  13.5347,  -7.1373],\n",
      "        [-11.6528,  13.4420,  -7.3365],\n",
      "        [-12.4049,  13.7106,  -7.6464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3625,   8.2577,   9.8802, -12.3035,  13.5544,  -7.4409],\n",
      "        [ 14.3195,   8.6702,  10.2510, -12.0953,  13.5082,  -7.4395],\n",
      "        [ 14.5273,   8.5893,  10.0454, -11.9529,  13.5207,  -7.1632],\n",
      "        [ 14.5011,   8.7978,  10.0304, -12.2377,  13.5347,  -7.1373],\n",
      "        [ 14.3221,   8.5872,  10.0316, -11.6528,  13.4420,  -7.3365],\n",
      "        [ 14.5788,   8.5513,  10.1407, -12.4049,  13.7106,  -7.6464]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4736260175704956\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2042,  8.1513, 10.0524],\n",
      "        [14.8578,  8.7503, 10.1279],\n",
      "        [14.3710,  8.2265, 10.1888],\n",
      "        [14.9526,  8.2944, 10.2924],\n",
      "        [14.7322,  8.1762,  9.5725],\n",
      "        [14.5139,  8.0861, 10.3957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3141, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9854,  13.4863,  -7.3846],\n",
      "        [-12.0057,  12.9299,  -7.4202],\n",
      "        [-12.3328,  13.7357,  -7.6773],\n",
      "        [-12.3358,  13.4997,  -7.7663],\n",
      "        [-12.2058,  13.3369,  -7.4185],\n",
      "        [-11.9644,  13.3584,  -7.1829]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2042,   8.1513,  10.0524, -11.9854,  13.4863,  -7.3846],\n",
      "        [ 14.8578,   8.7503,  10.1279, -12.0057,  12.9299,  -7.4202],\n",
      "        [ 14.3710,   8.2265,  10.1888, -12.3328,  13.7357,  -7.6773],\n",
      "        [ 14.9526,   8.2944,  10.2924, -12.3358,  13.4997,  -7.7663],\n",
      "        [ 14.7322,   8.1762,   9.5725, -12.2058,  13.3369,  -7.4185],\n",
      "        [ 14.5139,   8.0861,  10.3957, -11.9644,  13.3584,  -7.1829]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.4644932746887207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7466,  8.4046, 10.2669],\n",
      "        [14.4718,  8.3576, 10.1916],\n",
      "        [14.0293,  8.6171,  9.9216],\n",
      "        [14.5449,  8.6737,  9.9441],\n",
      "        [14.3713,  8.3417, 10.1829],\n",
      "        [14.7548,  8.1752,  9.9313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7596, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3327,  13.6463,  -7.4797],\n",
      "        [-12.1362,  13.8541,  -7.8462],\n",
      "        [-12.1397,  13.6486,  -7.3805],\n",
      "        [-12.3692,  13.6327,  -7.0373],\n",
      "        [-12.3857,  13.3880,  -7.3944],\n",
      "        [-12.2920,  13.3735,  -7.5494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7466,   8.4046,  10.2669, -12.3327,  13.6463,  -7.4797],\n",
      "        [ 14.4718,   8.3576,  10.1916, -12.1362,  13.8541,  -7.8462],\n",
      "        [ 14.0293,   8.6171,   9.9216, -12.1397,  13.6486,  -7.3805],\n",
      "        [ 14.5449,   8.6737,   9.9441, -12.3692,  13.6327,  -7.0373],\n",
      "        [ 14.3713,   8.3417,  10.1829, -12.3857,  13.3880,  -7.3944],\n",
      "        [ 14.7548,   8.1752,   9.9313, -12.2920,  13.3735,  -7.5494]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5053167343139648\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9275, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4216,  8.8159, 10.1472],\n",
      "        [14.4570,  8.6345, 10.0001],\n",
      "        [14.3988,  8.5271, 10.3737],\n",
      "        [14.7456,  8.5984, 10.1374],\n",
      "        [14.7732,  8.3239, 10.1922],\n",
      "        [14.3759,  8.9006,  9.6955]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.8612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0836,  13.7240,  -7.5065],\n",
      "        [-12.0544,  13.4163,  -7.4217],\n",
      "        [-11.9240,  13.3930,  -7.2539],\n",
      "        [-12.1934,  13.6312,  -7.7872],\n",
      "        [-12.1771,  13.6949,  -7.2567],\n",
      "        [-11.9323,  13.1238,  -7.4686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4216,   8.8159,  10.1472, -12.0836,  13.7240,  -7.5065],\n",
      "        [ 14.4570,   8.6345,  10.0001, -12.0544,  13.4163,  -7.4217],\n",
      "        [ 14.3988,   8.5271,  10.3737, -11.9240,  13.3930,  -7.2539],\n",
      "        [ 14.7456,   8.5984,  10.1374, -12.1934,  13.6312,  -7.7872],\n",
      "        [ 14.7732,   8.3239,  10.1922, -12.1771,  13.6949,  -7.2567],\n",
      "        [ 14.3759,   8.9006,   9.6955, -11.9323,  13.1238,  -7.4686]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4950867891311646\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0155, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7977,  8.6480,  9.9808],\n",
      "        [14.3411,  8.1459,  9.9111],\n",
      "        [14.2831,  8.4604, 10.0704],\n",
      "        [14.7790,  8.4440, 10.3025],\n",
      "        [14.3153,  8.5135, 10.2224],\n",
      "        [14.4198,  8.5341, 10.2921]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4454, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2873,  13.4997,  -7.5663],\n",
      "        [-12.3831,  13.6884,  -7.6373],\n",
      "        [-11.9182,  13.7520,  -7.5332],\n",
      "        [-12.1869,  13.4766,  -7.5760],\n",
      "        [-11.9544,  13.9608,  -7.5892],\n",
      "        [-12.2022,  13.7155,  -7.4067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7977,   8.6480,   9.9808, -12.2873,  13.4997,  -7.5663],\n",
      "        [ 14.3411,   8.1459,   9.9111, -12.3831,  13.6884,  -7.6373],\n",
      "        [ 14.2831,   8.4604,  10.0704, -11.9182,  13.7520,  -7.5332],\n",
      "        [ 14.7790,   8.4440,  10.3025, -12.1869,  13.4766,  -7.5760],\n",
      "        [ 14.3153,   8.5135,  10.2224, -11.9544,  13.9608,  -7.5892],\n",
      "        [ 14.4198,   8.5341,  10.2921, -12.2022,  13.7155,  -7.4067]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.502252221107483\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6309,  8.6986, 10.3226],\n",
      "        [13.9347,  8.1603,  9.9660],\n",
      "        [14.6536,  8.7372, 10.3378],\n",
      "        [14.3641,  8.7167, 10.2200],\n",
      "        [14.6604,  8.4476, 10.1260],\n",
      "        [14.5259,  8.5905,  9.9208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4234,  13.6971,  -7.6438],\n",
      "        [-12.3509,  13.6764,  -7.3348],\n",
      "        [-12.1048,  13.3872,  -7.4698],\n",
      "        [-12.3319,  13.9089,  -7.4063],\n",
      "        [-12.1707,  13.8587,  -7.6644],\n",
      "        [-12.3365,  13.6177,  -7.7273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6309,   8.6986,  10.3226, -12.4234,  13.6971,  -7.6438],\n",
      "        [ 13.9347,   8.1603,   9.9660, -12.3509,  13.6764,  -7.3348],\n",
      "        [ 14.6536,   8.7372,  10.3378, -12.1048,  13.3872,  -7.4698],\n",
      "        [ 14.3641,   8.7167,  10.2200, -12.3319,  13.9089,  -7.4063],\n",
      "        [ 14.6604,   8.4476,  10.1260, -12.1707,  13.8587,  -7.6644],\n",
      "        [ 14.5259,   8.5905,   9.9208, -12.3365,  13.6177,  -7.7273]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5140122175216675\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0422, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4845,  8.6436,  9.9578],\n",
      "        [14.3044,  8.1375, 10.4820],\n",
      "        [14.7638,  8.5268, 10.4278],\n",
      "        [15.3146,  8.5093, 10.1641],\n",
      "        [14.2510,  8.4207, 10.0161],\n",
      "        [14.9321,  8.7634, 10.0560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9474,  13.7573,  -7.5370],\n",
      "        [-11.9126,  13.3788,  -7.5451],\n",
      "        [-12.3480,  13.8919,  -7.5806],\n",
      "        [-11.9390,  13.4497,  -7.1376],\n",
      "        [-11.9815,  13.4631,  -7.6106],\n",
      "        [-12.2155,  13.7974,  -7.6272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4845,   8.6436,   9.9578, -11.9474,  13.7573,  -7.5370],\n",
      "        [ 14.3044,   8.1375,  10.4820, -11.9126,  13.3788,  -7.5451],\n",
      "        [ 14.7638,   8.5268,  10.4278, -12.3480,  13.8919,  -7.5806],\n",
      "        [ 15.3146,   8.5093,  10.1641, -11.9390,  13.4497,  -7.1376],\n",
      "        [ 14.2510,   8.4207,  10.0161, -11.9815,  13.4631,  -7.6106],\n",
      "        [ 14.9321,   8.7634,  10.0560, -12.2155,  13.7974,  -7.6272]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4906444549560547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7708,  8.6571, 10.1443],\n",
      "        [14.4985,  8.5109,  9.7967],\n",
      "        [14.9457,  8.6480,  9.8876],\n",
      "        [14.5378,  8.2588,  9.5872],\n",
      "        [14.4500,  8.6933, 10.0184],\n",
      "        [14.3904,  8.7001, 10.0235]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2472,  13.9056,  -7.5686],\n",
      "        [-12.1294,  13.3351,  -7.9686],\n",
      "        [-12.3615,  13.7410,  -7.7244],\n",
      "        [-12.1442,  13.6647,  -7.0958],\n",
      "        [-11.7545,  13.7644,  -7.3238],\n",
      "        [-12.3029,  14.0800,  -8.0224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7708,   8.6571,  10.1443, -12.2472,  13.9056,  -7.5686],\n",
      "        [ 14.4985,   8.5109,   9.7967, -12.1294,  13.3351,  -7.9686],\n",
      "        [ 14.9457,   8.6480,   9.8876, -12.3615,  13.7410,  -7.7244],\n",
      "        [ 14.5378,   8.2588,   9.5872, -12.1442,  13.6647,  -7.0958],\n",
      "        [ 14.4500,   8.6933,  10.0184, -11.7545,  13.7644,  -7.3238],\n",
      "        [ 14.3904,   8.7001,  10.0235, -12.3029,  14.0800,  -8.0224]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.5157538652420044\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4600, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.3759,  8.5765, 10.0625],\n",
      "        [14.8701,  9.0992, 10.2117],\n",
      "        [14.3666,  8.4158,  9.8085],\n",
      "        [14.3211,  8.3062, 10.3760],\n",
      "        [14.2754,  8.0563, 10.1554],\n",
      "        [14.4890,  8.8683, 10.2865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.9063, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.5588,  13.7096,  -7.6063],\n",
      "        [-12.1955,  13.9208,  -7.5577],\n",
      "        [-12.1882,  13.9432,  -7.7641],\n",
      "        [-12.1110,  13.6195,  -7.7019],\n",
      "        [-12.0009,  13.9293,  -7.6227],\n",
      "        [-12.3927,  14.0385,  -7.7989]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.3759,   8.5765,  10.0625, -11.5588,  13.7096,  -7.6063],\n",
      "        [ 14.8701,   9.0992,  10.2117, -12.1955,  13.9208,  -7.5577],\n",
      "        [ 14.3666,   8.4158,   9.8085, -12.1882,  13.9432,  -7.7641],\n",
      "        [ 14.3211,   8.3062,  10.3760, -12.1110,  13.6195,  -7.7019],\n",
      "        [ 14.2754,   8.0563,  10.1554, -12.0009,  13.9293,  -7.6227],\n",
      "        [ 14.4890,   8.8683,  10.2865, -12.3927,  14.0385,  -7.7989]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.4833365678787231\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6853,  8.9606, 10.3629],\n",
      "        [14.4654,  8.3202, 10.2364],\n",
      "        [14.7896,  8.7003, 10.2750],\n",
      "        [14.2351,  8.4094,  9.8844],\n",
      "        [14.7934,  8.9617, 10.5289],\n",
      "        [14.6531,  8.6123, 10.3599]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5662,  13.9108,  -7.9790],\n",
      "        [-12.3099,  13.6764,  -7.4225],\n",
      "        [-12.2989,  13.4599,  -7.4659],\n",
      "        [-12.2009,  13.9232,  -7.3522],\n",
      "        [-12.2979,  14.0794,  -7.9176],\n",
      "        [-12.5662,  13.8092,  -7.7789]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6853,   8.9606,  10.3629, -12.5662,  13.9108,  -7.9790],\n",
      "        [ 14.4654,   8.3202,  10.2364, -12.3099,  13.6764,  -7.4225],\n",
      "        [ 14.7896,   8.7003,  10.2750, -12.2989,  13.4599,  -7.4659],\n",
      "        [ 14.2351,   8.4094,   9.8844, -12.2009,  13.9232,  -7.3522],\n",
      "        [ 14.7934,   8.9617,  10.5289, -12.2979,  14.0794,  -7.9176],\n",
      "        [ 14.6531,   8.6123,  10.3599, -12.5662,  13.8092,  -7.7789]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5346369743347168\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5200,  8.4924, 10.3943],\n",
      "        [14.8322,  8.9683, 10.6371],\n",
      "        [14.3704,  8.5583, 10.3197],\n",
      "        [14.7042,  8.7722, 10.2362],\n",
      "        [14.5102,  8.4635,  9.9210],\n",
      "        [14.4095,  7.9103, 10.0792]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.6373, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1242,  13.6445,  -7.4334],\n",
      "        [-12.1997,  13.5829,  -7.6432],\n",
      "        [-11.8809,  14.0746,  -7.5193],\n",
      "        [-12.0056,  13.5102,  -7.4500],\n",
      "        [-12.2654,  13.8806,  -7.8396],\n",
      "        [-12.3387,  13.8322,  -7.7809]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5200,   8.4924,  10.3943, -12.1242,  13.6445,  -7.4334],\n",
      "        [ 14.8322,   8.9683,  10.6371, -12.1997,  13.5829,  -7.6432],\n",
      "        [ 14.3704,   8.5583,  10.3197, -11.8809,  14.0746,  -7.5193],\n",
      "        [ 14.7042,   8.7722,  10.2362, -12.0056,  13.5102,  -7.4500],\n",
      "        [ 14.5102,   8.4635,   9.9210, -12.2654,  13.8806,  -7.8396],\n",
      "        [ 14.4095,   7.9103,  10.0792, -12.3387,  13.8322,  -7.7809]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.504958152770996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7968,  8.4561, 10.2891],\n",
      "        [14.9269,  8.7599, 10.3455],\n",
      "        [14.6368,  8.5010, 10.2710],\n",
      "        [14.9504,  8.8190, 10.4428],\n",
      "        [14.6865,  8.6200, 10.2840],\n",
      "        [14.6358,  8.4240, 10.4161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5532,  13.6940,  -7.6829],\n",
      "        [-12.1519,  13.4640,  -7.3538],\n",
      "        [-12.4138,  13.5859,  -7.3365],\n",
      "        [-12.0875,  13.8141,  -7.3936],\n",
      "        [-12.1309,  13.4575,  -7.4507],\n",
      "        [-11.8164,  13.6915,  -7.3962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7968,   8.4561,  10.2891, -12.5532,  13.6940,  -7.6829],\n",
      "        [ 14.9269,   8.7599,  10.3455, -12.1519,  13.4640,  -7.3538],\n",
      "        [ 14.6368,   8.5010,  10.2710, -12.4138,  13.5859,  -7.3365],\n",
      "        [ 14.9504,   8.8190,  10.4428, -12.0875,  13.8141,  -7.3936],\n",
      "        [ 14.6865,   8.6200,  10.2840, -12.1309,  13.4575,  -7.4507],\n",
      "        [ 14.6358,   8.4240,  10.4161, -11.8164,  13.6915,  -7.3962]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5231359004974365\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.2784,  8.1875, 10.3497],\n",
      "        [14.8724,  8.5845, 10.3148],\n",
      "        [14.7851,  8.6307, 10.2089],\n",
      "        [14.8491,  8.4487, 10.5607],\n",
      "        [14.7108,  8.4968, 10.4369],\n",
      "        [14.4719,  8.6230, 10.0239]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.1731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1335,  13.9765,  -7.7251],\n",
      "        [-12.7084,  14.2201,  -7.8512],\n",
      "        [-11.9742,  13.7656,  -7.3229],\n",
      "        [-12.5589,  14.3708,  -7.8358],\n",
      "        [-11.8991,  13.7889,  -7.4915],\n",
      "        [-12.3536,  13.6462,  -7.6839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.2784,   8.1875,  10.3497, -12.1335,  13.9765,  -7.7251],\n",
      "        [ 14.8724,   8.5845,  10.3148, -12.7084,  14.2201,  -7.8512],\n",
      "        [ 14.7851,   8.6307,  10.2089, -11.9742,  13.7656,  -7.3229],\n",
      "        [ 14.8491,   8.4487,  10.5607, -12.5589,  14.3708,  -7.8358],\n",
      "        [ 14.7108,   8.4968,  10.4369, -11.8991,  13.7889,  -7.4915],\n",
      "        [ 14.4719,   8.6230,  10.0239, -12.3536,  13.6462,  -7.6839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5007455348968506\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7465, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8716,  8.6030, 10.3215],\n",
      "        [14.5591,  8.3681, 10.4568],\n",
      "        [14.3818,  8.1899,  9.9440],\n",
      "        [14.4634,  8.5062, 10.0055],\n",
      "        [14.8300,  8.5277, 10.4455],\n",
      "        [14.5390,  8.0523,  9.9156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0653, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3378,  13.6383,  -7.7637],\n",
      "        [-12.1917,  13.8224,  -7.5441],\n",
      "        [-12.5099,  14.0670,  -7.9274],\n",
      "        [-12.1551,  13.6889,  -7.4371],\n",
      "        [-11.9482,  13.7413,  -7.3684],\n",
      "        [-12.4433,  14.0161,  -7.4998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8716,   8.6030,  10.3215, -12.3378,  13.6383,  -7.7637],\n",
      "        [ 14.5591,   8.3681,  10.4568, -12.1917,  13.8224,  -7.5441],\n",
      "        [ 14.3818,   8.1899,   9.9440, -12.5099,  14.0670,  -7.9274],\n",
      "        [ 14.4634,   8.5062,  10.0055, -12.1551,  13.6889,  -7.4371],\n",
      "        [ 14.8300,   8.5277,  10.4455, -11.9482,  13.7413,  -7.3684],\n",
      "        [ 14.5390,   8.0523,   9.9156, -12.4433,  14.0161,  -7.4998]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.527055025100708\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6934, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6534,  8.7217, 10.3290],\n",
      "        [14.3921,  8.4149, 10.0259],\n",
      "        [14.7811,  8.8425, 10.4509],\n",
      "        [14.5522,  8.6430, 10.3609],\n",
      "        [14.5570,  8.6625, 10.2857],\n",
      "        [15.2390,  9.1182, 10.7189]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.6332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0260,  13.1707,  -7.7424],\n",
      "        [-12.1229,  14.0208,  -7.7472],\n",
      "        [-12.0927,  14.0426,  -7.7311],\n",
      "        [-12.1045,  13.6400,  -7.4564],\n",
      "        [-12.7195,  13.8409,  -7.8677],\n",
      "        [-11.7832,  13.4324,  -7.8723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6534,   8.7217,  10.3290, -12.0260,  13.1707,  -7.7424],\n",
      "        [ 14.3921,   8.4149,  10.0259, -12.1229,  14.0208,  -7.7472],\n",
      "        [ 14.7811,   8.8425,  10.4509, -12.0927,  14.0426,  -7.7311],\n",
      "        [ 14.5522,   8.6430,  10.3609, -12.1045,  13.6400,  -7.4564],\n",
      "        [ 14.5570,   8.6625,  10.2857, -12.7195,  13.8409,  -7.8677],\n",
      "        [ 15.2390,   9.1182,  10.7189, -11.7832,  13.4324,  -7.8723]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5074458122253418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8362,  8.6427, 10.3439],\n",
      "        [14.7729,  8.7650, 10.3867],\n",
      "        [14.6080,  8.4171, 10.0940],\n",
      "        [14.3395,  8.0689, 10.1957],\n",
      "        [14.5279,  8.2333,  9.8820],\n",
      "        [14.5190,  8.6599,  9.6988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0102,  13.5876,  -7.7616],\n",
      "        [-12.2128,  13.9815,  -7.6522],\n",
      "        [-11.9529,  13.8414,  -7.6162],\n",
      "        [-12.4244,  13.9661,  -7.7790],\n",
      "        [-11.9509,  13.7259,  -7.3122],\n",
      "        [-11.8927,  13.9032,  -7.7856]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8362,   8.6427,  10.3439, -12.0102,  13.5876,  -7.7616],\n",
      "        [ 14.7729,   8.7650,  10.3867, -12.2128,  13.9815,  -7.6522],\n",
      "        [ 14.6080,   8.4171,  10.0940, -11.9529,  13.8414,  -7.6162],\n",
      "        [ 14.3395,   8.0689,  10.1957, -12.4244,  13.9661,  -7.7790],\n",
      "        [ 14.5279,   8.2333,   9.8820, -11.9509,  13.7259,  -7.3122],\n",
      "        [ 14.5190,   8.6599,   9.6988, -11.8927,  13.9032,  -7.7856]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5222582817077637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8806,  8.5245, 10.2824],\n",
      "        [14.3619,  8.3208, 10.0134],\n",
      "        [14.4132,  8.7000,  9.9478],\n",
      "        [14.9710,  8.6670, 10.0061],\n",
      "        [14.8140,  8.5945, 10.2598],\n",
      "        [14.9538,  8.8698, 10.3925]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2608, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4536,  14.2154,  -7.5910],\n",
      "        [-12.3377,  14.0639,  -7.7718],\n",
      "        [-12.1803,  14.0627,  -7.9636],\n",
      "        [-12.3638,  13.6312,  -7.4373],\n",
      "        [-12.0476,  13.3295,  -7.0114],\n",
      "        [-12.1068,  13.6990,  -7.9109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8806,   8.5245,  10.2824, -12.4536,  14.2154,  -7.5910],\n",
      "        [ 14.3619,   8.3208,  10.0134, -12.3377,  14.0639,  -7.7718],\n",
      "        [ 14.4132,   8.7000,   9.9478, -12.1803,  14.0627,  -7.9636],\n",
      "        [ 14.9710,   8.6670,  10.0061, -12.3638,  13.6312,  -7.4373],\n",
      "        [ 14.8140,   8.5945,  10.2598, -12.0476,  13.3295,  -7.0114],\n",
      "        [ 14.9538,   8.8698,  10.3925, -12.1068,  13.6990,  -7.9109]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5392515659332275\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6982,  8.7899, 10.4953],\n",
      "        [14.7282,  8.6482, 10.7708],\n",
      "        [14.4898,  8.4271, 10.5978],\n",
      "        [14.8934,  8.8620, 10.4592],\n",
      "        [15.1429,  9.0238, 10.6944],\n",
      "        [14.4585,  8.1669, 10.1550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8781, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.8248,  13.4567,  -7.8782],\n",
      "        [-12.0966,  13.6608,  -7.7375],\n",
      "        [-12.4771,  13.9092,  -7.8209],\n",
      "        [-12.5176,  14.1628,  -8.1093],\n",
      "        [-12.3895,  13.8370,  -7.8266],\n",
      "        [-12.2540,  13.7223,  -8.0031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6982,   8.7899,  10.4953, -11.8248,  13.4567,  -7.8782],\n",
      "        [ 14.7282,   8.6482,  10.7708, -12.0966,  13.6608,  -7.7375],\n",
      "        [ 14.4898,   8.4271,  10.5978, -12.4771,  13.9092,  -7.8209],\n",
      "        [ 14.8934,   8.8620,  10.4592, -12.5176,  14.1628,  -8.1093],\n",
      "        [ 15.1429,   9.0238,  10.6944, -12.3895,  13.8370,  -7.8266],\n",
      "        [ 14.4585,   8.1669,  10.1550, -12.2540,  13.7223,  -8.0031]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.520931601524353\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5238, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7677,  8.5540, 10.2512],\n",
      "        [14.7314,  8.4182, 10.5636],\n",
      "        [14.4364,  8.4011, 10.2260],\n",
      "        [14.7070,  8.6190, 10.4198],\n",
      "        [14.5481,  8.2924, 10.4100],\n",
      "        [14.6825,  8.6656, 10.0842]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3056,  13.7760,  -7.6447],\n",
      "        [-12.0623,  13.9797,  -7.4390],\n",
      "        [-12.4407,  13.9661,  -7.6700],\n",
      "        [-12.0312,  14.0150,  -7.1088],\n",
      "        [-12.3683,  14.0585,  -7.6206],\n",
      "        [-12.2954,  13.9094,  -7.7700]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7677,   8.5540,  10.2512, -12.3056,  13.7760,  -7.6447],\n",
      "        [ 14.7314,   8.4182,  10.5636, -12.0623,  13.9797,  -7.4390],\n",
      "        [ 14.4364,   8.4011,  10.2260, -12.4407,  13.9661,  -7.6700],\n",
      "        [ 14.7070,   8.6190,  10.4198, -12.0312,  14.0150,  -7.1088],\n",
      "        [ 14.5481,   8.2924,  10.4100, -12.3683,  14.0585,  -7.6206],\n",
      "        [ 14.6825,   8.6656,  10.0842, -12.2954,  13.9094,  -7.7700]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5259084701538086\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4500,  8.5320, 10.3297],\n",
      "        [14.4828,  8.2349, 10.0197],\n",
      "        [14.8649,  8.4067, 10.5120],\n",
      "        [14.8568,  8.5618, 10.2469],\n",
      "        [14.7133,  8.7821, 10.4780],\n",
      "        [14.9293,  8.5191, 10.1172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1369,  13.7332,  -7.4258],\n",
      "        [-12.0132,  13.6382,  -7.7936],\n",
      "        [-12.3589,  13.3176,  -7.5194],\n",
      "        [-12.2936,  14.0042,  -7.8948],\n",
      "        [-12.2711,  13.6650,  -7.8226],\n",
      "        [-11.9906,  14.1117,  -7.4409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4500,   8.5320,  10.3297, -12.1369,  13.7332,  -7.4258],\n",
      "        [ 14.4828,   8.2349,  10.0197, -12.0132,  13.6382,  -7.7936],\n",
      "        [ 14.8649,   8.4067,  10.5120, -12.3589,  13.3176,  -7.5194],\n",
      "        [ 14.8568,   8.5618,  10.2469, -12.2936,  14.0042,  -7.8948],\n",
      "        [ 14.7133,   8.7821,  10.4780, -12.2711,  13.6650,  -7.8226],\n",
      "        [ 14.9293,   8.5191,  10.1172, -11.9906,  14.1117,  -7.4409]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.5110142230987549\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7940,  8.1925, 10.2531],\n",
      "        [15.1225,  9.0241, 10.4331],\n",
      "        [14.4528,  8.7529,  9.9982],\n",
      "        [14.9858,  8.9509, 10.3531],\n",
      "        [14.7447,  8.5704, 10.4224],\n",
      "        [14.6409,  8.6147, 10.1145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.4207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3490,  13.9823,  -7.8261],\n",
      "        [-12.4214,  13.8759,  -7.6342],\n",
      "        [-12.1408,  14.0723,  -7.6853],\n",
      "        [-12.5560,  13.7661,  -7.9760],\n",
      "        [-11.8603,  13.6263,  -7.1860],\n",
      "        [-12.1410,  13.7623,  -7.8758]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7940,   8.1925,  10.2531, -12.3490,  13.9823,  -7.8261],\n",
      "        [ 15.1225,   9.0241,  10.4331, -12.4214,  13.8759,  -7.6342],\n",
      "        [ 14.4528,   8.7529,   9.9982, -12.1408,  14.0723,  -7.6853],\n",
      "        [ 14.9858,   8.9509,  10.3531, -12.5560,  13.7661,  -7.9760],\n",
      "        [ 14.7447,   8.5704,  10.4224, -11.8603,  13.6263,  -7.1860],\n",
      "        [ 14.6409,   8.6147,  10.1145, -12.1410,  13.7623,  -7.8758]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5291887521743774\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0453, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4834,  8.2970, 10.5124],\n",
      "        [14.6814,  8.6789, 10.3047],\n",
      "        [14.8719,  8.9128, 10.4633],\n",
      "        [14.8917,  8.6569, 10.2964],\n",
      "        [14.6786,  8.2646, 10.0923],\n",
      "        [15.0333,  8.8910, 10.0687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6701,  14.0117,  -7.4280],\n",
      "        [-12.1702,  13.3266,  -7.9468],\n",
      "        [-12.3884,  13.7247,  -7.5232],\n",
      "        [-12.3182,  13.9308,  -7.9440],\n",
      "        [-12.3134,  14.2171,  -7.7235],\n",
      "        [-12.1899,  13.8412,  -7.6689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4834,   8.2970,  10.5124, -12.6701,  14.0117,  -7.4280],\n",
      "        [ 14.6814,   8.6789,  10.3047, -12.1702,  13.3266,  -7.9468],\n",
      "        [ 14.8719,   8.9128,  10.4633, -12.3884,  13.7247,  -7.5232],\n",
      "        [ 14.8917,   8.6569,  10.2964, -12.3182,  13.9308,  -7.9440],\n",
      "        [ 14.6786,   8.2646,  10.0923, -12.3134,  14.2171,  -7.7235],\n",
      "        [ 15.0333,   8.8910,  10.0687, -12.1899,  13.8412,  -7.6689]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5297350883483887\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4467, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7755,  8.4619, 10.5871],\n",
      "        [14.3817,  8.4514, 10.1668],\n",
      "        [15.0852,  8.7222, 10.4349],\n",
      "        [14.7415,  8.3879, 10.3943],\n",
      "        [14.8039,  8.4296, 10.4063],\n",
      "        [14.2344,  8.4595, 10.1964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.8357, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4592,  13.9071,  -7.9757],\n",
      "        [-12.3302,  13.7307,  -7.7360],\n",
      "        [-12.4919,  13.5150,  -7.5082],\n",
      "        [-12.5467,  13.8686,  -8.0304],\n",
      "        [-12.2495,  13.6407,  -7.5413],\n",
      "        [-12.6155,  14.0255,  -7.6374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7755,   8.4619,  10.5871, -12.4592,  13.9071,  -7.9757],\n",
      "        [ 14.3817,   8.4514,  10.1668, -12.3302,  13.7307,  -7.7360],\n",
      "        [ 15.0852,   8.7222,  10.4349, -12.4919,  13.5150,  -7.5082],\n",
      "        [ 14.7415,   8.3879,  10.3943, -12.5467,  13.8686,  -8.0304],\n",
      "        [ 14.8039,   8.4296,  10.4063, -12.2495,  13.6407,  -7.5413],\n",
      "        [ 14.2344,   8.4595,  10.1964, -12.6155,  14.0255,  -7.6374]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5458778142929077\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7309, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9491,  8.8425, 10.1038],\n",
      "        [14.3806,  8.3033, 10.3690],\n",
      "        [14.8929,  8.8591, 10.4209],\n",
      "        [14.1716,  8.1981, 10.0456],\n",
      "        [14.9105,  8.6306, 10.4104],\n",
      "        [15.0105,  8.7478, 10.3316]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0521, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1215,  13.6331,  -7.8449],\n",
      "        [-12.1533,  13.6393,  -7.9234],\n",
      "        [-12.4285,  13.8791,  -7.7818],\n",
      "        [-12.5793,  14.1052,  -7.6395],\n",
      "        [-11.9912,  14.0118,  -7.8931],\n",
      "        [-12.3225,  13.8689,  -7.9162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9491,   8.8425,  10.1038, -12.1215,  13.6331,  -7.8449],\n",
      "        [ 14.3806,   8.3033,  10.3690, -12.1533,  13.6393,  -7.9234],\n",
      "        [ 14.8929,   8.8591,  10.4209, -12.4285,  13.8791,  -7.7818],\n",
      "        [ 14.1716,   8.1981,  10.0456, -12.5793,  14.1052,  -7.6395],\n",
      "        [ 14.9105,   8.6306,  10.4104, -11.9912,  14.0118,  -7.8931],\n",
      "        [ 15.0105,   8.7478,  10.3316, -12.3225,  13.8689,  -7.9162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5337797403335571\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9908, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0046,  8.4288,  9.7869],\n",
      "        [14.7173,  8.8599, 10.4805],\n",
      "        [14.4377,  8.9977, 10.3987],\n",
      "        [14.8621,  8.4669, 10.3973],\n",
      "        [14.5999,  8.6941, 10.1503],\n",
      "        [14.2688,  8.8890, 10.8354]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4403, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-11.9688,  13.3728,  -8.0095],\n",
      "        [-12.3689,  13.7427,  -7.6613],\n",
      "        [-12.2904,  13.6469,  -8.0766],\n",
      "        [-12.3351,  13.8303,  -7.7272],\n",
      "        [-12.0446,  13.3419,  -7.6493],\n",
      "        [-12.6268,  14.3513,  -7.5945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0046,   8.4288,   9.7869, -11.9688,  13.3728,  -8.0095],\n",
      "        [ 14.7173,   8.8599,  10.4805, -12.3689,  13.7427,  -7.6613],\n",
      "        [ 14.4377,   8.9977,  10.3987, -12.2904,  13.6469,  -8.0766],\n",
      "        [ 14.8621,   8.4669,  10.3973, -12.3351,  13.8303,  -7.7272],\n",
      "        [ 14.5999,   8.6941,  10.1503, -12.0446,  13.3419,  -7.6493],\n",
      "        [ 14.2688,   8.8890,  10.8354, -12.6268,  14.3513,  -7.5945]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.514904260635376\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9006,  8.6485, 10.6195],\n",
      "        [14.6943,  8.6487, 10.4116],\n",
      "        [14.3030,  8.5210, 10.2040],\n",
      "        [14.8356,  8.5157, 10.3349],\n",
      "        [15.1716,  9.0854, 10.4212],\n",
      "        [14.8796,  8.7045, 10.2875]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5240,  14.0536,  -7.9666],\n",
      "        [-12.4488,  13.7858,  -7.6878],\n",
      "        [-12.3637,  13.8277,  -8.1039],\n",
      "        [-12.5734,  13.5124,  -7.6959],\n",
      "        [-12.4435,  14.0073,  -7.5814],\n",
      "        [-12.5909,  13.8656,  -7.8577]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9006,   8.6485,  10.6195, -12.5240,  14.0536,  -7.9666],\n",
      "        [ 14.6943,   8.6487,  10.4116, -12.4488,  13.7858,  -7.6878],\n",
      "        [ 14.3030,   8.5210,  10.2040, -12.3637,  13.8277,  -8.1039],\n",
      "        [ 14.8356,   8.5157,  10.3349, -12.5734,  13.5124,  -7.6959],\n",
      "        [ 15.1716,   9.0854,  10.4212, -12.4435,  14.0073,  -7.5814],\n",
      "        [ 14.8796,   8.7045,  10.2875, -12.5909,  13.8656,  -7.8577]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.561151385307312\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8676,  8.6765, 10.5511],\n",
      "        [14.3157,  8.4757,  9.9905],\n",
      "        [14.9749,  8.7443, 10.5805],\n",
      "        [14.6026,  8.7089, 10.1229],\n",
      "        [14.8361,  8.7673, 10.2395],\n",
      "        [14.7562,  8.8509, 10.6145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4745, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7031,  14.0244,  -7.8621],\n",
      "        [-12.6289,  14.0481,  -7.7475],\n",
      "        [-12.4489,  14.3300,  -7.6411],\n",
      "        [-12.3262,  13.8335,  -7.6169],\n",
      "        [-12.1679,  13.4300,  -7.4078],\n",
      "        [-12.0053,  13.6102,  -7.8684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8676,   8.6765,  10.5511, -12.7031,  14.0244,  -7.8621],\n",
      "        [ 14.3157,   8.4757,   9.9905, -12.6289,  14.0481,  -7.7475],\n",
      "        [ 14.9749,   8.7443,  10.5805, -12.4489,  14.3300,  -7.6411],\n",
      "        [ 14.6026,   8.7089,  10.1229, -12.3262,  13.8335,  -7.6169],\n",
      "        [ 14.8361,   8.7673,  10.2395, -12.1679,  13.4300,  -7.4078],\n",
      "        [ 14.7562,   8.8509,  10.6145, -12.0053,  13.6102,  -7.8684]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5608810186386108\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7213,  8.7369, 10.1091],\n",
      "        [14.6764,  8.8133, 10.6106],\n",
      "        [14.7478,  8.4775, 10.6547],\n",
      "        [15.1426,  8.8801, 10.3181],\n",
      "        [14.7162,  8.7408, 10.6349],\n",
      "        [14.9468,  8.5129, 10.1737]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9496, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7777,  14.3967,  -7.9308],\n",
      "        [-12.5802,  13.8833,  -7.9789],\n",
      "        [-11.8231,  13.8269,  -7.6161],\n",
      "        [-12.1950,  13.6811,  -7.5102],\n",
      "        [-12.6325,  14.2409,  -8.0393],\n",
      "        [-12.6061,  14.0088,  -8.2647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7213,   8.7369,  10.1091, -12.7777,  14.3967,  -7.9308],\n",
      "        [ 14.6764,   8.8133,  10.6106, -12.5802,  13.8833,  -7.9789],\n",
      "        [ 14.7478,   8.4775,  10.6547, -11.8231,  13.8269,  -7.6161],\n",
      "        [ 15.1426,   8.8801,  10.3181, -12.1950,  13.6811,  -7.5102],\n",
      "        [ 14.7162,   8.7408,  10.6349, -12.6325,  14.2409,  -8.0393],\n",
      "        [ 14.9468,   8.5129,  10.1737, -12.6061,  14.0088,  -8.2647]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5541555881500244\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8281, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6978,  8.7026, 10.4634],\n",
      "        [15.1917,  8.7708, 10.2947],\n",
      "        [14.6704,  9.0450, 10.1805],\n",
      "        [15.3402,  8.8140, 10.3551],\n",
      "        [14.6914,  8.6679, 10.2181],\n",
      "        [15.0954,  8.7802, 10.6633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7164, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2165,  13.7400,  -7.9889],\n",
      "        [-12.3564,  13.7336,  -7.4971],\n",
      "        [-12.3588,  14.0442,  -7.8831],\n",
      "        [-12.3626,  14.0107,  -8.0352],\n",
      "        [-12.2231,  13.8917,  -7.5147],\n",
      "        [-12.3686,  13.7080,  -7.9359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6978,   8.7026,  10.4634, -12.2165,  13.7400,  -7.9889],\n",
      "        [ 15.1917,   8.7708,  10.2947, -12.3564,  13.7336,  -7.4971],\n",
      "        [ 14.6704,   9.0450,  10.1805, -12.3588,  14.0442,  -7.8831],\n",
      "        [ 15.3402,   8.8140,  10.3551, -12.3626,  14.0107,  -8.0352],\n",
      "        [ 14.6914,   8.6679,  10.2181, -12.2231,  13.8917,  -7.5147],\n",
      "        [ 15.0954,   8.7802,  10.6633, -12.3686,  13.7080,  -7.9359]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.541643738746643\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7324,  8.7432,  9.9915],\n",
      "        [14.8063,  8.6932, 10.5136],\n",
      "        [14.6725,  8.6999, 10.3449],\n",
      "        [14.6094,  8.3317, 10.2469],\n",
      "        [14.8083,  8.3689, 10.3913],\n",
      "        [14.8722,  8.6784, 10.6212]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0105,  13.7573,  -7.7978],\n",
      "        [-12.2715,  14.0294,  -7.9105],\n",
      "        [-12.9688,  13.9298,  -8.1011],\n",
      "        [-12.3913,  14.0532,  -7.8225],\n",
      "        [-12.3606,  14.0488,  -7.8968],\n",
      "        [-12.2895,  13.7802,  -8.1549]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7324,   8.7432,   9.9915, -12.0105,  13.7573,  -7.7978],\n",
      "        [ 14.8063,   8.6932,  10.5136, -12.2715,  14.0294,  -7.9105],\n",
      "        [ 14.6725,   8.6999,  10.3449, -12.9688,  13.9298,  -8.1011],\n",
      "        [ 14.6094,   8.3317,  10.2469, -12.3913,  14.0532,  -7.8225],\n",
      "        [ 14.8083,   8.3689,  10.3913, -12.3606,  14.0488,  -7.8968],\n",
      "        [ 14.8722,   8.6784,  10.6212, -12.2895,  13.7802,  -8.1549]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5263067483901978\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8745,  9.0099, 10.5192],\n",
      "        [14.4765,  8.2819, 10.2534],\n",
      "        [14.9934,  8.8057, 10.7023],\n",
      "        [15.1600,  8.5880,  9.9826],\n",
      "        [14.9286,  8.8844, 10.4295],\n",
      "        [15.2239,  9.1015, 10.2872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2302, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2913,  13.8471,  -7.9756],\n",
      "        [-12.2814,  14.1010,  -7.7939],\n",
      "        [-12.0797,  14.0916,  -7.9060],\n",
      "        [-12.2098,  13.9730,  -7.7904],\n",
      "        [-12.5221,  14.0911,  -7.6656],\n",
      "        [-12.0582,  14.1718,  -8.1040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8745,   9.0099,  10.5192, -12.2913,  13.8471,  -7.9756],\n",
      "        [ 14.4765,   8.2819,  10.2534, -12.2814,  14.1010,  -7.7939],\n",
      "        [ 14.9934,   8.8057,  10.7023, -12.0797,  14.0916,  -7.9060],\n",
      "        [ 15.1600,   8.5880,   9.9826, -12.2098,  13.9730,  -7.7904],\n",
      "        [ 14.9286,   8.8844,  10.4295, -12.5221,  14.0911,  -7.6656],\n",
      "        [ 15.2239,   9.1015,  10.2872, -12.0582,  14.1718,  -8.1040]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5600062608718872\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6826,  8.6914, 10.5038],\n",
      "        [14.4479,  8.5110, 10.0979],\n",
      "        [14.9987,  8.6202, 10.8538],\n",
      "        [14.6888,  8.8676, 10.7193],\n",
      "        [14.9506,  9.1830, 10.4805],\n",
      "        [14.8577,  9.1394, 10.6112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.8039, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5421,  13.7926,  -7.7893],\n",
      "        [-12.5298,  14.0499,  -7.8001],\n",
      "        [-12.5146,  13.8104,  -7.9367],\n",
      "        [-12.0265,  13.7222,  -7.4041],\n",
      "        [-12.1796,  13.6107,  -7.6337],\n",
      "        [-12.3823,  14.1794,  -7.6716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6826,   8.6914,  10.5038, -12.5421,  13.7926,  -7.7893],\n",
      "        [ 14.4479,   8.5110,  10.0979, -12.5298,  14.0499,  -7.8001],\n",
      "        [ 14.9987,   8.6202,  10.8538, -12.5146,  13.8104,  -7.9367],\n",
      "        [ 14.6888,   8.8676,  10.7193, -12.0265,  13.7222,  -7.4041],\n",
      "        [ 14.9506,   9.1830,  10.4805, -12.1796,  13.6107,  -7.6337],\n",
      "        [ 14.8577,   9.1394,  10.6112, -12.3823,  14.1794,  -7.6716]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.549421787261963\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0112,  8.8853, 10.2923],\n",
      "        [14.8896,  8.8664, 10.2413],\n",
      "        [15.1103,  8.8590, 10.4497],\n",
      "        [14.8774,  8.4824, 10.9474],\n",
      "        [14.8357,  8.8429, 10.3290],\n",
      "        [14.8833,  8.8064, 10.4886]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6358, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.0960,  13.9570,  -7.8291],\n",
      "        [-12.2637,  14.1142,  -7.8770],\n",
      "        [-12.4060,  13.8078,  -7.8766],\n",
      "        [-12.8175,  14.0764,  -7.9886],\n",
      "        [-12.1040,  13.6691,  -7.9814],\n",
      "        [-12.6084,  14.0458,  -7.9464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0112,   8.8853,  10.2923, -12.0960,  13.9570,  -7.8291],\n",
      "        [ 14.8896,   8.8664,  10.2413, -12.2637,  14.1142,  -7.8770],\n",
      "        [ 15.1103,   8.8590,  10.4497, -12.4060,  13.8078,  -7.8766],\n",
      "        [ 14.8774,   8.4824,  10.9474, -12.8175,  14.0764,  -7.9886],\n",
      "        [ 14.8357,   8.8429,  10.3290, -12.1040,  13.6691,  -7.9814],\n",
      "        [ 14.8833,   8.8064,  10.4886, -12.6084,  14.0458,  -7.9464]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5559219121932983\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9472, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8455,  8.8628, 10.8952],\n",
      "        [14.7321,  8.7641, 10.3881],\n",
      "        [14.2029,  8.3008, 10.1766],\n",
      "        [14.1697,  8.5611, 10.1564],\n",
      "        [14.8195,  8.7394,  9.9646],\n",
      "        [14.4887,  8.6895, 10.2797]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7966, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2930,  13.9832,  -7.8245],\n",
      "        [-12.4010,  13.7691,  -8.0238],\n",
      "        [-12.5071,  14.1547,  -7.7746],\n",
      "        [-12.6507,  14.0389,  -8.1678],\n",
      "        [-12.3792,  13.7811,  -7.6541],\n",
      "        [-12.3802,  13.9982,  -7.8598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8455,   8.8628,  10.8952, -12.2930,  13.9832,  -7.8245],\n",
      "        [ 14.7321,   8.7641,  10.3881, -12.4010,  13.7691,  -8.0238],\n",
      "        [ 14.2029,   8.3008,  10.1766, -12.5071,  14.1547,  -7.7746],\n",
      "        [ 14.1697,   8.5611,  10.1564, -12.6507,  14.0389,  -8.1678],\n",
      "        [ 14.8195,   8.7394,   9.9646, -12.3792,  13.7811,  -7.6541],\n",
      "        [ 14.4887,   8.6895,  10.2797, -12.3802,  13.9982,  -7.8598]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5709797143936157\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7654, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6557,  8.7303, 10.5946],\n",
      "        [14.9159,  9.1606, 10.6764],\n",
      "        [15.2275,  8.8309, 10.3660],\n",
      "        [14.7366,  8.7235, 10.5728],\n",
      "        [14.7578,  8.9799, 10.4759],\n",
      "        [14.9312,  8.4666, 10.2084]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.8462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4824,  14.1570,  -7.8681],\n",
      "        [-12.3245,  13.9101,  -7.7373],\n",
      "        [-12.8840,  14.3646,  -7.9673],\n",
      "        [-12.1479,  13.4901,  -7.6091],\n",
      "        [-12.5773,  14.1469,  -7.9837],\n",
      "        [-12.6314,  14.2415,  -7.8869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6557,   8.7303,  10.5946, -12.4824,  14.1570,  -7.8681],\n",
      "        [ 14.9159,   9.1606,  10.6764, -12.3245,  13.9101,  -7.7373],\n",
      "        [ 15.2275,   8.8309,  10.3660, -12.8840,  14.3646,  -7.9673],\n",
      "        [ 14.7366,   8.7235,  10.5728, -12.1479,  13.4901,  -7.6091],\n",
      "        [ 14.7578,   8.9799,  10.4759, -12.5773,  14.1469,  -7.9837],\n",
      "        [ 14.9312,   8.4666,  10.2084, -12.6314,  14.2415,  -7.8869]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5611950159072876\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7079, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9339,  9.0004, 10.7014],\n",
      "        [15.2293,  8.7589, 10.4848],\n",
      "        [14.8133,  8.7795, 10.7526],\n",
      "        [14.5406,  8.6626, 10.4364],\n",
      "        [15.0892,  9.1990, 10.2980],\n",
      "        [14.8773,  8.7180, 10.6816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.0879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6625,  14.0626,  -8.0823],\n",
      "        [-12.0480,  13.8248,  -7.7838],\n",
      "        [-12.4079,  13.8817,  -8.2613],\n",
      "        [-12.4049,  13.5492,  -7.9158],\n",
      "        [-12.6320,  13.7272,  -7.8520],\n",
      "        [-12.4404,  13.8548,  -7.7163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9339,   9.0004,  10.7014, -12.6625,  14.0626,  -8.0823],\n",
      "        [ 15.2293,   8.7589,  10.4848, -12.0480,  13.8248,  -7.7838],\n",
      "        [ 14.8133,   8.7795,  10.7526, -12.4079,  13.8817,  -8.2613],\n",
      "        [ 14.5406,   8.6626,  10.4364, -12.4049,  13.5492,  -7.9158],\n",
      "        [ 15.0892,   9.1990,  10.2980, -12.6320,  13.7272,  -7.8520],\n",
      "        [ 14.8773,   8.7180,  10.6816, -12.4404,  13.8548,  -7.7163]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5833719968795776\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7652,  9.1248, 10.2750],\n",
      "        [14.8760,  8.7644, 10.6555],\n",
      "        [14.9970,  8.8716, 10.2500],\n",
      "        [14.6247,  8.8993, 10.3599],\n",
      "        [14.8301,  8.6515, 10.6755],\n",
      "        [14.5123,  8.7640, 10.1563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.5959, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2831,  13.7757,  -7.7848],\n",
      "        [-12.8409,  14.0368,  -7.9403],\n",
      "        [-12.4086,  13.7979,  -7.8476],\n",
      "        [-12.6838,  13.9235,  -7.8966],\n",
      "        [-12.4641,  14.0698,  -7.8461],\n",
      "        [-12.4812,  13.7103,  -7.6462]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7652,   9.1248,  10.2750, -12.2831,  13.7757,  -7.7848],\n",
      "        [ 14.8760,   8.7644,  10.6555, -12.8409,  14.0368,  -7.9403],\n",
      "        [ 14.9970,   8.8716,  10.2500, -12.4086,  13.7979,  -7.8476],\n",
      "        [ 14.6247,   8.8993,  10.3599, -12.6838,  13.9235,  -7.8966],\n",
      "        [ 14.8301,   8.6515,  10.6755, -12.4641,  14.0698,  -7.8461],\n",
      "        [ 14.5123,   8.7640,  10.1563, -12.4812,  13.7103,  -7.6462]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5530424118041992\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0483, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9686,  9.0386, 10.8139],\n",
      "        [14.7219,  8.6916, 10.1057],\n",
      "        [15.0587,  9.1348, 10.4090],\n",
      "        [14.9954,  8.6446, 10.4618],\n",
      "        [15.3174,  9.0355, 10.4882],\n",
      "        [14.8021,  8.5845, 10.3044]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4694,  13.8539,  -7.7044],\n",
      "        [-12.8023,  14.0767,  -7.7504],\n",
      "        [-12.4305,  13.7191,  -8.0549],\n",
      "        [-12.8168,  13.9518,  -7.7771],\n",
      "        [-12.2700,  13.8221,  -7.5831],\n",
      "        [-12.2072,  13.9116,  -8.2145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9686,   9.0386,  10.8139, -12.4694,  13.8539,  -7.7044],\n",
      "        [ 14.7219,   8.6916,  10.1057, -12.8023,  14.0767,  -7.7504],\n",
      "        [ 15.0587,   9.1348,  10.4090, -12.4305,  13.7191,  -8.0549],\n",
      "        [ 14.9954,   8.6446,  10.4618, -12.8168,  13.9518,  -7.7771],\n",
      "        [ 15.3174,   9.0355,  10.4882, -12.2700,  13.8221,  -7.5831],\n",
      "        [ 14.8021,   8.5845,  10.3044, -12.2072,  13.9116,  -8.2145]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.5792523622512817\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9601,  8.9383, 10.6415],\n",
      "        [14.6248,  9.2926, 10.4696],\n",
      "        [15.0650,  8.8964, 10.6116],\n",
      "        [14.7589,  8.9224, 10.6705],\n",
      "        [14.7620,  8.6652, 10.8735],\n",
      "        [15.0934,  8.4516, 10.0294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.4583, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6078,  13.7997,  -7.8158],\n",
      "        [-12.7590,  14.2450,  -8.1312],\n",
      "        [-12.8983,  13.9413,  -7.8544],\n",
      "        [-12.9246,  14.1289,  -7.9192],\n",
      "        [-12.4801,  13.8767,  -7.4121],\n",
      "        [-12.6225,  14.0475,  -8.0365]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9601,   8.9383,  10.6415, -12.6078,  13.7997,  -7.8158],\n",
      "        [ 14.6248,   9.2926,  10.4696, -12.7590,  14.2450,  -8.1312],\n",
      "        [ 15.0650,   8.8964,  10.6116, -12.8983,  13.9413,  -7.8544],\n",
      "        [ 14.7589,   8.9224,  10.6705, -12.9246,  14.1289,  -7.9192],\n",
      "        [ 14.7620,   8.6652,  10.8735, -12.4801,  13.8767,  -7.4121],\n",
      "        [ 15.0934,   8.4516,  10.0294, -12.6225,  14.0475,  -8.0365]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5757079124450684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.4657,  8.7929, 10.3013],\n",
      "        [14.7001,  8.8648, 10.7067],\n",
      "        [15.1949,  9.1213, 10.5237],\n",
      "        [15.0970,  8.7566, 10.6295],\n",
      "        [15.0491,  9.1314, 10.4065],\n",
      "        [15.0188,  9.2307, 10.5106]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9215, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5724,  14.0595,  -8.0227],\n",
      "        [-12.3098,  13.9300,  -8.0808],\n",
      "        [-12.5500,  13.9871,  -8.1493],\n",
      "        [-12.3151,  13.9124,  -8.0826],\n",
      "        [-12.4604,  13.9321,  -7.9425],\n",
      "        [-12.0604,  14.0715,  -7.8306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.4657,   8.7929,  10.3013, -12.5724,  14.0595,  -8.0227],\n",
      "        [ 14.7001,   8.8648,  10.7067, -12.3098,  13.9300,  -8.0808],\n",
      "        [ 15.1949,   9.1213,  10.5237, -12.5500,  13.9871,  -8.1493],\n",
      "        [ 15.0970,   8.7566,  10.6295, -12.3151,  13.9124,  -8.0826],\n",
      "        [ 15.0491,   9.1314,  10.4065, -12.4604,  13.9321,  -7.9425],\n",
      "        [ 15.0188,   9.2307,  10.5106, -12.0604,  14.0715,  -7.8306]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5525152683258057\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8771,  8.7941, 10.5656],\n",
      "        [15.0413,  8.8681, 10.6214],\n",
      "        [14.5407,  8.6785, 10.4728],\n",
      "        [14.7786,  8.9476, 10.7802],\n",
      "        [14.4361,  8.6520, 10.2439],\n",
      "        [14.7921,  8.9523, 10.2192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5522,  14.1868,  -8.3381],\n",
      "        [-12.3623,  14.1493,  -8.0993],\n",
      "        [-12.7551,  14.0118,  -7.6300],\n",
      "        [-12.5026,  13.7155,  -7.5948],\n",
      "        [-12.3101,  14.1332,  -7.7390],\n",
      "        [-12.5323,  14.2116,  -8.0743]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8771,   8.7941,  10.5656, -12.5522,  14.1868,  -8.3381],\n",
      "        [ 15.0413,   8.8681,  10.6214, -12.3623,  14.1493,  -8.0993],\n",
      "        [ 14.5407,   8.6785,  10.4728, -12.7551,  14.0118,  -7.6300],\n",
      "        [ 14.7786,   8.9476,  10.7802, -12.5026,  13.7155,  -7.5948],\n",
      "        [ 14.4361,   8.6520,  10.2439, -12.3101,  14.1332,  -7.7390],\n",
      "        [ 14.7921,   8.9523,  10.2192, -12.5323,  14.2116,  -8.0743]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5815609693527222\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8876,  8.9003, 10.5936],\n",
      "        [15.3247,  8.9423, 10.5150],\n",
      "        [14.6820,  8.4526, 10.3147],\n",
      "        [14.9596,  9.0347, 10.8390],\n",
      "        [15.1935,  8.8077, 10.4411],\n",
      "        [14.6357,  8.6449, 10.4149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.3587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4539,  13.7948,  -7.8426],\n",
      "        [-12.1197,  13.8979,  -7.8348],\n",
      "        [-12.1897,  13.8008,  -8.0849],\n",
      "        [-12.5455,  14.1982,  -8.1691],\n",
      "        [-12.3659,  13.8565,  -7.8649],\n",
      "        [-12.3359,  14.1326,  -8.2635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8876,   8.9003,  10.5936, -12.4539,  13.7948,  -7.8426],\n",
      "        [ 15.3247,   8.9423,  10.5150, -12.1197,  13.8979,  -7.8348],\n",
      "        [ 14.6820,   8.4526,  10.3147, -12.1897,  13.8008,  -8.0849],\n",
      "        [ 14.9596,   9.0347,  10.8390, -12.5455,  14.1982,  -8.1691],\n",
      "        [ 15.1935,   8.8077,  10.4411, -12.3659,  13.8565,  -7.8649],\n",
      "        [ 14.6357,   8.6449,  10.4149, -12.3359,  14.1326,  -8.2635]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5712318420410156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1903,  8.8034, 10.6699],\n",
      "        [15.4323,  8.6689, 10.6190],\n",
      "        [14.6501,  8.6300, 10.7584],\n",
      "        [14.9980,  8.8653, 10.5219],\n",
      "        [14.7201,  8.7692, 10.2978],\n",
      "        [15.2191,  8.7760, 10.7482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6851,  13.9449,  -7.7190],\n",
      "        [-12.4991,  14.3963,  -8.0109],\n",
      "        [-12.5064,  13.9681,  -8.0161],\n",
      "        [-12.5454,  13.6824,  -8.1018],\n",
      "        [-12.2613,  13.9058,  -7.6917],\n",
      "        [-12.4615,  14.0591,  -8.0560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1903,   8.8034,  10.6699, -12.6851,  13.9449,  -7.7190],\n",
      "        [ 15.4323,   8.6689,  10.6190, -12.4991,  14.3963,  -8.0109],\n",
      "        [ 14.6501,   8.6300,  10.7584, -12.5064,  13.9681,  -8.0161],\n",
      "        [ 14.9980,   8.8653,  10.5219, -12.5454,  13.6824,  -8.1018],\n",
      "        [ 14.7201,   8.7692,  10.2978, -12.2613,  13.9058,  -7.6917],\n",
      "        [ 15.2191,   8.7760,  10.7482, -12.4615,  14.0591,  -8.0560]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5898058414459229\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.5633,  9.0252, 10.3534],\n",
      "        [14.9652,  8.5939, 10.2331],\n",
      "        [14.8511,  8.8421, 10.6969],\n",
      "        [15.0355,  8.8577, 10.7336],\n",
      "        [14.9087,  8.9359, 10.4229],\n",
      "        [14.6123,  8.8946, 10.4352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7077,  13.8437,  -7.5691],\n",
      "        [-12.7488,  14.0192,  -8.4947],\n",
      "        [-12.4335,  14.0963,  -8.0586],\n",
      "        [-12.4333,  14.0900,  -7.9821],\n",
      "        [-12.4454,  14.2596,  -7.9071],\n",
      "        [-12.3903,  14.0610,  -8.2847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.5633,   9.0252,  10.3534, -12.7077,  13.8437,  -7.5691],\n",
      "        [ 14.9652,   8.5939,  10.2331, -12.7488,  14.0192,  -8.4947],\n",
      "        [ 14.8511,   8.8421,  10.6969, -12.4335,  14.0963,  -8.0586],\n",
      "        [ 15.0355,   8.8577,  10.7336, -12.4333,  14.0900,  -7.9821],\n",
      "        [ 14.9087,   8.9359,  10.4229, -12.4454,  14.2596,  -7.9071],\n",
      "        [ 14.6123,   8.8946,  10.4352, -12.3903,  14.0610,  -8.2847]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.5588724613189697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6092,  8.6362, 10.7098],\n",
      "        [14.6961,  8.7917, 10.8541],\n",
      "        [14.9962,  8.8114, 10.5967],\n",
      "        [14.9114,  8.7319, 10.3957],\n",
      "        [14.8267,  9.0418, 10.5681],\n",
      "        [15.0941,  9.0641, 10.6078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.0158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5105,  14.3096,  -7.9769],\n",
      "        [-12.8785,  14.2168,  -8.2668],\n",
      "        [-12.5897,  13.7259,  -8.2611],\n",
      "        [-13.0633,  14.2460,  -8.0422],\n",
      "        [-12.4250,  13.7901,  -7.9081],\n",
      "        [-12.3110,  13.8814,  -8.0692]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6092,   8.6362,  10.7098, -12.5105,  14.3096,  -7.9769],\n",
      "        [ 14.6961,   8.7917,  10.8541, -12.8785,  14.2168,  -8.2668],\n",
      "        [ 14.9962,   8.8114,  10.5967, -12.5897,  13.7259,  -8.2611],\n",
      "        [ 14.9114,   8.7319,  10.3957, -13.0633,  14.2460,  -8.0422],\n",
      "        [ 14.8267,   9.0418,  10.5681, -12.4250,  13.7901,  -7.9081],\n",
      "        [ 15.0941,   9.0641,  10.6078, -12.3110,  13.8814,  -8.0692]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.574735164642334\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5176, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0049,  9.3508, 10.5370],\n",
      "        [14.8202,  8.5924, 10.5789],\n",
      "        [15.0165,  8.9163, 10.5946],\n",
      "        [14.7499,  8.5861, 10.5087],\n",
      "        [15.0638,  8.9317, 10.7134],\n",
      "        [15.1169,  8.9558, 10.6695]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2139, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.5908,  13.7444,  -7.8914],\n",
      "        [-12.6528,  14.0487,  -8.2623],\n",
      "        [-12.5720,  14.1986,  -7.9109],\n",
      "        [-12.5718,  14.2177,  -7.8997],\n",
      "        [-12.4771,  14.0999,  -7.7144],\n",
      "        [-12.5181,  14.3050,  -7.9268]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0049,   9.3508,  10.5370, -12.5908,  13.7444,  -7.8914],\n",
      "        [ 14.8202,   8.5924,  10.5789, -12.6528,  14.0487,  -8.2623],\n",
      "        [ 15.0165,   8.9163,  10.5946, -12.5720,  14.1986,  -7.9109],\n",
      "        [ 14.7499,   8.5861,  10.5087, -12.5718,  14.2177,  -7.8997],\n",
      "        [ 15.0638,   8.9317,  10.7134, -12.4771,  14.0999,  -7.7144],\n",
      "        [ 15.1169,   8.9558,  10.6695, -12.5181,  14.3050,  -7.9268]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5871435403823853\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5657, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8037,  8.3865,  9.9291],\n",
      "        [15.0401,  8.7759, 10.4803],\n",
      "        [15.0715,  9.1129, 10.9057],\n",
      "        [14.7812,  8.9694, 10.5550],\n",
      "        [14.8214,  8.5893, 10.4021],\n",
      "        [14.8863,  8.7980, 10.3646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8536, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7682,  14.1723,  -8.0755],\n",
      "        [-12.5709,  14.1650,  -8.2551],\n",
      "        [-12.6440,  13.8136,  -8.0475],\n",
      "        [-12.5033,  13.6782,  -8.0563],\n",
      "        [-12.6550,  14.1710,  -8.0458],\n",
      "        [-12.7747,  13.8984,  -7.9073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8037,   8.3865,   9.9291, -12.7682,  14.1723,  -8.0755],\n",
      "        [ 15.0401,   8.7759,  10.4803, -12.5709,  14.1650,  -8.2551],\n",
      "        [ 15.0715,   9.1129,  10.9057, -12.6440,  13.8136,  -8.0475],\n",
      "        [ 14.7812,   8.9694,  10.5550, -12.5033,  13.6782,  -8.0563],\n",
      "        [ 14.8214,   8.5893,  10.4021, -12.6550,  14.1710,  -8.0458],\n",
      "        [ 14.8863,   8.7980,  10.3646, -12.7747,  13.8984,  -7.9073]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5603506565093994\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7277,  8.9357, 10.3373],\n",
      "        [14.5443,  8.2687, 10.5638],\n",
      "        [15.4361,  9.2071, 10.9660],\n",
      "        [15.1516,  9.1738, 10.8073],\n",
      "        [15.2059,  8.9712, 10.5172],\n",
      "        [14.8438,  8.8761, 10.3667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6524,  14.1481,  -8.0710],\n",
      "        [-12.3695,  13.7182,  -7.8523],\n",
      "        [-12.4988,  13.8675,  -8.1649],\n",
      "        [-12.7095,  14.5134,  -8.2491],\n",
      "        [-12.5645,  14.0996,  -8.1777],\n",
      "        [-12.6883,  14.1233,  -8.0915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7277,   8.9357,  10.3373, -12.6524,  14.1481,  -8.0710],\n",
      "        [ 14.5443,   8.2687,  10.5638, -12.3695,  13.7182,  -7.8523],\n",
      "        [ 15.4361,   9.2071,  10.9660, -12.4988,  13.8675,  -8.1649],\n",
      "        [ 15.1516,   9.1738,  10.8073, -12.7095,  14.5134,  -8.2491],\n",
      "        [ 15.2059,   8.9712,  10.5172, -12.5645,  14.0996,  -8.1777],\n",
      "        [ 14.8438,   8.8761,  10.3667, -12.6883,  14.1233,  -8.0915]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5766710042953491\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3256,  9.3084, 10.7734],\n",
      "        [14.9680,  8.9798, 10.4019],\n",
      "        [14.9793,  8.4786, 10.7971],\n",
      "        [14.9381,  8.8798, 10.5489],\n",
      "        [15.0640,  8.8056, 10.9327],\n",
      "        [14.9130,  8.7944, 10.4803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7633, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7041,  13.9082,  -8.0983],\n",
      "        [-12.9057,  14.0542,  -8.0515],\n",
      "        [-12.4380,  14.1571,  -8.2085],\n",
      "        [-12.4742,  14.0067,  -7.7743],\n",
      "        [-12.8823,  14.3318,  -8.2157],\n",
      "        [-12.7995,  13.9732,  -8.3298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3256,   9.3084,  10.7734, -12.7041,  13.9082,  -8.0983],\n",
      "        [ 14.9680,   8.9798,  10.4019, -12.9057,  14.0542,  -8.0515],\n",
      "        [ 14.9793,   8.4786,  10.7971, -12.4380,  14.1571,  -8.2085],\n",
      "        [ 14.9381,   8.8798,  10.5489, -12.4742,  14.0067,  -7.7743],\n",
      "        [ 15.0640,   8.8056,  10.9327, -12.8823,  14.3318,  -8.2157],\n",
      "        [ 14.9130,   8.7944,  10.4803, -12.7995,  13.9732,  -8.3298]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6151741743087769\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2630,  8.7671, 10.5128],\n",
      "        [15.3175,  9.1185, 10.6678],\n",
      "        [14.9870,  8.6313, 10.2043],\n",
      "        [14.6725,  8.8445, 10.8131],\n",
      "        [15.0161,  8.8471, 10.5032],\n",
      "        [15.0264,  9.1917, 10.2800]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6246,  14.1627,  -8.3096],\n",
      "        [-12.7595,  14.3242,  -8.0889],\n",
      "        [-12.4606,  14.4002,  -8.2425],\n",
      "        [-12.7992,  14.1575,  -7.8102],\n",
      "        [-12.6571,  13.9818,  -7.9017],\n",
      "        [-12.8193,  14.3323,  -7.7842]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2630,   8.7671,  10.5128, -12.6246,  14.1627,  -8.3096],\n",
      "        [ 15.3175,   9.1185,  10.6678, -12.7595,  14.3242,  -8.0889],\n",
      "        [ 14.9870,   8.6313,  10.2043, -12.4606,  14.4002,  -8.2425],\n",
      "        [ 14.6725,   8.8445,  10.8131, -12.7992,  14.1575,  -7.8102],\n",
      "        [ 15.0161,   8.8471,  10.5032, -12.6571,  13.9818,  -7.9017],\n",
      "        [ 15.0264,   9.1917,  10.2800, -12.8193,  14.3323,  -7.7842]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6029311418533325\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7087,  8.7753, 10.2396],\n",
      "        [15.3295,  9.0910, 10.5420],\n",
      "        [14.7577,  8.9507, 10.5203],\n",
      "        [14.7686,  8.5541, 10.6000],\n",
      "        [14.9369,  9.1179, 10.4978],\n",
      "        [15.0612,  8.9081, 10.6880]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4640, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7275,  13.8796,  -8.2335],\n",
      "        [-12.7984,  14.2643,  -8.1989],\n",
      "        [-12.5797,  14.2329,  -8.1843],\n",
      "        [-12.6424,  14.3798,  -8.0093],\n",
      "        [-12.6812,  14.0048,  -8.0959],\n",
      "        [-12.6561,  13.7521,  -8.0739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7087,   8.7753,  10.2396, -12.7275,  13.8796,  -8.2335],\n",
      "        [ 15.3295,   9.0910,  10.5420, -12.7984,  14.2643,  -8.1989],\n",
      "        [ 14.7577,   8.9507,  10.5203, -12.5797,  14.2329,  -8.1843],\n",
      "        [ 14.7686,   8.5541,  10.6000, -12.6424,  14.3798,  -8.0093],\n",
      "        [ 14.9369,   9.1179,  10.4978, -12.6812,  14.0048,  -8.0959],\n",
      "        [ 15.0612,   8.9081,  10.6880, -12.6561,  13.7521,  -8.0739]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5707823038101196\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9554,  8.7844, 10.4540],\n",
      "        [14.9176,  9.0353, 10.7653],\n",
      "        [14.6566,  9.2298, 10.4804],\n",
      "        [14.9899,  8.7171, 10.2938],\n",
      "        [14.0932,  8.9232, 10.3385],\n",
      "        [15.2925,  8.9803, 10.9943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3722,  14.2466,  -8.3115],\n",
      "        [-12.4975,  13.9696,  -8.3447],\n",
      "        [-12.2622,  14.4361,  -7.8216],\n",
      "        [-12.8045,  14.2204,  -8.1525],\n",
      "        [-12.8253,  14.0508,  -7.9746],\n",
      "        [-12.4891,  13.9452,  -7.8115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9554,   8.7844,  10.4540, -12.3722,  14.2466,  -8.3115],\n",
      "        [ 14.9176,   9.0353,  10.7653, -12.4975,  13.9696,  -8.3447],\n",
      "        [ 14.6566,   9.2298,  10.4804, -12.2622,  14.4361,  -7.8216],\n",
      "        [ 14.9899,   8.7171,  10.2938, -12.8045,  14.2204,  -8.1525],\n",
      "        [ 14.0932,   8.9232,  10.3385, -12.8253,  14.0508,  -7.9746],\n",
      "        [ 15.2925,   8.9803,  10.9943, -12.4891,  13.9452,  -7.8115]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5890896320343018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.6613,  9.0512, 10.1451],\n",
      "        [14.9325,  9.0159, 10.7509],\n",
      "        [15.1222,  9.0263, 11.0554],\n",
      "        [14.7010,  9.1228, 10.1633],\n",
      "        [15.0515,  9.0245, 10.8772],\n",
      "        [14.9506,  9.1545, 10.6432]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3835, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6528,  14.0084,  -8.1084],\n",
      "        [-12.6770,  14.2748,  -7.8399],\n",
      "        [-13.0659,  14.3259,  -8.7082],\n",
      "        [-12.5287,  13.9353,  -8.0358],\n",
      "        [-12.4858,  14.2023,  -8.2635],\n",
      "        [-12.9209,  14.3912,  -8.4773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.6613,   9.0512,  10.1451, -12.6528,  14.0084,  -8.1084],\n",
      "        [ 14.9325,   9.0159,  10.7509, -12.6770,  14.2748,  -7.8399],\n",
      "        [ 15.1222,   9.0263,  11.0554, -13.0659,  14.3259,  -8.7082],\n",
      "        [ 14.7010,   9.1228,  10.1633, -12.5287,  13.9353,  -8.0358],\n",
      "        [ 15.0515,   9.0245,  10.8772, -12.4858,  14.2023,  -8.2635],\n",
      "        [ 14.9506,   9.1545,  10.6432, -12.9209,  14.3912,  -8.4773]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5728482007980347\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9969, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0175,  9.2083, 10.5099],\n",
      "        [14.9820,  8.9178, 10.8949],\n",
      "        [15.0131,  8.5516, 10.1471],\n",
      "        [14.8523,  8.9608, 10.8209],\n",
      "        [14.9184,  8.9990, 10.4681],\n",
      "        [14.8194,  8.9956, 10.5359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4887, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2630,  14.0677,  -7.5784],\n",
      "        [-12.5498,  14.1081,  -8.0706],\n",
      "        [-12.1627,  13.9362,  -7.6120],\n",
      "        [-12.2438,  13.8478,  -7.8463],\n",
      "        [-12.8079,  14.3198,  -8.3324],\n",
      "        [-12.5957,  13.9274,  -8.3307]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0175,   9.2083,  10.5099, -12.2630,  14.0677,  -7.5784],\n",
      "        [ 14.9820,   8.9178,  10.8949, -12.5498,  14.1081,  -8.0706],\n",
      "        [ 15.0131,   8.5516,  10.1471, -12.1627,  13.9362,  -7.6120],\n",
      "        [ 14.8523,   8.9608,  10.8209, -12.2438,  13.8478,  -7.8463],\n",
      "        [ 14.9184,   8.9990,  10.4681, -12.8079,  14.3198,  -8.3324],\n",
      "        [ 14.8194,   8.9956,  10.5359, -12.5957,  13.9274,  -8.3307]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5893714427947998\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8883,  9.2153, 10.7312],\n",
      "        [14.8582,  9.0919, 10.8460],\n",
      "        [15.3645,  8.6885, 10.5695],\n",
      "        [15.1187,  9.2523, 10.5971],\n",
      "        [14.9281,  8.9052, 10.5985],\n",
      "        [14.8056,  9.0827, 10.6493]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.2488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.1245,  13.7986,  -7.6780],\n",
      "        [-12.7640,  13.8564,  -7.9826],\n",
      "        [-12.3338,  14.4308,  -8.2550],\n",
      "        [-12.7094,  13.9680,  -8.0045],\n",
      "        [-12.7567,  14.1357,  -7.7516],\n",
      "        [-12.7344,  13.9463,  -7.9084]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8883,   9.2153,  10.7312, -12.1245,  13.7986,  -7.6780],\n",
      "        [ 14.8582,   9.0919,  10.8460, -12.7640,  13.8564,  -7.9826],\n",
      "        [ 15.3645,   8.6885,  10.5695, -12.3338,  14.4308,  -8.2550],\n",
      "        [ 15.1187,   9.2523,  10.5971, -12.7094,  13.9680,  -8.0045],\n",
      "        [ 14.9281,   8.9052,  10.5985, -12.7567,  14.1357,  -7.7516],\n",
      "        [ 14.8056,   9.0827,  10.6493, -12.7344,  13.9463,  -7.9084]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.5849964618682861\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0190,  8.8714, 10.3405],\n",
      "        [15.0128,  9.1024, 10.2189],\n",
      "        [15.0472,  9.2164, 10.6588],\n",
      "        [15.2027,  8.9304, 10.7790],\n",
      "        [15.2097,  8.8726, 10.8069],\n",
      "        [14.7965,  9.0192, 10.3877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9239,  14.3462,  -8.2790],\n",
      "        [-12.5859,  13.8867,  -7.9564],\n",
      "        [-12.6270,  14.1742,  -7.8756],\n",
      "        [-12.7247,  14.3939,  -8.1557],\n",
      "        [-12.9332,  13.8737,  -8.0974],\n",
      "        [-12.5970,  14.2782,  -8.1552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0190,   8.8714,  10.3405, -12.9239,  14.3462,  -8.2790],\n",
      "        [ 15.0128,   9.1024,  10.2189, -12.5859,  13.8867,  -7.9564],\n",
      "        [ 15.0472,   9.2164,  10.6588, -12.6270,  14.1742,  -7.8756],\n",
      "        [ 15.2027,   8.9304,  10.7790, -12.7247,  14.3939,  -8.1557],\n",
      "        [ 15.2097,   8.8726,  10.8069, -12.9332,  13.8737,  -8.0974],\n",
      "        [ 14.7965,   9.0192,  10.3877, -12.5970,  14.2782,  -8.1552]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6046981811523438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0290, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3103,  9.2315, 10.6847],\n",
      "        [15.2626,  9.1264, 10.6454],\n",
      "        [14.8513,  9.3266, 10.8273],\n",
      "        [15.2745,  9.1575, 10.7596],\n",
      "        [14.3896,  8.6794, 10.5741],\n",
      "        [14.8910,  8.6364, 10.2281]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9390, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7441,  14.4945,  -8.3898],\n",
      "        [-12.8574,  14.1880,  -8.3526],\n",
      "        [-12.7676,  14.4043,  -8.1429],\n",
      "        [-12.6649,  14.1456,  -8.2271],\n",
      "        [-12.6510,  14.2573,  -8.0338],\n",
      "        [-12.4891,  13.9699,  -8.0417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3103,   9.2315,  10.6847, -12.7441,  14.4945,  -8.3898],\n",
      "        [ 15.2626,   9.1264,  10.6454, -12.8574,  14.1880,  -8.3526],\n",
      "        [ 14.8513,   9.3266,  10.8273, -12.7676,  14.4043,  -8.1429],\n",
      "        [ 15.2745,   9.1575,  10.7596, -12.6649,  14.1456,  -8.2271],\n",
      "        [ 14.3896,   8.6794,  10.5741, -12.6510,  14.2573,  -8.0338],\n",
      "        [ 14.8910,   8.6364,  10.2281, -12.4891,  13.9699,  -8.0417]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.633442997932434\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7890, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0116,  9.0610, 10.4920],\n",
      "        [15.4148,  9.5286, 10.8627],\n",
      "        [14.7908,  8.7670, 10.4165],\n",
      "        [15.0671,  8.9912, 10.8205],\n",
      "        [15.3707,  9.3030, 10.7241],\n",
      "        [14.9241,  9.1466, 10.7146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3238,  13.5256,  -7.7176],\n",
      "        [-12.6600,  14.3185,  -8.4269],\n",
      "        [-12.8674,  14.4635,  -8.6677],\n",
      "        [-13.0817,  14.2771,  -8.3903],\n",
      "        [-12.2929,  14.3749,  -8.2740],\n",
      "        [-12.4355,  13.8874,  -8.1421]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0116,   9.0610,  10.4920, -12.3238,  13.5256,  -7.7176],\n",
      "        [ 15.4148,   9.5286,  10.8627, -12.6600,  14.3185,  -8.4269],\n",
      "        [ 14.7908,   8.7670,  10.4165, -12.8674,  14.4635,  -8.6677],\n",
      "        [ 15.0671,   8.9912,  10.8205, -13.0817,  14.2771,  -8.3903],\n",
      "        [ 15.3707,   9.3030,  10.7241, -12.2929,  14.3749,  -8.2740],\n",
      "        [ 14.9241,   9.1466,  10.7146, -12.4355,  13.8874,  -8.1421]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.581389307975769\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7392, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0420,  8.9564, 10.5656],\n",
      "        [15.1197,  8.9796, 10.5062],\n",
      "        [14.9928,  8.9638, 10.2934],\n",
      "        [15.0688,  9.2167, 10.6957],\n",
      "        [15.0828,  8.6582, 10.4065],\n",
      "        [15.1389,  9.1024, 10.7498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7273, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7992,  13.9042,  -7.8511],\n",
      "        [-12.6644,  14.3341,  -8.3162],\n",
      "        [-12.7366,  14.3270,  -8.1368],\n",
      "        [-12.4896,  13.9079,  -7.9331],\n",
      "        [-12.8878,  14.6572,  -8.4310],\n",
      "        [-12.6984,  14.1126,  -8.1845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0420,   8.9564,  10.5656, -12.7992,  13.9042,  -7.8511],\n",
      "        [ 15.1197,   8.9796,  10.5062, -12.6644,  14.3341,  -8.3162],\n",
      "        [ 14.9928,   8.9638,  10.2934, -12.7366,  14.3270,  -8.1368],\n",
      "        [ 15.0688,   9.2167,  10.6957, -12.4896,  13.9079,  -7.9331],\n",
      "        [ 15.0828,   8.6582,  10.4065, -12.8878,  14.6572,  -8.4310],\n",
      "        [ 15.1389,   9.1024,  10.7498, -12.6984,  14.1126,  -8.1845]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6009265184402466\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.7905,  9.4103, 10.5784],\n",
      "        [15.3801,  9.0693, 10.6886],\n",
      "        [15.5492,  9.0137, 10.7010],\n",
      "        [14.8630,  9.0196, 10.7300],\n",
      "        [15.1546,  9.1476, 10.9583],\n",
      "        [15.2665,  9.0052, 11.0718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8963, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4382,  14.1391,  -8.0469],\n",
      "        [-12.5254,  14.3326,  -8.2809],\n",
      "        [-12.1956,  14.1253,  -7.3177],\n",
      "        [-12.5216,  14.2600,  -8.3561],\n",
      "        [-12.9541,  14.4947,  -8.1056],\n",
      "        [-12.4366,  13.9578,  -7.9987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.7905,   9.4103,  10.5784, -12.4382,  14.1391,  -8.0469],\n",
      "        [ 15.3801,   9.0693,  10.6886, -12.5254,  14.3326,  -8.2809],\n",
      "        [ 15.5492,   9.0137,  10.7010, -12.1956,  14.1253,  -7.3177],\n",
      "        [ 14.8630,   9.0196,  10.7300, -12.5216,  14.2600,  -8.3561],\n",
      "        [ 15.1546,   9.1476,  10.9583, -12.9541,  14.4947,  -8.1056],\n",
      "        [ 15.2665,   9.0052,  11.0718, -12.4366,  13.9578,  -7.9987]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.600759506225586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0326, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3014,  9.0499, 10.7983],\n",
      "        [15.1514,  9.3630, 10.4139],\n",
      "        [15.0364,  8.9610, 10.7159],\n",
      "        [15.3999,  8.9014, 10.6503],\n",
      "        [15.3309,  9.3518, 10.7720],\n",
      "        [14.9478,  8.8842, 10.7417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3080, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3748,  14.0558,  -7.8554],\n",
      "        [-12.8871,  14.2692,  -7.9657],\n",
      "        [-12.6992,  14.2436,  -8.2845],\n",
      "        [-12.5117,  14.0420,  -7.8395],\n",
      "        [-12.7188,  14.5119,  -8.2151],\n",
      "        [-12.5423,  13.7109,  -8.3268]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3014,   9.0499,  10.7983, -12.3748,  14.0558,  -7.8554],\n",
      "        [ 15.1514,   9.3630,  10.4139, -12.8871,  14.2692,  -7.9657],\n",
      "        [ 15.0364,   8.9610,  10.7159, -12.6992,  14.2436,  -8.2845],\n",
      "        [ 15.3999,   8.9014,  10.6503, -12.5117,  14.0420,  -7.8395],\n",
      "        [ 15.3309,   9.3518,  10.7720, -12.7188,  14.5119,  -8.2151],\n",
      "        [ 14.9478,   8.8842,  10.7417, -12.5423,  13.7109,  -8.3268]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6164177656173706\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1006,  9.3607, 10.9881],\n",
      "        [15.0601,  8.8440, 11.0186],\n",
      "        [14.8801,  8.7793, 10.4517],\n",
      "        [15.5037,  8.7870, 10.4258],\n",
      "        [14.8867,  9.5400, 10.5515],\n",
      "        [14.8735,  8.9800, 10.5141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7519,  14.3462,  -8.0303],\n",
      "        [-12.6142,  13.6681,  -7.9910],\n",
      "        [-12.8095,  13.9426,  -8.5919],\n",
      "        [-12.8294,  14.0578,  -7.9657],\n",
      "        [-12.7734,  13.9752,  -8.3910],\n",
      "        [-12.7573,  14.2107,  -8.6702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1006,   9.3607,  10.9881, -12.7519,  14.3462,  -8.0303],\n",
      "        [ 15.0601,   8.8440,  11.0186, -12.6142,  13.6681,  -7.9910],\n",
      "        [ 14.8801,   8.7793,  10.4517, -12.8095,  13.9426,  -8.5919],\n",
      "        [ 15.5037,   8.7870,  10.4258, -12.8294,  14.0578,  -7.9657],\n",
      "        [ 14.8867,   9.5400,  10.5515, -12.7734,  13.9752,  -8.3910],\n",
      "        [ 14.8735,   8.9800,  10.5141, -12.7573,  14.2107,  -8.6702]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6345911026000977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1745,  9.4062, 10.6745],\n",
      "        [15.0201,  9.3004, 10.9301],\n",
      "        [15.4635,  9.3442, 10.8622],\n",
      "        [15.1062,  8.9790, 10.8512],\n",
      "        [14.9443,  9.0242, 10.4180],\n",
      "        [15.0262,  9.0209, 10.9618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2494, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4322,  14.3839,  -8.2980],\n",
      "        [-12.1497,  13.6948,  -8.1414],\n",
      "        [-12.5158,  14.4915,  -8.3815],\n",
      "        [-12.9909,  14.4685,  -8.4698],\n",
      "        [-12.9478,  14.4337,  -8.2703],\n",
      "        [-12.8750,  14.1208,  -7.9908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1745,   9.4062,  10.6745, -12.4322,  14.3839,  -8.2980],\n",
      "        [ 15.0201,   9.3004,  10.9301, -12.1497,  13.6948,  -8.1414],\n",
      "        [ 15.4635,   9.3442,  10.8622, -12.5158,  14.4915,  -8.3815],\n",
      "        [ 15.1062,   8.9790,  10.8512, -12.9909,  14.4685,  -8.4698],\n",
      "        [ 14.9443,   9.0242,  10.4180, -12.9478,  14.4337,  -8.2703],\n",
      "        [ 15.0262,   9.0209,  10.9618, -12.8750,  14.1208,  -7.9908]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.62801194190979\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9423, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4667,  9.2782, 10.5145],\n",
      "        [14.8351,  9.0523, 10.6144],\n",
      "        [15.0964,  8.7950, 10.6412],\n",
      "        [15.2749,  8.9934, 11.3091],\n",
      "        [15.1016,  8.7875, 10.7456],\n",
      "        [15.2521,  9.3242, 10.4645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7410,  14.4341,  -8.4392],\n",
      "        [-13.0266,  14.3265,  -8.2154],\n",
      "        [-12.6353,  13.9942,  -8.0256],\n",
      "        [-13.0955,  14.2558,  -8.2261],\n",
      "        [-12.5536,  13.8859,  -8.2778],\n",
      "        [-13.0092,  14.4425,  -8.2933]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4667,   9.2782,  10.5145, -12.7410,  14.4341,  -8.4392],\n",
      "        [ 14.8351,   9.0523,  10.6144, -13.0266,  14.3265,  -8.2154],\n",
      "        [ 15.0964,   8.7950,  10.6412, -12.6353,  13.9942,  -8.0256],\n",
      "        [ 15.2749,   8.9934,  11.3091, -13.0955,  14.2558,  -8.2261],\n",
      "        [ 15.1016,   8.7875,  10.7456, -12.5536,  13.8859,  -8.2778],\n",
      "        [ 15.2521,   9.3242,  10.4645, -13.0092,  14.4425,  -8.2933]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6411069631576538\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1805,  9.2004, 10.7110],\n",
      "        [15.6837,  9.2626, 10.9895],\n",
      "        [15.4443,  9.2980, 10.9786],\n",
      "        [15.0191,  9.0916, 11.0224],\n",
      "        [15.2965,  8.9577, 10.7326],\n",
      "        [15.3288,  9.4133, 10.8941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.3449,  14.0088,  -8.1190],\n",
      "        [-12.8144,  14.9662,  -8.4932],\n",
      "        [-12.6004,  13.5779,  -8.2019],\n",
      "        [-12.4921,  14.1911,  -8.2795],\n",
      "        [-12.9676,  14.2070,  -7.9385],\n",
      "        [-12.4975,  14.3835,  -8.4254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1805,   9.2004,  10.7110, -12.3449,  14.0088,  -8.1190],\n",
      "        [ 15.6837,   9.2626,  10.9895, -12.8144,  14.9662,  -8.4932],\n",
      "        [ 15.4443,   9.2980,  10.9786, -12.6004,  13.5779,  -8.2019],\n",
      "        [ 15.0191,   9.0916,  11.0224, -12.4921,  14.1911,  -8.2795],\n",
      "        [ 15.2965,   8.9577,  10.7326, -12.9676,  14.2070,  -7.9385],\n",
      "        [ 15.3288,   9.4133,  10.8941, -12.4975,  14.3835,  -8.4254]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6167700290679932\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9517,  8.8522, 10.9828],\n",
      "        [15.1834,  9.3582, 10.5876],\n",
      "        [15.1776,  8.9317, 10.7704],\n",
      "        [15.0786,  9.2061, 10.9274],\n",
      "        [14.8846,  9.0064, 10.8006],\n",
      "        [14.7705,  8.9885, 10.6404]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3108, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.2340,  14.3420,  -7.8863],\n",
      "        [-12.3043,  14.3238,  -8.0814],\n",
      "        [-12.9926,  13.6922,  -8.1214],\n",
      "        [-13.3467,  14.4943,  -8.4354],\n",
      "        [-12.7178,  14.4264,  -8.3935],\n",
      "        [-12.8750,  13.8504,  -8.0294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9517,   8.8522,  10.9828, -12.2340,  14.3420,  -7.8863],\n",
      "        [ 15.1834,   9.3582,  10.5876, -12.3043,  14.3238,  -8.0814],\n",
      "        [ 15.1776,   8.9317,  10.7704, -12.9926,  13.6922,  -8.1214],\n",
      "        [ 15.0786,   9.2061,  10.9274, -13.3467,  14.4943,  -8.4354],\n",
      "        [ 14.8846,   9.0064,  10.8006, -12.7178,  14.4264,  -8.3935],\n",
      "        [ 14.7705,   8.9885,  10.6404, -12.8750,  13.8504,  -8.0294]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6131550073623657\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1998,  9.1507, 10.6457],\n",
      "        [15.6662,  9.1482, 10.9291],\n",
      "        [15.0768,  9.0255, 10.7060],\n",
      "        [15.0608,  9.0781, 10.5989],\n",
      "        [15.1107,  9.1186, 10.5540],\n",
      "        [15.1134,  8.7981, 10.6048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.0411,  14.8387,  -8.3147],\n",
      "        [-12.5576,  14.2474,  -8.2826],\n",
      "        [-13.0859,  14.2762,  -8.7073],\n",
      "        [-12.8633,  14.4832,  -8.5071],\n",
      "        [-13.0263,  14.1483,  -8.2253],\n",
      "        [-12.9698,  13.9308,  -8.3395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1998,   9.1507,  10.6457, -13.0411,  14.8387,  -8.3147],\n",
      "        [ 15.6662,   9.1482,  10.9291, -12.5576,  14.2474,  -8.2826],\n",
      "        [ 15.0768,   9.0255,  10.7060, -13.0859,  14.2762,  -8.7073],\n",
      "        [ 15.0608,   9.0781,  10.5989, -12.8633,  14.4832,  -8.5071],\n",
      "        [ 15.1107,   9.1186,  10.5540, -13.0263,  14.1483,  -8.2253],\n",
      "        [ 15.1134,   8.7981,  10.6048, -12.9698,  13.9308,  -8.3395]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.647469401359558\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5940,  9.2459, 10.9090],\n",
      "        [14.8630,  9.1331, 11.1497],\n",
      "        [14.9996,  8.9951, 10.8611],\n",
      "        [15.4377,  8.8335, 10.8800],\n",
      "        [15.2635,  9.1063, 10.5061],\n",
      "        [15.0569,  8.9547, 10.8300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8887,  14.2622,  -8.2422],\n",
      "        [-12.8721,  14.8326,  -8.3498],\n",
      "        [-12.6951,  14.2111,  -8.6768],\n",
      "        [-12.8070,  14.5224,  -8.2613],\n",
      "        [-12.6596,  14.5083,  -8.4883],\n",
      "        [-12.5897,  13.9919,  -8.3304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5940,   9.2459,  10.9090, -12.8887,  14.2622,  -8.2422],\n",
      "        [ 14.8630,   9.1331,  11.1497, -12.8721,  14.8326,  -8.3498],\n",
      "        [ 14.9996,   8.9951,  10.8611, -12.6951,  14.2111,  -8.6768],\n",
      "        [ 15.4377,   8.8335,  10.8800, -12.8070,  14.5224,  -8.2613],\n",
      "        [ 15.2635,   9.1063,  10.5061, -12.6596,  14.5083,  -8.4883],\n",
      "        [ 15.0569,   8.9547,  10.8300, -12.5897,  13.9919,  -8.3304]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6575394868850708\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1778,  9.1728, 10.6599],\n",
      "        [14.9457,  9.0739, 11.0827],\n",
      "        [14.9507,  9.1191, 10.8002],\n",
      "        [15.2636,  9.3206, 10.5047],\n",
      "        [15.0357,  9.0852, 10.9463],\n",
      "        [15.5479,  9.5451, 11.1762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7533,  14.3204,  -8.6695],\n",
      "        [-12.8198,  14.4536,  -8.6101],\n",
      "        [-12.9523,  14.5707,  -8.5340],\n",
      "        [-12.9722,  13.7833,  -8.0269],\n",
      "        [-12.6015,  14.0078,  -8.2595],\n",
      "        [-12.5805,  14.4137,  -8.1282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1778,   9.1728,  10.6599, -12.7533,  14.3204,  -8.6695],\n",
      "        [ 14.9457,   9.0739,  11.0827, -12.8198,  14.4536,  -8.6101],\n",
      "        [ 14.9507,   9.1191,  10.8002, -12.9523,  14.5707,  -8.5340],\n",
      "        [ 15.2636,   9.3206,  10.5047, -12.9722,  13.7833,  -8.0269],\n",
      "        [ 15.0357,   9.0852,  10.9463, -12.6015,  14.0078,  -8.2595],\n",
      "        [ 15.5479,   9.5451,  11.1762, -12.5805,  14.4137,  -8.1282]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6374117136001587\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2720,  9.2556, 10.7895],\n",
      "        [15.3520,  9.2634, 10.9006],\n",
      "        [14.9419,  8.8582, 10.4146],\n",
      "        [15.1099,  8.9360, 10.4934],\n",
      "        [15.1135,  9.5412, 11.0467],\n",
      "        [14.8859,  8.7526, 10.7503]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1754, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.0095,  14.2987,  -8.2643],\n",
      "        [-12.6993,  14.5160,  -8.5500],\n",
      "        [-12.9385,  14.3936,  -8.3550],\n",
      "        [-13.0440,  14.0889,  -8.5392],\n",
      "        [-13.0611,  14.3526,  -8.1584],\n",
      "        [-12.8680,  14.5041,  -8.2931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2720,   9.2556,  10.7895, -13.0095,  14.2987,  -8.2643],\n",
      "        [ 15.3520,   9.2634,  10.9006, -12.6993,  14.5160,  -8.5500],\n",
      "        [ 14.9419,   8.8582,  10.4146, -12.9385,  14.3936,  -8.3550],\n",
      "        [ 15.1099,   8.9360,  10.4934, -13.0440,  14.0889,  -8.5392],\n",
      "        [ 15.1135,   9.5412,  11.0467, -13.0611,  14.3526,  -8.1584],\n",
      "        [ 14.8859,   8.7526,  10.7503, -12.8680,  14.5041,  -8.2931]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.647039532661438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0513,  9.1501, 10.4382],\n",
      "        [15.4085,  8.9303, 10.7130],\n",
      "        [15.0648,  9.0821, 10.6393],\n",
      "        [15.4449,  9.1626, 10.9249],\n",
      "        [15.3463,  9.6257, 11.1433],\n",
      "        [14.9139,  9.1647, 11.0124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.7978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7065,  14.4904,  -8.2292],\n",
      "        [-12.8722,  14.5531,  -8.0492],\n",
      "        [-12.8723,  14.2304,  -8.4332],\n",
      "        [-12.7169,  13.8345,  -8.2930],\n",
      "        [-12.8410,  14.4440,  -8.2483],\n",
      "        [-12.4235,  14.1530,  -8.2690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0513,   9.1501,  10.4382, -12.7065,  14.4904,  -8.2292],\n",
      "        [ 15.4085,   8.9303,  10.7130, -12.8722,  14.5531,  -8.0492],\n",
      "        [ 15.0648,   9.0821,  10.6393, -12.8723,  14.2304,  -8.4332],\n",
      "        [ 15.4449,   9.1626,  10.9249, -12.7169,  13.8345,  -8.2930],\n",
      "        [ 15.3463,   9.6257,  11.1433, -12.8410,  14.4440,  -8.2483],\n",
      "        [ 14.9139,   9.1647,  11.0124, -12.4235,  14.1530,  -8.2690]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6259033679962158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2588, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9362,  9.2716, 10.7196],\n",
      "        [15.1186,  8.7434, 10.6200],\n",
      "        [15.4268,  8.6088, 10.5534],\n",
      "        [15.0048,  9.0665, 10.9375],\n",
      "        [14.6106,  9.1448, 11.1877],\n",
      "        [15.0790,  9.1465, 10.9345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7927, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4581,  14.1613,  -7.8917],\n",
      "        [-12.6784,  13.9667,  -8.6055],\n",
      "        [-12.5672,  14.0649,  -7.9580],\n",
      "        [-12.9079,  14.2430,  -8.1894],\n",
      "        [-12.5447,  14.3196,  -8.1845],\n",
      "        [-12.9016,  13.9428,  -8.4359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9362,   9.2716,  10.7196, -12.4581,  14.1613,  -7.8917],\n",
      "        [ 15.1186,   8.7434,  10.6200, -12.6784,  13.9667,  -8.6055],\n",
      "        [ 15.4268,   8.6088,  10.5534, -12.5672,  14.0649,  -7.9580],\n",
      "        [ 15.0048,   9.0665,  10.9375, -12.9079,  14.2430,  -8.1894],\n",
      "        [ 14.6106,   9.1448,  11.1877, -12.5447,  14.3196,  -8.1845],\n",
      "        [ 15.0790,   9.1465,  10.9345, -12.9016,  13.9428,  -8.4359]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6181665658950806\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7097, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.8471,  9.2137, 10.6916],\n",
      "        [15.0640,  9.0084, 10.6638],\n",
      "        [15.1485,  9.1500, 10.8453],\n",
      "        [14.7993,  9.0470, 10.9460],\n",
      "        [15.0054,  9.0004, 11.2850],\n",
      "        [15.1631,  9.2672, 10.7130]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8974, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8445,  14.7944,  -8.2223],\n",
      "        [-12.7400,  14.4417,  -8.1625],\n",
      "        [-13.1187,  14.4725,  -8.5330],\n",
      "        [-12.4184,  14.4810,  -8.4496],\n",
      "        [-13.1002,  14.5488,  -8.1305],\n",
      "        [-13.0625,  14.5434,  -8.3991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.8471,   9.2137,  10.6916, -12.8445,  14.7944,  -8.2223],\n",
      "        [ 15.0640,   9.0084,  10.6638, -12.7400,  14.4417,  -8.1625],\n",
      "        [ 15.1485,   9.1500,  10.8453, -13.1187,  14.4725,  -8.5330],\n",
      "        [ 14.7993,   9.0470,  10.9460, -12.4184,  14.4810,  -8.4496],\n",
      "        [ 15.0054,   9.0004,  11.2850, -13.1002,  14.5488,  -8.1305],\n",
      "        [ 15.1631,   9.2672,  10.7130, -13.0625,  14.5434,  -8.3991]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6368061304092407\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2250,  9.0717, 10.8368],\n",
      "        [15.6452,  9.2988, 11.1851],\n",
      "        [14.8285,  9.1461, 10.8361],\n",
      "        [15.2348,  8.9566, 10.9408],\n",
      "        [14.8937,  8.8108, 10.8582],\n",
      "        [15.3381,  9.2487, 11.0126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5795, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.0229,  14.1845,  -8.4067],\n",
      "        [-12.5593,  14.5535,  -8.5646],\n",
      "        [-13.1947,  14.8217,  -8.6251],\n",
      "        [-13.0489,  14.3841,  -8.2555],\n",
      "        [-12.6379,  14.4545,  -8.2865],\n",
      "        [-13.0474,  14.1374,  -8.3565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2250,   9.0717,  10.8368, -13.0229,  14.1845,  -8.4067],\n",
      "        [ 15.6452,   9.2988,  11.1851, -12.5593,  14.5535,  -8.5646],\n",
      "        [ 14.8285,   9.1461,  10.8361, -13.1947,  14.8217,  -8.6251],\n",
      "        [ 15.2348,   8.9566,  10.9408, -13.0489,  14.3841,  -8.2555],\n",
      "        [ 14.8937,   8.8108,  10.8582, -12.6379,  14.4545,  -8.2865],\n",
      "        [ 15.3381,   9.2487,  11.0126, -13.0474,  14.1374,  -8.3565]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.646562099456787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0847,  9.0822, 10.6005],\n",
      "        [15.3901,  9.3220, 10.9693],\n",
      "        [15.2217,  8.9324, 10.9239],\n",
      "        [15.1034,  9.4430, 10.8891],\n",
      "        [15.4695,  9.0728, 10.9562],\n",
      "        [15.0125,  9.0956, 11.1651]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8830,  14.6669,  -8.3545],\n",
      "        [-12.9843,  14.2433,  -8.4523],\n",
      "        [-13.2890,  14.5669,  -8.6243],\n",
      "        [-12.7691,  14.3439,  -8.5304],\n",
      "        [-12.8276,  14.1723,  -8.3468],\n",
      "        [-12.9005,  14.2185,  -8.4722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0847,   9.0822,  10.6005, -12.8830,  14.6669,  -8.3545],\n",
      "        [ 15.3901,   9.3220,  10.9693, -12.9843,  14.2433,  -8.4523],\n",
      "        [ 15.2217,   8.9324,  10.9239, -13.2890,  14.5669,  -8.6243],\n",
      "        [ 15.1034,   9.4430,  10.8891, -12.7691,  14.3439,  -8.5304],\n",
      "        [ 15.4695,   9.0728,  10.9562, -12.8276,  14.1723,  -8.3468],\n",
      "        [ 15.0125,   9.0956,  11.1651, -12.9005,  14.2185,  -8.4722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6422924995422363\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1397,  8.9392, 11.0446],\n",
      "        [15.1300,  8.9835, 10.9034],\n",
      "        [14.9709,  9.1202, 10.8198],\n",
      "        [15.0653,  8.9187, 10.5766],\n",
      "        [15.1423,  8.9984, 10.6461],\n",
      "        [15.4396,  9.3213, 10.7578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7034, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7751,  14.7349,  -8.5705],\n",
      "        [-12.8523,  14.2916,  -8.5234],\n",
      "        [-13.2566,  14.4850,  -8.3862],\n",
      "        [-12.8983,  14.3816,  -8.6705],\n",
      "        [-12.8325,  14.3458,  -8.4785],\n",
      "        [-13.0165,  14.5551,  -8.5947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1397,   8.9392,  11.0446, -12.7751,  14.7349,  -8.5705],\n",
      "        [ 15.1300,   8.9835,  10.9034, -12.8523,  14.2916,  -8.5234],\n",
      "        [ 14.9709,   9.1202,  10.8198, -13.2566,  14.4850,  -8.3862],\n",
      "        [ 15.0653,   8.9187,  10.5766, -12.8983,  14.3816,  -8.6705],\n",
      "        [ 15.1423,   8.9984,  10.6461, -12.8325,  14.3458,  -8.4785],\n",
      "        [ 15.4396,   9.3213,  10.7578, -13.0165,  14.5551,  -8.5947]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6572070121765137\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2564,  9.0415, 11.0848],\n",
      "        [15.1915,  9.3279, 10.9367],\n",
      "        [15.7022,  9.5505, 11.0192],\n",
      "        [15.1748,  9.0939, 10.7407],\n",
      "        [14.7577,  9.0265, 10.8003],\n",
      "        [15.6299,  9.1537, 11.1737]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8012,  14.0351,  -8.2160],\n",
      "        [-12.9637,  14.5561,  -8.4010],\n",
      "        [-12.9588,  14.8237,  -8.4834],\n",
      "        [-13.0437,  14.3114,  -8.3261],\n",
      "        [-12.8464,  14.0709,  -8.3429],\n",
      "        [-13.0178,  14.4653,  -8.5303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2564,   9.0415,  11.0848, -12.8012,  14.0351,  -8.2160],\n",
      "        [ 15.1915,   9.3279,  10.9367, -12.9637,  14.5561,  -8.4010],\n",
      "        [ 15.7022,   9.5505,  11.0192, -12.9588,  14.8237,  -8.4834],\n",
      "        [ 15.1748,   9.0939,  10.7407, -13.0437,  14.3114,  -8.3261],\n",
      "        [ 14.7577,   9.0265,  10.8003, -12.8464,  14.0709,  -8.3429],\n",
      "        [ 15.6299,   9.1537,  11.1737, -13.0178,  14.4653,  -8.5303]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6482517719268799\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3022,  9.0327, 10.4470],\n",
      "        [14.8926,  8.9427, 10.8716],\n",
      "        [15.4667,  9.2454, 10.8085],\n",
      "        [15.0557,  8.8348, 10.7644],\n",
      "        [15.3869,  9.2690, 10.9930],\n",
      "        [15.3904,  9.4716, 10.8984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.0619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7558,  14.6836,  -8.3334],\n",
      "        [-13.1988,  14.3888,  -8.2245],\n",
      "        [-13.1253,  14.3443,  -8.5672],\n",
      "        [-13.1476,  14.4915,  -8.4254],\n",
      "        [-12.9773,  14.1369,  -8.2820],\n",
      "        [-12.8437,  14.1699,  -8.3653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3022,   9.0327,  10.4470, -12.7558,  14.6836,  -8.3334],\n",
      "        [ 14.8926,   8.9427,  10.8716, -13.1988,  14.3888,  -8.2245],\n",
      "        [ 15.4667,   9.2454,  10.8085, -13.1253,  14.3443,  -8.5672],\n",
      "        [ 15.0557,   8.8348,  10.7644, -13.1476,  14.4915,  -8.4254],\n",
      "        [ 15.3869,   9.2690,  10.9930, -12.9773,  14.1369,  -8.2820],\n",
      "        [ 15.3904,   9.4716,  10.8984, -12.8437,  14.1699,  -8.3653]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.645996332168579\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1284,  8.7644, 11.0697],\n",
      "        [14.9979,  9.1645, 10.8294],\n",
      "        [15.0860,  9.1478, 10.4768],\n",
      "        [14.8810,  9.1492, 10.6873],\n",
      "        [14.6690,  8.9465, 10.7226],\n",
      "        [15.0546,  9.1495, 11.2926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6218, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.0174,  14.3848,  -8.7939],\n",
      "        [-13.1605,  14.8531,  -8.8731],\n",
      "        [-12.7303,  14.5470,  -8.3718],\n",
      "        [-12.3569,  14.5583,  -8.3850],\n",
      "        [-12.7958,  14.1388,  -8.3817],\n",
      "        [-12.7498,  14.4100,  -7.9067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1284,   8.7644,  11.0697, -13.0174,  14.3848,  -8.7939],\n",
      "        [ 14.9979,   9.1645,  10.8294, -13.1605,  14.8531,  -8.8731],\n",
      "        [ 15.0860,   9.1478,  10.4768, -12.7303,  14.5470,  -8.3718],\n",
      "        [ 14.8810,   9.1492,  10.6873, -12.3569,  14.5583,  -8.3850],\n",
      "        [ 14.6690,   8.9465,  10.7226, -12.7958,  14.1388,  -8.3817],\n",
      "        [ 15.0546,   9.1495,  11.2926, -12.7498,  14.4100,  -7.9067]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.656805396080017\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6749, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3548,  9.4371, 11.3147],\n",
      "        [15.7792,  9.3592, 10.9837],\n",
      "        [15.8331,  9.2493, 11.0103],\n",
      "        [14.9900,  9.0472, 10.9384],\n",
      "        [15.2735,  9.4640, 10.9875],\n",
      "        [15.4648,  8.9357, 11.0453]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9813,  14.3344,  -8.5285],\n",
      "        [-12.8280,  13.7960,  -8.3823],\n",
      "        [-12.6317,  14.0628,  -8.2219],\n",
      "        [-12.9645,  14.3898,  -8.1802],\n",
      "        [-12.9652,  14.2021,  -8.5016],\n",
      "        [-12.7939,  14.1872,  -8.0302]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3548,   9.4371,  11.3147, -12.9813,  14.3344,  -8.5285],\n",
      "        [ 15.7792,   9.3592,  10.9837, -12.8280,  13.7960,  -8.3823],\n",
      "        [ 15.8331,   9.2493,  11.0103, -12.6317,  14.0628,  -8.2219],\n",
      "        [ 14.9900,   9.0472,  10.9384, -12.9645,  14.3898,  -8.1802],\n",
      "        [ 15.2735,   9.4640,  10.9875, -12.9652,  14.2021,  -8.5016],\n",
      "        [ 15.4648,   8.9357,  11.0453, -12.7939,  14.1872,  -8.0302]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.680698037147522\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9694, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4365,  9.5487, 10.7851],\n",
      "        [15.3851,  9.3006, 10.6253],\n",
      "        [15.0048,  9.2379, 10.5808],\n",
      "        [14.8593,  9.1305, 10.7208],\n",
      "        [15.2523,  9.2873, 11.0887],\n",
      "        [15.4608,  9.1724, 10.9515]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.0134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8461,  14.1788,  -8.0828],\n",
      "        [-13.1137,  14.3120,  -8.7172],\n",
      "        [-12.9627,  14.4168,  -8.5135],\n",
      "        [-12.6680,  14.6994,  -8.4885],\n",
      "        [-13.2957,  14.2172,  -8.2025],\n",
      "        [-12.8902,  14.2332,  -8.3951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4365,   9.5487,  10.7851, -12.8461,  14.1788,  -8.0828],\n",
      "        [ 15.3851,   9.3006,  10.6253, -13.1137,  14.3120,  -8.7172],\n",
      "        [ 15.0048,   9.2379,  10.5808, -12.9627,  14.4168,  -8.5135],\n",
      "        [ 14.8593,   9.1305,  10.7208, -12.6680,  14.6994,  -8.4885],\n",
      "        [ 15.2523,   9.2873,  11.0887, -13.2957,  14.2172,  -8.2025],\n",
      "        [ 15.4608,   9.1724,  10.9515, -12.8902,  14.2332,  -8.3951]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6614034175872803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8964, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5258,  9.2018, 10.6538],\n",
      "        [15.5606,  9.1379, 11.0093],\n",
      "        [15.4541,  9.1918, 11.1151],\n",
      "        [15.0989,  9.7342, 10.8838],\n",
      "        [15.1923,  9.1096, 10.9230],\n",
      "        [15.3222,  9.1871, 10.6696]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1574,  14.5359,  -8.6789],\n",
      "        [-13.0236,  14.4566,  -8.5867],\n",
      "        [-13.0350,  14.2512,  -8.6479],\n",
      "        [-12.9938,  14.4636,  -8.5242],\n",
      "        [-12.6261,  14.3269,  -8.0511],\n",
      "        [-12.8894,  14.2096,  -8.1803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5258,   9.2018,  10.6538, -13.1574,  14.5359,  -8.6789],\n",
      "        [ 15.5606,   9.1379,  11.0093, -13.0236,  14.4566,  -8.5867],\n",
      "        [ 15.4541,   9.1918,  11.1151, -13.0350,  14.2512,  -8.6479],\n",
      "        [ 15.0989,   9.7342,  10.8838, -12.9938,  14.4636,  -8.5242],\n",
      "        [ 15.1923,   9.1096,  10.9230, -12.6261,  14.3269,  -8.0511],\n",
      "        [ 15.3222,   9.1871,  10.6696, -12.8894,  14.2096,  -8.1803]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.674831509590149\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2481,  9.1050, 10.7022],\n",
      "        [15.1648,  9.2915, 11.2043],\n",
      "        [15.2258,  9.6938, 10.9161],\n",
      "        [15.0303,  8.7861, 10.6021],\n",
      "        [15.7027,  9.4039, 10.8884],\n",
      "        [15.4310,  9.1989, 11.1782]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4890,  14.2608,  -8.0286],\n",
      "        [-12.9839,  14.2630,  -8.2069],\n",
      "        [-13.0863,  14.4553,  -8.6993],\n",
      "        [-13.1064,  14.2761,  -8.4613],\n",
      "        [-12.7563,  14.1199,  -8.1126],\n",
      "        [-13.1681,  14.4832,  -8.7488]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2481,   9.1050,  10.7022, -12.4890,  14.2608,  -8.0286],\n",
      "        [ 15.1648,   9.2915,  11.2043, -12.9839,  14.2630,  -8.2069],\n",
      "        [ 15.2258,   9.6938,  10.9161, -13.0863,  14.4553,  -8.6993],\n",
      "        [ 15.0303,   8.7861,  10.6021, -13.1064,  14.2761,  -8.4613],\n",
      "        [ 15.7027,   9.4039,  10.8884, -12.7563,  14.1199,  -8.1126],\n",
      "        [ 15.4310,   9.1989,  11.1782, -13.1681,  14.4832,  -8.7488]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.640738844871521\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1020, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1637,  9.4082, 10.3836],\n",
      "        [15.1039,  9.5226, 11.0229],\n",
      "        [15.2092,  9.4927, 10.8474],\n",
      "        [15.2672,  9.1877, 10.6682],\n",
      "        [15.4285,  9.3935, 11.3394],\n",
      "        [14.8941,  8.9930, 10.7765]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.3282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9639,  14.4266,  -8.7147],\n",
      "        [-13.0527,  13.9967,  -8.2413],\n",
      "        [-13.0455,  14.4119,  -8.5268],\n",
      "        [-12.7524,  14.2622,  -8.4521],\n",
      "        [-12.7681,  14.5416,  -8.3480],\n",
      "        [-13.2145,  14.5331,  -8.7128]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1637,   9.4082,  10.3836, -12.9639,  14.4266,  -8.7147],\n",
      "        [ 15.1039,   9.5226,  11.0229, -13.0527,  13.9967,  -8.2413],\n",
      "        [ 15.2092,   9.4927,  10.8474, -13.0455,  14.4119,  -8.5268],\n",
      "        [ 15.2672,   9.1877,  10.6682, -12.7524,  14.2622,  -8.4521],\n",
      "        [ 15.4285,   9.3935,  11.3394, -12.7681,  14.5416,  -8.3480],\n",
      "        [ 14.8941,   8.9930,  10.7765, -13.2145,  14.5331,  -8.7128]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6534693241119385\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0524, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4305,  9.6305, 10.9151],\n",
      "        [15.6558,  9.1601, 10.8714],\n",
      "        [15.3067,  9.5913, 10.9479],\n",
      "        [15.4631,  9.2988, 10.8669],\n",
      "        [15.3567,  9.5030, 10.9468],\n",
      "        [14.8095,  9.0610, 10.6503]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2514,  14.6360,  -8.7366],\n",
      "        [-12.5533,  14.4215,  -8.4401],\n",
      "        [-12.8168,  13.7049,  -7.9107],\n",
      "        [-12.7846,  14.5876,  -8.3415],\n",
      "        [-13.1523,  14.4486,  -8.2170],\n",
      "        [-12.7438,  14.3458,  -8.4079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4305,   9.6305,  10.9151, -13.2514,  14.6360,  -8.7366],\n",
      "        [ 15.6558,   9.1601,  10.8714, -12.5533,  14.4215,  -8.4401],\n",
      "        [ 15.3067,   9.5913,  10.9479, -12.8168,  13.7049,  -7.9107],\n",
      "        [ 15.4631,   9.2988,  10.8669, -12.7846,  14.5876,  -8.3415],\n",
      "        [ 15.3567,   9.5030,  10.9468, -13.1523,  14.4486,  -8.2170],\n",
      "        [ 14.8095,   9.0610,  10.6503, -12.7438,  14.3458,  -8.4079]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6933239698410034\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[14.9725,  9.3507, 10.7423],\n",
      "        [15.4043,  9.1262, 11.0870],\n",
      "        [15.1770,  9.2851, 10.7265],\n",
      "        [15.1519,  9.3062, 10.7779],\n",
      "        [15.1409,  9.4097, 10.8785],\n",
      "        [15.2219,  9.1814, 10.5046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6663, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9229,  14.1989,  -8.5581],\n",
      "        [-13.2216,  14.6397,  -8.6402],\n",
      "        [-13.0993,  14.3283,  -8.5000],\n",
      "        [-13.3935,  14.5161,  -8.7697],\n",
      "        [-12.1871,  14.2655,  -8.3220],\n",
      "        [-12.8059,  14.2801,  -8.3252]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 14.9725,   9.3507,  10.7423, -12.9229,  14.1989,  -8.5581],\n",
      "        [ 15.4043,   9.1262,  11.0870, -13.2216,  14.6397,  -8.6402],\n",
      "        [ 15.1770,   9.2851,  10.7265, -13.0993,  14.3283,  -8.5000],\n",
      "        [ 15.1519,   9.3062,  10.7779, -13.3935,  14.5161,  -8.7697],\n",
      "        [ 15.1409,   9.4097,  10.8785, -12.1871,  14.2655,  -8.3220],\n",
      "        [ 15.2219,   9.1814,  10.5046, -12.8059,  14.2801,  -8.3252]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6503868103027344\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4873,  9.4098, 11.0278],\n",
      "        [14.9293,  9.5718, 10.8544],\n",
      "        [15.4805,  9.4089, 11.1362],\n",
      "        [15.2196,  9.4200, 10.6550],\n",
      "        [14.9950,  9.3607, 10.8508],\n",
      "        [15.3464,  9.2926, 10.6833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.0444,  14.6295,  -8.9089],\n",
      "        [-12.8883,  14.0890,  -8.6268],\n",
      "        [-12.8541,  14.4734,  -8.5381],\n",
      "        [-13.2060,  14.7504,  -8.8852],\n",
      "        [-12.8660,  14.5761,  -8.4996],\n",
      "        [-12.8019,  14.3030,  -8.2948]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4873,   9.4098,  11.0278, -13.0444,  14.6295,  -8.9089],\n",
      "        [ 14.9293,   9.5718,  10.8544, -12.8883,  14.0890,  -8.6268],\n",
      "        [ 15.4805,   9.4089,  11.1362, -12.8541,  14.4734,  -8.5381],\n",
      "        [ 15.2196,   9.4200,  10.6550, -13.2060,  14.7504,  -8.8852],\n",
      "        [ 14.9950,   9.3607,  10.8508, -12.8660,  14.5761,  -8.4996],\n",
      "        [ 15.3464,   9.2926,  10.6833, -12.8019,  14.3030,  -8.2948]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.694761037826538\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3416,  9.4308, 10.5430],\n",
      "        [15.4175,  8.9673, 11.0547],\n",
      "        [15.4299,  9.0482, 11.0444],\n",
      "        [15.4865,  8.8954, 11.2361],\n",
      "        [15.7188,  9.4681, 10.9460],\n",
      "        [15.4965,  9.6471, 11.2778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6211, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9504,  14.2836,  -8.7837],\n",
      "        [-13.1703,  14.6979,  -8.4792],\n",
      "        [-12.8508,  14.4091,  -8.4542],\n",
      "        [-12.7725,  14.6437,  -8.8894],\n",
      "        [-13.4034,  14.5454,  -8.5866],\n",
      "        [-12.7615,  14.5488,  -8.5963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3416,   9.4308,  10.5430, -12.9504,  14.2836,  -8.7837],\n",
      "        [ 15.4175,   8.9673,  11.0547, -13.1703,  14.6979,  -8.4792],\n",
      "        [ 15.4299,   9.0482,  11.0444, -12.8508,  14.4091,  -8.4542],\n",
      "        [ 15.4865,   8.8954,  11.2361, -12.7725,  14.6437,  -8.8894],\n",
      "        [ 15.7188,   9.4681,  10.9460, -13.4034,  14.5454,  -8.5866],\n",
      "        [ 15.4965,   9.6471,  11.2778, -12.7615,  14.5488,  -8.5963]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6665809154510498\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9794, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4877,  9.4088, 11.2752],\n",
      "        [15.1998,  9.5605, 10.4163],\n",
      "        [14.9181,  9.1305, 10.8912],\n",
      "        [15.5674,  9.2773, 11.0658],\n",
      "        [15.6035,  9.2522, 11.2010],\n",
      "        [15.1947,  9.5688, 10.9197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2891, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8800,  14.8270,  -8.8692],\n",
      "        [-13.2176,  14.9312,  -8.8710],\n",
      "        [-12.3887,  14.2039,  -8.2450],\n",
      "        [-12.9667,  14.3610,  -8.4312],\n",
      "        [-12.7503,  14.5356,  -8.2823],\n",
      "        [-12.7921,  14.3057,  -8.5294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4877,   9.4088,  11.2752, -12.8800,  14.8270,  -8.8692],\n",
      "        [ 15.1998,   9.5605,  10.4163, -13.2176,  14.9312,  -8.8710],\n",
      "        [ 14.9181,   9.1305,  10.8912, -12.3887,  14.2039,  -8.2450],\n",
      "        [ 15.5674,   9.2773,  11.0658, -12.9667,  14.3610,  -8.4312],\n",
      "        [ 15.6035,   9.2522,  11.2010, -12.7503,  14.5356,  -8.2823],\n",
      "        [ 15.1947,   9.5688,  10.9197, -12.7921,  14.3057,  -8.5294]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7044591903686523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5127, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3548,  9.6479, 11.1755],\n",
      "        [15.3663,  9.4860, 11.1695],\n",
      "        [15.0913,  9.1851, 10.7304],\n",
      "        [15.3442,  9.2223, 11.0052],\n",
      "        [15.2841,  9.5101, 10.5235],\n",
      "        [15.2211,  9.1360, 11.0801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6843,  14.5235,  -8.5114],\n",
      "        [-12.7270,  14.1518,  -8.5051],\n",
      "        [-13.3993,  14.8724,  -8.8090],\n",
      "        [-13.3502,  14.4199,  -8.8224],\n",
      "        [-13.4070,  14.4798,  -8.5787],\n",
      "        [-12.5995,  14.3761,  -8.3736]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3548,   9.6479,  11.1755, -12.6843,  14.5235,  -8.5114],\n",
      "        [ 15.3663,   9.4860,  11.1695, -12.7270,  14.1518,  -8.5051],\n",
      "        [ 15.0913,   9.1851,  10.7304, -13.3993,  14.8724,  -8.8090],\n",
      "        [ 15.3442,   9.2223,  11.0052, -13.3502,  14.4199,  -8.8224],\n",
      "        [ 15.2841,   9.5101,  10.5235, -13.4070,  14.4798,  -8.5787],\n",
      "        [ 15.2211,   9.1360,  11.0801, -12.5995,  14.3761,  -8.3736]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6882705688476562\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4154, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4230,  8.9158, 10.6895],\n",
      "        [15.3012,  9.2267, 11.0319],\n",
      "        [15.5631,  9.3500, 11.0655],\n",
      "        [15.2274,  9.2922, 11.0729],\n",
      "        [15.7057,  9.6122, 11.4615],\n",
      "        [15.1535,  8.9624, 11.1391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4216, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1412,  14.3579,  -8.8717],\n",
      "        [-12.6094,  14.0838,  -8.5658],\n",
      "        [-13.0686,  14.4983,  -8.6191],\n",
      "        [-12.6803,  14.4755,  -8.2950],\n",
      "        [-12.8535,  14.2661,  -8.2627],\n",
      "        [-12.7681,  14.0380,  -8.5895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4230,   8.9158,  10.6895, -13.1412,  14.3579,  -8.8717],\n",
      "        [ 15.3012,   9.2267,  11.0319, -12.6094,  14.0838,  -8.5658],\n",
      "        [ 15.5631,   9.3500,  11.0655, -13.0686,  14.4983,  -8.6191],\n",
      "        [ 15.2274,   9.2922,  11.0729, -12.6803,  14.4755,  -8.2950],\n",
      "        [ 15.7057,   9.6122,  11.4615, -12.8535,  14.2661,  -8.2627],\n",
      "        [ 15.1535,   8.9624,  11.1391, -12.7681,  14.0380,  -8.5895]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6735727787017822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7109, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1683,  9.7786, 10.8419],\n",
      "        [15.0166,  8.9601, 11.0811],\n",
      "        [15.0939,  9.3180, 11.0327],\n",
      "        [15.2500,  9.0361, 11.2578],\n",
      "        [15.6433,  9.2948, 11.1670],\n",
      "        [15.8121,  9.3792, 10.9622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5090, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.4772,  14.3554,  -8.5124],\n",
      "        [-13.0134,  14.4040,  -8.5936],\n",
      "        [-13.2068,  14.5951,  -8.9322],\n",
      "        [-13.1451,  14.9574,  -9.0260],\n",
      "        [-12.7631,  14.4827,  -8.6035],\n",
      "        [-13.1572,  14.8327,  -8.3984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1683,   9.7786,  10.8419, -12.4772,  14.3554,  -8.5124],\n",
      "        [ 15.0166,   8.9601,  11.0811, -13.0134,  14.4040,  -8.5936],\n",
      "        [ 15.0939,   9.3180,  11.0327, -13.2068,  14.5951,  -8.9322],\n",
      "        [ 15.2500,   9.0361,  11.2578, -13.1451,  14.9574,  -9.0260],\n",
      "        [ 15.6433,   9.2948,  11.1670, -12.7631,  14.4827,  -8.6035],\n",
      "        [ 15.8121,   9.3792,  10.9622, -13.1572,  14.8327,  -8.3984]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6686094999313354\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2034, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5082,  9.1374, 10.7955],\n",
      "        [15.2647,  9.2706, 11.0597],\n",
      "        [15.7411,  9.5740, 11.1605],\n",
      "        [15.2333,  9.2336, 10.8796],\n",
      "        [15.3601,  9.5669, 11.1633],\n",
      "        [15.5356,  9.3874, 11.2884]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5219, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9108,  14.5872,  -8.6514],\n",
      "        [-12.8376,  14.5192,  -8.5111],\n",
      "        [-13.0747,  14.4878,  -8.7104],\n",
      "        [-12.8198,  14.3538,  -8.6876],\n",
      "        [-13.4011,  14.3357,  -8.5501],\n",
      "        [-12.9071,  14.4554,  -8.6548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5082,   9.1374,  10.7955, -12.9108,  14.5872,  -8.6514],\n",
      "        [ 15.2647,   9.2706,  11.0597, -12.8376,  14.5192,  -8.5111],\n",
      "        [ 15.7411,   9.5740,  11.1605, -13.0747,  14.4878,  -8.7104],\n",
      "        [ 15.2333,   9.2336,  10.8796, -12.8198,  14.3538,  -8.6876],\n",
      "        [ 15.3601,   9.5669,  11.1633, -13.4011,  14.3357,  -8.5501],\n",
      "        [ 15.5356,   9.3874,  11.2884, -12.9071,  14.4554,  -8.6548]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6839102506637573\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4598,  9.7220, 11.3953],\n",
      "        [15.7581,  9.4373, 10.8699],\n",
      "        [15.3036,  9.2398, 11.2038],\n",
      "        [15.2914,  9.6127, 10.9157],\n",
      "        [15.2790,  9.4307, 10.9871],\n",
      "        [15.3164,  9.0285, 10.6257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.5525, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8849,  14.3280,  -8.7643],\n",
      "        [-13.1486,  14.6321,  -8.4435],\n",
      "        [-12.7739,  14.9312,  -8.4261],\n",
      "        [-12.8361,  14.2077,  -8.8350],\n",
      "        [-12.9758,  14.4093,  -8.7672],\n",
      "        [-12.9177,  14.1408,  -8.1885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4598,   9.7220,  11.3953, -12.8849,  14.3280,  -8.7643],\n",
      "        [ 15.7581,   9.4373,  10.8699, -13.1486,  14.6321,  -8.4435],\n",
      "        [ 15.3036,   9.2398,  11.2038, -12.7739,  14.9312,  -8.4261],\n",
      "        [ 15.2914,   9.6127,  10.9157, -12.8361,  14.2077,  -8.8350],\n",
      "        [ 15.2790,   9.4307,  10.9871, -12.9758,  14.4093,  -8.7672],\n",
      "        [ 15.3164,   9.0285,  10.6257, -12.9177,  14.1408,  -8.1885]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7060060501098633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7291, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3704,  9.6985, 10.9585],\n",
      "        [15.5936,  9.1665, 11.3450],\n",
      "        [15.7248,  9.7938, 10.9522],\n",
      "        [15.1382,  9.5770, 10.9979],\n",
      "        [15.5874,  9.2026, 10.9298],\n",
      "        [15.6760,  9.5057, 11.0580]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.4580, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2421,  14.4871,  -8.9065],\n",
      "        [-13.0155,  14.3173,  -8.3219],\n",
      "        [-12.9985,  14.4916,  -8.7046],\n",
      "        [-12.7857,  14.7740,  -8.8305],\n",
      "        [-13.0624,  14.0808,  -7.9440],\n",
      "        [-13.0951,  14.3983,  -8.6379]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3704,   9.6985,  10.9585, -13.2421,  14.4871,  -8.9065],\n",
      "        [ 15.5936,   9.1665,  11.3450, -13.0155,  14.3173,  -8.3219],\n",
      "        [ 15.7248,   9.7938,  10.9522, -12.9985,  14.4916,  -8.7046],\n",
      "        [ 15.1382,   9.5770,  10.9979, -12.7857,  14.7740,  -8.8305],\n",
      "        [ 15.5874,   9.2026,  10.9298, -13.0624,  14.0808,  -7.9440],\n",
      "        [ 15.6760,   9.5057,  11.0580, -13.0951,  14.3983,  -8.6379]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7016793489456177\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5679,  9.3279, 10.8359],\n",
      "        [15.0795,  9.2811, 10.7410],\n",
      "        [15.5433,  9.4138, 11.2830],\n",
      "        [15.7261,  9.5355, 11.2212],\n",
      "        [15.3269,  9.2106, 11.1183],\n",
      "        [15.0423,  9.0301, 11.0400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2531, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9693,  14.8677,  -8.4692],\n",
      "        [-13.0414,  14.3476,  -8.8058],\n",
      "        [-13.2481,  15.0067,  -8.7307],\n",
      "        [-12.8744,  14.2429,  -8.4439],\n",
      "        [-13.0030,  14.2039,  -8.3461],\n",
      "        [-12.9807,  14.4400,  -8.3104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5679,   9.3279,  10.8359, -12.9693,  14.8677,  -8.4692],\n",
      "        [ 15.0795,   9.2811,  10.7410, -13.0414,  14.3476,  -8.8058],\n",
      "        [ 15.5433,   9.4138,  11.2830, -13.2481,  15.0067,  -8.7307],\n",
      "        [ 15.7261,   9.5355,  11.2212, -12.8744,  14.2429,  -8.4439],\n",
      "        [ 15.3269,   9.2106,  11.1183, -13.0030,  14.2039,  -8.3461],\n",
      "        [ 15.0423,   9.0301,  11.0400, -12.9807,  14.4400,  -8.3104]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6984245777130127\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3887,  9.2179, 11.4447],\n",
      "        [15.1450,  9.4897, 11.0528],\n",
      "        [14.8711,  9.4831, 10.9157],\n",
      "        [14.8528,  9.2856, 10.7409],\n",
      "        [15.5180,  9.6742, 11.1262],\n",
      "        [15.6273,  9.4688, 11.2934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9216, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8555,  14.3751,  -8.2873],\n",
      "        [-12.9807,  14.5783,  -8.4469],\n",
      "        [-12.9355,  14.5264,  -8.4229],\n",
      "        [-12.6762,  14.3666,  -8.5878],\n",
      "        [-12.8080,  14.6942,  -9.0234],\n",
      "        [-12.9357,  14.5844,  -8.5753]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3887,   9.2179,  11.4447, -12.8555,  14.3751,  -8.2873],\n",
      "        [ 15.1450,   9.4897,  11.0528, -12.9807,  14.5783,  -8.4469],\n",
      "        [ 14.8711,   9.4831,  10.9157, -12.9355,  14.5264,  -8.4229],\n",
      "        [ 14.8528,   9.2856,  10.7409, -12.6762,  14.3666,  -8.5878],\n",
      "        [ 15.5180,   9.6742,  11.1262, -12.8080,  14.6942,  -9.0234],\n",
      "        [ 15.6273,   9.4688,  11.2934, -12.9357,  14.5844,  -8.5753]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6941416263580322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5324,  9.5383, 11.0530],\n",
      "        [15.2776,  9.6587, 10.8648],\n",
      "        [15.6039,  9.6717, 11.4270],\n",
      "        [15.5439,  9.4286, 11.3252],\n",
      "        [15.4838,  9.4502, 11.1716],\n",
      "        [15.4612,  9.0603, 10.7250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5655, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8135,  14.5638,  -8.5126],\n",
      "        [-12.9669,  14.7543,  -8.8602],\n",
      "        [-12.7450,  14.9016,  -8.4060],\n",
      "        [-12.8935,  14.7724,  -8.6519],\n",
      "        [-13.5839,  14.6783,  -8.7510],\n",
      "        [-12.3047,  14.0081,  -7.8927]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5324,   9.5383,  11.0530, -12.8135,  14.5638,  -8.5126],\n",
      "        [ 15.2776,   9.6587,  10.8648, -12.9669,  14.7543,  -8.8602],\n",
      "        [ 15.6039,   9.6717,  11.4270, -12.7450,  14.9016,  -8.4060],\n",
      "        [ 15.5439,   9.4286,  11.3252, -12.8935,  14.7724,  -8.6519],\n",
      "        [ 15.4838,   9.4502,  11.1716, -13.5839,  14.6783,  -8.7510],\n",
      "        [ 15.4612,   9.0603,  10.7250, -12.3047,  14.0081,  -7.8927]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.7004008293151855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5062, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2034,  9.4944, 10.7371],\n",
      "        [15.5684,  9.4708, 11.1369],\n",
      "        [14.9923,  9.1632, 10.9505],\n",
      "        [15.4385,  9.3490, 10.8854],\n",
      "        [15.1687,  9.4609, 10.7825],\n",
      "        [15.6980,  9.6292, 11.1371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0206, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1803,  14.2069,  -8.5256],\n",
      "        [-13.2527,  14.8706,  -8.7599],\n",
      "        [-13.0150,  14.6600,  -8.3332],\n",
      "        [-13.3370,  14.3650,  -8.7292],\n",
      "        [-13.0451,  14.3045,  -8.6537],\n",
      "        [-12.9789,  14.1974,  -8.5445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2034,   9.4944,  10.7371, -13.1803,  14.2069,  -8.5256],\n",
      "        [ 15.5684,   9.4708,  11.1369, -13.2527,  14.8706,  -8.7599],\n",
      "        [ 14.9923,   9.1632,  10.9505, -13.0150,  14.6600,  -8.3332],\n",
      "        [ 15.4385,   9.3490,  10.8854, -13.3370,  14.3650,  -8.7292],\n",
      "        [ 15.1687,   9.4609,  10.7825, -13.0451,  14.3045,  -8.6537],\n",
      "        [ 15.6980,   9.6292,  11.1371, -12.9789,  14.1974,  -8.5445]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6782788038253784\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3954,  9.6444, 11.2108],\n",
      "        [15.5781,  9.6369, 11.1618],\n",
      "        [14.9167,  9.6460, 11.0238],\n",
      "        [15.3803,  9.4195, 11.0618],\n",
      "        [15.3947,  9.4594, 11.1202],\n",
      "        [15.2261,  9.4906, 10.8359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4664, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8288,  14.4639,  -8.4539],\n",
      "        [-13.2364,  14.6699,  -8.5125],\n",
      "        [-13.4523,  14.4771,  -8.7285],\n",
      "        [-13.1424,  14.9113,  -8.7512],\n",
      "        [-13.1832,  14.8568,  -8.7367],\n",
      "        [-12.8745,  14.6483,  -8.5251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3954,   9.6444,  11.2108, -12.8288,  14.4639,  -8.4539],\n",
      "        [ 15.5781,   9.6369,  11.1618, -13.2364,  14.6699,  -8.5125],\n",
      "        [ 14.9167,   9.6460,  11.0238, -13.4523,  14.4771,  -8.7285],\n",
      "        [ 15.3803,   9.4195,  11.0618, -13.1424,  14.9113,  -8.7512],\n",
      "        [ 15.3947,   9.4594,  11.1202, -13.1832,  14.8568,  -8.7367],\n",
      "        [ 15.2261,   9.4906,  10.8359, -12.8745,  14.6483,  -8.5251]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.701100468635559\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4936, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4938,  9.5841, 10.8622],\n",
      "        [15.3948,  9.3632, 10.6748],\n",
      "        [15.2041,  9.5413, 10.9740],\n",
      "        [15.4107,  9.6206, 10.7603],\n",
      "        [15.3939,  9.4810, 10.9745],\n",
      "        [15.6428,  9.2293, 11.1076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(4.6247, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3869,  14.3614,  -8.6461],\n",
      "        [-12.8825,  14.9302,  -8.8532],\n",
      "        [-13.3123,  14.3659,  -8.7771],\n",
      "        [-12.8859,  14.3779,  -8.5856],\n",
      "        [-13.4106,  14.7287,  -8.4753],\n",
      "        [-13.3369,  14.9383,  -8.7975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4938,   9.5841,  10.8622, -13.3869,  14.3614,  -8.6461],\n",
      "        [ 15.3948,   9.3632,  10.6748, -12.8825,  14.9302,  -8.8532],\n",
      "        [ 15.2041,   9.5413,  10.9740, -13.3123,  14.3659,  -8.7771],\n",
      "        [ 15.4107,   9.6206,  10.7603, -12.8859,  14.3779,  -8.5856],\n",
      "        [ 15.3939,   9.4810,  10.9745, -13.4106,  14.7287,  -8.4753],\n",
      "        [ 15.6428,   9.2293,  11.1076, -13.3369,  14.9383,  -8.7975]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7046732902526855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9781, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5028,  9.1897, 11.1983],\n",
      "        [15.2474,  9.6259, 10.9099],\n",
      "        [15.4833,  9.4355, 11.1150],\n",
      "        [15.2586,  9.4732, 11.2009],\n",
      "        [15.3561,  9.0005, 11.1299],\n",
      "        [15.6189,  9.6312, 11.0274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5450, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9481,  14.4058,  -8.5311],\n",
      "        [-13.3585,  14.7630,  -9.3167],\n",
      "        [-13.1897,  14.8558,  -8.7914],\n",
      "        [-13.0414,  14.7525,  -8.4130],\n",
      "        [-12.9942,  14.5598,  -8.6156],\n",
      "        [-12.9098,  14.2399,  -8.7001]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5028,   9.1897,  11.1983, -12.9481,  14.4058,  -8.5311],\n",
      "        [ 15.2474,   9.6259,  10.9099, -13.3585,  14.7630,  -9.3167],\n",
      "        [ 15.4833,   9.4355,  11.1150, -13.1897,  14.8558,  -8.7914],\n",
      "        [ 15.2586,   9.4732,  11.2009, -13.0414,  14.7525,  -8.4130],\n",
      "        [ 15.3561,   9.0005,  11.1299, -12.9942,  14.5598,  -8.6156],\n",
      "        [ 15.6189,   9.6312,  11.0274, -12.9098,  14.2399,  -8.7001]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7005048990249634\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7554, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6642,  9.7452, 11.2590],\n",
      "        [15.3257,  9.3637, 11.3128],\n",
      "        [15.2904,  9.2205, 10.7650],\n",
      "        [15.6609,  9.4702, 11.2225],\n",
      "        [15.3304,  9.7688, 11.1948],\n",
      "        [15.8145,  9.4805, 11.2629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2098,  14.3847,  -8.8419],\n",
      "        [-13.3339,  14.8140,  -8.4491],\n",
      "        [-12.7056,  14.7166,  -8.7777],\n",
      "        [-13.1413,  14.3679,  -8.6266],\n",
      "        [-13.0786,  14.7236,  -9.3010],\n",
      "        [-13.0852,  14.3766,  -8.6829]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6642,   9.7452,  11.2590, -13.2098,  14.3847,  -8.8419],\n",
      "        [ 15.3257,   9.3637,  11.3128, -13.3339,  14.8140,  -8.4491],\n",
      "        [ 15.2904,   9.2205,  10.7650, -12.7056,  14.7166,  -8.7777],\n",
      "        [ 15.6609,   9.4702,  11.2225, -13.1413,  14.3679,  -8.6266],\n",
      "        [ 15.3304,   9.7688,  11.1948, -13.0786,  14.7236,  -9.3010],\n",
      "        [ 15.8145,   9.4805,  11.2629, -13.0852,  14.3766,  -8.6829]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7268284559249878\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2891,  9.4546, 10.9785],\n",
      "        [15.5665,  9.4910, 11.0151],\n",
      "        [15.4638,  9.4389, 11.3607],\n",
      "        [15.5894,  9.5110, 10.8670],\n",
      "        [15.5879,  9.2277, 11.0484],\n",
      "        [15.6944,  9.3919, 11.0023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6048,  14.4273,  -8.2413],\n",
      "        [-12.7192,  14.6835,  -8.5088],\n",
      "        [-12.9482,  14.1570,  -8.7006],\n",
      "        [-13.1525,  14.8591,  -8.5378],\n",
      "        [-13.5261,  14.7007,  -8.4667],\n",
      "        [-13.2540,  14.3613,  -8.5824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2891,   9.4546,  10.9785, -12.6048,  14.4273,  -8.2413],\n",
      "        [ 15.5665,   9.4910,  11.0151, -12.7192,  14.6835,  -8.5088],\n",
      "        [ 15.4638,   9.4389,  11.3607, -12.9482,  14.1570,  -8.7006],\n",
      "        [ 15.5894,   9.5110,  10.8670, -13.1525,  14.8591,  -8.5378],\n",
      "        [ 15.5879,   9.2277,  11.0484, -13.5261,  14.7007,  -8.4667],\n",
      "        [ 15.6944,   9.3919,  11.0023, -13.2540,  14.3613,  -8.5824]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.6836872100830078\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5564,  9.5123, 11.2336],\n",
      "        [15.7548,  9.7977, 11.0714],\n",
      "        [15.5200,  9.7521, 10.6862],\n",
      "        [15.6938,  9.2852, 11.0846],\n",
      "        [15.5930,  9.6820, 11.1068],\n",
      "        [15.3284,  9.3177, 11.1914]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.8169, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8463,  14.4039,  -8.5516],\n",
      "        [-13.0097,  14.8101,  -8.5330],\n",
      "        [-13.2759,  14.3754,  -8.4762],\n",
      "        [-13.3705,  14.6519,  -8.6211],\n",
      "        [-13.2789,  14.4625,  -8.5150],\n",
      "        [-12.8834,  14.4336,  -8.4904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5564,   9.5123,  11.2336, -12.8463,  14.4039,  -8.5516],\n",
      "        [ 15.7548,   9.7977,  11.0714, -13.0097,  14.8101,  -8.5330],\n",
      "        [ 15.5200,   9.7521,  10.6862, -13.2759,  14.3754,  -8.4762],\n",
      "        [ 15.6938,   9.2852,  11.0846, -13.3705,  14.6519,  -8.6211],\n",
      "        [ 15.5930,   9.6820,  11.1068, -13.2789,  14.4625,  -8.5150],\n",
      "        [ 15.3284,   9.3177,  11.1914, -12.8834,  14.4336,  -8.4904]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7104922533035278\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0035, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.0732,  9.2809, 10.9346],\n",
      "        [15.6496,  9.4924, 11.1238],\n",
      "        [15.6136,  9.6550, 11.2859],\n",
      "        [15.7743,  9.4759, 11.4880],\n",
      "        [15.5874,  9.7891, 11.0827],\n",
      "        [15.2626,  9.3337, 10.8807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4005,  14.3921,  -8.8497],\n",
      "        [-13.0589,  14.7221,  -8.4436],\n",
      "        [-13.3553,  14.5633,  -8.8122],\n",
      "        [-12.9401,  14.7482,  -8.5869],\n",
      "        [-13.5444,  15.0097,  -9.0087],\n",
      "        [-12.8757,  14.6855,  -8.7435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.0732,   9.2809,  10.9346, -13.4005,  14.3921,  -8.8497],\n",
      "        [ 15.6496,   9.4924,  11.1238, -13.0589,  14.7221,  -8.4436],\n",
      "        [ 15.6136,   9.6550,  11.2859, -13.3553,  14.5633,  -8.8122],\n",
      "        [ 15.7743,   9.4759,  11.4880, -12.9401,  14.7482,  -8.5869],\n",
      "        [ 15.5874,   9.7891,  11.0827, -13.5444,  15.0097,  -9.0087],\n",
      "        [ 15.2626,   9.3337,  10.8807, -12.8757,  14.6855,  -8.7435]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.6930606365203857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(5.6879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3390,  9.1712, 11.2128],\n",
      "        [15.5132,  9.8248, 11.0028],\n",
      "        [15.3548,  9.2196, 10.7546],\n",
      "        [15.7494,  9.6189, 11.3311],\n",
      "        [15.5745,  9.2447, 11.2175],\n",
      "        [15.8183,  9.2227, 11.0477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9948, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1298,  14.8210,  -9.0410],\n",
      "        [-13.0286,  14.2945,  -8.5290],\n",
      "        [-13.2456,  14.4674,  -8.6828],\n",
      "        [-13.2667,  14.2875,  -8.7164],\n",
      "        [-13.6042,  14.9487,  -8.9902],\n",
      "        [-13.3061,  15.0597,  -9.0213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3390,   9.1712,  11.2128, -13.1298,  14.8210,  -9.0410],\n",
      "        [ 15.5132,   9.8248,  11.0028, -13.0286,  14.2945,  -8.5290],\n",
      "        [ 15.3548,   9.2196,  10.7546, -13.2456,  14.4674,  -8.6828],\n",
      "        [ 15.7494,   9.6189,  11.3311, -13.2667,  14.2875,  -8.7164],\n",
      "        [ 15.5745,   9.2447,  11.2175, -13.6042,  14.9487,  -8.9902],\n",
      "        [ 15.8183,   9.2227,  11.0477, -13.3061,  15.0597,  -9.0213]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7163008451461792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3563,  9.1761, 11.1355],\n",
      "        [15.3098,  8.9126, 11.3189],\n",
      "        [15.2542,  9.9568, 10.8357],\n",
      "        [15.5868,  8.9444, 11.1295],\n",
      "        [15.1962,  9.5014, 11.2003],\n",
      "        [15.7387,  9.6068, 11.1116]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3021,  14.6824,  -8.6697],\n",
      "        [-13.1627,  14.8442,  -8.7273],\n",
      "        [-13.5229,  14.9817,  -8.8723],\n",
      "        [-13.6584,  14.9027,  -8.7061],\n",
      "        [-13.3830,  14.9201,  -8.9387],\n",
      "        [-13.2911,  14.5377,  -8.6840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3563,   9.1761,  11.1355, -13.3021,  14.6824,  -8.6697],\n",
      "        [ 15.3098,   8.9126,  11.3189, -13.1627,  14.8442,  -8.7273],\n",
      "        [ 15.2542,   9.9568,  10.8357, -13.5229,  14.9817,  -8.8723],\n",
      "        [ 15.5868,   8.9444,  11.1295, -13.6584,  14.9027,  -8.7061],\n",
      "        [ 15.1962,   9.5014,  11.2003, -13.3830,  14.9201,  -8.9387],\n",
      "        [ 15.7387,   9.6068,  11.1116, -13.2911,  14.5377,  -8.6840]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7120736837387085\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7885, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6417,  9.6487, 11.0017],\n",
      "        [15.5075,  9.6486, 10.8897],\n",
      "        [15.0519,  9.2890, 10.8645],\n",
      "        [15.6265,  9.6815, 11.3516],\n",
      "        [15.6580,  9.7313, 11.3065],\n",
      "        [15.6107,  9.7678, 10.9601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4234, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4602,  14.9285,  -8.9930],\n",
      "        [-13.0392,  14.7297,  -8.8047],\n",
      "        [-12.9964,  14.7745,  -8.8821],\n",
      "        [-12.7738,  14.2577,  -8.8316],\n",
      "        [-13.1212,  14.9256,  -8.7923],\n",
      "        [-13.0381,  14.6530,  -8.8842]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6417,   9.6487,  11.0017, -13.4602,  14.9285,  -8.9930],\n",
      "        [ 15.5075,   9.6486,  10.8897, -13.0392,  14.7297,  -8.8047],\n",
      "        [ 15.0519,   9.2890,  10.8645, -12.9964,  14.7745,  -8.8821],\n",
      "        [ 15.6265,   9.6815,  11.3516, -12.7738,  14.2577,  -8.8316],\n",
      "        [ 15.6580,   9.7313,  11.3065, -13.1212,  14.9256,  -8.7923],\n",
      "        [ 15.6107,   9.7678,  10.9601, -13.0381,  14.6530,  -8.8842]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7399173974990845\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3345,  9.9154, 11.1148],\n",
      "        [15.5643,  9.3922, 11.1014],\n",
      "        [15.8043,  9.3804, 11.1882],\n",
      "        [15.7667,  9.6313, 10.7836],\n",
      "        [15.4852,  9.6337, 11.1381],\n",
      "        [15.5502,  9.6504, 11.1036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.9056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.9384,  14.6236,  -8.9246],\n",
      "        [-13.2590,  14.8982,  -8.8670],\n",
      "        [-12.9898,  14.6996,  -8.5061],\n",
      "        [-12.9430,  14.7713,  -9.2917],\n",
      "        [-13.4229,  14.7994,  -8.7684],\n",
      "        [-13.6760,  15.1990,  -9.2674]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3345,   9.9154,  11.1148, -12.9384,  14.6236,  -8.9246],\n",
      "        [ 15.5643,   9.3922,  11.1014, -13.2590,  14.8982,  -8.8670],\n",
      "        [ 15.8043,   9.3804,  11.1882, -12.9898,  14.6996,  -8.5061],\n",
      "        [ 15.7667,   9.6313,  10.7836, -12.9430,  14.7713,  -9.2917],\n",
      "        [ 15.4852,   9.6337,  11.1381, -13.4229,  14.7994,  -8.7684],\n",
      "        [ 15.5502,   9.6504,  11.1036, -13.6760,  15.1990,  -9.2674]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.720625638961792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8057, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5672,  9.4783, 11.0032],\n",
      "        [15.2674,  9.6133, 11.2226],\n",
      "        [15.8029,  9.8210, 11.4975],\n",
      "        [15.6845,  9.2694, 11.0363],\n",
      "        [15.4983,  9.3851, 10.7419],\n",
      "        [15.7298,  9.2416, 10.4967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.8765, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4841,  15.2236,  -8.8234],\n",
      "        [-13.4716,  14.8969,  -9.0241],\n",
      "        [-13.1589,  14.4802,  -8.8504],\n",
      "        [-13.0143,  14.4831,  -8.9231],\n",
      "        [-13.0262,  14.3786,  -8.7824],\n",
      "        [-13.2611,  14.9072,  -8.7207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5672,   9.4783,  11.0032, -13.4841,  15.2236,  -8.8234],\n",
      "        [ 15.2674,   9.6133,  11.2226, -13.4716,  14.8969,  -9.0241],\n",
      "        [ 15.8029,   9.8210,  11.4975, -13.1589,  14.4802,  -8.8504],\n",
      "        [ 15.6845,   9.2694,  11.0363, -13.0143,  14.4831,  -8.9231],\n",
      "        [ 15.4983,   9.3851,  10.7419, -13.0262,  14.3786,  -8.7824],\n",
      "        [ 15.7298,   9.2416,  10.4967, -13.2611,  14.9072,  -8.7207]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7406954765319824\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7781, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7343,  9.4888, 11.3176],\n",
      "        [15.7162,  9.6029, 11.1812],\n",
      "        [15.3778,  9.2042, 11.0692],\n",
      "        [15.3092,  9.4690, 11.1390],\n",
      "        [15.3244,  9.4809, 10.8450],\n",
      "        [15.5205,  9.3496, 11.0285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7090, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8036,  14.8246,  -8.4623],\n",
      "        [-12.9962,  14.7299,  -8.8809],\n",
      "        [-13.0813,  15.0712,  -8.8670],\n",
      "        [-13.1005,  14.3790,  -8.6070],\n",
      "        [-13.0646,  14.5394,  -8.8806],\n",
      "        [-12.9732,  14.5737,  -8.8220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7343,   9.4888,  11.3176, -12.8036,  14.8246,  -8.4623],\n",
      "        [ 15.7162,   9.6029,  11.1812, -12.9962,  14.7299,  -8.8809],\n",
      "        [ 15.3778,   9.2042,  11.0692, -13.0813,  15.0712,  -8.8670],\n",
      "        [ 15.3092,   9.4690,  11.1390, -13.1005,  14.3790,  -8.6070],\n",
      "        [ 15.3244,   9.4809,  10.8450, -13.0646,  14.5394,  -8.8806],\n",
      "        [ 15.5205,   9.3496,  11.0285, -12.9732,  14.5737,  -8.8220]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7329708337783813\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9227,  9.5604, 11.1205],\n",
      "        [15.8926,  9.6831, 11.2226],\n",
      "        [15.3208,  9.2796, 11.2815],\n",
      "        [15.8283,  9.3356, 11.5164],\n",
      "        [15.4202,  9.4066, 11.0692],\n",
      "        [15.5075,  9.5098, 11.2175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5530,  15.3854,  -9.1002],\n",
      "        [-13.0916,  14.4853,  -8.8202],\n",
      "        [-13.3728,  14.6766,  -9.0999],\n",
      "        [-13.3806,  14.8954,  -8.6949],\n",
      "        [-13.2687,  14.8134,  -9.1515],\n",
      "        [-13.2651,  14.6089,  -8.7768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9227,   9.5604,  11.1205, -13.5530,  15.3854,  -9.1002],\n",
      "        [ 15.8926,   9.6831,  11.2226, -13.0916,  14.4853,  -8.8202],\n",
      "        [ 15.3208,   9.2796,  11.2815, -13.3728,  14.6766,  -9.0999],\n",
      "        [ 15.8283,   9.3356,  11.5164, -13.3806,  14.8954,  -8.6949],\n",
      "        [ 15.4202,   9.4066,  11.0692, -13.2687,  14.8134,  -9.1515],\n",
      "        [ 15.5075,   9.5098,  11.2175, -13.2651,  14.6089,  -8.7768]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7687811851501465\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5172, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5118,  9.6184, 11.2750],\n",
      "        [16.0202,  9.6402, 11.3912],\n",
      "        [15.7022,  9.6023, 11.3944],\n",
      "        [15.5826,  9.6789, 11.2320],\n",
      "        [15.5273,  9.4291, 11.2851],\n",
      "        [15.8636,  9.7171, 11.1708]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.3557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1110,  14.6910,  -8.9555],\n",
      "        [-13.2761,  14.9186,  -9.0610],\n",
      "        [-13.2868,  14.6562,  -8.6373],\n",
      "        [-13.0084,  14.6451,  -8.7875],\n",
      "        [-13.2976,  14.7108,  -8.6281],\n",
      "        [-13.0759,  14.8216,  -8.3806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5118,   9.6184,  11.2750, -13.1110,  14.6910,  -8.9555],\n",
      "        [ 16.0202,   9.6402,  11.3912, -13.2761,  14.9186,  -9.0610],\n",
      "        [ 15.7022,   9.6023,  11.3944, -13.2868,  14.6562,  -8.6373],\n",
      "        [ 15.5826,   9.6789,  11.2320, -13.0084,  14.6451,  -8.7875],\n",
      "        [ 15.5273,   9.4291,  11.2851, -13.2976,  14.7108,  -8.6281],\n",
      "        [ 15.8636,   9.7171,  11.1708, -13.0759,  14.8216,  -8.3806]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7355448007583618\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9854, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8036,  9.5972, 11.2458],\n",
      "        [15.8376,  9.9325, 11.5644],\n",
      "        [15.5126,  9.5802, 11.2029],\n",
      "        [15.4242,  9.6151, 11.2313],\n",
      "        [15.6983,  9.6672, 11.1306],\n",
      "        [15.6279,  9.8106, 11.5373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.5060, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1429,  14.2935,  -8.6818],\n",
      "        [-13.0991,  14.7347,  -8.5097],\n",
      "        [-13.3516,  14.8749,  -8.9667],\n",
      "        [-13.5523,  14.7779,  -8.6964],\n",
      "        [-13.2007,  14.6883,  -9.2144],\n",
      "        [-13.0292,  14.5648,  -8.8918]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8036,   9.5972,  11.2458, -13.1429,  14.2935,  -8.6818],\n",
      "        [ 15.8376,   9.9325,  11.5644, -13.0991,  14.7347,  -8.5097],\n",
      "        [ 15.5126,   9.5802,  11.2029, -13.3516,  14.8749,  -8.9667],\n",
      "        [ 15.4242,   9.6151,  11.2313, -13.5523,  14.7779,  -8.6964],\n",
      "        [ 15.6983,   9.6672,  11.1306, -13.2007,  14.6883,  -9.2144],\n",
      "        [ 15.6279,   9.8106,  11.5373, -13.0292,  14.5648,  -8.8918]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7359542846679688\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1346, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.4483,  9.7909, 11.1018],\n",
      "        [15.7463,  9.2566, 11.3065],\n",
      "        [15.5574,  9.2134, 11.3170],\n",
      "        [15.6172,  9.3371, 11.4123],\n",
      "        [15.7150,  9.4200, 11.2868],\n",
      "        [15.9418,  9.6673, 11.1061]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2830,  14.4832,  -8.5886],\n",
      "        [-13.4753,  14.9711,  -8.8008],\n",
      "        [-12.7219,  14.6571,  -8.9384],\n",
      "        [-13.3953,  14.6252,  -8.6086],\n",
      "        [-12.7919,  14.5709,  -8.3776],\n",
      "        [-13.2943,  14.9366,  -9.2038]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.4483,   9.7909,  11.1018, -13.2830,  14.4832,  -8.5886],\n",
      "        [ 15.7463,   9.2566,  11.3065, -13.4753,  14.9711,  -8.8008],\n",
      "        [ 15.5574,   9.2134,  11.3170, -12.7219,  14.6571,  -8.9384],\n",
      "        [ 15.6172,   9.3371,  11.4123, -13.3953,  14.6252,  -8.6086],\n",
      "        [ 15.7150,   9.4200,  11.2868, -12.7919,  14.5709,  -8.3776],\n",
      "        [ 15.9418,   9.6673,  11.1061, -13.2943,  14.9366,  -9.2038]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.7279541492462158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1439, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.1621,  9.4497, 11.0908],\n",
      "        [15.6113,  9.7270, 11.3159],\n",
      "        [15.7948,  9.7410, 11.3397],\n",
      "        [15.9146,  9.5912, 11.3546],\n",
      "        [15.1933,  9.3485, 11.0616],\n",
      "        [15.9976,  9.8792, 11.2290]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2627, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2106,  14.8549,  -8.6706],\n",
      "        [-13.2648,  14.7484,  -9.1129],\n",
      "        [-13.1814,  14.5210,  -8.7740],\n",
      "        [-13.0809,  14.2921,  -8.5476],\n",
      "        [-13.3284,  14.9630,  -8.9094],\n",
      "        [-13.3888,  14.7552,  -9.0124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.1621,   9.4497,  11.0908, -13.2106,  14.8549,  -8.6706],\n",
      "        [ 15.6113,   9.7270,  11.3159, -13.2648,  14.7484,  -9.1129],\n",
      "        [ 15.7948,   9.7410,  11.3397, -13.1814,  14.5210,  -8.7740],\n",
      "        [ 15.9146,   9.5912,  11.3546, -13.0809,  14.2921,  -8.5476],\n",
      "        [ 15.1933,   9.3485,  11.0616, -13.3284,  14.9630,  -8.9094],\n",
      "        [ 15.9976,   9.8792,  11.2290, -13.3888,  14.7552,  -9.0124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7186998128890991\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9505, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3901,  9.5084, 10.8129],\n",
      "        [15.6380,  9.7101, 11.3582],\n",
      "        [15.2911,  9.6730, 11.0554],\n",
      "        [16.0107,  9.9089, 11.4960],\n",
      "        [15.9195,  9.9691, 11.4424],\n",
      "        [15.6404,  9.5716, 10.8854]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.7768, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.7792,  14.4362,  -8.7387],\n",
      "        [-13.0870,  15.0374,  -8.7023],\n",
      "        [-13.2360,  15.0245,  -9.2965],\n",
      "        [-13.3521,  14.5089,  -8.8069],\n",
      "        [-13.2985,  14.7876,  -9.0524],\n",
      "        [-13.4260,  14.9889,  -8.8050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3901,   9.5084,  10.8129, -12.7792,  14.4362,  -8.7387],\n",
      "        [ 15.6380,   9.7101,  11.3582, -13.0870,  15.0374,  -8.7023],\n",
      "        [ 15.2911,   9.6730,  11.0554, -13.2360,  15.0245,  -9.2965],\n",
      "        [ 16.0107,   9.9089,  11.4960, -13.3521,  14.5089,  -8.8069],\n",
      "        [ 15.9195,   9.9691,  11.4424, -13.2985,  14.7876,  -9.0524],\n",
      "        [ 15.6404,   9.5716,  10.8854, -13.4260,  14.9889,  -8.8050]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.705613136291504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.7706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9802,  9.9361, 11.5390],\n",
      "        [15.7683, 10.0552, 11.4019],\n",
      "        [15.5376,  9.5603, 10.9608],\n",
      "        [15.6921,  9.7052, 11.1116],\n",
      "        [15.4428,  9.4359, 11.1436],\n",
      "        [15.5479,  9.4085, 11.4331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6035, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1843,  14.4269,  -9.2297],\n",
      "        [-13.7232,  15.2436,  -8.9334],\n",
      "        [-13.1694,  14.6869,  -9.0116],\n",
      "        [-13.2745,  14.5886,  -9.0620],\n",
      "        [-13.0998,  14.6455,  -8.7983],\n",
      "        [-13.4995,  14.5926,  -9.0984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9802,   9.9361,  11.5390, -13.1843,  14.4269,  -9.2297],\n",
      "        [ 15.7683,  10.0552,  11.4019, -13.7232,  15.2436,  -8.9334],\n",
      "        [ 15.5376,   9.5603,  10.9608, -13.1694,  14.6869,  -9.0116],\n",
      "        [ 15.6921,   9.7052,  11.1116, -13.2745,  14.5886,  -9.0620],\n",
      "        [ 15.4428,   9.4359,  11.1436, -13.0998,  14.6455,  -8.7983],\n",
      "        [ 15.5479,   9.4085,  11.4331, -13.4995,  14.5926,  -9.0984]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7707042694091797\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5838,  9.5294, 11.0403],\n",
      "        [15.7201,  9.7640, 11.2732],\n",
      "        [15.6437,  9.1111, 11.0649],\n",
      "        [15.4049,  9.5446, 11.1183],\n",
      "        [15.5745,  9.5907, 10.9077],\n",
      "        [15.7673,  9.9267, 11.2461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.1862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5991,  15.3096,  -9.2834],\n",
      "        [-12.8289,  14.4550,  -8.5365],\n",
      "        [-13.4036,  14.7893,  -9.1003],\n",
      "        [-13.1580,  14.8216,  -8.6970],\n",
      "        [-13.2812,  14.7890,  -8.6951],\n",
      "        [-13.4275,  14.8011,  -9.3142]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5838,   9.5294,  11.0403, -13.5991,  15.3096,  -9.2834],\n",
      "        [ 15.7201,   9.7640,  11.2732, -12.8289,  14.4550,  -8.5365],\n",
      "        [ 15.6437,   9.1111,  11.0649, -13.4036,  14.7893,  -9.1003],\n",
      "        [ 15.4049,   9.5446,  11.1183, -13.1580,  14.8216,  -8.6970],\n",
      "        [ 15.5745,   9.5907,  10.9077, -13.2812,  14.7890,  -8.6951],\n",
      "        [ 15.7673,   9.9267,  11.2461, -13.4275,  14.8011,  -9.3142]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7609810829162598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4070, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5645,  9.6590, 10.9792],\n",
      "        [15.2441,  9.6363, 10.9696],\n",
      "        [15.7045,  9.7174, 10.9738],\n",
      "        [15.5947,  9.5920, 11.0814],\n",
      "        [15.6316,  9.7256, 11.5601],\n",
      "        [15.5750,  9.7412, 11.4348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0245, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4769,  15.2399,  -9.0491],\n",
      "        [-13.0959,  14.3735,  -9.0170],\n",
      "        [-13.4189,  14.7440,  -8.9844],\n",
      "        [-13.3977,  14.9289,  -9.0479],\n",
      "        [-13.3905,  14.6157,  -9.4015],\n",
      "        [-13.6403,  14.6972,  -8.9372]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5645,   9.6590,  10.9792, -13.4769,  15.2399,  -9.0491],\n",
      "        [ 15.2441,   9.6363,  10.9696, -13.0959,  14.3735,  -9.0170],\n",
      "        [ 15.7045,   9.7174,  10.9738, -13.4189,  14.7440,  -8.9844],\n",
      "        [ 15.5947,   9.5920,  11.0814, -13.3977,  14.9289,  -9.0479],\n",
      "        [ 15.6316,   9.7256,  11.5601, -13.3905,  14.6157,  -9.4015],\n",
      "        [ 15.5750,   9.7412,  11.4348, -13.6403,  14.6972,  -8.9372]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7555372714996338\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3608,  9.3595, 11.0793],\n",
      "        [15.6884,  9.8870, 11.5830],\n",
      "        [15.2818,  9.5549, 11.0272],\n",
      "        [15.3806,  9.7305, 11.2005],\n",
      "        [15.8133, 10.1186, 11.4978],\n",
      "        [15.6991,  9.8134, 11.6685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2366,  14.3905,  -8.8833],\n",
      "        [-13.3688,  14.7092,  -8.6082],\n",
      "        [-13.1369,  14.6901,  -8.5687],\n",
      "        [-12.8778,  14.9642,  -9.3193],\n",
      "        [-12.9053,  14.7662,  -8.9596],\n",
      "        [-13.5995,  14.9902,  -9.1482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3608,   9.3595,  11.0793, -13.2366,  14.3905,  -8.8833],\n",
      "        [ 15.6884,   9.8870,  11.5830, -13.3688,  14.7092,  -8.6082],\n",
      "        [ 15.2818,   9.5549,  11.0272, -13.1369,  14.6901,  -8.5687],\n",
      "        [ 15.3806,   9.7305,  11.2005, -12.8778,  14.9642,  -9.3193],\n",
      "        [ 15.8133,  10.1186,  11.4978, -12.9053,  14.7662,  -8.9596],\n",
      "        [ 15.6991,   9.8134,  11.6685, -13.5995,  14.9902,  -9.1482]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.7223790884017944\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9363,  9.5859, 11.5571],\n",
      "        [15.9256,  9.5742, 11.0205],\n",
      "        [15.7358,  9.7105, 11.3355],\n",
      "        [15.5678,  9.7904, 11.5208],\n",
      "        [15.9094,  9.9970, 11.2757],\n",
      "        [15.7261,  9.9833, 11.4112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.1872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4888,  15.0292,  -8.8232],\n",
      "        [-13.2084,  14.5728,  -8.8507],\n",
      "        [-13.2277,  14.4097,  -8.8106],\n",
      "        [-13.2123,  15.0317,  -9.0193],\n",
      "        [-13.0304,  15.1705,  -9.0273],\n",
      "        [-13.1072,  14.7572,  -8.9522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9363,   9.5859,  11.5571, -13.4888,  15.0292,  -8.8232],\n",
      "        [ 15.9256,   9.5742,  11.0205, -13.2084,  14.5728,  -8.8507],\n",
      "        [ 15.7358,   9.7105,  11.3355, -13.2277,  14.4097,  -8.8106],\n",
      "        [ 15.5678,   9.7904,  11.5208, -13.2123,  15.0317,  -9.0193],\n",
      "        [ 15.9094,   9.9970,  11.2757, -13.0304,  15.1705,  -9.0273],\n",
      "        [ 15.7261,   9.9833,  11.4112, -13.1072,  14.7572,  -8.9522]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.780814290046692\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0479,  9.8101, 11.2817],\n",
      "        [15.6282, 10.0003, 11.7700],\n",
      "        [15.4527,  9.7228, 11.6106],\n",
      "        [15.4661,  9.2862, 11.2622],\n",
      "        [15.5251,  9.2107, 11.0824],\n",
      "        [15.6646,  9.8894, 11.3805]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1178,  14.6919,  -8.8865],\n",
      "        [-13.6415,  14.8529,  -9.3119],\n",
      "        [-13.3690,  14.8170,  -8.7889],\n",
      "        [-13.3216,  14.8434,  -9.0048],\n",
      "        [-13.2284,  15.0120,  -8.8534],\n",
      "        [-13.2853,  15.0430,  -9.1896]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0479,   9.8101,  11.2817, -13.1178,  14.6919,  -8.8865],\n",
      "        [ 15.6282,  10.0003,  11.7700, -13.6415,  14.8529,  -9.3119],\n",
      "        [ 15.4527,   9.7228,  11.6106, -13.3690,  14.8170,  -8.7889],\n",
      "        [ 15.4661,   9.2862,  11.2622, -13.3216,  14.8434,  -9.0048],\n",
      "        [ 15.5251,   9.2107,  11.0824, -13.2284,  15.0120,  -8.8534],\n",
      "        [ 15.6646,   9.8894,  11.3805, -13.2853,  15.0430,  -9.1896]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7689908742904663\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8843,  9.6367, 11.2271],\n",
      "        [15.7696,  9.6160, 11.1544],\n",
      "        [15.9752,  9.9751, 11.5350],\n",
      "        [15.8729,  9.7069, 11.7127],\n",
      "        [15.4346,  9.6422, 10.9512],\n",
      "        [15.3161,  9.0806, 11.1168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0457, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5420,  14.8772,  -8.8877],\n",
      "        [-13.2455,  14.6183,  -9.0281],\n",
      "        [-13.5246,  14.6986,  -9.2618],\n",
      "        [-13.1881,  14.3972,  -8.8601],\n",
      "        [-13.3902,  15.3439,  -9.2203],\n",
      "        [-13.3842,  14.8528,  -8.8651]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8843,   9.6367,  11.2271, -13.5420,  14.8772,  -8.8877],\n",
      "        [ 15.7696,   9.6160,  11.1544, -13.2455,  14.6183,  -9.0281],\n",
      "        [ 15.9752,   9.9751,  11.5350, -13.5246,  14.6986,  -9.2618],\n",
      "        [ 15.8729,   9.7069,  11.7127, -13.1881,  14.3972,  -8.8601],\n",
      "        [ 15.4346,   9.6422,  10.9512, -13.3902,  15.3439,  -9.2203],\n",
      "        [ 15.3161,   9.0806,  11.1168, -13.3842,  14.8528,  -8.8651]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.770564317703247\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6404,  9.9122, 11.3524],\n",
      "        [15.4976,  9.7083, 11.2926],\n",
      "        [15.4942,  9.4675, 11.0867],\n",
      "        [15.6866,  9.5930, 11.2720],\n",
      "        [15.4040,  9.9782, 11.3288],\n",
      "        [15.7320,  9.7815, 11.2867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3931,  14.9695,  -8.7842],\n",
      "        [-13.1206,  14.8717,  -9.1393],\n",
      "        [-13.2051,  14.8976,  -8.9679],\n",
      "        [-13.3386,  14.8791,  -8.7280],\n",
      "        [-13.5882,  14.9996,  -9.0988],\n",
      "        [-13.8271,  15.1849,  -9.3030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6404,   9.9122,  11.3524, -13.3931,  14.9695,  -8.7842],\n",
      "        [ 15.4976,   9.7083,  11.2926, -13.1206,  14.8717,  -9.1393],\n",
      "        [ 15.4942,   9.4675,  11.0867, -13.2051,  14.8976,  -8.9679],\n",
      "        [ 15.6866,   9.5930,  11.2720, -13.3386,  14.8791,  -8.7280],\n",
      "        [ 15.4040,   9.9782,  11.3288, -13.5882,  14.9996,  -9.0988],\n",
      "        [ 15.7320,   9.7815,  11.2867, -13.8271,  15.1849,  -9.3030]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7687952518463135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6273,  9.9735, 11.0922],\n",
      "        [15.8396,  9.7473, 11.3321],\n",
      "        [15.7671,  9.4353, 11.4511],\n",
      "        [15.4834,  9.9878, 11.2602],\n",
      "        [15.8029,  9.6103, 11.5998],\n",
      "        [15.6004,  9.8085, 11.1604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8459, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4035,  14.2880,  -9.0245],\n",
      "        [-13.6105,  14.8475,  -8.8142],\n",
      "        [-13.4692,  14.9972,  -9.1642],\n",
      "        [-13.2756,  14.7994,  -8.6702],\n",
      "        [-13.0880,  14.8862,  -8.9662],\n",
      "        [-13.5209,  14.8858,  -9.1407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6273,   9.9735,  11.0922, -13.4035,  14.2880,  -9.0245],\n",
      "        [ 15.8396,   9.7473,  11.3321, -13.6105,  14.8475,  -8.8142],\n",
      "        [ 15.7671,   9.4353,  11.4511, -13.4692,  14.9972,  -9.1642],\n",
      "        [ 15.4834,   9.9878,  11.2602, -13.2756,  14.7994,  -8.6702],\n",
      "        [ 15.8029,   9.6103,  11.5998, -13.0880,  14.8862,  -8.9662],\n",
      "        [ 15.6004,   9.8085,  11.1604, -13.5209,  14.8858,  -9.1407]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7514103651046753\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7848, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7386,  9.9143, 11.3313],\n",
      "        [15.6772,  9.4518, 11.3256],\n",
      "        [16.0487, 10.1459, 11.8406],\n",
      "        [15.7099,  9.6536, 11.4304],\n",
      "        [15.5138,  9.2058, 10.9853],\n",
      "        [15.5106,  9.3014, 11.2331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5123,  14.9683,  -9.0898],\n",
      "        [-13.5206,  14.6475,  -9.1933],\n",
      "        [-12.8539,  14.5859,  -9.4104],\n",
      "        [-13.7410,  15.2317,  -8.9482],\n",
      "        [-13.3958,  14.5074,  -8.5807],\n",
      "        [-12.8466,  14.6901,  -8.8223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7386,   9.9143,  11.3313, -13.5123,  14.9683,  -9.0898],\n",
      "        [ 15.6772,   9.4518,  11.3256, -13.5206,  14.6475,  -9.1933],\n",
      "        [ 16.0487,  10.1459,  11.8406, -12.8539,  14.5859,  -9.4104],\n",
      "        [ 15.7099,   9.6536,  11.4304, -13.7410,  15.2317,  -8.9482],\n",
      "        [ 15.5138,   9.2058,  10.9853, -13.3958,  14.5074,  -8.5807],\n",
      "        [ 15.5106,   9.3014,  11.2331, -12.8466,  14.6901,  -8.8223]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.7794979810714722\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0202,  9.4529, 11.3978],\n",
      "        [15.6542,  9.4625, 11.2996],\n",
      "        [15.8970,  9.9404, 11.4420],\n",
      "        [15.8094,  9.5363, 11.1720],\n",
      "        [15.1497,  9.1373, 11.2344],\n",
      "        [14.9777,  9.4482, 11.1076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.8387,  15.0423,  -8.8500],\n",
      "        [-13.5569,  14.5375,  -8.4507],\n",
      "        [-13.4447,  14.5009,  -8.9690],\n",
      "        [-13.2816,  14.6493,  -8.7867],\n",
      "        [-13.6704,  14.8726,  -9.2555],\n",
      "        [-13.2837,  14.4618,  -8.8759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0202,   9.4529,  11.3978, -12.8387,  15.0423,  -8.8500],\n",
      "        [ 15.6542,   9.4625,  11.2996, -13.5569,  14.5375,  -8.4507],\n",
      "        [ 15.8970,   9.9404,  11.4420, -13.4447,  14.5009,  -8.9690],\n",
      "        [ 15.8094,   9.5363,  11.1720, -13.2816,  14.6493,  -8.7867],\n",
      "        [ 15.1497,   9.1373,  11.2344, -13.6704,  14.8726,  -9.2555],\n",
      "        [ 14.9777,   9.4482,  11.1076, -13.2837,  14.4618,  -8.8759]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7715177536010742\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6648,  9.8320, 11.4045],\n",
      "        [15.9860,  9.8402, 11.4370],\n",
      "        [15.7046,  9.4808, 11.4051],\n",
      "        [15.7619,  9.7911, 11.2812],\n",
      "        [15.5458,  9.6486, 11.1659],\n",
      "        [15.6793,  9.3965, 11.3977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2176, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-12.6760,  14.6041,  -8.6193],\n",
      "        [-13.6438,  14.9219,  -8.9375],\n",
      "        [-13.6607,  14.8693,  -9.0313],\n",
      "        [-13.0397,  14.7110,  -8.9061],\n",
      "        [-13.5111,  14.8057,  -8.9755],\n",
      "        [-13.4109,  15.1381,  -9.1145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6648,   9.8320,  11.4045, -12.6760,  14.6041,  -8.6193],\n",
      "        [ 15.9860,   9.8402,  11.4370, -13.6438,  14.9219,  -8.9375],\n",
      "        [ 15.7046,   9.4808,  11.4051, -13.6607,  14.8693,  -9.0313],\n",
      "        [ 15.7619,   9.7911,  11.2812, -13.0397,  14.7110,  -8.9061],\n",
      "        [ 15.5458,   9.6486,  11.1659, -13.5111,  14.8057,  -8.9755],\n",
      "        [ 15.6793,   9.3965,  11.3977, -13.4109,  15.1381,  -9.1145]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7511181831359863\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9732, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5314,  9.7652, 11.2192],\n",
      "        [15.9319,  9.4197, 10.9854],\n",
      "        [15.4764,  9.4841, 10.7329],\n",
      "        [16.1800, 10.0098, 11.3345],\n",
      "        [16.2806,  9.8946, 11.8919],\n",
      "        [15.5405,  9.3954, 11.0321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.0981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4061,  14.6518,  -9.0578],\n",
      "        [-13.6139,  14.9473,  -9.0218],\n",
      "        [-13.4475,  14.9561,  -9.0081],\n",
      "        [-13.3976,  14.5005,  -8.7332],\n",
      "        [-13.4562,  14.8741,  -9.1656],\n",
      "        [-13.5278,  14.8990,  -9.1339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5314,   9.7652,  11.2192, -13.4061,  14.6518,  -9.0578],\n",
      "        [ 15.9319,   9.4197,  10.9854, -13.6139,  14.9473,  -9.0218],\n",
      "        [ 15.4764,   9.4841,  10.7329, -13.4475,  14.9561,  -9.0081],\n",
      "        [ 16.1800,  10.0098,  11.3345, -13.3976,  14.5005,  -8.7332],\n",
      "        [ 16.2806,   9.8946,  11.8919, -13.4562,  14.8741,  -9.1656],\n",
      "        [ 15.5405,   9.3954,  11.0321, -13.5278,  14.8990,  -9.1339]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7595428228378296\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0721, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.2765,  9.3769, 11.3730],\n",
      "        [16.0091,  9.7215, 11.5085],\n",
      "        [15.9740,  9.8667, 11.2521],\n",
      "        [16.0315,  9.9326, 11.4115],\n",
      "        [15.9875, 10.0462, 11.4182],\n",
      "        [15.5891,  9.2409, 11.2408]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4565,  14.8746,  -9.2052],\n",
      "        [-13.5281,  14.9131,  -9.0945],\n",
      "        [-13.2514,  15.0037,  -9.0272],\n",
      "        [-13.0250,  14.8841,  -9.1406],\n",
      "        [-13.7598,  14.9986,  -8.9076],\n",
      "        [-13.1953,  14.8358,  -8.7254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.2765,   9.3769,  11.3730, -13.4565,  14.8746,  -9.2052],\n",
      "        [ 16.0091,   9.7215,  11.5085, -13.5281,  14.9131,  -9.0945],\n",
      "        [ 15.9740,   9.8667,  11.2521, -13.2514,  15.0037,  -9.0272],\n",
      "        [ 16.0315,   9.9326,  11.4115, -13.0250,  14.8841,  -9.1406],\n",
      "        [ 15.9875,  10.0462,  11.4182, -13.7598,  14.9986,  -8.9076],\n",
      "        [ 15.5891,   9.2409,  11.2408, -13.1953,  14.8358,  -8.7254]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.755326271057129\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7571, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6430,  9.9282, 10.9639],\n",
      "        [15.5194,  9.8474, 11.4024],\n",
      "        [16.0136,  9.6978, 11.2347],\n",
      "        [15.5448,  9.6738, 11.2505],\n",
      "        [15.6236,  9.9469, 11.4457],\n",
      "        [16.1029,  9.6880, 11.3406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7802, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2727,  15.0340,  -8.8361],\n",
      "        [-13.2526,  14.8593,  -9.1046],\n",
      "        [-13.1015,  14.6495,  -8.6689],\n",
      "        [-13.5342,  15.0545,  -8.9025],\n",
      "        [-13.6035,  14.7951,  -9.1038],\n",
      "        [-13.0749,  14.4857,  -8.7894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6430,   9.9282,  10.9639, -13.2727,  15.0340,  -8.8361],\n",
      "        [ 15.5194,   9.8474,  11.4024, -13.2526,  14.8593,  -9.1046],\n",
      "        [ 16.0136,   9.6978,  11.2347, -13.1015,  14.6495,  -8.6689],\n",
      "        [ 15.5448,   9.6738,  11.2505, -13.5342,  15.0545,  -8.9025],\n",
      "        [ 15.6236,   9.9469,  11.4457, -13.6035,  14.7951,  -9.1038],\n",
      "        [ 16.1029,   9.6880,  11.3406, -13.0749,  14.4857,  -8.7894]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.764343500137329\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0196, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5828, 10.0224, 11.4502],\n",
      "        [15.6257,  9.8354, 11.3255],\n",
      "        [15.6595,  9.8157, 11.5579],\n",
      "        [15.6663,  9.9126, 11.3620],\n",
      "        [15.5309, 10.0912, 11.3924],\n",
      "        [15.6061,  9.5940, 11.4439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9380, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.1387,  15.1551,  -9.1193],\n",
      "        [-13.4679,  14.6372,  -8.7519],\n",
      "        [-13.3464,  14.9719,  -9.2596],\n",
      "        [-13.6513,  14.9609,  -9.0645],\n",
      "        [-13.8224,  15.1499,  -9.0100],\n",
      "        [-13.2723,  14.8859,  -8.7870]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5828,  10.0224,  11.4502, -13.1387,  15.1551,  -9.1193],\n",
      "        [ 15.6257,   9.8354,  11.3255, -13.4679,  14.6372,  -8.7519],\n",
      "        [ 15.6595,   9.8157,  11.5579, -13.3464,  14.9719,  -9.2596],\n",
      "        [ 15.6663,   9.9126,  11.3620, -13.6513,  14.9609,  -9.0645],\n",
      "        [ 15.5309,  10.0912,  11.3924, -13.8224,  15.1499,  -9.0100],\n",
      "        [ 15.6061,   9.5940,  11.4439, -13.2723,  14.8859,  -8.7870]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.7821613550186157\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7895, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1777,  9.7800, 11.2078],\n",
      "        [15.7807,  9.6323, 11.3043],\n",
      "        [15.4839,  9.3460, 11.0700],\n",
      "        [15.6853,  9.8369, 11.6351],\n",
      "        [15.2609,  9.7273, 11.2586],\n",
      "        [15.9516,  9.8778, 11.7590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4672, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5446,  14.7186,  -8.8933],\n",
      "        [-13.3540,  14.9307,  -9.0727],\n",
      "        [-13.2116,  14.5364,  -8.8420],\n",
      "        [-13.4958,  15.0069,  -8.8057],\n",
      "        [-13.2036,  15.0035,  -9.1969],\n",
      "        [-13.7654,  15.3375,  -9.1612]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1777,   9.7800,  11.2078, -13.5446,  14.7186,  -8.8933],\n",
      "        [ 15.7807,   9.6323,  11.3043, -13.3540,  14.9307,  -9.0727],\n",
      "        [ 15.4839,   9.3460,  11.0700, -13.2116,  14.5364,  -8.8420],\n",
      "        [ 15.6853,   9.8369,  11.6351, -13.4958,  15.0069,  -8.8057],\n",
      "        [ 15.2609,   9.7273,  11.2586, -13.2036,  15.0035,  -9.1969],\n",
      "        [ 15.9516,   9.8778,  11.7590, -13.7654,  15.3375,  -9.1612]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7905720472335815\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7038,  9.6679, 10.8635],\n",
      "        [16.0240,  9.8160, 11.7692],\n",
      "        [15.8934,  9.7603, 11.3067],\n",
      "        [15.8982,  9.6732, 11.6650],\n",
      "        [15.7950, 10.1977, 11.5561],\n",
      "        [15.4682,  9.5547, 11.5709]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4826, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2016,  14.9319,  -8.8248],\n",
      "        [-13.5063,  15.1886,  -9.1860],\n",
      "        [-13.4448,  14.9662,  -9.0935],\n",
      "        [-13.5219,  14.8058,  -9.1499],\n",
      "        [-13.5691,  15.3297,  -9.0721],\n",
      "        [-13.1274,  14.7284,  -9.2838]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7038,   9.6679,  10.8635, -13.2016,  14.9319,  -8.8248],\n",
      "        [ 16.0240,   9.8160,  11.7692, -13.5063,  15.1886,  -9.1860],\n",
      "        [ 15.8934,   9.7603,  11.3067, -13.4448,  14.9662,  -9.0935],\n",
      "        [ 15.8982,   9.6732,  11.6650, -13.5219,  14.8058,  -9.1499],\n",
      "        [ 15.7950,  10.1977,  11.5561, -13.5691,  15.3297,  -9.0721],\n",
      "        [ 15.4682,   9.5547,  11.5709, -13.1274,  14.7284,  -9.2838]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7583709955215454\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4529, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7622,  9.8670, 11.2309],\n",
      "        [15.9869,  9.7996, 11.7985],\n",
      "        [16.0613,  9.7954, 10.9785],\n",
      "        [16.0237, 10.1894, 11.3216],\n",
      "        [15.7194,  9.7530, 11.5339],\n",
      "        [15.6302,  9.7848, 11.4559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6657, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6687,  15.2757,  -9.0487],\n",
      "        [-13.6707,  14.9616,  -9.0154],\n",
      "        [-13.3874,  14.8159,  -8.9483],\n",
      "        [-13.1795,  14.8583,  -8.9642],\n",
      "        [-13.4385,  15.0463,  -9.0568],\n",
      "        [-13.5124,  14.8114,  -9.3370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7622,   9.8670,  11.2309, -13.6687,  15.2757,  -9.0487],\n",
      "        [ 15.9869,   9.7996,  11.7985, -13.6707,  14.9616,  -9.0154],\n",
      "        [ 16.0613,   9.7954,  10.9785, -13.3874,  14.8159,  -8.9483],\n",
      "        [ 16.0237,  10.1894,  11.3216, -13.1795,  14.8583,  -8.9642],\n",
      "        [ 15.7194,   9.7530,  11.5339, -13.4385,  15.0463,  -9.0568],\n",
      "        [ 15.6302,   9.7848,  11.4559, -13.5124,  14.8114,  -9.3370]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7943427562713623\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8182,  9.7120, 11.4881],\n",
      "        [15.4555,  9.8780, 11.8892],\n",
      "        [15.6631,  9.8476, 11.2208],\n",
      "        [15.2149,  9.5400, 11.4673],\n",
      "        [15.9477,  9.9595, 11.4619],\n",
      "        [15.7257, 10.1548, 11.4586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4367,  14.5652,  -9.0224],\n",
      "        [-13.5028,  15.1884,  -9.1598],\n",
      "        [-13.2263,  15.0360,  -9.3081],\n",
      "        [-13.2298,  15.0437,  -9.0701],\n",
      "        [-13.4221,  15.0082,  -9.1063],\n",
      "        [-13.2169,  14.9128,  -9.0353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8182,   9.7120,  11.4881, -13.4367,  14.5652,  -9.0224],\n",
      "        [ 15.4555,   9.8780,  11.8892, -13.5028,  15.1884,  -9.1598],\n",
      "        [ 15.6631,   9.8476,  11.2208, -13.2263,  15.0360,  -9.3081],\n",
      "        [ 15.2149,   9.5400,  11.4673, -13.2298,  15.0437,  -9.0701],\n",
      "        [ 15.9477,   9.9595,  11.4619, -13.4221,  15.0082,  -9.1063],\n",
      "        [ 15.7257,  10.1548,  11.4586, -13.2169,  14.9128,  -9.0353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7827961444854736\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.3757,  9.6057, 11.2130],\n",
      "        [15.9561,  9.7726, 11.1084],\n",
      "        [15.7955,  9.8298, 11.2902],\n",
      "        [15.9745,  9.9170, 11.5544],\n",
      "        [15.6079, 10.0026, 11.6225],\n",
      "        [15.6102,  9.9502, 11.4185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6853,  14.3473,  -8.8418],\n",
      "        [-13.5521,  15.0861,  -9.3745],\n",
      "        [-13.4139,  14.5369,  -8.9526],\n",
      "        [-13.1580,  14.3500,  -9.0024],\n",
      "        [-13.3818,  14.9604,  -8.7974],\n",
      "        [-13.3333,  14.9200,  -9.2067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.3757,   9.6057,  11.2130, -13.6853,  14.3473,  -8.8418],\n",
      "        [ 15.9561,   9.7726,  11.1084, -13.5521,  15.0861,  -9.3745],\n",
      "        [ 15.7955,   9.8298,  11.2902, -13.4139,  14.5369,  -8.9526],\n",
      "        [ 15.9745,   9.9170,  11.5544, -13.1580,  14.3500,  -9.0024],\n",
      "        [ 15.6079,  10.0026,  11.6225, -13.3818,  14.9604,  -8.7974],\n",
      "        [ 15.6102,   9.9502,  11.4185, -13.3333,  14.9200,  -9.2067]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7545812129974365\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1441,  9.8481, 11.6033],\n",
      "        [16.2248,  9.9429, 11.4971],\n",
      "        [16.0185,  9.3853, 11.1512],\n",
      "        [16.0460,  9.6584, 11.5031],\n",
      "        [16.0435, 10.0377, 11.9788],\n",
      "        [15.9296, 10.0683, 11.4160]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3674,  15.1261,  -9.0320],\n",
      "        [-13.4864,  14.9512,  -9.1188],\n",
      "        [-13.4881,  14.8316,  -9.0280],\n",
      "        [-13.4156,  15.1798,  -9.4675],\n",
      "        [-13.7576,  15.0412,  -9.2830],\n",
      "        [-13.3950,  14.8483,  -8.9876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1441,   9.8481,  11.6033, -13.3674,  15.1261,  -9.0320],\n",
      "        [ 16.2248,   9.9429,  11.4971, -13.4864,  14.9512,  -9.1188],\n",
      "        [ 16.0185,   9.3853,  11.1512, -13.4881,  14.8316,  -9.0280],\n",
      "        [ 16.0460,   9.6584,  11.5031, -13.4156,  15.1798,  -9.4675],\n",
      "        [ 16.0435,  10.0377,  11.9788, -13.7576,  15.0412,  -9.2830],\n",
      "        [ 15.9296,  10.0683,  11.4160, -13.3950,  14.8483,  -8.9876]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.813863754272461\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1377, 10.1080, 11.4747],\n",
      "        [16.0013,  9.5120, 11.6844],\n",
      "        [15.8565, 10.1162, 11.6508],\n",
      "        [15.7007,  9.8681, 11.8362],\n",
      "        [15.9036,  9.9719, 11.5640],\n",
      "        [15.3923,  9.5385, 11.3257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(8.5932, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3120,  14.9119,  -9.0265],\n",
      "        [-13.6477,  14.8350,  -9.1269],\n",
      "        [-13.9085,  14.8944,  -9.2117],\n",
      "        [-13.5393,  14.5990,  -8.7362],\n",
      "        [-13.6152,  14.8976,  -8.9113],\n",
      "        [-13.6873,  14.8601,  -8.5589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1377,  10.1080,  11.4747, -13.3120,  14.9119,  -9.0265],\n",
      "        [ 16.0013,   9.5120,  11.6844, -13.6477,  14.8350,  -9.1269],\n",
      "        [ 15.8565,  10.1162,  11.6508, -13.9085,  14.8944,  -9.2117],\n",
      "        [ 15.7007,   9.8681,  11.8362, -13.5393,  14.5990,  -8.7362],\n",
      "        [ 15.9036,   9.9719,  11.5640, -13.6152,  14.8976,  -8.9113],\n",
      "        [ 15.3923,   9.5385,  11.3257, -13.6873,  14.8601,  -8.5589]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8099727630615234\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0198, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2064, 10.1782, 11.4460],\n",
      "        [15.9359,  9.7377, 11.6231],\n",
      "        [15.7482,  9.8944, 11.6826],\n",
      "        [16.2502, 10.3136, 11.8851],\n",
      "        [15.3982,  9.3043, 11.1412],\n",
      "        [15.8670, 10.0104, 11.2675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5910,  15.0040,  -9.2391],\n",
      "        [-13.9051,  15.0474,  -9.1568],\n",
      "        [-13.3079,  14.8043,  -9.2437],\n",
      "        [-13.5814,  14.8759,  -9.1736],\n",
      "        [-13.4157,  14.6171,  -9.0077],\n",
      "        [-13.2006,  15.1784,  -9.1040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2064,  10.1782,  11.4460, -13.5910,  15.0040,  -9.2391],\n",
      "        [ 15.9359,   9.7377,  11.6231, -13.9051,  15.0474,  -9.1568],\n",
      "        [ 15.7482,   9.8944,  11.6826, -13.3079,  14.8043,  -9.2437],\n",
      "        [ 16.2502,  10.3136,  11.8851, -13.5814,  14.8759,  -9.1736],\n",
      "        [ 15.3982,   9.3043,  11.1412, -13.4157,  14.6171,  -9.0077],\n",
      "        [ 15.8670,  10.0104,  11.2675, -13.2006,  15.1784,  -9.1040]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8235608339309692\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9785, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0028,  9.7385, 11.6691],\n",
      "        [15.6396,  9.9932, 11.4188],\n",
      "        [16.0041,  9.8685, 11.5761],\n",
      "        [15.5978,  9.6645, 11.0311],\n",
      "        [15.9596,  9.8697, 11.7360],\n",
      "        [15.7610,  9.6600, 11.1540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6840,  15.0426,  -9.1910],\n",
      "        [-13.4860,  14.8735,  -9.0908],\n",
      "        [-13.5786,  15.1072,  -9.3167],\n",
      "        [-13.8816,  15.2439,  -9.6760],\n",
      "        [-13.2712,  14.9558,  -9.1254],\n",
      "        [-13.1854,  14.8735,  -9.0832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0028,   9.7385,  11.6691, -13.6840,  15.0426,  -9.1910],\n",
      "        [ 15.6396,   9.9932,  11.4188, -13.4860,  14.8735,  -9.0908],\n",
      "        [ 16.0041,   9.8685,  11.5761, -13.5786,  15.1072,  -9.3167],\n",
      "        [ 15.5978,   9.6645,  11.0311, -13.8816,  15.2439,  -9.6760],\n",
      "        [ 15.9596,   9.8697,  11.7360, -13.2712,  14.9558,  -9.1254],\n",
      "        [ 15.7610,   9.6600,  11.1540, -13.1854,  14.8735,  -9.0832]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.817196011543274\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6744, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0690,  9.8795, 11.8206],\n",
      "        [15.5684,  9.8782, 11.6272],\n",
      "        [16.1037,  9.8229, 11.7471],\n",
      "        [15.8855, 10.0860, 11.5821],\n",
      "        [15.5869,  9.7479, 11.4882],\n",
      "        [15.7541,  9.8530, 11.4559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4030, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2506,  15.1908,  -9.3028],\n",
      "        [-13.6535,  15.2228,  -9.1397],\n",
      "        [-13.9331,  15.1098,  -9.1410],\n",
      "        [-13.7835,  14.7517,  -9.2031],\n",
      "        [-13.2213,  14.9955,  -9.4237],\n",
      "        [-13.5087,  14.9536,  -9.1036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0690,   9.8795,  11.8206, -13.2506,  15.1908,  -9.3028],\n",
      "        [ 15.5684,   9.8782,  11.6272, -13.6535,  15.2228,  -9.1397],\n",
      "        [ 16.1037,   9.8229,  11.7471, -13.9331,  15.1098,  -9.1410],\n",
      "        [ 15.8855,  10.0860,  11.5821, -13.7835,  14.7517,  -9.2031],\n",
      "        [ 15.5869,   9.7479,  11.4882, -13.2213,  14.9955,  -9.4237],\n",
      "        [ 15.7541,   9.8530,  11.4559, -13.5087,  14.9536,  -9.1036]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8241240978240967\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5623,  9.9423, 11.3608],\n",
      "        [16.0567,  9.9014, 11.7089],\n",
      "        [15.9244, 10.1525, 11.7278],\n",
      "        [15.9083,  9.8831, 11.3534],\n",
      "        [15.7393,  9.9913, 11.5248],\n",
      "        [15.9706,  9.9773, 11.5445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5294,  15.1158,  -8.9860],\n",
      "        [-13.6893,  14.7064,  -9.0953],\n",
      "        [-13.4981,  15.2911,  -9.0000],\n",
      "        [-13.4256,  15.0023,  -9.2865],\n",
      "        [-13.8591,  15.2301,  -9.0229],\n",
      "        [-13.5151,  15.1660,  -9.2373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5623,   9.9423,  11.3608, -13.5294,  15.1158,  -8.9860],\n",
      "        [ 16.0567,   9.9014,  11.7089, -13.6893,  14.7064,  -9.0953],\n",
      "        [ 15.9244,  10.1525,  11.7278, -13.4981,  15.2911,  -9.0000],\n",
      "        [ 15.9083,   9.8831,  11.3534, -13.4256,  15.0023,  -9.2865],\n",
      "        [ 15.7393,   9.9913,  11.5248, -13.8591,  15.2301,  -9.0229],\n",
      "        [ 15.9706,   9.9773,  11.5445, -13.5151,  15.1660,  -9.2373]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7930322885513306\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8067, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3410, 10.1941, 11.8762],\n",
      "        [15.8903, 10.1220, 11.6223],\n",
      "        [16.1580,  9.9688, 11.6487],\n",
      "        [15.9931,  9.9052, 11.1919],\n",
      "        [15.5153,  9.4122, 11.3463],\n",
      "        [15.9417, 10.1726, 11.3758]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6130,  15.0216,  -9.3708],\n",
      "        [-13.6441,  14.8268,  -8.7686],\n",
      "        [-13.2815,  14.6355,  -9.2623],\n",
      "        [-13.5401,  14.9055,  -8.9254],\n",
      "        [-13.8154,  14.9522,  -9.3598],\n",
      "        [-13.4085,  15.1346,  -8.7892]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3410,  10.1941,  11.8762, -13.6130,  15.0216,  -9.3708],\n",
      "        [ 15.8903,  10.1220,  11.6223, -13.6441,  14.8268,  -8.7686],\n",
      "        [ 16.1580,   9.9688,  11.6487, -13.2815,  14.6355,  -9.2623],\n",
      "        [ 15.9931,   9.9052,  11.1919, -13.5401,  14.9055,  -8.9254],\n",
      "        [ 15.5153,   9.4122,  11.3463, -13.8154,  14.9522,  -9.3598],\n",
      "        [ 15.9417,  10.1726,  11.3758, -13.4085,  15.1346,  -8.7892]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.8480620384216309\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0569, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1943, 10.1179, 11.6292],\n",
      "        [16.1024,  9.9268, 11.8533],\n",
      "        [15.9933, 10.0748, 11.4148],\n",
      "        [16.0087,  9.7380, 11.5273],\n",
      "        [16.0060, 10.3634, 11.5007],\n",
      "        [15.5356,  9.7038, 11.4680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2108, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2301,  14.8973,  -8.9369],\n",
      "        [-13.2227,  14.7745,  -9.1160],\n",
      "        [-13.2666,  14.6109,  -8.7775],\n",
      "        [-13.4247,  15.0668,  -9.2302],\n",
      "        [-13.8749,  15.6739,  -9.2488],\n",
      "        [-13.5993,  15.4624,  -9.2978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1943,  10.1179,  11.6292, -13.2301,  14.8973,  -8.9369],\n",
      "        [ 16.1024,   9.9268,  11.8533, -13.2227,  14.7745,  -9.1160],\n",
      "        [ 15.9933,  10.0748,  11.4148, -13.2666,  14.6109,  -8.7775],\n",
      "        [ 16.0087,   9.7380,  11.5273, -13.4247,  15.0668,  -9.2302],\n",
      "        [ 16.0060,  10.3634,  11.5007, -13.8749,  15.6739,  -9.2488],\n",
      "        [ 15.5356,   9.7038,  11.4680, -13.5993,  15.4624,  -9.2978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8200374841690063\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(5.1582, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0676, 10.3404, 11.8810],\n",
      "        [15.7873,  9.9370, 11.5011],\n",
      "        [16.1014, 10.1463, 11.8399],\n",
      "        [15.8728, 10.0589, 11.6430],\n",
      "        [16.0572,  9.9278, 11.1783],\n",
      "        [15.8442,  9.6216, 11.4364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3753, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6124,  14.9589,  -8.9271],\n",
      "        [-14.1421,  15.0560,  -9.0512],\n",
      "        [-13.1040,  14.6574,  -8.7637],\n",
      "        [-13.5347,  14.9642,  -9.5031],\n",
      "        [-13.3051,  14.9542,  -9.2268],\n",
      "        [-13.4553,  14.7863,  -9.0749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0676,  10.3404,  11.8810, -13.6124,  14.9589,  -8.9271],\n",
      "        [ 15.7873,   9.9370,  11.5011, -14.1421,  15.0560,  -9.0512],\n",
      "        [ 16.1014,  10.1463,  11.8399, -13.1040,  14.6574,  -8.7637],\n",
      "        [ 15.8728,  10.0589,  11.6430, -13.5347,  14.9642,  -9.5031],\n",
      "        [ 16.0572,   9.9278,  11.1783, -13.3051,  14.9542,  -9.2268],\n",
      "        [ 15.8442,   9.6216,  11.4364, -13.4553,  14.7863,  -9.0749]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8359249830245972\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9563, 10.1508, 11.5257],\n",
      "        [15.7820, 10.2766, 11.7634],\n",
      "        [15.9173,  9.9512, 11.8761],\n",
      "        [15.9789, 10.1292, 11.6993],\n",
      "        [16.2067,  9.8468, 11.4479],\n",
      "        [16.0250,  9.8328, 11.3248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6927,  14.9714,  -9.2125],\n",
      "        [-14.1237,  15.4357,  -9.2853],\n",
      "        [-13.7031,  15.1507,  -8.9761],\n",
      "        [-13.2751,  14.6546,  -9.0536],\n",
      "        [-13.4076,  15.2278,  -8.9473],\n",
      "        [-13.4977,  15.2328,  -8.9394]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9563,  10.1508,  11.5257, -13.6927,  14.9714,  -9.2125],\n",
      "        [ 15.7820,  10.2766,  11.7634, -14.1237,  15.4357,  -9.2853],\n",
      "        [ 15.9173,   9.9512,  11.8761, -13.7031,  15.1507,  -8.9761],\n",
      "        [ 15.9789,  10.1292,  11.6993, -13.2751,  14.6546,  -9.0536],\n",
      "        [ 16.2067,   9.8468,  11.4479, -13.4076,  15.2278,  -8.9473],\n",
      "        [ 16.0250,   9.8328,  11.3248, -13.4977,  15.2328,  -8.9394]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8236000537872314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9559,  9.6714, 11.2230],\n",
      "        [16.0969, 10.3277, 11.6414],\n",
      "        [15.9116,  9.7138, 11.6393],\n",
      "        [15.8334,  9.8457, 11.5536],\n",
      "        [15.3327,  9.8775, 11.5038],\n",
      "        [15.7764,  9.9705, 11.6043]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5076,  15.1546,  -9.5425],\n",
      "        [-14.0804,  14.8784,  -9.4138],\n",
      "        [-13.3706,  14.8901,  -9.2447],\n",
      "        [-13.6671,  15.5983,  -9.1911],\n",
      "        [-13.4398,  15.4869,  -9.4222],\n",
      "        [-13.7659,  15.2044,  -9.3366]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9559,   9.6714,  11.2230, -13.5076,  15.1546,  -9.5425],\n",
      "        [ 16.0969,  10.3277,  11.6414, -14.0804,  14.8784,  -9.4138],\n",
      "        [ 15.9116,   9.7138,  11.6393, -13.3706,  14.8901,  -9.2447],\n",
      "        [ 15.8334,   9.8457,  11.5536, -13.6671,  15.5983,  -9.1911],\n",
      "        [ 15.3327,   9.8775,  11.5038, -13.4398,  15.4869,  -9.4222],\n",
      "        [ 15.7764,   9.9705,  11.6043, -13.7659,  15.2044,  -9.3366]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8109797239303589\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5030, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1400, 10.1835, 11.5999],\n",
      "        [15.9920,  9.6451, 11.5461],\n",
      "        [16.1585, 10.0697, 11.7679],\n",
      "        [15.9552, 10.1051, 11.9229],\n",
      "        [15.6870,  9.8502, 11.2033],\n",
      "        [15.8253,  9.7766, 11.2458]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.5875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3019,  14.8124,  -9.3300],\n",
      "        [-13.8744,  15.4184,  -9.4488],\n",
      "        [-13.3369,  14.8582,  -9.2469],\n",
      "        [-13.9894,  15.0907,  -9.3823],\n",
      "        [-13.4412,  15.1571,  -9.1942],\n",
      "        [-13.1714,  14.9175,  -9.1900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1400,  10.1835,  11.5999, -13.3019,  14.8124,  -9.3300],\n",
      "        [ 15.9920,   9.6451,  11.5461, -13.8744,  15.4184,  -9.4488],\n",
      "        [ 16.1585,  10.0697,  11.7679, -13.3369,  14.8582,  -9.2469],\n",
      "        [ 15.9552,  10.1051,  11.9229, -13.9894,  15.0907,  -9.3823],\n",
      "        [ 15.6870,   9.8502,  11.2033, -13.4412,  15.1571,  -9.1942],\n",
      "        [ 15.8253,   9.7766,  11.2458, -13.1714,  14.9175,  -9.1900]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8262426853179932\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7585, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1330, 10.2765, 11.5016],\n",
      "        [16.0963, 10.1711, 11.6589],\n",
      "        [15.9023, 10.1681, 11.5894],\n",
      "        [15.7800,  9.8118, 11.1718],\n",
      "        [16.1584,  9.8434, 11.6199],\n",
      "        [15.8152, 10.0432, 11.6318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.3015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6420,  14.9926,  -9.3214],\n",
      "        [-13.6810,  14.7814,  -9.1973],\n",
      "        [-13.8421,  15.3475,  -9.4077],\n",
      "        [-13.4473,  15.1992,  -9.1106],\n",
      "        [-13.7372,  15.2334,  -9.3500],\n",
      "        [-13.4199,  15.1080,  -9.4080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1330,  10.2765,  11.5016, -13.6420,  14.9926,  -9.3214],\n",
      "        [ 16.0963,  10.1711,  11.6589, -13.6810,  14.7814,  -9.1973],\n",
      "        [ 15.9023,  10.1681,  11.5894, -13.8421,  15.3475,  -9.4077],\n",
      "        [ 15.7800,   9.8118,  11.1718, -13.4473,  15.1992,  -9.1106],\n",
      "        [ 16.1584,   9.8434,  11.6199, -13.7372,  15.2334,  -9.3500],\n",
      "        [ 15.8152,  10.0432,  11.6318, -13.4199,  15.1080,  -9.4080]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.8358333110809326\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0350,  9.7877, 11.7580],\n",
      "        [16.1962,  9.9233, 11.9895],\n",
      "        [16.0846, 10.2325, 11.6775],\n",
      "        [15.7038, 10.2217, 11.8443],\n",
      "        [16.1248, 10.1481, 11.4788],\n",
      "        [15.7705,  9.7367, 11.6251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4582, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5125,  15.0254,  -9.1214],\n",
      "        [-13.4669,  15.4005,  -9.1270],\n",
      "        [-13.7013,  15.1989,  -9.5024],\n",
      "        [-13.0575,  14.1652,  -8.8185],\n",
      "        [-13.5889,  15.5384,  -9.4494],\n",
      "        [-13.6976,  15.2841,  -9.1515]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0350,   9.7877,  11.7580, -13.5125,  15.0254,  -9.1214],\n",
      "        [ 16.1962,   9.9233,  11.9895, -13.4669,  15.4005,  -9.1270],\n",
      "        [ 16.0846,  10.2325,  11.6775, -13.7013,  15.1989,  -9.5024],\n",
      "        [ 15.7038,  10.2217,  11.8443, -13.0575,  14.1652,  -8.8185],\n",
      "        [ 16.1248,  10.1481,  11.4788, -13.5889,  15.5384,  -9.4494],\n",
      "        [ 15.7705,   9.7367,  11.6251, -13.6976,  15.2841,  -9.1515]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.827620267868042\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9483, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0771, 10.1373, 11.3633],\n",
      "        [15.5192, 10.2483, 11.4268],\n",
      "        [16.2436,  9.9103, 11.6089],\n",
      "        [16.2587, 10.0287, 11.4305],\n",
      "        [15.7491,  9.8553, 11.6663],\n",
      "        [16.0809, 10.4441, 11.2479]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.6823, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8885,  14.9813,  -9.2906],\n",
      "        [-13.3320,  14.9130,  -9.0635],\n",
      "        [-13.7928,  15.2911,  -9.5544],\n",
      "        [-14.1544,  14.8766,  -9.2811],\n",
      "        [-13.4323,  15.1469,  -9.0458],\n",
      "        [-13.5133,  15.2069,  -8.8986]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0771,  10.1373,  11.3633, -13.8885,  14.9813,  -9.2906],\n",
      "        [ 15.5192,  10.2483,  11.4268, -13.3320,  14.9130,  -9.0635],\n",
      "        [ 16.2436,   9.9103,  11.6089, -13.7928,  15.2911,  -9.5544],\n",
      "        [ 16.2587,  10.0287,  11.4305, -14.1544,  14.8766,  -9.2811],\n",
      "        [ 15.7491,   9.8553,  11.6663, -13.4323,  15.1469,  -9.0458],\n",
      "        [ 16.0809,  10.4441,  11.2479, -13.5133,  15.2069,  -8.8986]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8330318927764893\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7902, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6440,  9.9322, 11.9096],\n",
      "        [15.7941,  9.9603, 11.5490],\n",
      "        [16.0628,  9.8751, 11.5204],\n",
      "        [15.8613, 10.1679, 11.6082],\n",
      "        [15.5435,  9.6602, 11.4548],\n",
      "        [15.9895, 10.0387, 11.8823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4713, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8737,  14.9971,  -9.3682],\n",
      "        [-13.8241,  15.4247,  -9.4463],\n",
      "        [-13.4741,  15.0328,  -9.2826],\n",
      "        [-14.0636,  15.7319,  -9.4525],\n",
      "        [-13.3162,  14.9408,  -9.4594],\n",
      "        [-13.4814,  15.0309,  -9.3439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6440,   9.9322,  11.9096, -13.8737,  14.9971,  -9.3682],\n",
      "        [ 15.7941,   9.9603,  11.5490, -13.8241,  15.4247,  -9.4463],\n",
      "        [ 16.0628,   9.8751,  11.5204, -13.4741,  15.0328,  -9.2826],\n",
      "        [ 15.8613,  10.1679,  11.6082, -14.0636,  15.7319,  -9.4525],\n",
      "        [ 15.5435,   9.6602,  11.4548, -13.3162,  14.9408,  -9.4594],\n",
      "        [ 15.9895,  10.0387,  11.8823, -13.4814,  15.0309,  -9.3439]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8304795026779175\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3536, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4615, 10.2375, 11.8351],\n",
      "        [16.2773,  9.7670, 11.3699],\n",
      "        [15.8847, 10.3325, 11.3912],\n",
      "        [16.2042,  9.7057, 11.9053],\n",
      "        [16.0481, 10.1439, 11.9527],\n",
      "        [15.4757,  9.9071, 11.5421]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3629,  14.5781,  -9.1384],\n",
      "        [-14.0626,  15.0584,  -9.4657],\n",
      "        [-13.4543,  14.9389,  -9.2288],\n",
      "        [-13.7261,  14.8450,  -9.3535],\n",
      "        [-13.3548,  14.6182,  -8.8691],\n",
      "        [-13.4382,  15.1175,  -9.2305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4615,  10.2375,  11.8351, -13.3629,  14.5781,  -9.1384],\n",
      "        [ 16.2773,   9.7670,  11.3699, -14.0626,  15.0584,  -9.4657],\n",
      "        [ 15.8847,  10.3325,  11.3912, -13.4543,  14.9389,  -9.2288],\n",
      "        [ 16.2042,   9.7057,  11.9053, -13.7261,  14.8450,  -9.3535],\n",
      "        [ 16.0481,  10.1439,  11.9527, -13.3548,  14.6182,  -8.8691],\n",
      "        [ 15.4757,   9.9071,  11.5421, -13.4382,  15.1175,  -9.2305]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8457733392715454\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6890, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5611,  9.9841, 11.5805],\n",
      "        [16.0485,  9.9744, 11.3914],\n",
      "        [16.0031, 10.0130, 11.9052],\n",
      "        [16.2054, 10.1017, 11.4763],\n",
      "        [15.9040, 10.0450, 11.7097],\n",
      "        [16.1314, 10.3753, 11.4620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3664, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6227,  15.0717,  -9.2284],\n",
      "        [-13.5934,  14.7126,  -9.2200],\n",
      "        [-13.7182,  15.2816,  -9.2817],\n",
      "        [-13.5560,  15.0785,  -9.4412],\n",
      "        [-13.7466,  15.5524,  -9.2546],\n",
      "        [-13.6566,  14.9427,  -8.8272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5611,   9.9841,  11.5805, -13.6227,  15.0717,  -9.2284],\n",
      "        [ 16.0485,   9.9744,  11.3914, -13.5934,  14.7126,  -9.2200],\n",
      "        [ 16.0031,  10.0130,  11.9052, -13.7182,  15.2816,  -9.2817],\n",
      "        [ 16.2054,  10.1017,  11.4763, -13.5560,  15.0785,  -9.4412],\n",
      "        [ 15.9040,  10.0450,  11.7097, -13.7466,  15.5524,  -9.2546],\n",
      "        [ 16.1314,  10.3753,  11.4620, -13.6566,  14.9427,  -8.8272]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8547937870025635\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0787,  9.8966, 11.4381],\n",
      "        [16.1245, 10.2395, 11.6050],\n",
      "        [15.9764, 10.3178, 11.7264],\n",
      "        [15.8277,  9.8545, 11.0345],\n",
      "        [16.1272, 10.3853, 11.7374],\n",
      "        [16.0635,  9.9494, 12.0622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.4896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8280,  14.9833,  -9.2409],\n",
      "        [-13.6675,  15.0809,  -9.2665],\n",
      "        [-13.6881,  15.5013,  -9.2394],\n",
      "        [-13.7066,  15.2399,  -9.3609],\n",
      "        [-13.6513,  15.6309,  -9.4378],\n",
      "        [-13.7465,  14.9286,  -9.2446]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0787,   9.8966,  11.4381, -13.8280,  14.9833,  -9.2409],\n",
      "        [ 16.1245,  10.2395,  11.6050, -13.6675,  15.0809,  -9.2665],\n",
      "        [ 15.9764,  10.3178,  11.7264, -13.6881,  15.5013,  -9.2394],\n",
      "        [ 15.8277,   9.8545,  11.0345, -13.7066,  15.2399,  -9.3609],\n",
      "        [ 16.1272,  10.3853,  11.7374, -13.6513,  15.6309,  -9.4378],\n",
      "        [ 16.0635,   9.9494,  12.0622, -13.7465,  14.9286,  -9.2446]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.833228588104248\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8886,  9.8740, 11.7007],\n",
      "        [16.3089, 10.3847, 12.0307],\n",
      "        [16.1957, 10.0912, 11.5557],\n",
      "        [16.0498, 10.0600, 11.6298],\n",
      "        [16.0069, 10.1357, 11.5790],\n",
      "        [15.8056, 10.0402, 11.8994]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.0458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0297,  15.0766,  -9.2031],\n",
      "        [-13.7456,  14.9931,  -9.7036],\n",
      "        [-13.6692,  15.2321,  -9.0976],\n",
      "        [-13.5475,  14.8077,  -9.2788],\n",
      "        [-13.9612,  15.1987,  -9.6115],\n",
      "        [-13.8309,  15.2887,  -9.3278]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8886,   9.8740,  11.7007, -14.0297,  15.0766,  -9.2031],\n",
      "        [ 16.3089,  10.3847,  12.0307, -13.7456,  14.9931,  -9.7036],\n",
      "        [ 16.1957,  10.0912,  11.5557, -13.6692,  15.2321,  -9.0976],\n",
      "        [ 16.0498,  10.0600,  11.6298, -13.5475,  14.8077,  -9.2788],\n",
      "        [ 16.0069,  10.1357,  11.5790, -13.9612,  15.1987,  -9.6115],\n",
      "        [ 15.8056,  10.0402,  11.8994, -13.8309,  15.2887,  -9.3278]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.83950936794281\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7279,  9.6164, 11.5406],\n",
      "        [16.1147, 10.0389, 11.7159],\n",
      "        [16.0415,  9.7546, 11.5392],\n",
      "        [15.5716,  9.8225, 11.2616],\n",
      "        [15.5247,  9.9776, 11.2984],\n",
      "        [16.0699, 10.2876, 11.6566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0629, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6675,  15.1989,  -9.4636],\n",
      "        [-13.4010,  15.0393,  -9.2632],\n",
      "        [-13.7354,  14.8879,  -9.2947],\n",
      "        [-13.7577,  15.2921,  -9.4252],\n",
      "        [-13.4502,  15.0991,  -9.0773],\n",
      "        [-13.8181,  15.3631,  -9.3927]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7279,   9.6164,  11.5406, -13.6675,  15.1989,  -9.4636],\n",
      "        [ 16.1147,  10.0389,  11.7159, -13.4010,  15.0393,  -9.2632],\n",
      "        [ 16.0415,   9.7546,  11.5392, -13.7354,  14.8879,  -9.2947],\n",
      "        [ 15.5716,   9.8225,  11.2616, -13.7577,  15.2921,  -9.4252],\n",
      "        [ 15.5247,   9.9776,  11.2984, -13.4502,  15.0991,  -9.0773],\n",
      "        [ 16.0699,  10.2876,  11.6566, -13.8181,  15.3631,  -9.3927]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8234885931015015\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0930,  9.6974, 11.4850],\n",
      "        [15.9383,  9.8321, 11.4649],\n",
      "        [16.1490,  9.6068, 11.6528],\n",
      "        [15.8974,  9.8919, 11.5259],\n",
      "        [16.1273, 10.0360, 12.1352],\n",
      "        [16.0271, 10.0113, 11.7865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.7727, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1507,  15.5287,  -9.5512],\n",
      "        [-13.4226,  14.9228,  -9.0752],\n",
      "        [-13.9076,  15.0159,  -9.1273],\n",
      "        [-13.6231,  15.0748,  -9.1912],\n",
      "        [-13.6475,  15.0436,  -9.1642],\n",
      "        [-13.6461,  15.1735,  -9.2368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0930,   9.6974,  11.4850, -14.1507,  15.5287,  -9.5512],\n",
      "        [ 15.9383,   9.8321,  11.4649, -13.4226,  14.9228,  -9.0752],\n",
      "        [ 16.1490,   9.6068,  11.6528, -13.9076,  15.0159,  -9.1273],\n",
      "        [ 15.8974,   9.8919,  11.5259, -13.6231,  15.0748,  -9.1912],\n",
      "        [ 16.1273,  10.0360,  12.1352, -13.6475,  15.0436,  -9.1642],\n",
      "        [ 16.0271,  10.0113,  11.7865, -13.6461,  15.1735,  -9.2368]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8557063341140747\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4388, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.6982,  9.5890, 11.7200],\n",
      "        [16.3701, 10.0877, 11.6542],\n",
      "        [16.2652, 10.0796, 11.6169],\n",
      "        [15.8527,  9.8682, 11.4767],\n",
      "        [15.7399,  9.9240, 11.3448],\n",
      "        [15.9168,  9.7141, 11.8872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8863,  15.7121,  -9.3688],\n",
      "        [-13.5729,  14.9418,  -9.2733],\n",
      "        [-13.8331,  15.6100,  -9.2695],\n",
      "        [-13.4988,  15.4361,  -9.4369],\n",
      "        [-13.8590,  15.1054,  -9.1764],\n",
      "        [-13.2539,  15.1020,  -9.1581]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.6982,   9.5890,  11.7200, -13.8863,  15.7121,  -9.3688],\n",
      "        [ 16.3701,  10.0877,  11.6542, -13.5729,  14.9418,  -9.2733],\n",
      "        [ 16.2652,  10.0796,  11.6169, -13.8331,  15.6100,  -9.2695],\n",
      "        [ 15.8527,   9.8682,  11.4767, -13.4988,  15.4361,  -9.4369],\n",
      "        [ 15.7399,   9.9240,  11.3448, -13.8590,  15.1054,  -9.1764],\n",
      "        [ 15.9168,   9.7141,  11.8872, -13.2539,  15.1020,  -9.1581]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8430759906768799\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9159, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.5737,  9.7671, 11.2244],\n",
      "        [15.6788, 10.3263, 11.6309],\n",
      "        [16.1963, 10.1497, 11.5973],\n",
      "        [16.0528, 10.1086, 11.2188],\n",
      "        [16.1255,  9.9364, 12.0711],\n",
      "        [16.0893, 10.2460, 11.8231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.8778, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.2087,  14.9666,  -9.3419],\n",
      "        [-13.4095,  14.6926,  -9.2065],\n",
      "        [-13.7251,  15.0561,  -9.0965],\n",
      "        [-13.6589,  15.4847,  -9.4476],\n",
      "        [-13.5755,  15.1009,  -9.2739],\n",
      "        [-13.5969,  15.0927,  -9.0609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.5737,   9.7671,  11.2244, -13.2087,  14.9666,  -9.3419],\n",
      "        [ 15.6788,  10.3263,  11.6309, -13.4095,  14.6926,  -9.2065],\n",
      "        [ 16.1963,  10.1497,  11.5973, -13.7251,  15.0561,  -9.0965],\n",
      "        [ 16.0528,  10.1086,  11.2188, -13.6589,  15.4847,  -9.4476],\n",
      "        [ 16.1255,   9.9364,  12.0711, -13.5755,  15.1009,  -9.2739],\n",
      "        [ 16.0893,  10.2460,  11.8231, -13.5969,  15.0927,  -9.0609]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.7988601922988892\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0350, 10.1441, 11.8900],\n",
      "        [15.8555,  9.8565, 11.9826],\n",
      "        [16.0883, 10.1402, 12.0505],\n",
      "        [15.9868, 10.1827, 11.8436],\n",
      "        [16.2594, 10.1622, 11.7240],\n",
      "        [16.2864,  9.6551, 11.6923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.5487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4616,  15.0597,  -9.1522],\n",
      "        [-13.8012,  15.2650,  -8.9988],\n",
      "        [-13.2606,  14.8436,  -9.1988],\n",
      "        [-13.7171,  15.0911,  -9.3279],\n",
      "        [-13.6782,  15.4849,  -9.4370],\n",
      "        [-13.8693,  15.4764,  -9.5889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0350,  10.1441,  11.8900, -13.4616,  15.0597,  -9.1522],\n",
      "        [ 15.8555,   9.8565,  11.9826, -13.8012,  15.2650,  -8.9988],\n",
      "        [ 16.0883,  10.1402,  12.0505, -13.2606,  14.8436,  -9.1988],\n",
      "        [ 15.9868,  10.1827,  11.8436, -13.7171,  15.0911,  -9.3279],\n",
      "        [ 16.2594,  10.1622,  11.7240, -13.6782,  15.4849,  -9.4370],\n",
      "        [ 16.2864,   9.6551,  11.6923, -13.8693,  15.4764,  -9.5889]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.8492580652236938\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1811, 10.2330, 11.6004],\n",
      "        [16.0830,  9.8510, 11.6506],\n",
      "        [16.0178, 10.2612, 11.6477],\n",
      "        [15.4974, 10.1137, 11.5561],\n",
      "        [16.3413,  9.7966, 11.7646],\n",
      "        [15.9247,  9.8782, 11.3121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6697, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7185,  15.2075,  -9.0174],\n",
      "        [-14.2453,  15.2672,  -9.1715],\n",
      "        [-14.0649,  15.4181,  -9.1899],\n",
      "        [-13.7255,  15.0031,  -9.5078],\n",
      "        [-13.8012,  15.2376,  -9.3864],\n",
      "        [-13.9467,  15.1220,  -9.3567]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1811,  10.2330,  11.6004, -13.7185,  15.2075,  -9.0174],\n",
      "        [ 16.0830,   9.8510,  11.6506, -14.2453,  15.2672,  -9.1715],\n",
      "        [ 16.0178,  10.2612,  11.6477, -14.0649,  15.4181,  -9.1899],\n",
      "        [ 15.4974,  10.1137,  11.5561, -13.7255,  15.0031,  -9.5078],\n",
      "        [ 16.3413,   9.7966,  11.7646, -13.8012,  15.2376,  -9.3864],\n",
      "        [ 15.9247,   9.8782,  11.3121, -13.9467,  15.1220,  -9.3567]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8554470539093018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3175, 10.0150, 11.6212],\n",
      "        [15.9434,  9.8560, 11.7298],\n",
      "        [16.2048,  9.9131, 11.4633],\n",
      "        [15.9832, 10.2644, 11.8286],\n",
      "        [16.0144,  9.7740, 11.8801],\n",
      "        [16.2252,  9.9362, 11.6723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2932, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7537,  15.2874,  -8.9819],\n",
      "        [-13.7822,  15.3378,  -9.6384],\n",
      "        [-13.6178,  14.9838,  -9.0027],\n",
      "        [-13.7057,  15.1336,  -9.4887],\n",
      "        [-13.7167,  15.0422,  -9.4957],\n",
      "        [-13.9979,  15.2343,  -9.1244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3175,  10.0150,  11.6212, -13.7537,  15.2874,  -8.9819],\n",
      "        [ 15.9434,   9.8560,  11.7298, -13.7822,  15.3378,  -9.6384],\n",
      "        [ 16.2048,   9.9131,  11.4633, -13.6178,  14.9838,  -9.0027],\n",
      "        [ 15.9832,  10.2644,  11.8286, -13.7057,  15.1336,  -9.4887],\n",
      "        [ 16.0144,   9.7740,  11.8801, -13.7167,  15.0422,  -9.4957],\n",
      "        [ 16.2252,   9.9362,  11.6723, -13.9979,  15.2343,  -9.1244]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8603205680847168\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2783, 10.1620, 11.7194],\n",
      "        [15.6594,  9.7080, 11.5295],\n",
      "        [15.9397,  9.9742, 11.9502],\n",
      "        [16.2493, 10.0400, 11.4784],\n",
      "        [15.8610, 10.2713, 11.9291],\n",
      "        [15.7366, 10.1615, 11.6006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5498, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9998,  15.6009,  -9.6938],\n",
      "        [-13.8209,  15.1828,  -9.2504],\n",
      "        [-13.5043,  14.9752,  -9.5748],\n",
      "        [-13.5181,  15.3468,  -9.8739],\n",
      "        [-13.5800,  14.9672,  -9.3278],\n",
      "        [-13.5264,  15.4681,  -9.3367]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2783,  10.1620,  11.7194, -13.9998,  15.6009,  -9.6938],\n",
      "        [ 15.6594,   9.7080,  11.5295, -13.8209,  15.1828,  -9.2504],\n",
      "        [ 15.9397,   9.9742,  11.9502, -13.5043,  14.9752,  -9.5748],\n",
      "        [ 16.2493,  10.0400,  11.4784, -13.5181,  15.3468,  -9.8739],\n",
      "        [ 15.8610,  10.2713,  11.9291, -13.5800,  14.9672,  -9.3278],\n",
      "        [ 15.7366,  10.1615,  11.6006, -13.5264,  15.4681,  -9.3367]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8850089311599731\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0496, 10.1632, 11.2137],\n",
      "        [15.9135, 10.1431, 11.7062],\n",
      "        [15.9126, 10.0622, 11.3272],\n",
      "        [16.0565,  9.9883, 11.6009],\n",
      "        [15.9849, 10.1869, 11.8031],\n",
      "        [16.0559,  9.8928, 11.4638]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2463, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4681,  15.3750,  -9.2618],\n",
      "        [-13.4430,  15.4585,  -9.5471],\n",
      "        [-13.8111,  15.1988,  -9.2927],\n",
      "        [-14.0651,  15.4487,  -9.6298],\n",
      "        [-13.4493,  15.1273,  -9.3767],\n",
      "        [-14.0148,  15.5193,  -9.7470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0496,  10.1632,  11.2137, -13.4681,  15.3750,  -9.2618],\n",
      "        [ 15.9135,  10.1431,  11.7062, -13.4430,  15.4585,  -9.5471],\n",
      "        [ 15.9126,  10.0622,  11.3272, -13.8111,  15.1988,  -9.2927],\n",
      "        [ 16.0565,   9.9883,  11.6009, -14.0651,  15.4487,  -9.6298],\n",
      "        [ 15.9849,  10.1869,  11.8031, -13.4493,  15.1273,  -9.3767],\n",
      "        [ 16.0559,   9.8928,  11.4638, -14.0148,  15.5193,  -9.7470]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8421505689620972\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2831, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1364, 10.4367, 11.8041],\n",
      "        [16.5687, 10.2925, 11.7153],\n",
      "        [16.0733,  9.9344, 11.9043],\n",
      "        [16.7369, 10.4786, 11.8016],\n",
      "        [15.8103, 10.1802, 11.6744],\n",
      "        [16.2248, 10.2909, 11.6826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2670, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1078,  15.3956,  -9.6531],\n",
      "        [-14.0127,  15.1573,  -9.3128],\n",
      "        [-13.7703,  15.3175,  -9.3664],\n",
      "        [-13.7903,  15.3974,  -9.4881],\n",
      "        [-13.5838,  15.0692,  -9.2509],\n",
      "        [-14.0412,  15.4041,  -9.7055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1364,  10.4367,  11.8041, -14.1078,  15.3956,  -9.6531],\n",
      "        [ 16.5687,  10.2925,  11.7153, -14.0127,  15.1573,  -9.3128],\n",
      "        [ 16.0733,   9.9344,  11.9043, -13.7703,  15.3175,  -9.3664],\n",
      "        [ 16.7369,  10.4786,  11.8016, -13.7903,  15.3974,  -9.4881],\n",
      "        [ 15.8103,  10.1802,  11.6744, -13.5838,  15.0692,  -9.2509],\n",
      "        [ 16.2248,  10.2909,  11.6826, -14.0412,  15.4041,  -9.7055]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8863314390182495\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1021, 10.2456, 11.9458],\n",
      "        [16.4172, 10.3525, 11.8218],\n",
      "        [15.9803, 10.2449, 11.6938],\n",
      "        [16.3892,  9.9046, 11.6651],\n",
      "        [15.9873,  9.9440, 11.9833],\n",
      "        [16.2080, 10.1618, 11.6023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5805,  15.2992,  -9.8779],\n",
      "        [-14.1697,  15.3451,  -9.5140],\n",
      "        [-13.7953,  15.4017,  -9.3878],\n",
      "        [-14.0124,  15.2309,  -9.5464],\n",
      "        [-14.0912,  15.3357,  -9.6703],\n",
      "        [-13.7578,  15.3823,  -9.5262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1021,  10.2456,  11.9458, -13.5805,  15.2992,  -9.8779],\n",
      "        [ 16.4172,  10.3525,  11.8218, -14.1697,  15.3451,  -9.5140],\n",
      "        [ 15.9803,  10.2449,  11.6938, -13.7953,  15.4017,  -9.3878],\n",
      "        [ 16.3892,   9.9046,  11.6651, -14.0124,  15.2309,  -9.5464],\n",
      "        [ 15.9873,   9.9440,  11.9833, -14.0912,  15.3357,  -9.6703],\n",
      "        [ 16.2080,  10.1618,  11.6023, -13.7578,  15.3823,  -9.5262]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.8772605657577515\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9974, 10.0714, 11.6024],\n",
      "        [16.1640, 10.0141, 11.7553],\n",
      "        [16.1330, 10.2634, 11.9245],\n",
      "        [16.2277, 10.4186, 11.7428],\n",
      "        [16.2605,  9.9408, 11.3968],\n",
      "        [15.9801,  9.7466, 11.2101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2608, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6043,  15.3429,  -9.4364],\n",
      "        [-13.6928,  15.1193,  -9.8266],\n",
      "        [-13.2862,  15.2183,  -9.5462],\n",
      "        [-14.1638,  15.7592,  -9.4492],\n",
      "        [-14.1225,  15.5003,  -9.4530],\n",
      "        [-13.4409,  14.7493,  -9.0107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9974,  10.0714,  11.6024, -13.6043,  15.3429,  -9.4364],\n",
      "        [ 16.1640,  10.0141,  11.7553, -13.6928,  15.1193,  -9.8266],\n",
      "        [ 16.1330,  10.2634,  11.9245, -13.2862,  15.2183,  -9.5462],\n",
      "        [ 16.2277,  10.4186,  11.7428, -14.1638,  15.7592,  -9.4492],\n",
      "        [ 16.2605,   9.9408,  11.3968, -14.1225,  15.5003,  -9.4530],\n",
      "        [ 15.9801,   9.7466,  11.2101, -13.4409,  14.7493,  -9.0107]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.85692298412323\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9846, 10.1965, 12.1399],\n",
      "        [16.0036, 10.2347, 11.9284],\n",
      "        [15.9846, 10.1471, 11.8966],\n",
      "        [15.8228, 10.2629, 11.6748],\n",
      "        [16.2571, 10.2108, 11.6394],\n",
      "        [16.3629, 10.3022, 12.0441]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.3681,  15.1957,  -9.2666],\n",
      "        [-13.7476,  15.1922,  -9.7832],\n",
      "        [-13.8551,  15.4883,  -9.7270],\n",
      "        [-13.8416,  15.0474,  -9.3613],\n",
      "        [-13.8404,  15.1639,  -9.5504],\n",
      "        [-13.9161,  15.4333,  -9.2783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9846,  10.1965,  12.1399, -13.3681,  15.1957,  -9.2666],\n",
      "        [ 16.0036,  10.2347,  11.9284, -13.7476,  15.1922,  -9.7832],\n",
      "        [ 15.9846,  10.1471,  11.8966, -13.8551,  15.4883,  -9.7270],\n",
      "        [ 15.8228,  10.2629,  11.6748, -13.8416,  15.0474,  -9.3613],\n",
      "        [ 16.2571,  10.2108,  11.6394, -13.8404,  15.1639,  -9.5504],\n",
      "        [ 16.3629,  10.3022,  12.0441, -13.9161,  15.4333,  -9.2783]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8662174940109253\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3090, 10.3812, 11.5968],\n",
      "        [16.1495, 10.0789, 11.4746],\n",
      "        [16.1945, 10.0415, 11.8614],\n",
      "        [16.1183, 10.2172, 11.8044],\n",
      "        [16.0601, 10.3474, 11.7117],\n",
      "        [15.7196, 10.3964, 11.9837]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.5303,  15.3177,  -9.1702],\n",
      "        [-13.8095,  15.2972,  -9.1617],\n",
      "        [-13.7892,  15.3163,  -9.0035],\n",
      "        [-13.5448,  15.0701,  -9.3629],\n",
      "        [-14.0791,  15.5150,  -9.7484],\n",
      "        [-14.0027,  15.3628,  -9.8954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3090,  10.3812,  11.5968, -13.5303,  15.3177,  -9.1702],\n",
      "        [ 16.1495,  10.0789,  11.4746, -13.8095,  15.2972,  -9.1617],\n",
      "        [ 16.1945,  10.0415,  11.8614, -13.7892,  15.3163,  -9.0035],\n",
      "        [ 16.1183,  10.2172,  11.8044, -13.5448,  15.0701,  -9.3629],\n",
      "        [ 16.0601,  10.3474,  11.7117, -14.0791,  15.5150,  -9.7484],\n",
      "        [ 15.7196,  10.3964,  11.9837, -14.0027,  15.3628,  -9.8954]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8717478513717651\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1907, 10.3084, 11.9059],\n",
      "        [16.3076,  9.7625, 11.9221],\n",
      "        [16.3772, 10.3473, 11.7898],\n",
      "        [16.0581,  9.8780, 11.6434],\n",
      "        [15.9468, 10.1264, 12.0455],\n",
      "        [16.3531, 10.1643, 11.7556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8380,  15.2572,  -9.3100],\n",
      "        [-13.8316,  15.5711,  -9.7954],\n",
      "        [-13.3194,  15.4305,  -9.2041],\n",
      "        [-13.9149,  15.3103,  -9.4952],\n",
      "        [-13.9889,  15.2141,  -9.3658],\n",
      "        [-13.7876,  14.9168,  -9.4104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1907,  10.3084,  11.9059, -13.8380,  15.2572,  -9.3100],\n",
      "        [ 16.3076,   9.7625,  11.9221, -13.8316,  15.5711,  -9.7954],\n",
      "        [ 16.3772,  10.3473,  11.7898, -13.3194,  15.4305,  -9.2041],\n",
      "        [ 16.0581,   9.8780,  11.6434, -13.9149,  15.3103,  -9.4952],\n",
      "        [ 15.9468,  10.1264,  12.0455, -13.9889,  15.2141,  -9.3658],\n",
      "        [ 16.3531,  10.1643,  11.7556, -13.7876,  14.9168,  -9.4104]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8821660280227661\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8943, 10.1505, 11.8611],\n",
      "        [15.8074, 10.0866, 10.9958],\n",
      "        [16.0545,  9.8254, 11.6149],\n",
      "        [16.2479, 10.3933, 11.9741],\n",
      "        [16.2316,  9.7816, 11.7781],\n",
      "        [16.1878, 10.1817, 11.9759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8230,  15.6890,  -9.6766],\n",
      "        [-13.9026,  15.1847,  -9.8019],\n",
      "        [-14.1392,  15.5089,  -9.6354],\n",
      "        [-13.9052,  15.6347,  -9.7667],\n",
      "        [-14.1552,  15.3872,  -9.7812],\n",
      "        [-13.8602,  15.3545,  -9.5903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8943,  10.1505,  11.8611, -13.8230,  15.6890,  -9.6766],\n",
      "        [ 15.8074,  10.0866,  10.9958, -13.9026,  15.1847,  -9.8019],\n",
      "        [ 16.0545,   9.8254,  11.6149, -14.1392,  15.5089,  -9.6354],\n",
      "        [ 16.2479,  10.3933,  11.9741, -13.9052,  15.6347,  -9.7667],\n",
      "        [ 16.2316,   9.7816,  11.7781, -14.1552,  15.3872,  -9.7812],\n",
      "        [ 16.1878,  10.1817,  11.9759, -13.8602,  15.3545,  -9.5903]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8804876804351807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6633, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1889, 10.4335, 11.6629],\n",
      "        [15.9492,  9.9714, 11.8272],\n",
      "        [15.6273, 10.1383, 11.4576],\n",
      "        [15.7466,  9.9911, 11.6797],\n",
      "        [15.8141, 10.0924, 11.7177],\n",
      "        [16.3972,  9.9996, 11.6984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6992, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9174,  15.3995,  -9.8188],\n",
      "        [-14.2236,  15.7964,  -9.5786],\n",
      "        [-13.5324,  15.0102,  -8.7267],\n",
      "        [-14.0293,  15.3947,  -9.5630],\n",
      "        [-13.9599,  15.7486,  -9.4517],\n",
      "        [-13.6155,  15.5061,  -9.2200]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1889,  10.4335,  11.6629, -13.9174,  15.3995,  -9.8188],\n",
      "        [ 15.9492,   9.9714,  11.8272, -14.2236,  15.7964,  -9.5786],\n",
      "        [ 15.6273,  10.1383,  11.4576, -13.5324,  15.0102,  -8.7267],\n",
      "        [ 15.7466,   9.9911,  11.6797, -14.0293,  15.3947,  -9.5630],\n",
      "        [ 15.8141,  10.0924,  11.7177, -13.9599,  15.7486,  -9.4517],\n",
      "        [ 16.3972,   9.9996,  11.6984, -13.6155,  15.5061,  -9.2200]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.8897159099578857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1182, 10.2352, 11.7329],\n",
      "        [16.4956, 10.3612, 11.8930],\n",
      "        [15.9208, 10.3358, 11.6392],\n",
      "        [16.3362, 10.1320, 11.7875],\n",
      "        [15.7576, 10.0317, 11.6260],\n",
      "        [16.4527,  9.9850, 12.0851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.3974, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9770,  15.6229,  -9.3577],\n",
      "        [-13.9078,  15.5686,  -9.7884],\n",
      "        [-13.7759,  15.3454,  -9.3356],\n",
      "        [-13.6408,  15.1562,  -9.2115],\n",
      "        [-13.8011,  15.4453,  -9.1946],\n",
      "        [-13.5387,  14.9721,  -9.5663]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1182,  10.2352,  11.7329, -13.9770,  15.6229,  -9.3577],\n",
      "        [ 16.4956,  10.3612,  11.8930, -13.9078,  15.5686,  -9.7884],\n",
      "        [ 15.9208,  10.3358,  11.6392, -13.7759,  15.3454,  -9.3356],\n",
      "        [ 16.3362,  10.1320,  11.7875, -13.6408,  15.1562,  -9.2115],\n",
      "        [ 15.7576,  10.0317,  11.6260, -13.8011,  15.4453,  -9.1946],\n",
      "        [ 16.4527,   9.9850,  12.0851, -13.5387,  14.9721,  -9.5663]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8868615627288818\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4407, 10.3698, 11.6330],\n",
      "        [16.0419, 10.4654, 12.0931],\n",
      "        [15.9569,  9.9847, 11.8010],\n",
      "        [16.1647,  9.8426, 11.4715],\n",
      "        [16.2803, 10.4205, 11.9425],\n",
      "        [16.3299, 10.2006, 12.1409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.6863, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1249,  15.4303,  -9.9262],\n",
      "        [-14.2113,  15.5817,  -9.5534],\n",
      "        [-13.9689,  15.1516,  -9.5343],\n",
      "        [-13.5468,  15.5033,  -9.7645],\n",
      "        [-14.3792,  15.5710,  -9.5515],\n",
      "        [-14.0989,  15.6706,  -9.5170]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4407,  10.3698,  11.6330, -14.1249,  15.4303,  -9.9262],\n",
      "        [ 16.0419,  10.4654,  12.0931, -14.2113,  15.5817,  -9.5534],\n",
      "        [ 15.9569,   9.9847,  11.8010, -13.9689,  15.1516,  -9.5343],\n",
      "        [ 16.1647,   9.8426,  11.4715, -13.5468,  15.5033,  -9.7645],\n",
      "        [ 16.2803,  10.4205,  11.9425, -14.3792,  15.5710,  -9.5515],\n",
      "        [ 16.3299,  10.2006,  12.1409, -14.0989,  15.6706,  -9.5170]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9054548740386963\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9453, 10.4979, 11.4432],\n",
      "        [16.0806, 10.1105, 11.8609],\n",
      "        [16.1763,  9.8319, 11.8335],\n",
      "        [16.2235, 10.3173, 11.6835],\n",
      "        [16.2201, 10.0029, 11.8004],\n",
      "        [16.4627, 10.2201, 11.7367]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.7635, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1424,  15.0693,  -9.7404],\n",
      "        [-14.0260,  15.8536,  -9.6512],\n",
      "        [-14.3575,  15.5354,  -9.3781],\n",
      "        [-13.6320,  15.6327,  -9.9905],\n",
      "        [-13.6900,  15.2610,  -9.3071],\n",
      "        [-13.7691,  15.7071,  -9.5427]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9453,  10.4979,  11.4432, -14.1424,  15.0693,  -9.7404],\n",
      "        [ 16.0806,  10.1105,  11.8609, -14.0260,  15.8536,  -9.6512],\n",
      "        [ 16.1763,   9.8319,  11.8335, -14.3575,  15.5354,  -9.3781],\n",
      "        [ 16.2235,  10.3173,  11.6835, -13.6320,  15.6327,  -9.9905],\n",
      "        [ 16.2201,  10.0029,  11.8004, -13.6900,  15.2610,  -9.3071],\n",
      "        [ 16.4627,  10.2201,  11.7367, -13.7691,  15.7071,  -9.5427]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8741238117218018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5425, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0805, 10.1406, 12.0085],\n",
      "        [15.9994, 10.5514, 11.7131],\n",
      "        [16.3556, 10.3465, 12.3191],\n",
      "        [16.2583,  9.9386, 12.0223],\n",
      "        [16.1043, 10.4327, 11.6546],\n",
      "        [16.2782, 10.0445, 11.5552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8406, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6120,  15.0232,  -9.5637],\n",
      "        [-13.8420,  15.2211,  -9.4127],\n",
      "        [-13.9424,  15.4576,  -9.5889],\n",
      "        [-13.9028,  15.4099,  -9.7259],\n",
      "        [-13.8490,  15.3456,  -9.4258],\n",
      "        [-14.0284,  15.7193,  -9.6668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0805,  10.1406,  12.0085, -13.6120,  15.0232,  -9.5637],\n",
      "        [ 15.9994,  10.5514,  11.7131, -13.8420,  15.2211,  -9.4127],\n",
      "        [ 16.3556,  10.3465,  12.3191, -13.9424,  15.4576,  -9.5889],\n",
      "        [ 16.2583,   9.9386,  12.0223, -13.9028,  15.4099,  -9.7259],\n",
      "        [ 16.1043,  10.4327,  11.6546, -13.8490,  15.3456,  -9.4258],\n",
      "        [ 16.2782,  10.0445,  11.5552, -14.0284,  15.7193,  -9.6668]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.877522349357605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2835, 10.1661, 11.8383],\n",
      "        [16.6438, 10.6961, 11.5532],\n",
      "        [16.1571, 10.3728, 11.8677],\n",
      "        [16.1425, 10.3439, 11.8587],\n",
      "        [16.3416, 10.3680, 11.9522],\n",
      "        [16.3211, 10.2430, 11.8949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1678, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.4641,  15.2119,  -9.2802],\n",
      "        [-14.0205,  15.4364,  -9.7708],\n",
      "        [-13.3922,  14.9663,  -9.7459],\n",
      "        [-13.5718,  15.1771,  -9.9308],\n",
      "        [-13.7319,  15.4913,  -9.9678],\n",
      "        [-14.2238,  15.8410,  -9.8669]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2835,  10.1661,  11.8383, -13.4641,  15.2119,  -9.2802],\n",
      "        [ 16.6438,  10.6961,  11.5532, -14.0205,  15.4364,  -9.7708],\n",
      "        [ 16.1571,  10.3728,  11.8677, -13.3922,  14.9663,  -9.7459],\n",
      "        [ 16.1425,  10.3439,  11.8587, -13.5718,  15.1771,  -9.9308],\n",
      "        [ 16.3416,  10.3680,  11.9522, -13.7319,  15.4913,  -9.9678],\n",
      "        [ 16.3211,  10.2430,  11.8949, -14.2238,  15.8410,  -9.8669]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8798030614852905\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3956, 10.1253, 12.0218],\n",
      "        [15.8537,  9.9145, 11.8332],\n",
      "        [16.0989, 10.2066, 11.7242],\n",
      "        [16.2907, 10.3895, 11.6584],\n",
      "        [15.9382, 10.3747, 11.8174],\n",
      "        [16.2717, 10.1522, 11.9308]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1573,  15.3152,  -9.4543],\n",
      "        [-14.1578,  15.8248,  -9.6930],\n",
      "        [-14.1192,  15.9784,  -9.8220],\n",
      "        [-13.8598,  15.8703,  -9.4883],\n",
      "        [-13.7019,  15.1157,  -9.3265],\n",
      "        [-14.0445,  15.4610,  -9.5034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3956,  10.1253,  12.0218, -14.1573,  15.3152,  -9.4543],\n",
      "        [ 15.8537,   9.9145,  11.8332, -14.1578,  15.8248,  -9.6930],\n",
      "        [ 16.0989,  10.2066,  11.7242, -14.1192,  15.9784,  -9.8220],\n",
      "        [ 16.2907,  10.3895,  11.6584, -13.8598,  15.8703,  -9.4883],\n",
      "        [ 15.9382,  10.3747,  11.8174, -13.7019,  15.1157,  -9.3265],\n",
      "        [ 16.2717,  10.1522,  11.9308, -14.0445,  15.4610,  -9.5034]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.907461166381836\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.8012, 10.3832, 11.9842],\n",
      "        [16.2980, 10.1033, 11.7993],\n",
      "        [16.3144, 10.4927, 11.7683],\n",
      "        [16.4729,  9.9824, 11.9692],\n",
      "        [16.2668, 10.4314, 12.2325],\n",
      "        [15.8173,  9.9378, 11.4056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7253,  15.0941,  -9.4513],\n",
      "        [-13.9658,  15.7145,  -9.7128],\n",
      "        [-13.6176,  15.4666,  -9.9074],\n",
      "        [-13.7601,  15.2233,  -9.2986],\n",
      "        [-14.1717,  15.4529,  -9.7110],\n",
      "        [-14.1870,  15.8375, -10.0576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.8012,  10.3832,  11.9842, -13.7253,  15.0941,  -9.4513],\n",
      "        [ 16.2980,  10.1033,  11.7993, -13.9658,  15.7145,  -9.7128],\n",
      "        [ 16.3144,  10.4927,  11.7683, -13.6176,  15.4666,  -9.9074],\n",
      "        [ 16.4729,   9.9824,  11.9692, -13.7601,  15.2233,  -9.2986],\n",
      "        [ 16.2668,  10.4314,  12.2325, -14.1717,  15.4529,  -9.7110],\n",
      "        [ 15.8173,   9.9378,  11.4056, -14.1870,  15.8375, -10.0576]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8757587671279907\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9573, 10.1789, 11.3188],\n",
      "        [15.8898, 10.3460, 11.9867],\n",
      "        [16.4591,  9.9927, 11.6037],\n",
      "        [16.6058, 10.1238, 11.5719],\n",
      "        [16.2460,  9.8254, 11.8376],\n",
      "        [16.3208, 10.2816, 11.6824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6956, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7936,  15.5659,  -9.7149],\n",
      "        [-14.2841,  15.7434,  -9.6922],\n",
      "        [-13.9414,  15.2955,  -9.5868],\n",
      "        [-13.8472,  15.2939,  -9.3767],\n",
      "        [-13.9616,  15.4983,  -9.7433],\n",
      "        [-13.4459,  15.3603,  -9.3175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9573,  10.1789,  11.3188, -13.7936,  15.5659,  -9.7149],\n",
      "        [ 15.8898,  10.3460,  11.9867, -14.2841,  15.7434,  -9.6922],\n",
      "        [ 16.4591,   9.9927,  11.6037, -13.9414,  15.2955,  -9.5868],\n",
      "        [ 16.6058,  10.1238,  11.5719, -13.8472,  15.2939,  -9.3767],\n",
      "        [ 16.2460,   9.8254,  11.8376, -13.9616,  15.4983,  -9.7433],\n",
      "        [ 16.3208,  10.2816,  11.6824, -13.4459,  15.3603,  -9.3175]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8736748695373535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3622, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0917, 10.1399, 11.8909],\n",
      "        [16.1862, 10.4918, 11.4956],\n",
      "        [16.5599, 10.4497, 11.9688],\n",
      "        [16.3352, 10.3776, 11.9433],\n",
      "        [16.0049, 10.3573, 11.6671],\n",
      "        [16.0828, 10.3520, 11.8062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7363,  15.3623,  -9.5532],\n",
      "        [-13.9981,  14.8736,  -9.5690],\n",
      "        [-13.8855,  15.2379,  -9.5335],\n",
      "        [-13.7526,  15.9461,  -9.7379],\n",
      "        [-14.1114,  15.5000,  -9.6817],\n",
      "        [-13.9184,  15.4928,  -9.7700]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0917,  10.1399,  11.8909, -13.7363,  15.3623,  -9.5532],\n",
      "        [ 16.1862,  10.4918,  11.4956, -13.9981,  14.8736,  -9.5690],\n",
      "        [ 16.5599,  10.4497,  11.9688, -13.8855,  15.2379,  -9.5335],\n",
      "        [ 16.3352,  10.3776,  11.9433, -13.7526,  15.9461,  -9.7379],\n",
      "        [ 16.0049,  10.3573,  11.6671, -14.1114,  15.5000,  -9.6817],\n",
      "        [ 16.0828,  10.3520,  11.8062, -13.9184,  15.4928,  -9.7700]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.8890444040298462\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.7310,  9.9611, 11.8666],\n",
      "        [15.9440,  9.8869, 11.8434],\n",
      "        [16.3223, 10.1687, 11.8580],\n",
      "        [15.9085, 10.2301, 11.4755],\n",
      "        [15.9568,  9.7734, 11.9912],\n",
      "        [15.9849, 10.5016, 11.7144]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.0681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3776,  16.0087,  -9.9923],\n",
      "        [-13.9570,  15.6388,  -9.6323],\n",
      "        [-13.9630,  15.1525,  -9.7748],\n",
      "        [-14.2727,  15.8405,  -9.6941],\n",
      "        [-13.7501,  15.0732,  -9.1585],\n",
      "        [-13.8973,  15.3897,  -9.8084]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.7310,   9.9611,  11.8666, -14.3776,  16.0087,  -9.9923],\n",
      "        [ 15.9440,   9.8869,  11.8434, -13.9570,  15.6388,  -9.6323],\n",
      "        [ 16.3223,  10.1687,  11.8580, -13.9630,  15.1525,  -9.7748],\n",
      "        [ 15.9085,  10.2301,  11.4755, -14.2727,  15.8405,  -9.6941],\n",
      "        [ 15.9568,   9.7734,  11.9912, -13.7501,  15.0732,  -9.1585],\n",
      "        [ 15.9849,  10.5016,  11.7144, -13.8973,  15.3897,  -9.8084]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9031336307525635\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1736, 10.0319, 11.9790],\n",
      "        [16.4099, 10.4082, 12.3199],\n",
      "        [16.0191,  9.9353, 11.9007],\n",
      "        [16.4261, 10.1566, 12.0366],\n",
      "        [16.4633, 10.8080, 11.9936],\n",
      "        [16.0467, 10.2360, 11.4138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.9031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0530,  15.3940,  -9.9411],\n",
      "        [-14.1225,  15.4394,  -9.6820],\n",
      "        [-13.8056,  15.3742, -10.0947],\n",
      "        [-13.7375,  15.4714,  -9.7193],\n",
      "        [-13.5917,  15.2606,  -9.6342],\n",
      "        [-13.9923,  15.4932,  -9.6939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1736,  10.0319,  11.9790, -14.0530,  15.3940,  -9.9411],\n",
      "        [ 16.4099,  10.4082,  12.3199, -14.1225,  15.4394,  -9.6820],\n",
      "        [ 16.0191,   9.9353,  11.9007, -13.8056,  15.3742, -10.0947],\n",
      "        [ 16.4261,  10.1566,  12.0366, -13.7375,  15.4714,  -9.7193],\n",
      "        [ 16.4633,  10.8080,  11.9936, -13.5917,  15.2606,  -9.6342],\n",
      "        [ 16.0467,  10.2360,  11.4138, -13.9923,  15.4932,  -9.6939]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9062657356262207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3887, 10.4977, 12.0451],\n",
      "        [16.3696, 10.3736, 11.8237],\n",
      "        [15.8796,  9.7915, 11.7427],\n",
      "        [16.3194, 10.1250, 12.0813],\n",
      "        [15.9318,  9.9724, 11.7229],\n",
      "        [16.1404, 10.0619, 11.6605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3640,  15.7988,  -9.7531],\n",
      "        [-13.7719,  15.3147,  -9.8458],\n",
      "        [-14.4662,  15.6893,  -9.8873],\n",
      "        [-13.8741,  15.2097,  -9.5177],\n",
      "        [-13.8215,  15.0770,  -9.3515],\n",
      "        [-14.1780,  15.7264,  -9.9073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3887,  10.4977,  12.0451, -14.3640,  15.7988,  -9.7531],\n",
      "        [ 16.3696,  10.3736,  11.8237, -13.7719,  15.3147,  -9.8458],\n",
      "        [ 15.8796,   9.7915,  11.7427, -14.4662,  15.6893,  -9.8873],\n",
      "        [ 16.3194,  10.1250,  12.0813, -13.8741,  15.2097,  -9.5177],\n",
      "        [ 15.9318,   9.9724,  11.7229, -13.8215,  15.0770,  -9.3515],\n",
      "        [ 16.1404,  10.0619,  11.6605, -14.1780,  15.7264,  -9.9073]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9390182495117188\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5839, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3573, 10.3329, 11.8195],\n",
      "        [16.0983, 10.4242, 11.9846],\n",
      "        [16.2146, 10.4094, 11.6716],\n",
      "        [16.0394, 10.5788, 11.2623],\n",
      "        [16.1634, 10.3165, 11.5398],\n",
      "        [16.6258, 10.1698, 11.9767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.6769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0637,  15.5313,  -9.7299],\n",
      "        [-14.2052,  15.2242,  -9.2009],\n",
      "        [-14.0058,  15.3840,  -9.9625],\n",
      "        [-13.9576,  15.4224,  -9.6219],\n",
      "        [-14.0634,  15.5840,  -9.5460],\n",
      "        [-14.0407,  15.6504,  -9.6839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3573,  10.3329,  11.8195, -14.0637,  15.5313,  -9.7299],\n",
      "        [ 16.0983,  10.4242,  11.9846, -14.2052,  15.2242,  -9.2009],\n",
      "        [ 16.2146,  10.4094,  11.6716, -14.0058,  15.3840,  -9.9625],\n",
      "        [ 16.0394,  10.5788,  11.2623, -13.9576,  15.4224,  -9.6219],\n",
      "        [ 16.1634,  10.3165,  11.5398, -14.0634,  15.5840,  -9.5460],\n",
      "        [ 16.6258,  10.1698,  11.9767, -14.0407,  15.6504,  -9.6839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.917117714881897\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5963, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2611, 10.4563, 11.6244],\n",
      "        [16.1171, 10.4372, 12.0714],\n",
      "        [16.1224,  9.8724, 11.4746],\n",
      "        [16.1499, 10.4768, 11.8439],\n",
      "        [16.1786, 10.3249, 12.0437],\n",
      "        [15.8290, 10.6724, 11.6104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1862,  15.6615,  -9.6329],\n",
      "        [-13.7956,  15.4708,  -9.6587],\n",
      "        [-13.7307,  15.0407,  -9.2753],\n",
      "        [-14.1081,  15.5827,  -9.7791],\n",
      "        [-13.8226,  15.4530,  -9.6972],\n",
      "        [-14.0866,  15.6853,  -9.7600]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2611,  10.4563,  11.6244, -14.1862,  15.6615,  -9.6329],\n",
      "        [ 16.1171,  10.4372,  12.0714, -13.7956,  15.4708,  -9.6587],\n",
      "        [ 16.1224,   9.8724,  11.4746, -13.7307,  15.0407,  -9.2753],\n",
      "        [ 16.1499,  10.4768,  11.8439, -14.1081,  15.5827,  -9.7791],\n",
      "        [ 16.1786,  10.3249,  12.0437, -13.8226,  15.4530,  -9.6972],\n",
      "        [ 15.8290,  10.6724,  11.6104, -14.0866,  15.6853,  -9.7600]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9148211479187012\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5654, 10.3214, 12.0658],\n",
      "        [16.6634, 10.5660, 12.2034],\n",
      "        [16.4226, 10.3391, 11.9172],\n",
      "        [16.0166, 10.4115, 11.4724],\n",
      "        [17.0303, 10.7271, 12.3797],\n",
      "        [16.4072, 10.4975, 12.3159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5710, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2215,  15.3669,  -9.1874],\n",
      "        [-14.0034,  15.5435,  -9.8032],\n",
      "        [-13.8109,  15.3278,  -9.6711],\n",
      "        [-13.8282,  15.7577,  -9.6494],\n",
      "        [-14.0170,  15.6032,  -9.7650],\n",
      "        [-13.9625,  15.5303,  -9.8450]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5654,  10.3214,  12.0658, -14.2215,  15.3669,  -9.1874],\n",
      "        [ 16.6634,  10.5660,  12.2034, -14.0034,  15.5435,  -9.8032],\n",
      "        [ 16.4226,  10.3391,  11.9172, -13.8109,  15.3278,  -9.6711],\n",
      "        [ 16.0166,  10.4115,  11.4724, -13.8282,  15.7577,  -9.6494],\n",
      "        [ 17.0303,  10.7271,  12.3797, -14.0170,  15.6032,  -9.7650],\n",
      "        [ 16.4072,  10.4975,  12.3159, -13.9625,  15.5303,  -9.8450]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9276068210601807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4845, 10.2508, 11.7445],\n",
      "        [15.8403, 10.0840, 11.7749],\n",
      "        [16.4900, 10.6485, 12.2102],\n",
      "        [16.1927, 10.3705, 11.5863],\n",
      "        [16.5006, 10.3653, 12.3455],\n",
      "        [16.3200, 10.5324, 11.7041]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5450, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9628,  15.7584,  -9.9744],\n",
      "        [-13.9207,  15.4394,  -9.6038],\n",
      "        [-13.4575,  15.4199,  -9.7727],\n",
      "        [-13.8527,  15.2859,  -9.7814],\n",
      "        [-13.9893,  15.7690,  -9.8859],\n",
      "        [-13.9535,  15.3580,  -9.3632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4845,  10.2508,  11.7445, -13.9628,  15.7584,  -9.9744],\n",
      "        [ 15.8403,  10.0840,  11.7749, -13.9207,  15.4394,  -9.6038],\n",
      "        [ 16.4900,  10.6485,  12.2102, -13.4575,  15.4199,  -9.7727],\n",
      "        [ 16.1927,  10.3705,  11.5863, -13.8527,  15.2859,  -9.7814],\n",
      "        [ 16.5006,  10.3653,  12.3455, -13.9893,  15.7690,  -9.8859],\n",
      "        [ 16.3200,  10.5324,  11.7041, -13.9535,  15.3580,  -9.3632]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9273159503936768\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4054, 10.4645, 11.7333],\n",
      "        [16.1448,  9.7615, 11.5994],\n",
      "        [16.2958, 10.4643, 12.0246],\n",
      "        [16.2905, 10.5636, 11.7548],\n",
      "        [16.3074, 10.1141, 11.7860],\n",
      "        [16.2419, 10.8672, 11.7971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0860,  15.7433, -10.0304],\n",
      "        [-14.2039,  15.4519,  -9.8535],\n",
      "        [-13.8700,  15.4532,  -9.6551],\n",
      "        [-13.6336,  15.6954,  -9.8106],\n",
      "        [-13.8501,  15.7592,  -9.5522],\n",
      "        [-14.0903,  15.3370,  -9.8266]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4054,  10.4645,  11.7333, -14.0860,  15.7433, -10.0304],\n",
      "        [ 16.1448,   9.7615,  11.5994, -14.2039,  15.4519,  -9.8535],\n",
      "        [ 16.2958,  10.4643,  12.0246, -13.8700,  15.4532,  -9.6551],\n",
      "        [ 16.2905,  10.5636,  11.7548, -13.6336,  15.6954,  -9.8106],\n",
      "        [ 16.3074,  10.1141,  11.7860, -13.8501,  15.7592,  -9.5522],\n",
      "        [ 16.2419,  10.8672,  11.7971, -14.0903,  15.3370,  -9.8266]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9316637516021729\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6978, 10.6038, 12.0136],\n",
      "        [16.3315, 10.1252, 12.3341],\n",
      "        [15.9511, 10.1680, 11.8692],\n",
      "        [16.7699, 10.2514, 12.3592],\n",
      "        [16.2061, 10.3431, 12.1382],\n",
      "        [16.6004, 10.6090, 12.3562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.3742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8336,  14.8758,  -8.8513],\n",
      "        [-13.9980,  15.5726,  -9.8016],\n",
      "        [-14.1059,  15.1269,  -9.7775],\n",
      "        [-13.9451,  15.4132,  -9.9024],\n",
      "        [-14.1754,  15.5153,  -9.9376],\n",
      "        [-13.7748,  15.4789,  -9.4893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6978,  10.6038,  12.0136, -13.8336,  14.8758,  -8.8513],\n",
      "        [ 16.3315,  10.1252,  12.3341, -13.9980,  15.5726,  -9.8016],\n",
      "        [ 15.9511,  10.1680,  11.8692, -14.1059,  15.1269,  -9.7775],\n",
      "        [ 16.7699,  10.2514,  12.3592, -13.9451,  15.4132,  -9.9024],\n",
      "        [ 16.2061,  10.3431,  12.1382, -14.1754,  15.5153,  -9.9376],\n",
      "        [ 16.6004,  10.6090,  12.3562, -13.7748,  15.4789,  -9.4893]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9175994396209717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4087, 10.3244, 12.1057],\n",
      "        [16.2570, 10.2755, 11.6756],\n",
      "        [16.3811, 10.3530, 11.8855],\n",
      "        [16.3226, 10.4309, 12.0242],\n",
      "        [16.4179, 10.6101, 12.0787],\n",
      "        [16.2308, 10.2803, 11.8943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8999,  15.4274,  -9.6280],\n",
      "        [-13.9805,  15.5686,  -9.7657],\n",
      "        [-14.2004,  15.3011,  -9.9712],\n",
      "        [-14.2939,  15.5426,  -9.7877],\n",
      "        [-14.1740,  15.9061,  -9.7551],\n",
      "        [-14.1012,  15.7893,  -9.7167]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4087,  10.3244,  12.1057, -13.8999,  15.4274,  -9.6280],\n",
      "        [ 16.2570,  10.2755,  11.6756, -13.9805,  15.5686,  -9.7657],\n",
      "        [ 16.3811,  10.3530,  11.8855, -14.2004,  15.3011,  -9.9712],\n",
      "        [ 16.3226,  10.4309,  12.0242, -14.2939,  15.5426,  -9.7877],\n",
      "        [ 16.4179,  10.6101,  12.0787, -14.1740,  15.9061,  -9.7551],\n",
      "        [ 16.2308,  10.2803,  11.8943, -14.1012,  15.7893,  -9.7167]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9272027015686035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6614, 10.5696, 11.7697],\n",
      "        [16.6582, 10.4253, 12.0119],\n",
      "        [16.0796,  9.9758, 11.7059],\n",
      "        [16.5159, 10.3113, 11.7806],\n",
      "        [16.6452, 10.5700, 11.9683],\n",
      "        [16.1136, 10.0312, 12.1521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2178,  15.4164,  -9.7427],\n",
      "        [-13.9655,  15.4949,  -9.5669],\n",
      "        [-13.8893,  15.4210,  -9.3975],\n",
      "        [-13.8393,  15.6278,  -9.6719],\n",
      "        [-13.8575,  15.4661,  -9.5055],\n",
      "        [-14.0271,  15.1978, -10.2542]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6614,  10.5696,  11.7697, -14.2178,  15.4164,  -9.7427],\n",
      "        [ 16.6582,  10.4253,  12.0119, -13.9655,  15.4949,  -9.5669],\n",
      "        [ 16.0796,   9.9758,  11.7059, -13.8893,  15.4210,  -9.3975],\n",
      "        [ 16.5159,  10.3113,  11.7806, -13.8393,  15.6278,  -9.6719],\n",
      "        [ 16.6452,  10.5700,  11.9683, -13.8575,  15.4661,  -9.5055],\n",
      "        [ 16.1136,  10.0312,  12.1521, -14.0271,  15.1978, -10.2542]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9400086402893066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5416, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[15.9897, 10.3407, 12.0007],\n",
      "        [16.1799, 10.1844, 11.8635],\n",
      "        [16.9286, 10.5099, 12.1333],\n",
      "        [16.4284, 10.3766, 11.8144],\n",
      "        [16.4694, 10.6146, 11.9793],\n",
      "        [16.4508, 10.3513, 11.8672]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.0791, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9294,  15.5632,  -9.4661],\n",
      "        [-13.9287,  15.6874,  -9.6334],\n",
      "        [-14.6295,  15.8561, -10.0533],\n",
      "        [-14.2394,  15.5300,  -9.9198],\n",
      "        [-14.2475,  15.6002,  -9.6867],\n",
      "        [-14.3541,  15.5769,  -9.6648]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 15.9897,  10.3407,  12.0007, -13.9294,  15.5632,  -9.4661],\n",
      "        [ 16.1799,  10.1844,  11.8635, -13.9287,  15.6874,  -9.6334],\n",
      "        [ 16.9286,  10.5099,  12.1333, -14.6295,  15.8561, -10.0533],\n",
      "        [ 16.4284,  10.3766,  11.8144, -14.2394,  15.5300,  -9.9198],\n",
      "        [ 16.4694,  10.6146,  11.9793, -14.2475,  15.6002,  -9.6867],\n",
      "        [ 16.4508,  10.3513,  11.8672, -14.3541,  15.5769,  -9.6648]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.911388635635376\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8364, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8475, 10.7052, 12.2396],\n",
      "        [16.5724, 10.7105, 11.8404],\n",
      "        [16.0240, 10.3813, 11.7500],\n",
      "        [16.3470, 10.4158, 12.1998],\n",
      "        [16.5282, 10.3277, 12.0454],\n",
      "        [16.1348, 10.1016, 11.6299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.7153,  15.1933,  -9.4663],\n",
      "        [-14.0549,  15.6146,  -9.8837],\n",
      "        [-14.3996,  15.6149,  -9.8960],\n",
      "        [-14.1428,  15.5846,  -9.6220],\n",
      "        [-13.9883,  15.2898,  -9.5567],\n",
      "        [-14.2011,  15.6033,  -9.9312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8475,  10.7052,  12.2396, -13.7153,  15.1933,  -9.4663],\n",
      "        [ 16.5724,  10.7105,  11.8404, -14.0549,  15.6146,  -9.8837],\n",
      "        [ 16.0240,  10.3813,  11.7500, -14.3996,  15.6149,  -9.8960],\n",
      "        [ 16.3470,  10.4158,  12.1998, -14.1428,  15.5846,  -9.6220],\n",
      "        [ 16.5282,  10.3277,  12.0454, -13.9883,  15.2898,  -9.5567],\n",
      "        [ 16.1348,  10.1016,  11.6299, -14.2011,  15.6033,  -9.9312]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9483704566955566\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4572, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3209, 10.4726, 12.0074],\n",
      "        [16.3078, 10.3074, 12.0750],\n",
      "        [16.4413, 10.3226, 11.7122],\n",
      "        [15.9641, 10.0292, 11.8410],\n",
      "        [16.3189, 10.5792, 12.4393],\n",
      "        [16.5905, 10.3813, 12.1470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0590, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9420,  15.6089, -10.0517],\n",
      "        [-14.0530,  15.6025,  -9.8427],\n",
      "        [-13.8757,  15.7035,  -9.9309],\n",
      "        [-14.6848,  15.9740,  -9.8823],\n",
      "        [-14.5175,  15.9715,  -9.8867],\n",
      "        [-14.1657,  15.5550, -10.0151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3209,  10.4726,  12.0074, -13.9420,  15.6089, -10.0517],\n",
      "        [ 16.3078,  10.3074,  12.0750, -14.0530,  15.6025,  -9.8427],\n",
      "        [ 16.4413,  10.3226,  11.7122, -13.8757,  15.7035,  -9.9309],\n",
      "        [ 15.9641,  10.0292,  11.8410, -14.6848,  15.9740,  -9.8823],\n",
      "        [ 16.3189,  10.5792,  12.4393, -14.5175,  15.9715,  -9.8867],\n",
      "        [ 16.5905,  10.3813,  12.1470, -14.1657,  15.5550, -10.0151]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.93756103515625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4613, 10.5232, 12.0893],\n",
      "        [16.0209, 10.3756, 12.0372],\n",
      "        [16.6143, 10.7112, 12.0552],\n",
      "        [16.6812, 10.3151, 11.8151],\n",
      "        [16.3904,  9.9916, 12.2687],\n",
      "        [15.8818, 10.1176, 11.7240]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.0228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.6366,  15.6773,  -9.7676],\n",
      "        [-14.0083,  15.8593,  -9.8184],\n",
      "        [-14.2341,  15.8807,  -9.8556],\n",
      "        [-13.8611,  15.6214,  -9.7477],\n",
      "        [-14.2853,  15.6796,  -9.8160],\n",
      "        [-13.9555,  15.3068, -10.0554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4613,  10.5232,  12.0893, -13.6366,  15.6773,  -9.7676],\n",
      "        [ 16.0209,  10.3756,  12.0372, -14.0083,  15.8593,  -9.8184],\n",
      "        [ 16.6143,  10.7112,  12.0552, -14.2341,  15.8807,  -9.8556],\n",
      "        [ 16.6812,  10.3151,  11.8151, -13.8611,  15.6214,  -9.7477],\n",
      "        [ 16.3904,   9.9916,  12.2687, -14.2853,  15.6796,  -9.8160],\n",
      "        [ 15.8818,  10.1176,  11.7240, -13.9555,  15.3068, -10.0554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9397635459899902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7071, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0233, 10.2549, 12.3046],\n",
      "        [16.1102, 10.0948, 12.0014],\n",
      "        [16.6894, 10.5674, 11.9337],\n",
      "        [15.8083, 10.3753, 12.1596],\n",
      "        [16.6181, 10.5131, 12.0078],\n",
      "        [16.1310,  9.8729, 12.0046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0552,  15.7768,  -9.6986],\n",
      "        [-14.2121,  15.5343,  -9.9264],\n",
      "        [-14.3659,  15.8959,  -9.9350],\n",
      "        [-14.5344,  15.6295, -10.2352],\n",
      "        [-14.5369,  15.7777,  -9.8130],\n",
      "        [-13.9989,  15.5554,  -9.6893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0233,  10.2549,  12.3046, -14.0552,  15.7768,  -9.6986],\n",
      "        [ 16.1102,  10.0948,  12.0014, -14.2121,  15.5343,  -9.9264],\n",
      "        [ 16.6894,  10.5674,  11.9337, -14.3659,  15.8959,  -9.9350],\n",
      "        [ 15.8083,  10.3753,  12.1596, -14.5344,  15.6295, -10.2352],\n",
      "        [ 16.6181,  10.5131,  12.0078, -14.5369,  15.7777,  -9.8130],\n",
      "        [ 16.1310,   9.8729,  12.0046, -13.9989,  15.5554,  -9.6893]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9342628717422485\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7532, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3177, 10.1089, 11.7019],\n",
      "        [16.4089, 10.5211, 12.2618],\n",
      "        [16.5788,  9.9770, 12.3514],\n",
      "        [16.1999, 10.3919, 12.0796],\n",
      "        [16.4836, 10.9310, 12.0122],\n",
      "        [16.1945, 10.1012, 11.8558]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.0940, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2984,  15.4523,  -9.8969],\n",
      "        [-13.8931,  15.3981,  -9.5625],\n",
      "        [-14.4485,  15.4260,  -9.9527],\n",
      "        [-14.1396,  15.4147,  -9.6929],\n",
      "        [-13.8948,  15.5022,  -9.5966],\n",
      "        [-14.1205,  15.6655, -10.0162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3177,  10.1089,  11.7019, -14.2984,  15.4523,  -9.8969],\n",
      "        [ 16.4089,  10.5211,  12.2618, -13.8931,  15.3981,  -9.5625],\n",
      "        [ 16.5788,   9.9770,  12.3514, -14.4485,  15.4260,  -9.9527],\n",
      "        [ 16.1999,  10.3919,  12.0796, -14.1396,  15.4147,  -9.6929],\n",
      "        [ 16.4836,  10.9310,  12.0122, -13.8948,  15.5022,  -9.5966],\n",
      "        [ 16.1945,  10.1012,  11.8558, -14.1205,  15.6655, -10.0162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.925984501838684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4743, 10.6771, 12.1563],\n",
      "        [16.1831, 10.9359, 12.0054],\n",
      "        [15.9671, 10.3900, 11.9975],\n",
      "        [16.5825, 10.8887, 12.0942],\n",
      "        [16.3003, 10.6357, 12.1528],\n",
      "        [16.1386, 10.6124, 12.1086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8979,  15.7423, -10.0021],\n",
      "        [-14.2663,  15.3029,  -9.7571],\n",
      "        [-14.4058,  15.7155,  -9.7949],\n",
      "        [-13.8877,  15.3010,  -9.8105],\n",
      "        [-14.2296,  15.5134, -10.1393],\n",
      "        [-14.5446,  16.0654,  -9.7831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4743,  10.6771,  12.1563, -13.8979,  15.7423, -10.0021],\n",
      "        [ 16.1831,  10.9359,  12.0054, -14.2663,  15.3029,  -9.7571],\n",
      "        [ 15.9671,  10.3900,  11.9975, -14.4058,  15.7155,  -9.7949],\n",
      "        [ 16.5825,  10.8887,  12.0942, -13.8877,  15.3010,  -9.8105],\n",
      "        [ 16.3003,  10.6357,  12.1528, -14.2296,  15.5134, -10.1393],\n",
      "        [ 16.1386,  10.6124,  12.1086, -14.5446,  16.0654,  -9.7831]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9576648473739624\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5895, 10.2650, 12.0454],\n",
      "        [16.6389, 10.7170, 12.2812],\n",
      "        [16.6098, 10.4225, 11.9384],\n",
      "        [16.5705, 10.3686, 11.8631],\n",
      "        [16.4778, 10.2980, 12.1943],\n",
      "        [16.5221, 10.4952, 12.3139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.1407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3098,  15.7235,  -9.9053],\n",
      "        [-14.3384,  15.8883, -10.0686],\n",
      "        [-14.0019,  15.9252,  -9.9297],\n",
      "        [-14.2321,  15.6879, -10.0166],\n",
      "        [-13.8983,  15.7423,  -9.5772],\n",
      "        [-13.8074,  15.6402,  -9.4898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5895,  10.2650,  12.0454, -14.3098,  15.7235,  -9.9053],\n",
      "        [ 16.6389,  10.7170,  12.2812, -14.3384,  15.8883, -10.0686],\n",
      "        [ 16.6098,  10.4225,  11.9384, -14.0019,  15.9252,  -9.9297],\n",
      "        [ 16.5705,  10.3686,  11.8631, -14.2321,  15.6879, -10.0166],\n",
      "        [ 16.4778,  10.2980,  12.1943, -13.8983,  15.7423,  -9.5772],\n",
      "        [ 16.5221,  10.4952,  12.3139, -13.8074,  15.6402,  -9.4898]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9584386348724365\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6993, 10.3955, 12.1416],\n",
      "        [16.3312, 10.6582, 12.0984],\n",
      "        [16.4332, 10.7632, 12.0602],\n",
      "        [15.9173, 10.5144, 12.2574],\n",
      "        [16.7506, 10.5576, 11.8048],\n",
      "        [16.5385, 10.8422, 12.0328]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2707, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1402,  15.6495, -10.0861],\n",
      "        [-14.1585,  15.7317,  -9.9219],\n",
      "        [-14.4642,  15.4269, -10.1139],\n",
      "        [-14.4025,  16.0248, -10.0265],\n",
      "        [-14.0746,  15.9016,  -9.6546],\n",
      "        [-14.2735,  15.4874, -10.0406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6993,  10.3955,  12.1416, -14.1402,  15.6495, -10.0861],\n",
      "        [ 16.3312,  10.6582,  12.0984, -14.1585,  15.7317,  -9.9219],\n",
      "        [ 16.4332,  10.7632,  12.0602, -14.4642,  15.4269, -10.1139],\n",
      "        [ 15.9173,  10.5144,  12.2574, -14.4025,  16.0248, -10.0265],\n",
      "        [ 16.7506,  10.5576,  11.8048, -14.0746,  15.9016,  -9.6546],\n",
      "        [ 16.5385,  10.8422,  12.0328, -14.2735,  15.4874, -10.0406]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.966551661491394\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8921, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.1487, 10.6225, 12.0777],\n",
      "        [16.5860, 10.4924, 12.3746],\n",
      "        [16.4987, 10.6194, 12.0267],\n",
      "        [16.3502, 10.2101, 12.3192],\n",
      "        [16.4551, 10.5102, 12.2358],\n",
      "        [16.2696, 10.5866, 11.8991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.6149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9827,  15.5089,  -9.6834],\n",
      "        [-14.4347,  15.7811,  -9.9585],\n",
      "        [-14.2265,  15.9692, -10.0805],\n",
      "        [-14.2575,  15.6062, -10.2075],\n",
      "        [-14.0215,  15.7271, -10.0041],\n",
      "        [-13.3478,  15.0220,  -9.3769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.1487,  10.6225,  12.0777, -13.9827,  15.5089,  -9.6834],\n",
      "        [ 16.5860,  10.4924,  12.3746, -14.4347,  15.7811,  -9.9585],\n",
      "        [ 16.4987,  10.6194,  12.0267, -14.2265,  15.9692, -10.0805],\n",
      "        [ 16.3502,  10.2101,  12.3192, -14.2575,  15.6062, -10.2075],\n",
      "        [ 16.4551,  10.5102,  12.2358, -14.0215,  15.7271, -10.0041],\n",
      "        [ 16.2696,  10.5866,  11.8991, -13.3478,  15.0220,  -9.3769]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9371434450149536\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6536, 10.4861, 12.0595],\n",
      "        [16.7884, 10.5355, 11.9604],\n",
      "        [16.9086, 10.3994, 12.3278],\n",
      "        [16.5324, 10.6304, 12.1804],\n",
      "        [16.3247,  9.8309, 11.9523],\n",
      "        [16.4250, 10.6207, 11.7192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0326, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5769,  15.3959,  -9.8173],\n",
      "        [-14.7249,  15.6065, -10.1198],\n",
      "        [-14.0216,  15.4268, -10.1651],\n",
      "        [-14.2094,  15.5210,  -9.8846],\n",
      "        [-14.5996,  15.8622,  -9.8153],\n",
      "        [-13.9467,  15.4832,  -9.5635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6536,  10.4861,  12.0595, -14.5769,  15.3959,  -9.8173],\n",
      "        [ 16.7884,  10.5355,  11.9604, -14.7249,  15.6065, -10.1198],\n",
      "        [ 16.9086,  10.3994,  12.3278, -14.0216,  15.4268, -10.1651],\n",
      "        [ 16.5324,  10.6304,  12.1804, -14.2094,  15.5210,  -9.8846],\n",
      "        [ 16.3247,   9.8309,  11.9523, -14.5996,  15.8622,  -9.8153],\n",
      "        [ 16.4250,  10.6207,  11.7192, -13.9467,  15.4832,  -9.5635]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.965749979019165\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7812, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3039, 10.3399, 11.9205],\n",
      "        [16.5427, 10.5791, 12.1211],\n",
      "        [16.5791, 10.6943, 11.9424],\n",
      "        [16.5732, 10.3832, 12.2055],\n",
      "        [16.2596, 10.4490, 12.0658],\n",
      "        [16.3244, 10.5040, 11.6534]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.9547,  15.7499,  -9.8349],\n",
      "        [-13.9556,  15.2281,  -9.7243],\n",
      "        [-13.8443,  15.7491, -10.0058],\n",
      "        [-13.6450,  15.7175,  -9.8598],\n",
      "        [-13.9986,  15.3274,  -9.6083],\n",
      "        [-14.3769,  15.9776,  -9.8568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3039,  10.3399,  11.9205, -13.9547,  15.7499,  -9.8349],\n",
      "        [ 16.5427,  10.5791,  12.1211, -13.9556,  15.2281,  -9.7243],\n",
      "        [ 16.5791,  10.6943,  11.9424, -13.8443,  15.7491, -10.0058],\n",
      "        [ 16.5732,  10.3832,  12.2055, -13.6450,  15.7175,  -9.8598],\n",
      "        [ 16.2596,  10.4490,  12.0658, -13.9986,  15.3274,  -9.6083],\n",
      "        [ 16.3244,  10.5040,  11.6534, -14.3769,  15.9776,  -9.8568]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9417545795440674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0190, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3281, 10.5861, 12.4951],\n",
      "        [16.0684, 10.4374, 12.0023],\n",
      "        [16.2026, 10.5624, 12.2454],\n",
      "        [16.0737,  9.9857, 12.0115],\n",
      "        [16.3439, 10.2419, 12.0939],\n",
      "        [16.4266, 10.3613, 11.9681]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.7754, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2591,  15.6212,  -9.9318],\n",
      "        [-13.9496,  15.4631, -10.0264],\n",
      "        [-14.1348,  15.4293,  -9.5051],\n",
      "        [-14.2632,  15.8311,  -9.7183],\n",
      "        [-13.9871,  15.6122, -10.2434],\n",
      "        [-14.4096,  16.0477, -10.3429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3281,  10.5861,  12.4951, -14.2591,  15.6212,  -9.9318],\n",
      "        [ 16.0684,  10.4374,  12.0023, -13.9496,  15.4631, -10.0264],\n",
      "        [ 16.2026,  10.5624,  12.2454, -14.1348,  15.4293,  -9.5051],\n",
      "        [ 16.0737,   9.9857,  12.0115, -14.2632,  15.8311,  -9.7183],\n",
      "        [ 16.3439,  10.2419,  12.0939, -13.9871,  15.6122, -10.2434],\n",
      "        [ 16.4266,  10.3613,  11.9681, -14.4096,  16.0477, -10.3429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9702035188674927\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3611, 10.7219, 12.1328],\n",
      "        [16.1803, 10.1136, 12.0468],\n",
      "        [16.2720, 10.4218, 11.9004],\n",
      "        [16.6728, 10.6692, 12.0985],\n",
      "        [16.2559, 10.2046, 12.0350],\n",
      "        [16.8166, 10.6261, 12.3066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3993, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3280,  15.7297,  -9.9525],\n",
      "        [-14.0943,  15.8609, -10.0891],\n",
      "        [-13.9344,  15.7708,  -9.9607],\n",
      "        [-14.3223,  15.7892,  -9.9793],\n",
      "        [-13.9354,  15.4239, -10.1418],\n",
      "        [-14.1878,  15.4274,  -9.8601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3611,  10.7219,  12.1328, -14.3280,  15.7297,  -9.9525],\n",
      "        [ 16.1803,  10.1136,  12.0468, -14.0943,  15.8609, -10.0891],\n",
      "        [ 16.2720,  10.4218,  11.9004, -13.9344,  15.7708,  -9.9607],\n",
      "        [ 16.6728,  10.6692,  12.0985, -14.3223,  15.7892,  -9.9793],\n",
      "        [ 16.2559,  10.2046,  12.0350, -13.9354,  15.4239, -10.1418],\n",
      "        [ 16.8166,  10.6261,  12.3066, -14.1878,  15.4274,  -9.8601]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9681316614151\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7808, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5583, 10.7646, 11.9152],\n",
      "        [16.2028, 10.7271, 11.9690],\n",
      "        [16.3016, 10.6768, 11.8993],\n",
      "        [16.5982, 10.5766, 12.1691],\n",
      "        [16.0741, 10.5399, 12.3249],\n",
      "        [16.4788, 10.3879, 11.9517]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3369, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2399,  15.7028,  -9.8784],\n",
      "        [-14.4639,  15.6085,  -9.8635],\n",
      "        [-14.6628,  15.7315, -10.2288],\n",
      "        [-14.0108,  15.5818,  -9.9426],\n",
      "        [-13.8313,  15.7499,  -9.8154],\n",
      "        [-14.6875,  15.7664, -10.1393]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5583,  10.7646,  11.9152, -14.2399,  15.7028,  -9.8784],\n",
      "        [ 16.2028,  10.7271,  11.9690, -14.4639,  15.6085,  -9.8635],\n",
      "        [ 16.3016,  10.6768,  11.8993, -14.6628,  15.7315, -10.2288],\n",
      "        [ 16.5982,  10.5766,  12.1691, -14.0108,  15.5818,  -9.9426],\n",
      "        [ 16.0741,  10.5399,  12.3249, -13.8313,  15.7499,  -9.8154],\n",
      "        [ 16.4788,  10.3879,  11.9517, -14.6875,  15.7664, -10.1393]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.968022108078003\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2239, 10.6795, 11.9548],\n",
      "        [16.4853, 10.3440, 12.0893],\n",
      "        [16.7055, 10.8469, 12.2361],\n",
      "        [16.2522, 10.0478, 12.0608],\n",
      "        [16.2938, 10.8755, 11.9946],\n",
      "        [16.4930, 10.7053, 11.8439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9515, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3511,  15.9347, -10.1131],\n",
      "        [-14.4466,  15.5262, -10.0175],\n",
      "        [-14.5657,  16.2084, -10.2538],\n",
      "        [-14.1319,  15.2598,  -9.7904],\n",
      "        [-14.2922,  15.7198, -10.1617],\n",
      "        [-14.4431,  15.8894, -10.5012]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2239,  10.6795,  11.9548, -14.3511,  15.9347, -10.1131],\n",
      "        [ 16.4853,  10.3440,  12.0893, -14.4466,  15.5262, -10.0175],\n",
      "        [ 16.7055,  10.8469,  12.2361, -14.5657,  16.2084, -10.2538],\n",
      "        [ 16.2522,  10.0478,  12.0608, -14.1319,  15.2598,  -9.7904],\n",
      "        [ 16.2938,  10.8755,  11.9946, -14.2922,  15.7198, -10.1617],\n",
      "        [ 16.4930,  10.7053,  11.8439, -14.4431,  15.8894, -10.5012]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9654581546783447\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3454, 10.1578, 12.0396],\n",
      "        [16.1352, 10.3955, 11.9560],\n",
      "        [16.4843, 10.4878, 12.3771],\n",
      "        [16.3295, 10.3579, 12.1924],\n",
      "        [16.6559, 10.5220, 12.4767],\n",
      "        [16.1260, 10.8081, 12.2439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.1659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-13.8765,  15.5317,  -9.8701],\n",
      "        [-14.0916,  15.7038,  -9.7181],\n",
      "        [-14.4404,  15.6113, -10.1391],\n",
      "        [-14.1746,  15.5411, -10.0268],\n",
      "        [-14.2715,  15.7502,  -9.8599],\n",
      "        [-13.7763,  15.4683,  -9.9946]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3454,  10.1578,  12.0396, -13.8765,  15.5317,  -9.8701],\n",
      "        [ 16.1352,  10.3955,  11.9560, -14.0916,  15.7038,  -9.7181],\n",
      "        [ 16.4843,  10.4878,  12.3771, -14.4404,  15.6113, -10.1391],\n",
      "        [ 16.3295,  10.3579,  12.1924, -14.1746,  15.5411, -10.0268],\n",
      "        [ 16.6559,  10.5220,  12.4767, -14.2715,  15.7502,  -9.8599],\n",
      "        [ 16.1260,  10.8081,  12.2439, -13.7763,  15.4683,  -9.9946]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9428402185440063\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5056, 10.6431, 12.2526],\n",
      "        [16.5469, 10.5792, 11.9446],\n",
      "        [16.4731, 10.4019, 12.2114],\n",
      "        [16.6764, 10.2055, 12.1251],\n",
      "        [16.7841, 10.9751, 12.1124],\n",
      "        [16.4289, 10.3846, 12.2735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.8897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3543,  15.7058,  -9.8942],\n",
      "        [-14.2547,  15.4101,  -9.6718],\n",
      "        [-14.2027,  15.6574, -10.0681],\n",
      "        [-14.2132,  15.4348,  -9.7572],\n",
      "        [-14.5952,  15.7661, -10.2067],\n",
      "        [-13.9252,  15.7391,  -9.9646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5056,  10.6431,  12.2526, -14.3543,  15.7058,  -9.8942],\n",
      "        [ 16.5469,  10.5792,  11.9446, -14.2547,  15.4101,  -9.6718],\n",
      "        [ 16.4731,  10.4019,  12.2114, -14.2027,  15.6574, -10.0681],\n",
      "        [ 16.6764,  10.2055,  12.1251, -14.2132,  15.4348,  -9.7572],\n",
      "        [ 16.7841,  10.9751,  12.1124, -14.5952,  15.7661, -10.2067],\n",
      "        [ 16.4289,  10.3846,  12.2735, -13.9252,  15.7391,  -9.9646]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9794895648956299\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5112, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6158, 10.5609, 12.1483],\n",
      "        [16.9305, 10.7593, 12.3810],\n",
      "        [16.6496, 10.7426, 12.2117],\n",
      "        [16.6194, 10.4821, 12.1931],\n",
      "        [16.2892, 10.6529, 12.1709],\n",
      "        [16.1501,  9.7978, 11.9642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4965, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2444,  15.6989,  -9.7115],\n",
      "        [-14.5925,  15.6901, -10.1768],\n",
      "        [-13.9478,  15.1051,  -9.4419],\n",
      "        [-14.3133,  15.5788, -10.0403],\n",
      "        [-14.4834,  15.7601, -10.5538],\n",
      "        [-14.3825,  15.3605,  -9.9343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6158,  10.5609,  12.1483, -14.2444,  15.6989,  -9.7115],\n",
      "        [ 16.9305,  10.7593,  12.3810, -14.5925,  15.6901, -10.1768],\n",
      "        [ 16.6496,  10.7426,  12.2117, -13.9478,  15.1051,  -9.4419],\n",
      "        [ 16.6194,  10.4821,  12.1931, -14.3133,  15.5788, -10.0403],\n",
      "        [ 16.2892,  10.6529,  12.1709, -14.4834,  15.7601, -10.5538],\n",
      "        [ 16.1501,   9.7978,  11.9642, -14.3825,  15.3605,  -9.9343]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9756301641464233\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5063, 10.4107, 11.8028],\n",
      "        [16.6621, 10.7982, 11.9394],\n",
      "        [16.2902, 10.6682, 12.1365],\n",
      "        [16.5125, 10.9525, 12.2610],\n",
      "        [16.6040, 10.6605, 12.2723],\n",
      "        [16.6629, 10.7933, 12.4345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.0944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3859,  15.9169,  -9.8994],\n",
      "        [-14.3463,  15.8191, -10.2501],\n",
      "        [-14.2102,  16.1197, -10.0088],\n",
      "        [-14.3780,  16.0498, -10.2442],\n",
      "        [-14.1654,  15.6296,  -9.8599],\n",
      "        [-14.4093,  15.6886,  -9.8634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5063,  10.4107,  11.8028, -14.3859,  15.9169,  -9.8994],\n",
      "        [ 16.6621,  10.7982,  11.9394, -14.3463,  15.8191, -10.2501],\n",
      "        [ 16.2902,  10.6682,  12.1365, -14.2102,  16.1197, -10.0088],\n",
      "        [ 16.5125,  10.9525,  12.2610, -14.3780,  16.0498, -10.2442],\n",
      "        [ 16.6040,  10.6605,  12.2723, -14.1654,  15.6296,  -9.8599],\n",
      "        [ 16.6629,  10.7933,  12.4345, -14.4093,  15.6886,  -9.8634]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9687561988830566\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4591, 10.3314, 11.9020],\n",
      "        [16.5702, 10.6457, 11.9149],\n",
      "        [16.5914, 10.5617, 12.0136],\n",
      "        [16.4467, 10.8059, 12.1120],\n",
      "        [16.5133, 10.6414, 12.2993],\n",
      "        [16.2976, 10.5756, 12.1293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2736, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0031,  15.4223,  -9.6988],\n",
      "        [-14.2031,  15.6296,  -9.6338],\n",
      "        [-14.0534,  15.3218,  -9.8262],\n",
      "        [-14.2965,  15.7389,  -9.9964],\n",
      "        [-14.0881,  15.7141, -10.0330],\n",
      "        [-14.1383,  16.2711, -10.0770]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4591,  10.3314,  11.9020, -14.0031,  15.4223,  -9.6988],\n",
      "        [ 16.5702,  10.6457,  11.9149, -14.2031,  15.6296,  -9.6338],\n",
      "        [ 16.5914,  10.5617,  12.0136, -14.0534,  15.3218,  -9.8262],\n",
      "        [ 16.4467,  10.8059,  12.1120, -14.2965,  15.7389,  -9.9964],\n",
      "        [ 16.5133,  10.6414,  12.2993, -14.0881,  15.7141, -10.0330],\n",
      "        [ 16.2976,  10.5756,  12.1293, -14.1383,  16.2711, -10.0770]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9486136436462402\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7937, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3973, 10.4318, 12.1413],\n",
      "        [16.2925, 10.3510, 11.9147],\n",
      "        [16.9184, 10.8797, 12.0940],\n",
      "        [16.7292, 10.6182, 12.0345],\n",
      "        [16.9383, 10.9196, 12.2744],\n",
      "        [16.0228, 10.1668, 11.7303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.1981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2695,  15.5951,  -9.9359],\n",
      "        [-14.4749,  15.6730,  -9.9901],\n",
      "        [-14.4755,  16.0626, -10.2813],\n",
      "        [-14.0579,  15.7768, -10.2649],\n",
      "        [-14.4080,  16.3391, -10.0194],\n",
      "        [-14.5810,  16.1243, -10.3794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3973,  10.4318,  12.1413, -14.2695,  15.5951,  -9.9359],\n",
      "        [ 16.2925,  10.3510,  11.9147, -14.4749,  15.6730,  -9.9901],\n",
      "        [ 16.9184,  10.8797,  12.0940, -14.4755,  16.0626, -10.2813],\n",
      "        [ 16.7292,  10.6182,  12.0345, -14.0579,  15.7768, -10.2649],\n",
      "        [ 16.9383,  10.9196,  12.2744, -14.4080,  16.3391, -10.0194],\n",
      "        [ 16.0228,  10.1668,  11.7303, -14.5810,  16.1243, -10.3794]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9683419466018677\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7520, 10.2953, 12.2259],\n",
      "        [16.7460, 10.2676, 12.0755],\n",
      "        [16.6556, 10.8497, 12.3946],\n",
      "        [16.3391, 10.8714, 12.0159],\n",
      "        [17.0189, 10.7539, 12.5092],\n",
      "        [16.1467, 10.1694, 11.8111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5292, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1699,  15.7405,  -9.7924],\n",
      "        [-14.3282,  15.9243, -10.0027],\n",
      "        [-13.9385,  15.5886, -10.3391],\n",
      "        [-14.5921,  15.7973,  -9.8694],\n",
      "        [-14.5453,  15.8121,  -9.9368],\n",
      "        [-14.2633,  16.0745, -10.4051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7520,  10.2953,  12.2259, -14.1699,  15.7405,  -9.7924],\n",
      "        [ 16.7460,  10.2676,  12.0755, -14.3282,  15.9243, -10.0027],\n",
      "        [ 16.6556,  10.8497,  12.3946, -13.9385,  15.5886, -10.3391],\n",
      "        [ 16.3391,  10.8714,  12.0159, -14.5921,  15.7973,  -9.8694],\n",
      "        [ 17.0189,  10.7539,  12.5092, -14.5453,  15.8121,  -9.9368],\n",
      "        [ 16.1467,  10.1694,  11.8111, -14.2633,  16.0745, -10.4051]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.982924222946167\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9395, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4601, 10.5594, 12.1409],\n",
      "        [16.0466, 10.4160, 12.1041],\n",
      "        [16.7140, 10.7746, 12.2692],\n",
      "        [16.1296, 10.0110, 12.0521],\n",
      "        [16.5961, 10.3260, 12.4966],\n",
      "        [16.2695, 10.6426, 12.1190]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2919,  15.8188, -10.1081],\n",
      "        [-14.1656,  15.7743,  -9.7934],\n",
      "        [-14.3565,  15.7231,  -9.9981],\n",
      "        [-14.2351,  15.8218,  -9.7919],\n",
      "        [-14.2253,  15.6689, -10.0406],\n",
      "        [-14.4884,  15.8904, -10.2611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4601,  10.5594,  12.1409, -14.2919,  15.8188, -10.1081],\n",
      "        [ 16.0466,  10.4160,  12.1041, -14.1656,  15.7743,  -9.7934],\n",
      "        [ 16.7140,  10.7746,  12.2692, -14.3565,  15.7231,  -9.9981],\n",
      "        [ 16.1296,  10.0110,  12.0521, -14.2351,  15.8218,  -9.7919],\n",
      "        [ 16.5961,  10.3260,  12.4966, -14.2253,  15.6689, -10.0406],\n",
      "        [ 16.2695,  10.6426,  12.1190, -14.4884,  15.8904, -10.2611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9828670024871826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9895, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4672, 10.6080, 12.2550],\n",
      "        [16.8056, 10.9710, 12.1957],\n",
      "        [16.3156, 10.5184, 12.2150],\n",
      "        [16.3939, 10.5944, 12.5155],\n",
      "        [16.9240, 11.0945, 12.3903],\n",
      "        [16.0696, 10.7738, 11.9306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3260,  15.7315,  -9.8015],\n",
      "        [-14.6031,  15.9758, -10.2112],\n",
      "        [-13.9032,  15.8841,  -9.6274],\n",
      "        [-13.9861,  15.5744,  -9.5986],\n",
      "        [-14.7493,  15.6134, -10.1896],\n",
      "        [-14.3910,  15.6374,  -9.6339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4672,  10.6080,  12.2550, -14.3260,  15.7315,  -9.8015],\n",
      "        [ 16.8056,  10.9710,  12.1957, -14.6031,  15.9758, -10.2112],\n",
      "        [ 16.3156,  10.5184,  12.2150, -13.9032,  15.8841,  -9.6274],\n",
      "        [ 16.3939,  10.5944,  12.5155, -13.9861,  15.5744,  -9.5986],\n",
      "        [ 16.9240,  11.0945,  12.3903, -14.7493,  15.6134, -10.1896],\n",
      "        [ 16.0696,  10.7738,  11.9306, -14.3910,  15.6374,  -9.6339]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9835710525512695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7046, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3710, 10.5233, 12.2331],\n",
      "        [16.5133, 10.4649, 11.7920],\n",
      "        [16.3795, 10.5441, 11.6740],\n",
      "        [16.8458, 10.8427, 12.3117],\n",
      "        [16.6004, 10.8402, 12.3241],\n",
      "        [16.4802, 10.4045, 12.3444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5317,  15.9521,  -9.9337],\n",
      "        [-14.4857,  16.0439, -10.0943],\n",
      "        [-14.5739,  16.1355, -10.2056],\n",
      "        [-13.9772,  15.9436,  -9.8394],\n",
      "        [-14.4254,  15.9417, -10.1517],\n",
      "        [-14.0769,  15.5639, -10.4132]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3710,  10.5233,  12.2331, -14.5317,  15.9521,  -9.9337],\n",
      "        [ 16.5133,  10.4649,  11.7920, -14.4857,  16.0439, -10.0943],\n",
      "        [ 16.3795,  10.5441,  11.6740, -14.5739,  16.1355, -10.2056],\n",
      "        [ 16.8458,  10.8427,  12.3117, -13.9772,  15.9436,  -9.8394],\n",
      "        [ 16.6004,  10.8402,  12.3241, -14.4254,  15.9417, -10.1517],\n",
      "        [ 16.4802,  10.4045,  12.3444, -14.0769,  15.5639, -10.4132]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9890007972717285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5616, 10.3926, 12.0740],\n",
      "        [16.3805, 10.7762, 12.1489],\n",
      "        [16.8050, 10.7471, 12.3593],\n",
      "        [16.4258, 10.3527, 12.0595],\n",
      "        [16.5743, 10.4524, 12.0793],\n",
      "        [16.3636, 10.6151, 12.1614]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9568, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2019,  15.8357, -10.0477],\n",
      "        [-14.3635,  15.8327, -10.3966],\n",
      "        [-14.2118,  15.5676,  -9.7170],\n",
      "        [-14.0126,  15.4771,  -9.9931],\n",
      "        [-14.1421,  15.9655, -10.2764],\n",
      "        [-14.0786,  15.7377,  -9.8075]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5616,  10.3926,  12.0740, -14.2019,  15.8357, -10.0477],\n",
      "        [ 16.3805,  10.7762,  12.1489, -14.3635,  15.8327, -10.3966],\n",
      "        [ 16.8050,  10.7471,  12.3593, -14.2118,  15.5676,  -9.7170],\n",
      "        [ 16.4258,  10.3527,  12.0595, -14.0126,  15.4771,  -9.9931],\n",
      "        [ 16.5743,  10.4524,  12.0793, -14.1421,  15.9655, -10.2764],\n",
      "        [ 16.3636,  10.6151,  12.1614, -14.0786,  15.7377,  -9.8075]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9826470613479614\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9625, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3794, 10.6737, 12.2000],\n",
      "        [16.4674, 10.6449, 11.9268],\n",
      "        [16.4080, 10.5706, 12.1320],\n",
      "        [16.7232, 10.5562, 12.1274],\n",
      "        [16.5924, 10.9199, 12.5253],\n",
      "        [16.3745, 10.5501, 12.3916]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2541, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4226,  15.8999, -10.2951],\n",
      "        [-14.6149,  15.6307, -10.1686],\n",
      "        [-14.4921,  15.8130, -10.5293],\n",
      "        [-14.3958,  15.8930, -10.3302],\n",
      "        [-14.7414,  15.6746,  -9.9427],\n",
      "        [-14.0848,  15.8617,  -9.9002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3794,  10.6737,  12.2000, -14.4226,  15.8999, -10.2951],\n",
      "        [ 16.4674,  10.6449,  11.9268, -14.6149,  15.6307, -10.1686],\n",
      "        [ 16.4080,  10.5706,  12.1320, -14.4921,  15.8130, -10.5293],\n",
      "        [ 16.7232,  10.5562,  12.1274, -14.3958,  15.8930, -10.3302],\n",
      "        [ 16.5924,  10.9199,  12.5253, -14.7414,  15.6746,  -9.9427],\n",
      "        [ 16.3745,  10.5501,  12.3916, -14.0848,  15.8617,  -9.9002]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9945449829101562\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6520, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6908, 11.2657, 12.7295],\n",
      "        [16.1309, 10.7819, 11.8880],\n",
      "        [16.3653, 10.9000, 12.6470],\n",
      "        [16.3240, 10.2536, 11.9344],\n",
      "        [16.9840, 11.0064, 12.2567],\n",
      "        [16.4957, 10.9449, 12.7628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.0923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1496,  15.9115, -10.1074],\n",
      "        [-14.0825,  15.6799,  -9.8508],\n",
      "        [-13.8966,  15.3547,  -9.6248],\n",
      "        [-14.1236,  15.7617, -10.1462],\n",
      "        [-14.3016,  15.6023,  -9.7644],\n",
      "        [-14.2258,  15.7632, -10.0990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6908,  11.2657,  12.7295, -14.1496,  15.9115, -10.1074],\n",
      "        [ 16.1309,  10.7819,  11.8880, -14.0825,  15.6799,  -9.8508],\n",
      "        [ 16.3653,  10.9000,  12.6470, -13.8966,  15.3547,  -9.6248],\n",
      "        [ 16.3240,  10.2536,  11.9344, -14.1236,  15.7617, -10.1462],\n",
      "        [ 16.9840,  11.0064,  12.2567, -14.3016,  15.6023,  -9.7644],\n",
      "        [ 16.4957,  10.9449,  12.7628, -14.2258,  15.7632, -10.0990]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0282695293426514\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8078, 10.4431, 12.0219],\n",
      "        [16.2118, 10.1290, 12.2167],\n",
      "        [17.0807, 11.2476, 12.3738],\n",
      "        [16.1267, 10.5095, 11.8020],\n",
      "        [16.5348, 10.7803, 12.2599],\n",
      "        [16.6258, 10.2822, 11.8473]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.0433,  15.3649, -10.1035],\n",
      "        [-14.1952,  15.9281, -10.0955],\n",
      "        [-14.2371,  15.5818, -10.0895],\n",
      "        [-14.6837,  16.2140,  -9.9850],\n",
      "        [-14.2352,  15.8354, -10.1235],\n",
      "        [-14.2672,  15.8576, -10.3566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8078,  10.4431,  12.0219, -14.0433,  15.3649, -10.1035],\n",
      "        [ 16.2118,  10.1290,  12.2167, -14.1952,  15.9281, -10.0955],\n",
      "        [ 17.0807,  11.2476,  12.3738, -14.2371,  15.5818, -10.0895],\n",
      "        [ 16.1267,  10.5095,  11.8020, -14.6837,  16.2140,  -9.9850],\n",
      "        [ 16.5348,  10.7803,  12.2599, -14.2352,  15.8354, -10.1235],\n",
      "        [ 16.6258,  10.2822,  11.8473, -14.2672,  15.8576, -10.3566]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.982208251953125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6983, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2799, 10.3196, 12.1275],\n",
      "        [16.6114, 10.5613, 12.0767],\n",
      "        [16.7528, 10.9316, 12.1086],\n",
      "        [16.5749, 10.5475, 12.5406],\n",
      "        [16.7979, 10.6781, 12.5151],\n",
      "        [16.2646, 10.6348, 11.9467]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3606,  15.6409, -10.1338],\n",
      "        [-14.2225,  15.9210,  -9.9888],\n",
      "        [-14.1690,  15.7578, -10.4098],\n",
      "        [-14.5306,  15.7865, -10.5142],\n",
      "        [-14.4177,  15.8159, -10.1180],\n",
      "        [-14.4692,  15.5230,  -9.9944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2799,  10.3196,  12.1275, -14.3606,  15.6409, -10.1338],\n",
      "        [ 16.6114,  10.5613,  12.0767, -14.2225,  15.9210,  -9.9888],\n",
      "        [ 16.7528,  10.9316,  12.1086, -14.1690,  15.7578, -10.4098],\n",
      "        [ 16.5749,  10.5475,  12.5406, -14.5306,  15.7865, -10.5142],\n",
      "        [ 16.7979,  10.6781,  12.5151, -14.4177,  15.8159, -10.1180],\n",
      "        [ 16.2646,  10.6348,  11.9467, -14.4692,  15.5230,  -9.9944]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9757018089294434\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7395, 10.7239, 12.1259],\n",
      "        [16.7026, 10.5509, 12.1667],\n",
      "        [16.5770, 10.5149, 11.8382],\n",
      "        [16.3771, 10.5156, 12.4709],\n",
      "        [16.5751, 10.7420, 12.3946],\n",
      "        [16.5147, 10.2860, 11.8012]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3300,  15.7350,  -9.8022],\n",
      "        [-14.3118,  15.9986, -10.2170],\n",
      "        [-14.4647,  15.2568,  -9.7842],\n",
      "        [-14.2836,  15.9113,  -9.8532],\n",
      "        [-14.4296,  16.0410, -10.2663],\n",
      "        [-14.6124,  15.9701, -10.2757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7395,  10.7239,  12.1259, -14.3300,  15.7350,  -9.8022],\n",
      "        [ 16.7026,  10.5509,  12.1667, -14.3118,  15.9986, -10.2170],\n",
      "        [ 16.5770,  10.5149,  11.8382, -14.4647,  15.2568,  -9.7842],\n",
      "        [ 16.3771,  10.5156,  12.4709, -14.2836,  15.9113,  -9.8532],\n",
      "        [ 16.5751,  10.7420,  12.3946, -14.4296,  16.0410, -10.2663],\n",
      "        [ 16.5147,  10.2860,  11.8012, -14.6124,  15.9701, -10.2757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.000257730484009\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1093, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.0475, 10.6345, 12.0715],\n",
      "        [16.4525, 10.7011, 12.3401],\n",
      "        [16.7697, 10.5251, 12.1818],\n",
      "        [16.4236, 10.5048, 12.0574],\n",
      "        [15.9987, 10.5102, 11.7884],\n",
      "        [16.6003, 10.7845, 12.2345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.6718, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4517,  16.1266, -10.2619],\n",
      "        [-14.6613,  16.1130, -10.4681],\n",
      "        [-14.2781,  15.5595,  -9.8350],\n",
      "        [-14.1000,  15.6546,  -9.9764],\n",
      "        [-14.5314,  15.5401,  -9.9866],\n",
      "        [-14.6024,  16.6051, -10.5771]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.0475,  10.6345,  12.0715, -14.4517,  16.1266, -10.2619],\n",
      "        [ 16.4525,  10.7011,  12.3401, -14.6613,  16.1130, -10.4681],\n",
      "        [ 16.7697,  10.5251,  12.1818, -14.2781,  15.5595,  -9.8350],\n",
      "        [ 16.4236,  10.5048,  12.0574, -14.1000,  15.6546,  -9.9764],\n",
      "        [ 15.9987,  10.5102,  11.7884, -14.5314,  15.5401,  -9.9866],\n",
      "        [ 16.6003,  10.7845,  12.2345, -14.6024,  16.6051, -10.5771]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9870402812957764\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4815, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2687, 10.3653, 12.1022],\n",
      "        [16.4444, 10.7887, 12.3559],\n",
      "        [16.5994, 10.5045, 11.9764],\n",
      "        [16.4235, 10.8242, 12.2940],\n",
      "        [16.5423, 10.8048, 12.0566],\n",
      "        [16.7124, 10.9567, 12.3011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2878, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4729,  15.8380, -10.0515],\n",
      "        [-14.4721,  15.6459, -10.1436],\n",
      "        [-14.3924,  15.6020,  -9.8268],\n",
      "        [-14.2126,  15.7534, -10.0310],\n",
      "        [-14.2368,  15.6788, -10.2389],\n",
      "        [-14.2146,  15.6572,  -9.7249]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2687,  10.3653,  12.1022, -14.4729,  15.8380, -10.0515],\n",
      "        [ 16.4444,  10.7887,  12.3559, -14.4721,  15.6459, -10.1436],\n",
      "        [ 16.5994,  10.5045,  11.9764, -14.3924,  15.6020,  -9.8268],\n",
      "        [ 16.4235,  10.8242,  12.2940, -14.2126,  15.7534, -10.0310],\n",
      "        [ 16.5423,  10.8048,  12.0566, -14.2368,  15.6788, -10.2389],\n",
      "        [ 16.7124,  10.9567,  12.3011, -14.2146,  15.6572,  -9.7249]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-1.9840409755706787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9596, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.2130, 10.8676, 12.0807],\n",
      "        [16.3753, 10.7231, 12.4354],\n",
      "        [16.7344, 10.7826, 12.4830],\n",
      "        [16.6940, 10.4589, 12.0196],\n",
      "        [16.1611, 10.4586, 11.7407],\n",
      "        [16.6217, 10.6925, 12.3615]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.2147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5354,  15.8717, -10.0008],\n",
      "        [-14.3559,  15.9473, -10.1487],\n",
      "        [-14.1736,  15.7427, -10.0507],\n",
      "        [-14.1176,  15.4841, -10.0329],\n",
      "        [-14.5209,  16.0409, -10.0669],\n",
      "        [-14.6840,  16.0337, -10.0888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.2130,  10.8676,  12.0807, -14.5354,  15.8717, -10.0008],\n",
      "        [ 16.3753,  10.7231,  12.4354, -14.3559,  15.9473, -10.1487],\n",
      "        [ 16.7344,  10.7826,  12.4830, -14.1736,  15.7427, -10.0507],\n",
      "        [ 16.6940,  10.4589,  12.0196, -14.1176,  15.4841, -10.0329],\n",
      "        [ 16.1611,  10.4586,  11.7407, -14.5209,  16.0409, -10.0669],\n",
      "        [ 16.6217,  10.6925,  12.3615, -14.6840,  16.0337, -10.0888]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-1.9933305978775024\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2306, 10.7362, 12.3866],\n",
      "        [16.3550, 10.3529, 11.7386],\n",
      "        [17.0887, 11.0878, 12.3798],\n",
      "        [16.5158, 10.7683, 12.1478],\n",
      "        [16.6011, 10.9869, 12.5085],\n",
      "        [16.6954, 10.7380, 12.2680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5945, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2432,  16.1982, -10.0130],\n",
      "        [-14.2360,  16.2277, -10.1170],\n",
      "        [-14.1113,  16.1465,  -9.7010],\n",
      "        [-14.2839,  15.7427, -10.1419],\n",
      "        [-14.1022,  15.7536, -10.2116],\n",
      "        [-14.2979,  16.1147, -10.1295]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2306,  10.7362,  12.3866, -14.2432,  16.1982, -10.0130],\n",
      "        [ 16.3550,  10.3529,  11.7386, -14.2360,  16.2277, -10.1170],\n",
      "        [ 17.0887,  11.0878,  12.3798, -14.1113,  16.1465,  -9.7010],\n",
      "        [ 16.5158,  10.7683,  12.1478, -14.2839,  15.7427, -10.1419],\n",
      "        [ 16.6011,  10.9869,  12.5085, -14.1022,  15.7536, -10.2116],\n",
      "        [ 16.6954,  10.7380,  12.2680, -14.2979,  16.1147, -10.1295]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.043518304824829\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0163, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0656, 10.6604, 12.3849],\n",
      "        [16.5597, 10.5413, 12.1895],\n",
      "        [16.7743, 10.8909, 12.1005],\n",
      "        [16.7099, 10.6189, 11.8647],\n",
      "        [16.8163, 11.1365, 12.4185],\n",
      "        [16.8077, 10.9446, 12.4548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.5531, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6616,  16.0397, -10.4626],\n",
      "        [-14.3654,  15.7976, -10.0225],\n",
      "        [-14.5637,  16.0890, -10.6396],\n",
      "        [-14.7244,  16.1981, -10.4229],\n",
      "        [-14.4048,  16.2482, -10.0731],\n",
      "        [-14.7272,  15.9705,  -9.9217]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0656,  10.6604,  12.3849, -14.6616,  16.0397, -10.4626],\n",
      "        [ 16.5597,  10.5413,  12.1895, -14.3654,  15.7976, -10.0225],\n",
      "        [ 16.7743,  10.8909,  12.1005, -14.5637,  16.0890, -10.6396],\n",
      "        [ 16.7099,  10.6189,  11.8647, -14.7244,  16.1981, -10.4229],\n",
      "        [ 16.8163,  11.1365,  12.4185, -14.4048,  16.2482, -10.0731],\n",
      "        [ 16.8077,  10.9446,  12.4548, -14.7272,  15.9705,  -9.9217]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0468547344207764\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9234, 10.6525, 12.3800],\n",
      "        [16.8607, 10.5808, 12.0594],\n",
      "        [16.8087, 10.7938, 12.5354],\n",
      "        [16.6603, 10.7764, 12.2528],\n",
      "        [16.0176, 10.6467, 12.4113],\n",
      "        [16.8585, 10.7467, 12.7761]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2713, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4829,  15.8432, -10.0518],\n",
      "        [-14.3660,  16.0498, -10.3900],\n",
      "        [-14.1569,  15.8651, -10.1609],\n",
      "        [-14.6872,  16.0705, -10.1864],\n",
      "        [-14.6702,  16.0665, -10.3200],\n",
      "        [-14.6653,  16.2603, -10.2528]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9234,  10.6525,  12.3800, -14.4829,  15.8432, -10.0518],\n",
      "        [ 16.8607,  10.5808,  12.0594, -14.3660,  16.0498, -10.3900],\n",
      "        [ 16.8087,  10.7938,  12.5354, -14.1569,  15.8651, -10.1609],\n",
      "        [ 16.6603,  10.7764,  12.2528, -14.6872,  16.0705, -10.1864],\n",
      "        [ 16.0176,  10.6467,  12.4113, -14.6702,  16.0665, -10.3200],\n",
      "        [ 16.8585,  10.7467,  12.7761, -14.6653,  16.2603, -10.2528]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.02888560295105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7721, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5313, 10.6213, 12.1092],\n",
      "        [17.0042, 10.6681, 12.2278],\n",
      "        [16.4276, 10.6499, 12.0586],\n",
      "        [17.1554, 10.9585, 12.7648],\n",
      "        [16.9241, 10.7021, 12.3543],\n",
      "        [16.9846, 10.6929, 12.3840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.1910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3667,  15.7243, -10.3095],\n",
      "        [-14.5273,  16.0529, -10.2849],\n",
      "        [-14.0687,  15.8169, -10.1867],\n",
      "        [-14.5533,  15.9834, -10.1397],\n",
      "        [-14.4240,  16.1651, -10.2137],\n",
      "        [-14.2063,  15.9474,  -9.9957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5313,  10.6213,  12.1092, -14.3667,  15.7243, -10.3095],\n",
      "        [ 17.0042,  10.6681,  12.2278, -14.5273,  16.0529, -10.2849],\n",
      "        [ 16.4276,  10.6499,  12.0586, -14.0687,  15.8169, -10.1867],\n",
      "        [ 17.1554,  10.9585,  12.7648, -14.5533,  15.9834, -10.1397],\n",
      "        [ 16.9241,  10.7021,  12.3543, -14.4240,  16.1651, -10.2137],\n",
      "        [ 16.9846,  10.6929,  12.3840, -14.2063,  15.9474,  -9.9957]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.003640651702881\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.3934, 10.3307, 12.0343],\n",
      "        [16.3615, 10.7199, 12.4066],\n",
      "        [16.4081, 10.4156, 12.2834],\n",
      "        [16.3608, 10.2844, 11.8514],\n",
      "        [16.9154, 10.9334, 12.5518],\n",
      "        [16.1491, 10.6065, 12.0791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3308, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7625,  16.2633, -10.3981],\n",
      "        [-14.6336,  16.1557, -10.3748],\n",
      "        [-14.8209,  15.7703, -10.3381],\n",
      "        [-14.4485,  15.7213, -10.2266],\n",
      "        [-14.2885,  15.5139,  -9.7026],\n",
      "        [-13.6913,  15.6508, -10.1585]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.3934,  10.3307,  12.0343, -14.7625,  16.2633, -10.3981],\n",
      "        [ 16.3615,  10.7199,  12.4066, -14.6336,  16.1557, -10.3748],\n",
      "        [ 16.4081,  10.4156,  12.2834, -14.8209,  15.7703, -10.3381],\n",
      "        [ 16.3608,  10.2844,  11.8514, -14.4485,  15.7213, -10.2266],\n",
      "        [ 16.9154,  10.9334,  12.5518, -14.2885,  15.5139,  -9.7026],\n",
      "        [ 16.1491,  10.6065,  12.0791, -13.6913,  15.6508, -10.1585]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.0120835304260254\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6647, 10.5554, 12.1481],\n",
      "        [16.7262, 10.8070, 12.0207],\n",
      "        [16.6798, 10.9370, 11.9068],\n",
      "        [17.0001, 10.8471, 12.6142],\n",
      "        [16.4711, 10.7664, 12.1950],\n",
      "        [16.7716, 10.9817, 12.4159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5327,  15.8164,  -9.9208],\n",
      "        [-14.1343,  15.3435,  -9.9211],\n",
      "        [-14.2259,  15.6943,  -9.9422],\n",
      "        [-14.4998,  15.8410, -10.4679],\n",
      "        [-14.5375,  15.8131, -10.0692],\n",
      "        [-14.5754,  15.9892, -10.4692]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6647,  10.5554,  12.1481, -14.5327,  15.8164,  -9.9208],\n",
      "        [ 16.7262,  10.8070,  12.0207, -14.1343,  15.3435,  -9.9211],\n",
      "        [ 16.6798,  10.9370,  11.9068, -14.2259,  15.6943,  -9.9422],\n",
      "        [ 17.0001,  10.8471,  12.6142, -14.4998,  15.8410, -10.4679],\n",
      "        [ 16.4711,  10.7664,  12.1950, -14.5375,  15.8131, -10.0692],\n",
      "        [ 16.7716,  10.9817,  12.4159, -14.5754,  15.9892, -10.4692]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0114176273345947\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9783, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5121, 10.8970, 12.0859],\n",
      "        [16.7433, 11.0711, 12.2339],\n",
      "        [16.2904, 10.5263, 12.3818],\n",
      "        [16.5715, 10.8012, 12.4039],\n",
      "        [16.7715, 10.5747, 12.4123],\n",
      "        [16.6920, 10.4925, 12.2483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3623,  16.1390, -10.0609],\n",
      "        [-14.5201,  16.1751, -10.3880],\n",
      "        [-14.8499,  15.8660, -10.3194],\n",
      "        [-14.4814,  15.8541, -10.5825],\n",
      "        [-14.3993,  15.8847, -10.1317],\n",
      "        [-14.4319,  16.2547, -10.5455]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5121,  10.8970,  12.0859, -14.3623,  16.1390, -10.0609],\n",
      "        [ 16.7433,  11.0711,  12.2339, -14.5201,  16.1751, -10.3880],\n",
      "        [ 16.2904,  10.5263,  12.3818, -14.8499,  15.8660, -10.3194],\n",
      "        [ 16.5715,  10.8012,  12.4039, -14.4814,  15.8541, -10.5825],\n",
      "        [ 16.7715,  10.5747,  12.4123, -14.3993,  15.8847, -10.1317],\n",
      "        [ 16.6920,  10.4925,  12.2483, -14.4319,  16.2547, -10.5455]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.016695499420166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7994, 10.9766, 11.9458],\n",
      "        [16.7198, 11.1837, 12.2179],\n",
      "        [16.2856, 10.7386, 12.5335],\n",
      "        [16.4516, 10.7704, 12.1497],\n",
      "        [16.6534, 10.8366, 12.3995],\n",
      "        [16.8938, 10.8380, 12.3561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.6879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.2184,  16.0726, -10.0003],\n",
      "        [-14.6085,  16.1167, -10.2182],\n",
      "        [-14.3004,  16.1636, -10.3628],\n",
      "        [-14.7741,  16.2435, -10.2005],\n",
      "        [-14.5935,  16.4299, -10.1704],\n",
      "        [-14.4762,  15.4288, -10.0817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7994,  10.9766,  11.9458, -14.2184,  16.0726, -10.0003],\n",
      "        [ 16.7198,  11.1837,  12.2179, -14.6085,  16.1167, -10.2182],\n",
      "        [ 16.2856,  10.7386,  12.5335, -14.3004,  16.1636, -10.3628],\n",
      "        [ 16.4516,  10.7704,  12.1497, -14.7741,  16.2435, -10.2005],\n",
      "        [ 16.6534,  10.8366,  12.3995, -14.5935,  16.4299, -10.1704],\n",
      "        [ 16.8938,  10.8380,  12.3561, -14.4762,  15.4288, -10.0817]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.021428346633911\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4789, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5527, 10.5286, 12.5643],\n",
      "        [16.6858, 10.5202, 12.3900],\n",
      "        [16.9344, 11.0261, 11.8934],\n",
      "        [16.5755, 10.4623, 12.2048],\n",
      "        [16.5518, 10.7111, 12.0849],\n",
      "        [16.7050, 10.9538, 12.5572]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.5735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5152,  16.2737, -10.3691],\n",
      "        [-14.4524,  15.6275,  -9.9613],\n",
      "        [-14.5083,  16.3823, -10.7978],\n",
      "        [-14.5035,  16.0180, -10.4173],\n",
      "        [-14.3376,  16.0278,  -9.9844],\n",
      "        [-14.5574,  15.5779, -10.4726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5527,  10.5286,  12.5643, -14.5152,  16.2737, -10.3691],\n",
      "        [ 16.6858,  10.5202,  12.3900, -14.4524,  15.6275,  -9.9613],\n",
      "        [ 16.9344,  11.0261,  11.8934, -14.5083,  16.3823, -10.7978],\n",
      "        [ 16.5755,  10.4623,  12.2048, -14.5035,  16.0180, -10.4173],\n",
      "        [ 16.5518,  10.7111,  12.0849, -14.3376,  16.0278,  -9.9844],\n",
      "        [ 16.7050,  10.9538,  12.5572, -14.5574,  15.5779, -10.4726]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.037870407104492\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7101, 10.8308, 12.1609],\n",
      "        [16.8579, 10.9196, 12.8104],\n",
      "        [16.9213, 10.7924, 12.3997],\n",
      "        [16.7817, 10.7402, 12.4104],\n",
      "        [16.9646, 10.7099, 12.4418],\n",
      "        [16.5332, 10.6980, 12.2467]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.6963, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6237,  15.8740, -10.2778],\n",
      "        [-13.9721,  15.3687,  -9.6657],\n",
      "        [-14.3597,  15.5390,  -9.7635],\n",
      "        [-14.4878,  15.9583, -10.0591],\n",
      "        [-14.7245,  16.2146, -10.3579],\n",
      "        [-14.3371,  16.3244, -10.3201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7101,  10.8308,  12.1609, -14.6237,  15.8740, -10.2778],\n",
      "        [ 16.8579,  10.9196,  12.8104, -13.9721,  15.3687,  -9.6657],\n",
      "        [ 16.9213,  10.7924,  12.3997, -14.3597,  15.5390,  -9.7635],\n",
      "        [ 16.7817,  10.7402,  12.4104, -14.4878,  15.9583, -10.0591],\n",
      "        [ 16.9646,  10.7099,  12.4418, -14.7245,  16.2146, -10.3579],\n",
      "        [ 16.5332,  10.6980,  12.2467, -14.3371,  16.3244, -10.3201]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0308749675750732\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5939, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4725, 10.5952, 11.8153],\n",
      "        [16.6849, 10.6969, 12.3123],\n",
      "        [16.4547, 10.8729, 12.0533],\n",
      "        [16.9004, 11.1012, 12.5896],\n",
      "        [16.7639, 11.0208, 12.3850],\n",
      "        [16.3815, 10.4613, 12.2241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.7488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4198,  15.8181, -10.3420],\n",
      "        [-14.4247,  15.6342, -10.2770],\n",
      "        [-14.3847,  15.8927, -10.2079],\n",
      "        [-14.4733,  16.1852, -10.3945],\n",
      "        [-14.5049,  15.2623, -10.2336],\n",
      "        [-14.4296,  15.9154, -10.3180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4725,  10.5952,  11.8153, -14.4198,  15.8181, -10.3420],\n",
      "        [ 16.6849,  10.6969,  12.3123, -14.4247,  15.6342, -10.2770],\n",
      "        [ 16.4547,  10.8729,  12.0533, -14.3847,  15.8927, -10.2079],\n",
      "        [ 16.9004,  11.1012,  12.5896, -14.4733,  16.1852, -10.3945],\n",
      "        [ 16.7639,  11.0208,  12.3850, -14.5049,  15.2623, -10.2336],\n",
      "        [ 16.3815,  10.4613,  12.2241, -14.4296,  15.9154, -10.3180]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.002656936645508\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9192, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8195, 11.0628, 12.0784],\n",
      "        [17.3090, 11.0776, 12.5951],\n",
      "        [16.7004, 10.6905, 12.2271],\n",
      "        [16.5281, 10.5065, 12.5505],\n",
      "        [16.6153, 11.1124, 12.2733],\n",
      "        [16.7763, 11.1081, 12.4164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9103, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.1721,  15.7377,  -9.9803],\n",
      "        [-14.4492,  15.7343, -10.2650],\n",
      "        [-14.6925,  16.1754, -10.6900],\n",
      "        [-14.2795,  15.9667, -10.0250],\n",
      "        [-14.4242,  16.1805, -10.2448],\n",
      "        [-14.5097,  16.3745, -10.2249]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8195,  11.0628,  12.0784, -14.1721,  15.7377,  -9.9803],\n",
      "        [ 17.3090,  11.0776,  12.5951, -14.4492,  15.7343, -10.2650],\n",
      "        [ 16.7004,  10.6905,  12.2271, -14.6925,  16.1754, -10.6900],\n",
      "        [ 16.5281,  10.5065,  12.5505, -14.2795,  15.9667, -10.0250],\n",
      "        [ 16.6153,  11.1124,  12.2733, -14.4242,  16.1805, -10.2448],\n",
      "        [ 16.7763,  11.1081,  12.4164, -14.5097,  16.3745, -10.2249]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0236198902130127\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9203, 10.8327, 12.7274],\n",
      "        [17.3947, 11.2115, 12.4697],\n",
      "        [17.2384, 10.9358, 12.6783],\n",
      "        [16.2618, 10.7204, 12.4179],\n",
      "        [16.5217, 10.6134, 12.3727],\n",
      "        [16.9329, 10.7945, 12.5455]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5966, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4602,  15.9898, -10.2783],\n",
      "        [-14.6122,  15.9192, -10.2246],\n",
      "        [-14.7734,  16.1678, -10.4828],\n",
      "        [-14.4761,  16.1558, -10.3241],\n",
      "        [-14.2471,  16.0776, -10.0948],\n",
      "        [-14.1482,  15.6459, -10.4218]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9203,  10.8327,  12.7274, -14.4602,  15.9898, -10.2783],\n",
      "        [ 17.3947,  11.2115,  12.4697, -14.6122,  15.9192, -10.2246],\n",
      "        [ 17.2384,  10.9358,  12.6783, -14.7734,  16.1678, -10.4828],\n",
      "        [ 16.2618,  10.7204,  12.4179, -14.4761,  16.1558, -10.3241],\n",
      "        [ 16.5217,  10.6134,  12.3727, -14.2471,  16.0776, -10.0948],\n",
      "        [ 16.9329,  10.7945,  12.5455, -14.1482,  15.6459, -10.4218]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.059342861175537\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5851, 10.5965, 12.4758],\n",
      "        [17.0297, 10.8752, 12.3644],\n",
      "        [16.2833, 10.8649, 12.4218],\n",
      "        [16.6493, 10.7557, 12.5848],\n",
      "        [16.2808, 10.5367, 12.4588],\n",
      "        [16.4307, 10.8824, 12.8913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4939,  16.0543, -10.5498],\n",
      "        [-14.8036,  15.8992, -10.3458],\n",
      "        [-14.1687,  15.3941,  -9.8006],\n",
      "        [-14.5502,  15.9851, -10.0784],\n",
      "        [-14.4680,  15.8915, -10.3884],\n",
      "        [-14.4205,  15.9003, -10.5359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5851,  10.5965,  12.4758, -14.4939,  16.0543, -10.5498],\n",
      "        [ 17.0297,  10.8752,  12.3644, -14.8036,  15.8992, -10.3458],\n",
      "        [ 16.2833,  10.8649,  12.4218, -14.1687,  15.3941,  -9.8006],\n",
      "        [ 16.6493,  10.7557,  12.5848, -14.5502,  15.9851, -10.0784],\n",
      "        [ 16.2808,  10.5367,  12.4588, -14.4680,  15.8915, -10.3884],\n",
      "        [ 16.4307,  10.8824,  12.8913, -14.4205,  15.9003, -10.5359]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.040112257003784\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6860, 10.6998, 12.3538],\n",
      "        [16.4384, 10.9577, 12.5457],\n",
      "        [16.9766, 10.7500, 12.3380],\n",
      "        [16.8476, 10.8736, 12.5457],\n",
      "        [17.0553, 11.2556, 12.7745],\n",
      "        [16.3629, 10.9083, 12.3657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8511, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6500,  16.3280, -10.6253],\n",
      "        [-14.3884,  15.8205, -10.1987],\n",
      "        [-14.8343,  15.8234, -10.1907],\n",
      "        [-14.3394,  16.3173, -10.1769],\n",
      "        [-14.5560,  15.9358, -10.3400],\n",
      "        [-14.4146,  16.0020, -10.4687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6860,  10.6998,  12.3538, -14.6500,  16.3280, -10.6253],\n",
      "        [ 16.4384,  10.9577,  12.5457, -14.3884,  15.8205, -10.1987],\n",
      "        [ 16.9766,  10.7500,  12.3380, -14.8343,  15.8234, -10.1907],\n",
      "        [ 16.8476,  10.8736,  12.5457, -14.3394,  16.3173, -10.1769],\n",
      "        [ 17.0553,  11.2556,  12.7745, -14.5560,  15.9358, -10.3400],\n",
      "        [ 16.3629,  10.9083,  12.3657, -14.4146,  16.0020, -10.4687]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0536835193634033\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7585, 10.5295, 12.4877],\n",
      "        [16.7765, 10.7805, 12.5052],\n",
      "        [17.2040, 11.3443, 12.5850],\n",
      "        [17.3024, 10.7991, 12.8823],\n",
      "        [16.9887, 10.8443, 12.6247],\n",
      "        [16.7573, 10.4124, 12.1288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4669, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5028,  15.8190, -10.2379],\n",
      "        [-14.4754,  16.3878, -10.2786],\n",
      "        [-13.8644,  15.3066,  -9.9901],\n",
      "        [-14.4364,  15.8272, -10.1363],\n",
      "        [-14.9848,  15.9565, -10.5859],\n",
      "        [-14.7107,  15.9995, -10.4354]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7585,  10.5295,  12.4877, -14.5028,  15.8190, -10.2379],\n",
      "        [ 16.7765,  10.7805,  12.5052, -14.4754,  16.3878, -10.2786],\n",
      "        [ 17.2040,  11.3443,  12.5850, -13.8644,  15.3066,  -9.9901],\n",
      "        [ 17.3024,  10.7991,  12.8823, -14.4364,  15.8272, -10.1363],\n",
      "        [ 16.9887,  10.8443,  12.6247, -14.9848,  15.9565, -10.5859],\n",
      "        [ 16.7573,  10.4124,  12.1288, -14.7107,  15.9995, -10.4354]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0392088890075684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9577, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7222, 10.7066, 11.8893],\n",
      "        [16.8247, 11.0605, 12.1917],\n",
      "        [16.7531, 10.7151, 12.6097],\n",
      "        [16.9444, 10.6021, 12.6969],\n",
      "        [16.4766, 10.7820, 12.2161],\n",
      "        [16.7592, 10.8720, 12.7362]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5278,  15.8795,  -9.9757],\n",
      "        [-14.2693,  16.4081, -10.6510],\n",
      "        [-14.3185,  15.6723, -10.2613],\n",
      "        [-14.3317,  15.7720,  -9.9465],\n",
      "        [-14.2956,  15.7675, -10.2647],\n",
      "        [-14.2442,  15.6530, -10.2604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7222,  10.7066,  11.8893, -14.5278,  15.8795,  -9.9757],\n",
      "        [ 16.8247,  11.0605,  12.1917, -14.2693,  16.4081, -10.6510],\n",
      "        [ 16.7531,  10.7151,  12.6097, -14.3185,  15.6723, -10.2613],\n",
      "        [ 16.9444,  10.6021,  12.6969, -14.3317,  15.7720,  -9.9465],\n",
      "        [ 16.4766,  10.7820,  12.2161, -14.2956,  15.7675, -10.2647],\n",
      "        [ 16.7592,  10.8720,  12.7362, -14.2442,  15.6530, -10.2604]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.0223217010498047\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8888, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5892, 11.0287, 12.3964],\n",
      "        [16.9101, 11.2456, 12.6720],\n",
      "        [16.5571, 11.0369, 12.5456],\n",
      "        [16.7164, 11.1598, 12.6467],\n",
      "        [16.9467, 11.0384, 12.5808],\n",
      "        [16.6068, 11.2033, 12.2363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.5011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5941,  15.9981, -10.2896],\n",
      "        [-14.7903,  16.3141, -10.4753],\n",
      "        [-14.7684,  16.3850, -10.6444],\n",
      "        [-14.2564,  15.9003, -10.0882],\n",
      "        [-14.8309,  16.0729, -10.3267],\n",
      "        [-14.3116,  16.1116, -10.0485]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5892,  11.0287,  12.3964, -14.5941,  15.9981, -10.2896],\n",
      "        [ 16.9101,  11.2456,  12.6720, -14.7903,  16.3141, -10.4753],\n",
      "        [ 16.5571,  11.0369,  12.5456, -14.7684,  16.3850, -10.6444],\n",
      "        [ 16.7164,  11.1598,  12.6467, -14.2564,  15.9003, -10.0882],\n",
      "        [ 16.9467,  11.0384,  12.5808, -14.8309,  16.0729, -10.3267],\n",
      "        [ 16.6068,  11.2033,  12.2363, -14.3116,  16.1116, -10.0485]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.048043966293335\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7895, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1165, 11.0572, 12.3441],\n",
      "        [16.5335, 10.8590, 12.0436],\n",
      "        [16.4458, 10.4040, 12.4797],\n",
      "        [17.2314, 11.1243, 12.6968],\n",
      "        [16.8800, 11.2483, 12.7177],\n",
      "        [16.6940, 10.6494, 12.5069]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8293, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5337,  15.7611, -10.1704],\n",
      "        [-14.8934,  16.1032, -10.0912],\n",
      "        [-14.7908,  16.2829, -10.8585],\n",
      "        [-14.5346,  16.2657, -10.4426],\n",
      "        [-14.5437,  16.5265, -10.7007],\n",
      "        [-14.4195,  16.3208,  -9.9232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1165,  11.0572,  12.3441, -14.5337,  15.7611, -10.1704],\n",
      "        [ 16.5335,  10.8590,  12.0436, -14.8934,  16.1032, -10.0912],\n",
      "        [ 16.4458,  10.4040,  12.4797, -14.7908,  16.2829, -10.8585],\n",
      "        [ 17.2314,  11.1243,  12.6968, -14.5346,  16.2657, -10.4426],\n",
      "        [ 16.8800,  11.2483,  12.7177, -14.5437,  16.5265, -10.7007],\n",
      "        [ 16.6940,  10.6494,  12.5069, -14.4195,  16.3208,  -9.9232]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0612359046936035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0370, 11.2237, 12.3450],\n",
      "        [17.0793, 10.6753, 12.6826],\n",
      "        [17.1180, 10.7007, 12.9348],\n",
      "        [17.0643, 11.0437, 12.7194],\n",
      "        [17.3802, 11.0245, 12.4871],\n",
      "        [16.6146, 10.6730, 12.5704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.7132, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6069,  16.0077, -10.4057],\n",
      "        [-14.1954,  15.5493,  -9.9732],\n",
      "        [-14.2907,  15.9460, -10.1230],\n",
      "        [-14.9544,  16.2595, -10.6428],\n",
      "        [-14.8096,  15.8375,  -9.9626],\n",
      "        [-14.2961,  16.3628, -10.4229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0370,  11.2237,  12.3450, -14.6069,  16.0077, -10.4057],\n",
      "        [ 17.0793,  10.6753,  12.6826, -14.1954,  15.5493,  -9.9732],\n",
      "        [ 17.1180,  10.7007,  12.9348, -14.2907,  15.9460, -10.1230],\n",
      "        [ 17.0643,  11.0437,  12.7194, -14.9544,  16.2595, -10.6428],\n",
      "        [ 17.3802,  11.0245,  12.4871, -14.8096,  15.8375,  -9.9626],\n",
      "        [ 16.6146,  10.6730,  12.5704, -14.2961,  16.3628, -10.4229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0724265575408936\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8288, 11.0826, 12.5310],\n",
      "        [16.8981, 10.9056, 12.6671],\n",
      "        [16.9690, 11.1590, 12.5319],\n",
      "        [17.1003, 11.0169, 12.5578],\n",
      "        [16.6787, 10.9579, 12.5224],\n",
      "        [16.8095, 10.5825, 12.1272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.6360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6000,  15.7715, -10.2495],\n",
      "        [-14.2544,  16.0390, -10.2358],\n",
      "        [-14.2592,  15.8114, -10.3046],\n",
      "        [-14.4136,  16.1254, -10.6181],\n",
      "        [-14.5855,  16.1933, -10.1613],\n",
      "        [-14.7353,  16.0354, -10.0002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8288,  11.0826,  12.5310, -14.6000,  15.7715, -10.2495],\n",
      "        [ 16.8981,  10.9056,  12.6671, -14.2544,  16.0390, -10.2358],\n",
      "        [ 16.9690,  11.1590,  12.5319, -14.2592,  15.8114, -10.3046],\n",
      "        [ 17.1003,  11.0169,  12.5578, -14.4136,  16.1254, -10.6181],\n",
      "        [ 16.6787,  10.9579,  12.5224, -14.5855,  16.1933, -10.1613],\n",
      "        [ 16.8095,  10.5825,  12.1272, -14.7353,  16.0354, -10.0002]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0606603622436523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6108, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7545, 11.0996, 12.4519],\n",
      "        [16.8170, 10.9502, 12.2831],\n",
      "        [17.0271, 10.9229, 12.6072],\n",
      "        [16.8713, 10.2350, 12.1301],\n",
      "        [16.9501, 10.9336, 12.3748],\n",
      "        [16.4716, 10.8162, 12.4014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4062, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4708,  15.9482, -10.2439],\n",
      "        [-14.9298,  16.1618, -10.7153],\n",
      "        [-14.3089,  15.8340, -10.0258],\n",
      "        [-14.8737,  16.3914, -10.7393],\n",
      "        [-14.4574,  16.1525, -10.1304],\n",
      "        [-14.4341,  16.2396, -10.6743]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7545,  11.0996,  12.4519, -14.4708,  15.9482, -10.2439],\n",
      "        [ 16.8170,  10.9502,  12.2831, -14.9298,  16.1618, -10.7153],\n",
      "        [ 17.0271,  10.9229,  12.6072, -14.3089,  15.8340, -10.0258],\n",
      "        [ 16.8713,  10.2350,  12.1301, -14.8737,  16.3914, -10.7393],\n",
      "        [ 16.9501,  10.9336,  12.3748, -14.4574,  16.1525, -10.1304],\n",
      "        [ 16.4716,  10.8162,  12.4014, -14.4341,  16.2396, -10.6743]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0579280853271484\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8154, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6928, 10.8553, 12.4773],\n",
      "        [16.8440, 10.5863, 12.2844],\n",
      "        [17.0082, 11.2508, 12.6288],\n",
      "        [17.2214, 10.9471, 12.3956],\n",
      "        [17.0201, 11.1837, 12.9055],\n",
      "        [17.1285, 11.2366, 12.5984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4514,  16.1012, -10.4740],\n",
      "        [-14.1558,  15.9886,  -9.8966],\n",
      "        [-14.8579,  16.4075, -10.5366],\n",
      "        [-14.1158,  16.1147, -10.6287],\n",
      "        [-14.5385,  15.8516, -10.2628],\n",
      "        [-14.4646,  15.9348, -10.7965]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6928,  10.8553,  12.4773, -14.4514,  16.1012, -10.4740],\n",
      "        [ 16.8440,  10.5863,  12.2844, -14.1558,  15.9886,  -9.8966],\n",
      "        [ 17.0082,  11.2508,  12.6288, -14.8579,  16.4075, -10.5366],\n",
      "        [ 17.2214,  10.9471,  12.3956, -14.1158,  16.1147, -10.6287],\n",
      "        [ 17.0201,  11.1837,  12.9055, -14.5385,  15.8516, -10.2628],\n",
      "        [ 17.1285,  11.2366,  12.5984, -14.4646,  15.9348, -10.7965]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.0584659576416016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.4596, 11.3698, 12.1016],\n",
      "        [17.0194, 10.9767, 12.4413],\n",
      "        [16.6034, 10.7997, 12.0590],\n",
      "        [16.3866, 10.8598, 12.5465],\n",
      "        [16.8792, 11.2860, 12.9110],\n",
      "        [16.5230, 10.7595, 12.3828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9792,  16.4349, -10.2767],\n",
      "        [-14.4403,  16.0048, -10.7548],\n",
      "        [-14.6846,  16.2172, -10.6101],\n",
      "        [-14.9669,  16.2042, -10.3973],\n",
      "        [-14.5824,  15.9107, -10.3693],\n",
      "        [-14.7730,  16.1110, -10.1830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.4596,  11.3698,  12.1016, -14.9792,  16.4349, -10.2767],\n",
      "        [ 17.0194,  10.9767,  12.4413, -14.4403,  16.0048, -10.7548],\n",
      "        [ 16.6034,  10.7997,  12.0590, -14.6846,  16.2172, -10.6101],\n",
      "        [ 16.3866,  10.8598,  12.5465, -14.9669,  16.2042, -10.3973],\n",
      "        [ 16.8792,  11.2860,  12.9110, -14.5824,  15.9107, -10.3693],\n",
      "        [ 16.5230,  10.7595,  12.3828, -14.7730,  16.1110, -10.1830]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.064211845397949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1295, 11.1005, 12.6532],\n",
      "        [17.0679, 11.1735, 12.3310],\n",
      "        [16.8374, 11.1362, 12.0731],\n",
      "        [17.0901, 11.3420, 12.5520],\n",
      "        [16.6516, 10.8068, 12.3635],\n",
      "        [16.8621, 10.9345, 12.6060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8471,  16.2222, -10.3722],\n",
      "        [-14.7447,  16.1460, -10.1926],\n",
      "        [-14.3317,  15.9094, -10.1665],\n",
      "        [-14.7789,  16.3978, -10.5481],\n",
      "        [-14.5371,  15.9133, -10.2870],\n",
      "        [-14.5245,  15.9094, -10.4071]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1295,  11.1005,  12.6532, -14.8471,  16.2222, -10.3722],\n",
      "        [ 17.0679,  11.1735,  12.3310, -14.7447,  16.1460, -10.1926],\n",
      "        [ 16.8374,  11.1362,  12.0731, -14.3317,  15.9094, -10.1665],\n",
      "        [ 17.0901,  11.3420,  12.5520, -14.7789,  16.3978, -10.5481],\n",
      "        [ 16.6516,  10.8068,  12.3635, -14.5371,  15.9133, -10.2870],\n",
      "        [ 16.8621,  10.9345,  12.6060, -14.5245,  15.9094, -10.4071]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0978543758392334\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9294, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9240, 11.3819, 12.5769],\n",
      "        [16.8033, 10.8252, 12.5597],\n",
      "        [16.9324, 10.9263, 12.6405],\n",
      "        [16.5837, 11.1072, 12.3828],\n",
      "        [16.8429, 11.2386, 12.4954],\n",
      "        [16.9547, 10.9442, 12.5728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9738,  16.5126, -10.5134],\n",
      "        [-14.4720,  16.0556, -10.4326],\n",
      "        [-14.4522,  15.9116, -10.5028],\n",
      "        [-14.6985,  15.8945, -10.4603],\n",
      "        [-14.8809,  16.2659, -10.6481],\n",
      "        [-15.0389,  16.4802, -10.7074]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9240,  11.3819,  12.5769, -14.9738,  16.5126, -10.5134],\n",
      "        [ 16.8033,  10.8252,  12.5597, -14.4720,  16.0556, -10.4326],\n",
      "        [ 16.9324,  10.9263,  12.6405, -14.4522,  15.9116, -10.5028],\n",
      "        [ 16.5837,  11.1072,  12.3828, -14.6985,  15.8945, -10.4603],\n",
      "        [ 16.8429,  11.2386,  12.4954, -14.8809,  16.2659, -10.6481],\n",
      "        [ 16.9547,  10.9442,  12.5728, -15.0389,  16.4802, -10.7074]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1047635078430176\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2789, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9502, 10.7787, 12.3760],\n",
      "        [16.6662, 10.8874, 12.2426],\n",
      "        [16.7338, 10.8805, 12.1313],\n",
      "        [17.0907, 11.2796, 12.7668],\n",
      "        [17.1142, 10.9457, 12.6929],\n",
      "        [16.9468, 10.8196, 12.3439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9896,  16.1397, -10.3473],\n",
      "        [-14.8669,  16.1466, -10.4870],\n",
      "        [-14.5326,  16.1455, -10.4289],\n",
      "        [-14.9200,  15.9516, -10.3867],\n",
      "        [-14.7890,  16.2237, -10.8745],\n",
      "        [-15.0337,  15.9043, -10.6437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9502,  10.7787,  12.3760, -14.9896,  16.1397, -10.3473],\n",
      "        [ 16.6662,  10.8874,  12.2426, -14.8669,  16.1466, -10.4870],\n",
      "        [ 16.7338,  10.8805,  12.1313, -14.5326,  16.1455, -10.4289],\n",
      "        [ 17.0907,  11.2796,  12.7668, -14.9200,  15.9516, -10.3867],\n",
      "        [ 17.1142,  10.9457,  12.6929, -14.7890,  16.2237, -10.8745],\n",
      "        [ 16.9468,  10.8196,  12.3439, -15.0337,  15.9043, -10.6437]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0785017013549805\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6853, 11.0364, 12.2813],\n",
      "        [17.2387, 11.3402, 12.8996],\n",
      "        [17.3215, 11.1984, 12.7286],\n",
      "        [17.1358, 10.9494, 12.2816],\n",
      "        [16.7640, 10.9984, 12.1165],\n",
      "        [16.6292, 10.5366, 12.4484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9258,  16.1230, -10.6195],\n",
      "        [-14.6649,  16.0509, -10.5220],\n",
      "        [-14.5514,  16.1916,  -9.8722],\n",
      "        [-14.5699,  16.1923, -10.6537],\n",
      "        [-14.8816,  16.3065, -10.5248],\n",
      "        [-14.9799,  16.4297, -10.6859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6853,  11.0364,  12.2813, -14.9258,  16.1230, -10.6195],\n",
      "        [ 17.2387,  11.3402,  12.8996, -14.6649,  16.0509, -10.5220],\n",
      "        [ 17.3215,  11.1984,  12.7286, -14.5514,  16.1916,  -9.8722],\n",
      "        [ 17.1358,  10.9494,  12.2816, -14.5699,  16.1923, -10.6537],\n",
      "        [ 16.7640,  10.9984,  12.1165, -14.8816,  16.3065, -10.5248],\n",
      "        [ 16.6292,  10.5366,  12.4484, -14.9799,  16.4297, -10.6859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0729565620422363\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2362, 11.1040, 12.7772],\n",
      "        [17.0471, 10.9987, 12.5775],\n",
      "        [16.6457, 10.9386, 12.6498],\n",
      "        [16.5542, 10.9532, 12.5961],\n",
      "        [16.6122, 10.6644, 12.1395],\n",
      "        [16.2766, 10.8735, 11.7035]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.5134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9163,  16.4316, -10.8404],\n",
      "        [-14.4818,  16.3604, -10.4149],\n",
      "        [-14.4581,  15.7104, -10.1924],\n",
      "        [-14.6288,  15.9447, -10.4874],\n",
      "        [-14.9609,  16.5352, -10.7697],\n",
      "        [-14.8960,  15.9364, -10.1636]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2362,  11.1040,  12.7772, -14.9163,  16.4316, -10.8404],\n",
      "        [ 17.0471,  10.9987,  12.5775, -14.4818,  16.3604, -10.4149],\n",
      "        [ 16.6457,  10.9386,  12.6498, -14.4581,  15.7104, -10.1924],\n",
      "        [ 16.5542,  10.9532,  12.5961, -14.6288,  15.9447, -10.4874],\n",
      "        [ 16.6122,  10.6644,  12.1395, -14.9609,  16.5352, -10.7697],\n",
      "        [ 16.2766,  10.8735,  11.7035, -14.8960,  15.9364, -10.1636]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.122615098953247\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0720, 11.3060, 12.3513],\n",
      "        [16.7922, 10.5111, 12.1739],\n",
      "        [16.5753, 10.7858, 11.9636],\n",
      "        [16.7365, 10.8101, 12.3551],\n",
      "        [17.1856, 11.1789, 12.6088],\n",
      "        [17.0053, 11.2596, 12.8572]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8908, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2527,  16.6793, -10.8417],\n",
      "        [-14.4782,  16.1852, -10.0920],\n",
      "        [-14.8629,  15.7937, -10.2745],\n",
      "        [-14.7664,  16.0344, -10.6661],\n",
      "        [-14.8657,  16.4260, -10.7657],\n",
      "        [-14.6813,  16.1963, -10.4323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0720,  11.3060,  12.3513, -15.2527,  16.6793, -10.8417],\n",
      "        [ 16.7922,  10.5111,  12.1739, -14.4782,  16.1852, -10.0920],\n",
      "        [ 16.5753,  10.7858,  11.9636, -14.8629,  15.7937, -10.2745],\n",
      "        [ 16.7365,  10.8101,  12.3551, -14.7664,  16.0344, -10.6661],\n",
      "        [ 17.1856,  11.1789,  12.6088, -14.8657,  16.4260, -10.7657],\n",
      "        [ 17.0053,  11.2596,  12.8572, -14.6813,  16.1963, -10.4323]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1202478408813477\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2106, 11.1828, 13.0408],\n",
      "        [16.4530, 10.9966, 12.1237],\n",
      "        [16.9377, 11.2050, 12.4097],\n",
      "        [17.2057, 10.8945, 12.7818],\n",
      "        [16.5337, 10.9219, 12.5860],\n",
      "        [16.7450, 11.2573, 12.0693]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8930,  16.4106, -10.8162],\n",
      "        [-14.7148,  16.1571, -10.2733],\n",
      "        [-15.1935,  16.1965, -10.5141],\n",
      "        [-14.5256,  16.2376, -10.0971],\n",
      "        [-14.7055,  16.0999, -10.6416],\n",
      "        [-15.3569,  16.5144, -10.8267]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2106,  11.1828,  13.0408, -14.8930,  16.4106, -10.8162],\n",
      "        [ 16.4530,  10.9966,  12.1237, -14.7148,  16.1571, -10.2733],\n",
      "        [ 16.9377,  11.2050,  12.4097, -15.1935,  16.1965, -10.5141],\n",
      "        [ 17.2057,  10.8945,  12.7818, -14.5256,  16.2376, -10.0971],\n",
      "        [ 16.5337,  10.9219,  12.5860, -14.7055,  16.0999, -10.6416],\n",
      "        [ 16.7450,  11.2573,  12.0693, -15.3569,  16.5144, -10.8267]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.13230037689209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0141, 11.4517, 12.5676],\n",
      "        [16.9492, 11.2682, 12.7508],\n",
      "        [17.0894, 11.0213, 12.6128],\n",
      "        [16.7132, 11.1368, 12.7651],\n",
      "        [16.4078, 11.0028, 12.4067],\n",
      "        [16.6482, 10.8124, 12.2577]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3612,  15.9344, -10.6190],\n",
      "        [-14.5587,  15.9560, -10.1707],\n",
      "        [-14.5436,  16.2031, -10.6142],\n",
      "        [-14.7005,  16.0190, -10.2481],\n",
      "        [-14.6622,  16.3122, -10.7629],\n",
      "        [-14.5413,  16.0985, -10.5310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0141,  11.4517,  12.5676, -14.3612,  15.9344, -10.6190],\n",
      "        [ 16.9492,  11.2682,  12.7508, -14.5587,  15.9560, -10.1707],\n",
      "        [ 17.0894,  11.0213,  12.6128, -14.5436,  16.2031, -10.6142],\n",
      "        [ 16.7132,  11.1368,  12.7651, -14.7005,  16.0190, -10.2481],\n",
      "        [ 16.4078,  11.0028,  12.4067, -14.6622,  16.3122, -10.7629],\n",
      "        [ 16.6482,  10.8124,  12.2577, -14.5413,  16.0985, -10.5310]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0921432971954346\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0822, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8801, 11.2280, 13.1083],\n",
      "        [16.4100, 10.7023, 12.0502],\n",
      "        [16.5813, 10.7261, 12.4508],\n",
      "        [16.8548, 10.8796, 12.4814],\n",
      "        [16.9433, 10.5243, 12.3482],\n",
      "        [16.9959, 11.0396, 12.3147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7783, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6577,  15.9298, -10.6123],\n",
      "        [-14.8889,  16.5147, -10.4644],\n",
      "        [-14.6991,  16.2970, -10.7612],\n",
      "        [-15.0841,  15.8780, -10.7328],\n",
      "        [-14.5884,  16.0256, -10.1920],\n",
      "        [-14.6984,  16.1703, -10.1397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8801,  11.2280,  13.1083, -14.6577,  15.9298, -10.6123],\n",
      "        [ 16.4100,  10.7023,  12.0502, -14.8889,  16.5147, -10.4644],\n",
      "        [ 16.5813,  10.7261,  12.4508, -14.6991,  16.2970, -10.7612],\n",
      "        [ 16.8548,  10.8796,  12.4814, -15.0841,  15.8780, -10.7328],\n",
      "        [ 16.9433,  10.5243,  12.3482, -14.5884,  16.0256, -10.1920],\n",
      "        [ 16.9959,  11.0396,  12.3147, -14.6984,  16.1703, -10.1397]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.105947494506836\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1611, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0278, 11.3122, 12.6518],\n",
      "        [16.7001, 11.1097, 12.4541],\n",
      "        [16.6920, 10.9279, 12.3176],\n",
      "        [16.5163, 11.0943, 12.3358],\n",
      "        [16.9941, 10.9258, 12.5561],\n",
      "        [16.6765, 10.3993, 12.3072]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6743, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9370,  16.2406, -10.6381],\n",
      "        [-14.7877,  16.0807, -10.2352],\n",
      "        [-14.3784,  15.8924,  -9.9560],\n",
      "        [-14.7513,  16.2090, -10.4696],\n",
      "        [-14.5638,  16.2567, -10.2399],\n",
      "        [-14.3982,  15.8209, -10.4932]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0278,  11.3122,  12.6518, -14.9370,  16.2406, -10.6381],\n",
      "        [ 16.7001,  11.1097,  12.4541, -14.7877,  16.0807, -10.2352],\n",
      "        [ 16.6920,  10.9279,  12.3176, -14.3784,  15.8924,  -9.9560],\n",
      "        [ 16.5163,  11.0943,  12.3358, -14.7513,  16.2090, -10.4696],\n",
      "        [ 16.9941,  10.9258,  12.5561, -14.5638,  16.2567, -10.2399],\n",
      "        [ 16.6765,  10.3993,  12.3072, -14.3982,  15.8209, -10.4932]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.113475799560547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0689, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2348, 11.4660, 12.8818],\n",
      "        [17.1245, 11.3321, 12.4293],\n",
      "        [16.8557, 10.8125, 12.4387],\n",
      "        [17.1718, 10.9171, 12.4030],\n",
      "        [16.9534, 10.9255, 12.2719],\n",
      "        [17.2435, 10.9378, 13.2325]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5209,  16.0700, -10.2035],\n",
      "        [-15.0354,  16.2379, -10.5608],\n",
      "        [-14.5167,  16.3503, -10.2706],\n",
      "        [-14.7251,  16.1964, -10.6407],\n",
      "        [-14.9250,  16.4712, -10.8340],\n",
      "        [-15.0569,  16.4525, -10.6022]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2348,  11.4660,  12.8818, -14.5209,  16.0700, -10.2035],\n",
      "        [ 17.1245,  11.3321,  12.4293, -15.0354,  16.2379, -10.5608],\n",
      "        [ 16.8557,  10.8125,  12.4387, -14.5167,  16.3503, -10.2706],\n",
      "        [ 17.1718,  10.9171,  12.4030, -14.7251,  16.1964, -10.6407],\n",
      "        [ 16.9534,  10.9255,  12.2719, -14.9250,  16.4712, -10.8340],\n",
      "        [ 17.2435,  10.9378,  13.2325, -15.0569,  16.4525, -10.6022]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.115262985229492\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4403, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7548, 11.0890, 12.3756],\n",
      "        [16.6062, 10.6748, 12.6474],\n",
      "        [17.2935, 11.4783, 12.6604],\n",
      "        [16.5300, 11.2522, 12.6341],\n",
      "        [16.6472, 11.0047, 12.4108],\n",
      "        [16.5905, 10.6512, 12.1072]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8233, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5799,  15.9801, -10.4754],\n",
      "        [-14.6296,  15.9757, -10.6445],\n",
      "        [-15.0171,  16.4125, -10.6338],\n",
      "        [-14.5533,  15.5812, -10.4757],\n",
      "        [-14.8002,  16.3036, -10.7913],\n",
      "        [-14.9066,  16.3340, -10.6953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7548,  11.0890,  12.3756, -14.5799,  15.9801, -10.4754],\n",
      "        [ 16.6062,  10.6748,  12.6474, -14.6296,  15.9757, -10.6445],\n",
      "        [ 17.2935,  11.4783,  12.6604, -15.0171,  16.4125, -10.6338],\n",
      "        [ 16.5300,  11.2522,  12.6341, -14.5533,  15.5812, -10.4757],\n",
      "        [ 16.6472,  11.0047,  12.4108, -14.8002,  16.3036, -10.7913],\n",
      "        [ 16.5905,  10.6512,  12.1072, -14.9066,  16.3340, -10.6953]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.076375961303711\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9287, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8249, 11.2671, 12.1286],\n",
      "        [16.8882, 11.1973, 12.6928],\n",
      "        [16.7825, 10.8969, 12.9589],\n",
      "        [16.9579, 11.0468, 12.4243],\n",
      "        [16.8062, 11.3386, 12.5597],\n",
      "        [16.7909, 11.1187, 12.5259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5395, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8705,  16.3771, -10.5156],\n",
      "        [-14.8426,  15.9703, -10.6522],\n",
      "        [-14.9050,  16.0341, -10.3413],\n",
      "        [-14.8675,  16.1044, -10.5709],\n",
      "        [-14.5844,  16.0560, -10.3874],\n",
      "        [-14.6507,  16.4615, -10.5383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8249,  11.2671,  12.1286, -14.8705,  16.3771, -10.5156],\n",
      "        [ 16.8882,  11.1973,  12.6928, -14.8426,  15.9703, -10.6522],\n",
      "        [ 16.7825,  10.8969,  12.9589, -14.9050,  16.0341, -10.3413],\n",
      "        [ 16.9579,  11.0468,  12.4243, -14.8675,  16.1044, -10.5709],\n",
      "        [ 16.8062,  11.3386,  12.5597, -14.5844,  16.0560, -10.3874],\n",
      "        [ 16.7909,  11.1187,  12.5259, -14.6507,  16.4615, -10.5383]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.091522693634033\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9610, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1683, 11.3181, 12.8405],\n",
      "        [17.0198, 11.2281, 12.4182],\n",
      "        [17.0979, 11.0170, 12.7459],\n",
      "        [17.1798, 11.3641, 12.7628],\n",
      "        [16.8373, 10.9733, 12.3532],\n",
      "        [17.0415, 10.8797, 12.5371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.7287, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1586,  16.6091, -10.6181],\n",
      "        [-14.8918,  16.3433, -10.7971],\n",
      "        [-14.8886,  15.9168, -10.5488],\n",
      "        [-15.0092,  16.1088, -10.4915],\n",
      "        [-14.8848,  16.6018, -10.4546],\n",
      "        [-14.8217,  16.5524, -10.5141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1683,  11.3181,  12.8405, -15.1586,  16.6091, -10.6181],\n",
      "        [ 17.0198,  11.2281,  12.4182, -14.8918,  16.3433, -10.7971],\n",
      "        [ 17.0979,  11.0170,  12.7459, -14.8886,  15.9168, -10.5488],\n",
      "        [ 17.1798,  11.3641,  12.7628, -15.0092,  16.1088, -10.4915],\n",
      "        [ 16.8373,  10.9733,  12.3532, -14.8848,  16.6018, -10.4546],\n",
      "        [ 17.0415,  10.8797,  12.5371, -14.8217,  16.5524, -10.5141]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.142120599746704\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2671, 11.2250, 12.8365],\n",
      "        [17.0350, 11.2380, 12.5349],\n",
      "        [17.2145, 11.6618, 12.7678],\n",
      "        [17.2096, 11.4189, 12.4847],\n",
      "        [16.8687, 11.0583, 12.2239],\n",
      "        [16.9625, 11.0677, 12.6831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6727,  16.3647, -10.6225],\n",
      "        [-14.7871,  16.3591, -10.5257],\n",
      "        [-14.9745,  16.2728, -10.5146],\n",
      "        [-14.7493,  16.0609, -10.5566],\n",
      "        [-14.2335,  15.6071, -10.3013],\n",
      "        [-14.7579,  16.0158, -10.5269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2671,  11.2250,  12.8365, -14.6727,  16.3647, -10.6225],\n",
      "        [ 17.0350,  11.2380,  12.5349, -14.7871,  16.3591, -10.5257],\n",
      "        [ 17.2145,  11.6618,  12.7678, -14.9745,  16.2728, -10.5146],\n",
      "        [ 17.2096,  11.4189,  12.4847, -14.7493,  16.0609, -10.5566],\n",
      "        [ 16.8687,  11.0583,  12.2239, -14.2335,  15.6071, -10.3013],\n",
      "        [ 16.9625,  11.0677,  12.6831, -14.7579,  16.0158, -10.5269]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1299495697021484\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2486, 11.1933, 12.7333],\n",
      "        [17.1354, 11.1085, 12.8278],\n",
      "        [16.6854, 10.9683, 12.7282],\n",
      "        [16.6612, 11.4606, 12.8121],\n",
      "        [17.1974, 11.4305, 12.7262],\n",
      "        [16.6100, 10.6552, 12.2627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3431, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7376,  16.2204, -10.7303],\n",
      "        [-14.5707,  16.3627, -10.3488],\n",
      "        [-14.2596,  15.6854, -10.2927],\n",
      "        [-14.5757,  15.9469, -10.4690],\n",
      "        [-14.2878,  15.7371, -10.1614],\n",
      "        [-15.0218,  16.1587, -10.3555]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2486,  11.1933,  12.7333, -14.7376,  16.2204, -10.7303],\n",
      "        [ 17.1354,  11.1085,  12.8278, -14.5707,  16.3627, -10.3488],\n",
      "        [ 16.6854,  10.9683,  12.7282, -14.2596,  15.6854, -10.2927],\n",
      "        [ 16.6612,  11.4606,  12.8121, -14.5757,  15.9469, -10.4690],\n",
      "        [ 17.1974,  11.4305,  12.7262, -14.2878,  15.7371, -10.1614],\n",
      "        [ 16.6100,  10.6552,  12.2627, -15.0218,  16.1587, -10.3555]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1259212493896484\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8214, 11.4078, 12.8276],\n",
      "        [17.0586, 11.2540, 12.7043],\n",
      "        [17.0533, 11.6631, 12.5729],\n",
      "        [16.5179, 10.8593, 12.3538],\n",
      "        [17.1933, 11.2870, 12.3766],\n",
      "        [16.6691, 10.8850, 12.5286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.5779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.5454,  16.6095, -10.8441],\n",
      "        [-14.8285,  16.2112, -10.5120],\n",
      "        [-14.4072,  15.8999, -10.2193],\n",
      "        [-15.0350,  16.3991, -10.6979],\n",
      "        [-14.7792,  15.9073, -10.4208],\n",
      "        [-14.4946,  15.9248, -10.3604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8214,  11.4078,  12.8276, -14.5454,  16.6095, -10.8441],\n",
      "        [ 17.0586,  11.2540,  12.7043, -14.8285,  16.2112, -10.5120],\n",
      "        [ 17.0533,  11.6631,  12.5729, -14.4072,  15.8999, -10.2193],\n",
      "        [ 16.5179,  10.8593,  12.3538, -15.0350,  16.3991, -10.6979],\n",
      "        [ 17.1933,  11.2870,  12.3766, -14.7792,  15.9073, -10.4208],\n",
      "        [ 16.6691,  10.8850,  12.5286, -14.4946,  15.9248, -10.3604]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.1233818531036377\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3397, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2211, 11.2661, 12.8740],\n",
      "        [17.0228, 11.2500, 12.5591],\n",
      "        [16.3217, 11.0708, 12.2803],\n",
      "        [16.7178, 11.0299, 12.7648],\n",
      "        [16.9258, 11.1495, 12.7356],\n",
      "        [17.3705, 11.5034, 13.3788]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.6877, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.0570,  15.9069, -10.3085],\n",
      "        [-14.9309,  16.3570, -10.8512],\n",
      "        [-14.3539,  16.0622, -10.6073],\n",
      "        [-14.7796,  16.4961, -10.7638],\n",
      "        [-14.5998,  16.4334, -10.4350],\n",
      "        [-15.1229,  16.6596, -11.0645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2211,  11.2661,  12.8740, -15.0570,  15.9069, -10.3085],\n",
      "        [ 17.0228,  11.2500,  12.5591, -14.9309,  16.3570, -10.8512],\n",
      "        [ 16.3217,  11.0708,  12.2803, -14.3539,  16.0622, -10.6073],\n",
      "        [ 16.7178,  11.0299,  12.7648, -14.7796,  16.4961, -10.7638],\n",
      "        [ 16.9258,  11.1495,  12.7356, -14.5998,  16.4334, -10.4350],\n",
      "        [ 17.3705,  11.5034,  13.3788, -15.1229,  16.6596, -11.0645]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.12668776512146\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7349, 10.9128, 12.7747],\n",
      "        [17.2162, 11.3552, 12.3740],\n",
      "        [16.8784, 11.1031, 12.6359],\n",
      "        [17.2367, 11.1195, 12.5103],\n",
      "        [16.7532, 11.0812, 12.3506],\n",
      "        [16.6732, 10.8289, 12.7079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2148,  16.4744, -10.5677],\n",
      "        [-14.6525,  16.1500, -10.8225],\n",
      "        [-14.9662,  16.5326, -10.8089],\n",
      "        [-14.8864,  16.3969, -10.4473],\n",
      "        [-14.8659,  16.7044, -10.6822],\n",
      "        [-14.8277,  16.2189, -10.7253]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7349,  10.9128,  12.7747, -15.2148,  16.4744, -10.5677],\n",
      "        [ 17.2162,  11.3552,  12.3740, -14.6525,  16.1500, -10.8225],\n",
      "        [ 16.8784,  11.1031,  12.6359, -14.9662,  16.5326, -10.8089],\n",
      "        [ 17.2367,  11.1195,  12.5103, -14.8864,  16.3969, -10.4473],\n",
      "        [ 16.7532,  11.0812,  12.3506, -14.8659,  16.7044, -10.6822],\n",
      "        [ 16.6732,  10.8289,  12.7079, -14.8277,  16.2189, -10.7253]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.117361545562744\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1879, 11.4213, 12.5130],\n",
      "        [16.9262, 10.4984, 12.3183],\n",
      "        [17.3044, 11.4556, 12.7563],\n",
      "        [17.2678, 11.0961, 12.4725],\n",
      "        [16.7133, 11.0667, 12.4359],\n",
      "        [17.0211, 11.0391, 12.5861]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3695, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8662,  16.4105, -10.9289],\n",
      "        [-14.8149,  16.3668, -10.5465],\n",
      "        [-15.3177,  16.6014, -10.9150],\n",
      "        [-14.8497,  16.0735, -10.4450],\n",
      "        [-15.0757,  16.0628, -10.6181],\n",
      "        [-15.0087,  16.3144, -10.3882]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1879,  11.4213,  12.5130, -14.8662,  16.4105, -10.9289],\n",
      "        [ 16.9262,  10.4984,  12.3183, -14.8149,  16.3668, -10.5465],\n",
      "        [ 17.3044,  11.4556,  12.7563, -15.3177,  16.6014, -10.9150],\n",
      "        [ 17.2678,  11.0961,  12.4725, -14.8497,  16.0735, -10.4450],\n",
      "        [ 16.7133,  11.0667,  12.4359, -15.0757,  16.0628, -10.6181],\n",
      "        [ 17.0211,  11.0391,  12.5861, -15.0087,  16.3144, -10.3882]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1351208686828613\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8698, 11.5587, 12.1320],\n",
      "        [16.9334, 11.2698, 12.7847],\n",
      "        [16.9238, 11.3203, 12.7927],\n",
      "        [16.7552, 10.9469, 12.5964],\n",
      "        [16.7028, 11.0678, 12.9748],\n",
      "        [16.7398, 11.3084, 12.7114]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4012,  16.2652, -10.6666],\n",
      "        [-14.4636,  15.8512, -10.5094],\n",
      "        [-14.8075,  16.2929, -10.9094],\n",
      "        [-14.8997,  16.3674, -10.4213],\n",
      "        [-14.7527,  16.2736, -10.5185],\n",
      "        [-14.7114,  16.3399, -10.2525]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8698,  11.5587,  12.1320, -14.4012,  16.2652, -10.6666],\n",
      "        [ 16.9334,  11.2698,  12.7847, -14.4636,  15.8512, -10.5094],\n",
      "        [ 16.9238,  11.3203,  12.7927, -14.8075,  16.2929, -10.9094],\n",
      "        [ 16.7552,  10.9469,  12.5964, -14.8997,  16.3674, -10.4213],\n",
      "        [ 16.7028,  11.0678,  12.9748, -14.7527,  16.2736, -10.5185],\n",
      "        [ 16.7398,  11.3084,  12.7114, -14.7114,  16.3399, -10.2525]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.0979979038238525\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(5.8517, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7500, 11.1000, 12.7458],\n",
      "        [17.4327, 11.6176, 12.8005],\n",
      "        [17.1041, 11.6619, 12.6898],\n",
      "        [17.0598, 11.3250, 12.7734],\n",
      "        [17.3760, 10.7114, 12.4977],\n",
      "        [17.3757, 11.6609, 12.7136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0416, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4598,  15.9539, -10.6223],\n",
      "        [-14.2524,  15.7696, -10.4829],\n",
      "        [-14.6099,  16.3276, -10.5713],\n",
      "        [-14.8640,  16.5934, -10.8418],\n",
      "        [-14.4340,  16.4163, -10.7946],\n",
      "        [-14.9297,  16.6295, -10.7953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7500,  11.1000,  12.7458, -14.4598,  15.9539, -10.6223],\n",
      "        [ 17.4327,  11.6176,  12.8005, -14.2524,  15.7696, -10.4829],\n",
      "        [ 17.1041,  11.6619,  12.6898, -14.6099,  16.3276, -10.5713],\n",
      "        [ 17.0598,  11.3250,  12.7734, -14.8640,  16.5934, -10.8418],\n",
      "        [ 17.3760,  10.7114,  12.4977, -14.4340,  16.4163, -10.7946],\n",
      "        [ 17.3757,  11.6609,  12.7136, -14.9297,  16.6295, -10.7953]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.097714900970459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4201, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.5804, 11.3985, 12.7551],\n",
      "        [17.0971, 11.3499, 12.5305],\n",
      "        [16.9997, 10.9723, 13.0173],\n",
      "        [17.3584, 11.5189, 12.8378],\n",
      "        [16.8501, 11.4790, 12.7251],\n",
      "        [17.3433, 11.4348, 12.8326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9609, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7061,  16.0422, -10.9891],\n",
      "        [-14.6973,  16.2656, -10.7167],\n",
      "        [-14.4870,  16.0905, -10.6635],\n",
      "        [-14.6696,  15.8891, -10.3619],\n",
      "        [-14.8029,  16.4705, -10.4073],\n",
      "        [-14.5233,  16.3735, -10.8114]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.5804,  11.3985,  12.7551, -14.7061,  16.0422, -10.9891],\n",
      "        [ 17.0971,  11.3499,  12.5305, -14.6973,  16.2656, -10.7167],\n",
      "        [ 16.9997,  10.9723,  13.0173, -14.4870,  16.0905, -10.6635],\n",
      "        [ 17.3584,  11.5189,  12.8378, -14.6696,  15.8891, -10.3619],\n",
      "        [ 16.8501,  11.4790,  12.7251, -14.8029,  16.4705, -10.4073],\n",
      "        [ 17.3433,  11.4348,  12.8326, -14.5233,  16.3735, -10.8114]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.110095739364624\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2246, 11.2445, 12.3301],\n",
      "        [16.8210, 10.9990, 12.6038],\n",
      "        [17.1802, 11.2928, 12.7256],\n",
      "        [17.2382, 11.3907, 12.9810],\n",
      "        [17.5304, 11.1582, 12.7266],\n",
      "        [16.9026, 10.9779, 12.5960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6682,  16.1483, -10.8195],\n",
      "        [-14.7805,  16.2083, -10.6538],\n",
      "        [-14.7769,  16.2055, -10.5883],\n",
      "        [-15.0938,  16.3266, -10.8896],\n",
      "        [-14.9555,  16.5526, -10.6783],\n",
      "        [-14.8183,  16.0553, -10.8898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2246,  11.2445,  12.3301, -14.6682,  16.1483, -10.8195],\n",
      "        [ 16.8210,  10.9990,  12.6038, -14.7805,  16.2083, -10.6538],\n",
      "        [ 17.1802,  11.2928,  12.7256, -14.7769,  16.2055, -10.5883],\n",
      "        [ 17.2382,  11.3907,  12.9810, -15.0938,  16.3266, -10.8896],\n",
      "        [ 17.5304,  11.1582,  12.7266, -14.9555,  16.5526, -10.6783],\n",
      "        [ 16.9026,  10.9779,  12.5960, -14.8183,  16.0553, -10.8898]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.120328187942505\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7506, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1031, 11.0720, 12.6667],\n",
      "        [16.6669, 10.8444, 12.5038],\n",
      "        [17.3970, 11.5255, 12.8163],\n",
      "        [16.9722, 11.4487, 12.6785],\n",
      "        [16.9640, 10.9878, 12.7035],\n",
      "        [17.1775, 11.0482, 12.6980]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9988,  16.3106, -11.1637],\n",
      "        [-15.0950,  16.2957, -10.5082],\n",
      "        [-14.9352,  16.2343, -10.6253],\n",
      "        [-14.5951,  16.2627, -11.0497],\n",
      "        [-15.0187,  15.8895, -10.7460],\n",
      "        [-15.3119,  16.6978, -11.1197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1031,  11.0720,  12.6667, -14.9988,  16.3106, -11.1637],\n",
      "        [ 16.6669,  10.8444,  12.5038, -15.0950,  16.2957, -10.5082],\n",
      "        [ 17.3970,  11.5255,  12.8163, -14.9352,  16.2343, -10.6253],\n",
      "        [ 16.9722,  11.4487,  12.6785, -14.5951,  16.2627, -11.0497],\n",
      "        [ 16.9640,  10.9878,  12.7035, -15.0187,  15.8895, -10.7460],\n",
      "        [ 17.1775,  11.0482,  12.6980, -15.3119,  16.6978, -11.1197]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.138532876968384\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7080, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7277, 11.0367, 12.5857],\n",
      "        [17.0339, 10.7767, 13.0386],\n",
      "        [17.1172, 11.3709, 12.5164],\n",
      "        [17.1844, 10.9791, 12.9875],\n",
      "        [16.9904, 11.2654, 12.9128],\n",
      "        [17.1866, 11.2681, 12.7009]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9813, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9538,  16.3177, -10.9202],\n",
      "        [-15.0705,  16.1193, -10.1561],\n",
      "        [-14.5965,  16.6310, -10.8515],\n",
      "        [-14.6272,  15.8596, -10.7769],\n",
      "        [-14.8049,  16.4871, -10.7923],\n",
      "        [-14.9393,  16.6707, -10.6237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7277,  11.0367,  12.5857, -14.9538,  16.3177, -10.9202],\n",
      "        [ 17.0339,  10.7767,  13.0386, -15.0705,  16.1193, -10.1561],\n",
      "        [ 17.1172,  11.3709,  12.5164, -14.5965,  16.6310, -10.8515],\n",
      "        [ 17.1844,  10.9791,  12.9875, -14.6272,  15.8596, -10.7769],\n",
      "        [ 16.9904,  11.2654,  12.9128, -14.8049,  16.4871, -10.7923],\n",
      "        [ 17.1866,  11.2681,  12.7009, -14.9393,  16.6707, -10.6237]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.117154359817505\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1392, 11.0761, 12.4823],\n",
      "        [16.7575, 11.1031, 12.6408],\n",
      "        [17.3388, 11.1428, 12.7251],\n",
      "        [16.8035, 11.1904, 12.9833],\n",
      "        [17.3686, 11.2694, 12.5742],\n",
      "        [16.9063, 11.2744, 13.0829]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9236, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.3806,  16.1882, -10.2421],\n",
      "        [-15.1208,  16.2533, -10.5235],\n",
      "        [-14.4795,  16.1850, -10.1900],\n",
      "        [-14.5931,  16.0073, -10.5024],\n",
      "        [-15.2404,  16.3811, -11.1220],\n",
      "        [-14.6264,  16.2361, -10.8252]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1392,  11.0761,  12.4823, -14.3806,  16.1882, -10.2421],\n",
      "        [ 16.7575,  11.1031,  12.6408, -15.1208,  16.2533, -10.5235],\n",
      "        [ 17.3388,  11.1428,  12.7251, -14.4795,  16.1850, -10.1900],\n",
      "        [ 16.8035,  11.1904,  12.9833, -14.5931,  16.0073, -10.5024],\n",
      "        [ 17.3686,  11.2694,  12.5742, -15.2404,  16.3811, -11.1220],\n",
      "        [ 16.9063,  11.2744,  13.0829, -14.6264,  16.2361, -10.8252]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1088833808898926\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7162, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9412, 10.8659, 12.6905],\n",
      "        [17.2844, 11.2104, 12.6030],\n",
      "        [17.1810, 11.2947, 12.9851],\n",
      "        [17.1574, 11.4291, 12.7706],\n",
      "        [16.6539, 10.9817, 12.5736],\n",
      "        [16.8966, 11.0270, 12.8565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2439, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2055,  16.5049, -10.8441],\n",
      "        [-15.0502,  16.2993, -10.7966],\n",
      "        [-14.5291,  16.5068, -10.4879],\n",
      "        [-15.1245,  16.7749, -10.8236],\n",
      "        [-15.0306,  16.4363, -10.9572],\n",
      "        [-15.2578,  16.6431, -10.9417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9412,  10.8659,  12.6905, -15.2055,  16.5049, -10.8441],\n",
      "        [ 17.2844,  11.2104,  12.6030, -15.0502,  16.2993, -10.7966],\n",
      "        [ 17.1810,  11.2947,  12.9851, -14.5291,  16.5068, -10.4879],\n",
      "        [ 17.1574,  11.4291,  12.7706, -15.1245,  16.7749, -10.8236],\n",
      "        [ 16.6539,  10.9817,  12.5736, -15.0306,  16.4363, -10.9572],\n",
      "        [ 16.8966,  11.0270,  12.8565, -15.2578,  16.6431, -10.9417]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1362364292144775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3842, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9826, 11.4367, 12.7192],\n",
      "        [16.8660, 11.4030, 12.7098],\n",
      "        [17.0321, 11.3115, 12.9954],\n",
      "        [17.3843, 11.2003, 13.3126],\n",
      "        [16.9000, 10.9692, 12.3830],\n",
      "        [16.5896, 11.2181, 12.5438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9437,  16.2516, -10.9569],\n",
      "        [-14.7464,  16.4567, -10.9486],\n",
      "        [-14.4871,  16.6037, -10.6105],\n",
      "        [-14.9675,  16.4680, -10.9177],\n",
      "        [-15.0593,  16.3151, -10.7841],\n",
      "        [-14.6968,  16.1396, -10.5731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9826,  11.4367,  12.7192, -14.9437,  16.2516, -10.9569],\n",
      "        [ 16.8660,  11.4030,  12.7098, -14.7464,  16.4567, -10.9486],\n",
      "        [ 17.0321,  11.3115,  12.9954, -14.4871,  16.6037, -10.6105],\n",
      "        [ 17.3843,  11.2003,  13.3126, -14.9675,  16.4680, -10.9177],\n",
      "        [ 16.9000,  10.9692,  12.3830, -15.0593,  16.3151, -10.7841],\n",
      "        [ 16.5896,  11.2181,  12.5438, -14.6968,  16.1396, -10.5731]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.1418581008911133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2716, 11.7973, 12.8975],\n",
      "        [17.0175, 11.1573, 12.6402],\n",
      "        [16.7941, 11.3130, 12.6211],\n",
      "        [17.0844, 11.5904, 13.0371],\n",
      "        [17.1231, 11.3870, 12.8618],\n",
      "        [17.8812, 11.7240, 12.9962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9569, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7118,  15.8989, -10.1875],\n",
      "        [-15.0558,  15.9734, -10.3903],\n",
      "        [-14.5054,  15.9332, -10.4704],\n",
      "        [-14.8905,  16.4208, -10.8228],\n",
      "        [-15.1178,  16.4330, -11.0140],\n",
      "        [-15.0022,  16.2370, -10.7327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2716,  11.7973,  12.8975, -14.7118,  15.8989, -10.1875],\n",
      "        [ 17.0175,  11.1573,  12.6402, -15.0558,  15.9734, -10.3903],\n",
      "        [ 16.7941,  11.3130,  12.6211, -14.5054,  15.9332, -10.4704],\n",
      "        [ 17.0844,  11.5904,  13.0371, -14.8905,  16.4208, -10.8228],\n",
      "        [ 17.1231,  11.3870,  12.8618, -15.1178,  16.4330, -11.0140],\n",
      "        [ 17.8812,  11.7240,  12.9962, -15.0022,  16.2370, -10.7327]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.144566297531128\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4935, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3097, 11.5051, 12.6709],\n",
      "        [17.0719, 11.1371, 12.6941],\n",
      "        [17.1631, 11.1309, 12.4882],\n",
      "        [16.8366, 10.8235, 12.5259],\n",
      "        [17.0995, 11.2876, 12.8608],\n",
      "        [17.1565, 11.1215, 12.4475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7335,  16.4166, -10.5390],\n",
      "        [-15.1894,  16.8830, -11.1580],\n",
      "        [-14.5642,  16.8828, -11.0563],\n",
      "        [-14.8769,  16.5580, -10.7828],\n",
      "        [-15.0907,  16.9295, -11.0758],\n",
      "        [-14.9200,  16.5144, -11.0373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3097,  11.5051,  12.6709, -14.7335,  16.4166, -10.5390],\n",
      "        [ 17.0719,  11.1371,  12.6941, -15.1894,  16.8830, -11.1580],\n",
      "        [ 17.1631,  11.1309,  12.4882, -14.5642,  16.8828, -11.0563],\n",
      "        [ 16.8366,  10.8235,  12.5259, -14.8769,  16.5580, -10.7828],\n",
      "        [ 17.0995,  11.2876,  12.8608, -15.0907,  16.9295, -11.0758],\n",
      "        [ 17.1565,  11.1215,  12.4475, -14.9200,  16.5144, -11.0373]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.151129722595215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5958, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.6940, 11.1807, 12.6502],\n",
      "        [16.6941, 11.0271, 12.4749],\n",
      "        [16.9056, 11.1405, 12.6581],\n",
      "        [17.1443, 11.4490, 12.7850],\n",
      "        [17.0741, 11.1671, 12.6460],\n",
      "        [16.9412, 11.0737, 12.2354]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.8208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1575,  16.6634, -10.8615],\n",
      "        [-15.0420,  16.4954, -10.8778],\n",
      "        [-15.3144,  16.3476, -11.0506],\n",
      "        [-15.0462,  16.5114, -10.7459],\n",
      "        [-15.0344,  16.5122, -10.9899],\n",
      "        [-14.9286,  16.3567, -10.5287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.6940,  11.1807,  12.6502, -15.1575,  16.6634, -10.8615],\n",
      "        [ 16.6941,  11.0271,  12.4749, -15.0420,  16.4954, -10.8778],\n",
      "        [ 16.9056,  11.1405,  12.6581, -15.3144,  16.3476, -11.0506],\n",
      "        [ 17.1443,  11.4490,  12.7850, -15.0462,  16.5114, -10.7459],\n",
      "        [ 17.0741,  11.1671,  12.6460, -15.0344,  16.5122, -10.9899],\n",
      "        [ 16.9412,  11.0737,  12.2354, -14.9286,  16.3567, -10.5287]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.13856840133667\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1423, 11.5621, 12.9197],\n",
      "        [16.9449, 11.0193, 12.4458],\n",
      "        [16.7283, 11.3714, 12.4394],\n",
      "        [17.2763, 11.3857, 12.8127],\n",
      "        [17.3274, 11.3997, 12.9250],\n",
      "        [17.1186, 11.2130, 12.5470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3611,  16.6741, -10.9317],\n",
      "        [-15.4201,  16.6374, -11.1964],\n",
      "        [-14.6177,  16.3263, -10.3911],\n",
      "        [-14.6891,  16.4654, -10.4711],\n",
      "        [-15.1393,  16.3933, -10.8759],\n",
      "        [-14.8972,  16.4292, -10.3487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1423,  11.5621,  12.9197, -15.3611,  16.6741, -10.9317],\n",
      "        [ 16.9449,  11.0193,  12.4458, -15.4201,  16.6374, -11.1964],\n",
      "        [ 16.7283,  11.3714,  12.4394, -14.6177,  16.3263, -10.3911],\n",
      "        [ 17.2763,  11.3857,  12.8127, -14.6891,  16.4654, -10.4711],\n",
      "        [ 17.3274,  11.3997,  12.9250, -15.1393,  16.3933, -10.8759],\n",
      "        [ 17.1186,  11.2130,  12.5470, -14.8972,  16.4292, -10.3487]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1794698238372803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5824, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2925, 11.1628, 12.5489],\n",
      "        [17.1616, 11.1433, 12.6063],\n",
      "        [17.3103, 11.3292, 12.6108],\n",
      "        [16.9817, 11.0850, 13.0578],\n",
      "        [17.2715, 11.1137, 12.7326],\n",
      "        [17.0231, 11.5195, 12.5734]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(9.6407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.4906,  16.5960, -10.7401],\n",
      "        [-14.7529,  16.0252, -10.7308],\n",
      "        [-15.0500,  16.8454, -10.7333],\n",
      "        [-14.9889,  16.5557, -10.6241],\n",
      "        [-14.9213,  16.3616, -10.7259],\n",
      "        [-14.5811,  15.8087, -10.4910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2925,  11.1628,  12.5489, -14.4906,  16.5960, -10.7401],\n",
      "        [ 17.1616,  11.1433,  12.6063, -14.7529,  16.0252, -10.7308],\n",
      "        [ 17.3103,  11.3292,  12.6108, -15.0500,  16.8454, -10.7333],\n",
      "        [ 16.9817,  11.0850,  13.0578, -14.9889,  16.5557, -10.6241],\n",
      "        [ 17.2715,  11.1137,  12.7326, -14.9213,  16.3616, -10.7259],\n",
      "        [ 17.0231,  11.5195,  12.5734, -14.5811,  15.8087, -10.4910]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.144780397415161\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7161, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8647, 11.2152, 12.8566],\n",
      "        [17.1666, 11.1831, 12.8172],\n",
      "        [17.5397, 11.3188, 13.0926],\n",
      "        [17.1930, 11.0918, 12.7079],\n",
      "        [17.2510, 11.0966, 12.9716],\n",
      "        [17.2281, 11.5180, 13.1048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5292, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1126,  16.4453, -10.8760],\n",
      "        [-14.9695,  16.5864, -10.7937],\n",
      "        [-14.9566,  16.2873, -10.7456],\n",
      "        [-14.6945,  16.5900, -10.8744],\n",
      "        [-14.9701,  16.0938, -10.7622],\n",
      "        [-14.8149,  16.0687, -10.7389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8647,  11.2152,  12.8566, -15.1126,  16.4453, -10.8760],\n",
      "        [ 17.1666,  11.1831,  12.8172, -14.9695,  16.5864, -10.7937],\n",
      "        [ 17.5397,  11.3188,  13.0926, -14.9566,  16.2873, -10.7456],\n",
      "        [ 17.1930,  11.0918,  12.7079, -14.6945,  16.5900, -10.8744],\n",
      "        [ 17.2510,  11.0966,  12.9716, -14.9701,  16.0938, -10.7622],\n",
      "        [ 17.2281,  11.5180,  13.1048, -14.8149,  16.0687, -10.7389]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.150310516357422\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7159, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1350, 11.1058, 12.7864],\n",
      "        [17.0433, 11.2869, 13.0138],\n",
      "        [16.7881, 11.0393, 12.7057],\n",
      "        [17.3049, 11.2651, 12.9554],\n",
      "        [17.3079, 11.4684, 12.8763],\n",
      "        [17.1261, 11.1124, 12.5649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6900, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2556,  16.6271, -10.7980],\n",
      "        [-14.7871,  16.8592, -10.8279],\n",
      "        [-14.9500,  16.6178, -11.2847],\n",
      "        [-14.5484,  15.9664, -10.9043],\n",
      "        [-15.1142,  16.4539, -10.7650],\n",
      "        [-14.8612,  16.5565, -10.5931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1350,  11.1058,  12.7864, -15.2556,  16.6271, -10.7980],\n",
      "        [ 17.0433,  11.2869,  13.0138, -14.7871,  16.8592, -10.8279],\n",
      "        [ 16.7881,  11.0393,  12.7057, -14.9500,  16.6178, -11.2847],\n",
      "        [ 17.3049,  11.2651,  12.9554, -14.5484,  15.9664, -10.9043],\n",
      "        [ 17.3079,  11.4684,  12.8763, -15.1142,  16.4539, -10.7650],\n",
      "        [ 17.1261,  11.1124,  12.5649, -14.8612,  16.5565, -10.5931]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1640398502349854\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3637, 11.3762, 12.7417],\n",
      "        [16.8114, 11.3168, 12.5856],\n",
      "        [17.7186, 11.7353, 13.1263],\n",
      "        [17.3969, 11.2076, 13.0908],\n",
      "        [17.3150, 11.1966, 12.8733],\n",
      "        [17.0705, 10.9357, 12.4066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4967, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1376,  16.9049, -11.1101],\n",
      "        [-15.3683,  16.5021, -11.0734],\n",
      "        [-14.9747,  16.4839, -10.6210],\n",
      "        [-14.9286,  16.1622, -10.3379],\n",
      "        [-15.3509,  16.6167, -11.1123],\n",
      "        [-14.8026,  16.3058, -10.9822]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3637,  11.3762,  12.7417, -15.1376,  16.9049, -11.1101],\n",
      "        [ 16.8114,  11.3168,  12.5856, -15.3683,  16.5021, -11.0734],\n",
      "        [ 17.7186,  11.7353,  13.1263, -14.9747,  16.4839, -10.6210],\n",
      "        [ 17.3969,  11.2076,  13.0908, -14.9286,  16.1622, -10.3379],\n",
      "        [ 17.3150,  11.1966,  12.8733, -15.3509,  16.6167, -11.1123],\n",
      "        [ 17.0705,  10.9357,  12.4066, -14.8026,  16.3058, -10.9822]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1867012977600098\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.7538, 11.0769, 12.8859],\n",
      "        [17.4087, 11.1792, 12.5215],\n",
      "        [16.6972, 11.0824, 12.6697],\n",
      "        [17.5662, 11.1907, 12.7874],\n",
      "        [16.8987, 11.4854, 12.7214],\n",
      "        [17.2787, 11.4141, 12.8330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9429,  16.6257, -10.9262],\n",
      "        [-15.0519,  16.3906, -10.4458],\n",
      "        [-14.8731,  16.4579, -10.6121],\n",
      "        [-15.1113,  16.5547, -11.0731],\n",
      "        [-14.6516,  15.9931, -10.4206],\n",
      "        [-15.3557,  16.4630, -10.7437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.7538,  11.0769,  12.8859, -14.9429,  16.6257, -10.9262],\n",
      "        [ 17.4087,  11.1792,  12.5215, -15.0519,  16.3906, -10.4458],\n",
      "        [ 16.6972,  11.0824,  12.6697, -14.8731,  16.4579, -10.6121],\n",
      "        [ 17.5662,  11.1907,  12.7874, -15.1113,  16.5547, -11.0731],\n",
      "        [ 16.8987,  11.4854,  12.7214, -14.6516,  15.9931, -10.4206],\n",
      "        [ 17.2787,  11.4141,  12.8330, -15.3557,  16.4630, -10.7437]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.148545980453491\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3843, 11.2755, 13.2431],\n",
      "        [16.9930, 11.7486, 13.0232],\n",
      "        [17.2239, 11.8525, 13.1108],\n",
      "        [16.9935, 11.0748, 13.0173],\n",
      "        [17.4868, 11.6711, 13.4491],\n",
      "        [17.5120, 11.4513, 13.2405]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.1052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8058,  16.5093, -11.4244],\n",
      "        [-15.1951,  16.6686, -10.8661],\n",
      "        [-14.8391,  15.9320, -10.2925],\n",
      "        [-15.0192,  16.4543, -10.9712],\n",
      "        [-15.3009,  16.4075, -11.2583],\n",
      "        [-14.5903,  16.2890, -10.5353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3843,  11.2755,  13.2431, -14.8058,  16.5093, -11.4244],\n",
      "        [ 16.9930,  11.7486,  13.0232, -15.1951,  16.6686, -10.8661],\n",
      "        [ 17.2239,  11.8525,  13.1108, -14.8391,  15.9320, -10.2925],\n",
      "        [ 16.9935,  11.0748,  13.0173, -15.0192,  16.4543, -10.9712],\n",
      "        [ 17.4868,  11.6711,  13.4491, -15.3009,  16.4075, -11.2583],\n",
      "        [ 17.5120,  11.4513,  13.2405, -14.5903,  16.2890, -10.5353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1918833255767822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3071, 11.6625, 13.0541],\n",
      "        [17.3086, 11.5047, 12.7155],\n",
      "        [17.5511, 11.7015, 13.0002],\n",
      "        [17.8205, 11.7301, 12.9595],\n",
      "        [16.9603, 11.3628, 12.7716],\n",
      "        [17.2109, 11.2761, 12.8356]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.5717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4026,  16.7647, -11.2075],\n",
      "        [-15.2277,  16.5667, -11.1659],\n",
      "        [-14.8485,  16.4163, -10.7119],\n",
      "        [-14.7510,  16.2183, -10.3714],\n",
      "        [-15.1348,  16.7880, -11.4158],\n",
      "        [-15.0381,  16.6736, -11.2785]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3071,  11.6625,  13.0541, -15.4026,  16.7647, -11.2075],\n",
      "        [ 17.3086,  11.5047,  12.7155, -15.2277,  16.5667, -11.1659],\n",
      "        [ 17.5511,  11.7015,  13.0002, -14.8485,  16.4163, -10.7119],\n",
      "        [ 17.8205,  11.7301,  12.9595, -14.7510,  16.2183, -10.3714],\n",
      "        [ 16.9603,  11.3628,  12.7716, -15.1348,  16.7880, -11.4158],\n",
      "        [ 17.2109,  11.2761,  12.8356, -15.0381,  16.6736, -11.2785]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2069895267486572\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0819, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8701, 11.2149, 12.4642],\n",
      "        [17.5467, 11.5063, 12.6707],\n",
      "        [17.6759, 11.6434, 12.9187],\n",
      "        [16.9394, 11.3708, 12.7780],\n",
      "        [17.2359, 11.5652, 12.7958],\n",
      "        [16.5983, 11.1411, 12.6559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.6868, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.6104,  16.8186, -10.7996],\n",
      "        [-14.9429,  16.5003, -11.1883],\n",
      "        [-14.6749,  16.6679, -10.9494],\n",
      "        [-14.9528,  16.5781, -10.9291],\n",
      "        [-15.0935,  16.6084, -10.9410],\n",
      "        [-15.2656,  16.7403, -10.7881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8701,  11.2149,  12.4642, -14.6104,  16.8186, -10.7996],\n",
      "        [ 17.5467,  11.5063,  12.6707, -14.9429,  16.5003, -11.1883],\n",
      "        [ 17.6759,  11.6434,  12.9187, -14.6749,  16.6679, -10.9494],\n",
      "        [ 16.9394,  11.3708,  12.7780, -14.9528,  16.5781, -10.9291],\n",
      "        [ 17.2359,  11.5652,  12.7958, -15.0935,  16.6084, -10.9410],\n",
      "        [ 16.5983,  11.1411,  12.6559, -15.2656,  16.7403, -10.7881]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.1420135498046875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6599, 11.4256, 13.0954],\n",
      "        [17.2319, 11.3752, 12.8996],\n",
      "        [17.4840, 11.7201, 12.6917],\n",
      "        [16.9425, 11.4028, 12.6862],\n",
      "        [17.4089, 11.2949, 13.0242],\n",
      "        [17.3787, 11.2789, 12.9883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1537,  16.6070, -11.2298],\n",
      "        [-14.6052,  16.3692, -10.4031],\n",
      "        [-15.2620,  16.3481, -10.7555],\n",
      "        [-14.7069,  16.4485, -10.6070],\n",
      "        [-15.1365,  16.3545, -10.8522],\n",
      "        [-14.8444,  16.2372, -10.9392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6599,  11.4256,  13.0954, -15.1537,  16.6070, -11.2298],\n",
      "        [ 17.2319,  11.3752,  12.8996, -14.6052,  16.3692, -10.4031],\n",
      "        [ 17.4840,  11.7201,  12.6917, -15.2620,  16.3481, -10.7555],\n",
      "        [ 16.9425,  11.4028,  12.6862, -14.7069,  16.4485, -10.6070],\n",
      "        [ 17.4089,  11.2949,  13.0242, -15.1365,  16.3545, -10.8522],\n",
      "        [ 17.3787,  11.2789,  12.9883, -14.8444,  16.2372, -10.9392]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.211686849594116\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5789, 11.3236, 12.8167],\n",
      "        [17.4157, 11.3379, 12.6396],\n",
      "        [16.4730, 10.9939, 12.7933],\n",
      "        [17.1048, 11.2386, 13.0084],\n",
      "        [17.0049, 10.9581, 13.0748],\n",
      "        [17.0391, 11.4406, 12.9419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1602,  16.6430, -10.9805],\n",
      "        [-14.8495,  16.2283, -10.6152],\n",
      "        [-15.1845,  16.2638, -10.6176],\n",
      "        [-14.5571,  16.4571, -10.6931],\n",
      "        [-14.7523,  16.3414, -11.0314],\n",
      "        [-14.8800,  16.5297, -10.6905]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5789,  11.3236,  12.8167, -15.1602,  16.6430, -10.9805],\n",
      "        [ 17.4157,  11.3379,  12.6396, -14.8495,  16.2283, -10.6152],\n",
      "        [ 16.4730,  10.9939,  12.7933, -15.1845,  16.2638, -10.6176],\n",
      "        [ 17.1048,  11.2386,  13.0084, -14.5571,  16.4571, -10.6931],\n",
      "        [ 17.0049,  10.9581,  13.0748, -14.7523,  16.3414, -11.0314],\n",
      "        [ 17.0391,  11.4406,  12.9419, -14.8800,  16.5297, -10.6905]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.196225166320801\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0107, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1830, 11.2706, 12.8460],\n",
      "        [17.5069, 11.2686, 13.1381],\n",
      "        [17.0812, 11.5432, 12.6708],\n",
      "        [17.5523, 11.4325, 12.7962],\n",
      "        [17.1366, 11.2800, 12.7474],\n",
      "        [17.0713, 11.4300, 12.6947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4121,  16.7621, -10.9387],\n",
      "        [-15.5770,  16.7646, -11.2591],\n",
      "        [-15.3870,  16.7066, -11.0673],\n",
      "        [-14.9748,  16.5915, -11.0691],\n",
      "        [-14.9766,  16.7063, -10.9478],\n",
      "        [-15.2972,  16.9408, -11.1964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1830,  11.2706,  12.8460, -15.4121,  16.7621, -10.9387],\n",
      "        [ 17.5069,  11.2686,  13.1381, -15.5770,  16.7646, -11.2591],\n",
      "        [ 17.0812,  11.5432,  12.6708, -15.3870,  16.7066, -11.0673],\n",
      "        [ 17.5523,  11.4325,  12.7962, -14.9748,  16.5915, -11.0691],\n",
      "        [ 17.1366,  11.2800,  12.7474, -14.9766,  16.7063, -10.9478],\n",
      "        [ 17.0713,  11.4300,  12.6947, -15.2972,  16.9408, -11.1964]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1883840560913086\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.8513, 11.1089, 13.0437],\n",
      "        [16.6834, 10.7977, 12.6387],\n",
      "        [17.3505, 11.5056, 13.0615],\n",
      "        [17.1887, 10.6246, 12.8338],\n",
      "        [17.4462, 11.2396, 13.0307],\n",
      "        [17.0681, 11.7115, 12.7168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1755,  16.3022, -10.5961],\n",
      "        [-15.3662,  16.6276, -10.9430],\n",
      "        [-15.0165,  16.8068, -11.0875],\n",
      "        [-15.0668,  15.8048, -10.9328],\n",
      "        [-15.2553,  16.8908, -11.0607],\n",
      "        [-15.1313,  16.6975, -11.0746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.8513,  11.1089,  13.0437, -15.1755,  16.3022, -10.5961],\n",
      "        [ 16.6834,  10.7977,  12.6387, -15.3662,  16.6276, -10.9430],\n",
      "        [ 17.3505,  11.5056,  13.0615, -15.0165,  16.8068, -11.0875],\n",
      "        [ 17.1887,  10.6246,  12.8338, -15.0668,  15.8048, -10.9328],\n",
      "        [ 17.4462,  11.2396,  13.0307, -15.2553,  16.8908, -11.0607],\n",
      "        [ 17.0681,  11.7115,  12.7168, -15.1313,  16.6975, -11.0746]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1587941646575928\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6961, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5447, 11.6231, 12.7958],\n",
      "        [17.2094, 11.5707, 12.7518],\n",
      "        [17.2300, 11.5992, 12.8751],\n",
      "        [16.9610, 11.2594, 12.7249],\n",
      "        [17.6130, 11.7884, 13.3099],\n",
      "        [17.2382, 11.3334, 12.9174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.4045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2651,  16.5439, -10.9727],\n",
      "        [-15.4011,  16.7968, -11.3551],\n",
      "        [-14.8349,  16.3678, -10.7308],\n",
      "        [-14.8828,  16.3938, -10.6410],\n",
      "        [-14.9637,  16.4222, -10.8683],\n",
      "        [-15.0364,  16.7211, -10.8943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5447,  11.6231,  12.7958, -15.2651,  16.5439, -10.9727],\n",
      "        [ 17.2094,  11.5707,  12.7518, -15.4011,  16.7968, -11.3551],\n",
      "        [ 17.2300,  11.5992,  12.8751, -14.8349,  16.3678, -10.7308],\n",
      "        [ 16.9610,  11.2594,  12.7249, -14.8828,  16.3938, -10.6410],\n",
      "        [ 17.6130,  11.7884,  13.3099, -14.9637,  16.4222, -10.8683],\n",
      "        [ 17.2382,  11.3334,  12.9174, -15.0364,  16.7211, -10.8943]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2034480571746826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6446, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1414, 11.4626, 12.8089],\n",
      "        [17.0670, 11.0192, 12.7822],\n",
      "        [16.7386, 11.6583, 12.3171],\n",
      "        [17.3245, 11.0583, 12.7890],\n",
      "        [16.8939, 11.3459, 13.2266],\n",
      "        [17.3059, 11.4291, 12.7642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1558, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.7853,  16.6207, -11.0999],\n",
      "        [-14.9772,  16.4072, -10.6072],\n",
      "        [-14.7950,  16.2761, -11.0267],\n",
      "        [-15.1359,  16.5654, -11.1941],\n",
      "        [-15.2456,  16.4222, -11.2250],\n",
      "        [-14.8863,  16.4858, -10.9008]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1414,  11.4626,  12.8089, -14.7853,  16.6207, -11.0999],\n",
      "        [ 17.0670,  11.0192,  12.7822, -14.9772,  16.4072, -10.6072],\n",
      "        [ 16.7386,  11.6583,  12.3171, -14.7950,  16.2761, -11.0267],\n",
      "        [ 17.3245,  11.0583,  12.7890, -15.1359,  16.5654, -11.1941],\n",
      "        [ 16.8939,  11.3459,  13.2266, -15.2456,  16.4222, -11.2250],\n",
      "        [ 17.3059,  11.4291,  12.7642, -14.8863,  16.4858, -10.9008]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.178814172744751\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4123, 11.3860, 13.3645],\n",
      "        [17.3407, 11.0191, 12.5495],\n",
      "        [17.2276, 11.5302, 12.8582],\n",
      "        [16.8211, 11.5287, 12.9827],\n",
      "        [17.3802, 11.2771, 12.9653],\n",
      "        [17.2992, 11.6754, 13.2305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.0197,  16.2900, -10.7960],\n",
      "        [-15.2161,  16.6816, -11.2733],\n",
      "        [-14.7583,  16.5639, -11.0053],\n",
      "        [-14.8424,  16.0197, -10.6078],\n",
      "        [-14.9445,  16.5371, -11.0217],\n",
      "        [-15.4009,  16.9222, -11.4828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4123,  11.3860,  13.3645, -15.0197,  16.2900, -10.7960],\n",
      "        [ 17.3407,  11.0191,  12.5495, -15.2161,  16.6816, -11.2733],\n",
      "        [ 17.2276,  11.5302,  12.8582, -14.7583,  16.5639, -11.0053],\n",
      "        [ 16.8211,  11.5287,  12.9827, -14.8424,  16.0197, -10.6078],\n",
      "        [ 17.3802,  11.2771,  12.9653, -14.9445,  16.5371, -11.0217],\n",
      "        [ 17.2992,  11.6754,  13.2305, -15.4009,  16.9222, -11.4828]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2000832557678223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2045, 11.4545, 13.1304],\n",
      "        [17.1251, 11.0392, 12.9052],\n",
      "        [17.2594, 10.9743, 12.2520],\n",
      "        [17.3087, 11.7005, 13.0717],\n",
      "        [16.5699, 11.2718, 12.5952],\n",
      "        [17.5302, 11.7584, 13.0562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0239, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1089,  16.5695, -11.4123],\n",
      "        [-15.0846,  16.3763, -10.9147],\n",
      "        [-15.0715,  16.6470, -11.1547],\n",
      "        [-14.6499,  16.7063, -10.9775],\n",
      "        [-14.7363,  16.6204, -10.8368],\n",
      "        [-14.8859,  16.6571, -10.8720]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2045,  11.4545,  13.1304, -15.1089,  16.5695, -11.4123],\n",
      "        [ 17.1251,  11.0392,  12.9052, -15.0846,  16.3763, -10.9147],\n",
      "        [ 17.2594,  10.9743,  12.2520, -15.0715,  16.6470, -11.1547],\n",
      "        [ 17.3087,  11.7005,  13.0717, -14.6499,  16.7063, -10.9775],\n",
      "        [ 16.5699,  11.2718,  12.5952, -14.7363,  16.6204, -10.8368],\n",
      "        [ 17.5302,  11.7584,  13.0562, -14.8859,  16.6571, -10.8720]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2033982276916504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5350, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1964, 11.8486, 12.9102],\n",
      "        [17.1564, 11.5487, 12.7079],\n",
      "        [17.4217, 11.1606, 12.6001],\n",
      "        [17.3295, 11.3220, 13.3607],\n",
      "        [17.2574, 11.6884, 13.1669],\n",
      "        [17.2767, 11.2297, 13.0722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2605,  16.7572, -11.2834],\n",
      "        [-15.2065,  16.4374, -10.9330],\n",
      "        [-15.1543,  16.5604, -10.8878],\n",
      "        [-15.4141,  16.7006, -11.3418],\n",
      "        [-14.8267,  16.2296, -10.7287],\n",
      "        [-15.3141,  16.4655, -10.8610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1964,  11.8486,  12.9102, -15.2605,  16.7572, -11.2834],\n",
      "        [ 17.1564,  11.5487,  12.7079, -15.2065,  16.4374, -10.9330],\n",
      "        [ 17.4217,  11.1606,  12.6001, -15.1543,  16.5604, -10.8878],\n",
      "        [ 17.3295,  11.3220,  13.3607, -15.4141,  16.7006, -11.3418],\n",
      "        [ 17.2574,  11.6884,  13.1669, -14.8267,  16.2296, -10.7287],\n",
      "        [ 17.2767,  11.2297,  13.0722, -15.3141,  16.4655, -10.8610]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2110178470611572\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3335, 11.4998, 13.0874],\n",
      "        [16.6943, 10.6865, 12.5834],\n",
      "        [17.5055, 11.4814, 12.7427],\n",
      "        [17.2474, 11.4673, 13.3176],\n",
      "        [17.2482, 11.2302, 12.9482],\n",
      "        [17.5108, 11.6136, 13.1694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2721,  16.5001, -10.8893],\n",
      "        [-14.7258,  16.6669, -10.9526],\n",
      "        [-15.1942,  16.6065, -11.1260],\n",
      "        [-15.1569,  17.1187, -10.9850],\n",
      "        [-15.2557,  16.7002, -10.7869],\n",
      "        [-15.3516,  16.4816, -11.0762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3335,  11.4998,  13.0874, -15.2721,  16.5001, -10.8893],\n",
      "        [ 16.6943,  10.6865,  12.5834, -14.7258,  16.6669, -10.9526],\n",
      "        [ 17.5055,  11.4814,  12.7427, -15.1942,  16.6065, -11.1260],\n",
      "        [ 17.2474,  11.4673,  13.3176, -15.1569,  17.1187, -10.9850],\n",
      "        [ 17.2482,  11.2302,  12.9482, -15.2557,  16.7002, -10.7869],\n",
      "        [ 17.5108,  11.6136,  13.1694, -15.3516,  16.4816, -11.0762]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2051339149475098\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5013, 11.4949, 12.9479],\n",
      "        [17.1150, 11.2363, 12.8385],\n",
      "        [17.1660, 11.2803, 12.5848],\n",
      "        [17.2761, 11.2981, 12.9638],\n",
      "        [17.5206, 11.5105, 12.8951],\n",
      "        [17.4503, 11.2028, 12.7868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3133, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.0368,  16.4048, -10.8278],\n",
      "        [-15.4353,  16.7988, -10.9538],\n",
      "        [-15.3442,  16.5727, -10.7940],\n",
      "        [-15.3316,  16.7029, -11.1181],\n",
      "        [-15.5964,  16.9306, -11.2309],\n",
      "        [-15.2381,  16.6383, -10.6545]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5013,  11.4949,  12.9479, -15.0368,  16.4048, -10.8278],\n",
      "        [ 17.1150,  11.2363,  12.8385, -15.4353,  16.7988, -10.9538],\n",
      "        [ 17.1660,  11.2803,  12.5848, -15.3442,  16.5727, -10.7940],\n",
      "        [ 17.2761,  11.2981,  12.9638, -15.3316,  16.7029, -11.1181],\n",
      "        [ 17.5206,  11.5105,  12.8951, -15.5964,  16.9306, -11.2309],\n",
      "        [ 17.4503,  11.2028,  12.7868, -15.2381,  16.6383, -10.6545]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2006995677948\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3939, 11.3853, 12.7758],\n",
      "        [17.6592, 11.6985, 13.2875],\n",
      "        [17.2279, 11.3471, 12.8079],\n",
      "        [17.5821, 11.8559, 13.0189],\n",
      "        [17.4668, 11.8977, 12.7793],\n",
      "        [17.5221, 11.6943, 12.9139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3042,  16.7923, -11.1795],\n",
      "        [-15.3487,  16.9534, -11.3169],\n",
      "        [-14.7912,  16.4887, -11.0413],\n",
      "        [-15.2773,  16.7355, -10.8781],\n",
      "        [-15.4564,  16.8694, -11.1241],\n",
      "        [-15.2143,  16.4543, -11.1765]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3939,  11.3853,  12.7758, -15.3042,  16.7923, -11.1795],\n",
      "        [ 17.6592,  11.6985,  13.2875, -15.3487,  16.9534, -11.3169],\n",
      "        [ 17.2279,  11.3471,  12.8079, -14.7912,  16.4887, -11.0413],\n",
      "        [ 17.5821,  11.8559,  13.0189, -15.2773,  16.7355, -10.8781],\n",
      "        [ 17.4668,  11.8977,  12.7793, -15.4564,  16.8694, -11.1241],\n",
      "        [ 17.5221,  11.6943,  12.9139, -15.2143,  16.4543, -11.1765]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.2090234756469727\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7365, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7346, 11.1825, 13.2140],\n",
      "        [17.1549, 11.3277, 12.8153],\n",
      "        [17.4176, 11.5958, 12.8763],\n",
      "        [17.4652, 11.3497, 12.8667],\n",
      "        [17.4524, 11.5547, 12.6922],\n",
      "        [17.4133, 11.3981, 12.9826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4168,  16.7049, -11.2961],\n",
      "        [-14.9158,  16.3874, -11.1280],\n",
      "        [-15.1939,  16.2626, -11.0928],\n",
      "        [-15.1812,  16.4327, -10.4857],\n",
      "        [-14.6816,  16.5626, -10.8286],\n",
      "        [-15.1011,  16.4650, -11.0684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7346,  11.1825,  13.2140, -15.4168,  16.7049, -11.2961],\n",
      "        [ 17.1549,  11.3277,  12.8153, -14.9158,  16.3874, -11.1280],\n",
      "        [ 17.4176,  11.5958,  12.8763, -15.1939,  16.2626, -11.0928],\n",
      "        [ 17.4652,  11.3497,  12.8667, -15.1812,  16.4327, -10.4857],\n",
      "        [ 17.4524,  11.5547,  12.6922, -14.6816,  16.5626, -10.8286],\n",
      "        [ 17.4133,  11.3981,  12.9826, -15.1011,  16.4650, -11.0684]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.235729694366455\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1955, 11.5746, 12.8242],\n",
      "        [17.5643, 11.4997, 12.9032],\n",
      "        [16.7164, 11.2122, 12.5704],\n",
      "        [16.5847, 11.5278, 12.8074],\n",
      "        [17.2690, 11.6738, 12.7013],\n",
      "        [16.9269, 11.3655, 13.0773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.5892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.8723,  16.0507, -10.8147],\n",
      "        [-15.1302,  16.7217, -11.1983],\n",
      "        [-15.3015,  16.4668, -11.1008],\n",
      "        [-15.0593,  16.4180, -10.9509],\n",
      "        [-15.0871,  16.4827, -10.4984],\n",
      "        [-15.2006,  16.5630, -10.8593]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1955,  11.5746,  12.8242, -14.8723,  16.0507, -10.8147],\n",
      "        [ 17.5643,  11.4997,  12.9032, -15.1302,  16.7217, -11.1983],\n",
      "        [ 16.7164,  11.2122,  12.5704, -15.3015,  16.4668, -11.1008],\n",
      "        [ 16.5847,  11.5278,  12.8074, -15.0593,  16.4180, -10.9509],\n",
      "        [ 17.2690,  11.6738,  12.7013, -15.0871,  16.4827, -10.4984],\n",
      "        [ 16.9269,  11.3655,  13.0773, -15.2006,  16.5630, -10.8593]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.177473783493042\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3907, 11.4727, 12.9814],\n",
      "        [17.0441, 11.9222, 12.9894],\n",
      "        [17.0117, 11.1453, 13.3205],\n",
      "        [17.9893, 11.7547, 13.3952],\n",
      "        [17.3070, 11.8231, 13.0547],\n",
      "        [17.4529, 11.8025, 13.0119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1223, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3556,  16.9687, -10.9420],\n",
      "        [-15.5797,  17.0789, -11.5699],\n",
      "        [-15.5190,  16.8360, -11.2529],\n",
      "        [-15.0738,  16.6151, -10.8279],\n",
      "        [-15.1954,  16.9882, -11.5516],\n",
      "        [-15.4886,  16.9393, -11.1478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3907,  11.4727,  12.9814, -15.3556,  16.9687, -10.9420],\n",
      "        [ 17.0441,  11.9222,  12.9894, -15.5797,  17.0789, -11.5699],\n",
      "        [ 17.0117,  11.1453,  13.3205, -15.5190,  16.8360, -11.2529],\n",
      "        [ 17.9893,  11.7547,  13.3952, -15.0738,  16.6151, -10.8279],\n",
      "        [ 17.3070,  11.8231,  13.0547, -15.1954,  16.9882, -11.5516],\n",
      "        [ 17.4529,  11.8025,  13.0119, -15.4886,  16.9393, -11.1478]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.222482442855835\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0604, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4608, 11.5164, 13.3555],\n",
      "        [17.5117, 12.0067, 13.2977],\n",
      "        [17.4164, 11.1577, 12.9038],\n",
      "        [17.6050, 11.3343, 12.8446],\n",
      "        [17.6921, 11.4527, 13.0591],\n",
      "        [17.5732, 11.7345, 13.4547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.2903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9944,  16.9095, -11.1044],\n",
      "        [-15.2677,  16.5173, -10.6740],\n",
      "        [-15.2908,  17.0808, -11.5000],\n",
      "        [-15.2847,  16.7168, -11.1346],\n",
      "        [-15.3268,  16.4790, -10.9809],\n",
      "        [-15.5217,  16.5024, -11.3352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4608,  11.5164,  13.3555, -14.9944,  16.9095, -11.1044],\n",
      "        [ 17.5117,  12.0067,  13.2977, -15.2677,  16.5173, -10.6740],\n",
      "        [ 17.4164,  11.1577,  12.9038, -15.2908,  17.0808, -11.5000],\n",
      "        [ 17.6050,  11.3343,  12.8446, -15.2847,  16.7168, -11.1346],\n",
      "        [ 17.6921,  11.4527,  13.0591, -15.3268,  16.4790, -10.9809],\n",
      "        [ 17.5732,  11.7345,  13.4547, -15.5217,  16.5024, -11.3352]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.23262357711792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9213, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2505, 11.5757, 13.2128],\n",
      "        [17.0762, 11.3830, 12.9181],\n",
      "        [17.7477, 11.5882, 13.2285],\n",
      "        [17.0795, 11.3239, 12.7562],\n",
      "        [17.5032, 11.3016, 13.3658],\n",
      "        [17.6865, 11.3800, 12.9868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9599,  16.3520, -10.7789],\n",
      "        [-15.0071,  16.3501, -11.0568],\n",
      "        [-15.1921,  16.8416, -11.1924],\n",
      "        [-15.1839,  16.4692, -11.1010],\n",
      "        [-15.0057,  16.4515, -10.8908],\n",
      "        [-15.2130,  16.5223, -10.9687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2505,  11.5757,  13.2128, -14.9599,  16.3520, -10.7789],\n",
      "        [ 17.0762,  11.3830,  12.9181, -15.0071,  16.3501, -11.0568],\n",
      "        [ 17.7477,  11.5882,  13.2285, -15.1921,  16.8416, -11.1924],\n",
      "        [ 17.0795,  11.3239,  12.7562, -15.1839,  16.4692, -11.1010],\n",
      "        [ 17.5032,  11.3016,  13.3658, -15.0057,  16.4515, -10.8908],\n",
      "        [ 17.6865,  11.3800,  12.9868, -15.2130,  16.5223, -10.9687]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.203716993331909\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0275, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6389, 11.8414, 13.2867],\n",
      "        [17.5209, 11.5438, 13.0613],\n",
      "        [17.3208, 11.5464, 12.6060],\n",
      "        [17.5830, 11.2758, 12.7296],\n",
      "        [17.3410, 11.2299, 13.2188],\n",
      "        [17.2990, 11.6517, 12.7102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.2907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4386,  16.3104, -11.2349],\n",
      "        [-15.5334,  16.7552, -11.3931],\n",
      "        [-15.2553,  16.6024, -10.9505],\n",
      "        [-15.2869,  16.6142, -10.8549],\n",
      "        [-15.1422,  16.5544, -11.2161],\n",
      "        [-14.9857,  16.9698, -11.1767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6389,  11.8414,  13.2867, -15.4386,  16.3104, -11.2349],\n",
      "        [ 17.5209,  11.5438,  13.0613, -15.5334,  16.7552, -11.3931],\n",
      "        [ 17.3208,  11.5464,  12.6060, -15.2553,  16.6024, -10.9505],\n",
      "        [ 17.5830,  11.2758,  12.7296, -15.2869,  16.6142, -10.8549],\n",
      "        [ 17.3410,  11.2299,  13.2188, -15.1422,  16.5544, -11.2161],\n",
      "        [ 17.2990,  11.6517,  12.7102, -14.9857,  16.9698, -11.1767]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.2438807487487793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4411, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3324, 11.1705, 13.4167],\n",
      "        [17.2480, 11.2991, 13.0553],\n",
      "        [17.0456, 11.1930, 12.3410],\n",
      "        [17.2756, 11.3463, 13.1711],\n",
      "        [17.3076, 11.6055, 13.0076],\n",
      "        [17.5809, 11.4896, 12.8776]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3122, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1711,  16.6134, -10.8902],\n",
      "        [-15.1424,  16.8041, -10.7734],\n",
      "        [-15.2247,  16.6868, -10.8318],\n",
      "        [-15.2147,  16.7988, -11.1496],\n",
      "        [-15.7961,  17.3156, -11.1437],\n",
      "        [-15.3257,  16.4118, -10.9211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3324,  11.1705,  13.4167, -15.1711,  16.6134, -10.8902],\n",
      "        [ 17.2480,  11.2991,  13.0553, -15.1424,  16.8041, -10.7734],\n",
      "        [ 17.0456,  11.1930,  12.3410, -15.2247,  16.6868, -10.8318],\n",
      "        [ 17.2756,  11.3463,  13.1711, -15.2147,  16.7988, -11.1496],\n",
      "        [ 17.3076,  11.6055,  13.0076, -15.7961,  17.3156, -11.1437],\n",
      "        [ 17.5809,  11.4896,  12.8776, -15.3257,  16.4118, -10.9211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2194085121154785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2545, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6785, 11.8265, 13.2252],\n",
      "        [17.1578, 10.9627, 12.9329],\n",
      "        [16.9694, 11.4525, 12.8256],\n",
      "        [17.8197, 11.7012, 13.1650],\n",
      "        [17.7123, 11.3814, 13.1124],\n",
      "        [17.3518, 11.9740, 13.0229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.0462,  16.5464, -10.7532],\n",
      "        [-15.4454,  16.9541, -11.1594],\n",
      "        [-15.5012,  17.0936, -10.9965],\n",
      "        [-15.5536,  16.8826, -11.0435],\n",
      "        [-15.2210,  16.5823, -11.1841],\n",
      "        [-14.9712,  16.6106, -11.0462]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6785,  11.8265,  13.2252, -15.0462,  16.5464, -10.7532],\n",
      "        [ 17.1578,  10.9627,  12.9329, -15.4454,  16.9541, -11.1594],\n",
      "        [ 16.9694,  11.4525,  12.8256, -15.5012,  17.0936, -10.9965],\n",
      "        [ 17.8197,  11.7012,  13.1650, -15.5536,  16.8826, -11.0435],\n",
      "        [ 17.7123,  11.3814,  13.1124, -15.2210,  16.5823, -11.1841],\n",
      "        [ 17.3518,  11.9740,  13.0229, -14.9712,  16.6106, -11.0462]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.236175537109375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6581, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0135, 11.0195, 12.9013],\n",
      "        [17.7549, 11.9053, 13.1616],\n",
      "        [17.5421, 11.6815, 13.5496],\n",
      "        [17.4429, 11.3273, 13.1824],\n",
      "        [17.4649, 11.6569, 12.8208],\n",
      "        [17.6688, 11.9262, 13.1819]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.4182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2636,  16.2875, -11.0464],\n",
      "        [-15.0975,  16.8853, -11.2733],\n",
      "        [-14.7908,  16.6202, -11.0151],\n",
      "        [-15.0675,  16.8210, -11.0971],\n",
      "        [-15.0668,  16.3562, -10.9109],\n",
      "        [-15.2019,  16.9394, -11.3669]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0135,  11.0195,  12.9013, -15.2636,  16.2875, -11.0464],\n",
      "        [ 17.7549,  11.9053,  13.1616, -15.0975,  16.8853, -11.2733],\n",
      "        [ 17.5421,  11.6815,  13.5496, -14.7908,  16.6202, -11.0151],\n",
      "        [ 17.4429,  11.3273,  13.1824, -15.0675,  16.8210, -11.0971],\n",
      "        [ 17.4649,  11.6569,  12.8208, -15.0668,  16.3562, -10.9109],\n",
      "        [ 17.6688,  11.9262,  13.1819, -15.2019,  16.9394, -11.3669]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.1855711936950684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4946, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6257, 11.3121, 13.1860],\n",
      "        [17.0581, 11.7691, 12.8314],\n",
      "        [17.5699, 11.9110, 13.1363],\n",
      "        [17.3363, 11.5028, 13.2029],\n",
      "        [17.4421, 11.9737, 12.7844],\n",
      "        [17.4065, 11.4508, 13.2851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4280,  16.8322, -11.2586],\n",
      "        [-15.4649,  17.1203, -11.0415],\n",
      "        [-15.2588,  16.4896, -11.2341],\n",
      "        [-15.2601,  16.8009, -11.2310],\n",
      "        [-15.2586,  16.4979, -11.4125],\n",
      "        [-15.1425,  16.6420, -11.4491]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6257,  11.3121,  13.1860, -15.4280,  16.8322, -11.2586],\n",
      "        [ 17.0581,  11.7691,  12.8314, -15.4649,  17.1203, -11.0415],\n",
      "        [ 17.5699,  11.9110,  13.1363, -15.2588,  16.4896, -11.2341],\n",
      "        [ 17.3363,  11.5028,  13.2029, -15.2601,  16.8009, -11.2310],\n",
      "        [ 17.4421,  11.9737,  12.7844, -15.2586,  16.4979, -11.4125],\n",
      "        [ 17.4065,  11.4508,  13.2851, -15.1425,  16.6420, -11.4491]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2459566593170166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6294, 11.6156, 13.5329],\n",
      "        [17.4935, 11.7941, 13.1101],\n",
      "        [17.2853, 11.5181, 13.0020],\n",
      "        [17.1776, 11.5750, 13.0150],\n",
      "        [17.3522, 11.5198, 13.3355],\n",
      "        [17.4583, 11.6340, 13.1352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3808,  16.5400, -10.9822],\n",
      "        [-14.9261,  16.8313, -11.0451],\n",
      "        [-15.4678,  16.7204, -11.5169],\n",
      "        [-15.1445,  16.6789, -11.0077],\n",
      "        [-14.6670,  16.1547, -11.1033],\n",
      "        [-15.0459,  16.5674, -11.1264]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6294,  11.6156,  13.5329, -15.3808,  16.5400, -10.9822],\n",
      "        [ 17.4935,  11.7941,  13.1101, -14.9261,  16.8313, -11.0451],\n",
      "        [ 17.2853,  11.5181,  13.0020, -15.4678,  16.7204, -11.5169],\n",
      "        [ 17.1776,  11.5750,  13.0150, -15.1445,  16.6789, -11.0077],\n",
      "        [ 17.3522,  11.5198,  13.3355, -14.6670,  16.1547, -11.1033],\n",
      "        [ 17.4583,  11.6340,  13.1352, -15.0459,  16.5674, -11.1264]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.252971887588501\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5957, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6646, 12.0861, 13.1514],\n",
      "        [17.2951, 11.7679, 12.8068],\n",
      "        [17.3536, 11.6559, 13.0392],\n",
      "        [17.2333, 11.8923, 12.8482],\n",
      "        [17.3312, 11.7311, 13.4105],\n",
      "        [17.2752, 11.8630, 13.1493]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6849,  17.0546, -11.2972],\n",
      "        [-15.4377,  16.2970, -11.2342],\n",
      "        [-15.3906,  17.0552, -11.2341],\n",
      "        [-15.0255,  16.7087, -11.0175],\n",
      "        [-15.2086,  16.7335, -10.9115],\n",
      "        [-15.5095,  16.3785, -10.9536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6646,  12.0861,  13.1514, -15.6849,  17.0546, -11.2972],\n",
      "        [ 17.2951,  11.7679,  12.8068, -15.4377,  16.2970, -11.2342],\n",
      "        [ 17.3536,  11.6559,  13.0392, -15.3906,  17.0552, -11.2341],\n",
      "        [ 17.2333,  11.8923,  12.8482, -15.0255,  16.7087, -11.0175],\n",
      "        [ 17.3312,  11.7311,  13.4105, -15.2086,  16.7335, -10.9115],\n",
      "        [ 17.2752,  11.8630,  13.1493, -15.5095,  16.3785, -10.9536]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.275846242904663\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9472, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7237, 11.8909, 12.8925],\n",
      "        [17.2725, 11.4649, 12.8273],\n",
      "        [17.6886, 11.4852, 13.1059],\n",
      "        [17.6779, 11.8757, 12.7439],\n",
      "        [17.4689, 11.4451, 12.9687],\n",
      "        [17.7465, 11.4967, 13.1516]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.1429, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8194,  17.1849, -11.5309],\n",
      "        [-15.5015,  16.6346, -10.9868],\n",
      "        [-15.1310,  16.5740, -11.1348],\n",
      "        [-15.1337,  16.5835, -11.1166],\n",
      "        [-15.3085,  16.3058, -10.9875],\n",
      "        [-15.0916,  16.6392, -11.0668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7237,  11.8909,  12.8925, -15.8194,  17.1849, -11.5309],\n",
      "        [ 17.2725,  11.4649,  12.8273, -15.5015,  16.6346, -10.9868],\n",
      "        [ 17.6886,  11.4852,  13.1059, -15.1310,  16.5740, -11.1348],\n",
      "        [ 17.6779,  11.8757,  12.7439, -15.1337,  16.5835, -11.1166],\n",
      "        [ 17.4689,  11.4451,  12.9687, -15.3085,  16.3058, -10.9875],\n",
      "        [ 17.7465,  11.4967,  13.1516, -15.0916,  16.6392, -11.0668]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2762203216552734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6108, 12.0002, 12.9730],\n",
      "        [17.5508, 11.7400, 13.5886],\n",
      "        [17.7796, 11.8391, 13.3271],\n",
      "        [17.1332, 11.6345, 13.1590],\n",
      "        [17.2540, 11.6155, 12.8024],\n",
      "        [17.5874, 11.4490, 12.9205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0368, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3757,  16.6292, -10.9492],\n",
      "        [-15.1765,  16.6771, -11.2189],\n",
      "        [-15.2354,  16.5182, -11.0409],\n",
      "        [-15.6521,  17.2577, -11.6787],\n",
      "        [-15.4094,  16.6362, -11.1190],\n",
      "        [-15.0662,  16.6021, -10.9050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6108,  12.0002,  12.9730, -15.3757,  16.6292, -10.9492],\n",
      "        [ 17.5508,  11.7400,  13.5886, -15.1765,  16.6771, -11.2189],\n",
      "        [ 17.7796,  11.8391,  13.3271, -15.2354,  16.5182, -11.0409],\n",
      "        [ 17.1332,  11.6345,  13.1590, -15.6521,  17.2577, -11.6787],\n",
      "        [ 17.2540,  11.6155,  12.8024, -15.4094,  16.6362, -11.1190],\n",
      "        [ 17.5874,  11.4490,  12.9205, -15.0662,  16.6021, -10.9050]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2472786903381348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9247, 11.5081, 13.0685],\n",
      "        [17.3227, 11.9326, 13.3242],\n",
      "        [17.7311, 11.3700, 12.8932],\n",
      "        [17.5795, 12.0809, 13.0496],\n",
      "        [17.7241, 12.2302, 13.4765],\n",
      "        [17.4776, 12.0264, 13.2056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0217, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.5858,  16.6443, -11.5687],\n",
      "        [-15.2938,  16.6956, -10.7484],\n",
      "        [-15.0383,  16.6195, -11.3306],\n",
      "        [-15.5268,  17.0302, -11.0865],\n",
      "        [-15.3513,  16.8908, -11.2934],\n",
      "        [-14.7516,  15.7788, -10.5146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9247,  11.5081,  13.0685, -15.5858,  16.6443, -11.5687],\n",
      "        [ 17.3227,  11.9326,  13.3242, -15.2938,  16.6956, -10.7484],\n",
      "        [ 17.7311,  11.3700,  12.8932, -15.0383,  16.6195, -11.3306],\n",
      "        [ 17.5795,  12.0809,  13.0496, -15.5268,  17.0302, -11.0865],\n",
      "        [ 17.7241,  12.2302,  13.4765, -15.3513,  16.8908, -11.2934],\n",
      "        [ 17.4776,  12.0264,  13.2056, -14.7516,  15.7788, -10.5146]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2675185203552246\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9669, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3251, 11.6610, 13.0095],\n",
      "        [17.6659, 11.7574, 13.5639],\n",
      "        [17.2321, 11.6083, 13.1271],\n",
      "        [17.5762, 11.8730, 13.0282],\n",
      "        [17.5956, 11.6000, 13.2162],\n",
      "        [17.5887, 11.7181, 13.1019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3610, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1269,  16.6339, -11.0095],\n",
      "        [-15.1921,  16.7561, -11.0037],\n",
      "        [-15.0836,  16.6369, -11.1197],\n",
      "        [-15.4545,  16.6939, -11.2859],\n",
      "        [-15.5471,  16.5946, -11.1403],\n",
      "        [-15.8980,  16.7172, -11.4525]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3251,  11.6610,  13.0095, -15.1269,  16.6339, -11.0095],\n",
      "        [ 17.6659,  11.7574,  13.5639, -15.1921,  16.7561, -11.0037],\n",
      "        [ 17.2321,  11.6083,  13.1271, -15.0836,  16.6369, -11.1197],\n",
      "        [ 17.5762,  11.8730,  13.0282, -15.4545,  16.6939, -11.2859],\n",
      "        [ 17.5956,  11.6000,  13.2162, -15.5471,  16.5946, -11.1403],\n",
      "        [ 17.5887,  11.7181,  13.1019, -15.8980,  16.7172, -11.4525]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2276558876037598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3008, 11.7751, 13.0768],\n",
      "        [17.3864, 11.7156, 13.1390],\n",
      "        [17.8848, 12.1210, 13.1749],\n",
      "        [17.7496, 11.8510, 13.7792],\n",
      "        [17.4687, 11.5695, 13.3012],\n",
      "        [17.4654, 11.5281, 13.2863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6548, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4229,  16.7552, -11.4990],\n",
      "        [-15.6643,  16.9012, -11.5441],\n",
      "        [-14.8083,  16.6509, -11.3624],\n",
      "        [-15.0525,  16.7371, -10.9749],\n",
      "        [-15.1758,  16.9487, -11.6884],\n",
      "        [-14.9763,  16.6251, -10.9132]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3008,  11.7751,  13.0768, -15.4229,  16.7552, -11.4990],\n",
      "        [ 17.3864,  11.7156,  13.1390, -15.6643,  16.9012, -11.5441],\n",
      "        [ 17.8848,  12.1210,  13.1749, -14.8083,  16.6509, -11.3624],\n",
      "        [ 17.7496,  11.8510,  13.7792, -15.0525,  16.7371, -10.9749],\n",
      "        [ 17.4687,  11.5695,  13.3012, -15.1758,  16.9487, -11.6884],\n",
      "        [ 17.4654,  11.5281,  13.2863, -14.9763,  16.6251, -10.9132]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2481579780578613\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5494, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5349, 11.9802, 13.2829],\n",
      "        [17.1916, 11.3949, 13.2954],\n",
      "        [17.2787, 11.7166, 12.7804],\n",
      "        [17.6717, 12.3479, 13.5234],\n",
      "        [17.3283, 11.7916, 13.0200],\n",
      "        [17.5649, 11.6122, 13.2577]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2586, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1601,  16.7530, -11.1808],\n",
      "        [-15.3317,  16.6407, -11.1544],\n",
      "        [-14.9865,  16.7738, -10.9294],\n",
      "        [-15.4953,  16.3754, -11.0924],\n",
      "        [-15.3870,  16.6204, -11.2357],\n",
      "        [-15.5667,  16.7272, -10.9897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5349,  11.9802,  13.2829, -15.1601,  16.7530, -11.1808],\n",
      "        [ 17.1916,  11.3949,  13.2954, -15.3317,  16.6407, -11.1544],\n",
      "        [ 17.2787,  11.7166,  12.7804, -14.9865,  16.7738, -10.9294],\n",
      "        [ 17.6717,  12.3479,  13.5234, -15.4953,  16.3754, -11.0924],\n",
      "        [ 17.3283,  11.7916,  13.0200, -15.3870,  16.6204, -11.2357],\n",
      "        [ 17.5649,  11.6122,  13.2577, -15.5667,  16.7272, -10.9897]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.2597947120666504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5012, 12.1079, 13.3049],\n",
      "        [17.2150, 11.7972, 12.8544],\n",
      "        [17.9438, 11.6431, 13.0002],\n",
      "        [17.4241, 11.8515, 13.1058],\n",
      "        [17.3688, 11.8729, 12.9015],\n",
      "        [17.8881, 11.9348, 13.5455]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2305,  16.3904, -11.3889],\n",
      "        [-15.3056,  16.9219, -11.4149],\n",
      "        [-15.7895,  17.2349, -11.4516],\n",
      "        [-15.3563,  16.7113, -11.2015],\n",
      "        [-15.3745,  16.9227, -11.4008],\n",
      "        [-15.4141,  16.9501, -11.3643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5012,  12.1079,  13.3049, -15.2305,  16.3904, -11.3889],\n",
      "        [ 17.2150,  11.7972,  12.8544, -15.3056,  16.9219, -11.4149],\n",
      "        [ 17.9438,  11.6431,  13.0002, -15.7895,  17.2349, -11.4516],\n",
      "        [ 17.4241,  11.8515,  13.1058, -15.3563,  16.7113, -11.2015],\n",
      "        [ 17.3688,  11.8729,  12.9015, -15.3745,  16.9227, -11.4008],\n",
      "        [ 17.8881,  11.9348,  13.5455, -15.4141,  16.9501, -11.3643]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2588322162628174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4073, 11.6794, 13.2031],\n",
      "        [17.5820, 12.0012, 12.7539],\n",
      "        [17.1715, 11.4912, 12.7768],\n",
      "        [17.4009, 11.7987, 12.9504],\n",
      "        [17.5089, 11.8553, 12.9969],\n",
      "        [17.5319, 11.3017, 12.9476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.4972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.0501,  16.6281, -11.1082],\n",
      "        [-15.5131,  16.8734, -11.0838],\n",
      "        [-15.2154,  16.8023, -11.4826],\n",
      "        [-15.5051,  16.9123, -11.4789],\n",
      "        [-15.4779,  16.6283, -11.1821],\n",
      "        [-15.4615,  17.0207, -11.5273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4073,  11.6794,  13.2031, -15.0501,  16.6281, -11.1082],\n",
      "        [ 17.5820,  12.0012,  12.7539, -15.5131,  16.8734, -11.0838],\n",
      "        [ 17.1715,  11.4912,  12.7768, -15.2154,  16.8023, -11.4826],\n",
      "        [ 17.4009,  11.7987,  12.9504, -15.5051,  16.9123, -11.4789],\n",
      "        [ 17.5089,  11.8553,  12.9969, -15.4779,  16.6283, -11.1821],\n",
      "        [ 17.5319,  11.3017,  12.9476, -15.4615,  17.0207, -11.5273]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2417612075805664\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3204, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[16.9668, 11.6508, 13.4611],\n",
      "        [17.5349, 11.6075, 13.5466],\n",
      "        [17.7322, 11.6695, 13.2939],\n",
      "        [17.4530, 11.8786, 13.2120],\n",
      "        [17.1796, 11.1517, 13.1307],\n",
      "        [17.5424, 11.6257, 12.8924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8326, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3642,  16.7425, -11.0541],\n",
      "        [-14.9283,  16.9448, -11.2981],\n",
      "        [-14.9805,  16.8312, -11.4635],\n",
      "        [-14.6965,  16.2378, -11.0493],\n",
      "        [-15.3184,  16.9348, -11.1472],\n",
      "        [-15.1382,  16.3986, -11.1429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 16.9668,  11.6508,  13.4611, -15.3642,  16.7425, -11.0541],\n",
      "        [ 17.5349,  11.6075,  13.5466, -14.9283,  16.9448, -11.2981],\n",
      "        [ 17.7322,  11.6695,  13.2939, -14.9805,  16.8312, -11.4635],\n",
      "        [ 17.4530,  11.8786,  13.2120, -14.6965,  16.2378, -11.0493],\n",
      "        [ 17.1796,  11.1517,  13.1307, -15.3184,  16.9348, -11.1472],\n",
      "        [ 17.5424,  11.6257,  12.8924, -15.1382,  16.3986, -11.1429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.240898847579956\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.1714, 11.8034, 12.7301],\n",
      "        [17.2064, 11.4774, 12.7754],\n",
      "        [17.4817, 11.9206, 13.6138],\n",
      "        [17.6584, 11.3301, 13.1653],\n",
      "        [17.4579, 11.7405, 13.4070],\n",
      "        [17.8436, 11.7193, 13.1833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4761, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9019,  16.8087, -11.1963],\n",
      "        [-15.2029,  16.6943, -11.5088],\n",
      "        [-15.7266,  16.9440, -11.6236],\n",
      "        [-15.4132,  16.8433, -11.1412],\n",
      "        [-15.6273,  16.9291, -11.3800],\n",
      "        [-15.3049,  16.7079, -11.4051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.1714,  11.8034,  12.7301, -14.9019,  16.8087, -11.1963],\n",
      "        [ 17.2064,  11.4774,  12.7754, -15.2029,  16.6943, -11.5088],\n",
      "        [ 17.4817,  11.9206,  13.6138, -15.7266,  16.9440, -11.6236],\n",
      "        [ 17.6584,  11.3301,  13.1653, -15.4132,  16.8433, -11.1412],\n",
      "        [ 17.4579,  11.7405,  13.4070, -15.6273,  16.9291, -11.3800],\n",
      "        [ 17.8436,  11.7193,  13.1833, -15.3049,  16.7079, -11.4051]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2241127490997314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5823, 11.9179, 13.3576],\n",
      "        [17.5542, 11.4968, 13.1509],\n",
      "        [17.5881, 11.4782, 12.7591],\n",
      "        [16.9434, 11.4801, 12.9234],\n",
      "        [17.2361, 11.3255, 13.1185],\n",
      "        [17.5657, 12.1065, 13.3518]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3230,  16.8495, -11.2074],\n",
      "        [-15.9935,  17.2071, -11.4121],\n",
      "        [-15.0602,  16.7309, -11.0968],\n",
      "        [-15.4043,  16.4625, -11.1875],\n",
      "        [-15.5159,  16.8483, -11.1925],\n",
      "        [-15.1955,  16.6230, -11.2977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5823,  11.9179,  13.3576, -15.3230,  16.8495, -11.2074],\n",
      "        [ 17.5542,  11.4968,  13.1509, -15.9935,  17.2071, -11.4121],\n",
      "        [ 17.5881,  11.4782,  12.7591, -15.0602,  16.7309, -11.0968],\n",
      "        [ 16.9434,  11.4801,  12.9234, -15.4043,  16.4625, -11.1875],\n",
      "        [ 17.2361,  11.3255,  13.1185, -15.5159,  16.8483, -11.1925],\n",
      "        [ 17.5657,  12.1065,  13.3518, -15.1955,  16.6230, -11.2977]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2746033668518066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4731, 11.3404, 12.7169],\n",
      "        [17.7177, 11.5936, 12.9511],\n",
      "        [17.2954, 11.1406, 13.2360],\n",
      "        [17.5929, 11.7844, 13.1492],\n",
      "        [17.3333, 11.8113, 12.9921],\n",
      "        [17.6400, 11.6244, 12.9977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0929, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4943,  16.4713, -11.1344],\n",
      "        [-15.0053,  16.6775, -11.2293],\n",
      "        [-15.4236,  16.6692, -10.9224],\n",
      "        [-15.3830,  16.7425, -11.3863],\n",
      "        [-15.0322,  16.7804, -11.1234],\n",
      "        [-15.2173,  17.4042, -11.2176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4731,  11.3404,  12.7169, -15.4943,  16.4713, -11.1344],\n",
      "        [ 17.7177,  11.5936,  12.9511, -15.0053,  16.6775, -11.2293],\n",
      "        [ 17.2954,  11.1406,  13.2360, -15.4236,  16.6692, -10.9224],\n",
      "        [ 17.5929,  11.7844,  13.1492, -15.3830,  16.7425, -11.3863],\n",
      "        [ 17.3333,  11.8113,  12.9921, -15.0322,  16.7804, -11.1234],\n",
      "        [ 17.6400,  11.6244,  12.9977, -15.2173,  17.4042, -11.2176]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.23239803314209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9746, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7203, 11.8427, 13.0386],\n",
      "        [17.4520, 11.8517, 12.8456],\n",
      "        [17.9865, 12.0503, 13.6042],\n",
      "        [17.6602, 11.7062, 13.3477],\n",
      "        [17.8635, 11.9171, 13.5424],\n",
      "        [17.0545, 11.3523, 12.6432]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7970, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1430,  16.9118, -11.2155],\n",
      "        [-15.6463,  17.2318, -11.5918],\n",
      "        [-15.5773,  16.8032, -11.1481],\n",
      "        [-15.2223,  16.6065, -11.0703],\n",
      "        [-15.3600,  17.0664, -11.1819],\n",
      "        [-15.3212,  16.5767, -11.3971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7203,  11.8427,  13.0386, -15.1430,  16.9118, -11.2155],\n",
      "        [ 17.4520,  11.8517,  12.8456, -15.6463,  17.2318, -11.5918],\n",
      "        [ 17.9865,  12.0503,  13.6042, -15.5773,  16.8032, -11.1481],\n",
      "        [ 17.6602,  11.7062,  13.3477, -15.2223,  16.6065, -11.0703],\n",
      "        [ 17.8635,  11.9171,  13.5424, -15.3600,  17.0664, -11.1819],\n",
      "        [ 17.0545,  11.3523,  12.6432, -15.3212,  16.5767, -11.3971]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.268583059310913\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5694, 11.6313, 13.0706],\n",
      "        [17.5213, 11.5578, 13.5727],\n",
      "        [17.7377, 11.7217, 13.2253],\n",
      "        [17.2636, 11.4450, 13.0824],\n",
      "        [17.4049, 11.8414, 13.1273],\n",
      "        [17.6401, 11.4442, 12.9365]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-14.9749,  16.9025, -10.8832],\n",
      "        [-15.7446,  16.9086, -11.6455],\n",
      "        [-15.1664,  16.5626, -11.3667],\n",
      "        [-15.1677,  16.8203, -11.2513],\n",
      "        [-15.3589,  16.6549, -11.1952],\n",
      "        [-15.3558,  17.0255, -11.1124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5694,  11.6313,  13.0706, -14.9749,  16.9025, -10.8832],\n",
      "        [ 17.5213,  11.5578,  13.5727, -15.7446,  16.9086, -11.6455],\n",
      "        [ 17.7377,  11.7217,  13.2253, -15.1664,  16.5626, -11.3667],\n",
      "        [ 17.2636,  11.4450,  13.0824, -15.1677,  16.8203, -11.2513],\n",
      "        [ 17.4049,  11.8414,  13.1273, -15.3589,  16.6549, -11.1952],\n",
      "        [ 17.6401,  11.4442,  12.9365, -15.3558,  17.0255, -11.1124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2516610622406006\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6907, 11.7362, 13.2069],\n",
      "        [17.1338, 11.8251, 13.3540],\n",
      "        [17.6987, 11.8762, 13.5416],\n",
      "        [17.4837, 11.5556, 13.0955],\n",
      "        [17.3823, 11.5119, 12.7625],\n",
      "        [17.5963, 11.7221, 12.8796]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.9124, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6559,  17.0741, -11.1893],\n",
      "        [-15.5788,  17.1654, -11.5473],\n",
      "        [-15.5543,  16.6611, -10.8919],\n",
      "        [-15.4004,  16.7805, -10.9825],\n",
      "        [-15.3134,  16.8708, -11.3384],\n",
      "        [-15.6294,  16.9316, -11.1512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6907,  11.7362,  13.2069, -15.6559,  17.0741, -11.1893],\n",
      "        [ 17.1338,  11.8251,  13.3540, -15.5788,  17.1654, -11.5473],\n",
      "        [ 17.6987,  11.8762,  13.5416, -15.5543,  16.6611, -10.8919],\n",
      "        [ 17.4837,  11.5556,  13.0955, -15.4004,  16.7805, -10.9825],\n",
      "        [ 17.3823,  11.5119,  12.7625, -15.3134,  16.8708, -11.3384],\n",
      "        [ 17.5963,  11.7221,  12.8796, -15.6294,  16.9316, -11.1512]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.287043333053589\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.2629, 11.6044, 13.1309],\n",
      "        [17.5940, 11.3710, 13.0145],\n",
      "        [17.4828, 11.6750, 13.3451],\n",
      "        [17.7688, 11.6865, 13.2654],\n",
      "        [17.1464, 11.6627, 13.2635],\n",
      "        [17.6451, 11.7501, 13.0644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7419,  16.9576, -11.5522],\n",
      "        [-15.6727,  17.2232, -11.6334],\n",
      "        [-15.4293,  16.6744, -11.2981],\n",
      "        [-15.3951,  16.9540, -11.7902],\n",
      "        [-15.5851,  17.2944, -11.5454],\n",
      "        [-15.2785,  16.4611, -11.5181]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.2629,  11.6044,  13.1309, -15.7419,  16.9576, -11.5522],\n",
      "        [ 17.5940,  11.3710,  13.0145, -15.6727,  17.2232, -11.6334],\n",
      "        [ 17.4828,  11.6750,  13.3451, -15.4293,  16.6744, -11.2981],\n",
      "        [ 17.7688,  11.6865,  13.2654, -15.3951,  16.9540, -11.7902],\n",
      "        [ 17.1464,  11.6627,  13.2635, -15.5851,  17.2944, -11.5454],\n",
      "        [ 17.6451,  11.7501,  13.0644, -15.2785,  16.4611, -11.5181]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.269521951675415\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6341, 11.9042, 13.1621],\n",
      "        [17.7730, 11.5076, 12.9403],\n",
      "        [17.6774, 12.1262, 13.5786],\n",
      "        [18.4241, 11.9682, 13.3761],\n",
      "        [18.0107, 11.6136, 13.4769],\n",
      "        [17.7924, 12.2156, 13.1938]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2223,  16.9662, -11.4254],\n",
      "        [-15.6091,  16.8217, -11.5120],\n",
      "        [-15.3926,  16.7184, -11.6165],\n",
      "        [-15.4295,  16.5556, -11.0323],\n",
      "        [-15.0601,  16.6260, -11.0266],\n",
      "        [-15.6954,  17.1817, -11.8326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6341,  11.9042,  13.1621, -15.2223,  16.9662, -11.4254],\n",
      "        [ 17.7730,  11.5076,  12.9403, -15.6091,  16.8217, -11.5120],\n",
      "        [ 17.6774,  12.1262,  13.5786, -15.3926,  16.7184, -11.6165],\n",
      "        [ 18.4241,  11.9682,  13.3761, -15.4295,  16.5556, -11.0323],\n",
      "        [ 18.0107,  11.6136,  13.4769, -15.0601,  16.6260, -11.0266],\n",
      "        [ 17.7924,  12.2156,  13.1938, -15.6954,  17.1817, -11.8326]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2807364463806152\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4446, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7296, 11.5650, 13.3289],\n",
      "        [17.3781, 11.8561, 13.5253],\n",
      "        [17.7881, 12.0692, 13.3340],\n",
      "        [17.5235, 11.8553, 13.3602],\n",
      "        [17.9021, 11.8372, 13.4989],\n",
      "        [17.5453, 11.8410, 13.1858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.4596, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6295,  17.2437, -11.6292],\n",
      "        [-14.9638,  16.6028, -11.0178],\n",
      "        [-15.0443,  16.6903, -11.3720],\n",
      "        [-15.7534,  17.2170, -11.4380],\n",
      "        [-15.2511,  16.5543, -10.8333],\n",
      "        [-16.0093,  17.4163, -11.9004]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7296,  11.5650,  13.3289, -15.6295,  17.2437, -11.6292],\n",
      "        [ 17.3781,  11.8561,  13.5253, -14.9638,  16.6028, -11.0178],\n",
      "        [ 17.7881,  12.0692,  13.3340, -15.0443,  16.6903, -11.3720],\n",
      "        [ 17.5235,  11.8553,  13.3602, -15.7534,  17.2170, -11.4380],\n",
      "        [ 17.9021,  11.8372,  13.4989, -15.2511,  16.5543, -10.8333],\n",
      "        [ 17.5453,  11.8410,  13.1858, -16.0093,  17.4163, -11.9004]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.3020520210266113\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6136, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5497, 11.8823, 13.2832],\n",
      "        [17.7162, 11.9932, 13.2858],\n",
      "        [17.7546, 11.6637, 13.1328],\n",
      "        [17.6595, 11.7700, 13.0612],\n",
      "        [17.6987, 11.7561, 13.3523],\n",
      "        [17.5965, 11.8894, 13.6637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1351,  15.9820, -11.0961],\n",
      "        [-15.1059,  16.5300, -11.3513],\n",
      "        [-15.2975,  17.2600, -11.4376],\n",
      "        [-15.2230,  16.7492, -11.4125],\n",
      "        [-15.5330,  16.7529, -10.7817],\n",
      "        [-15.5266,  17.2126, -11.4863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5497,  11.8823,  13.2832, -15.1351,  15.9820, -11.0961],\n",
      "        [ 17.7162,  11.9932,  13.2858, -15.1059,  16.5300, -11.3513],\n",
      "        [ 17.7546,  11.6637,  13.1328, -15.2975,  17.2600, -11.4376],\n",
      "        [ 17.6595,  11.7700,  13.0612, -15.2230,  16.7492, -11.4125],\n",
      "        [ 17.6987,  11.7561,  13.3523, -15.5330,  16.7529, -10.7817],\n",
      "        [ 17.5965,  11.8894,  13.6637, -15.5266,  17.2126, -11.4863]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2533469200134277\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3847, 11.7041, 13.1416],\n",
      "        [17.8407, 11.9764, 13.3940],\n",
      "        [17.6747, 11.4961, 13.1036],\n",
      "        [16.7662, 11.8939, 13.3030],\n",
      "        [17.0401, 11.8153, 13.1112],\n",
      "        [17.6741, 11.7143, 13.3825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3801,  17.0299, -11.3660],\n",
      "        [-16.0806,  17.1917, -11.3365],\n",
      "        [-15.3943,  16.9809, -11.2848],\n",
      "        [-14.9762,  16.7816, -11.3892],\n",
      "        [-15.3714,  16.8035, -11.3802],\n",
      "        [-15.3061,  16.9751, -11.2381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3847,  11.7041,  13.1416, -15.3801,  17.0299, -11.3660],\n",
      "        [ 17.8407,  11.9764,  13.3940, -16.0806,  17.1917, -11.3365],\n",
      "        [ 17.6747,  11.4961,  13.1036, -15.3943,  16.9809, -11.2848],\n",
      "        [ 16.7662,  11.8939,  13.3030, -14.9762,  16.7816, -11.3892],\n",
      "        [ 17.0401,  11.8153,  13.1112, -15.3714,  16.8035, -11.3802],\n",
      "        [ 17.6741,  11.7143,  13.3825, -15.3061,  16.9751, -11.2381]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2729904651641846\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.0008, 11.9400, 13.4489],\n",
      "        [17.6093, 11.7826, 13.1715],\n",
      "        [18.3231, 12.0429, 13.3914],\n",
      "        [17.5549, 11.4254, 13.0876],\n",
      "        [17.2259, 11.5161, 12.9097],\n",
      "        [17.4735, 11.8392, 13.5430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.3122, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6190,  16.6825, -11.3521],\n",
      "        [-15.5056,  16.5260, -11.2852],\n",
      "        [-15.1835,  16.8429, -11.0821],\n",
      "        [-15.3941,  16.9928, -11.3875],\n",
      "        [-15.6385,  17.2458, -11.6580],\n",
      "        [-15.4354,  16.8956, -11.5125]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.0008,  11.9400,  13.4489, -15.6190,  16.6825, -11.3521],\n",
      "        [ 17.6093,  11.7826,  13.1715, -15.5056,  16.5260, -11.2852],\n",
      "        [ 18.3231,  12.0429,  13.3914, -15.1835,  16.8429, -11.0821],\n",
      "        [ 17.5549,  11.4254,  13.0876, -15.3941,  16.9928, -11.3875],\n",
      "        [ 17.2259,  11.5161,  12.9097, -15.6385,  17.2458, -11.6580],\n",
      "        [ 17.4735,  11.8392,  13.5430, -15.4354,  16.8956, -11.5125]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.269761323928833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4313, 11.5665, 12.9883],\n",
      "        [17.8154, 11.7774, 13.6121],\n",
      "        [17.1106, 11.4213, 13.2478],\n",
      "        [17.6509, 11.3928, 13.5517],\n",
      "        [17.5267, 11.9449, 13.5587],\n",
      "        [17.6844, 11.5797, 13.5464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9454, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.1028,  17.0475, -11.4522],\n",
      "        [-15.4224,  17.1136, -11.4270],\n",
      "        [-15.4086,  16.7128, -11.3437],\n",
      "        [-15.4974,  17.0180, -11.4376],\n",
      "        [-15.3448,  16.7922, -11.2368],\n",
      "        [-15.5915,  17.1737, -11.6752]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4313,  11.5665,  12.9883, -15.1028,  17.0475, -11.4522],\n",
      "        [ 17.8154,  11.7774,  13.6121, -15.4224,  17.1136, -11.4270],\n",
      "        [ 17.1106,  11.4213,  13.2478, -15.4086,  16.7128, -11.3437],\n",
      "        [ 17.6509,  11.3928,  13.5517, -15.4974,  17.0180, -11.4376],\n",
      "        [ 17.5267,  11.9449,  13.5587, -15.3448,  16.7922, -11.2368],\n",
      "        [ 17.6844,  11.5797,  13.5464, -15.5915,  17.1737, -11.6752]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.265146255493164\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3783, 11.8835, 13.1691],\n",
      "        [17.2889, 11.4870, 13.4921],\n",
      "        [17.5019, 11.8557, 13.0618],\n",
      "        [17.2382, 11.6585, 13.1698],\n",
      "        [17.4395, 12.1351, 13.0219],\n",
      "        [17.3801, 11.7345, 13.0119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.2246, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8194,  17.0081, -11.7699],\n",
      "        [-15.5295,  16.7831, -11.6156],\n",
      "        [-15.3505,  16.4996, -10.9654],\n",
      "        [-15.7697,  16.8517, -11.5593],\n",
      "        [-15.6993,  16.9593, -11.3073],\n",
      "        [-15.5742,  17.2829, -11.8440]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3783,  11.8835,  13.1691, -15.8194,  17.0081, -11.7699],\n",
      "        [ 17.2889,  11.4870,  13.4921, -15.5295,  16.7831, -11.6156],\n",
      "        [ 17.5019,  11.8557,  13.0618, -15.3505,  16.4996, -10.9654],\n",
      "        [ 17.2382,  11.6585,  13.1698, -15.7697,  16.8517, -11.5593],\n",
      "        [ 17.4395,  12.1351,  13.0219, -15.6993,  16.9593, -11.3073],\n",
      "        [ 17.3801,  11.7345,  13.0119, -15.5742,  17.2829, -11.8440]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.295332431793213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7469, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8199, 11.7644, 13.4183],\n",
      "        [17.6319, 11.9368, 12.8967],\n",
      "        [17.8352, 11.6734, 13.4015],\n",
      "        [17.3607, 11.5915, 13.5244],\n",
      "        [17.3760, 11.6695, 13.0167],\n",
      "        [17.7487, 12.0012, 13.3635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1593, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3610,  16.7366, -11.2303],\n",
      "        [-15.5246,  17.3253, -11.4952],\n",
      "        [-15.6594,  17.1443, -11.3821],\n",
      "        [-16.0100,  16.9785, -11.4617],\n",
      "        [-15.7578,  17.0967, -11.4671],\n",
      "        [-15.3559,  16.8096, -11.5288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8199,  11.7644,  13.4183, -15.3610,  16.7366, -11.2303],\n",
      "        [ 17.6319,  11.9368,  12.8967, -15.5246,  17.3253, -11.4952],\n",
      "        [ 17.8352,  11.6734,  13.4015, -15.6594,  17.1443, -11.3821],\n",
      "        [ 17.3607,  11.5915,  13.5244, -16.0100,  16.9785, -11.4617],\n",
      "        [ 17.3760,  11.6695,  13.0167, -15.7578,  17.0967, -11.4671],\n",
      "        [ 17.7487,  12.0012,  13.3635, -15.3559,  16.8096, -11.5288]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.2964906692504883\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.3360, 11.4643, 13.2221],\n",
      "        [17.4935, 12.0122, 13.1691],\n",
      "        [17.6329, 12.3335, 13.2233],\n",
      "        [17.3891, 11.4408, 12.6141],\n",
      "        [17.8512, 11.9186, 13.4869],\n",
      "        [17.6475, 11.8143, 13.3247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6894,  17.1000, -11.6423],\n",
      "        [-15.3543,  17.0965, -11.6542],\n",
      "        [-15.4562,  17.1760, -11.2334],\n",
      "        [-15.1541,  16.6759, -11.2510],\n",
      "        [-15.3144,  16.8346, -11.1189],\n",
      "        [-14.9644,  16.4436, -11.3164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.3360,  11.4643,  13.2221, -15.6894,  17.1000, -11.6423],\n",
      "        [ 17.4935,  12.0122,  13.1691, -15.3543,  17.0965, -11.6542],\n",
      "        [ 17.6329,  12.3335,  13.2233, -15.4562,  17.1760, -11.2334],\n",
      "        [ 17.3891,  11.4408,  12.6141, -15.1541,  16.6759, -11.2510],\n",
      "        [ 17.8512,  11.9186,  13.4869, -15.3144,  16.8346, -11.1189],\n",
      "        [ 17.6475,  11.8143,  13.3247, -14.9644,  16.4436, -11.3164]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2863471508026123\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6496, 11.7053, 13.3184],\n",
      "        [17.6921, 12.0045, 13.6568],\n",
      "        [17.6888, 11.7611, 12.9536],\n",
      "        [17.4457, 11.9486, 13.3737],\n",
      "        [17.6173, 11.8869, 13.0945],\n",
      "        [17.4765, 11.7000, 13.0975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.1199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4484,  16.9403, -11.4889],\n",
      "        [-15.6149,  16.5878, -11.3742],\n",
      "        [-15.2553,  17.0151, -11.2807],\n",
      "        [-15.5683,  17.1853, -11.6977],\n",
      "        [-15.6400,  16.7834, -11.1682],\n",
      "        [-15.6286,  16.6366, -11.5794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6496,  11.7053,  13.3184, -15.4484,  16.9403, -11.4889],\n",
      "        [ 17.6921,  12.0045,  13.6568, -15.6149,  16.5878, -11.3742],\n",
      "        [ 17.6888,  11.7611,  12.9536, -15.2553,  17.0151, -11.2807],\n",
      "        [ 17.4457,  11.9486,  13.3737, -15.5683,  17.1853, -11.6977],\n",
      "        [ 17.6173,  11.8869,  13.0945, -15.6400,  16.7834, -11.1682],\n",
      "        [ 17.4765,  11.7000,  13.0975, -15.6286,  16.6366, -11.5794]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.297602653503418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8675, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6301, 12.0066, 13.4211],\n",
      "        [17.2919, 11.7972, 13.4505],\n",
      "        [17.9036, 11.9316, 13.6317],\n",
      "        [17.6884, 11.7202, 13.5545],\n",
      "        [17.6519, 12.1836, 13.6450],\n",
      "        [17.0752, 11.6958, 12.2934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5628, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3596,  17.1602, -11.5714],\n",
      "        [-14.9991,  16.7521, -11.4442],\n",
      "        [-15.6822,  16.7966, -11.4540],\n",
      "        [-15.6126,  17.1520, -11.5660],\n",
      "        [-15.9547,  17.3563, -11.4338],\n",
      "        [-15.3282,  17.0542, -11.4356]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6301,  12.0066,  13.4211, -15.3596,  17.1602, -11.5714],\n",
      "        [ 17.2919,  11.7972,  13.4505, -14.9991,  16.7521, -11.4442],\n",
      "        [ 17.9036,  11.9316,  13.6317, -15.6822,  16.7966, -11.4540],\n",
      "        [ 17.6884,  11.7202,  13.5545, -15.6126,  17.1520, -11.5660],\n",
      "        [ 17.6519,  12.1836,  13.6450, -15.9547,  17.3563, -11.4338],\n",
      "        [ 17.0752,  11.6958,  12.2934, -15.3282,  17.0542, -11.4356]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.312086343765259\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5267, 11.6538, 13.5515],\n",
      "        [17.5069, 11.7140, 13.4480],\n",
      "        [17.5179, 11.2106, 13.3344],\n",
      "        [17.7468, 11.8120, 13.2587],\n",
      "        [18.1335, 12.3690, 13.6072],\n",
      "        [17.5181, 11.9151, 13.2500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0256, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9399,  17.4391, -11.8268],\n",
      "        [-15.8873,  17.0883, -11.4549],\n",
      "        [-15.3824,  17.0337, -11.9746],\n",
      "        [-15.6944,  16.7625, -11.4758],\n",
      "        [-15.5157,  16.9165, -11.2057],\n",
      "        [-15.9634,  16.8408, -11.4992]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5267,  11.6538,  13.5515, -15.9399,  17.4391, -11.8268],\n",
      "        [ 17.5069,  11.7140,  13.4480, -15.8873,  17.0883, -11.4549],\n",
      "        [ 17.5179,  11.2106,  13.3344, -15.3824,  17.0337, -11.9746],\n",
      "        [ 17.7468,  11.8120,  13.2587, -15.6944,  16.7625, -11.4758],\n",
      "        [ 18.1335,  12.3690,  13.6072, -15.5157,  16.9165, -11.2057],\n",
      "        [ 17.5181,  11.9151,  13.2500, -15.9634,  16.8408, -11.4992]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.328256130218506\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6586, 12.2663, 13.0872],\n",
      "        [17.7925, 12.0321, 13.1496],\n",
      "        [17.2930, 11.4820, 12.9972],\n",
      "        [17.2956, 11.6571, 13.3218],\n",
      "        [17.4852, 11.8728, 14.1339],\n",
      "        [17.7705, 12.0082, 13.2575]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.3413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8287,  17.2567, -11.6926],\n",
      "        [-15.4980,  16.9345, -11.2662],\n",
      "        [-15.4761,  16.6504, -11.8477],\n",
      "        [-15.5368,  17.1048, -11.3001],\n",
      "        [-15.0780,  16.5529, -11.3221],\n",
      "        [-15.5197,  16.6718, -11.9302]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6586,  12.2663,  13.0872, -15.8287,  17.2567, -11.6926],\n",
      "        [ 17.7925,  12.0321,  13.1496, -15.4980,  16.9345, -11.2662],\n",
      "        [ 17.2930,  11.4820,  12.9972, -15.4761,  16.6504, -11.8477],\n",
      "        [ 17.2956,  11.6571,  13.3218, -15.5368,  17.1048, -11.3001],\n",
      "        [ 17.4852,  11.8728,  14.1339, -15.0780,  16.5529, -11.3221],\n",
      "        [ 17.7705,  12.0082,  13.2575, -15.5197,  16.6718, -11.9302]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.324296474456787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0187, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8210, 12.2893, 13.4777],\n",
      "        [17.6660, 12.0345, 13.2702],\n",
      "        [17.5841, 11.6315, 13.2463],\n",
      "        [17.5224, 11.5371, 13.3470],\n",
      "        [17.7721, 12.2015, 13.1872],\n",
      "        [18.0836, 12.0528, 13.8066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7208,  17.5387, -11.6069],\n",
      "        [-15.5217,  16.7704, -11.1610],\n",
      "        [-15.3342,  16.9238, -11.7381],\n",
      "        [-15.1581,  16.7395, -11.3943],\n",
      "        [-15.7704,  17.5686, -11.8712],\n",
      "        [-15.8745,  16.9084, -11.4319]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8210,  12.2893,  13.4777, -15.7208,  17.5387, -11.6069],\n",
      "        [ 17.6660,  12.0345,  13.2702, -15.5217,  16.7704, -11.1610],\n",
      "        [ 17.5841,  11.6315,  13.2463, -15.3342,  16.9238, -11.7381],\n",
      "        [ 17.5224,  11.5371,  13.3470, -15.1581,  16.7395, -11.3943],\n",
      "        [ 17.7721,  12.2015,  13.1872, -15.7704,  17.5686, -11.8712],\n",
      "        [ 18.0836,  12.0528,  13.8066, -15.8745,  16.9084, -11.4319]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.3484137058258057\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7737, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9473, 12.0877, 13.7626],\n",
      "        [17.5123, 12.1052, 13.3949],\n",
      "        [17.4570, 11.7585, 13.1749],\n",
      "        [17.6304, 11.7936, 13.0874],\n",
      "        [17.6135, 12.1663, 13.1788],\n",
      "        [17.7815, 11.7394, 13.3505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4803,  16.5559, -11.0807],\n",
      "        [-15.5306,  16.8107, -11.1538],\n",
      "        [-15.7683,  16.9675, -11.6869],\n",
      "        [-15.2652,  16.7922, -11.5141],\n",
      "        [-15.3136,  16.5880, -11.5050],\n",
      "        [-15.6519,  17.0644, -11.4476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9473,  12.0877,  13.7626, -15.4803,  16.5559, -11.0807],\n",
      "        [ 17.5123,  12.1052,  13.3949, -15.5306,  16.8107, -11.1538],\n",
      "        [ 17.4570,  11.7585,  13.1749, -15.7683,  16.9675, -11.6869],\n",
      "        [ 17.6304,  11.7936,  13.0874, -15.2652,  16.7922, -11.5141],\n",
      "        [ 17.6135,  12.1663,  13.1788, -15.3136,  16.5880, -11.5050],\n",
      "        [ 17.7815,  11.7394,  13.3505, -15.6519,  17.0644, -11.4476]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3238558769226074\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0102, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9815, 11.9701, 13.3018],\n",
      "        [17.9233, 12.1042, 13.2745],\n",
      "        [18.0114, 12.0522, 13.3088],\n",
      "        [17.4817, 11.7794, 13.3188],\n",
      "        [17.5869, 12.2745, 13.5691],\n",
      "        [17.8375, 12.1344, 13.2331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0674, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8585,  17.1317, -11.9083],\n",
      "        [-15.8353,  16.8604, -11.4710],\n",
      "        [-15.6218,  16.9271, -11.3662],\n",
      "        [-15.9499,  17.3909, -11.5657],\n",
      "        [-15.6064,  16.9007, -11.4328],\n",
      "        [-15.7293,  16.8464, -11.5655]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9815,  11.9701,  13.3018, -15.8585,  17.1317, -11.9083],\n",
      "        [ 17.9233,  12.1042,  13.2745, -15.8353,  16.8604, -11.4710],\n",
      "        [ 18.0114,  12.0522,  13.3088, -15.6218,  16.9271, -11.3662],\n",
      "        [ 17.4817,  11.7794,  13.3188, -15.9499,  17.3909, -11.5657],\n",
      "        [ 17.5869,  12.2745,  13.5691, -15.6064,  16.9007, -11.4328],\n",
      "        [ 17.8375,  12.1344,  13.2331, -15.7293,  16.8464, -11.5655]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.342621088027954\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9771, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5915, 11.9317, 13.3065],\n",
      "        [17.6488, 12.2460, 13.4294],\n",
      "        [17.9764, 11.8859, 13.3961],\n",
      "        [17.5308, 11.9770, 13.9611],\n",
      "        [17.7600, 11.9509, 13.2107],\n",
      "        [17.2840, 11.6664, 13.0942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.8949, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3021,  16.7103, -11.4748],\n",
      "        [-15.7539,  17.3459, -11.6445],\n",
      "        [-15.6126,  17.0498, -11.5294],\n",
      "        [-15.8387,  17.0201, -11.4998],\n",
      "        [-15.5340,  16.6713, -11.1988],\n",
      "        [-15.6536,  16.5076, -11.2398]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5915,  11.9317,  13.3065, -15.3021,  16.7103, -11.4748],\n",
      "        [ 17.6488,  12.2460,  13.4294, -15.7539,  17.3459, -11.6445],\n",
      "        [ 17.9764,  11.8859,  13.3961, -15.6126,  17.0498, -11.5294],\n",
      "        [ 17.5308,  11.9770,  13.9611, -15.8387,  17.0201, -11.4998],\n",
      "        [ 17.7600,  11.9509,  13.2107, -15.5340,  16.6713, -11.1988],\n",
      "        [ 17.2840,  11.6664,  13.0942, -15.6536,  16.5076, -11.2398]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.2988922595977783\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7125, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8259, 12.1024, 13.4432],\n",
      "        [17.7718, 11.4606, 13.2381],\n",
      "        [17.8286, 11.8687, 13.1427],\n",
      "        [17.9030, 12.1672, 13.6796],\n",
      "        [17.7307, 11.7097, 13.5259],\n",
      "        [17.9570, 11.9749, 13.4157]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.8027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7522,  17.0800, -11.3468],\n",
      "        [-15.9419,  16.8199, -11.8507],\n",
      "        [-15.3897,  17.4260, -11.9438],\n",
      "        [-15.4574,  17.2524, -11.5712],\n",
      "        [-15.2605,  16.6088, -11.1964],\n",
      "        [-15.4514,  16.7817, -11.6498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8259,  12.1024,  13.4432, -15.7522,  17.0800, -11.3468],\n",
      "        [ 17.7718,  11.4606,  13.2381, -15.9419,  16.8199, -11.8507],\n",
      "        [ 17.8286,  11.8687,  13.1427, -15.3897,  17.4260, -11.9438],\n",
      "        [ 17.9030,  12.1672,  13.6796, -15.4574,  17.2524, -11.5712],\n",
      "        [ 17.7307,  11.7097,  13.5259, -15.2605,  16.6088, -11.1964],\n",
      "        [ 17.9570,  11.9749,  13.4157, -15.4514,  16.7817, -11.6498]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3343138694763184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6341, 12.3848, 13.4108],\n",
      "        [17.7836, 11.9011, 13.4351],\n",
      "        [17.8224, 11.7092, 13.3940],\n",
      "        [17.8396, 12.0931, 13.5043],\n",
      "        [17.9875, 12.5521, 13.7815],\n",
      "        [17.7850, 12.0412, 13.5212]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0180, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6835,  17.0239, -11.4242],\n",
      "        [-15.4234,  17.0568, -11.8619],\n",
      "        [-15.6048,  17.1916, -11.7773],\n",
      "        [-15.7391,  17.2190, -11.4590],\n",
      "        [-15.0930,  17.0106, -11.5849],\n",
      "        [-16.1653,  17.5652, -11.8017]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6341,  12.3848,  13.4108, -15.6835,  17.0239, -11.4242],\n",
      "        [ 17.7836,  11.9011,  13.4351, -15.4234,  17.0568, -11.8619],\n",
      "        [ 17.8224,  11.7092,  13.3940, -15.6048,  17.1916, -11.7773],\n",
      "        [ 17.8396,  12.0931,  13.5043, -15.7391,  17.2190, -11.4590],\n",
      "        [ 17.9875,  12.5521,  13.7815, -15.0930,  17.0106, -11.5849],\n",
      "        [ 17.7850,  12.0412,  13.5212, -16.1653,  17.5652, -11.8017]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3307831287384033\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6627, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8971, 12.1734, 13.6985],\n",
      "        [18.3494, 12.7095, 13.7569],\n",
      "        [17.4933, 12.2003, 13.5186],\n",
      "        [17.5405, 11.6902, 12.7468],\n",
      "        [17.8235, 11.9344, 13.0167],\n",
      "        [17.9190, 11.7964, 13.4321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.8085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2327,  16.8027, -11.8152],\n",
      "        [-15.7266,  16.6491, -11.5010],\n",
      "        [-15.6200,  17.2320, -11.4628],\n",
      "        [-15.7663,  17.4896, -12.1148],\n",
      "        [-15.8320,  16.8760, -11.5636],\n",
      "        [-15.5531,  16.3269, -11.4552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8971,  12.1734,  13.6985, -15.2327,  16.8027, -11.8152],\n",
      "        [ 18.3494,  12.7095,  13.7569, -15.7266,  16.6491, -11.5010],\n",
      "        [ 17.4933,  12.2003,  13.5186, -15.6200,  17.2320, -11.4628],\n",
      "        [ 17.5405,  11.6902,  12.7468, -15.7663,  17.4896, -12.1148],\n",
      "        [ 17.8235,  11.9344,  13.0167, -15.8320,  16.8760, -11.5636],\n",
      "        [ 17.9190,  11.7964,  13.4321, -15.5531,  16.3269, -11.4552]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.338444471359253\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8649, 11.9538, 13.4641],\n",
      "        [17.6341, 12.1309, 12.9687],\n",
      "        [17.5689, 11.6577, 13.2488],\n",
      "        [17.7600, 12.1752, 13.6182],\n",
      "        [18.0330, 12.0312, 13.5922],\n",
      "        [17.9286, 12.0176, 13.3118]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.5116,  16.5702, -11.3763],\n",
      "        [-15.4427,  16.7085, -11.4305],\n",
      "        [-15.9312,  17.1548, -11.8099],\n",
      "        [-15.7343,  17.3570, -11.4060],\n",
      "        [-15.6115,  16.6611, -11.5468],\n",
      "        [-15.5403,  16.7720, -11.6174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8649,  11.9538,  13.4641, -15.5116,  16.5702, -11.3763],\n",
      "        [ 17.6341,  12.1309,  12.9687, -15.4427,  16.7085, -11.4305],\n",
      "        [ 17.5689,  11.6577,  13.2488, -15.9312,  17.1548, -11.8099],\n",
      "        [ 17.7600,  12.1752,  13.6182, -15.7343,  17.3570, -11.4060],\n",
      "        [ 18.0330,  12.0312,  13.5922, -15.6115,  16.6611, -11.5468],\n",
      "        [ 17.9286,  12.0176,  13.3118, -15.5403,  16.7720, -11.6174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3201441764831543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7136, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7198, 12.2225, 13.4692],\n",
      "        [18.1842, 11.9993, 13.7038],\n",
      "        [17.8880, 12.4005, 13.3218],\n",
      "        [18.1433, 11.9733, 13.5708],\n",
      "        [17.8768, 12.1039, 13.3618],\n",
      "        [17.8211, 11.8701, 13.1857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.8685, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0009,  16.9476, -11.7125],\n",
      "        [-15.4804,  17.1647, -11.5695],\n",
      "        [-15.4121,  17.1391, -11.4240],\n",
      "        [-15.7496,  17.3459, -11.6544],\n",
      "        [-15.8795,  17.5690, -11.8658],\n",
      "        [-15.7165,  17.2026, -11.3237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7198,  12.2225,  13.4692, -16.0009,  16.9476, -11.7125],\n",
      "        [ 18.1842,  11.9993,  13.7038, -15.4804,  17.1647, -11.5695],\n",
      "        [ 17.8880,  12.4005,  13.3218, -15.4121,  17.1391, -11.4240],\n",
      "        [ 18.1433,  11.9733,  13.5708, -15.7496,  17.3459, -11.6544],\n",
      "        [ 17.8768,  12.1039,  13.3618, -15.8795,  17.5690, -11.8658],\n",
      "        [ 17.8211,  11.8701,  13.1857, -15.7165,  17.2026, -11.3237]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3454067707061768\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.4946, 11.8074, 13.3950],\n",
      "        [18.0703, 11.8305, 13.9574],\n",
      "        [17.8809, 11.6856, 13.8720],\n",
      "        [18.2288, 12.1177, 13.5647],\n",
      "        [17.6151, 11.9738, 13.4613],\n",
      "        [17.5865, 11.9358, 13.5123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2112, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7434,  16.8513, -11.1740],\n",
      "        [-15.2977,  17.0294, -11.5300],\n",
      "        [-15.9291,  17.0666, -11.6611],\n",
      "        [-15.3533,  17.1156, -11.5086],\n",
      "        [-15.8217,  16.9783, -11.5701],\n",
      "        [-15.5566,  17.2208, -11.6559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.4946,  11.8074,  13.3950, -15.7434,  16.8513, -11.1740],\n",
      "        [ 18.0703,  11.8305,  13.9574, -15.2977,  17.0294, -11.5300],\n",
      "        [ 17.8809,  11.6856,  13.8720, -15.9291,  17.0666, -11.6611],\n",
      "        [ 18.2288,  12.1177,  13.5647, -15.3533,  17.1156, -11.5086],\n",
      "        [ 17.6151,  11.9738,  13.4613, -15.8217,  16.9783, -11.5701],\n",
      "        [ 17.5865,  11.9358,  13.5123, -15.5566,  17.2208, -11.6559]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3104071617126465\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9129, 12.1681, 13.4899],\n",
      "        [17.9460, 12.3567, 13.3271],\n",
      "        [17.6272, 11.9106, 13.3786],\n",
      "        [17.6172, 11.9524, 13.3994],\n",
      "        [17.5794, 11.7708, 13.5074],\n",
      "        [17.9383, 12.3468, 13.1640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7465,  17.2294, -11.7055],\n",
      "        [-15.8910,  17.2110, -11.7866],\n",
      "        [-15.5975,  17.4690, -11.6312],\n",
      "        [-15.5651,  16.7105, -11.2846],\n",
      "        [-15.5777,  17.3525, -11.4781],\n",
      "        [-15.4983,  17.1900, -11.7209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9129,  12.1681,  13.4899, -15.7465,  17.2294, -11.7055],\n",
      "        [ 17.9460,  12.3567,  13.3271, -15.8910,  17.2110, -11.7866],\n",
      "        [ 17.6272,  11.9106,  13.3786, -15.5975,  17.4690, -11.6312],\n",
      "        [ 17.6172,  11.9524,  13.3994, -15.5651,  16.7105, -11.2846],\n",
      "        [ 17.5794,  11.7708,  13.5074, -15.5777,  17.3525, -11.4781],\n",
      "        [ 17.9383,  12.3468,  13.1640, -15.4983,  17.1900, -11.7209]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3564488887786865\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8644, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8419, 12.0876, 13.6586],\n",
      "        [17.7770, 11.9463, 13.4092],\n",
      "        [16.9961, 11.8162, 13.2038],\n",
      "        [17.5304, 11.7997, 13.6734],\n",
      "        [17.8167, 11.7339, 13.3841],\n",
      "        [17.9689, 11.8109, 13.8283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.1083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3951,  16.7426, -11.2994],\n",
      "        [-15.4641,  16.8889, -11.4237],\n",
      "        [-15.6870,  17.1864, -11.5911],\n",
      "        [-15.8591,  16.8678, -11.5547],\n",
      "        [-15.6296,  16.9388, -11.8826],\n",
      "        [-15.8943,  17.6693, -11.8059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8419,  12.0876,  13.6586, -15.3951,  16.7426, -11.2994],\n",
      "        [ 17.7770,  11.9463,  13.4092, -15.4641,  16.8889, -11.4237],\n",
      "        [ 16.9961,  11.8162,  13.2038, -15.6870,  17.1864, -11.5911],\n",
      "        [ 17.5304,  11.7997,  13.6734, -15.8591,  16.8678, -11.5547],\n",
      "        [ 17.8167,  11.7339,  13.3841, -15.6296,  16.9388, -11.8826],\n",
      "        [ 17.9689,  11.8109,  13.8283, -15.8943,  17.6693, -11.8059]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.333435297012329\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0060, 12.0308, 13.4024],\n",
      "        [17.3686, 11.7318, 13.5042],\n",
      "        [17.8079, 11.8209, 13.6921],\n",
      "        [17.6756, 11.8748, 13.4522],\n",
      "        [17.8061, 12.5747, 13.6095],\n",
      "        [18.1823, 12.6092, 13.8626]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7107, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.4011,  16.8872, -11.4456],\n",
      "        [-15.6148,  16.7897, -11.2735],\n",
      "        [-15.9391,  17.4809, -11.9987],\n",
      "        [-15.8194,  17.3180, -11.9507],\n",
      "        [-15.7593,  17.1754, -11.5553],\n",
      "        [-15.5254,  17.1678, -11.8461]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0060,  12.0308,  13.4024, -15.4011,  16.8872, -11.4456],\n",
      "        [ 17.3686,  11.7318,  13.5042, -15.6148,  16.7897, -11.2735],\n",
      "        [ 17.8079,  11.8209,  13.6921, -15.9391,  17.4809, -11.9987],\n",
      "        [ 17.6756,  11.8748,  13.4522, -15.8194,  17.3180, -11.9507],\n",
      "        [ 17.8061,  12.5747,  13.6095, -15.7593,  17.1754, -11.5553],\n",
      "        [ 18.1823,  12.6092,  13.8626, -15.5254,  17.1678, -11.8461]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.337597608566284\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9131, 12.0751, 13.8422],\n",
      "        [17.9035, 11.9679, 13.7457],\n",
      "        [17.8117, 11.6969, 13.6448],\n",
      "        [17.5376, 11.7050, 13.2012],\n",
      "        [17.6619, 11.8009, 13.3852],\n",
      "        [17.7454, 11.6825, 13.2548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1625, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9946,  16.8851, -11.6203],\n",
      "        [-15.7597,  17.2632, -11.7075],\n",
      "        [-15.8171,  16.8969, -11.5952],\n",
      "        [-15.7292,  17.1710, -11.7962],\n",
      "        [-15.6309,  17.3797, -11.6787],\n",
      "        [-15.4163,  16.5579, -11.4332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9131,  12.0751,  13.8422, -15.9946,  16.8851, -11.6203],\n",
      "        [ 17.9035,  11.9679,  13.7457, -15.7597,  17.2632, -11.7075],\n",
      "        [ 17.8117,  11.6969,  13.6448, -15.8171,  16.8969, -11.5952],\n",
      "        [ 17.5376,  11.7050,  13.2012, -15.7292,  17.1710, -11.7962],\n",
      "        [ 17.6619,  11.8009,  13.3852, -15.6309,  17.3797, -11.6787],\n",
      "        [ 17.7454,  11.6825,  13.2548, -15.4163,  16.5579, -11.4332]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.365293025970459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6281, 11.9866, 13.5419],\n",
      "        [17.8791, 12.3497, 13.5304],\n",
      "        [17.8553, 12.2483, 13.8870],\n",
      "        [17.7033, 11.8849, 13.5006],\n",
      "        [17.7087, 12.2341, 13.4687],\n",
      "        [17.8088, 11.8239, 13.6878]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3105,  17.2438, -11.8684],\n",
      "        [-15.2314,  16.9751, -11.5729],\n",
      "        [-15.5234,  16.9547, -11.4136],\n",
      "        [-15.8764,  17.3065, -11.9215],\n",
      "        [-15.3450,  16.9560, -11.6195],\n",
      "        [-15.8680,  17.1024, -11.6186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6281,  11.9866,  13.5419, -15.3105,  17.2438, -11.8684],\n",
      "        [ 17.8791,  12.3497,  13.5304, -15.2314,  16.9751, -11.5729],\n",
      "        [ 17.8553,  12.2483,  13.8870, -15.5234,  16.9547, -11.4136],\n",
      "        [ 17.7033,  11.8849,  13.5006, -15.8764,  17.3065, -11.9215],\n",
      "        [ 17.7087,  12.2341,  13.4687, -15.3450,  16.9560, -11.6195],\n",
      "        [ 17.8088,  11.8239,  13.6878, -15.8680,  17.1024, -11.6186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.340442419052124\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6176, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8896, 11.9541, 13.3437],\n",
      "        [17.6481, 12.3842, 13.3992],\n",
      "        [17.7589, 12.1831, 13.4059],\n",
      "        [17.6415, 12.1200, 13.3077],\n",
      "        [17.6405, 12.0236, 13.4109],\n",
      "        [17.7775, 12.0936, 13.8981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1311, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8003,  17.0580, -11.6964],\n",
      "        [-15.6446,  17.2785, -11.5214],\n",
      "        [-15.8028,  17.3076, -11.7448],\n",
      "        [-15.6224,  17.1646, -11.6395],\n",
      "        [-15.5903,  16.8784, -11.5306],\n",
      "        [-15.9444,  17.5563, -12.1760]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8896,  11.9541,  13.3437, -15.8003,  17.0580, -11.6964],\n",
      "        [ 17.6481,  12.3842,  13.3992, -15.6446,  17.2785, -11.5214],\n",
      "        [ 17.7589,  12.1831,  13.4059, -15.8028,  17.3076, -11.7448],\n",
      "        [ 17.6415,  12.1200,  13.3077, -15.6224,  17.1646, -11.6395],\n",
      "        [ 17.6405,  12.0236,  13.4109, -15.5903,  16.8784, -11.5306],\n",
      "        [ 17.7775,  12.0936,  13.8981, -15.9444,  17.5563, -12.1760]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3489630222320557\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7792, 12.0735, 13.3688],\n",
      "        [18.2259, 12.2749, 13.5176],\n",
      "        [18.0697, 12.1061, 13.6521],\n",
      "        [17.9192, 12.2518, 13.7721],\n",
      "        [17.7066, 11.8610, 13.2236],\n",
      "        [17.6612, 12.4477, 12.9967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6850, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7459,  16.7301, -11.2420],\n",
      "        [-16.0163,  17.5105, -11.5914],\n",
      "        [-15.3878,  16.9599, -11.6491],\n",
      "        [-15.6466,  17.0741, -11.7345],\n",
      "        [-15.7626,  16.9389, -11.2274],\n",
      "        [-15.3179,  17.0196, -11.4677]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7792,  12.0735,  13.3688, -15.7459,  16.7301, -11.2420],\n",
      "        [ 18.2259,  12.2749,  13.5176, -16.0163,  17.5105, -11.5914],\n",
      "        [ 18.0697,  12.1061,  13.6521, -15.3878,  16.9599, -11.6491],\n",
      "        [ 17.9192,  12.2518,  13.7721, -15.6466,  17.0741, -11.7345],\n",
      "        [ 17.7066,  11.8610,  13.2236, -15.7626,  16.9389, -11.2274],\n",
      "        [ 17.6612,  12.4477,  12.9967, -15.3179,  17.0196, -11.4677]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3332934379577637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6573, 12.2716, 13.5303],\n",
      "        [18.2313, 12.4029, 13.7651],\n",
      "        [17.4746, 12.2191, 13.3291],\n",
      "        [17.5359, 11.6424, 12.8627],\n",
      "        [17.4696, 11.7623, 13.4120],\n",
      "        [17.9562, 11.9668, 13.6910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3860,  17.1698, -11.4849],\n",
      "        [-15.5439,  17.0073, -11.8435],\n",
      "        [-15.8754,  17.0991, -11.7613],\n",
      "        [-15.8657,  17.3945, -11.7589],\n",
      "        [-15.9646,  17.1798, -11.7209],\n",
      "        [-15.7867,  17.2692, -12.1177]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6573,  12.2716,  13.5303, -15.3860,  17.1698, -11.4849],\n",
      "        [ 18.2313,  12.4029,  13.7651, -15.5439,  17.0073, -11.8435],\n",
      "        [ 17.4746,  12.2191,  13.3291, -15.8754,  17.0991, -11.7613],\n",
      "        [ 17.5359,  11.6424,  12.8627, -15.8657,  17.3945, -11.7589],\n",
      "        [ 17.4696,  11.7623,  13.4120, -15.9646,  17.1798, -11.7209],\n",
      "        [ 17.9562,  11.9668,  13.6910, -15.7867,  17.2692, -12.1177]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.345134973526001\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1103, 11.9589, 13.3469],\n",
      "        [17.2335, 11.8141, 13.1223],\n",
      "        [18.0986, 12.2226, 13.5972],\n",
      "        [18.0112, 12.3019, 13.4796],\n",
      "        [18.0198, 12.0166, 13.4579],\n",
      "        [18.1243, 12.3118, 13.4308]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.4592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8357,  17.2386, -11.4245],\n",
      "        [-15.6717,  16.8291, -11.5780],\n",
      "        [-15.9445,  17.5117, -11.5863],\n",
      "        [-15.2365,  16.7466, -11.4285],\n",
      "        [-15.0852,  16.7507, -11.8099],\n",
      "        [-15.8559,  17.1241, -11.5501]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1103,  11.9589,  13.3469, -15.8357,  17.2386, -11.4245],\n",
      "        [ 17.2335,  11.8141,  13.1223, -15.6717,  16.8291, -11.5780],\n",
      "        [ 18.0986,  12.2226,  13.5972, -15.9445,  17.5117, -11.5863],\n",
      "        [ 18.0112,  12.3019,  13.4796, -15.2365,  16.7466, -11.4285],\n",
      "        [ 18.0198,  12.0166,  13.4579, -15.0852,  16.7507, -11.8099],\n",
      "        [ 18.1243,  12.3118,  13.4308, -15.8559,  17.1241, -11.5501]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.3629658222198486\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1595, 12.1372, 13.7438],\n",
      "        [18.2057, 12.4242, 13.3721],\n",
      "        [18.1485, 12.1333, 13.8478],\n",
      "        [18.0275, 12.1443, 13.2532],\n",
      "        [17.5565, 12.3624, 13.7522],\n",
      "        [17.6151, 12.2057, 13.4850]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.8972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6708,  17.4051, -11.8933],\n",
      "        [-15.6231,  17.2740, -11.6768],\n",
      "        [-15.7932,  17.1415, -11.4950],\n",
      "        [-16.0465,  17.5334, -11.7772],\n",
      "        [-15.8103,  17.1364, -11.7183],\n",
      "        [-15.5170,  16.9464, -11.6119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1595,  12.1372,  13.7438, -15.6708,  17.4051, -11.8933],\n",
      "        [ 18.2057,  12.4242,  13.3721, -15.6231,  17.2740, -11.6768],\n",
      "        [ 18.1485,  12.1333,  13.8478, -15.7932,  17.1415, -11.4950],\n",
      "        [ 18.0275,  12.1443,  13.2532, -16.0465,  17.5334, -11.7772],\n",
      "        [ 17.5565,  12.3624,  13.7522, -15.8103,  17.1364, -11.7183],\n",
      "        [ 17.6151,  12.2057,  13.4850, -15.5170,  16.9464, -11.6119]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.390167236328125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9038, 12.0162, 13.3558],\n",
      "        [17.8839, 12.2622, 13.1795],\n",
      "        [17.7259, 12.0464, 13.1253],\n",
      "        [17.8256, 12.1826, 13.2033],\n",
      "        [17.8982, 12.0960, 13.8161],\n",
      "        [17.6605, 12.1374, 13.2150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5234, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8903,  17.0950, -11.5273],\n",
      "        [-15.8340,  17.3382, -11.9002],\n",
      "        [-15.3829,  17.0054, -11.5828],\n",
      "        [-15.2278,  17.3139, -11.4999],\n",
      "        [-15.4484,  16.4046, -11.2623],\n",
      "        [-15.9838,  17.1636, -11.8292]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9038,  12.0162,  13.3558, -15.8903,  17.0950, -11.5273],\n",
      "        [ 17.8839,  12.2622,  13.1795, -15.8340,  17.3382, -11.9002],\n",
      "        [ 17.7259,  12.0464,  13.1253, -15.3829,  17.0054, -11.5828],\n",
      "        [ 17.8256,  12.1826,  13.2033, -15.2278,  17.3139, -11.4999],\n",
      "        [ 17.8982,  12.0960,  13.8161, -15.4484,  16.4046, -11.2623],\n",
      "        [ 17.6605,  12.1374,  13.2150, -15.9838,  17.1636, -11.8292]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3574483394622803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5411, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7604, 12.2011, 13.2645],\n",
      "        [17.9824, 12.1222, 13.9414],\n",
      "        [17.9852, 11.7588, 13.4819],\n",
      "        [18.1221, 12.2844, 13.5427],\n",
      "        [17.8841, 11.9691, 13.3110],\n",
      "        [17.5053, 11.8430, 13.4245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1966, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8211,  17.0430, -11.6761],\n",
      "        [-15.5221,  17.3551, -11.9320],\n",
      "        [-15.7609,  17.0899, -11.6552],\n",
      "        [-15.3973,  16.5444, -11.5796],\n",
      "        [-15.5430,  17.4139, -11.6441],\n",
      "        [-15.8586,  17.2414, -11.6062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7604,  12.2011,  13.2645, -15.8211,  17.0430, -11.6761],\n",
      "        [ 17.9824,  12.1222,  13.9414, -15.5221,  17.3551, -11.9320],\n",
      "        [ 17.9852,  11.7588,  13.4819, -15.7609,  17.0899, -11.6552],\n",
      "        [ 18.1221,  12.2844,  13.5427, -15.3973,  16.5444, -11.5796],\n",
      "        [ 17.8841,  11.9691,  13.3110, -15.5430,  17.4139, -11.6441],\n",
      "        [ 17.5053,  11.8430,  13.4245, -15.8586,  17.2414, -11.6062]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3530685901641846\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9396, 12.6069, 13.5829],\n",
      "        [18.1243, 12.4013, 13.7228],\n",
      "        [17.6423, 12.2313, 13.7596],\n",
      "        [17.8983, 12.0640, 13.5244],\n",
      "        [18.3523, 12.0665, 13.8243],\n",
      "        [17.8846, 11.9980, 13.6435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.4226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0999,  16.8751, -11.7323],\n",
      "        [-15.8424,  17.2657, -11.8831],\n",
      "        [-15.5800,  16.9813, -11.1178],\n",
      "        [-15.6280,  17.2383, -11.5234],\n",
      "        [-15.7826,  17.0810, -11.8545],\n",
      "        [-15.5879,  16.8006, -11.7851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9396,  12.6069,  13.5829, -16.0999,  16.8751, -11.7323],\n",
      "        [ 18.1243,  12.4013,  13.7228, -15.8424,  17.2657, -11.8831],\n",
      "        [ 17.6423,  12.2313,  13.7596, -15.5800,  16.9813, -11.1178],\n",
      "        [ 17.8983,  12.0640,  13.5244, -15.6280,  17.2383, -11.5234],\n",
      "        [ 18.3523,  12.0665,  13.8243, -15.7826,  17.0810, -11.8545],\n",
      "        [ 17.8846,  11.9980,  13.6435, -15.5879,  16.8006, -11.7851]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.383596658706665\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6593, 11.6919, 13.8388],\n",
      "        [18.2526, 12.0445, 13.3762],\n",
      "        [18.3315, 12.4258, 13.6961],\n",
      "        [17.9694, 12.1393, 13.8701],\n",
      "        [17.6014, 11.8352, 13.5398],\n",
      "        [17.8431, 12.2173, 13.5322]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.2304,  16.7945, -11.9340],\n",
      "        [-15.8689,  17.4401, -11.7445],\n",
      "        [-15.6171,  17.2338, -11.6855],\n",
      "        [-15.5305,  17.1681, -11.8015],\n",
      "        [-15.6382,  16.8385, -11.5439],\n",
      "        [-15.4336,  17.0867, -11.2035]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6593,  11.6919,  13.8388, -15.2304,  16.7945, -11.9340],\n",
      "        [ 18.2526,  12.0445,  13.3762, -15.8689,  17.4401, -11.7445],\n",
      "        [ 18.3315,  12.4258,  13.6961, -15.6171,  17.2338, -11.6855],\n",
      "        [ 17.9694,  12.1393,  13.8701, -15.5305,  17.1681, -11.8015],\n",
      "        [ 17.6014,  11.8352,  13.5398, -15.6382,  16.8385, -11.5439],\n",
      "        [ 17.8431,  12.2173,  13.5322, -15.4336,  17.0867, -11.2035]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.344024181365967\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5834, 12.4472, 13.7101],\n",
      "        [17.9740, 11.9310, 13.7629],\n",
      "        [17.3833, 12.1474, 13.1387],\n",
      "        [17.9783, 12.0314, 13.4254],\n",
      "        [17.7971, 11.6657, 13.0484],\n",
      "        [17.9338, 12.5306, 13.9559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2480, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8790,  17.4106, -11.8697],\n",
      "        [-15.7584,  17.1785, -11.5736],\n",
      "        [-15.6691,  17.3575, -11.8455],\n",
      "        [-15.7970,  17.1803, -11.3838],\n",
      "        [-16.1963,  17.1851, -12.1104],\n",
      "        [-15.5991,  17.0872, -11.5353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5834,  12.4472,  13.7101, -15.8790,  17.4106, -11.8697],\n",
      "        [ 17.9740,  11.9310,  13.7629, -15.7584,  17.1785, -11.5736],\n",
      "        [ 17.3833,  12.1474,  13.1387, -15.6691,  17.3575, -11.8455],\n",
      "        [ 17.9783,  12.0314,  13.4254, -15.7970,  17.1803, -11.3838],\n",
      "        [ 17.7971,  11.6657,  13.0484, -16.1963,  17.1851, -12.1104],\n",
      "        [ 17.9338,  12.5306,  13.9559, -15.5991,  17.0872, -11.5353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.423623561859131\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6503, 11.5987, 13.2575],\n",
      "        [17.9214, 11.9603, 13.9178],\n",
      "        [17.7385, 11.8157, 13.4140],\n",
      "        [17.3721, 12.1235, 13.4567],\n",
      "        [17.7977, 11.8397, 13.6087],\n",
      "        [17.5517, 11.9967, 13.4833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2732, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8530,  17.1884, -11.3543],\n",
      "        [-15.9739,  17.4031, -12.0532],\n",
      "        [-15.6702,  16.7656, -11.2350],\n",
      "        [-15.7014,  16.9180, -11.8825],\n",
      "        [-16.0795,  17.0484, -11.7847],\n",
      "        [-15.7339,  17.3812, -11.7630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6503,  11.5987,  13.2575, -15.8530,  17.1884, -11.3543],\n",
      "        [ 17.9214,  11.9603,  13.9178, -15.9739,  17.4031, -12.0532],\n",
      "        [ 17.7385,  11.8157,  13.4140, -15.6702,  16.7656, -11.2350],\n",
      "        [ 17.3721,  12.1235,  13.4567, -15.7014,  16.9180, -11.8825],\n",
      "        [ 17.7977,  11.8397,  13.6087, -16.0795,  17.0484, -11.7847],\n",
      "        [ 17.5517,  11.9967,  13.4833, -15.7339,  17.3812, -11.7630]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.339390516281128\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.5837, 12.0155, 13.6174],\n",
      "        [17.8419, 12.4811, 13.5002],\n",
      "        [18.1532, 12.5014, 13.0711],\n",
      "        [17.7458, 12.4517, 14.0457],\n",
      "        [17.4648, 12.2875, 13.4878],\n",
      "        [17.9021, 12.2775, 13.7958]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.2704, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.3867,  17.2591, -11.6738],\n",
      "        [-15.5711,  16.7511, -11.6312],\n",
      "        [-15.8220,  17.5509, -12.0491],\n",
      "        [-16.3153,  17.9519, -12.2228],\n",
      "        [-15.7466,  17.1556, -11.4880],\n",
      "        [-15.4406,  16.9388, -11.5544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.5837,  12.0155,  13.6174, -15.3867,  17.2591, -11.6738],\n",
      "        [ 17.8419,  12.4811,  13.5002, -15.5711,  16.7511, -11.6312],\n",
      "        [ 18.1532,  12.5014,  13.0711, -15.8220,  17.5509, -12.0491],\n",
      "        [ 17.7458,  12.4517,  14.0457, -16.3153,  17.9519, -12.2228],\n",
      "        [ 17.4648,  12.2875,  13.4878, -15.7466,  17.1556, -11.4880],\n",
      "        [ 17.9021,  12.2775,  13.7958, -15.4406,  16.9388, -11.5544]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3547658920288086\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6453, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9811, 12.2451, 13.6615],\n",
      "        [17.3493, 11.5895, 13.4237],\n",
      "        [17.7267, 12.3228, 13.7099],\n",
      "        [17.9710, 12.4274, 13.8573],\n",
      "        [17.7711, 12.4114, 13.8335],\n",
      "        [18.2008, 12.5779, 13.6085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.2731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9265,  17.1688, -11.8336],\n",
      "        [-15.2911,  16.8881, -11.4796],\n",
      "        [-15.4903,  17.1880, -12.0150],\n",
      "        [-15.9092,  17.2095, -11.9490],\n",
      "        [-15.6179,  17.2216, -11.9039],\n",
      "        [-16.1979,  17.4986, -11.6191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9811,  12.2451,  13.6615, -15.9265,  17.1688, -11.8336],\n",
      "        [ 17.3493,  11.5895,  13.4237, -15.2911,  16.8881, -11.4796],\n",
      "        [ 17.7267,  12.3228,  13.7099, -15.4903,  17.1880, -12.0150],\n",
      "        [ 17.9710,  12.4274,  13.8573, -15.9092,  17.2095, -11.9490],\n",
      "        [ 17.7711,  12.4114,  13.8335, -15.6179,  17.2216, -11.9039],\n",
      "        [ 18.2008,  12.5779,  13.6085, -16.1979,  17.4986, -11.6191]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3907787799835205\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9398, 12.0447, 13.6153],\n",
      "        [17.7098, 12.2350, 13.9108],\n",
      "        [17.5953, 12.1042, 13.3971],\n",
      "        [18.0671, 12.2859, 13.3800],\n",
      "        [17.9058, 12.1959, 13.8978],\n",
      "        [18.0833, 12.1260, 13.8787]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0456,  16.9834, -11.8366],\n",
      "        [-15.9187,  16.9127, -11.9270],\n",
      "        [-15.6071,  17.2209, -11.7756],\n",
      "        [-15.8348,  17.2828, -11.7198],\n",
      "        [-15.6393,  17.2516, -11.6071],\n",
      "        [-15.9944,  17.2982, -11.5097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9398,  12.0447,  13.6153, -16.0456,  16.9834, -11.8366],\n",
      "        [ 17.7098,  12.2350,  13.9108, -15.9187,  16.9127, -11.9270],\n",
      "        [ 17.5953,  12.1042,  13.3971, -15.6071,  17.2209, -11.7756],\n",
      "        [ 18.0671,  12.2859,  13.3800, -15.8348,  17.2828, -11.7198],\n",
      "        [ 17.9058,  12.1959,  13.8978, -15.6393,  17.2516, -11.6071],\n",
      "        [ 18.0833,  12.1260,  13.8787, -15.9944,  17.2982, -11.5097]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.382584571838379\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6832, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7234, 12.2360, 13.8298],\n",
      "        [17.9163, 12.0843, 13.6299],\n",
      "        [17.6346, 11.9650, 13.5507],\n",
      "        [17.9175, 12.0380, 13.1836],\n",
      "        [17.6065, 12.0890, 13.5296],\n",
      "        [17.9047, 11.6570, 13.2799]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5264, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6820,  17.3396, -11.3220],\n",
      "        [-15.6161,  17.1230, -11.8859],\n",
      "        [-15.7738,  17.2372, -11.7341],\n",
      "        [-15.9210,  17.4778, -12.0073],\n",
      "        [-16.1539,  17.4492, -11.7724],\n",
      "        [-16.0956,  17.2281, -11.9066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7234,  12.2360,  13.8298, -15.6820,  17.3396, -11.3220],\n",
      "        [ 17.9163,  12.0843,  13.6299, -15.6161,  17.1230, -11.8859],\n",
      "        [ 17.6346,  11.9650,  13.5507, -15.7738,  17.2372, -11.7341],\n",
      "        [ 17.9175,  12.0380,  13.1836, -15.9210,  17.4778, -12.0073],\n",
      "        [ 17.6065,  12.0890,  13.5296, -16.1539,  17.4492, -11.7724],\n",
      "        [ 17.9047,  11.6570,  13.2799, -16.0956,  17.2281, -11.9066]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3789079189300537\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6948, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2370, 12.2974, 13.7398],\n",
      "        [18.1893, 12.3487, 13.7025],\n",
      "        [18.0207, 11.9799, 13.7062],\n",
      "        [17.5703, 11.9552, 13.4810],\n",
      "        [17.5656, 12.2167, 13.7770],\n",
      "        [17.8016, 11.9965, 13.6585]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8175,  17.4291, -11.6717],\n",
      "        [-15.2746,  16.8547, -11.4655],\n",
      "        [-16.1403,  17.3951, -11.6331],\n",
      "        [-15.7927,  17.3039, -11.7023],\n",
      "        [-15.5368,  17.1059, -12.0135],\n",
      "        [-15.5238,  17.2362, -11.5978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2370,  12.2974,  13.7398, -15.8175,  17.4291, -11.6717],\n",
      "        [ 18.1893,  12.3487,  13.7025, -15.2746,  16.8547, -11.4655],\n",
      "        [ 18.0207,  11.9799,  13.7062, -16.1403,  17.3951, -11.6331],\n",
      "        [ 17.5703,  11.9552,  13.4810, -15.7927,  17.3039, -11.7023],\n",
      "        [ 17.5656,  12.2167,  13.7770, -15.5368,  17.1059, -12.0135],\n",
      "        [ 17.8016,  11.9965,  13.6585, -15.5238,  17.2362, -11.5978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.410205602645874\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1556, 12.5707, 14.1228],\n",
      "        [17.9924, 12.3030, 13.6539],\n",
      "        [18.0679, 12.0335, 13.4377],\n",
      "        [18.2506, 12.4884, 14.0081],\n",
      "        [18.5034, 12.1036, 13.4867],\n",
      "        [17.7226, 12.2983, 13.4968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7115, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2709,  17.5838, -12.0530],\n",
      "        [-15.8790,  17.4125, -11.9001],\n",
      "        [-16.0359,  17.4091, -11.8847],\n",
      "        [-16.3451,  17.2030, -11.7405],\n",
      "        [-15.8486,  17.4273, -12.0534],\n",
      "        [-15.4696,  17.3704, -11.6574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1556,  12.5707,  14.1228, -16.2709,  17.5838, -12.0530],\n",
      "        [ 17.9924,  12.3030,  13.6539, -15.8790,  17.4125, -11.9001],\n",
      "        [ 18.0679,  12.0335,  13.4377, -16.0359,  17.4091, -11.8847],\n",
      "        [ 18.2506,  12.4884,  14.0081, -16.3451,  17.2030, -11.7405],\n",
      "        [ 18.5034,  12.1036,  13.4867, -15.8486,  17.4273, -12.0534],\n",
      "        [ 17.7226,  12.2983,  13.4968, -15.4696,  17.3704, -11.6574]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.445556402206421\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7542, 12.5078, 13.7154],\n",
      "        [18.0833, 12.4316, 13.8771],\n",
      "        [17.9426, 12.2393, 13.8738],\n",
      "        [17.7663, 11.8836, 13.3064],\n",
      "        [18.2432, 12.2749, 13.5441],\n",
      "        [17.5945, 11.5945, 13.6243]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8293,  17.1145, -12.0590],\n",
      "        [-15.9263,  17.6184, -11.6791],\n",
      "        [-15.6743,  17.2612, -12.0341],\n",
      "        [-16.3045,  17.7618, -11.9482],\n",
      "        [-16.0289,  17.4834, -12.1617],\n",
      "        [-15.6939,  16.9517, -11.9320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7542,  12.5078,  13.7154, -15.8293,  17.1145, -12.0590],\n",
      "        [ 18.0833,  12.4316,  13.8771, -15.9263,  17.6184, -11.6791],\n",
      "        [ 17.9426,  12.2393,  13.8738, -15.6743,  17.2612, -12.0341],\n",
      "        [ 17.7663,  11.8836,  13.3064, -16.3045,  17.7618, -11.9482],\n",
      "        [ 18.2432,  12.2749,  13.5441, -16.0289,  17.4834, -12.1617],\n",
      "        [ 17.5945,  11.5945,  13.6243, -15.6939,  16.9517, -11.9320]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.394522190093994\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7581, 11.9080, 13.2724],\n",
      "        [17.7806, 12.2895, 13.9994],\n",
      "        [17.9098, 12.2771, 13.5387],\n",
      "        [18.0105, 12.1210, 13.5375],\n",
      "        [17.6662, 12.2242, 13.8598],\n",
      "        [18.3199, 12.3288, 13.7384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1080, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1029,  17.4475, -12.0710],\n",
      "        [-16.3792,  17.4569, -11.8454],\n",
      "        [-15.8187,  16.6591, -11.6768],\n",
      "        [-15.8803,  17.3041, -11.8316],\n",
      "        [-15.6788,  16.9978, -11.8481],\n",
      "        [-16.0010,  17.4344, -11.8108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7581,  11.9080,  13.2724, -16.1029,  17.4475, -12.0710],\n",
      "        [ 17.7806,  12.2895,  13.9994, -16.3792,  17.4569, -11.8454],\n",
      "        [ 17.9098,  12.2771,  13.5387, -15.8187,  16.6591, -11.6768],\n",
      "        [ 18.0105,  12.1210,  13.5375, -15.8803,  17.3041, -11.8316],\n",
      "        [ 17.6662,  12.2242,  13.8598, -15.6788,  16.9978, -11.8481],\n",
      "        [ 18.3199,  12.3288,  13.7384, -16.0010,  17.4344, -11.8108]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3825531005859375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2899, 12.3206, 13.8360],\n",
      "        [17.9280, 12.4635, 13.9036],\n",
      "        [18.3851, 12.7756, 13.8971],\n",
      "        [17.9814, 12.1886, 13.7493],\n",
      "        [18.0367, 12.6184, 13.5501],\n",
      "        [18.2407, 12.2298, 13.7427]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8826, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.5399,  17.1503, -11.7254],\n",
      "        [-16.1729,  17.3116, -12.0293],\n",
      "        [-16.0245,  17.3157, -12.3354],\n",
      "        [-15.9296,  17.2899, -11.9599],\n",
      "        [-15.5993,  16.8491, -11.5710],\n",
      "        [-15.6126,  17.1179, -11.6853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2899,  12.3206,  13.8360, -15.5399,  17.1503, -11.7254],\n",
      "        [ 17.9280,  12.4635,  13.9036, -16.1729,  17.3116, -12.0293],\n",
      "        [ 18.3851,  12.7756,  13.8971, -16.0245,  17.3157, -12.3354],\n",
      "        [ 17.9814,  12.1886,  13.7493, -15.9296,  17.2899, -11.9599],\n",
      "        [ 18.0367,  12.6184,  13.5501, -15.5993,  16.8491, -11.5710],\n",
      "        [ 18.2407,  12.2298,  13.7427, -15.6126,  17.1179, -11.6853]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.408864974975586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6212, 12.0895, 13.8196],\n",
      "        [17.9077, 12.1871, 13.7306],\n",
      "        [17.9620, 12.6778, 13.8848],\n",
      "        [17.8365, 12.0896, 13.6746],\n",
      "        [17.7283, 12.3484, 13.5268],\n",
      "        [17.9057, 12.2338, 13.4843]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9478,  17.5767, -11.9610],\n",
      "        [-16.0043,  17.5250, -12.1384],\n",
      "        [-15.9991,  17.2810, -12.3493],\n",
      "        [-16.0944,  17.6573, -12.0754],\n",
      "        [-15.6660,  17.1724, -12.1995],\n",
      "        [-16.2354,  17.0588, -11.6732]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6212,  12.0895,  13.8196, -15.9478,  17.5767, -11.9610],\n",
      "        [ 17.9077,  12.1871,  13.7306, -16.0043,  17.5250, -12.1384],\n",
      "        [ 17.9620,  12.6778,  13.8848, -15.9991,  17.2810, -12.3493],\n",
      "        [ 17.8365,  12.0896,  13.6746, -16.0944,  17.6573, -12.0754],\n",
      "        [ 17.7283,  12.3484,  13.5268, -15.6660,  17.1724, -12.1995],\n",
      "        [ 17.9057,  12.2338,  13.4843, -16.2354,  17.0588, -11.6732]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4410107135772705\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.9385, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3288, 12.5830, 14.1250],\n",
      "        [17.3545, 12.0319, 13.4273],\n",
      "        [18.1948, 12.6300, 13.8897],\n",
      "        [18.2763, 12.2013, 13.5581],\n",
      "        [17.7751, 11.9996, 13.5709],\n",
      "        [18.1283, 12.6182, 13.9259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.8350, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.5789,  17.0464, -12.0903],\n",
      "        [-16.2509,  17.4772, -11.9800],\n",
      "        [-16.1307,  17.0377, -11.7026],\n",
      "        [-15.9166,  17.1350, -11.9481],\n",
      "        [-15.8830,  17.0164, -11.7313],\n",
      "        [-16.0244,  17.4262, -12.2630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3288,  12.5830,  14.1250, -15.5789,  17.0464, -12.0903],\n",
      "        [ 17.3545,  12.0319,  13.4273, -16.2509,  17.4772, -11.9800],\n",
      "        [ 18.1948,  12.6300,  13.8897, -16.1307,  17.0377, -11.7026],\n",
      "        [ 18.2763,  12.2013,  13.5581, -15.9166,  17.1350, -11.9481],\n",
      "        [ 17.7751,  11.9996,  13.5709, -15.8830,  17.0164, -11.7313],\n",
      "        [ 18.1283,  12.6182,  13.9259, -16.0244,  17.4262, -12.2630]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.4317593574523926\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.6329, 12.3586, 13.7329],\n",
      "        [18.0622, 11.9211, 13.4203],\n",
      "        [18.1260, 12.2208, 14.1366],\n",
      "        [18.1299, 12.5345, 13.7131],\n",
      "        [17.9283, 12.2415, 13.9850],\n",
      "        [17.6707, 12.3944, 13.6089]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7837, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0692,  17.1536, -12.1051],\n",
      "        [-15.9795,  17.1524, -11.5943],\n",
      "        [-16.2137,  18.0364, -12.2765],\n",
      "        [-16.0751,  17.0324, -11.7216],\n",
      "        [-15.6642,  17.2616, -12.1205],\n",
      "        [-16.2421,  17.7589, -12.0429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.6329,  12.3586,  13.7329, -16.0692,  17.1536, -12.1051],\n",
      "        [ 18.0622,  11.9211,  13.4203, -15.9795,  17.1524, -11.5943],\n",
      "        [ 18.1260,  12.2208,  14.1366, -16.2137,  18.0364, -12.2765],\n",
      "        [ 18.1299,  12.5345,  13.7131, -16.0751,  17.0324, -11.7216],\n",
      "        [ 17.9283,  12.2415,  13.9850, -15.6642,  17.2616, -12.1205],\n",
      "        [ 17.6707,  12.3944,  13.6089, -16.2421,  17.7589, -12.0429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.399541139602661\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8610, 12.4635, 13.5597],\n",
      "        [18.1878, 12.1897, 13.5462],\n",
      "        [18.3506, 12.2296, 13.9851],\n",
      "        [17.7661, 12.0392, 13.5992],\n",
      "        [18.4676, 12.5060, 13.6885],\n",
      "        [18.4926, 12.8029, 13.7780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.0854, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7680,  17.3867, -11.9166],\n",
      "        [-16.1927,  17.7450, -12.0480],\n",
      "        [-16.0899,  17.6953, -12.1082],\n",
      "        [-15.5014,  17.0731, -11.9880],\n",
      "        [-16.1319,  17.5695, -11.9765],\n",
      "        [-15.3045,  17.0290, -11.6106]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8610,  12.4635,  13.5597, -15.7680,  17.3867, -11.9166],\n",
      "        [ 18.1878,  12.1897,  13.5462, -16.1927,  17.7450, -12.0480],\n",
      "        [ 18.3506,  12.2296,  13.9851, -16.0899,  17.6953, -12.1082],\n",
      "        [ 17.7661,  12.0392,  13.5992, -15.5014,  17.0731, -11.9880],\n",
      "        [ 18.4676,  12.5060,  13.6885, -16.1319,  17.5695, -11.9765],\n",
      "        [ 18.4926,  12.8029,  13.7780, -15.3045,  17.0290, -11.6106]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4031577110290527\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6768, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8897, 12.3504, 13.8041],\n",
      "        [17.6844, 12.0155, 13.7382],\n",
      "        [18.0167, 12.1987, 13.6915],\n",
      "        [18.0863, 12.3682, 13.8366],\n",
      "        [17.6719, 12.0609, 13.4304],\n",
      "        [17.4989, 11.8224, 13.4195]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6362, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9482,  17.2532, -11.4627],\n",
      "        [-15.7764,  17.1322, -11.5310],\n",
      "        [-16.0244,  17.4667, -11.5756],\n",
      "        [-15.8093,  17.5252, -11.8584],\n",
      "        [-15.7772,  17.1047, -11.7750],\n",
      "        [-16.1495,  17.2569, -11.7273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8897,  12.3504,  13.8041, -15.9482,  17.2532, -11.4627],\n",
      "        [ 17.6844,  12.0155,  13.7382, -15.7764,  17.1322, -11.5310],\n",
      "        [ 18.0167,  12.1987,  13.6915, -16.0244,  17.4667, -11.5756],\n",
      "        [ 18.0863,  12.3682,  13.8366, -15.8093,  17.5252, -11.8584],\n",
      "        [ 17.6719,  12.0609,  13.4304, -15.7772,  17.1047, -11.7750],\n",
      "        [ 17.4989,  11.8224,  13.4195, -16.1495,  17.2569, -11.7273]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.405039072036743\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0181, 12.4143, 13.5179],\n",
      "        [18.1910, 12.3030, 13.4932],\n",
      "        [17.8755, 12.2948, 13.4852],\n",
      "        [18.2991, 12.4592, 13.6292],\n",
      "        [18.0030, 12.6363, 13.5816],\n",
      "        [18.1774, 12.5132, 13.7636]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.4249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8090,  16.9513, -11.5377],\n",
      "        [-15.6214,  17.6125, -11.8601],\n",
      "        [-15.7395,  17.3426, -11.6717],\n",
      "        [-16.0650,  17.5274, -12.1162],\n",
      "        [-16.1996,  17.1672, -11.6297],\n",
      "        [-15.4460,  17.3164, -12.1565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0181,  12.4143,  13.5179, -15.8090,  16.9513, -11.5377],\n",
      "        [ 18.1910,  12.3030,  13.4932, -15.6214,  17.6125, -11.8601],\n",
      "        [ 17.8755,  12.2948,  13.4852, -15.7395,  17.3426, -11.6717],\n",
      "        [ 18.2991,  12.4592,  13.6292, -16.0650,  17.5274, -12.1162],\n",
      "        [ 18.0030,  12.6363,  13.5816, -16.1996,  17.1672, -11.6297],\n",
      "        [ 18.1774,  12.5132,  13.7636, -15.4460,  17.3164, -12.1565]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.3944153785705566\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9095, 12.7349, 13.5599],\n",
      "        [17.7712, 12.4345, 13.5124],\n",
      "        [18.1464, 11.9578, 13.6916],\n",
      "        [18.0992, 11.9235, 13.3837],\n",
      "        [18.0323, 12.1412, 13.7313],\n",
      "        [17.8654, 12.3874, 13.7474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4278, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2933,  17.3319, -11.7290],\n",
      "        [-15.6974,  16.8416, -11.2055],\n",
      "        [-15.8717,  17.6255, -12.1904],\n",
      "        [-16.2712,  17.6371, -12.3455],\n",
      "        [-16.2679,  17.3950, -12.0864],\n",
      "        [-16.0885,  17.2457, -11.7864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9095,  12.7349,  13.5599, -16.2933,  17.3319, -11.7290],\n",
      "        [ 17.7712,  12.4345,  13.5124, -15.6974,  16.8416, -11.2055],\n",
      "        [ 18.1464,  11.9578,  13.6916, -15.8717,  17.6255, -12.1904],\n",
      "        [ 18.0992,  11.9235,  13.3837, -16.2712,  17.6371, -12.3455],\n",
      "        [ 18.0323,  12.1412,  13.7313, -16.2679,  17.3950, -12.0864],\n",
      "        [ 17.8654,  12.3874,  13.7474, -16.0885,  17.2457, -11.7864]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4219720363616943\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9998, 12.2050, 13.5638],\n",
      "        [18.2706, 12.4029, 13.2831],\n",
      "        [18.2599, 12.5608, 13.7824],\n",
      "        [18.4028, 12.7853, 14.0416],\n",
      "        [18.1686, 12.3448, 13.7373],\n",
      "        [17.9534, 11.8059, 13.5256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.6285,  17.5080, -11.9467],\n",
      "        [-15.9848,  17.3935, -12.0113],\n",
      "        [-15.8738,  16.9793, -11.9711],\n",
      "        [-15.8040,  17.2418, -12.0711],\n",
      "        [-15.6416,  17.0064, -11.6971],\n",
      "        [-16.1141,  17.7363, -12.3585]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9998,  12.2050,  13.5638, -15.6285,  17.5080, -11.9467],\n",
      "        [ 18.2706,  12.4029,  13.2831, -15.9848,  17.3935, -12.0113],\n",
      "        [ 18.2599,  12.5608,  13.7824, -15.8738,  16.9793, -11.9711],\n",
      "        [ 18.4028,  12.7853,  14.0416, -15.8040,  17.2418, -12.0711],\n",
      "        [ 18.1686,  12.3448,  13.7373, -15.6416,  17.0064, -11.6971],\n",
      "        [ 17.9534,  11.8059,  13.5256, -16.1141,  17.7363, -12.3585]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.4085662364959717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5691, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0600, 12.4517, 13.7107],\n",
      "        [17.8489, 11.9056, 13.8985],\n",
      "        [17.9904, 12.2682, 13.8489],\n",
      "        [18.1806, 12.8273, 14.0656],\n",
      "        [18.0650, 12.5246, 13.9688],\n",
      "        [18.3339, 12.5873, 13.6718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2748,  17.6173, -11.9454],\n",
      "        [-16.1844,  17.5529, -11.9715],\n",
      "        [-16.1408,  17.5735, -12.0408],\n",
      "        [-16.1274,  17.2728, -11.9203],\n",
      "        [-15.9229,  17.3148, -12.2400],\n",
      "        [-15.6613,  17.1609, -11.3242]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0600,  12.4517,  13.7107, -16.2748,  17.6173, -11.9454],\n",
      "        [ 17.8489,  11.9056,  13.8985, -16.1844,  17.5529, -11.9715],\n",
      "        [ 17.9904,  12.2682,  13.8489, -16.1408,  17.5735, -12.0408],\n",
      "        [ 18.1806,  12.8273,  14.0656, -16.1274,  17.2728, -11.9203],\n",
      "        [ 18.0650,  12.5246,  13.9688, -15.9229,  17.3148, -12.2400],\n",
      "        [ 18.3339,  12.5873,  13.6718, -15.6613,  17.1609, -11.3242]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.439190149307251\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5078, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2746, 12.1409, 13.2650],\n",
      "        [18.1764, 12.2784, 13.6144],\n",
      "        [17.9799, 12.0011, 13.5188],\n",
      "        [18.1561, 12.0896, 14.1366],\n",
      "        [17.7916, 12.5494, 13.6120],\n",
      "        [17.9215, 12.0766, 13.4934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.5563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0521,  17.6128, -12.0794],\n",
      "        [-15.8228,  17.3087, -11.6755],\n",
      "        [-15.7677,  17.4971, -11.8876],\n",
      "        [-15.7715,  17.4140, -11.6990],\n",
      "        [-16.0254,  17.5831, -11.9106],\n",
      "        [-16.0027,  17.0453, -12.0093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2746,  12.1409,  13.2650, -16.0521,  17.6128, -12.0794],\n",
      "        [ 18.1764,  12.2784,  13.6144, -15.8228,  17.3087, -11.6755],\n",
      "        [ 17.9799,  12.0011,  13.5188, -15.7677,  17.4971, -11.8876],\n",
      "        [ 18.1561,  12.0896,  14.1366, -15.7715,  17.4140, -11.6990],\n",
      "        [ 17.7916,  12.5494,  13.6120, -16.0254,  17.5831, -11.9106],\n",
      "        [ 17.9215,  12.0766,  13.4934, -16.0027,  17.0453, -12.0093]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.425046682357788\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6939, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9527, 12.5665, 13.7479],\n",
      "        [18.4656, 12.4390, 13.6555],\n",
      "        [17.8532, 12.1528, 13.4999],\n",
      "        [17.9616, 12.1115, 13.9307],\n",
      "        [18.4206, 12.5638, 13.9159],\n",
      "        [17.7601, 12.2736, 13.8005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.2127, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8286,  17.1616, -11.5320],\n",
      "        [-16.1648,  17.6604, -12.2111],\n",
      "        [-16.0623,  17.6418, -12.1376],\n",
      "        [-16.0482,  17.5740, -11.8568],\n",
      "        [-15.9220,  17.8638, -12.1417],\n",
      "        [-15.9785,  17.5117, -11.7435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9527,  12.5665,  13.7479, -15.8286,  17.1616, -11.5320],\n",
      "        [ 18.4656,  12.4390,  13.6555, -16.1648,  17.6604, -12.2111],\n",
      "        [ 17.8532,  12.1528,  13.4999, -16.0623,  17.6418, -12.1376],\n",
      "        [ 17.9616,  12.1115,  13.9307, -16.0482,  17.5740, -11.8568],\n",
      "        [ 18.4206,  12.5638,  13.9159, -15.9220,  17.8638, -12.1417],\n",
      "        [ 17.7601,  12.2736,  13.8005, -15.9785,  17.5117, -11.7435]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.413823127746582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6445, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0159, 12.5712, 13.7052],\n",
      "        [17.7870, 12.2302, 14.0871],\n",
      "        [18.2221, 12.2921, 14.0025],\n",
      "        [17.8104, 12.4531, 13.6995],\n",
      "        [18.0552, 12.0399, 13.5887],\n",
      "        [18.6782, 12.4093, 14.3140]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7368, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7895,  17.3146, -12.1033],\n",
      "        [-16.5487,  17.9763, -12.3675],\n",
      "        [-15.9856,  17.0605, -11.9039],\n",
      "        [-15.8734,  17.2691, -11.9542],\n",
      "        [-16.0199,  17.1697, -11.7182],\n",
      "        [-16.0640,  17.6513, -12.5541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0159,  12.5712,  13.7052, -15.7895,  17.3146, -12.1033],\n",
      "        [ 17.7870,  12.2302,  14.0871, -16.5487,  17.9763, -12.3675],\n",
      "        [ 18.2221,  12.2921,  14.0025, -15.9856,  17.0605, -11.9039],\n",
      "        [ 17.8104,  12.4531,  13.6995, -15.8734,  17.2691, -11.9542],\n",
      "        [ 18.0552,  12.0399,  13.5887, -16.0199,  17.1697, -11.7182],\n",
      "        [ 18.6782,  12.4093,  14.3140, -16.0640,  17.6513, -12.5541]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.427777051925659\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6718, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6593, 12.6919, 14.3523],\n",
      "        [18.4643, 12.5503, 13.8225],\n",
      "        [17.8617, 12.1806, 13.9295],\n",
      "        [18.1380, 12.5578, 13.6837],\n",
      "        [18.2597, 12.2192, 14.1199],\n",
      "        [17.9944, 12.5254, 13.7474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1463,  17.2682, -12.1486],\n",
      "        [-16.2561,  17.4678, -11.8137],\n",
      "        [-15.5593,  16.8980, -11.7978],\n",
      "        [-15.7984,  17.4205, -12.0097],\n",
      "        [-15.9469,  17.2903, -11.5833],\n",
      "        [-15.8423,  17.6517, -12.2175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6593,  12.6919,  14.3523, -16.1463,  17.2682, -12.1486],\n",
      "        [ 18.4643,  12.5503,  13.8225, -16.2561,  17.4678, -11.8137],\n",
      "        [ 17.8617,  12.1806,  13.9295, -15.5593,  16.8980, -11.7978],\n",
      "        [ 18.1380,  12.5578,  13.6837, -15.7984,  17.4205, -12.0097],\n",
      "        [ 18.2597,  12.2192,  14.1199, -15.9469,  17.2903, -11.5833],\n",
      "        [ 17.9944,  12.5254,  13.7474, -15.8423,  17.6517, -12.2175]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4872841835021973\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6395, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9724, 12.4875, 13.5213],\n",
      "        [18.2126, 12.0806, 13.6182],\n",
      "        [18.3662, 12.2223, 13.9883],\n",
      "        [18.2339, 12.6539, 13.7865],\n",
      "        [18.1399, 12.0848, 13.8241],\n",
      "        [17.9756, 12.3468, 13.8673]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.8435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0633,  17.5270, -12.3027],\n",
      "        [-15.5858,  17.2114, -12.1148],\n",
      "        [-15.8657,  17.4983, -11.6678],\n",
      "        [-16.2371,  17.7798, -11.9730],\n",
      "        [-16.2698,  17.8368, -12.3233],\n",
      "        [-16.0423,  17.9004, -12.0611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9724,  12.4875,  13.5213, -16.0633,  17.5270, -12.3027],\n",
      "        [ 18.2126,  12.0806,  13.6182, -15.5858,  17.2114, -12.1148],\n",
      "        [ 18.3662,  12.2223,  13.9883, -15.8657,  17.4983, -11.6678],\n",
      "        [ 18.2339,  12.6539,  13.7865, -16.2371,  17.7798, -11.9730],\n",
      "        [ 18.1399,  12.0848,  13.8241, -16.2698,  17.8368, -12.3233],\n",
      "        [ 17.9756,  12.3468,  13.8673, -16.0423,  17.9004, -12.0611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.434593677520752\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6376, 12.4061, 14.1849],\n",
      "        [17.9957, 12.2106, 13.7253],\n",
      "        [18.5633, 12.6855, 13.8623],\n",
      "        [18.0905, 12.6317, 13.6140],\n",
      "        [18.2820, 12.3611, 13.7594],\n",
      "        [18.2803, 12.6307, 13.8857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2863,  17.5279, -11.9839],\n",
      "        [-15.5779,  17.4827, -12.2184],\n",
      "        [-16.4318,  17.4649, -12.0128],\n",
      "        [-15.5857,  16.7855, -11.8639],\n",
      "        [-16.2746,  17.1728, -12.2007],\n",
      "        [-15.8473,  17.7619, -12.2054]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6376,  12.4061,  14.1849, -16.2863,  17.5279, -11.9839],\n",
      "        [ 17.9957,  12.2106,  13.7253, -15.5779,  17.4827, -12.2184],\n",
      "        [ 18.5633,  12.6855,  13.8623, -16.4318,  17.4649, -12.0128],\n",
      "        [ 18.0905,  12.6317,  13.6140, -15.5857,  16.7855, -11.8639],\n",
      "        [ 18.2820,  12.3611,  13.7594, -16.2746,  17.1728, -12.2007],\n",
      "        [ 18.2803,  12.6307,  13.8857, -15.8473,  17.7619, -12.2054]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4839377403259277\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8828, 12.0266, 13.8467],\n",
      "        [18.1848, 12.2608, 13.5934],\n",
      "        [18.2422, 12.3505, 13.7707],\n",
      "        [17.5596, 12.4628, 13.2565],\n",
      "        [18.1674, 12.1597, 13.8587],\n",
      "        [17.4941, 11.7957, 13.3360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5411, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9314,  17.0000, -11.6835],\n",
      "        [-16.1674,  17.6752, -12.5920],\n",
      "        [-15.7372,  17.3112, -12.1007],\n",
      "        [-16.2045,  17.6661, -12.1870],\n",
      "        [-15.7282,  17.4079, -12.1629],\n",
      "        [-16.3884,  17.2728, -12.2697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8828,  12.0266,  13.8467, -15.9314,  17.0000, -11.6835],\n",
      "        [ 18.1848,  12.2608,  13.5934, -16.1674,  17.6752, -12.5920],\n",
      "        [ 18.2422,  12.3505,  13.7707, -15.7372,  17.3112, -12.1007],\n",
      "        [ 17.5596,  12.4628,  13.2565, -16.2045,  17.6661, -12.1870],\n",
      "        [ 18.1674,  12.1597,  13.8587, -15.7282,  17.4079, -12.1629],\n",
      "        [ 17.4941,  11.7957,  13.3360, -16.3884,  17.2728, -12.2697]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.408838987350464\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5109, 12.5736, 13.9115],\n",
      "        [17.9473, 12.2890, 13.8179],\n",
      "        [17.9935, 12.0388, 13.4566],\n",
      "        [18.0735, 12.6416, 13.8842],\n",
      "        [18.0413, 12.5770, 13.8686],\n",
      "        [18.1137, 12.5887, 13.7010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2479,  17.4092, -12.0169],\n",
      "        [-16.1498,  17.6084, -12.2196],\n",
      "        [-16.0388,  17.2267, -12.1446],\n",
      "        [-16.1679,  17.4132, -12.3057],\n",
      "        [-16.1674,  17.5731, -12.0074],\n",
      "        [-16.0423,  17.7016, -12.4245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5109,  12.5736,  13.9115, -16.2479,  17.4092, -12.0169],\n",
      "        [ 17.9473,  12.2890,  13.8179, -16.1498,  17.6084, -12.2196],\n",
      "        [ 17.9935,  12.0388,  13.4566, -16.0388,  17.2267, -12.1446],\n",
      "        [ 18.0735,  12.6416,  13.8842, -16.1679,  17.4132, -12.3057],\n",
      "        [ 18.0413,  12.5770,  13.8686, -16.1674,  17.5731, -12.0074],\n",
      "        [ 18.1137,  12.5887,  13.7010, -16.0423,  17.7016, -12.4245]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4724535942077637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3693, 12.0880, 13.7422],\n",
      "        [17.9810, 12.1332, 13.7056],\n",
      "        [17.9572, 12.0853, 13.6512],\n",
      "        [17.8771, 12.4465, 13.9057],\n",
      "        [17.9011, 11.6205, 13.7889],\n",
      "        [18.1423, 12.6369, 13.9012]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2148, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9695,  17.3125, -12.1748],\n",
      "        [-16.3463,  17.8929, -12.1209],\n",
      "        [-15.8505,  17.2784, -12.4892],\n",
      "        [-15.8279,  17.7492, -11.9121],\n",
      "        [-16.0197,  17.5359, -12.2524],\n",
      "        [-15.8830,  17.3504, -11.5452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3693,  12.0880,  13.7422, -15.9695,  17.3125, -12.1748],\n",
      "        [ 17.9810,  12.1332,  13.7056, -16.3463,  17.8929, -12.1209],\n",
      "        [ 17.9572,  12.0853,  13.6512, -15.8505,  17.2784, -12.4892],\n",
      "        [ 17.8771,  12.4465,  13.9057, -15.8279,  17.7492, -11.9121],\n",
      "        [ 17.9011,  11.6205,  13.7889, -16.0197,  17.5359, -12.2524],\n",
      "        [ 18.1423,  12.6369,  13.9012, -15.8830,  17.3504, -11.5452]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4454212188720703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4819, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7038, 11.9579, 13.7597],\n",
      "        [17.9054, 12.1558, 13.5221],\n",
      "        [18.3657, 12.4985, 13.9223],\n",
      "        [18.2802, 12.3952, 13.9678],\n",
      "        [18.2723, 12.1646, 13.8631],\n",
      "        [18.2811, 12.3797, 13.9845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0046,  17.4136, -11.8782],\n",
      "        [-16.0648,  17.5777, -12.2883],\n",
      "        [-16.1813,  17.4422, -12.3536],\n",
      "        [-16.1729,  17.6101, -12.4248],\n",
      "        [-15.8984,  17.4783, -12.3657],\n",
      "        [-16.0987,  17.4771, -12.1412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7038,  11.9579,  13.7597, -16.0046,  17.4136, -11.8782],\n",
      "        [ 17.9054,  12.1558,  13.5221, -16.0648,  17.5777, -12.2883],\n",
      "        [ 18.3657,  12.4985,  13.9223, -16.1813,  17.4422, -12.3536],\n",
      "        [ 18.2802,  12.3952,  13.9678, -16.1729,  17.6101, -12.4248],\n",
      "        [ 18.2723,  12.1646,  13.8631, -15.8984,  17.4783, -12.3657],\n",
      "        [ 18.2811,  12.3797,  13.9845, -16.0987,  17.4771, -12.1412]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.415041923522949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0604, 12.1034, 13.5973],\n",
      "        [17.9654, 12.3023, 13.4525],\n",
      "        [18.4577, 12.3695, 14.0107],\n",
      "        [17.9127, 12.2518, 13.7773],\n",
      "        [18.0743, 12.5506, 14.3109],\n",
      "        [18.3541, 12.0096, 13.7971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.4430, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8813,  17.5063, -11.9682],\n",
      "        [-16.5568,  17.5154, -12.3821],\n",
      "        [-16.0698,  17.5969, -12.1123],\n",
      "        [-16.1394,  17.3587, -12.0628],\n",
      "        [-16.2155,  17.4117, -12.1190],\n",
      "        [-16.3094,  17.6769, -11.9269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0604,  12.1034,  13.5973, -15.8813,  17.5063, -11.9682],\n",
      "        [ 17.9654,  12.3023,  13.4525, -16.5568,  17.5154, -12.3821],\n",
      "        [ 18.4577,  12.3695,  14.0107, -16.0698,  17.5969, -12.1123],\n",
      "        [ 17.9127,  12.2518,  13.7773, -16.1394,  17.3587, -12.0628],\n",
      "        [ 18.0743,  12.5506,  14.3109, -16.2155,  17.4117, -12.1190],\n",
      "        [ 18.3541,  12.0096,  13.7971, -16.3094,  17.6769, -11.9269]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.429993152618408\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4125, 12.2222, 14.2573],\n",
      "        [18.3829, 12.4941, 13.8385],\n",
      "        [18.2611, 12.2574, 13.5462],\n",
      "        [17.8442, 12.3931, 13.6005],\n",
      "        [18.3291, 12.5840, 14.1712],\n",
      "        [18.2030, 12.2951, 13.8635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.3386, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.8665,  17.5171, -12.0605],\n",
      "        [-16.1022,  17.7604, -12.0592],\n",
      "        [-16.2540,  17.9483, -12.2807],\n",
      "        [-15.9823,  17.4856, -11.8716],\n",
      "        [-16.1156,  17.4997, -12.1105],\n",
      "        [-15.7727,  17.5064, -12.5196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4125,  12.2222,  14.2573, -15.8665,  17.5171, -12.0605],\n",
      "        [ 18.3829,  12.4941,  13.8385, -16.1022,  17.7604, -12.0592],\n",
      "        [ 18.2611,  12.2574,  13.5462, -16.2540,  17.9483, -12.2807],\n",
      "        [ 17.8442,  12.3931,  13.6005, -15.9823,  17.4856, -11.8716],\n",
      "        [ 18.3291,  12.5840,  14.1712, -16.1156,  17.4997, -12.1105],\n",
      "        [ 18.2030,  12.2951,  13.8635, -15.7727,  17.5064, -12.5196]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4717133045196533\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3074, 12.2546, 13.8791],\n",
      "        [17.7897, 11.9688, 13.9376],\n",
      "        [18.3843, 12.5776, 13.6380],\n",
      "        [18.2750, 12.4644, 13.7535],\n",
      "        [18.5274, 12.6025, 14.4050],\n",
      "        [18.4474, 12.6956, 14.1182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0622, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1843,  17.7865, -12.4752],\n",
      "        [-15.6172,  17.2092, -12.0958],\n",
      "        [-16.1155,  17.4840, -11.8751],\n",
      "        [-16.1890,  17.6308, -12.1040],\n",
      "        [-15.8177,  17.2654, -11.7207],\n",
      "        [-15.6724,  16.6317, -11.6541]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3074,  12.2546,  13.8791, -16.1843,  17.7865, -12.4752],\n",
      "        [ 17.7897,  11.9688,  13.9376, -15.6172,  17.2092, -12.0958],\n",
      "        [ 18.3843,  12.5776,  13.6380, -16.1155,  17.4840, -11.8751],\n",
      "        [ 18.2750,  12.4644,  13.7535, -16.1890,  17.6308, -12.1040],\n",
      "        [ 18.5274,  12.6025,  14.4050, -15.8177,  17.2654, -11.7207],\n",
      "        [ 18.4474,  12.6956,  14.1182, -15.6724,  16.6317, -11.6541]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4765498638153076\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9802, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5031, 12.6804, 14.2085],\n",
      "        [18.5136, 12.6389, 14.2809],\n",
      "        [18.2108, 12.3780, 14.1686],\n",
      "        [17.9569, 12.2627, 13.6748],\n",
      "        [17.8693, 12.0820, 13.0150],\n",
      "        [18.4384, 12.5869, 13.7828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(11.0433, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9774,  17.2290, -12.0028],\n",
      "        [-16.2370,  17.8689, -12.0997],\n",
      "        [-15.7783,  17.4834, -11.8345],\n",
      "        [-15.7509,  17.2471, -11.7253],\n",
      "        [-15.9950,  17.3959, -11.9557],\n",
      "        [-15.9108,  17.6749, -12.0410]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5031,  12.6804,  14.2085, -15.9774,  17.2290, -12.0028],\n",
      "        [ 18.5136,  12.6389,  14.2809, -16.2370,  17.8689, -12.0997],\n",
      "        [ 18.2108,  12.3780,  14.1686, -15.7783,  17.4834, -11.8345],\n",
      "        [ 17.9569,  12.2627,  13.6748, -15.7509,  17.2471, -11.7253],\n",
      "        [ 17.8693,  12.0820,  13.0150, -15.9950,  17.3959, -11.9557],\n",
      "        [ 18.4384,  12.5869,  13.7828, -15.9108,  17.6749, -12.0410]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4809324741363525\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8000, 12.5473, 14.0272],\n",
      "        [18.2806, 12.4376, 14.0739],\n",
      "        [18.2538, 12.4422, 13.7540],\n",
      "        [17.6637, 11.9768, 13.5248],\n",
      "        [17.8129, 12.4215, 13.2895],\n",
      "        [18.4920, 12.2199, 13.9189]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0543, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0255,  17.5694, -12.3795],\n",
      "        [-15.9687,  17.3654, -11.7739],\n",
      "        [-16.0340,  17.7731, -12.1782],\n",
      "        [-16.0165,  17.7613, -12.0520],\n",
      "        [-16.3200,  17.7541, -12.4396],\n",
      "        [-15.8605,  17.6845, -12.1351]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8000,  12.5473,  14.0272, -16.0255,  17.5694, -12.3795],\n",
      "        [ 18.2806,  12.4376,  14.0739, -15.9687,  17.3654, -11.7739],\n",
      "        [ 18.2538,  12.4422,  13.7540, -16.0340,  17.7731, -12.1782],\n",
      "        [ 17.6637,  11.9768,  13.5248, -16.0165,  17.7613, -12.0520],\n",
      "        [ 17.8129,  12.4215,  13.2895, -16.3200,  17.7541, -12.4396],\n",
      "        [ 18.4920,  12.2199,  13.9189, -15.8605,  17.6845, -12.1351]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5008292198181152\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7063, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3382, 12.4647, 13.7097],\n",
      "        [18.6777, 12.6943, 14.1074],\n",
      "        [18.7199, 12.6316, 14.1689],\n",
      "        [18.0968, 12.3782, 13.8436],\n",
      "        [18.0890, 12.6430, 13.7151],\n",
      "        [17.9849, 12.7134, 13.9417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7666,  17.2687, -12.0781],\n",
      "        [-15.8736,  17.1538, -11.7487],\n",
      "        [-15.9757,  17.7771, -12.1995],\n",
      "        [-16.3806,  17.6739, -12.4125],\n",
      "        [-15.8415,  17.7076, -12.0992],\n",
      "        [-16.1985,  17.3499, -11.7309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3382,  12.4647,  13.7097, -15.7666,  17.2687, -12.0781],\n",
      "        [ 18.6777,  12.6943,  14.1074, -15.8736,  17.1538, -11.7487],\n",
      "        [ 18.7199,  12.6316,  14.1689, -15.9757,  17.7771, -12.1995],\n",
      "        [ 18.0968,  12.3782,  13.8436, -16.3806,  17.6739, -12.4125],\n",
      "        [ 18.0890,  12.6430,  13.7151, -15.8415,  17.7076, -12.0992],\n",
      "        [ 17.9849,  12.7134,  13.9417, -16.1985,  17.3499, -11.7309]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.452633857727051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.7829, 12.2497, 13.7747],\n",
      "        [17.9889, 12.0467, 13.6978],\n",
      "        [18.2303, 12.4493, 14.1497],\n",
      "        [18.2196, 12.8593, 14.1383],\n",
      "        [17.6524, 12.3724, 14.0029],\n",
      "        [18.4970, 12.6931, 14.2766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.7022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5794,  17.6398, -12.1872],\n",
      "        [-16.6981,  17.7340, -12.4363],\n",
      "        [-16.4368,  17.5422, -12.0176],\n",
      "        [-16.2294,  17.5021, -12.1440],\n",
      "        [-16.3155,  17.9282, -12.3582],\n",
      "        [-16.1017,  17.6270, -12.1488]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.7829,  12.2497,  13.7747, -16.5794,  17.6398, -12.1872],\n",
      "        [ 17.9889,  12.0467,  13.6978, -16.6981,  17.7340, -12.4363],\n",
      "        [ 18.2303,  12.4493,  14.1497, -16.4368,  17.5422, -12.0176],\n",
      "        [ 18.2196,  12.8593,  14.1383, -16.2294,  17.5021, -12.1440],\n",
      "        [ 17.6524,  12.3724,  14.0029, -16.3155,  17.9282, -12.3582],\n",
      "        [ 18.4970,  12.6931,  14.2766, -16.1017,  17.6270, -12.1488]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.456425666809082\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0406, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3947, 12.6399, 14.0497],\n",
      "        [18.1404, 12.5430, 13.3739],\n",
      "        [18.1898, 12.7041, 13.5133],\n",
      "        [18.8064, 12.6520, 14.3302],\n",
      "        [18.1612, 12.9141, 13.8390],\n",
      "        [18.1543, 12.8465, 13.6330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4989, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.7060,  17.5136, -11.9501],\n",
      "        [-15.9846,  17.7297, -11.8134],\n",
      "        [-16.0093,  17.5450, -11.4717],\n",
      "        [-15.8910,  17.7080, -12.7223],\n",
      "        [-15.8446,  17.3377, -11.9722],\n",
      "        [-16.1088,  17.6153, -12.1406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3947,  12.6399,  14.0497, -15.7060,  17.5136, -11.9501],\n",
      "        [ 18.1404,  12.5430,  13.3739, -15.9846,  17.7297, -11.8134],\n",
      "        [ 18.1898,  12.7041,  13.5133, -16.0093,  17.5450, -11.4717],\n",
      "        [ 18.8064,  12.6520,  14.3302, -15.8910,  17.7080, -12.7223],\n",
      "        [ 18.1612,  12.9141,  13.8390, -15.8446,  17.3377, -11.9722],\n",
      "        [ 18.1543,  12.8465,  13.6330, -16.1088,  17.6153, -12.1406]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.475188732147217\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5093, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4420, 12.8344, 13.7467],\n",
      "        [18.2664, 12.3026, 13.9206],\n",
      "        [18.1142, 12.2581, 14.0354],\n",
      "        [18.9256, 12.5866, 13.8661],\n",
      "        [17.8929, 12.4968, 14.1344],\n",
      "        [18.6823, 12.7642, 14.1620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.4638, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1625,  17.3872, -12.5608],\n",
      "        [-16.0426,  17.3595, -12.3988],\n",
      "        [-16.1846,  17.9742, -12.2973],\n",
      "        [-15.7791,  17.4876, -12.3342],\n",
      "        [-16.2760,  17.6011, -12.1558],\n",
      "        [-16.2574,  17.4648, -11.4248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4420,  12.8344,  13.7467, -16.1625,  17.3872, -12.5608],\n",
      "        [ 18.2664,  12.3026,  13.9206, -16.0426,  17.3595, -12.3988],\n",
      "        [ 18.1142,  12.2581,  14.0354, -16.1846,  17.9742, -12.2973],\n",
      "        [ 18.9256,  12.5866,  13.8661, -15.7791,  17.4876, -12.3342],\n",
      "        [ 17.8929,  12.4968,  14.1344, -16.2760,  17.6011, -12.1558],\n",
      "        [ 18.6823,  12.7642,  14.1620, -16.2574,  17.4648, -11.4248]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4889440536499023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6638, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4711, 12.4447, 13.7639],\n",
      "        [18.3864, 12.7242, 14.1152],\n",
      "        [18.2982, 12.7650, 14.0778],\n",
      "        [17.9404, 12.2743, 13.7848],\n",
      "        [18.0234, 12.1844, 13.9619],\n",
      "        [18.4120, 12.3281, 13.9661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9508, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4960,  17.9653, -12.1083],\n",
      "        [-16.6336,  17.5737, -11.9763],\n",
      "        [-15.9117,  17.5001, -11.9126],\n",
      "        [-16.1625,  17.5713, -12.3991],\n",
      "        [-16.2094,  17.8875, -12.5283],\n",
      "        [-15.8716,  17.5951, -12.0471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4711,  12.4447,  13.7639, -16.4960,  17.9653, -12.1083],\n",
      "        [ 18.3864,  12.7242,  14.1152, -16.6336,  17.5737, -11.9763],\n",
      "        [ 18.2982,  12.7650,  14.0778, -15.9117,  17.5001, -11.9126],\n",
      "        [ 17.9404,  12.2743,  13.7848, -16.1625,  17.5713, -12.3991],\n",
      "        [ 18.0234,  12.1844,  13.9619, -16.2094,  17.8875, -12.5283],\n",
      "        [ 18.4120,  12.3281,  13.9661, -15.8716,  17.5951, -12.0471]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4979488849639893\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.7811, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4287, 12.4725, 14.3235],\n",
      "        [17.6708, 12.2013, 13.6792],\n",
      "        [17.5375, 12.0673, 13.4944],\n",
      "        [18.4608, 12.6514, 14.2566],\n",
      "        [18.1952, 12.3312, 13.6566],\n",
      "        [18.2685, 12.8327, 14.3244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9115,  17.7454, -12.2853],\n",
      "        [-15.8543,  17.5623, -11.9415],\n",
      "        [-16.0985,  17.7154, -12.1903],\n",
      "        [-16.2807,  17.3975, -12.0898],\n",
      "        [-16.2974,  17.5648, -12.2741],\n",
      "        [-16.0332,  17.3010, -11.9314]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4287,  12.4725,  14.3235, -15.9115,  17.7454, -12.2853],\n",
      "        [ 17.6708,  12.2013,  13.6792, -15.8543,  17.5623, -11.9415],\n",
      "        [ 17.5375,  12.0673,  13.4944, -16.0985,  17.7154, -12.1903],\n",
      "        [ 18.4608,  12.6514,  14.2566, -16.2807,  17.3975, -12.0898],\n",
      "        [ 18.1952,  12.3312,  13.6566, -16.2974,  17.5648, -12.2741],\n",
      "        [ 18.2685,  12.8327,  14.3244, -16.0332,  17.3010, -11.9314]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.500910520553589\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1100, 12.2691, 14.0459],\n",
      "        [18.0138, 12.5037, 13.2596],\n",
      "        [18.1121, 12.2658, 13.6086],\n",
      "        [18.5416, 12.6192, 14.2295],\n",
      "        [18.2999, 12.7719, 14.3717],\n",
      "        [17.9895, 12.1507, 13.9553]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7334, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5556,  17.3105, -12.3666],\n",
      "        [-16.3072,  17.3641, -12.2927],\n",
      "        [-15.7367,  17.7692, -12.0575],\n",
      "        [-16.0543,  17.7078, -12.2729],\n",
      "        [-16.0980,  17.3593, -12.5310],\n",
      "        [-16.4972,  17.6404, -12.3284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1100,  12.2691,  14.0459, -16.5556,  17.3105, -12.3666],\n",
      "        [ 18.0138,  12.5037,  13.2596, -16.3072,  17.3641, -12.2927],\n",
      "        [ 18.1121,  12.2658,  13.6086, -15.7367,  17.7692, -12.0575],\n",
      "        [ 18.5416,  12.6192,  14.2295, -16.0543,  17.7078, -12.2729],\n",
      "        [ 18.2999,  12.7719,  14.3717, -16.0980,  17.3593, -12.5310],\n",
      "        [ 17.9895,  12.1507,  13.9553, -16.4972,  17.6404, -12.3284]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4798176288604736\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9567, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3974, 12.7173, 13.7481],\n",
      "        [18.1387, 12.3643, 13.7985],\n",
      "        [18.5662, 12.5961, 13.6240],\n",
      "        [18.2465, 12.4304, 14.1982],\n",
      "        [17.7381, 11.9756, 13.5960],\n",
      "        [18.7045, 12.8040, 14.0943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9399, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3414,  17.8328, -12.2018],\n",
      "        [-16.4588,  17.5608, -12.1736],\n",
      "        [-15.9692,  17.6274, -12.3809],\n",
      "        [-16.3050,  17.7466, -12.4098],\n",
      "        [-16.2760,  18.1086, -12.3676],\n",
      "        [-16.0928,  17.4324, -11.6050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3974,  12.7173,  13.7481, -16.3414,  17.8328, -12.2018],\n",
      "        [ 18.1387,  12.3643,  13.7985, -16.4588,  17.5608, -12.1736],\n",
      "        [ 18.5662,  12.5961,  13.6240, -15.9692,  17.6274, -12.3809],\n",
      "        [ 18.2465,  12.4304,  14.1982, -16.3050,  17.7466, -12.4098],\n",
      "        [ 17.7381,  11.9756,  13.5960, -16.2760,  18.1086, -12.3676],\n",
      "        [ 18.7045,  12.8040,  14.0943, -16.0928,  17.4324, -11.6050]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.498732328414917\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7911, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3410, 12.1100, 13.6857],\n",
      "        [18.0568, 12.4719, 14.0443],\n",
      "        [18.0094, 12.7203, 13.5900],\n",
      "        [18.4652, 12.3228, 13.9663],\n",
      "        [18.2275, 12.1433, 13.6049],\n",
      "        [18.2899, 12.5311, 13.9338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2672,  17.6602, -12.1995],\n",
      "        [-15.9365,  17.6452, -12.1436],\n",
      "        [-16.0661,  17.2728, -11.7637],\n",
      "        [-16.5383,  17.5447, -12.3383],\n",
      "        [-16.0742,  17.7909, -12.1105],\n",
      "        [-16.0026,  17.5848, -12.0552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3410,  12.1100,  13.6857, -16.2672,  17.6602, -12.1995],\n",
      "        [ 18.0568,  12.4719,  14.0443, -15.9365,  17.6452, -12.1436],\n",
      "        [ 18.0094,  12.7203,  13.5900, -16.0661,  17.2728, -11.7637],\n",
      "        [ 18.4652,  12.3228,  13.9663, -16.5383,  17.5447, -12.3383],\n",
      "        [ 18.2275,  12.1433,  13.6049, -16.0742,  17.7909, -12.1105],\n",
      "        [ 18.2899,  12.5311,  13.9338, -16.0026,  17.5848, -12.0552]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4761745929718018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3881, 13.0395, 14.3576],\n",
      "        [18.3346, 12.4947, 13.7994],\n",
      "        [17.9426, 12.2455, 13.9605],\n",
      "        [18.0703, 12.3845, 13.8154],\n",
      "        [18.2213, 12.8067, 14.0806],\n",
      "        [18.3077, 12.7013, 14.0519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3334,  17.8312, -12.1869],\n",
      "        [-16.5529,  17.7249, -12.2943],\n",
      "        [-16.1035,  17.7874, -12.2036],\n",
      "        [-16.6052,  17.6673, -12.4210],\n",
      "        [-16.5088,  17.4428, -12.5510],\n",
      "        [-16.4030,  17.8346, -12.2353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3881,  13.0395,  14.3576, -16.3334,  17.8312, -12.1869],\n",
      "        [ 18.3346,  12.4947,  13.7994, -16.5529,  17.7249, -12.2943],\n",
      "        [ 17.9426,  12.2455,  13.9605, -16.1035,  17.7874, -12.2036],\n",
      "        [ 18.0703,  12.3845,  13.8154, -16.6052,  17.6673, -12.4210],\n",
      "        [ 18.2213,  12.8067,  14.0806, -16.5088,  17.4428, -12.5510],\n",
      "        [ 18.3077,  12.7013,  14.0519, -16.4030,  17.8346, -12.2353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5276403427124023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7639, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1418, 12.8365, 13.9913],\n",
      "        [18.2455, 12.4413, 13.9011],\n",
      "        [18.6404, 12.6542, 13.8494],\n",
      "        [18.1225, 12.5256, 14.0591],\n",
      "        [18.1694, 12.9394, 14.0455],\n",
      "        [18.0043, 12.3236, 14.0632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9234, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1962,  17.4805, -12.3615],\n",
      "        [-16.2094,  17.6033, -12.1100],\n",
      "        [-16.3701,  18.0092, -12.4640],\n",
      "        [-16.3895,  18.0031, -12.4368],\n",
      "        [-16.1202,  17.7942, -12.5598],\n",
      "        [-15.6198,  17.1642, -12.2566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1418,  12.8365,  13.9913, -16.1962,  17.4805, -12.3615],\n",
      "        [ 18.2455,  12.4413,  13.9011, -16.2094,  17.6033, -12.1100],\n",
      "        [ 18.6404,  12.6542,  13.8494, -16.3701,  18.0092, -12.4640],\n",
      "        [ 18.1225,  12.5256,  14.0591, -16.3895,  18.0031, -12.4368],\n",
      "        [ 18.1694,  12.9394,  14.0455, -16.1202,  17.7942, -12.5598],\n",
      "        [ 18.0043,  12.3236,  14.0632, -15.6198,  17.1642, -12.2566]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.492846965789795\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6842, 12.8490, 13.9181],\n",
      "        [18.4917, 12.3528, 14.1486],\n",
      "        [18.3102, 12.6776, 13.9092],\n",
      "        [17.8895, 12.5189, 13.3093],\n",
      "        [18.5505, 12.5655, 13.8259],\n",
      "        [18.6240, 12.4368, 13.9372]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2707,  17.6384, -12.6133],\n",
      "        [-16.3314,  17.4347, -12.0051],\n",
      "        [-16.3671,  18.0564, -12.5194],\n",
      "        [-16.0674,  17.6431, -12.3986],\n",
      "        [-16.0313,  17.5794, -11.9352],\n",
      "        [-15.8173,  17.7701, -12.3554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6842,  12.8490,  13.9181, -16.2707,  17.6384, -12.6133],\n",
      "        [ 18.4917,  12.3528,  14.1486, -16.3314,  17.4347, -12.0051],\n",
      "        [ 18.3102,  12.6776,  13.9092, -16.3671,  18.0564, -12.5194],\n",
      "        [ 17.8895,  12.5189,  13.3093, -16.0674,  17.6431, -12.3986],\n",
      "        [ 18.5505,  12.5655,  13.8259, -16.0313,  17.5794, -11.9352],\n",
      "        [ 18.6240,  12.4368,  13.9372, -15.8173,  17.7701, -12.3554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5242698192596436\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2643, 12.1718, 13.7121],\n",
      "        [18.3551, 12.6597, 13.6319],\n",
      "        [18.0690, 12.4629, 13.8664],\n",
      "        [18.1750, 12.7033, 14.0131],\n",
      "        [18.1987, 12.3872, 14.2283],\n",
      "        [18.6519, 12.6855, 14.5168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5904,  17.6936, -12.1633],\n",
      "        [-16.2998,  17.7886, -12.3824],\n",
      "        [-16.4816,  18.1437, -12.5099],\n",
      "        [-16.2860,  17.7486, -12.2668],\n",
      "        [-16.4087,  18.1210, -12.5341],\n",
      "        [-16.0807,  17.5047, -12.2974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2643,  12.1718,  13.7121, -16.5904,  17.6936, -12.1633],\n",
      "        [ 18.3551,  12.6597,  13.6319, -16.2998,  17.7886, -12.3824],\n",
      "        [ 18.0690,  12.4629,  13.8664, -16.4816,  18.1437, -12.5099],\n",
      "        [ 18.1750,  12.7033,  14.0131, -16.2860,  17.7486, -12.2668],\n",
      "        [ 18.1987,  12.3872,  14.2283, -16.4087,  18.1210, -12.5341],\n",
      "        [ 18.6519,  12.6855,  14.5168, -16.0807,  17.5047, -12.2974]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4874043464660645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8348, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3216, 12.8914, 14.0322],\n",
      "        [18.1793, 12.6461, 14.0866],\n",
      "        [18.2492, 12.2942, 14.2997],\n",
      "        [18.5431, 12.8082, 14.1415],\n",
      "        [18.4703, 12.7071, 13.5613],\n",
      "        [18.7600, 12.5906, 14.3172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9752,  17.4885, -12.3538],\n",
      "        [-16.3842,  18.2367, -12.4095],\n",
      "        [-15.9941,  17.5595, -12.1625],\n",
      "        [-16.0014,  17.6494, -12.3124],\n",
      "        [-16.3557,  17.6591, -12.4172],\n",
      "        [-16.2076,  17.6280, -12.2822]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3216,  12.8914,  14.0322, -15.9752,  17.4885, -12.3538],\n",
      "        [ 18.1793,  12.6461,  14.0866, -16.3842,  18.2367, -12.4095],\n",
      "        [ 18.2492,  12.2942,  14.2997, -15.9941,  17.5595, -12.1625],\n",
      "        [ 18.5431,  12.8082,  14.1415, -16.0014,  17.6494, -12.3124],\n",
      "        [ 18.4703,  12.7071,  13.5613, -16.3557,  17.6591, -12.4172],\n",
      "        [ 18.7600,  12.5906,  14.3172, -16.2076,  17.6280, -12.2822]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5018482208251953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6411, 12.9714, 14.6852],\n",
      "        [18.4314, 12.9115, 14.0565],\n",
      "        [18.3244, 12.6159, 13.9389],\n",
      "        [17.7507, 12.3632, 13.9757],\n",
      "        [18.4617, 12.5497, 14.0495],\n",
      "        [18.4650, 12.7850, 13.7133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6894, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1561,  17.6905, -12.1420],\n",
      "        [-16.5340,  17.7848, -12.0638],\n",
      "        [-16.4731,  17.6682, -12.3498],\n",
      "        [-15.9024,  17.4999, -12.2424],\n",
      "        [-16.0126,  17.4607, -12.2061],\n",
      "        [-16.1860,  17.6437, -12.1334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6411,  12.9714,  14.6852, -16.1561,  17.6905, -12.1420],\n",
      "        [ 18.4314,  12.9115,  14.0565, -16.5340,  17.7848, -12.0638],\n",
      "        [ 18.3244,  12.6159,  13.9389, -16.4731,  17.6682, -12.3498],\n",
      "        [ 17.7507,  12.3632,  13.9757, -15.9024,  17.4999, -12.2424],\n",
      "        [ 18.4617,  12.5497,  14.0495, -16.0126,  17.4607, -12.2061],\n",
      "        [ 18.4650,  12.7850,  13.7133, -16.1860,  17.6437, -12.1334]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.545780658721924\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2425, 12.1167, 14.0132],\n",
      "        [18.5411, 12.6030, 14.1181],\n",
      "        [18.4504, 12.3315, 13.8288],\n",
      "        [18.1965, 12.4479, 14.1450],\n",
      "        [18.0957, 12.6511, 14.0415],\n",
      "        [17.9065, 12.5941, 14.2326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2470,  17.5072, -12.0975],\n",
      "        [-16.2449,  17.6216, -12.2749],\n",
      "        [-16.3246,  17.6837, -12.1587],\n",
      "        [-16.2049,  17.3120, -12.6552],\n",
      "        [-16.1871,  17.3662, -12.4521],\n",
      "        [-16.0445,  17.5509, -12.1828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2425,  12.1167,  14.0132, -16.2470,  17.5072, -12.0975],\n",
      "        [ 18.5411,  12.6030,  14.1181, -16.2449,  17.6216, -12.2749],\n",
      "        [ 18.4504,  12.3315,  13.8288, -16.3246,  17.6837, -12.1587],\n",
      "        [ 18.1965,  12.4479,  14.1450, -16.2049,  17.3120, -12.6552],\n",
      "        [ 18.0957,  12.6511,  14.0415, -16.1871,  17.3662, -12.4521],\n",
      "        [ 17.9065,  12.5941,  14.2326, -16.0445,  17.5509, -12.1828]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.4856483936309814\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8770, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6405, 12.8020, 14.0626],\n",
      "        [18.5370, 12.7807, 14.0756],\n",
      "        [18.2907, 12.6910, 14.2119],\n",
      "        [18.4320, 12.6043, 14.1175],\n",
      "        [18.5525, 12.9829, 14.0028],\n",
      "        [18.4618, 12.8398, 13.9320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.4461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4062,  17.9899, -12.6193],\n",
      "        [-16.1665,  17.7799, -12.3098],\n",
      "        [-16.2592,  18.1606, -12.3307],\n",
      "        [-16.3839,  17.2600, -12.1195],\n",
      "        [-15.7450,  17.7066, -12.2508],\n",
      "        [-16.2487,  17.5498, -12.3358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6405,  12.8020,  14.0626, -16.4062,  17.9899, -12.6193],\n",
      "        [ 18.5370,  12.7807,  14.0756, -16.1665,  17.7799, -12.3098],\n",
      "        [ 18.2907,  12.6910,  14.2119, -16.2592,  18.1606, -12.3307],\n",
      "        [ 18.4320,  12.6043,  14.1175, -16.3839,  17.2600, -12.1195],\n",
      "        [ 18.5525,  12.9829,  14.0028, -15.7450,  17.7066, -12.2508],\n",
      "        [ 18.4618,  12.8398,  13.9320, -16.2487,  17.5498, -12.3358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.544041395187378\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4083, 13.1948, 14.1282],\n",
      "        [17.9903, 12.3940, 13.8484],\n",
      "        [18.3707, 12.4174, 14.4171],\n",
      "        [18.3299, 12.6796, 14.2605],\n",
      "        [18.3512, 13.0128, 14.0148],\n",
      "        [18.3829, 12.6821, 14.0031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.4291, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2300,  17.8115, -12.4080],\n",
      "        [-16.5635,  17.7865, -12.2240],\n",
      "        [-15.9535,  17.7097, -11.9663],\n",
      "        [-16.2558,  18.1094, -12.3837],\n",
      "        [-16.3928,  17.9803, -12.2982],\n",
      "        [-16.3757,  18.0608, -12.3159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4083,  13.1948,  14.1282, -16.2300,  17.8115, -12.4080],\n",
      "        [ 17.9903,  12.3940,  13.8484, -16.5635,  17.7865, -12.2240],\n",
      "        [ 18.3707,  12.4174,  14.4171, -15.9535,  17.7097, -11.9663],\n",
      "        [ 18.3299,  12.6796,  14.2605, -16.2558,  18.1094, -12.3837],\n",
      "        [ 18.3512,  13.0128,  14.0148, -16.3928,  17.9803, -12.2982],\n",
      "        [ 18.3829,  12.6821,  14.0031, -16.3757,  18.0608, -12.3159]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.534761905670166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9631, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1021, 12.7844, 14.3392],\n",
      "        [19.0136, 12.8987, 14.4481],\n",
      "        [18.3490, 12.5389, 14.2380],\n",
      "        [17.9954, 12.6246, 13.8365],\n",
      "        [18.6106, 12.6743, 14.3905],\n",
      "        [18.0631, 12.3365, 13.9301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.5913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2761,  17.5841, -12.8098],\n",
      "        [-15.9923,  17.4906, -11.9582],\n",
      "        [-16.2753,  17.5546, -12.4377],\n",
      "        [-16.2208,  17.2472, -11.8760],\n",
      "        [-16.3085,  18.0195, -12.7535],\n",
      "        [-16.3822,  17.4945, -12.1388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1021,  12.7844,  14.3392, -16.2761,  17.5841, -12.8098],\n",
      "        [ 19.0136,  12.8987,  14.4481, -15.9923,  17.4906, -11.9582],\n",
      "        [ 18.3490,  12.5389,  14.2380, -16.2753,  17.5546, -12.4377],\n",
      "        [ 17.9954,  12.6246,  13.8365, -16.2208,  17.2472, -11.8760],\n",
      "        [ 18.6106,  12.6743,  14.3905, -16.3085,  18.0195, -12.7535],\n",
      "        [ 18.0631,  12.3365,  13.9301, -16.3822,  17.4945, -12.1388]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.522526264190674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6514, 13.4472, 14.1363],\n",
      "        [18.3905, 12.7224, 13.7523],\n",
      "        [18.1131, 12.5657, 14.2691],\n",
      "        [18.5418, 12.6272, 14.3653],\n",
      "        [18.6035, 12.6020, 14.1390],\n",
      "        [18.6708, 13.0052, 14.3980]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3828, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1046,  17.0114, -12.1796],\n",
      "        [-16.3413,  17.6641, -12.3222],\n",
      "        [-16.0585,  17.5709, -12.2744],\n",
      "        [-16.5520,  18.0120, -12.6625],\n",
      "        [-16.5652,  17.8870, -12.6247],\n",
      "        [-16.1428,  17.7152, -12.4739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6514,  13.4472,  14.1363, -16.1046,  17.0114, -12.1796],\n",
      "        [ 18.3905,  12.7224,  13.7523, -16.3413,  17.6641, -12.3222],\n",
      "        [ 18.1131,  12.5657,  14.2691, -16.0585,  17.5709, -12.2744],\n",
      "        [ 18.5418,  12.6272,  14.3653, -16.5520,  18.0120, -12.6625],\n",
      "        [ 18.6035,  12.6020,  14.1390, -16.5652,  17.8870, -12.6247],\n",
      "        [ 18.6708,  13.0052,  14.3980, -16.1428,  17.7152, -12.4739]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5273919105529785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6256, 13.0466, 14.1438],\n",
      "        [18.3567, 12.3655, 13.9744],\n",
      "        [18.4652, 12.9377, 13.6413],\n",
      "        [18.3252, 13.2518, 14.2983],\n",
      "        [18.2761, 12.8434, 14.0182],\n",
      "        [18.2960, 12.7292, 13.9145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4530, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5285,  17.4785, -12.2982],\n",
      "        [-16.0874,  17.9546, -12.4524],\n",
      "        [-16.3984,  17.5603, -12.2776],\n",
      "        [-16.2157,  17.5663, -12.3030],\n",
      "        [-16.6371,  17.9706, -12.6418],\n",
      "        [-16.4309,  18.4974, -12.6014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6256,  13.0466,  14.1438, -16.5285,  17.4785, -12.2982],\n",
      "        [ 18.3567,  12.3655,  13.9744, -16.0874,  17.9546, -12.4524],\n",
      "        [ 18.4652,  12.9377,  13.6413, -16.3984,  17.5603, -12.2776],\n",
      "        [ 18.3252,  13.2518,  14.2983, -16.2157,  17.5663, -12.3030],\n",
      "        [ 18.2761,  12.8434,  14.0182, -16.6371,  17.9706, -12.6418],\n",
      "        [ 18.2960,  12.7292,  13.9145, -16.4309,  18.4974, -12.6014]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.541640520095825\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.8287, 12.3560, 13.9735],\n",
      "        [18.8394, 12.9398, 14.2537],\n",
      "        [18.3858, 12.6970, 14.0823],\n",
      "        [18.6769, 12.9583, 14.3332],\n",
      "        [18.0530, 12.2840, 14.0718],\n",
      "        [18.4866, 12.9848, 14.2003]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.2056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5912,  18.0292, -12.3166],\n",
      "        [-16.3197,  17.3818, -11.9190],\n",
      "        [-16.3922,  17.4027, -12.2510],\n",
      "        [-16.4687,  17.8349, -12.5221],\n",
      "        [-16.3126,  18.0683, -12.6949],\n",
      "        [-16.1779,  17.8483, -12.3358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.8287,  12.3560,  13.9735, -16.5912,  18.0292, -12.3166],\n",
      "        [ 18.8394,  12.9398,  14.2537, -16.3197,  17.3818, -11.9190],\n",
      "        [ 18.3858,  12.6970,  14.0823, -16.3922,  17.4027, -12.2510],\n",
      "        [ 18.6769,  12.9583,  14.3332, -16.4687,  17.8349, -12.5221],\n",
      "        [ 18.0530,  12.2840,  14.0718, -16.3126,  18.0683, -12.6949],\n",
      "        [ 18.4866,  12.9848,  14.2003, -16.1779,  17.8483, -12.3358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5032222270965576\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8416, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2342, 12.9558, 13.9398],\n",
      "        [18.8572, 12.9154, 14.4349],\n",
      "        [18.9067, 12.8567, 14.4586],\n",
      "        [17.9912, 12.9365, 13.7122],\n",
      "        [18.6640, 12.7137, 14.2272],\n",
      "        [18.3625, 12.7294, 14.3321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5545, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4028,  17.6599, -12.0743],\n",
      "        [-16.0760,  17.7020, -12.4730],\n",
      "        [-16.7628,  17.9065, -12.6126],\n",
      "        [-16.3446,  17.9530, -12.3451],\n",
      "        [-16.8193,  17.8173, -12.3556],\n",
      "        [-16.4052,  17.8669, -12.4074]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2342,  12.9558,  13.9398, -16.4028,  17.6599, -12.0743],\n",
      "        [ 18.8572,  12.9154,  14.4349, -16.0760,  17.7020, -12.4730],\n",
      "        [ 18.9067,  12.8567,  14.4586, -16.7628,  17.9065, -12.6126],\n",
      "        [ 17.9912,  12.9365,  13.7122, -16.3446,  17.9530, -12.3451],\n",
      "        [ 18.6640,  12.7137,  14.2272, -16.8193,  17.8173, -12.3556],\n",
      "        [ 18.3625,  12.7294,  14.3321, -16.4052,  17.8669, -12.4074]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5168402194976807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3393, 12.2160, 14.2025],\n",
      "        [18.5537, 12.6274, 14.2662],\n",
      "        [18.4865, 12.8622, 14.1453],\n",
      "        [18.3090, 12.6387, 14.1210],\n",
      "        [18.1406, 12.4346, 13.9460],\n",
      "        [18.3753, 12.7717, 14.4078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9588, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3256,  17.4685, -12.3156],\n",
      "        [-15.9387,  17.6441, -12.4877],\n",
      "        [-16.4846,  18.0170, -12.8213],\n",
      "        [-16.1454,  17.6435, -12.3843],\n",
      "        [-16.1822,  17.2891, -12.7198],\n",
      "        [-16.5091,  18.1892, -12.3168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3393,  12.2160,  14.2025, -16.3256,  17.4685, -12.3156],\n",
      "        [ 18.5537,  12.6274,  14.2662, -15.9387,  17.6441, -12.4877],\n",
      "        [ 18.4865,  12.8622,  14.1453, -16.4846,  18.0170, -12.8213],\n",
      "        [ 18.3090,  12.6387,  14.1210, -16.1454,  17.6435, -12.3843],\n",
      "        [ 18.1406,  12.4346,  13.9460, -16.1822,  17.2891, -12.7198],\n",
      "        [ 18.3753,  12.7717,  14.4078, -16.5091,  18.1892, -12.3168]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.512078285217285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1944, 12.6236, 13.9842],\n",
      "        [18.2899, 12.6379, 14.1981],\n",
      "        [18.4955, 12.7225, 13.8838],\n",
      "        [18.4936, 12.8770, 14.0805],\n",
      "        [18.2787, 12.7007, 14.1040],\n",
      "        [18.1396, 12.6029, 14.2293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.5472, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0464,  17.5643, -12.1071],\n",
      "        [-15.7392,  17.3044, -12.2577],\n",
      "        [-16.1887,  17.8940, -12.1925],\n",
      "        [-16.6842,  17.8621, -12.6847],\n",
      "        [-16.5697,  18.1144, -12.5639],\n",
      "        [-16.0935,  17.8083, -12.2607]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1944,  12.6236,  13.9842, -16.0464,  17.5643, -12.1071],\n",
      "        [ 18.2899,  12.6379,  14.1981, -15.7392,  17.3044, -12.2577],\n",
      "        [ 18.4955,  12.7225,  13.8838, -16.1887,  17.8940, -12.1925],\n",
      "        [ 18.4936,  12.8770,  14.0805, -16.6842,  17.8621, -12.6847],\n",
      "        [ 18.2787,  12.7007,  14.1040, -16.5697,  18.1144, -12.5639],\n",
      "        [ 18.1396,  12.6029,  14.2293, -16.0935,  17.8083, -12.2607]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5018277168273926\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1984, 12.2185, 13.7760],\n",
      "        [18.1291, 12.5473, 13.8935],\n",
      "        [18.4433, 12.5858, 13.5653],\n",
      "        [18.7212, 12.8605, 14.1557],\n",
      "        [18.7209, 12.9252, 14.0564],\n",
      "        [18.3700, 12.5656, 14.0369]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1823, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8835,  18.6201, -13.1011],\n",
      "        [-16.3982,  18.1235, -12.8553],\n",
      "        [-16.6229,  17.9441, -12.8046],\n",
      "        [-16.5071,  17.7646, -12.4608],\n",
      "        [-16.4621,  17.6682, -12.2165],\n",
      "        [-16.5550,  18.1577, -12.7085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1984,  12.2185,  13.7760, -16.8835,  18.6201, -13.1011],\n",
      "        [ 18.1291,  12.5473,  13.8935, -16.3982,  18.1235, -12.8553],\n",
      "        [ 18.4433,  12.5858,  13.5653, -16.6229,  17.9441, -12.8046],\n",
      "        [ 18.7212,  12.8605,  14.1557, -16.5071,  17.7646, -12.4608],\n",
      "        [ 18.7209,  12.9252,  14.0564, -16.4621,  17.6682, -12.2165],\n",
      "        [ 18.3700,  12.5656,  14.0369, -16.5550,  18.1577, -12.7085]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5474655628204346\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8603, 12.8343, 13.8719],\n",
      "        [18.2596, 13.0013, 14.1809],\n",
      "        [18.6863, 12.7957, 14.3221],\n",
      "        [18.4696, 12.5320, 13.9180],\n",
      "        [18.5604, 12.6957, 14.0047],\n",
      "        [18.1125, 12.8038, 14.1610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7298, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1251,  18.3404, -12.7548],\n",
      "        [-16.5392,  18.0643, -12.5413],\n",
      "        [-16.8179,  18.0286, -12.8334],\n",
      "        [-16.4087,  17.7477, -12.5269],\n",
      "        [-16.0069,  17.7811, -12.6602],\n",
      "        [-16.3191,  17.5119, -12.4133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8603,  12.8343,  13.8719, -17.1251,  18.3404, -12.7548],\n",
      "        [ 18.2596,  13.0013,  14.1809, -16.5392,  18.0643, -12.5413],\n",
      "        [ 18.6863,  12.7957,  14.3221, -16.8179,  18.0286, -12.8334],\n",
      "        [ 18.4696,  12.5320,  13.9180, -16.4087,  17.7477, -12.5269],\n",
      "        [ 18.5604,  12.6957,  14.0047, -16.0069,  17.7811, -12.6602],\n",
      "        [ 18.1125,  12.8038,  14.1610, -16.3191,  17.5119, -12.4133]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5869157314300537\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8957, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5111, 13.0119, 14.1719],\n",
      "        [18.4318, 12.7472, 14.3202],\n",
      "        [18.3300, 12.9109, 13.8411],\n",
      "        [18.3965, 12.8721, 14.0869],\n",
      "        [18.5013, 12.9162, 14.1036],\n",
      "        [18.2663, 12.5280, 14.1403]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.8620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3743,  17.6614, -12.2598],\n",
      "        [-16.0448,  17.2264, -12.1287],\n",
      "        [-16.4162,  17.6565, -12.6855],\n",
      "        [-16.6689,  18.0948, -13.0477],\n",
      "        [-16.4842,  18.0856, -12.5174],\n",
      "        [-16.5523,  18.2070, -12.5971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5111,  13.0119,  14.1719, -16.3743,  17.6614, -12.2598],\n",
      "        [ 18.4318,  12.7472,  14.3202, -16.0448,  17.2264, -12.1287],\n",
      "        [ 18.3300,  12.9109,  13.8411, -16.4162,  17.6565, -12.6855],\n",
      "        [ 18.3965,  12.8721,  14.0869, -16.6689,  18.0948, -13.0477],\n",
      "        [ 18.5013,  12.9162,  14.1036, -16.4842,  18.0856, -12.5174],\n",
      "        [ 18.2663,  12.5280,  14.1403, -16.5523,  18.2070, -12.5971]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.545974016189575\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.7351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2222, 12.8555, 14.3336],\n",
      "        [18.3220, 12.7743, 14.1212],\n",
      "        [18.5611, 12.9488, 14.0715],\n",
      "        [18.4777, 12.6697, 14.2460],\n",
      "        [18.5788, 12.8060, 13.9180],\n",
      "        [18.2170, 12.6555, 14.1123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7878, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4944,  17.8850, -12.4477],\n",
      "        [-16.4140,  17.8196, -12.5950],\n",
      "        [-16.6970,  17.9971, -12.8178],\n",
      "        [-17.0258,  18.2540, -12.5074],\n",
      "        [-16.1924,  17.9474, -12.3823],\n",
      "        [-16.4141,  17.7197, -12.2589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2222,  12.8555,  14.3336, -16.4944,  17.8850, -12.4477],\n",
      "        [ 18.3220,  12.7743,  14.1212, -16.4140,  17.8196, -12.5950],\n",
      "        [ 18.5611,  12.9488,  14.0715, -16.6970,  17.9971, -12.8178],\n",
      "        [ 18.4777,  12.6697,  14.2460, -17.0258,  18.2540, -12.5074],\n",
      "        [ 18.5788,  12.8060,  13.9180, -16.1924,  17.9474, -12.3823],\n",
      "        [ 18.2170,  12.6555,  14.1123, -16.4141,  17.7197, -12.2589]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.547962188720703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3059, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2957, 12.7649, 14.5473],\n",
      "        [18.2771, 12.6471, 14.1075],\n",
      "        [18.0969, 12.8288, 14.4162],\n",
      "        [18.5007, 12.9960, 14.6539],\n",
      "        [18.2473, 12.2453, 14.2370],\n",
      "        [18.2567, 13.0517, 14.2158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1862,  17.7477, -12.4288],\n",
      "        [-16.9888,  18.0431, -12.6438],\n",
      "        [-16.9488,  18.1229, -13.1690],\n",
      "        [-16.7205,  18.1739, -12.4530],\n",
      "        [-16.3306,  17.9847, -12.3231],\n",
      "        [-16.4246,  17.7872, -12.6977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2957,  12.7649,  14.5473, -16.1862,  17.7477, -12.4288],\n",
      "        [ 18.2771,  12.6471,  14.1075, -16.9888,  18.0431, -12.6438],\n",
      "        [ 18.0969,  12.8288,  14.4162, -16.9488,  18.1229, -13.1690],\n",
      "        [ 18.5007,  12.9960,  14.6539, -16.7205,  18.1739, -12.4530],\n",
      "        [ 18.2473,  12.2453,  14.2370, -16.3306,  17.9847, -12.3231],\n",
      "        [ 18.2567,  13.0517,  14.2158, -16.4246,  17.7872, -12.6977]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.546823501586914\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8921, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6059, 13.1465, 14.1964],\n",
      "        [18.4633, 12.5608, 13.9038],\n",
      "        [18.0672, 12.6486, 13.8224],\n",
      "        [18.3231, 12.6032, 13.9118],\n",
      "        [18.3673, 13.1122, 14.1201],\n",
      "        [18.6368, 12.5251, 14.2880]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7192,  18.1880, -12.7321],\n",
      "        [-16.3640,  18.1970, -12.5476],\n",
      "        [-16.7025,  18.3876, -12.9055],\n",
      "        [-16.5538,  18.0270, -12.4668],\n",
      "        [-16.4257,  18.1849, -12.5688],\n",
      "        [-16.2735,  17.9584, -12.8196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6059,  13.1465,  14.1964, -16.7192,  18.1880, -12.7321],\n",
      "        [ 18.4633,  12.5608,  13.9038, -16.3640,  18.1970, -12.5476],\n",
      "        [ 18.0672,  12.6486,  13.8224, -16.7025,  18.3876, -12.9055],\n",
      "        [ 18.3231,  12.6032,  13.9118, -16.5538,  18.0270, -12.4668],\n",
      "        [ 18.3673,  13.1122,  14.1201, -16.4257,  18.1849, -12.5688],\n",
      "        [ 18.6368,  12.5251,  14.2880, -16.2735,  17.9584, -12.8196]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5856754779815674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5202, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4441, 12.8880, 14.3919],\n",
      "        [18.4818, 12.7274, 14.4044],\n",
      "        [18.4718, 12.9274, 14.3632],\n",
      "        [18.4472, 12.5782, 14.5511],\n",
      "        [18.7239, 12.9228, 14.3033],\n",
      "        [18.2911, 12.6509, 13.7949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.1493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9826,  17.5877, -12.0771],\n",
      "        [-16.0689,  18.0113, -12.7668],\n",
      "        [-16.1556,  17.5387, -12.2730],\n",
      "        [-16.0504,  17.7427, -12.4425],\n",
      "        [-16.2759,  18.0276, -12.9155],\n",
      "        [-16.8222,  18.2001, -12.8893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4441,  12.8880,  14.3919, -15.9826,  17.5877, -12.0771],\n",
      "        [ 18.4818,  12.7274,  14.4044, -16.0689,  18.0113, -12.7668],\n",
      "        [ 18.4718,  12.9274,  14.3632, -16.1556,  17.5387, -12.2730],\n",
      "        [ 18.4472,  12.5782,  14.5511, -16.0504,  17.7427, -12.4425],\n",
      "        [ 18.7239,  12.9228,  14.3033, -16.2759,  18.0276, -12.9155],\n",
      "        [ 18.2911,  12.6509,  13.7949, -16.8222,  18.2001, -12.8893]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5391228199005127\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2663, 12.6199, 13.8903],\n",
      "        [18.1792, 13.1513, 13.8787],\n",
      "        [18.7082, 12.6230, 14.3393],\n",
      "        [18.6307, 12.8306, 14.5356],\n",
      "        [18.6698, 12.7335, 14.5717],\n",
      "        [18.3806, 12.9983, 13.9781]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.9384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6479,  17.9437, -12.4635],\n",
      "        [-16.5718,  17.8105, -12.4693],\n",
      "        [-16.3547,  17.9901, -12.6822],\n",
      "        [-16.4825,  17.5751, -12.6229],\n",
      "        [-16.1507,  17.6950, -12.3772],\n",
      "        [-16.5943,  17.8687, -12.7211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2663,  12.6199,  13.8903, -16.6479,  17.9437, -12.4635],\n",
      "        [ 18.1792,  13.1513,  13.8787, -16.5718,  17.8105, -12.4693],\n",
      "        [ 18.7082,  12.6230,  14.3393, -16.3547,  17.9901, -12.6822],\n",
      "        [ 18.6307,  12.8306,  14.5356, -16.4825,  17.5751, -12.6229],\n",
      "        [ 18.6698,  12.7335,  14.5717, -16.1507,  17.6950, -12.3772],\n",
      "        [ 18.3806,  12.9983,  13.9781, -16.5943,  17.8687, -12.7211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.539787530899048\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.2329, 12.7580, 14.0285],\n",
      "        [18.6893, 13.0324, 14.2042],\n",
      "        [18.4436, 12.9162, 13.9711],\n",
      "        [18.3356, 12.1600, 14.0424],\n",
      "        [18.3497, 12.4223, 14.2120],\n",
      "        [18.2012, 12.4378, 14.1094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1239, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1907,  17.7796, -12.4550],\n",
      "        [-16.1712,  18.0400, -12.7922],\n",
      "        [-16.4265,  17.8281, -12.4235],\n",
      "        [-16.2817,  17.9877, -12.6275],\n",
      "        [-16.6114,  18.2118, -13.0864],\n",
      "        [-16.1245,  17.7156, -12.3253]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.2329,  12.7580,  14.0285, -16.1907,  17.7796, -12.4550],\n",
      "        [ 18.6893,  13.0324,  14.2042, -16.1712,  18.0400, -12.7922],\n",
      "        [ 18.4436,  12.9162,  13.9711, -16.4265,  17.8281, -12.4235],\n",
      "        [ 18.3356,  12.1600,  14.0424, -16.2817,  17.9877, -12.6275],\n",
      "        [ 18.3497,  12.4223,  14.2120, -16.6114,  18.2118, -13.0864],\n",
      "        [ 18.2012,  12.4378,  14.1094, -16.1245,  17.7156, -12.3253]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.532837390899658\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7196, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3381, 12.5873, 14.1443],\n",
      "        [18.9072, 13.0187, 14.7316],\n",
      "        [18.5923, 12.8808, 14.2714],\n",
      "        [18.4371, 12.6874, 14.0358],\n",
      "        [18.2345, 12.5404, 14.0808],\n",
      "        [18.3517, 13.1138, 14.2184]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4629,  17.8876, -12.6810],\n",
      "        [-15.7999,  17.6975, -12.4475],\n",
      "        [-16.5941,  17.5288, -12.4727],\n",
      "        [-16.3952,  18.1290, -12.3754],\n",
      "        [-16.7536,  18.2311, -12.5495],\n",
      "        [-16.0151,  17.6060, -12.0582]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3381,  12.5873,  14.1443, -16.4629,  17.8876, -12.6810],\n",
      "        [ 18.9072,  13.0187,  14.7316, -15.7999,  17.6975, -12.4475],\n",
      "        [ 18.5923,  12.8808,  14.2714, -16.5941,  17.5288, -12.4727],\n",
      "        [ 18.4371,  12.6874,  14.0358, -16.3952,  18.1290, -12.3754],\n",
      "        [ 18.2345,  12.5404,  14.0808, -16.7536,  18.2311, -12.5495],\n",
      "        [ 18.3517,  13.1138,  14.2184, -16.0151,  17.6060, -12.0582]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5509254932403564\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7954, 12.6324, 14.1204],\n",
      "        [18.8305, 13.1357, 14.3039],\n",
      "        [18.2615, 12.6576, 13.7658],\n",
      "        [18.7508, 13.0242, 14.4094],\n",
      "        [18.3504, 13.0130, 14.2789],\n",
      "        [18.4147, 12.9703, 13.7855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5970, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1958,  17.6658, -12.5435],\n",
      "        [-16.7285,  17.9155, -12.3872],\n",
      "        [-16.7079,  17.7005, -12.4298],\n",
      "        [-16.5059,  17.9775, -12.2957],\n",
      "        [-16.6171,  18.3269, -12.5177],\n",
      "        [-16.5355,  17.6495, -12.3424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7954,  12.6324,  14.1204, -16.1958,  17.6658, -12.5435],\n",
      "        [ 18.8305,  13.1357,  14.3039, -16.7285,  17.9155, -12.3872],\n",
      "        [ 18.2615,  12.6576,  13.7658, -16.7079,  17.7005, -12.4298],\n",
      "        [ 18.7508,  13.0242,  14.4094, -16.5059,  17.9775, -12.2957],\n",
      "        [ 18.3504,  13.0130,  14.2789, -16.6171,  18.3269, -12.5177],\n",
      "        [ 18.4147,  12.9703,  13.7855, -16.5355,  17.6495, -12.3424]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5581881999969482\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7346, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9290, 12.9776, 14.1719],\n",
      "        [18.2319, 12.4069, 14.2976],\n",
      "        [18.9390, 12.6828, 13.9808],\n",
      "        [18.4419, 12.3604, 14.2217],\n",
      "        [18.4114, 12.5703, 14.0975],\n",
      "        [18.4433, 13.0867, 14.1653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4556,  17.7643, -12.8073],\n",
      "        [-16.9049,  17.9835, -12.7025],\n",
      "        [-16.4012,  17.5902, -12.4467],\n",
      "        [-16.5724,  17.9609, -12.7802],\n",
      "        [-16.7056,  17.7036, -12.3505],\n",
      "        [-16.5984,  18.0472, -12.6437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9290,  12.9776,  14.1719, -16.4556,  17.7643, -12.8073],\n",
      "        [ 18.2319,  12.4069,  14.2976, -16.9049,  17.9835, -12.7025],\n",
      "        [ 18.9390,  12.6828,  13.9808, -16.4012,  17.5902, -12.4467],\n",
      "        [ 18.4419,  12.3604,  14.2217, -16.5724,  17.9609, -12.7802],\n",
      "        [ 18.4114,  12.5703,  14.0975, -16.7056,  17.7036, -12.3505],\n",
      "        [ 18.4433,  13.0867,  14.1653, -16.5984,  18.0472, -12.6437]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.587038993835449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4807, 12.6658, 14.2970],\n",
      "        [18.6329, 12.6296, 14.2525],\n",
      "        [18.5658, 12.9771, 14.2801],\n",
      "        [19.0429, 12.7812, 14.4955],\n",
      "        [18.4041, 12.8120, 13.7091],\n",
      "        [18.4925, 12.9474, 14.2269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.2685,  17.8540, -12.7830],\n",
      "        [-16.4360,  18.2050, -13.0763],\n",
      "        [-16.3633,  17.4602, -12.6126],\n",
      "        [-16.5380,  17.5266, -12.3480],\n",
      "        [-16.7064,  17.5614, -12.5274],\n",
      "        [-16.9768,  18.2233, -12.5348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4807,  12.6658,  14.2970, -16.2685,  17.8540, -12.7830],\n",
      "        [ 18.6329,  12.6296,  14.2525, -16.4360,  18.2050, -13.0763],\n",
      "        [ 18.5658,  12.9771,  14.2801, -16.3633,  17.4602, -12.6126],\n",
      "        [ 19.0429,  12.7812,  14.4955, -16.5380,  17.5266, -12.3480],\n",
      "        [ 18.4041,  12.8120,  13.7091, -16.7064,  17.5614, -12.5274],\n",
      "        [ 18.4925,  12.9474,  14.2269, -16.9768,  18.2233, -12.5348]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5639543533325195\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8935, 13.0378, 14.4814],\n",
      "        [18.3471, 12.8594, 13.9459],\n",
      "        [17.8351, 12.9261, 13.3887],\n",
      "        [18.5975, 12.9135, 14.4814],\n",
      "        [18.3023, 12.7411, 14.1916],\n",
      "        [18.5123, 12.7269, 14.0286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8433, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7298,  18.0568, -12.4717],\n",
      "        [-16.4697,  17.5550, -12.5005],\n",
      "        [-16.8274,  18.0695, -12.5382],\n",
      "        [-16.1949,  17.3921, -12.3891],\n",
      "        [-16.5761,  18.1702, -12.5543],\n",
      "        [-16.5817,  18.0238, -12.7190]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8935,  13.0378,  14.4814, -16.7298,  18.0568, -12.4717],\n",
      "        [ 18.3471,  12.8594,  13.9459, -16.4697,  17.5550, -12.5005],\n",
      "        [ 17.8351,  12.9261,  13.3887, -16.8274,  18.0695, -12.5382],\n",
      "        [ 18.5975,  12.9135,  14.4814, -16.1949,  17.3921, -12.3891],\n",
      "        [ 18.3023,  12.7411,  14.1916, -16.5761,  18.1702, -12.5543],\n",
      "        [ 18.5123,  12.7269,  14.0286, -16.5817,  18.0238, -12.7190]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6078901290893555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6934, 12.8417, 14.3636],\n",
      "        [18.3622, 12.9450, 13.8787],\n",
      "        [18.5276, 13.0263, 14.2053],\n",
      "        [18.6506, 13.1735, 14.0963],\n",
      "        [18.2327, 12.6952, 14.0964],\n",
      "        [18.4372, 12.4504, 14.0807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4122,  17.7873, -12.8364],\n",
      "        [-16.4374,  17.6920, -12.3895],\n",
      "        [-16.3283,  18.0923, -12.6945],\n",
      "        [-16.2734,  17.3746, -12.4754],\n",
      "        [-16.4246,  17.8212, -12.5132],\n",
      "        [-16.3566,  18.1900, -12.5340]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6934,  12.8417,  14.3636, -16.4122,  17.7873, -12.8364],\n",
      "        [ 18.3622,  12.9450,  13.8787, -16.4374,  17.6920, -12.3895],\n",
      "        [ 18.5276,  13.0263,  14.2053, -16.3283,  18.0923, -12.6945],\n",
      "        [ 18.6506,  13.1735,  14.0963, -16.2734,  17.3746, -12.4754],\n",
      "        [ 18.2327,  12.6952,  14.0964, -16.4246,  17.8212, -12.5132],\n",
      "        [ 18.4372,  12.4504,  14.0807, -16.3566,  18.1900, -12.5340]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5841116905212402\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9783, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4021, 12.8191, 14.0399],\n",
      "        [18.7890, 12.8685, 14.2076],\n",
      "        [18.5220, 12.7663, 13.7054],\n",
      "        [18.8012, 13.1656, 14.2587],\n",
      "        [18.3913, 12.8970, 14.0978],\n",
      "        [18.6728, 12.8876, 14.0070]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5167,  18.1998, -12.9418],\n",
      "        [-16.2092,  18.1237, -12.2843],\n",
      "        [-16.8694,  18.0352, -12.6632],\n",
      "        [-16.4306,  17.8162, -12.6586],\n",
      "        [-16.3010,  18.0785, -12.5628],\n",
      "        [-16.9517,  18.0461, -12.4985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4021,  12.8191,  14.0399, -16.5167,  18.1998, -12.9418],\n",
      "        [ 18.7890,  12.8685,  14.2076, -16.2092,  18.1237, -12.2843],\n",
      "        [ 18.5220,  12.7663,  13.7054, -16.8694,  18.0352, -12.6632],\n",
      "        [ 18.8012,  13.1656,  14.2587, -16.4306,  17.8162, -12.6586],\n",
      "        [ 18.3913,  12.8970,  14.0978, -16.3010,  18.0785, -12.5628],\n",
      "        [ 18.6728,  12.8876,  14.0070, -16.9517,  18.0461, -12.4985]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5758237838745117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6884, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.0633, 12.7435, 13.9654],\n",
      "        [18.8916, 12.7143, 14.6886],\n",
      "        [18.5404, 12.9089, 13.9516],\n",
      "        [18.6985, 12.8686, 14.2039],\n",
      "        [18.4994, 12.5122, 14.1975],\n",
      "        [18.4582, 12.6500, 14.1054]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5369, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7434,  18.3966, -13.0390],\n",
      "        [-16.6948,  18.1344, -13.1184],\n",
      "        [-16.6521,  17.8491, -12.3920],\n",
      "        [-16.0079,  17.8630, -12.8106],\n",
      "        [-16.5902,  17.7488, -12.7078],\n",
      "        [-16.4535,  18.0494, -12.8353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.0633,  12.7435,  13.9654, -16.7434,  18.3966, -13.0390],\n",
      "        [ 18.8916,  12.7143,  14.6886, -16.6948,  18.1344, -13.1184],\n",
      "        [ 18.5404,  12.9089,  13.9516, -16.6521,  17.8491, -12.3920],\n",
      "        [ 18.6985,  12.8686,  14.2039, -16.0079,  17.8630, -12.8106],\n",
      "        [ 18.4994,  12.5122,  14.1975, -16.5902,  17.7488, -12.7078],\n",
      "        [ 18.4582,  12.6500,  14.1054, -16.4535,  18.0494, -12.8353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5699281692504883\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6037, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6129, 13.2031, 14.2478],\n",
      "        [18.3993, 12.6570, 14.1704],\n",
      "        [18.6244, 13.1679, 14.4492],\n",
      "        [19.0907, 13.1811, 14.5150],\n",
      "        [18.7317, 12.9384, 14.4911],\n",
      "        [18.8682, 12.9064, 14.3323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7683, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3300,  17.8475, -12.5073],\n",
      "        [-16.4852,  17.6388, -12.7849],\n",
      "        [-16.6487,  17.8397, -12.3210],\n",
      "        [-16.5529,  18.3179, -12.6109],\n",
      "        [-16.1565,  18.0854, -12.3120],\n",
      "        [-16.5822,  18.0669, -12.4698]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6129,  13.2031,  14.2478, -16.3300,  17.8475, -12.5073],\n",
      "        [ 18.3993,  12.6570,  14.1704, -16.4852,  17.6388, -12.7849],\n",
      "        [ 18.6244,  13.1679,  14.4492, -16.6487,  17.8397, -12.3210],\n",
      "        [ 19.0907,  13.1811,  14.5150, -16.5529,  18.3179, -12.6109],\n",
      "        [ 18.7317,  12.9384,  14.4911, -16.1565,  18.0854, -12.3120],\n",
      "        [ 18.8682,  12.9064,  14.3323, -16.5822,  18.0669, -12.4698]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5830836296081543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5336, 12.7777, 14.1398],\n",
      "        [18.8704, 12.8679, 14.3925],\n",
      "        [18.6777, 12.8836, 14.0165],\n",
      "        [18.3369, 12.4436, 13.9117],\n",
      "        [18.1179, 12.7096, 13.5161],\n",
      "        [18.7855, 12.8674, 14.6204]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7707,  17.9581, -12.3809],\n",
      "        [-16.5693,  18.1567, -12.8226],\n",
      "        [-16.4113,  17.7497, -12.6643],\n",
      "        [-16.4191,  17.8150, -12.5407],\n",
      "        [-16.6966,  17.9330, -12.8502],\n",
      "        [-16.1351,  17.3353, -12.2637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5336,  12.7777,  14.1398, -16.7707,  17.9581, -12.3809],\n",
      "        [ 18.8704,  12.8679,  14.3925, -16.5693,  18.1567, -12.8226],\n",
      "        [ 18.6777,  12.8836,  14.0165, -16.4113,  17.7497, -12.6643],\n",
      "        [ 18.3369,  12.4436,  13.9117, -16.4191,  17.8150, -12.5407],\n",
      "        [ 18.1179,  12.7096,  13.5161, -16.6966,  17.9330, -12.8502],\n",
      "        [ 18.7855,  12.8674,  14.6204, -16.1351,  17.3353, -12.2637]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.5784101486206055\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5644, 12.8976, 14.1420],\n",
      "        [18.5131, 12.9725, 14.3296],\n",
      "        [18.2271, 12.9738, 14.1192],\n",
      "        [18.6408, 12.9504, 14.2466],\n",
      "        [18.6080, 12.4182, 14.3832],\n",
      "        [18.8472, 13.2005, 14.4671]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.7726, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5187,  18.2291, -12.8907],\n",
      "        [-16.7580,  18.3204, -13.0290],\n",
      "        [-16.6098,  17.9348, -12.6113],\n",
      "        [-16.6895,  17.9788, -12.8694],\n",
      "        [-16.5024,  18.1996, -12.7127],\n",
      "        [-17.0253,  17.7886, -12.5049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5644,  12.8976,  14.1420, -16.5187,  18.2291, -12.8907],\n",
      "        [ 18.5131,  12.9725,  14.3296, -16.7580,  18.3204, -13.0290],\n",
      "        [ 18.2271,  12.9738,  14.1192, -16.6098,  17.9348, -12.6113],\n",
      "        [ 18.6408,  12.9504,  14.2466, -16.6895,  17.9788, -12.8694],\n",
      "        [ 18.6080,  12.4182,  14.3832, -16.5024,  18.1996, -12.7127],\n",
      "        [ 18.8472,  13.2005,  14.4671, -17.0253,  17.7886, -12.5049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5928759574890137\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9330, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.1786, 12.4630, 14.0936],\n",
      "        [18.8416, 12.6666, 14.2736],\n",
      "        [18.6345, 12.9307, 14.4800],\n",
      "        [18.8541, 13.3512, 14.3719],\n",
      "        [18.3548, 12.6735, 13.6373],\n",
      "        [18.5405, 12.7817, 14.2557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9626, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8444,  18.1110, -12.9337],\n",
      "        [-16.6695,  17.5093, -12.9679],\n",
      "        [-16.5214,  17.5854, -12.8883],\n",
      "        [-16.3669,  17.9846, -13.0281],\n",
      "        [-16.6907,  18.1888, -12.9891],\n",
      "        [-16.7470,  18.1897, -12.6531]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.1786,  12.4630,  14.0936, -16.8444,  18.1110, -12.9337],\n",
      "        [ 18.8416,  12.6666,  14.2736, -16.6695,  17.5093, -12.9679],\n",
      "        [ 18.6345,  12.9307,  14.4800, -16.5214,  17.5854, -12.8883],\n",
      "        [ 18.8541,  13.3512,  14.3719, -16.3669,  17.9846, -13.0281],\n",
      "        [ 18.3548,  12.6735,  13.6373, -16.6907,  18.1888, -12.9891],\n",
      "        [ 18.5405,  12.7817,  14.2557, -16.7470,  18.1897, -12.6531]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5712642669677734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3721, 12.5249, 14.2319],\n",
      "        [18.5398, 12.9244, 13.9367],\n",
      "        [18.4814, 12.7053, 14.2108],\n",
      "        [18.6884, 13.3687, 14.3327],\n",
      "        [18.8283, 12.8964, 14.2328],\n",
      "        [18.4406, 12.6406, 13.9735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6264, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8838,  18.3068, -12.6742],\n",
      "        [-17.0603,  18.3182, -12.9834],\n",
      "        [-16.5746,  17.9291, -12.3940],\n",
      "        [-16.5533,  17.8872, -12.6926],\n",
      "        [-16.4070,  17.5033, -11.9857],\n",
      "        [-16.8771,  17.9484, -13.0686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3721,  12.5249,  14.2319, -16.8838,  18.3068, -12.6742],\n",
      "        [ 18.5398,  12.9244,  13.9367, -17.0603,  18.3182, -12.9834],\n",
      "        [ 18.4814,  12.7053,  14.2108, -16.5746,  17.9291, -12.3940],\n",
      "        [ 18.6884,  13.3687,  14.3327, -16.5533,  17.8872, -12.6926],\n",
      "        [ 18.8283,  12.8964,  14.2328, -16.4070,  17.5033, -11.9857],\n",
      "        [ 18.4406,  12.6406,  13.9735, -16.8771,  17.9484, -13.0686]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.588484764099121\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9008, 13.1554, 14.5300],\n",
      "        [18.4472, 12.4883, 14.0817],\n",
      "        [18.9326, 13.0152, 14.7771],\n",
      "        [18.5574, 13.0191, 14.5807],\n",
      "        [18.5288, 12.9885, 14.1006],\n",
      "        [18.2546, 12.7683, 14.0275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.3088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6929,  18.3708, -12.8306],\n",
      "        [-16.4559,  17.9302, -12.8921],\n",
      "        [-16.4850,  18.2387, -13.0884],\n",
      "        [-15.9573,  18.1463, -12.6129],\n",
      "        [-16.8345,  18.5076, -12.6255],\n",
      "        [-16.8543,  18.3119, -13.1919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9008,  13.1554,  14.5300, -16.6929,  18.3708, -12.8306],\n",
      "        [ 18.4472,  12.4883,  14.0817, -16.4559,  17.9302, -12.8921],\n",
      "        [ 18.9326,  13.0152,  14.7771, -16.4850,  18.2387, -13.0884],\n",
      "        [ 18.5574,  13.0191,  14.5807, -15.9573,  18.1463, -12.6129],\n",
      "        [ 18.5288,  12.9885,  14.1006, -16.8345,  18.5076, -12.6255],\n",
      "        [ 18.2546,  12.7683,  14.0275, -16.8543,  18.3119, -13.1919]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.636411428451538\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[17.9588, 12.6377, 13.7359],\n",
      "        [18.4652, 12.8800, 14.2655],\n",
      "        [18.6098, 13.2481, 14.1803],\n",
      "        [17.9787, 11.9076, 13.9849],\n",
      "        [18.4011, 13.0000, 14.1313],\n",
      "        [18.8014, 13.1763, 14.6160]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1753,  17.8354, -12.3020],\n",
      "        [-16.4449,  17.9362, -12.9961],\n",
      "        [-16.5807,  17.9951, -12.6517],\n",
      "        [-16.8179,  18.1402, -12.9027],\n",
      "        [-16.5436,  17.9896, -12.6205],\n",
      "        [-17.0880,  18.2621, -12.7550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 17.9588,  12.6377,  13.7359, -16.1753,  17.8354, -12.3020],\n",
      "        [ 18.4652,  12.8800,  14.2655, -16.4449,  17.9362, -12.9961],\n",
      "        [ 18.6098,  13.2481,  14.1803, -16.5807,  17.9951, -12.6517],\n",
      "        [ 17.9787,  11.9076,  13.9849, -16.8179,  18.1402, -12.9027],\n",
      "        [ 18.4011,  13.0000,  14.1313, -16.5436,  17.9896, -12.6205],\n",
      "        [ 18.8014,  13.1763,  14.6160, -17.0880,  18.2621, -12.7550]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.5253641605377197\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6067, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7777, 12.7683, 14.3540],\n",
      "        [18.5739, 13.0055, 14.0921],\n",
      "        [18.6490, 12.6664, 13.9422],\n",
      "        [18.7274, 12.6898, 14.7210],\n",
      "        [18.6806, 12.8412, 14.3822],\n",
      "        [18.3798, 12.8505, 14.3274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.2777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8002,  18.1744, -13.0630],\n",
      "        [-16.4906,  18.2306, -12.7091],\n",
      "        [-16.3107,  17.8676, -12.5230],\n",
      "        [-16.2122,  17.7558, -12.7152],\n",
      "        [-16.7459,  18.0235, -12.6669],\n",
      "        [-16.5249,  18.4451, -12.3974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7777,  12.7683,  14.3540, -16.8002,  18.1744, -13.0630],\n",
      "        [ 18.5739,  13.0055,  14.0921, -16.4906,  18.2306, -12.7091],\n",
      "        [ 18.6490,  12.6664,  13.9422, -16.3107,  17.8676, -12.5230],\n",
      "        [ 18.7274,  12.6898,  14.7210, -16.2122,  17.7558, -12.7152],\n",
      "        [ 18.6806,  12.8412,  14.3822, -16.7459,  18.0235, -12.6669],\n",
      "        [ 18.3798,  12.8505,  14.3274, -16.5249,  18.4451, -12.3974]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.6201729774475098\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0225, 13.4414, 14.4685],\n",
      "        [19.0565, 13.0727, 14.5952],\n",
      "        [18.7811, 13.2205, 14.9834],\n",
      "        [18.7597, 13.2129, 14.7564],\n",
      "        [19.0303, 13.1662, 14.7350],\n",
      "        [18.5732, 13.3099, 14.6020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5526, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3464,  17.9223, -12.5749],\n",
      "        [-16.7862,  17.9869, -12.8091],\n",
      "        [-16.9465,  18.2490, -12.8457],\n",
      "        [-16.8216,  18.4923, -12.8391],\n",
      "        [-16.7110,  18.1438, -12.9937],\n",
      "        [-16.9734,  18.5903, -13.1743]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0225,  13.4414,  14.4685, -16.3464,  17.9223, -12.5749],\n",
      "        [ 19.0565,  13.0727,  14.5952, -16.7862,  17.9869, -12.8091],\n",
      "        [ 18.7811,  13.2205,  14.9834, -16.9465,  18.2490, -12.8457],\n",
      "        [ 18.7597,  13.2129,  14.7564, -16.8216,  18.4923, -12.8391],\n",
      "        [ 19.0303,  13.1662,  14.7350, -16.7110,  18.1438, -12.9937],\n",
      "        [ 18.5732,  13.3099,  14.6020, -16.9734,  18.5903, -13.1743]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.626650333404541\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3839, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8298, 13.0603, 14.2808],\n",
      "        [18.4497, 12.7615, 14.1757],\n",
      "        [18.7928, 13.2116, 14.3612],\n",
      "        [18.4276, 12.8348, 14.2648],\n",
      "        [18.4344, 12.4982, 14.3816],\n",
      "        [18.8632, 12.9670, 14.8159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.1512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8684,  18.2054, -12.7349],\n",
      "        [-16.8782,  17.9636, -12.8000],\n",
      "        [-16.6611,  17.8675, -12.8241],\n",
      "        [-16.9827,  18.3785, -13.0386],\n",
      "        [-16.4888,  17.6537, -12.5420],\n",
      "        [-16.9731,  18.1287, -12.6868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8298,  13.0603,  14.2808, -16.8684,  18.2054, -12.7349],\n",
      "        [ 18.4497,  12.7615,  14.1757, -16.8782,  17.9636, -12.8000],\n",
      "        [ 18.7928,  13.2116,  14.3612, -16.6611,  17.8675, -12.8241],\n",
      "        [ 18.4276,  12.8348,  14.2648, -16.9827,  18.3785, -13.0386],\n",
      "        [ 18.4344,  12.4982,  14.3816, -16.4888,  17.6537, -12.5420],\n",
      "        [ 18.8632,  12.9670,  14.8159, -16.9731,  18.1287, -12.6868]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6261532306671143\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6858, 12.9380, 14.2773],\n",
      "        [18.7431, 13.1723, 14.4180],\n",
      "        [18.7300, 13.2080, 14.3787],\n",
      "        [18.8650, 13.1394, 14.4111],\n",
      "        [18.7881, 12.7980, 14.8599],\n",
      "        [18.7302, 12.9957, 14.3525]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9617,  17.9108, -12.5559],\n",
      "        [-16.6419,  17.7961, -12.8483],\n",
      "        [-16.5732,  17.6569, -12.4891],\n",
      "        [-16.8395,  18.2898, -12.7572],\n",
      "        [-16.8987,  18.0646, -13.1278],\n",
      "        [-16.7390,  18.0002, -12.6279]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6858,  12.9380,  14.2773, -16.9617,  17.9108, -12.5559],\n",
      "        [ 18.7431,  13.1723,  14.4180, -16.6419,  17.7961, -12.8483],\n",
      "        [ 18.7300,  13.2080,  14.3787, -16.5732,  17.6569, -12.4891],\n",
      "        [ 18.8650,  13.1394,  14.4111, -16.8395,  18.2898, -12.7572],\n",
      "        [ 18.7881,  12.7980,  14.8599, -16.8987,  18.0646, -13.1278],\n",
      "        [ 18.7302,  12.9957,  14.3525, -16.7390,  18.0002, -12.6279]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6102168560028076\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9404, 13.2459, 14.5498],\n",
      "        [18.7579, 12.6801, 14.4430],\n",
      "        [18.4857, 13.2282, 14.5834],\n",
      "        [18.5610, 13.2839, 14.1797],\n",
      "        [17.9456, 12.7473, 14.1808],\n",
      "        [18.7812, 13.3992, 14.0623]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.5222, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6056,  17.9420, -12.5499],\n",
      "        [-16.8030,  17.9454, -12.6106],\n",
      "        [-16.5735,  17.9892, -12.6158],\n",
      "        [-16.2563,  18.3936, -12.9212],\n",
      "        [-16.3439,  18.1658, -12.6622],\n",
      "        [-16.3713,  17.5072, -12.1438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9404,  13.2459,  14.5498, -16.6056,  17.9420, -12.5499],\n",
      "        [ 18.7579,  12.6801,  14.4430, -16.8030,  17.9454, -12.6106],\n",
      "        [ 18.4857,  13.2282,  14.5834, -16.5735,  17.9892, -12.6158],\n",
      "        [ 18.5610,  13.2839,  14.1797, -16.2563,  18.3936, -12.9212],\n",
      "        [ 17.9456,  12.7473,  14.1808, -16.3439,  18.1658, -12.6622],\n",
      "        [ 18.7812,  13.3992,  14.0623, -16.3713,  17.5072, -12.1438]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.631152391433716\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1922, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0720, 13.2521, 14.8705],\n",
      "        [18.5099, 12.6405, 14.3005],\n",
      "        [18.1973, 12.5632, 13.8704],\n",
      "        [18.8170, 13.0955, 14.2005],\n",
      "        [18.3025, 12.8865, 13.8741],\n",
      "        [18.9946, 12.9720, 14.5831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9345,  17.8916, -12.7391],\n",
      "        [-16.9817,  18.6055, -13.0585],\n",
      "        [-16.5883,  17.9543, -12.4968],\n",
      "        [-16.8564,  18.0507, -12.6729],\n",
      "        [-16.5500,  17.9848, -12.6040],\n",
      "        [-16.4283,  18.1295, -12.6424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0720,  13.2521,  14.8705, -16.9345,  17.8916, -12.7391],\n",
      "        [ 18.5099,  12.6405,  14.3005, -16.9817,  18.6055, -13.0585],\n",
      "        [ 18.1973,  12.5632,  13.8704, -16.5883,  17.9543, -12.4968],\n",
      "        [ 18.8170,  13.0955,  14.2005, -16.8564,  18.0507, -12.6729],\n",
      "        [ 18.3025,  12.8865,  13.8741, -16.5500,  17.9848, -12.6040],\n",
      "        [ 18.9946,  12.9720,  14.5831, -16.4283,  18.1295, -12.6424]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.658247232437134\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8076, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2338, 13.2069, 14.4947],\n",
      "        [18.5351, 12.9607, 14.2278],\n",
      "        [18.2359, 12.6164, 13.7783],\n",
      "        [18.7265, 13.0769, 14.2867],\n",
      "        [18.3155, 13.1559, 14.4574],\n",
      "        [18.5165, 12.8718, 14.5137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-15.9742,  17.7776, -12.3912],\n",
      "        [-16.8169,  18.4440, -12.9319],\n",
      "        [-16.5998,  17.7612, -12.5687],\n",
      "        [-16.7179,  18.1277, -13.1959],\n",
      "        [-16.4985,  18.3527, -12.8640],\n",
      "        [-16.6001,  18.2464, -12.9865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2338,  13.2069,  14.4947, -15.9742,  17.7776, -12.3912],\n",
      "        [ 18.5351,  12.9607,  14.2278, -16.8169,  18.4440, -12.9319],\n",
      "        [ 18.2359,  12.6164,  13.7783, -16.5998,  17.7612, -12.5687],\n",
      "        [ 18.7265,  13.0769,  14.2867, -16.7179,  18.1277, -13.1959],\n",
      "        [ 18.3155,  13.1559,  14.4574, -16.4985,  18.3527, -12.8640],\n",
      "        [ 18.5165,  12.8718,  14.5137, -16.6001,  18.2464, -12.9865]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.6224567890167236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9702, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.3151, 12.7926, 14.4420],\n",
      "        [18.8546, 12.8364, 14.4803],\n",
      "        [18.6549, 13.1921, 14.7570],\n",
      "        [18.3986, 12.7099, 13.8912],\n",
      "        [18.7617, 13.0286, 14.5400],\n",
      "        [18.7391, 13.2373, 14.5228]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7885, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.0269,  17.5503, -12.7064],\n",
      "        [-16.7021,  18.1067, -12.8798],\n",
      "        [-16.4649,  17.5759, -12.7363],\n",
      "        [-16.8985,  18.3277, -12.9885],\n",
      "        [-17.0630,  18.2834, -12.8850],\n",
      "        [-16.8370,  18.3351, -12.9492]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.3151,  12.7926,  14.4420, -16.0269,  17.5503, -12.7064],\n",
      "        [ 18.8546,  12.8364,  14.4803, -16.7021,  18.1067, -12.8798],\n",
      "        [ 18.6549,  13.1921,  14.7570, -16.4649,  17.5759, -12.7363],\n",
      "        [ 18.3986,  12.7099,  13.8912, -16.8985,  18.3277, -12.9885],\n",
      "        [ 18.7617,  13.0286,  14.5400, -17.0630,  18.2834, -12.8850],\n",
      "        [ 18.7391,  13.2373,  14.5228, -16.8370,  18.3351, -12.9492]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.573608636856079\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9953, 13.6251, 14.5475],\n",
      "        [19.1253, 13.5035, 14.5942],\n",
      "        [18.9784, 13.2182, 14.6594],\n",
      "        [18.9545, 13.1955, 14.1873],\n",
      "        [18.8823, 13.2629, 14.5076],\n",
      "        [18.4838, 12.8272, 14.4866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.6538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4968,  18.0103, -12.8868],\n",
      "        [-16.8336,  18.2154, -12.9607],\n",
      "        [-16.6987,  18.1345, -13.0803],\n",
      "        [-16.4804,  18.0594, -12.8083],\n",
      "        [-16.7759,  18.0151, -12.8764],\n",
      "        [-16.5551,  17.6473, -12.7289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9953,  13.6251,  14.5475, -16.4968,  18.0103, -12.8868],\n",
      "        [ 19.1253,  13.5035,  14.5942, -16.8336,  18.2154, -12.9607],\n",
      "        [ 18.9784,  13.2182,  14.6594, -16.6987,  18.1345, -13.0803],\n",
      "        [ 18.9545,  13.1955,  14.1873, -16.4804,  18.0594, -12.8083],\n",
      "        [ 18.8823,  13.2629,  14.5076, -16.7759,  18.0151, -12.8764],\n",
      "        [ 18.4838,  12.8272,  14.4866, -16.5551,  17.6473, -12.7289]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.651695489883423\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6390, 13.0161, 14.1337],\n",
      "        [18.5579, 12.7858, 14.3918],\n",
      "        [18.4264, 13.3291, 14.2332],\n",
      "        [18.4119, 12.8993, 14.2477],\n",
      "        [18.8928, 12.9389, 14.6761],\n",
      "        [18.3079, 12.6529, 14.2395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.9779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0241,  18.3128, -12.6798],\n",
      "        [-16.5065,  18.0845, -13.1416],\n",
      "        [-17.0651,  18.3505, -12.7819],\n",
      "        [-16.6948,  18.1324, -12.6749],\n",
      "        [-16.9353,  18.3041, -12.8365],\n",
      "        [-16.9573,  18.2765, -12.8619]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6390,  13.0161,  14.1337, -17.0241,  18.3128, -12.6798],\n",
      "        [ 18.5579,  12.7858,  14.3918, -16.5065,  18.0845, -13.1416],\n",
      "        [ 18.4264,  13.3291,  14.2332, -17.0651,  18.3505, -12.7819],\n",
      "        [ 18.4119,  12.8993,  14.2477, -16.6948,  18.1324, -12.6749],\n",
      "        [ 18.8928,  12.9389,  14.6761, -16.9353,  18.3041, -12.8365],\n",
      "        [ 18.3079,  12.6529,  14.2395, -16.9573,  18.2765, -12.8619]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6260879039764404\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6848, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0153, 13.5629, 14.7611],\n",
      "        [18.4025, 13.0889, 14.4213],\n",
      "        [18.6269, 13.1651, 14.6635],\n",
      "        [18.2528, 13.1492, 14.6364],\n",
      "        [18.7114, 13.3752, 14.4301],\n",
      "        [18.8309, 12.8440, 14.1663]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5569, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3493,  18.2986, -12.8364],\n",
      "        [-16.7807,  18.3855, -12.7817],\n",
      "        [-16.5477,  17.4023, -12.6535],\n",
      "        [-16.9121,  18.4708, -12.8130],\n",
      "        [-16.4473,  18.0643, -12.6307],\n",
      "        [-16.7651,  18.3958, -12.7995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0153,  13.5629,  14.7611, -16.3493,  18.2986, -12.8364],\n",
      "        [ 18.4025,  13.0889,  14.4213, -16.7807,  18.3855, -12.7817],\n",
      "        [ 18.6269,  13.1651,  14.6635, -16.5477,  17.4023, -12.6535],\n",
      "        [ 18.2528,  13.1492,  14.6364, -16.9121,  18.4708, -12.8130],\n",
      "        [ 18.7114,  13.3752,  14.4301, -16.4473,  18.0643, -12.6307],\n",
      "        [ 18.8309,  12.8440,  14.1663, -16.7651,  18.3958, -12.7995]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6639404296875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0253, 12.9701, 14.3090],\n",
      "        [18.3526, 12.8767, 14.7091],\n",
      "        [18.4098, 12.7582, 14.0444],\n",
      "        [19.2156, 13.6104, 14.7833],\n",
      "        [18.6968, 13.2283, 14.5360],\n",
      "        [18.4894, 13.0537, 14.4929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9031,  18.3420, -13.1024],\n",
      "        [-16.5405,  18.1894, -12.7921],\n",
      "        [-16.4686,  18.0599, -12.9551],\n",
      "        [-16.4171,  18.2680, -12.7480],\n",
      "        [-16.8714,  18.1008, -12.7990],\n",
      "        [-16.3601,  17.8299, -12.6521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0253,  12.9701,  14.3090, -16.9031,  18.3420, -13.1024],\n",
      "        [ 18.3526,  12.8767,  14.7091, -16.5405,  18.1894, -12.7921],\n",
      "        [ 18.4098,  12.7582,  14.0444, -16.4686,  18.0599, -12.9551],\n",
      "        [ 19.2156,  13.6104,  14.7833, -16.4171,  18.2680, -12.7480],\n",
      "        [ 18.6968,  13.2283,  14.5360, -16.8714,  18.1008, -12.7990],\n",
      "        [ 18.4894,  13.0537,  14.4929, -16.3601,  17.8299, -12.6521]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.654818058013916\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5217, 12.7910, 14.5480],\n",
      "        [18.5007, 12.7000, 14.1350],\n",
      "        [18.8961, 13.1692, 14.4821],\n",
      "        [18.1991, 12.7677, 13.9608],\n",
      "        [18.6053, 12.7189, 14.1365],\n",
      "        [18.6837, 13.4172, 14.7907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9500,  18.3841, -12.7977],\n",
      "        [-16.5567,  17.7877, -12.5867],\n",
      "        [-16.2547,  18.2882, -12.8071],\n",
      "        [-16.3187,  17.9158, -12.7709],\n",
      "        [-16.6521,  18.3313, -12.9208],\n",
      "        [-16.8954,  18.3984, -12.8416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5217,  12.7910,  14.5480, -16.9500,  18.3841, -12.7977],\n",
      "        [ 18.5007,  12.7000,  14.1350, -16.5567,  17.7877, -12.5867],\n",
      "        [ 18.8961,  13.1692,  14.4821, -16.2547,  18.2882, -12.8071],\n",
      "        [ 18.1991,  12.7677,  13.9608, -16.3187,  17.9158, -12.7709],\n",
      "        [ 18.6053,  12.7189,  14.1365, -16.6521,  18.3313, -12.9208],\n",
      "        [ 18.6837,  13.4172,  14.7907, -16.8954,  18.3984, -12.8416]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.6356654167175293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5450, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9405, 13.1810, 14.5651],\n",
      "        [18.3146, 12.8004, 14.2484],\n",
      "        [18.8210, 13.2352, 14.3759],\n",
      "        [18.8120, 13.2257, 14.3510],\n",
      "        [18.6085, 12.2676, 14.5975],\n",
      "        [18.5708, 13.2344, 14.5262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.1838, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9299,  18.0648, -12.6139],\n",
      "        [-16.7198,  18.0379, -12.7223],\n",
      "        [-16.7254,  17.7003, -12.6926],\n",
      "        [-16.8482,  18.1665, -13.1042],\n",
      "        [-16.9204,  18.0045, -12.7873],\n",
      "        [-17.2195,  18.2902, -13.0773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9405,  13.1810,  14.5651, -16.9299,  18.0648, -12.6139],\n",
      "        [ 18.3146,  12.8004,  14.2484, -16.7198,  18.0379, -12.7223],\n",
      "        [ 18.8210,  13.2352,  14.3759, -16.7254,  17.7003, -12.6926],\n",
      "        [ 18.8120,  13.2257,  14.3510, -16.8482,  18.1665, -13.1042],\n",
      "        [ 18.6085,  12.2676,  14.5975, -16.9204,  18.0045, -12.7873],\n",
      "        [ 18.5708,  13.2344,  14.5262, -17.2195,  18.2902, -13.0773]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.652945041656494\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1586, 13.3179, 14.7368],\n",
      "        [18.5338, 12.4650, 14.3630],\n",
      "        [18.7921, 12.7757, 14.4800],\n",
      "        [18.6904, 13.2713, 14.4756],\n",
      "        [18.5119, 13.0610, 14.3161],\n",
      "        [18.8343, 13.2869, 14.6120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.1893,  18.0609, -13.1723],\n",
      "        [-17.0434,  18.1162, -13.0038],\n",
      "        [-16.5781,  17.9646, -12.6878],\n",
      "        [-16.8922,  17.6633, -13.0015],\n",
      "        [-16.9767,  18.6961, -13.1451],\n",
      "        [-16.9883,  18.8405, -13.1145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1586,  13.3179,  14.7368, -16.1893,  18.0609, -13.1723],\n",
      "        [ 18.5338,  12.4650,  14.3630, -17.0434,  18.1162, -13.0038],\n",
      "        [ 18.7921,  12.7757,  14.4800, -16.5781,  17.9646, -12.6878],\n",
      "        [ 18.6904,  13.2713,  14.4756, -16.8922,  17.6633, -13.0015],\n",
      "        [ 18.5119,  13.0610,  14.3161, -16.9767,  18.6961, -13.1451],\n",
      "        [ 18.8343,  13.2869,  14.6120, -16.9883,  18.8405, -13.1145]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.664498805999756\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5541, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7605, 12.9448, 14.5956],\n",
      "        [18.7849, 13.3923, 14.3936],\n",
      "        [18.2276, 13.0472, 14.4992],\n",
      "        [18.7078, 13.4468, 14.0964],\n",
      "        [18.8962, 13.2616, 14.3662],\n",
      "        [18.4610, 13.2544, 14.5048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4753,  17.4574, -12.2589],\n",
      "        [-16.7987,  18.2637, -12.8002],\n",
      "        [-16.8269,  18.0840, -12.7177],\n",
      "        [-16.8336,  17.9703, -12.7159],\n",
      "        [-16.7427,  17.9162, -12.6059],\n",
      "        [-16.9876,  18.4654, -13.0830]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7605,  12.9448,  14.5956, -16.4753,  17.4574, -12.2589],\n",
      "        [ 18.7849,  13.3923,  14.3936, -16.7987,  18.2637, -12.8002],\n",
      "        [ 18.2276,  13.0472,  14.4992, -16.8269,  18.0840, -12.7177],\n",
      "        [ 18.7078,  13.4468,  14.0964, -16.8336,  17.9703, -12.7159],\n",
      "        [ 18.8962,  13.2616,  14.3662, -16.7427,  17.9162, -12.6059],\n",
      "        [ 18.4610,  13.2544,  14.5048, -16.9876,  18.4654, -13.0830]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6119163036346436\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5433, 12.9576, 14.1816],\n",
      "        [19.0995, 12.8021, 14.5028],\n",
      "        [18.6067, 13.0275, 14.4825],\n",
      "        [18.4878, 12.8627, 14.2882],\n",
      "        [18.4347, 12.9024, 14.1192],\n",
      "        [18.9605, 13.0696, 14.1457]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.0384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8619,  18.6135, -13.0217],\n",
      "        [-16.7127,  17.9458, -12.6507],\n",
      "        [-16.6495,  18.3683, -13.1185],\n",
      "        [-16.1873,  18.0715, -12.6960],\n",
      "        [-17.0768,  18.2211, -13.1011],\n",
      "        [-16.7371,  18.1963, -12.9780]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5433,  12.9576,  14.1816, -16.8619,  18.6135, -13.0217],\n",
      "        [ 19.0995,  12.8021,  14.5028, -16.7127,  17.9458, -12.6507],\n",
      "        [ 18.6067,  13.0275,  14.4825, -16.6495,  18.3683, -13.1185],\n",
      "        [ 18.4878,  12.8627,  14.2882, -16.1873,  18.0715, -12.6960],\n",
      "        [ 18.4347,  12.9024,  14.1192, -17.0768,  18.2211, -13.1011],\n",
      "        [ 18.9605,  13.0696,  14.1457, -16.7371,  18.1963, -12.9780]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6403732299804688\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6447, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1135, 13.3413, 14.9017],\n",
      "        [18.8117, 13.1442, 14.3217],\n",
      "        [18.5650, 12.7261, 14.4130],\n",
      "        [19.0139, 13.4089, 14.7736],\n",
      "        [18.0713, 13.1692, 14.1012],\n",
      "        [18.6199, 13.1634, 14.2271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.0585, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6258,  18.0851, -12.7535],\n",
      "        [-16.8544,  17.8539, -13.0740],\n",
      "        [-16.7021,  18.2355, -12.6831],\n",
      "        [-17.1606,  18.5530, -13.0388],\n",
      "        [-16.8585,  18.3131, -13.3139],\n",
      "        [-16.8218,  18.2869, -13.0880]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1135,  13.3413,  14.9017, -16.6258,  18.0851, -12.7535],\n",
      "        [ 18.8117,  13.1442,  14.3217, -16.8544,  17.8539, -13.0740],\n",
      "        [ 18.5650,  12.7261,  14.4130, -16.7021,  18.2355, -12.6831],\n",
      "        [ 19.0139,  13.4089,  14.7736, -17.1606,  18.5530, -13.0388],\n",
      "        [ 18.0713,  13.1692,  14.1012, -16.8585,  18.3131, -13.3139],\n",
      "        [ 18.6199,  13.1634,  14.2271, -16.8218,  18.2869, -13.0880]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.676297187805176\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5055, 13.1617, 15.4638],\n",
      "        [19.0866, 13.1750, 14.6829],\n",
      "        [19.0990, 13.1436, 14.6479],\n",
      "        [18.7802, 13.1690, 14.5083],\n",
      "        [18.5537, 13.4750, 14.4802],\n",
      "        [18.9467, 13.2996, 14.8702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6400,  17.8046, -12.3293],\n",
      "        [-16.7987,  18.1745, -12.9636],\n",
      "        [-16.7370,  17.8078, -12.8648],\n",
      "        [-17.2936,  18.9683, -13.1622],\n",
      "        [-17.1088,  18.4375, -13.1268],\n",
      "        [-16.5460,  18.3039, -12.8671]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5055,  13.1617,  15.4638, -16.6400,  17.8046, -12.3293],\n",
      "        [ 19.0866,  13.1750,  14.6829, -16.7987,  18.1745, -12.9636],\n",
      "        [ 19.0990,  13.1436,  14.6479, -16.7370,  17.8078, -12.8648],\n",
      "        [ 18.7802,  13.1690,  14.5083, -17.2936,  18.9683, -13.1622],\n",
      "        [ 18.5537,  13.4750,  14.4802, -17.1088,  18.4375, -13.1268],\n",
      "        [ 18.9467,  13.2996,  14.8702, -16.5460,  18.3039, -12.8671]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.6957626342773438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0223, 13.0585, 14.7116],\n",
      "        [18.5814, 13.0828, 14.4645],\n",
      "        [18.6869, 12.9048, 14.6237],\n",
      "        [18.9941, 13.0249, 14.8617],\n",
      "        [18.9963, 13.2738, 14.2319],\n",
      "        [18.9946, 13.2996, 14.3529]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.2373, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.5366,  18.3067, -12.6726],\n",
      "        [-16.6864,  18.3926, -12.8500],\n",
      "        [-16.8295,  17.9390, -12.9062],\n",
      "        [-16.6706,  18.1621, -13.0829],\n",
      "        [-16.7462,  18.0261, -13.0916],\n",
      "        [-16.7895,  18.2743, -12.8758]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0223,  13.0585,  14.7116, -16.5366,  18.3067, -12.6726],\n",
      "        [ 18.5814,  13.0828,  14.4645, -16.6864,  18.3926, -12.8500],\n",
      "        [ 18.6869,  12.9048,  14.6237, -16.8295,  17.9390, -12.9062],\n",
      "        [ 18.9941,  13.0249,  14.8617, -16.6706,  18.1621, -13.0829],\n",
      "        [ 18.9963,  13.2738,  14.2319, -16.7462,  18.0261, -13.0916],\n",
      "        [ 18.9946,  13.2996,  14.3529, -16.7895,  18.2743, -12.8758]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6641955375671387\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.4770, 13.2894, 14.5420],\n",
      "        [19.1363, 13.2871, 14.7585],\n",
      "        [18.5451, 12.8791, 14.3087],\n",
      "        [18.7558, 13.4223, 14.6561],\n",
      "        [18.7048, 12.9457, 14.5262],\n",
      "        [19.0406, 13.3042, 14.3998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5205,  18.5168, -13.4319],\n",
      "        [-16.7729,  18.0335, -12.9568],\n",
      "        [-16.5650,  17.9817, -12.6795],\n",
      "        [-16.2713,  17.9741, -12.7969],\n",
      "        [-16.4613,  18.1311, -12.8796],\n",
      "        [-16.8534,  18.4901, -12.8511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.4770,  13.2894,  14.5420, -17.5205,  18.5168, -13.4319],\n",
      "        [ 19.1363,  13.2871,  14.7585, -16.7729,  18.0335, -12.9568],\n",
      "        [ 18.5451,  12.8791,  14.3087, -16.5650,  17.9817, -12.6795],\n",
      "        [ 18.7558,  13.4223,  14.6561, -16.2713,  17.9741, -12.7969],\n",
      "        [ 18.7048,  12.9457,  14.5262, -16.4613,  18.1311, -12.8796],\n",
      "        [ 19.0406,  13.3042,  14.3998, -16.8534,  18.4901, -12.8511]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.681680202484131\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2328, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7774, 13.3198, 14.4936],\n",
      "        [18.5714, 13.3147, 14.6044],\n",
      "        [19.0557, 13.3451, 14.4331],\n",
      "        [18.6414, 13.5783, 14.5611],\n",
      "        [18.8581, 12.8953, 14.5833],\n",
      "        [18.8746, 12.8342, 14.3809]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.3950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.3602,  18.2322, -12.8372],\n",
      "        [-16.8450,  18.0388, -12.6167],\n",
      "        [-16.6379,  18.3052, -12.7712],\n",
      "        [-16.7049,  18.3918, -13.1311],\n",
      "        [-17.0267,  18.6820, -13.0118],\n",
      "        [-17.1204,  18.3352, -12.8102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7774,  13.3198,  14.4936, -16.3602,  18.2322, -12.8372],\n",
      "        [ 18.5714,  13.3147,  14.6044, -16.8450,  18.0388, -12.6167],\n",
      "        [ 19.0557,  13.3451,  14.4331, -16.6379,  18.3052, -12.7712],\n",
      "        [ 18.6414,  13.5783,  14.5611, -16.7049,  18.3918, -13.1311],\n",
      "        [ 18.8581,  12.8953,  14.5833, -17.0267,  18.6820, -13.0118],\n",
      "        [ 18.8746,  12.8342,  14.3809, -17.1204,  18.3352, -12.8102]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.651487112045288\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6376, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1230, 13.4256, 14.9075],\n",
      "        [18.8553, 13.1407, 14.6198],\n",
      "        [18.5273, 13.1232, 14.5548],\n",
      "        [18.7501, 13.1629, 13.7994],\n",
      "        [18.8672, 13.0735, 14.2977],\n",
      "        [18.5902, 12.7794, 14.2670]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6055, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9614,  18.2592, -13.0739],\n",
      "        [-17.0306,  18.2183, -12.4430],\n",
      "        [-16.8194,  18.2374, -13.0349],\n",
      "        [-16.3251,  18.1441, -13.0444],\n",
      "        [-17.0547,  18.3913, -12.7738],\n",
      "        [-16.9492,  18.2347, -13.0562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1230,  13.4256,  14.9075, -16.9614,  18.2592, -13.0739],\n",
      "        [ 18.8553,  13.1407,  14.6198, -17.0306,  18.2183, -12.4430],\n",
      "        [ 18.5273,  13.1232,  14.5548, -16.8194,  18.2374, -13.0349],\n",
      "        [ 18.7501,  13.1629,  13.7994, -16.3251,  18.1441, -13.0444],\n",
      "        [ 18.8672,  13.0735,  14.2977, -17.0547,  18.3913, -12.7738],\n",
      "        [ 18.5902,  12.7794,  14.2670, -16.9492,  18.2347, -13.0562]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7024545669555664\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2966, 13.5748, 14.9726],\n",
      "        [18.5784, 13.4451, 14.3257],\n",
      "        [19.0369, 13.0273, 14.6558],\n",
      "        [18.9238, 12.7747, 14.1275],\n",
      "        [18.4749, 13.1753, 14.4912],\n",
      "        [19.2981, 13.5356, 14.9764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7125, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2714,  18.6239, -12.8564],\n",
      "        [-16.9525,  18.3152, -13.1354],\n",
      "        [-17.0115,  18.2462, -13.1480],\n",
      "        [-16.6455,  18.0042, -12.8304],\n",
      "        [-16.5875,  18.2216, -12.5865],\n",
      "        [-17.1360,  18.3242, -12.8540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2966,  13.5748,  14.9726, -17.2714,  18.6239, -12.8564],\n",
      "        [ 18.5784,  13.4451,  14.3257, -16.9525,  18.3152, -13.1354],\n",
      "        [ 19.0369,  13.0273,  14.6558, -17.0115,  18.2462, -13.1480],\n",
      "        [ 18.9238,  12.7747,  14.1275, -16.6455,  18.0042, -12.8304],\n",
      "        [ 18.4749,  13.1753,  14.4912, -16.5875,  18.2216, -12.5865],\n",
      "        [ 19.2981,  13.5356,  14.9764, -17.1360,  18.3242, -12.8540]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7296714782714844\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7093, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8000, 13.3425, 14.3990],\n",
      "        [18.8564, 13.1277, 14.0908],\n",
      "        [19.4799, 13.6234, 14.6558],\n",
      "        [19.2958, 13.6321, 14.4463],\n",
      "        [19.2664, 13.3079, 14.7101],\n",
      "        [18.8516, 13.2243, 14.4027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8888, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1458,  18.2734, -13.3365],\n",
      "        [-16.9683,  18.4919, -12.9318],\n",
      "        [-17.0826,  18.5182, -13.1444],\n",
      "        [-16.5588,  18.0349, -13.0437],\n",
      "        [-16.6695,  18.4219, -13.1616],\n",
      "        [-16.6536,  18.5178, -13.2226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8000,  13.3425,  14.3990, -17.1458,  18.2734, -13.3365],\n",
      "        [ 18.8564,  13.1277,  14.0908, -16.9683,  18.4919, -12.9318],\n",
      "        [ 19.4799,  13.6234,  14.6558, -17.0826,  18.5182, -13.1444],\n",
      "        [ 19.2958,  13.6321,  14.4463, -16.5588,  18.0349, -13.0437],\n",
      "        [ 19.2664,  13.3079,  14.7101, -16.6695,  18.4219, -13.1616],\n",
      "        [ 18.8516,  13.2243,  14.4027, -16.6536,  18.5178, -13.2226]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.680757522583008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9529, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6129, 13.4643, 14.4806],\n",
      "        [18.1704, 13.1086, 14.1437],\n",
      "        [18.8360, 13.2439, 14.4718],\n",
      "        [18.7897, 12.9362, 14.2827],\n",
      "        [18.6878, 13.0939, 14.9147],\n",
      "        [18.6539, 13.1929, 14.6030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.4579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1636,  18.1050, -13.1945],\n",
      "        [-16.7667,  17.9959, -12.8354],\n",
      "        [-17.1317,  18.7527, -12.9904],\n",
      "        [-17.0821,  18.2512, -12.5744],\n",
      "        [-16.2723,  18.3792, -12.8267],\n",
      "        [-16.9786,  18.4934, -13.4622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6129,  13.4643,  14.4806, -17.1636,  18.1050, -13.1945],\n",
      "        [ 18.1704,  13.1086,  14.1437, -16.7667,  17.9959, -12.8354],\n",
      "        [ 18.8360,  13.2439,  14.4718, -17.1317,  18.7527, -12.9904],\n",
      "        [ 18.7897,  12.9362,  14.2827, -17.0821,  18.2512, -12.5744],\n",
      "        [ 18.6878,  13.0939,  14.9147, -16.2723,  18.3792, -12.8267],\n",
      "        [ 18.6539,  13.1929,  14.6030, -16.9786,  18.4934, -13.4622]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.673366069793701\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9774, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9878, 13.0350, 14.5730],\n",
      "        [19.0489, 12.9457, 14.7005],\n",
      "        [18.3981, 12.6472, 14.4906],\n",
      "        [18.8493, 13.1460, 14.4896],\n",
      "        [18.5699, 13.4088, 14.9206],\n",
      "        [18.9607, 13.2639, 14.3944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9760,  18.3284, -13.0604],\n",
      "        [-17.0143,  18.5867, -13.4145],\n",
      "        [-17.2716,  18.3564, -13.1901],\n",
      "        [-16.6617,  18.0676, -12.9117],\n",
      "        [-17.0272,  18.7441, -12.9329],\n",
      "        [-16.6876,  17.4320, -13.0838]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9878,  13.0350,  14.5730, -16.9760,  18.3284, -13.0604],\n",
      "        [ 19.0489,  12.9457,  14.7005, -17.0143,  18.5867, -13.4145],\n",
      "        [ 18.3981,  12.6472,  14.4906, -17.2716,  18.3564, -13.1901],\n",
      "        [ 18.8493,  13.1460,  14.4896, -16.6617,  18.0676, -12.9117],\n",
      "        [ 18.5699,  13.4088,  14.9206, -17.0272,  18.7441, -12.9329],\n",
      "        [ 18.9607,  13.2639,  14.3944, -16.6876,  17.4320, -13.0838]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6832244396209717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7685, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5055, 13.3382, 14.6667],\n",
      "        [19.0503, 13.4004, 14.7383],\n",
      "        [19.1226, 13.2653, 14.6002],\n",
      "        [18.7758, 12.8094, 14.3856],\n",
      "        [18.8830, 13.4875, 14.5530],\n",
      "        [19.1113, 12.9161, 14.5520]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.6443, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0818,  18.9362, -13.2448],\n",
      "        [-16.7658,  18.2111, -13.1288],\n",
      "        [-16.5661,  18.1220, -12.9076],\n",
      "        [-17.1241,  18.7143, -13.3991],\n",
      "        [-16.9917,  17.8955, -13.0036],\n",
      "        [-16.9814,  18.1127, -12.8186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5055,  13.3382,  14.6667, -17.0818,  18.9362, -13.2448],\n",
      "        [ 19.0503,  13.4004,  14.7383, -16.7658,  18.2111, -13.1288],\n",
      "        [ 19.1226,  13.2653,  14.6002, -16.5661,  18.1220, -12.9076],\n",
      "        [ 18.7758,  12.8094,  14.3856, -17.1241,  18.7143, -13.3991],\n",
      "        [ 18.8830,  13.4875,  14.5530, -16.9917,  17.8955, -13.0036],\n",
      "        [ 19.1113,  12.9161,  14.5520, -16.9814,  18.1127, -12.8186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.737863302230835\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7143, 13.1262, 14.7373],\n",
      "        [18.9866, 13.3372, 14.3699],\n",
      "        [18.7098, 13.5829, 14.6154],\n",
      "        [18.8309, 12.9211, 13.7797],\n",
      "        [18.6779, 12.7854, 14.3213],\n",
      "        [18.6484, 13.3105, 14.5952]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.8084, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6752,  18.1953, -13.0529],\n",
      "        [-17.6610,  18.7230, -13.4480],\n",
      "        [-16.9324,  18.3321, -12.9975],\n",
      "        [-17.0029,  18.6852, -13.2286],\n",
      "        [-16.9053,  18.0568, -12.9815],\n",
      "        [-16.8823,  18.5373, -13.1393]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7143,  13.1262,  14.7373, -16.6752,  18.1953, -13.0529],\n",
      "        [ 18.9866,  13.3372,  14.3699, -17.6610,  18.7230, -13.4480],\n",
      "        [ 18.7098,  13.5829,  14.6154, -16.9324,  18.3321, -12.9975],\n",
      "        [ 18.8309,  12.9211,  13.7797, -17.0029,  18.6852, -13.2286],\n",
      "        [ 18.6779,  12.7854,  14.3213, -16.9053,  18.0568, -12.9815],\n",
      "        [ 18.6484,  13.3105,  14.5952, -16.8823,  18.5373, -13.1393]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.671217203140259\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1022, 12.9354, 14.9543],\n",
      "        [18.5404, 13.4749, 14.5106],\n",
      "        [18.9602, 13.1110, 14.7527],\n",
      "        [19.2191, 13.6600, 14.5469],\n",
      "        [19.5704, 13.6778, 14.9762],\n",
      "        [19.1945, 12.8731, 14.6208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2500, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6560,  18.1141, -12.3118],\n",
      "        [-16.8957,  18.0430, -12.4324],\n",
      "        [-16.9234,  17.5095, -12.6839],\n",
      "        [-17.0139,  18.3404, -13.1013],\n",
      "        [-17.4420,  18.7570, -13.4848],\n",
      "        [-16.8391,  18.5194, -12.9226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1022,  12.9354,  14.9543, -16.6560,  18.1141, -12.3118],\n",
      "        [ 18.5404,  13.4749,  14.5106, -16.8957,  18.0430, -12.4324],\n",
      "        [ 18.9602,  13.1110,  14.7527, -16.9234,  17.5095, -12.6839],\n",
      "        [ 19.2191,  13.6600,  14.5469, -17.0139,  18.3404, -13.1013],\n",
      "        [ 19.5704,  13.6778,  14.9762, -17.4420,  18.7570, -13.4848],\n",
      "        [ 19.1945,  12.8731,  14.6208, -16.8391,  18.5194, -12.9226]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6776156425476074\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8374, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8643, 13.3748, 14.8314],\n",
      "        [18.9947, 13.5644, 14.9030],\n",
      "        [18.9149, 13.3095, 14.6558],\n",
      "        [18.6720, 13.0297, 14.1896],\n",
      "        [19.0383, 13.2881, 14.3381],\n",
      "        [19.0030, 13.3774, 14.7429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6271,  17.9620, -12.9160],\n",
      "        [-17.3237,  18.2177, -12.9174],\n",
      "        [-16.6907,  18.4003, -13.2800],\n",
      "        [-17.0221,  18.7491, -13.5585],\n",
      "        [-16.6696,  18.3777, -12.9402],\n",
      "        [-16.9557,  18.4351, -12.9694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8643,  13.3748,  14.8314, -16.6271,  17.9620, -12.9160],\n",
      "        [ 18.9947,  13.5644,  14.9030, -17.3237,  18.2177, -12.9174],\n",
      "        [ 18.9149,  13.3095,  14.6558, -16.6907,  18.4003, -13.2800],\n",
      "        [ 18.6720,  13.0297,  14.1896, -17.0221,  18.7491, -13.5585],\n",
      "        [ 19.0383,  13.2881,  14.3381, -16.6696,  18.3777, -12.9402],\n",
      "        [ 19.0030,  13.3774,  14.7429, -16.9557,  18.4351, -12.9694]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.679893970489502\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4118, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9513, 13.4126, 14.5934],\n",
      "        [18.8900, 13.3514, 14.6556],\n",
      "        [18.8855, 12.9567, 14.4176],\n",
      "        [19.1448, 13.2364, 14.8384],\n",
      "        [18.8389, 13.3719, 14.8099],\n",
      "        [18.7078, 13.0553, 14.3464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2756, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.4987,  18.3084, -13.0139],\n",
      "        [-16.8774,  18.3955, -12.8910],\n",
      "        [-16.6995,  18.1060, -12.9210],\n",
      "        [-16.7624,  18.0055, -12.8190],\n",
      "        [-16.8381,  18.1018, -12.4909],\n",
      "        [-16.8033,  18.2339, -13.3568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9513,  13.4126,  14.5934, -16.4987,  18.3084, -13.0139],\n",
      "        [ 18.8900,  13.3514,  14.6556, -16.8774,  18.3955, -12.8910],\n",
      "        [ 18.8855,  12.9567,  14.4176, -16.6995,  18.1060, -12.9210],\n",
      "        [ 19.1448,  13.2364,  14.8384, -16.7624,  18.0055, -12.8190],\n",
      "        [ 18.8389,  13.3719,  14.8099, -16.8381,  18.1018, -12.4909],\n",
      "        [ 18.7078,  13.0553,  14.3464, -16.8033,  18.2339, -13.3568]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6851086616516113\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9610, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9084, 12.9877, 14.7104],\n",
      "        [19.1458, 13.3512, 14.7806],\n",
      "        [19.1265, 12.9199, 14.5705],\n",
      "        [18.8799, 13.0805, 14.2726],\n",
      "        [18.7636, 13.3823, 14.6159],\n",
      "        [18.6749, 13.2113, 14.3383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.2324, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1048,  18.2557, -13.4647],\n",
      "        [-17.0028,  18.5546, -13.0740],\n",
      "        [-16.9804,  18.5708, -13.1050],\n",
      "        [-16.9740,  18.3723, -13.2765],\n",
      "        [-16.6681,  18.0595, -12.7555],\n",
      "        [-16.8569,  18.2029, -12.6896]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9084,  12.9877,  14.7104, -17.1048,  18.2557, -13.4647],\n",
      "        [ 19.1458,  13.3512,  14.7806, -17.0028,  18.5546, -13.0740],\n",
      "        [ 19.1265,  12.9199,  14.5705, -16.9804,  18.5708, -13.1050],\n",
      "        [ 18.8799,  13.0805,  14.2726, -16.9740,  18.3723, -13.2765],\n",
      "        [ 18.7636,  13.3823,  14.6159, -16.6681,  18.0595, -12.7555],\n",
      "        [ 18.6749,  13.2113,  14.3383, -16.8569,  18.2029, -12.6896]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.698732376098633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7962, 13.2489, 14.5198],\n",
      "        [19.0052, 13.3893, 14.5822],\n",
      "        [19.0857, 13.6890, 14.6707],\n",
      "        [19.1563, 13.4403, 14.6555],\n",
      "        [18.7784, 13.6055, 14.7323],\n",
      "        [18.9169, 13.1935, 14.9282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5796, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1043,  18.2795, -13.0707],\n",
      "        [-17.0848,  18.5995, -13.0979],\n",
      "        [-17.0306,  18.7167, -13.3683],\n",
      "        [-16.8790,  18.6383, -13.0991],\n",
      "        [-16.7421,  18.4024, -12.9363],\n",
      "        [-17.0303,  18.3734, -13.1345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7962,  13.2489,  14.5198, -17.1043,  18.2795, -13.0707],\n",
      "        [ 19.0052,  13.3893,  14.5822, -17.0848,  18.5995, -13.0979],\n",
      "        [ 19.0857,  13.6890,  14.6707, -17.0306,  18.7167, -13.3683],\n",
      "        [ 19.1563,  13.4403,  14.6555, -16.8790,  18.6383, -13.0991],\n",
      "        [ 18.7784,  13.6055,  14.7323, -16.7421,  18.4024, -12.9363],\n",
      "        [ 18.9169,  13.1935,  14.9282, -17.0303,  18.3734, -13.1345]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.688826322555542\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6358, 12.9996, 14.5054],\n",
      "        [18.9870, 13.6888, 14.7393],\n",
      "        [19.2900, 13.3284, 14.5823],\n",
      "        [18.4357, 12.6526, 13.9829],\n",
      "        [18.8802, 13.1838, 14.3948],\n",
      "        [18.6392, 12.7046, 14.2325]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.2186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1379,  18.4119, -13.0392],\n",
      "        [-17.0476,  18.5826, -13.2873],\n",
      "        [-16.3084,  17.9828, -12.6948],\n",
      "        [-16.9570,  18.4543, -13.5082],\n",
      "        [-16.9410,  18.5277, -13.2555],\n",
      "        [-17.1146,  18.9503, -13.3256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6358,  12.9996,  14.5054, -17.1379,  18.4119, -13.0392],\n",
      "        [ 18.9870,  13.6888,  14.7393, -17.0476,  18.5826, -13.2873],\n",
      "        [ 19.2900,  13.3284,  14.5823, -16.3084,  17.9828, -12.6948],\n",
      "        [ 18.4357,  12.6526,  13.9829, -16.9570,  18.4543, -13.5082],\n",
      "        [ 18.8802,  13.1838,  14.3948, -16.9410,  18.5277, -13.2555],\n",
      "        [ 18.6392,  12.7046,  14.2325, -17.1146,  18.9503, -13.3256]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6805167198181152\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8067, 13.3587, 14.1656],\n",
      "        [18.1871, 12.8114, 14.5061],\n",
      "        [18.7923, 13.5788, 14.3445],\n",
      "        [18.6067, 13.2068, 14.7528],\n",
      "        [19.1070, 13.4225, 14.9325],\n",
      "        [19.1538, 13.2736, 14.7858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0933,  18.2191, -12.8586],\n",
      "        [-16.3516,  17.6443, -12.6041],\n",
      "        [-16.7985,  18.3311, -12.8935],\n",
      "        [-16.9807,  18.5850, -13.2146],\n",
      "        [-17.1832,  18.2955, -13.3028],\n",
      "        [-17.1770,  18.6740, -13.5652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8067,  13.3587,  14.1656, -17.0933,  18.2191, -12.8586],\n",
      "        [ 18.1871,  12.8114,  14.5061, -16.3516,  17.6443, -12.6041],\n",
      "        [ 18.7923,  13.5788,  14.3445, -16.7985,  18.3311, -12.8935],\n",
      "        [ 18.6067,  13.2068,  14.7528, -16.9807,  18.5850, -13.2146],\n",
      "        [ 19.1070,  13.4225,  14.9325, -17.1832,  18.2955, -13.3028],\n",
      "        [ 19.1538,  13.2736,  14.7858, -17.1770,  18.6740, -13.5652]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.6769747734069824\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2817, 13.6431, 14.7997],\n",
      "        [18.4341, 12.6611, 14.4328],\n",
      "        [18.9888, 13.4655, 14.9791],\n",
      "        [18.5882, 13.1295, 13.7517],\n",
      "        [18.7990, 12.9589, 14.8414],\n",
      "        [18.9521, 13.3196, 14.8014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9457, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1320,  18.6670, -13.0735],\n",
      "        [-16.8330,  17.9510, -13.0998],\n",
      "        [-17.2710,  18.5870, -12.8211],\n",
      "        [-16.8488,  18.1015, -13.0635],\n",
      "        [-16.8169,  18.2559, -12.9769],\n",
      "        [-17.0044,  18.4866, -13.4205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2817,  13.6431,  14.7997, -17.1320,  18.6670, -13.0735],\n",
      "        [ 18.4341,  12.6611,  14.4328, -16.8330,  17.9510, -13.0998],\n",
      "        [ 18.9888,  13.4655,  14.9791, -17.2710,  18.5870, -12.8211],\n",
      "        [ 18.5882,  13.1295,  13.7517, -16.8488,  18.1015, -13.0635],\n",
      "        [ 18.7990,  12.9589,  14.8414, -16.8169,  18.2559, -12.9769],\n",
      "        [ 18.9521,  13.3196,  14.8014, -17.0044,  18.4866, -13.4205]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.742875576019287\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7622, 13.1087, 14.3612],\n",
      "        [19.0787, 12.8789, 14.3962],\n",
      "        [19.3866, 13.5050, 14.8754],\n",
      "        [19.3439, 13.2870, 14.8764],\n",
      "        [18.4256, 13.0009, 14.3500],\n",
      "        [19.4647, 13.3910, 14.6245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2628, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8161,  18.7377, -13.4219],\n",
      "        [-16.8672,  18.1705, -12.8007],\n",
      "        [-16.5260,  18.4295, -12.6932],\n",
      "        [-16.7553,  17.8867, -12.8945],\n",
      "        [-16.6044,  18.3171, -13.2374],\n",
      "        [-16.6000,  17.8595, -12.5668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7622,  13.1087,  14.3612, -16.8161,  18.7377, -13.4219],\n",
      "        [ 19.0787,  12.8789,  14.3962, -16.8672,  18.1705, -12.8007],\n",
      "        [ 19.3866,  13.5050,  14.8754, -16.5260,  18.4295, -12.6932],\n",
      "        [ 19.3439,  13.2870,  14.8764, -16.7553,  17.8867, -12.8945],\n",
      "        [ 18.4256,  13.0009,  14.3500, -16.6044,  18.3171, -13.2374],\n",
      "        [ 19.4647,  13.3910,  14.6245, -16.6000,  17.8595, -12.5668]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.694517135620117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1746, 13.3418, 14.8699],\n",
      "        [18.5565, 13.0673, 14.2485],\n",
      "        [19.2917, 13.5804, 14.5978],\n",
      "        [18.7980, 13.0096, 14.8650],\n",
      "        [18.9903, 13.2264, 14.3935],\n",
      "        [18.4975, 12.8880, 14.5270]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.6303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0023,  18.5389, -13.3055],\n",
      "        [-16.8110,  18.2206, -12.8715],\n",
      "        [-17.0316,  18.0701, -13.3063],\n",
      "        [-16.9014,  18.1645, -13.1544],\n",
      "        [-17.0305,  18.6180, -13.0757],\n",
      "        [-17.4895,  18.7224, -13.5864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1746,  13.3418,  14.8699, -17.0023,  18.5389, -13.3055],\n",
      "        [ 18.5565,  13.0673,  14.2485, -16.8110,  18.2206, -12.8715],\n",
      "        [ 19.2917,  13.5804,  14.5978, -17.0316,  18.0701, -13.3063],\n",
      "        [ 18.7980,  13.0096,  14.8650, -16.9014,  18.1645, -13.1544],\n",
      "        [ 18.9903,  13.2264,  14.3935, -17.0305,  18.6180, -13.0757],\n",
      "        [ 18.4975,  12.8880,  14.5270, -17.4895,  18.7224, -13.5864]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.733766794204712\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7341, 12.9999, 14.5883],\n",
      "        [18.5381, 12.9605, 14.6226],\n",
      "        [18.7154, 13.2456, 14.7755],\n",
      "        [19.1729, 13.4113, 14.8026],\n",
      "        [18.6033, 13.0407, 14.4413],\n",
      "        [19.1108, 13.2459, 15.1281]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8850,  18.0213, -13.1125],\n",
      "        [-16.9432,  18.0754, -12.9596],\n",
      "        [-17.1076,  18.7084, -13.0401],\n",
      "        [-17.0235,  18.2062, -12.8461],\n",
      "        [-17.0207,  18.3597, -13.2098],\n",
      "        [-16.6894,  18.4617, -12.7596]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7341,  12.9999,  14.5883, -16.8850,  18.0213, -13.1125],\n",
      "        [ 18.5381,  12.9605,  14.6226, -16.9432,  18.0754, -12.9596],\n",
      "        [ 18.7154,  13.2456,  14.7755, -17.1076,  18.7084, -13.0401],\n",
      "        [ 19.1729,  13.4113,  14.8026, -17.0235,  18.2062, -12.8461],\n",
      "        [ 18.6033,  13.0407,  14.4413, -17.0207,  18.3597, -13.2098],\n",
      "        [ 19.1108,  13.2459,  15.1281, -16.6894,  18.4617, -12.7596]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.679297924041748\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6042, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.6636, 13.3471, 14.0300],\n",
      "        [18.9678, 12.9099, 14.2291],\n",
      "        [19.1797, 13.4892, 14.5567],\n",
      "        [18.9142, 13.2442, 14.8346],\n",
      "        [18.8335, 13.3658, 15.0835],\n",
      "        [18.8965, 13.1372, 14.7772]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.2448, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9299,  18.5076, -13.3683],\n",
      "        [-16.8428,  18.1713, -12.9446],\n",
      "        [-16.5058,  18.3318, -13.1092],\n",
      "        [-16.9255,  18.2318, -13.3538],\n",
      "        [-16.6177,  18.0598, -12.9945],\n",
      "        [-17.1046,  18.6774, -13.0759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.6636,  13.3471,  14.0300, -16.9299,  18.5076, -13.3683],\n",
      "        [ 18.9678,  12.9099,  14.2291, -16.8428,  18.1713, -12.9446],\n",
      "        [ 19.1797,  13.4892,  14.5567, -16.5058,  18.3318, -13.1092],\n",
      "        [ 18.9142,  13.2442,  14.8346, -16.9255,  18.2318, -13.3538],\n",
      "        [ 18.8335,  13.3658,  15.0835, -16.6177,  18.0598, -12.9945],\n",
      "        [ 18.8965,  13.1372,  14.7772, -17.1046,  18.6774, -13.0759]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.684133768081665\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5994, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1351, 13.2602, 14.5263],\n",
      "        [18.9087, 13.3580, 14.8233],\n",
      "        [18.8255, 13.7541, 14.8625],\n",
      "        [18.5276, 12.9916, 14.5389],\n",
      "        [19.0129, 13.3424, 14.8621],\n",
      "        [18.8393, 13.1934, 14.8216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9835,  18.1996, -13.3953],\n",
      "        [-16.6803,  18.0395, -12.9860],\n",
      "        [-17.0170,  17.9186, -12.9710],\n",
      "        [-17.0068,  18.4563, -13.2959],\n",
      "        [-17.3372,  18.5194, -13.2284],\n",
      "        [-17.0665,  18.4643, -13.4454]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1351,  13.2602,  14.5263, -16.9835,  18.1996, -13.3953],\n",
      "        [ 18.9087,  13.3580,  14.8233, -16.6803,  18.0395, -12.9860],\n",
      "        [ 18.8255,  13.7541,  14.8625, -17.0170,  17.9186, -12.9710],\n",
      "        [ 18.5276,  12.9916,  14.5389, -17.0068,  18.4563, -13.2959],\n",
      "        [ 19.0129,  13.3424,  14.8621, -17.3372,  18.5194, -13.2284],\n",
      "        [ 18.8393,  13.1934,  14.8216, -17.0665,  18.4643, -13.4454]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7146201133728027\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5731, 13.1980, 14.3621],\n",
      "        [18.7736, 13.2460, 14.0742],\n",
      "        [19.1857, 13.1804, 14.4753],\n",
      "        [18.3735, 13.0645, 14.2864],\n",
      "        [18.8229, 13.2670, 14.6745],\n",
      "        [18.9249, 13.3163, 14.8485]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9465, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0777,  18.5803, -13.0559],\n",
      "        [-17.3172,  18.4150, -13.1733],\n",
      "        [-17.2251,  18.3228, -13.1601],\n",
      "        [-16.5083,  18.6510, -12.9444],\n",
      "        [-17.4573,  18.6592, -13.3606],\n",
      "        [-16.9134,  17.8962, -12.3929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5731,  13.1980,  14.3621, -17.0777,  18.5803, -13.0559],\n",
      "        [ 18.7736,  13.2460,  14.0742, -17.3172,  18.4150, -13.1733],\n",
      "        [ 19.1857,  13.1804,  14.4753, -17.2251,  18.3228, -13.1601],\n",
      "        [ 18.3735,  13.0645,  14.2864, -16.5083,  18.6510, -12.9444],\n",
      "        [ 18.8229,  13.2670,  14.6745, -17.4573,  18.6592, -13.3606],\n",
      "        [ 18.9249,  13.3163,  14.8485, -16.9134,  17.8962, -12.3929]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.6907541751861572\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0722, 13.4649, 14.8194],\n",
      "        [18.5413, 13.2578, 14.6454],\n",
      "        [19.4179, 13.1052, 15.0400],\n",
      "        [19.1938, 13.2556, 14.7762],\n",
      "        [19.0480, 13.5748, 14.6730],\n",
      "        [18.7184, 13.2749, 14.6777]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0256, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5311,  18.9576, -13.4008],\n",
      "        [-16.9518,  18.3223, -12.9474],\n",
      "        [-16.6670,  18.2065, -12.9724],\n",
      "        [-16.9700,  18.4729, -13.2967],\n",
      "        [-16.8880,  17.9307, -12.8250],\n",
      "        [-16.9894,  18.1703, -13.0055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0722,  13.4649,  14.8194, -17.5311,  18.9576, -13.4008],\n",
      "        [ 18.5413,  13.2578,  14.6454, -16.9518,  18.3223, -12.9474],\n",
      "        [ 19.4179,  13.1052,  15.0400, -16.6670,  18.2065, -12.9724],\n",
      "        [ 19.1938,  13.2556,  14.7762, -16.9700,  18.4729, -13.2967],\n",
      "        [ 19.0480,  13.5748,  14.6730, -16.8880,  17.9307, -12.8250],\n",
      "        [ 18.7184,  13.2749,  14.6777, -16.9894,  18.1703, -13.0055]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7614123821258545\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8969, 13.4972, 14.9929],\n",
      "        [19.3026, 13.4823, 14.7797],\n",
      "        [19.0823, 13.6742, 14.7563],\n",
      "        [19.2391, 13.8422, 14.8704],\n",
      "        [19.1481, 13.7287, 14.4125],\n",
      "        [19.0964, 13.4669, 15.0182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1704, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7115,  18.0903, -12.8100],\n",
      "        [-16.8639,  18.6948, -13.2137],\n",
      "        [-17.1973,  18.5792, -13.3336],\n",
      "        [-16.3364,  18.3577, -12.7481],\n",
      "        [-16.9788,  18.4509, -13.1416],\n",
      "        [-17.1556,  18.1625, -12.7643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8969,  13.4972,  14.9929, -16.7115,  18.0903, -12.8100],\n",
      "        [ 19.3026,  13.4823,  14.7797, -16.8639,  18.6948, -13.2137],\n",
      "        [ 19.0823,  13.6742,  14.7563, -17.1973,  18.5792, -13.3336],\n",
      "        [ 19.2391,  13.8422,  14.8704, -16.3364,  18.3577, -12.7481],\n",
      "        [ 19.1481,  13.7287,  14.4125, -16.9788,  18.4509, -13.1416],\n",
      "        [ 19.0964,  13.4669,  15.0182, -17.1556,  18.1625, -12.7643]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7107837200164795\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3623, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2810, 13.1587, 14.6610],\n",
      "        [18.5066, 13.3808, 14.7819],\n",
      "        [19.1274, 13.5899, 15.2245],\n",
      "        [19.3320, 13.5504, 14.5985],\n",
      "        [18.6592, 13.2166, 14.4948],\n",
      "        [19.3241, 13.5238, 14.9877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.6342,  18.3138, -13.3321],\n",
      "        [-17.0074,  18.5952, -13.1245],\n",
      "        [-16.7196,  17.8434, -12.7169],\n",
      "        [-16.8420,  18.4768, -13.5835],\n",
      "        [-17.4427,  18.4295, -13.3892],\n",
      "        [-17.3964,  18.7121, -13.0908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2810,  13.1587,  14.6610, -16.6342,  18.3138, -13.3321],\n",
      "        [ 18.5066,  13.3808,  14.7819, -17.0074,  18.5952, -13.1245],\n",
      "        [ 19.1274,  13.5899,  15.2245, -16.7196,  17.8434, -12.7169],\n",
      "        [ 19.3320,  13.5504,  14.5985, -16.8420,  18.4768, -13.5835],\n",
      "        [ 18.6592,  13.2166,  14.4948, -17.4427,  18.4295, -13.3892],\n",
      "        [ 19.3241,  13.5238,  14.9877, -17.3964,  18.7121, -13.0908]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7220211029052734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5816, 13.7773, 14.8918],\n",
      "        [19.0018, 13.2494, 14.8168],\n",
      "        [18.7489, 13.6421, 14.9260],\n",
      "        [19.0461, 13.4863, 14.7166],\n",
      "        [18.9188, 13.4796, 14.4213],\n",
      "        [19.0599, 13.4505, 14.6694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.1740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2347,  18.7945, -13.1064],\n",
      "        [-17.0084,  18.2913, -13.0630],\n",
      "        [-16.9967,  18.7409, -13.3203],\n",
      "        [-16.8965,  18.8265, -13.3939],\n",
      "        [-17.0589,  18.1855, -12.9051],\n",
      "        [-17.3427,  18.4988, -13.4868]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5816,  13.7773,  14.8918, -17.2347,  18.7945, -13.1064],\n",
      "        [ 19.0018,  13.2494,  14.8168, -17.0084,  18.2913, -13.0630],\n",
      "        [ 18.7489,  13.6421,  14.9260, -16.9967,  18.7409, -13.3203],\n",
      "        [ 19.0461,  13.4863,  14.7166, -16.8965,  18.8265, -13.3939],\n",
      "        [ 18.9188,  13.4796,  14.4213, -17.0589,  18.1855, -12.9051],\n",
      "        [ 19.0599,  13.4505,  14.6694, -17.3427,  18.4988, -13.4868]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.781203508377075\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4316, 13.4356, 14.9367],\n",
      "        [19.1875, 13.3474, 14.7849],\n",
      "        [19.3525, 13.4868, 14.6910],\n",
      "        [18.8071, 13.5100, 14.7316],\n",
      "        [19.0983, 13.4636, 14.4173],\n",
      "        [19.3441, 13.5565, 14.9951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.4241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3609,  18.6154, -13.3292],\n",
      "        [-17.2413,  18.4077, -13.6469],\n",
      "        [-16.9203,  18.4986, -13.4962],\n",
      "        [-16.8989,  18.0156, -12.9534],\n",
      "        [-16.5540,  18.4396, -13.1660],\n",
      "        [-16.9895,  18.6026, -13.1978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4316,  13.4356,  14.9367, -17.3609,  18.6154, -13.3292],\n",
      "        [ 19.1875,  13.3474,  14.7849, -17.2413,  18.4077, -13.6469],\n",
      "        [ 19.3525,  13.4868,  14.6910, -16.9203,  18.4986, -13.4962],\n",
      "        [ 18.8071,  13.5100,  14.7316, -16.8989,  18.0156, -12.9534],\n",
      "        [ 19.0983,  13.4636,  14.4173, -16.5540,  18.4396, -13.1660],\n",
      "        [ 19.3441,  13.5565,  14.9951, -16.9895,  18.6026, -13.1978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.771608352661133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.0315, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2835, 13.5480, 15.0105],\n",
      "        [19.3177, 13.7471, 14.6701],\n",
      "        [19.0562, 12.9683, 14.8919],\n",
      "        [19.1136, 13.5692, 14.9698],\n",
      "        [18.8799, 13.4416, 14.4605],\n",
      "        [19.0635, 13.3758, 14.7823]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.6366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2506,  18.5995, -13.3514],\n",
      "        [-16.9639,  18.2836, -12.6119],\n",
      "        [-17.1551,  18.6926, -13.3251],\n",
      "        [-17.1282,  18.2325, -12.7690],\n",
      "        [-16.7807,  17.9617, -12.9670],\n",
      "        [-17.1329,  17.9905, -13.0712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2835,  13.5480,  15.0105, -17.2506,  18.5995, -13.3514],\n",
      "        [ 19.3177,  13.7471,  14.6701, -16.9639,  18.2836, -12.6119],\n",
      "        [ 19.0562,  12.9683,  14.8919, -17.1551,  18.6926, -13.3251],\n",
      "        [ 19.1136,  13.5692,  14.9698, -17.1282,  18.2325, -12.7690],\n",
      "        [ 18.8799,  13.4416,  14.4605, -16.7807,  17.9617, -12.9670],\n",
      "        [ 19.0635,  13.3758,  14.7823, -17.1329,  17.9905, -13.0712]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.7690176963806152\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7330, 13.3678, 14.5792],\n",
      "        [19.0453, 13.7391, 15.1024],\n",
      "        [19.2385, 13.6269, 14.9526],\n",
      "        [19.1116, 13.5248, 15.0651],\n",
      "        [19.2388, 13.3155, 14.5403],\n",
      "        [18.7751, 13.1660, 14.7493]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8065, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7107,  18.1445, -13.2773],\n",
      "        [-17.7061,  18.4855, -13.4311],\n",
      "        [-17.3253,  18.9812, -13.3192],\n",
      "        [-17.2020,  18.5612, -13.3226],\n",
      "        [-17.1893,  18.8506, -13.3740],\n",
      "        [-17.1025,  18.5804, -13.2417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7330,  13.3678,  14.5792, -16.7107,  18.1445, -13.2773],\n",
      "        [ 19.0453,  13.7391,  15.1024, -17.7061,  18.4855, -13.4311],\n",
      "        [ 19.2385,  13.6269,  14.9526, -17.3253,  18.9812, -13.3192],\n",
      "        [ 19.1116,  13.5248,  15.0651, -17.2020,  18.5612, -13.3226],\n",
      "        [ 19.2388,  13.3155,  14.5403, -17.1893,  18.8506, -13.3740],\n",
      "        [ 18.7751,  13.1660,  14.7493, -17.1025,  18.5804, -13.2417]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.701897382736206\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.5290, 13.4118, 14.9060],\n",
      "        [18.8417, 13.1123, 14.9648],\n",
      "        [18.9259, 13.5279, 14.9173],\n",
      "        [19.2711, 13.3907, 14.8314],\n",
      "        [18.9261, 13.4392, 14.3802],\n",
      "        [18.9494, 13.4311, 15.1735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7305,  18.7066, -13.5655],\n",
      "        [-17.3499,  18.3577, -13.3761],\n",
      "        [-17.2605,  18.4347, -13.3991],\n",
      "        [-16.7843,  17.9499, -13.1026],\n",
      "        [-17.3672,  18.6752, -13.5214],\n",
      "        [-16.8431,  18.3396, -13.3436]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.5290,  13.4118,  14.9060, -16.7305,  18.7066, -13.5655],\n",
      "        [ 18.8417,  13.1123,  14.9648, -17.3499,  18.3577, -13.3761],\n",
      "        [ 18.9259,  13.5279,  14.9173, -17.2605,  18.4347, -13.3991],\n",
      "        [ 19.2711,  13.3907,  14.8314, -16.7843,  17.9499, -13.1026],\n",
      "        [ 18.9261,  13.4392,  14.3802, -17.3672,  18.6752, -13.5214],\n",
      "        [ 18.9494,  13.4311,  15.1735, -16.8431,  18.3396, -13.3436]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7262206077575684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7219, 13.0047, 14.5749],\n",
      "        [18.9850, 13.3504, 14.8880],\n",
      "        [19.3720, 13.0153, 14.7562],\n",
      "        [19.1988, 13.2297, 14.7346],\n",
      "        [19.1793, 13.3772, 14.3780],\n",
      "        [19.4953, 13.6168, 14.7769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.7939,  18.0154, -12.9767],\n",
      "        [-17.0975,  18.6642, -13.4795],\n",
      "        [-17.0323,  18.1124, -13.3005],\n",
      "        [-17.3561,  18.6571, -13.4365],\n",
      "        [-17.2644,  18.9989, -13.8317],\n",
      "        [-17.1581,  18.6611, -13.4010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7219,  13.0047,  14.5749, -16.7939,  18.0154, -12.9767],\n",
      "        [ 18.9850,  13.3504,  14.8880, -17.0975,  18.6642, -13.4795],\n",
      "        [ 19.3720,  13.0153,  14.7562, -17.0323,  18.1124, -13.3005],\n",
      "        [ 19.1988,  13.2297,  14.7346, -17.3561,  18.6571, -13.4365],\n",
      "        [ 19.1793,  13.3772,  14.3780, -17.2644,  18.9989, -13.8317],\n",
      "        [ 19.4953,  13.6168,  14.7769, -17.1581,  18.6611, -13.4010]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.68892240524292\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4057, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3668, 13.9898, 15.1216],\n",
      "        [19.1641, 13.4751, 14.8431],\n",
      "        [18.9968, 13.6895, 14.8253],\n",
      "        [18.8944, 13.3392, 14.6183],\n",
      "        [19.3131, 13.5797, 15.0903],\n",
      "        [19.3050, 13.5196, 14.8175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4385, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5614,  18.9455, -13.2614],\n",
      "        [-17.2832,  18.3969, -13.2031],\n",
      "        [-17.2972,  18.6344, -13.2420],\n",
      "        [-17.5274,  18.9662, -13.3596],\n",
      "        [-16.5491,  18.2869, -13.4123],\n",
      "        [-17.5214,  18.6183, -13.4341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3668,  13.9898,  15.1216, -17.5614,  18.9455, -13.2614],\n",
      "        [ 19.1641,  13.4751,  14.8431, -17.2832,  18.3969, -13.2031],\n",
      "        [ 18.9968,  13.6895,  14.8253, -17.2972,  18.6344, -13.2420],\n",
      "        [ 18.8944,  13.3392,  14.6183, -17.5274,  18.9662, -13.3596],\n",
      "        [ 19.3131,  13.5797,  15.0903, -16.5491,  18.2869, -13.4123],\n",
      "        [ 19.3050,  13.5196,  14.8175, -17.5214,  18.6183, -13.4341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.806584358215332\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2192, 13.4027, 14.5812],\n",
      "        [19.0955, 13.2308, 14.5430],\n",
      "        [19.0597, 13.0604, 14.7382],\n",
      "        [19.1383, 13.3773, 14.8694],\n",
      "        [19.0266, 13.4859, 15.0313],\n",
      "        [19.6275, 13.9088, 15.0717]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.7733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5195,  18.8873, -13.2246],\n",
      "        [-17.6138,  19.0470, -13.1519],\n",
      "        [-16.9509,  18.6320, -13.1635],\n",
      "        [-17.1895,  18.3770, -13.1806],\n",
      "        [-17.6387,  18.7298, -13.7681],\n",
      "        [-17.3564,  19.0302, -13.7740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2192,  13.4027,  14.5812, -17.5195,  18.8873, -13.2246],\n",
      "        [ 19.0955,  13.2308,  14.5430, -17.6138,  19.0470, -13.1519],\n",
      "        [ 19.0597,  13.0604,  14.7382, -16.9509,  18.6320, -13.1635],\n",
      "        [ 19.1383,  13.3773,  14.8694, -17.1895,  18.3770, -13.1806],\n",
      "        [ 19.0266,  13.4859,  15.0313, -17.6387,  18.7298, -13.7681],\n",
      "        [ 19.6275,  13.9088,  15.0717, -17.3564,  19.0302, -13.7740]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.766061544418335\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5034, 13.7971, 14.7773],\n",
      "        [18.9984, 13.4871, 14.8731],\n",
      "        [19.2727, 13.5867, 14.7188],\n",
      "        [19.4066, 13.8108, 15.2713],\n",
      "        [18.7538, 13.3732, 14.4800],\n",
      "        [19.0475, 13.5166, 14.8605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2065,  18.5534, -13.1972],\n",
      "        [-16.9758,  18.3829, -13.2788],\n",
      "        [-16.8245,  18.0728, -13.0111],\n",
      "        [-17.3622,  18.3596, -13.2956],\n",
      "        [-17.2242,  18.7389, -13.4761],\n",
      "        [-16.6178,  18.2778, -13.0138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5034,  13.7971,  14.7773, -17.2065,  18.5534, -13.1972],\n",
      "        [ 18.9984,  13.4871,  14.8731, -16.9758,  18.3829, -13.2788],\n",
      "        [ 19.2727,  13.5867,  14.7188, -16.8245,  18.0728, -13.0111],\n",
      "        [ 19.4066,  13.8108,  15.2713, -17.3622,  18.3596, -13.2956],\n",
      "        [ 18.7538,  13.3732,  14.4800, -17.2242,  18.7389, -13.4761],\n",
      "        [ 19.0475,  13.5166,  14.8605, -16.6178,  18.2778, -13.0138]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.779337167739868\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6917, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3691, 13.6782, 15.1824],\n",
      "        [18.7950, 13.6313, 15.0029],\n",
      "        [18.7052, 13.2428, 14.2403],\n",
      "        [18.8243, 13.3054, 14.6074],\n",
      "        [19.1328, 13.8253, 14.8575],\n",
      "        [19.2691, 13.5245, 15.0353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0736,  18.2507, -12.8407],\n",
      "        [-17.4353,  18.7696, -13.1982],\n",
      "        [-16.8260,  18.4735, -13.0266],\n",
      "        [-17.2577,  18.8741, -13.4725],\n",
      "        [-17.1867,  18.1365, -13.7350],\n",
      "        [-17.3996,  18.2784, -13.4783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3691,  13.6782,  15.1824, -17.0736,  18.2507, -12.8407],\n",
      "        [ 18.7950,  13.6313,  15.0029, -17.4353,  18.7696, -13.1982],\n",
      "        [ 18.7052,  13.2428,  14.2403, -16.8260,  18.4735, -13.0266],\n",
      "        [ 18.8243,  13.3054,  14.6074, -17.2577,  18.8741, -13.4725],\n",
      "        [ 19.1328,  13.8253,  14.8575, -17.1867,  18.1365, -13.7350],\n",
      "        [ 19.2691,  13.5245,  15.0353, -17.3996,  18.2784, -13.4783]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.769087791442871\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4213, 13.6382, 15.1680],\n",
      "        [19.3192, 13.4966, 14.9765],\n",
      "        [18.8914, 13.2157, 14.8732],\n",
      "        [18.8332, 13.9314, 15.0013],\n",
      "        [18.7888, 13.4648, 14.9914],\n",
      "        [19.2017, 13.6708, 15.0176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0345, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1098,  18.9207, -13.5398],\n",
      "        [-17.2979,  18.1565, -13.0801],\n",
      "        [-16.9424,  18.0684, -13.3017],\n",
      "        [-17.0854,  18.1178, -13.0865],\n",
      "        [-16.9692,  18.5014, -12.9412],\n",
      "        [-17.0806,  18.1844, -13.4527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4213,  13.6382,  15.1680, -17.1098,  18.9207, -13.5398],\n",
      "        [ 19.3192,  13.4966,  14.9765, -17.2979,  18.1565, -13.0801],\n",
      "        [ 18.8914,  13.2157,  14.8732, -16.9424,  18.0684, -13.3017],\n",
      "        [ 18.8332,  13.9314,  15.0013, -17.0854,  18.1178, -13.0865],\n",
      "        [ 18.7888,  13.4648,  14.9914, -16.9692,  18.5014, -12.9412],\n",
      "        [ 19.2017,  13.6708,  15.0176, -17.0806,  18.1844, -13.4527]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8009891510009766\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1962, 13.5344, 14.8793],\n",
      "        [18.9702, 13.4278, 14.7180],\n",
      "        [19.4612, 13.4261, 14.8063],\n",
      "        [19.5623, 13.7613, 15.4121],\n",
      "        [19.4191, 13.2510, 14.7519],\n",
      "        [19.1101, 13.6682, 14.9206]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(5.9774, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0725,  17.6504, -13.1338],\n",
      "        [-17.3198,  18.7786, -13.4589],\n",
      "        [-17.4005,  18.8187, -13.5934],\n",
      "        [-17.1238,  18.6072, -13.1324],\n",
      "        [-17.1845,  18.6642, -13.1873],\n",
      "        [-17.2329,  18.6315, -13.2436]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1962,  13.5344,  14.8793, -17.0725,  17.6504, -13.1338],\n",
      "        [ 18.9702,  13.4278,  14.7180, -17.3198,  18.7786, -13.4589],\n",
      "        [ 19.4612,  13.4261,  14.8063, -17.4005,  18.8187, -13.5934],\n",
      "        [ 19.5623,  13.7613,  15.4121, -17.1238,  18.6072, -13.1324],\n",
      "        [ 19.4191,  13.2510,  14.7519, -17.1845,  18.6642, -13.1873],\n",
      "        [ 19.1101,  13.6682,  14.9206, -17.2329,  18.6315, -13.2436]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.739751100540161\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9620, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2966, 13.3968, 14.8838],\n",
      "        [18.9479, 12.8081, 14.5945],\n",
      "        [18.8832, 13.9625, 14.8691],\n",
      "        [19.4637, 13.6317, 14.8538],\n",
      "        [18.7656, 13.2525, 15.1834],\n",
      "        [18.9988, 13.3838, 14.8112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9469, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1320,  18.6078, -13.1197],\n",
      "        [-17.0096,  18.3494, -13.3706],\n",
      "        [-17.0900,  17.9490, -12.9551],\n",
      "        [-16.6539,  18.2724, -12.7376],\n",
      "        [-17.2818,  18.7456, -13.5021],\n",
      "        [-16.9824,  18.1657, -13.4712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2966,  13.3968,  14.8838, -17.1320,  18.6078, -13.1197],\n",
      "        [ 18.9479,  12.8081,  14.5945, -17.0096,  18.3494, -13.3706],\n",
      "        [ 18.8832,  13.9625,  14.8691, -17.0900,  17.9490, -12.9551],\n",
      "        [ 19.4637,  13.6317,  14.8538, -16.6539,  18.2724, -12.7376],\n",
      "        [ 18.7656,  13.2525,  15.1834, -17.2818,  18.7456, -13.5021],\n",
      "        [ 18.9988,  13.3838,  14.8112, -16.9824,  18.1657, -13.4712]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.768123149871826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7890, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0508, 13.9630, 14.6130],\n",
      "        [18.8261, 12.9751, 14.3710],\n",
      "        [18.8814, 13.1796, 14.3345],\n",
      "        [19.2706, 13.6589, 15.0170],\n",
      "        [19.0688, 13.7853, 14.8693],\n",
      "        [19.4813, 14.0806, 14.8452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3580, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4448,  19.2413, -13.7047],\n",
      "        [-17.1362,  18.5073, -13.3480],\n",
      "        [-16.8803,  18.6528, -13.4761],\n",
      "        [-16.9798,  18.7258, -13.5067],\n",
      "        [-17.1429,  18.8469, -13.3706],\n",
      "        [-17.5292,  18.6089, -13.2197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0508,  13.9630,  14.6130, -17.4448,  19.2413, -13.7047],\n",
      "        [ 18.8261,  12.9751,  14.3710, -17.1362,  18.5073, -13.3480],\n",
      "        [ 18.8814,  13.1796,  14.3345, -16.8803,  18.6528, -13.4761],\n",
      "        [ 19.2706,  13.6589,  15.0170, -16.9798,  18.7258, -13.5067],\n",
      "        [ 19.0688,  13.7853,  14.8693, -17.1429,  18.8469, -13.3706],\n",
      "        [ 19.4813,  14.0806,  14.8452, -17.5292,  18.6089, -13.2197]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.796135187149048\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0606, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.7617, 13.2909, 14.7872],\n",
      "        [19.3587, 13.2347, 14.8884],\n",
      "        [18.9089, 13.4964, 14.7726],\n",
      "        [18.8905, 13.0297, 14.8951],\n",
      "        [18.8733, 13.2440, 14.8625],\n",
      "        [19.0181, 13.4579, 14.8502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2861, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1508,  18.7161, -13.4488],\n",
      "        [-17.1386,  18.4160, -13.3933],\n",
      "        [-16.8367,  18.5796, -12.9986],\n",
      "        [-17.6141,  18.6808, -13.5646],\n",
      "        [-17.1007,  18.7399, -13.8460],\n",
      "        [-17.3456,  18.6728, -13.9912]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.7617,  13.2909,  14.7872, -17.1508,  18.7161, -13.4488],\n",
      "        [ 19.3587,  13.2347,  14.8884, -17.1386,  18.4160, -13.3933],\n",
      "        [ 18.9089,  13.4964,  14.7726, -16.8367,  18.5796, -12.9986],\n",
      "        [ 18.8905,  13.0297,  14.8951, -17.6141,  18.6808, -13.5646],\n",
      "        [ 18.8733,  13.2440,  14.8625, -17.1007,  18.7399, -13.8460],\n",
      "        [ 19.0181,  13.4579,  14.8502, -17.3456,  18.6728, -13.9912]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.7503199577331543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6743, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3009, 13.6110, 14.8808],\n",
      "        [18.9310, 13.7729, 15.1557],\n",
      "        [18.7829, 13.6061, 14.8117],\n",
      "        [19.0556, 13.5273, 14.7705],\n",
      "        [18.7782, 13.7271, 15.0167],\n",
      "        [19.4129, 13.1219, 14.9907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6184, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3200,  18.4955, -13.2588],\n",
      "        [-17.3210,  18.6919, -12.9387],\n",
      "        [-17.5356,  18.8871, -13.6926],\n",
      "        [-17.3110,  18.7427, -13.3974],\n",
      "        [-17.2367,  18.4191, -13.3687],\n",
      "        [-17.0943,  18.4932, -13.5487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3009,  13.6110,  14.8808, -17.3200,  18.4955, -13.2588],\n",
      "        [ 18.9310,  13.7729,  15.1557, -17.3210,  18.6919, -12.9387],\n",
      "        [ 18.7829,  13.6061,  14.8117, -17.5356,  18.8871, -13.6926],\n",
      "        [ 19.0556,  13.5273,  14.7705, -17.3110,  18.7427, -13.3974],\n",
      "        [ 18.7782,  13.7271,  15.0167, -17.2367,  18.4191, -13.3687],\n",
      "        [ 19.4129,  13.1219,  14.9907, -17.0943,  18.4932, -13.5487]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7809486389160156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5560, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6893, 13.7308, 14.9169],\n",
      "        [18.9001, 13.6306, 15.0325],\n",
      "        [18.7786, 13.1601, 14.7670],\n",
      "        [18.8078, 13.2379, 14.4087],\n",
      "        [19.0005, 13.8235, 15.2595],\n",
      "        [19.4091, 13.6996, 14.8576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3604, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4750,  18.6736, -13.6052],\n",
      "        [-17.2054,  18.4450, -13.4329],\n",
      "        [-17.3111,  18.7134, -13.5861],\n",
      "        [-17.1745,  18.9613, -13.7252],\n",
      "        [-16.9992,  18.5035, -13.2953],\n",
      "        [-17.1344,  18.4201, -13.2644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6893,  13.7308,  14.9169, -17.4750,  18.6736, -13.6052],\n",
      "        [ 18.9001,  13.6306,  15.0325, -17.2054,  18.4450, -13.4329],\n",
      "        [ 18.7786,  13.1601,  14.7670, -17.3111,  18.7134, -13.5861],\n",
      "        [ 18.8078,  13.2379,  14.4087, -17.1745,  18.9613, -13.7252],\n",
      "        [ 19.0005,  13.8235,  15.2595, -16.9992,  18.5035, -13.2953],\n",
      "        [ 19.4091,  13.6996,  14.8576, -17.1344,  18.4201, -13.2644]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.817295551300049\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9457, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3238, 13.5680, 15.1259],\n",
      "        [19.3909, 13.5593, 14.9996],\n",
      "        [18.8212, 13.4977, 14.8403],\n",
      "        [19.0104, 13.4333, 14.5849],\n",
      "        [19.3144, 13.2822, 14.2845],\n",
      "        [19.2815, 13.5946, 14.9335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.7280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3498,  18.5492, -13.1092],\n",
      "        [-17.0840,  18.4851, -13.2694],\n",
      "        [-17.3143,  18.4954, -13.1614],\n",
      "        [-17.3805,  18.6556, -13.4880],\n",
      "        [-17.3242,  18.6892, -13.6714],\n",
      "        [-17.4168,  18.8753, -13.8180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3238,  13.5680,  15.1259, -17.3498,  18.5492, -13.1092],\n",
      "        [ 19.3909,  13.5593,  14.9996, -17.0840,  18.4851, -13.2694],\n",
      "        [ 18.8212,  13.4977,  14.8403, -17.3143,  18.4954, -13.1614],\n",
      "        [ 19.0104,  13.4333,  14.5849, -17.3805,  18.6556, -13.4880],\n",
      "        [ 19.3144,  13.2822,  14.2845, -17.3242,  18.6892, -13.6714],\n",
      "        [ 19.2815,  13.5946,  14.9335, -17.4168,  18.8753, -13.8180]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.791537046432495\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5279, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9757, 13.2093, 14.8660],\n",
      "        [19.0592, 13.2568, 14.9440],\n",
      "        [19.0995, 13.5551, 15.0864],\n",
      "        [18.9839, 13.6324, 14.7013],\n",
      "        [19.2748, 13.7012, 15.0238],\n",
      "        [18.9527, 13.3871, 14.8171]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.2678, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9439,  18.6908, -13.4301],\n",
      "        [-16.7078,  18.2271, -13.0507],\n",
      "        [-17.4656,  19.3538, -13.8409],\n",
      "        [-17.0733,  18.9694, -13.2386],\n",
      "        [-17.3269,  18.4732, -13.0820],\n",
      "        [-17.2188,  18.1648, -13.0522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9757,  13.2093,  14.8660, -16.9439,  18.6908, -13.4301],\n",
      "        [ 19.0592,  13.2568,  14.9440, -16.7078,  18.2271, -13.0507],\n",
      "        [ 19.0995,  13.5551,  15.0864, -17.4656,  19.3538, -13.8409],\n",
      "        [ 18.9839,  13.6324,  14.7013, -17.0733,  18.9694, -13.2386],\n",
      "        [ 19.2748,  13.7012,  15.0238, -17.3269,  18.4732, -13.0820],\n",
      "        [ 18.9527,  13.3871,  14.8171, -17.2188,  18.1648, -13.0522]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.759737730026245\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9156, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1705, 13.3706, 14.5109],\n",
      "        [19.3657, 13.6941, 15.1036],\n",
      "        [19.8638, 14.1626, 15.2295],\n",
      "        [18.8702, 13.5643, 14.6966],\n",
      "        [19.2855, 13.6870, 14.9664],\n",
      "        [19.3292, 13.5275, 14.8055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9109, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8043,  18.3525, -13.0844],\n",
      "        [-17.6359,  18.5599, -13.8706],\n",
      "        [-17.4654,  19.1906, -13.6738],\n",
      "        [-17.2992,  18.2004, -13.4070],\n",
      "        [-17.3947,  18.3299, -13.1493],\n",
      "        [-16.9077,  18.8247, -13.5779]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1705,  13.3706,  14.5109, -16.8043,  18.3525, -13.0844],\n",
      "        [ 19.3657,  13.6941,  15.1036, -17.6359,  18.5599, -13.8706],\n",
      "        [ 19.8638,  14.1626,  15.2295, -17.4654,  19.1906, -13.6738],\n",
      "        [ 18.8702,  13.5643,  14.6966, -17.2992,  18.2004, -13.4070],\n",
      "        [ 19.2855,  13.6870,  14.9664, -17.3947,  18.3299, -13.1493],\n",
      "        [ 19.3292,  13.5275,  14.8055, -16.9077,  18.8247, -13.5779]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7432007789611816\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4245, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3221, 13.8891, 15.1420],\n",
      "        [19.2732, 13.3432, 14.9995],\n",
      "        [18.6362, 13.5478, 14.3289],\n",
      "        [19.4737, 13.8748, 14.7591],\n",
      "        [19.0486, 13.8528, 15.1612],\n",
      "        [19.0885, 13.7528, 14.9400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2773,  18.5716, -13.6525],\n",
      "        [-17.2648,  19.0595, -13.4061],\n",
      "        [-17.2516,  18.8474, -13.3639],\n",
      "        [-16.9329,  18.2844, -13.3204],\n",
      "        [-17.1449,  18.5496, -13.7113],\n",
      "        [-17.1704,  18.4199, -13.1768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3221,  13.8891,  15.1420, -17.2773,  18.5716, -13.6525],\n",
      "        [ 19.2732,  13.3432,  14.9995, -17.2648,  19.0595, -13.4061],\n",
      "        [ 18.6362,  13.5478,  14.3289, -17.2516,  18.8474, -13.3639],\n",
      "        [ 19.4737,  13.8748,  14.7591, -16.9329,  18.2844, -13.3204],\n",
      "        [ 19.0486,  13.8528,  15.1612, -17.1449,  18.5496, -13.7113],\n",
      "        [ 19.0885,  13.7528,  14.9400, -17.1704,  18.4199, -13.1768]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.811506986618042\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2113, 13.3392, 14.9798],\n",
      "        [19.2404, 13.9527, 15.0753],\n",
      "        [19.2859, 13.5076, 15.3181],\n",
      "        [19.2010, 13.4923, 14.6567],\n",
      "        [19.5174, 13.7417, 15.0752],\n",
      "        [19.0742, 14.0224, 15.2633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0792,  18.9105, -13.5293],\n",
      "        [-17.3041,  18.9781, -13.7054],\n",
      "        [-17.0988,  18.5234, -13.4305],\n",
      "        [-16.9755,  18.6795, -12.9259],\n",
      "        [-17.5715,  18.9492, -13.6123],\n",
      "        [-17.5718,  18.2590, -13.6120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2113,  13.3392,  14.9798, -17.0792,  18.9105, -13.5293],\n",
      "        [ 19.2404,  13.9527,  15.0753, -17.3041,  18.9781, -13.7054],\n",
      "        [ 19.2859,  13.5076,  15.3181, -17.0988,  18.5234, -13.4305],\n",
      "        [ 19.2010,  13.4923,  14.6567, -16.9755,  18.6795, -12.9259],\n",
      "        [ 19.5174,  13.7417,  15.0752, -17.5715,  18.9492, -13.6123],\n",
      "        [ 19.0742,  14.0224,  15.2633, -17.5718,  18.2590, -13.6120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7913992404937744\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4952, 13.8807, 14.8758],\n",
      "        [19.2463, 13.9285, 15.2645],\n",
      "        [19.2168, 13.2523, 14.8195],\n",
      "        [18.3436, 13.1558, 14.3364],\n",
      "        [18.9519, 13.1638, 14.6994],\n",
      "        [18.7573, 13.2368, 14.9998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8874,  18.2568, -13.5411],\n",
      "        [-17.5425,  18.8267, -13.6652],\n",
      "        [-17.6597,  19.0206, -13.6288],\n",
      "        [-17.1278,  18.3303, -13.2640],\n",
      "        [-17.0797,  18.4823, -13.2032],\n",
      "        [-17.2593,  18.3141, -13.6153]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4952,  13.8807,  14.8758, -16.8874,  18.2568, -13.5411],\n",
      "        [ 19.2463,  13.9285,  15.2645, -17.5425,  18.8267, -13.6652],\n",
      "        [ 19.2168,  13.2523,  14.8195, -17.6597,  19.0206, -13.6288],\n",
      "        [ 18.3436,  13.1558,  14.3364, -17.1278,  18.3303, -13.2640],\n",
      "        [ 18.9519,  13.1638,  14.6994, -17.0797,  18.4823, -13.2032],\n",
      "        [ 18.7573,  13.2368,  14.9998, -17.2593,  18.3141, -13.6153]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.793046474456787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2123, 13.6337, 14.7588],\n",
      "        [19.1892, 13.5578, 14.8879],\n",
      "        [19.8564, 13.8855, 15.5802],\n",
      "        [19.3157, 13.6291, 15.0785],\n",
      "        [18.8005, 13.8229, 14.9940],\n",
      "        [19.0331, 13.2005, 14.8564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9239, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3089,  19.0772, -13.8573],\n",
      "        [-17.1036,  18.4980, -13.4246],\n",
      "        [-17.2310,  18.2693, -13.4436],\n",
      "        [-17.3855,  19.0337, -13.8344],\n",
      "        [-16.8911,  18.7329, -13.5213],\n",
      "        [-17.7023,  18.7275, -13.4384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2123,  13.6337,  14.7588, -17.3089,  19.0772, -13.8573],\n",
      "        [ 19.1892,  13.5578,  14.8879, -17.1036,  18.4980, -13.4246],\n",
      "        [ 19.8564,  13.8855,  15.5802, -17.2310,  18.2693, -13.4436],\n",
      "        [ 19.3157,  13.6291,  15.0785, -17.3855,  19.0337, -13.8344],\n",
      "        [ 18.8005,  13.8229,  14.9940, -16.8911,  18.7329, -13.5213],\n",
      "        [ 19.0331,  13.2005,  14.8564, -17.7023,  18.7275, -13.4384]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8086183071136475\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6910, 13.6837, 15.0523],\n",
      "        [19.0660, 13.1634, 14.4508],\n",
      "        [18.2850, 13.3218, 14.4789],\n",
      "        [19.0491, 13.2435, 14.7028],\n",
      "        [19.3090, 13.4238, 15.0189],\n",
      "        [19.8030, 14.0535, 15.4675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(10.8041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0507,  18.3479, -13.7707],\n",
      "        [-17.5424,  18.8469, -13.6083],\n",
      "        [-17.1952,  18.5675, -13.5900],\n",
      "        [-17.2945,  18.8001, -13.5690],\n",
      "        [-17.3457,  18.8962, -13.4643],\n",
      "        [-17.3465,  18.3598, -13.0833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6910,  13.6837,  15.0523, -17.0507,  18.3479, -13.7707],\n",
      "        [ 19.0660,  13.1634,  14.4508, -17.5424,  18.8469, -13.6083],\n",
      "        [ 18.2850,  13.3218,  14.4789, -17.1952,  18.5675, -13.5900],\n",
      "        [ 19.0491,  13.2435,  14.7028, -17.2945,  18.8001, -13.5690],\n",
      "        [ 19.3090,  13.4238,  15.0189, -17.3457,  18.8962, -13.4643],\n",
      "        [ 19.8030,  14.0535,  15.4675, -17.3465,  18.3598, -13.0833]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8157341480255127\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8104, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2909, 13.5282, 14.9358],\n",
      "        [19.5534, 13.6717, 14.9073],\n",
      "        [19.0499, 13.2388, 14.3344],\n",
      "        [18.7679, 13.5748, 14.8627],\n",
      "        [19.3174, 13.7455, 14.9727],\n",
      "        [19.3045, 13.5329, 14.7745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.0271, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8712,  19.2503, -13.8593],\n",
      "        [-17.7257,  18.7473, -13.4882],\n",
      "        [-16.9108,  18.5856, -13.3837],\n",
      "        [-17.4271,  18.7722, -13.6370],\n",
      "        [-17.3051,  18.8542, -13.7111],\n",
      "        [-17.3261,  18.7077, -13.2261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2909,  13.5282,  14.9358, -17.8712,  19.2503, -13.8593],\n",
      "        [ 19.5534,  13.6717,  14.9073, -17.7257,  18.7473, -13.4882],\n",
      "        [ 19.0499,  13.2388,  14.3344, -16.9108,  18.5856, -13.3837],\n",
      "        [ 18.7679,  13.5748,  14.8627, -17.4271,  18.7722, -13.6370],\n",
      "        [ 19.3174,  13.7455,  14.9727, -17.3051,  18.8542, -13.7111],\n",
      "        [ 19.3045,  13.5329,  14.7745, -17.3261,  18.7077, -13.2261]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8360791206359863\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2142, 13.4148, 15.0933],\n",
      "        [19.4012, 13.3690, 14.7468],\n",
      "        [19.4551, 14.0061, 15.0808],\n",
      "        [19.3688, 13.7080, 14.9720],\n",
      "        [19.2935, 13.3904, 15.0902],\n",
      "        [19.2875, 13.5400, 14.7578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4838,  18.6595, -13.8052],\n",
      "        [-17.0671,  18.0945, -13.5210],\n",
      "        [-17.3410,  18.2799, -13.1519],\n",
      "        [-17.3847,  18.8554, -13.3828],\n",
      "        [-17.3152,  18.9852, -13.4549],\n",
      "        [-17.3465,  18.9136, -13.9129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2142,  13.4148,  15.0933, -17.4838,  18.6595, -13.8052],\n",
      "        [ 19.4012,  13.3690,  14.7468, -17.0671,  18.0945, -13.5210],\n",
      "        [ 19.4551,  14.0061,  15.0808, -17.3410,  18.2799, -13.1519],\n",
      "        [ 19.3688,  13.7080,  14.9720, -17.3847,  18.8554, -13.3828],\n",
      "        [ 19.2935,  13.3904,  15.0902, -17.3152,  18.9852, -13.4549],\n",
      "        [ 19.2875,  13.5400,  14.7578, -17.3465,  18.9136, -13.9129]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.8114261627197266\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2674, 13.5473, 14.9181],\n",
      "        [19.0378, 13.6042, 14.8515],\n",
      "        [19.3597, 13.6056, 14.8656],\n",
      "        [19.0819, 13.5807, 15.0838],\n",
      "        [19.7252, 14.0107, 15.0566],\n",
      "        [19.3999, 13.7561, 15.1906]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6260, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3405,  18.8258, -13.3019],\n",
      "        [-17.0208,  18.7119, -13.5995],\n",
      "        [-17.5803,  18.6396, -13.6284],\n",
      "        [-17.0320,  18.6418, -13.4057],\n",
      "        [-17.3517,  18.5403, -13.0495],\n",
      "        [-17.6291,  18.6477, -13.7065]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2674,  13.5473,  14.9181, -17.3405,  18.8258, -13.3019],\n",
      "        [ 19.0378,  13.6042,  14.8515, -17.0208,  18.7119, -13.5995],\n",
      "        [ 19.3597,  13.6056,  14.8656, -17.5803,  18.6396, -13.6284],\n",
      "        [ 19.0819,  13.5807,  15.0838, -17.0320,  18.6418, -13.4057],\n",
      "        [ 19.7252,  14.0107,  15.0566, -17.3517,  18.5403, -13.0495],\n",
      "        [ 19.3999,  13.7561,  15.1906, -17.6291,  18.6477, -13.7065]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8044958114624023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2581, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4768, 13.8971, 15.3567],\n",
      "        [19.3617, 13.8595, 14.6326],\n",
      "        [18.8584, 13.3971, 14.8081],\n",
      "        [19.7083, 13.4607, 15.2098],\n",
      "        [19.1082, 13.5869, 14.9020],\n",
      "        [19.3922, 13.7836, 14.8794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0500, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3630,  18.6507, -13.5212],\n",
      "        [-17.1221,  19.1643, -13.5910],\n",
      "        [-17.4108,  18.7982, -13.7447],\n",
      "        [-16.6851,  18.4476, -13.5429],\n",
      "        [-17.4079,  19.2960, -14.0262],\n",
      "        [-17.4062,  18.7515, -13.5134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4768,  13.8971,  15.3567, -17.3630,  18.6507, -13.5212],\n",
      "        [ 19.3617,  13.8595,  14.6326, -17.1221,  19.1643, -13.5910],\n",
      "        [ 18.8584,  13.3971,  14.8081, -17.4108,  18.7982, -13.7447],\n",
      "        [ 19.7083,  13.4607,  15.2098, -16.6851,  18.4476, -13.5429],\n",
      "        [ 19.1082,  13.5869,  14.9020, -17.4079,  19.2960, -14.0262],\n",
      "        [ 19.3922,  13.7836,  14.8794, -17.4062,  18.7515, -13.5134]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8381595611572266\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2764, 13.6882, 14.9599],\n",
      "        [19.5544, 13.6474, 14.9480],\n",
      "        [19.5562, 13.5785, 14.9432],\n",
      "        [19.4536, 13.5290, 15.0740],\n",
      "        [19.5510, 13.9469, 15.1180],\n",
      "        [18.7820, 13.1021, 14.3784]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.1510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5282,  18.8055, -13.9099],\n",
      "        [-17.1960,  18.7128, -13.9162],\n",
      "        [-17.2688,  18.2978, -13.6395],\n",
      "        [-16.5531,  18.3020, -13.4133],\n",
      "        [-17.5483,  18.9390, -13.5897],\n",
      "        [-17.0969,  18.7741, -13.3642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2764,  13.6882,  14.9599, -17.5282,  18.8055, -13.9099],\n",
      "        [ 19.5544,  13.6474,  14.9480, -17.1960,  18.7128, -13.9162],\n",
      "        [ 19.5562,  13.5785,  14.9432, -17.2688,  18.2978, -13.6395],\n",
      "        [ 19.4536,  13.5290,  15.0740, -16.5531,  18.3020, -13.4133],\n",
      "        [ 19.5510,  13.9469,  15.1180, -17.5483,  18.9390, -13.5897],\n",
      "        [ 18.7820,  13.1021,  14.3784, -17.0969,  18.7741, -13.3642]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8265278339385986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1800, 13.6734, 15.0873],\n",
      "        [19.3519, 13.7968, 15.0796],\n",
      "        [19.2943, 13.9274, 15.1082],\n",
      "        [19.0887, 14.0273, 15.0890],\n",
      "        [18.8984, 13.5516, 15.0170],\n",
      "        [18.9957, 13.2793, 15.0049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5201,  19.0405, -13.6620],\n",
      "        [-17.4820,  18.9169, -13.6454],\n",
      "        [-17.7757,  19.0294, -13.4919],\n",
      "        [-17.0803,  18.7901, -13.5379],\n",
      "        [-17.0690,  18.9110, -13.4410],\n",
      "        [-17.2889,  18.7460, -13.2555]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1800,  13.6734,  15.0873, -17.5201,  19.0405, -13.6620],\n",
      "        [ 19.3519,  13.7968,  15.0796, -17.4820,  18.9169, -13.6454],\n",
      "        [ 19.2943,  13.9274,  15.1082, -17.7757,  19.0294, -13.4919],\n",
      "        [ 19.0887,  14.0273,  15.0890, -17.0803,  18.7901, -13.5379],\n",
      "        [ 18.8984,  13.5516,  15.0170, -17.0690,  18.9110, -13.4410],\n",
      "        [ 18.9957,  13.2793,  15.0049, -17.2889,  18.7460, -13.2555]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8293750286102295\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7860, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3893, 13.6316, 15.1051],\n",
      "        [19.4874, 13.8074, 15.1472],\n",
      "        [19.1216, 13.7801, 15.0692],\n",
      "        [19.5661, 13.7971, 15.1920],\n",
      "        [19.6257, 14.0212, 15.6702],\n",
      "        [19.7848, 14.1516, 15.1757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3747,  18.9034, -13.3762],\n",
      "        [-17.7263,  18.8567, -14.0465],\n",
      "        [-17.4924,  19.2362, -13.9568],\n",
      "        [-17.3230,  18.8087, -13.8454],\n",
      "        [-17.5482,  18.7581, -13.4907],\n",
      "        [-17.0848,  18.2592, -13.0778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3893,  13.6316,  15.1051, -17.3747,  18.9034, -13.3762],\n",
      "        [ 19.4874,  13.8074,  15.1472, -17.7263,  18.8567, -14.0465],\n",
      "        [ 19.1216,  13.7801,  15.0692, -17.4924,  19.2362, -13.9568],\n",
      "        [ 19.5661,  13.7971,  15.1920, -17.3230,  18.8087, -13.8454],\n",
      "        [ 19.6257,  14.0212,  15.6702, -17.5482,  18.7581, -13.4907],\n",
      "        [ 19.7848,  14.1516,  15.1757, -17.0848,  18.2592, -13.0778]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.827590227127075\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0110, 13.4177, 14.9142],\n",
      "        [19.3787, 13.4245, 14.9751],\n",
      "        [19.3139, 13.6870, 14.7645],\n",
      "        [19.1817, 13.5554, 14.8546],\n",
      "        [18.5876, 13.4960, 14.6129],\n",
      "        [19.1706, 12.8346, 14.6422]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3935, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4462,  18.9129, -13.8982],\n",
      "        [-17.6933,  18.7781, -13.5125],\n",
      "        [-17.6139,  19.0044, -13.5643],\n",
      "        [-17.8380,  19.1707, -13.5605],\n",
      "        [-17.3344,  19.0480, -13.6628],\n",
      "        [-17.8729,  19.2460, -13.8504]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0110,  13.4177,  14.9142, -17.4462,  18.9129, -13.8982],\n",
      "        [ 19.3787,  13.4245,  14.9751, -17.6933,  18.7781, -13.5125],\n",
      "        [ 19.3139,  13.6870,  14.7645, -17.6139,  19.0044, -13.5643],\n",
      "        [ 19.1817,  13.5554,  14.8546, -17.8380,  19.1707, -13.5605],\n",
      "        [ 18.5876,  13.4960,  14.6129, -17.3344,  19.0480, -13.6628],\n",
      "        [ 19.1706,  12.8346,  14.6422, -17.8729,  19.2460, -13.8504]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.8114662170410156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9799, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2906, 13.1699, 14.9212],\n",
      "        [19.4112, 13.6379, 15.3531],\n",
      "        [19.5648, 13.8909, 15.5855],\n",
      "        [19.3690, 13.7386, 15.0446],\n",
      "        [19.0926, 13.9275, 14.9605],\n",
      "        [19.6015, 13.4374, 14.9206]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2403, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2266,  18.4861, -13.5635],\n",
      "        [-17.4915,  19.0570, -13.6509],\n",
      "        [-17.9169,  19.6025, -13.9852],\n",
      "        [-17.6352,  18.7645, -13.7716],\n",
      "        [-17.7864,  18.9947, -13.7251],\n",
      "        [-17.7708,  19.0391, -14.0343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2906,  13.1699,  14.9212, -17.2266,  18.4861, -13.5635],\n",
      "        [ 19.4112,  13.6379,  15.3531, -17.4915,  19.0570, -13.6509],\n",
      "        [ 19.5648,  13.8909,  15.5855, -17.9169,  19.6025, -13.9852],\n",
      "        [ 19.3690,  13.7386,  15.0446, -17.6352,  18.7645, -13.7716],\n",
      "        [ 19.0926,  13.9275,  14.9605, -17.7864,  18.9947, -13.7251],\n",
      "        [ 19.6015,  13.4374,  14.9206, -17.7708,  19.0391, -14.0343]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7973415851593018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8899, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2579, 13.4595, 14.5717],\n",
      "        [19.3938, 13.8388, 15.2296],\n",
      "        [19.2517, 13.5852, 15.0006],\n",
      "        [19.1975, 13.6249, 14.6827],\n",
      "        [19.3317, 13.5012, 14.7759],\n",
      "        [19.2274, 13.7916, 15.2881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1620,  18.7532, -13.7920],\n",
      "        [-17.4139,  18.9795, -13.7675],\n",
      "        [-17.1727,  18.2971, -13.2712],\n",
      "        [-17.3929,  18.6634, -13.7106],\n",
      "        [-17.2733,  18.6208, -13.6492],\n",
      "        [-16.9059,  18.6235, -13.5095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2579,  13.4595,  14.5717, -17.1620,  18.7532, -13.7920],\n",
      "        [ 19.3938,  13.8388,  15.2296, -17.4139,  18.9795, -13.7675],\n",
      "        [ 19.2517,  13.5852,  15.0006, -17.1727,  18.2971, -13.2712],\n",
      "        [ 19.1975,  13.6249,  14.6827, -17.3929,  18.6634, -13.7106],\n",
      "        [ 19.3317,  13.5012,  14.7759, -17.2733,  18.6208, -13.6492],\n",
      "        [ 19.2274,  13.7916,  15.2881, -16.9059,  18.6235, -13.5095]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8012659549713135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1822, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0231, 13.6765, 14.7498],\n",
      "        [19.0378, 13.7443, 15.2721],\n",
      "        [19.0696, 13.7604, 15.0088],\n",
      "        [19.1043, 13.9567, 14.9897],\n",
      "        [19.4570, 14.3595, 15.1916],\n",
      "        [19.8659, 14.1058, 15.4020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4631,  18.6751, -13.6766],\n",
      "        [-17.3258,  18.9247, -13.5841],\n",
      "        [-17.2328,  18.7589, -13.6594],\n",
      "        [-17.4460,  18.9189, -13.6099],\n",
      "        [-17.7418,  18.9823, -13.8737],\n",
      "        [-17.3044,  18.6236, -13.4711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0231,  13.6765,  14.7498, -17.4631,  18.6751, -13.6766],\n",
      "        [ 19.0378,  13.7443,  15.2721, -17.3258,  18.9247, -13.5841],\n",
      "        [ 19.0696,  13.7604,  15.0088, -17.2328,  18.7589, -13.6594],\n",
      "        [ 19.1043,  13.9567,  14.9897, -17.4460,  18.9189, -13.6099],\n",
      "        [ 19.4570,  14.3595,  15.1916, -17.7418,  18.9823, -13.8737],\n",
      "        [ 19.8659,  14.1058,  15.4020, -17.3044,  18.6236, -13.4711]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8067476749420166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1170, 13.5766, 15.3089],\n",
      "        [19.4183, 13.7141, 15.1228],\n",
      "        [18.7679, 13.3626, 15.0100],\n",
      "        [19.7683, 13.7291, 14.9746],\n",
      "        [19.5491, 14.0161, 15.2177],\n",
      "        [19.6867, 14.1903, 15.0774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7581, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7379,  19.0618, -13.7368],\n",
      "        [-17.2610,  19.3271, -13.7581],\n",
      "        [-17.0065,  18.7112, -13.9125],\n",
      "        [-17.8341,  19.2387, -13.9078],\n",
      "        [-17.6246,  18.7331, -13.6374],\n",
      "        [-17.1299,  18.2838, -13.2427]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1170,  13.5766,  15.3089, -17.7379,  19.0618, -13.7368],\n",
      "        [ 19.4183,  13.7141,  15.1228, -17.2610,  19.3271, -13.7581],\n",
      "        [ 18.7679,  13.3626,  15.0100, -17.0065,  18.7112, -13.9125],\n",
      "        [ 19.7683,  13.7291,  14.9746, -17.8341,  19.2387, -13.9078],\n",
      "        [ 19.5491,  14.0161,  15.2177, -17.6246,  18.7331, -13.6374],\n",
      "        [ 19.6867,  14.1903,  15.0774, -17.1299,  18.2838, -13.2427]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.846846103668213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4227, 14.0056, 15.1320],\n",
      "        [19.3031, 13.8945, 15.1514],\n",
      "        [19.0384, 13.7158, 15.1587],\n",
      "        [19.3872, 13.9647, 15.1329],\n",
      "        [19.5905, 13.7623, 15.2352],\n",
      "        [19.4151, 13.6982, 14.6774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2014,  18.3558, -13.3834],\n",
      "        [-17.5308,  19.1033, -13.9336],\n",
      "        [-17.8402,  19.2533, -13.8565],\n",
      "        [-17.9153,  18.9679, -13.7466],\n",
      "        [-17.3287,  18.8094, -13.4295],\n",
      "        [-16.8779,  18.3097, -13.3931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4227,  14.0056,  15.1320, -17.2014,  18.3558, -13.3834],\n",
      "        [ 19.3031,  13.8945,  15.1514, -17.5308,  19.1033, -13.9336],\n",
      "        [ 19.0384,  13.7158,  15.1587, -17.8402,  19.2533, -13.8565],\n",
      "        [ 19.3872,  13.9647,  15.1329, -17.9153,  18.9679, -13.7466],\n",
      "        [ 19.5905,  13.7623,  15.2352, -17.3287,  18.8094, -13.4295],\n",
      "        [ 19.4151,  13.6982,  14.6774, -16.8779,  18.3097, -13.3931]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.828432559967041\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8953, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.9436, 13.6327, 15.0740],\n",
      "        [19.5943, 13.5097, 15.0751],\n",
      "        [19.3961, 13.9319, 14.9328],\n",
      "        [19.6823, 13.9003, 14.8347],\n",
      "        [19.6691, 13.7404, 15.3736],\n",
      "        [19.2561, 13.3798, 15.1521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1737,  18.3360, -13.9010],\n",
      "        [-17.4024,  18.6950, -13.6234],\n",
      "        [-17.2597,  18.6023, -13.3150],\n",
      "        [-17.0350,  18.3837, -13.5127],\n",
      "        [-17.5127,  19.0073, -13.8662],\n",
      "        [-17.6981,  18.7751, -13.5051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.9436,  13.6327,  15.0740, -17.1737,  18.3360, -13.9010],\n",
      "        [ 19.5943,  13.5097,  15.0751, -17.4024,  18.6950, -13.6234],\n",
      "        [ 19.3961,  13.9319,  14.9328, -17.2597,  18.6023, -13.3150],\n",
      "        [ 19.6823,  13.9003,  14.8347, -17.0350,  18.3837, -13.5127],\n",
      "        [ 19.6691,  13.7404,  15.3736, -17.5127,  19.0073, -13.8662],\n",
      "        [ 19.2561,  13.3798,  15.1521, -17.6981,  18.7751, -13.5051]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.8054988384246826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2943, 13.8302, 15.0259],\n",
      "        [19.5518, 13.6674, 15.1101],\n",
      "        [19.0037, 14.0640, 15.1966],\n",
      "        [19.2888, 13.6961, 15.0754],\n",
      "        [19.7176, 13.9773, 15.3633],\n",
      "        [19.2710, 13.8709, 15.1231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7046,  18.9953, -14.0905],\n",
      "        [-17.0239,  18.5837, -13.6133],\n",
      "        [-17.7601,  19.0449, -13.8790],\n",
      "        [-17.8511,  19.1739, -13.8128],\n",
      "        [-16.7523,  18.6930, -13.1007],\n",
      "        [-17.5991,  19.3959, -13.8716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2943,  13.8302,  15.0259, -17.7046,  18.9953, -14.0905],\n",
      "        [ 19.5518,  13.6674,  15.1101, -17.0239,  18.5837, -13.6133],\n",
      "        [ 19.0037,  14.0640,  15.1966, -17.7601,  19.0449, -13.8790],\n",
      "        [ 19.2888,  13.6961,  15.0754, -17.8511,  19.1739, -13.8128],\n",
      "        [ 19.7176,  13.9773,  15.3633, -16.7523,  18.6930, -13.1007],\n",
      "        [ 19.2710,  13.8709,  15.1231, -17.5991,  19.3959, -13.8716]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.858294725418091\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4269, 13.9512, 15.3104],\n",
      "        [19.4104, 13.9454, 15.1945],\n",
      "        [19.5892, 14.0417, 15.1288],\n",
      "        [19.6017, 13.8781, 14.9189],\n",
      "        [19.1977, 13.7102, 15.0271],\n",
      "        [19.5614, 13.8741, 15.2546]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.2452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5563,  18.5833, -13.3901],\n",
      "        [-17.2768,  18.9950, -13.4309],\n",
      "        [-16.9065,  18.3650, -13.3701],\n",
      "        [-17.1984,  18.4359, -13.6545],\n",
      "        [-17.1452,  18.9003, -13.7665],\n",
      "        [-17.3355,  18.6602, -14.0523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4269,  13.9512,  15.3104, -17.5563,  18.5833, -13.3901],\n",
      "        [ 19.4104,  13.9454,  15.1945, -17.2768,  18.9950, -13.4309],\n",
      "        [ 19.5892,  14.0417,  15.1288, -16.9065,  18.3650, -13.3701],\n",
      "        [ 19.6017,  13.8781,  14.9189, -17.1984,  18.4359, -13.6545],\n",
      "        [ 19.1977,  13.7102,  15.0271, -17.1452,  18.9003, -13.7665],\n",
      "        [ 19.5614,  13.8741,  15.2546, -17.3355,  18.6602, -14.0523]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.851910352706909\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5223, 14.1748, 14.9586],\n",
      "        [19.2063, 13.4698, 15.0791],\n",
      "        [19.5392, 13.5020, 15.0875],\n",
      "        [19.4441, 13.5948, 15.1836],\n",
      "        [19.3527, 14.0815, 14.8738],\n",
      "        [19.5361, 14.1371, 15.3722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5996, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8623,  19.1491, -13.7570],\n",
      "        [-17.5763,  18.1625, -13.3376],\n",
      "        [-17.4567,  18.5544, -13.6671],\n",
      "        [-17.4622,  18.9016, -13.7804],\n",
      "        [-17.9677,  19.0001, -14.0287],\n",
      "        [-17.3328,  18.9291, -13.5227]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5223,  14.1748,  14.9586, -17.8623,  19.1491, -13.7570],\n",
      "        [ 19.2063,  13.4698,  15.0791, -17.5763,  18.1625, -13.3376],\n",
      "        [ 19.5392,  13.5020,  15.0875, -17.4567,  18.5544, -13.6671],\n",
      "        [ 19.4441,  13.5948,  15.1836, -17.4622,  18.9016, -13.7804],\n",
      "        [ 19.3527,  14.0815,  14.8738, -17.9677,  19.0001, -14.0287],\n",
      "        [ 19.5361,  14.1371,  15.3722, -17.3328,  18.9291, -13.5227]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8788583278656006\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6395, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3262, 13.2480, 14.9261],\n",
      "        [19.3105, 13.9985, 15.1590],\n",
      "        [19.2606, 13.8140, 14.8076],\n",
      "        [19.1831, 13.5461, 14.9647],\n",
      "        [20.2311, 14.3953, 15.5608],\n",
      "        [19.0178, 13.5200, 15.0113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.9523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6154,  18.9735, -13.6108],\n",
      "        [-17.3153,  18.9552, -13.6818],\n",
      "        [-17.8116,  18.9455, -13.4137],\n",
      "        [-17.5436,  18.7505, -13.7484],\n",
      "        [-17.6135,  19.0652, -13.7700],\n",
      "        [-17.2021,  18.9489, -13.4754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3262,  13.2480,  14.9261, -17.6154,  18.9735, -13.6108],\n",
      "        [ 19.3105,  13.9985,  15.1590, -17.3153,  18.9552, -13.6818],\n",
      "        [ 19.2606,  13.8140,  14.8076, -17.8116,  18.9455, -13.4137],\n",
      "        [ 19.1831,  13.5461,  14.9647, -17.5436,  18.7505, -13.7484],\n",
      "        [ 20.2311,  14.3953,  15.5608, -17.6135,  19.0652, -13.7700],\n",
      "        [ 19.0178,  13.5200,  15.0113, -17.2021,  18.9489, -13.4754]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.835301399230957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1500, 13.3835, 14.6070],\n",
      "        [19.6670, 14.1647, 15.0071],\n",
      "        [19.3983, 13.9524, 15.1007],\n",
      "        [19.4935, 13.9262, 15.3325],\n",
      "        [19.2391, 13.8947, 15.3448],\n",
      "        [19.8502, 14.0591, 15.4509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.1427,  18.5614, -13.4869],\n",
      "        [-17.5568,  18.7899, -13.3747],\n",
      "        [-17.9620,  19.3332, -13.8499],\n",
      "        [-17.2346,  18.4593, -13.7140],\n",
      "        [-17.9548,  18.8692, -13.9117],\n",
      "        [-17.2826,  18.6330, -13.7104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1500,  13.3835,  14.6070, -17.1427,  18.5614, -13.4869],\n",
      "        [ 19.6670,  14.1647,  15.0071, -17.5568,  18.7899, -13.3747],\n",
      "        [ 19.3983,  13.9524,  15.1007, -17.9620,  19.3332, -13.8499],\n",
      "        [ 19.4935,  13.9262,  15.3325, -17.2346,  18.4593, -13.7140],\n",
      "        [ 19.2391,  13.8947,  15.3448, -17.9548,  18.8692, -13.9117],\n",
      "        [ 19.8502,  14.0591,  15.4509, -17.2826,  18.6330, -13.7104]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.7968006134033203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5030, 13.8275, 15.2496],\n",
      "        [19.7704, 13.8363, 15.0142],\n",
      "        [19.5183, 13.7786, 15.3856],\n",
      "        [19.4145, 13.9183, 15.0369],\n",
      "        [19.7995, 14.0416, 15.6006],\n",
      "        [18.9119, 13.3671, 14.8246]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.1381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4280,  18.7138, -13.8772],\n",
      "        [-16.9275,  18.4151, -13.5775],\n",
      "        [-17.8017,  19.1245, -14.4093],\n",
      "        [-17.7272,  18.6517, -13.2590],\n",
      "        [-17.8164,  18.7435, -13.9050],\n",
      "        [-16.9282,  18.7931, -13.3595]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5030,  13.8275,  15.2496, -17.4280,  18.7138, -13.8772],\n",
      "        [ 19.7704,  13.8363,  15.0142, -16.9275,  18.4151, -13.5775],\n",
      "        [ 19.5183,  13.7786,  15.3856, -17.8017,  19.1245, -14.4093],\n",
      "        [ 19.4145,  13.9183,  15.0369, -17.7272,  18.6517, -13.2590],\n",
      "        [ 19.7995,  14.0416,  15.6006, -17.8164,  18.7435, -13.9050],\n",
      "        [ 18.9119,  13.3671,  14.8246, -16.9282,  18.7931, -13.3595]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.864137649536133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3925, 13.8940, 15.1609],\n",
      "        [19.0101, 13.9732, 15.1990],\n",
      "        [19.4674, 13.7834, 15.0425],\n",
      "        [19.6588, 14.1799, 15.6423],\n",
      "        [19.2882, 13.4434, 14.9211],\n",
      "        [19.1317, 14.0804, 15.3979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.1341, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.9663,  18.4340, -13.3375],\n",
      "        [-17.5669,  18.7535, -13.6331],\n",
      "        [-17.2916,  18.7893, -13.4942],\n",
      "        [-17.1975,  18.5839, -13.2035],\n",
      "        [-17.6325,  19.0190, -14.1065],\n",
      "        [-17.9406,  19.0824, -13.7704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3925,  13.8940,  15.1609, -16.9663,  18.4340, -13.3375],\n",
      "        [ 19.0101,  13.9732,  15.1990, -17.5669,  18.7535, -13.6331],\n",
      "        [ 19.4674,  13.7834,  15.0425, -17.2916,  18.7893, -13.4942],\n",
      "        [ 19.6588,  14.1799,  15.6423, -17.1975,  18.5839, -13.2035],\n",
      "        [ 19.2882,  13.4434,  14.9211, -17.6325,  19.0190, -14.1065],\n",
      "        [ 19.1317,  14.0804,  15.3979, -17.9406,  19.0824, -13.7704]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.831432819366455\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3431, 14.0121, 14.8935],\n",
      "        [19.2779, 14.0555, 15.3252],\n",
      "        [19.2850, 13.8035, 14.6928],\n",
      "        [19.7804, 13.7716, 15.5938],\n",
      "        [19.3473, 13.8376, 15.3140],\n",
      "        [19.5288, 13.6844, 15.0378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.7969, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8334,  19.0503, -13.7086],\n",
      "        [-17.6464,  18.6283, -13.6464],\n",
      "        [-17.2046,  19.1357, -13.4443],\n",
      "        [-17.5228,  19.1934, -13.9399],\n",
      "        [-17.3026,  18.7175, -13.7171],\n",
      "        [-17.6425,  19.0286, -13.6478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3431,  14.0121,  14.8935, -17.8334,  19.0503, -13.7086],\n",
      "        [ 19.2779,  14.0555,  15.3252, -17.6464,  18.6283, -13.6464],\n",
      "        [ 19.2850,  13.8035,  14.6928, -17.2046,  19.1357, -13.4443],\n",
      "        [ 19.7804,  13.7716,  15.5938, -17.5228,  19.1934, -13.9399],\n",
      "        [ 19.3473,  13.8376,  15.3140, -17.3026,  18.7175, -13.7171],\n",
      "        [ 19.5288,  13.6844,  15.0378, -17.6425,  19.0286, -13.6478]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.867286205291748\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5993, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2701, 13.9071, 14.9969],\n",
      "        [19.2814, 13.6312, 15.3586],\n",
      "        [19.5717, 14.0121, 15.0785],\n",
      "        [19.7878, 14.2240, 15.5038],\n",
      "        [19.3772, 13.6410, 15.0116],\n",
      "        [19.3451, 13.6503, 15.2310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5660, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.0700,  18.6688, -13.8459],\n",
      "        [-17.3138,  18.4489, -13.3867],\n",
      "        [-17.7065,  19.1252, -13.9145],\n",
      "        [-17.3090,  18.8376, -13.4897],\n",
      "        [-17.7984,  19.1738, -14.3558],\n",
      "        [-17.6834,  19.2580, -13.6675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2701,  13.9071,  14.9969, -17.0700,  18.6688, -13.8459],\n",
      "        [ 19.2814,  13.6312,  15.3586, -17.3138,  18.4489, -13.3867],\n",
      "        [ 19.5717,  14.0121,  15.0785, -17.7065,  19.1252, -13.9145],\n",
      "        [ 19.7878,  14.2240,  15.5038, -17.3090,  18.8376, -13.4897],\n",
      "        [ 19.3772,  13.6410,  15.0116, -17.7984,  19.1738, -14.3558],\n",
      "        [ 19.3451,  13.6503,  15.2310, -17.6834,  19.2580, -13.6675]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8406238555908203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2566, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1532, 13.8946, 15.1534],\n",
      "        [19.6712, 14.3590, 15.2920],\n",
      "        [19.1353, 13.5893, 15.2592],\n",
      "        [19.4582, 13.9071, 15.0190],\n",
      "        [19.2386, 13.8306, 14.8298],\n",
      "        [19.5053, 13.7279, 15.1080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6866,  19.0152, -13.8222],\n",
      "        [-18.0452,  18.8107, -14.0820],\n",
      "        [-17.4073,  18.8939, -13.7740],\n",
      "        [-17.6167,  19.1068, -13.6342],\n",
      "        [-17.6534,  19.0892, -13.7796],\n",
      "        [-17.6737,  18.6565, -13.9387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1532,  13.8946,  15.1534, -17.6866,  19.0152, -13.8222],\n",
      "        [ 19.6712,  14.3590,  15.2920, -18.0452,  18.8107, -14.0820],\n",
      "        [ 19.1353,  13.5893,  15.2592, -17.4073,  18.8939, -13.7740],\n",
      "        [ 19.4582,  13.9071,  15.0190, -17.6167,  19.1068, -13.6342],\n",
      "        [ 19.2386,  13.8306,  14.8298, -17.6534,  19.0892, -13.7796],\n",
      "        [ 19.5053,  13.7279,  15.1080, -17.6737,  18.6565, -13.9387]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8653507232666016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8799, 13.7037, 15.1869],\n",
      "        [19.0478, 13.8508, 15.2462],\n",
      "        [19.7265, 14.5748, 15.6148],\n",
      "        [19.9988, 14.1331, 15.1619],\n",
      "        [20.1839, 14.3608, 15.5744],\n",
      "        [19.6253, 14.1181, 15.1331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6047,  18.9415, -13.7486],\n",
      "        [-17.4430,  18.9670, -13.7410],\n",
      "        [-17.7003,  18.9599, -13.9444],\n",
      "        [-17.1346,  18.3927, -13.3749],\n",
      "        [-17.8358,  19.0694, -14.0646],\n",
      "        [-17.9641,  19.3156, -14.2178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8799,  13.7037,  15.1869, -17.6047,  18.9415, -13.7486],\n",
      "        [ 19.0478,  13.8508,  15.2462, -17.4430,  18.9670, -13.7410],\n",
      "        [ 19.7265,  14.5748,  15.6148, -17.7003,  18.9599, -13.9444],\n",
      "        [ 19.9988,  14.1331,  15.1619, -17.1346,  18.3927, -13.3749],\n",
      "        [ 20.1839,  14.3608,  15.5744, -17.8358,  19.0694, -14.0646],\n",
      "        [ 19.6253,  14.1181,  15.1331, -17.9641,  19.3156, -14.2178]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.846052408218384\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6297, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5816, 13.9817, 15.3108],\n",
      "        [19.3807, 13.7909, 15.2663],\n",
      "        [19.4560, 13.7382, 15.0789],\n",
      "        [19.5154, 13.9610, 15.0788],\n",
      "        [19.2132, 13.8101, 15.5307],\n",
      "        [19.8517, 13.9221, 15.1055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.8150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.2884,  18.9119, -13.4895],\n",
      "        [-17.7672,  19.1211, -14.1064],\n",
      "        [-17.8110,  18.8527, -13.6829],\n",
      "        [-17.7874,  19.0375, -13.8529],\n",
      "        [-17.4366,  18.9481, -14.1553],\n",
      "        [-17.3887,  18.6743, -13.6513]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5816,  13.9817,  15.3108, -17.2884,  18.9119, -13.4895],\n",
      "        [ 19.3807,  13.7909,  15.2663, -17.7672,  19.1211, -14.1064],\n",
      "        [ 19.4560,  13.7382,  15.0789, -17.8110,  18.8527, -13.6829],\n",
      "        [ 19.5154,  13.9610,  15.0788, -17.7874,  19.0375, -13.8529],\n",
      "        [ 19.2132,  13.8101,  15.5307, -17.4366,  18.9481, -14.1553],\n",
      "        [ 19.8517,  13.9221,  15.1055, -17.3887,  18.6743, -13.6513]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.876413583755493\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4956, 13.8484, 15.3490],\n",
      "        [19.6870, 13.7141, 15.2028],\n",
      "        [19.7932, 13.8519, 14.5638],\n",
      "        [19.4514, 13.9934, 14.8685],\n",
      "        [18.9169, 13.4805, 15.1292],\n",
      "        [18.9260, 13.8292, 15.0221]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9902, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3366,  18.7386, -13.4669],\n",
      "        [-17.5511,  18.5595, -13.9063],\n",
      "        [-17.3575,  18.8416, -13.6833],\n",
      "        [-17.6634,  19.1782, -13.8469],\n",
      "        [-17.5786,  18.9908, -13.8355],\n",
      "        [-18.2154,  19.6730, -14.0547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4956,  13.8484,  15.3490, -17.3366,  18.7386, -13.4669],\n",
      "        [ 19.6870,  13.7141,  15.2028, -17.5511,  18.5595, -13.9063],\n",
      "        [ 19.7932,  13.8519,  14.5638, -17.3575,  18.8416, -13.6833],\n",
      "        [ 19.4514,  13.9934,  14.8685, -17.6634,  19.1782, -13.8469],\n",
      "        [ 18.9169,  13.4805,  15.1292, -17.5786,  18.9908, -13.8355],\n",
      "        [ 18.9260,  13.8292,  15.0221, -18.2154,  19.6730, -14.0547]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.868281126022339\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4775, 14.0090, 15.0658],\n",
      "        [19.5562, 13.7901, 15.4248],\n",
      "        [19.1323, 13.9256, 15.2868],\n",
      "        [19.6235, 14.0602, 15.2171],\n",
      "        [19.3453, 13.8415, 14.6288],\n",
      "        [19.5998, 13.7921, 15.1032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0333, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6350,  18.6702, -13.8677],\n",
      "        [-17.8281,  19.2028, -13.9363],\n",
      "        [-17.5508,  18.7938, -13.5194],\n",
      "        [-18.0769,  19.3047, -14.3120],\n",
      "        [-17.8352,  18.9974, -13.7645],\n",
      "        [-17.7163,  18.8389, -13.8787]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4775,  14.0090,  15.0658, -17.6350,  18.6702, -13.8677],\n",
      "        [ 19.5562,  13.7901,  15.4248, -17.8281,  19.2028, -13.9363],\n",
      "        [ 19.1323,  13.9256,  15.2868, -17.5508,  18.7938, -13.5194],\n",
      "        [ 19.6235,  14.0602,  15.2171, -18.0769,  19.3047, -14.3120],\n",
      "        [ 19.3453,  13.8415,  14.6288, -17.8352,  18.9974, -13.7645],\n",
      "        [ 19.5998,  13.7921,  15.1032, -17.7163,  18.8389, -13.8787]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8750476837158203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6714, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[18.8825, 13.3216, 14.9896],\n",
      "        [19.6123, 14.2330, 15.2359],\n",
      "        [19.6383, 14.1128, 15.6178],\n",
      "        [19.3484, 13.7036, 14.8736],\n",
      "        [19.3530, 13.9048, 15.4829],\n",
      "        [19.1943, 14.0953, 15.2059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3512,  18.9230, -13.8199],\n",
      "        [-17.2795,  18.8518, -13.4893],\n",
      "        [-17.4754,  19.0083, -13.7294],\n",
      "        [-17.4912,  18.5602, -14.0812],\n",
      "        [-18.0423,  19.0730, -13.8488],\n",
      "        [-17.8030,  18.8842, -14.3488]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 18.8825,  13.3216,  14.9896, -17.3512,  18.9230, -13.8199],\n",
      "        [ 19.6123,  14.2330,  15.2359, -17.2795,  18.8518, -13.4893],\n",
      "        [ 19.6383,  14.1128,  15.6178, -17.4754,  19.0083, -13.7294],\n",
      "        [ 19.3484,  13.7036,  14.8736, -17.4912,  18.5602, -14.0812],\n",
      "        [ 19.3530,  13.9048,  15.4829, -18.0423,  19.0730, -13.8488],\n",
      "        [ 19.1943,  14.0953,  15.2059, -17.8030,  18.8842, -14.3488]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.829948663711548\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1527, 13.8953, 15.6658],\n",
      "        [19.5202, 14.0449, 15.1651],\n",
      "        [19.9250, 14.2085, 15.6418],\n",
      "        [19.8466, 13.8013, 15.1055],\n",
      "        [19.3101, 14.1932, 15.4872],\n",
      "        [19.8195, 14.0842, 15.5890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5037,  19.1349, -13.9998],\n",
      "        [-17.5570,  18.9163, -13.4124],\n",
      "        [-17.7897,  19.1532, -13.9836],\n",
      "        [-17.5261,  18.8473, -13.8442],\n",
      "        [-17.8781,  19.2555, -13.9061],\n",
      "        [-17.2954,  19.0720, -13.9584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1527,  13.8953,  15.6658, -17.5037,  19.1349, -13.9998],\n",
      "        [ 19.5202,  14.0449,  15.1651, -17.5570,  18.9163, -13.4124],\n",
      "        [ 19.9250,  14.2085,  15.6418, -17.7897,  19.1532, -13.9836],\n",
      "        [ 19.8466,  13.8013,  15.1055, -17.5261,  18.8473, -13.8442],\n",
      "        [ 19.3101,  14.1932,  15.4872, -17.8781,  19.2555, -13.9061],\n",
      "        [ 19.8195,  14.0842,  15.5890, -17.2954,  19.0720, -13.9584]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.937044382095337\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.0973, 13.4483, 14.6870],\n",
      "        [19.1535, 13.7918, 15.3185],\n",
      "        [20.0733, 13.9994, 15.3816],\n",
      "        [20.0594, 14.2857, 15.7198],\n",
      "        [19.9717, 14.0688, 15.3280],\n",
      "        [18.7916, 13.7944, 14.7877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5129, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9589,  19.2224, -14.2495],\n",
      "        [-17.6088,  18.7449, -13.4622],\n",
      "        [-17.5233,  19.1919, -13.8467],\n",
      "        [-17.3644,  18.6884, -13.6628],\n",
      "        [-17.7033,  19.1551, -14.0422],\n",
      "        [-17.6696,  18.6532, -13.4188]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.0973,  13.4483,  14.6870, -17.9589,  19.2224, -14.2495],\n",
      "        [ 19.1535,  13.7918,  15.3185, -17.6088,  18.7449, -13.4622],\n",
      "        [ 20.0733,  13.9994,  15.3816, -17.5233,  19.1919, -13.8467],\n",
      "        [ 20.0594,  14.2857,  15.7198, -17.3644,  18.6884, -13.6628],\n",
      "        [ 19.9717,  14.0688,  15.3280, -17.7033,  19.1551, -14.0422],\n",
      "        [ 18.7916,  13.7944,  14.7877, -17.6696,  18.6532, -13.4188]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8643722534179688\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0748, 14.5852, 15.6208],\n",
      "        [19.8198, 14.0646, 15.5787],\n",
      "        [19.5456, 13.8727, 15.2618],\n",
      "        [19.1693, 14.1533, 15.3641],\n",
      "        [19.2552, 14.1967, 15.2416],\n",
      "        [19.6260, 13.8923, 15.1223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7269,  19.1792, -14.2205],\n",
      "        [-17.8471,  19.3988, -14.1198],\n",
      "        [-17.9709,  18.9748, -13.8236],\n",
      "        [-17.4584,  18.9714, -13.8811],\n",
      "        [-17.4572,  18.6890, -13.6051],\n",
      "        [-17.4208,  19.0639, -13.7545]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0748,  14.5852,  15.6208, -17.7269,  19.1792, -14.2205],\n",
      "        [ 19.8198,  14.0646,  15.5787, -17.8471,  19.3988, -14.1198],\n",
      "        [ 19.5456,  13.8727,  15.2618, -17.9709,  18.9748, -13.8236],\n",
      "        [ 19.1693,  14.1533,  15.3641, -17.4584,  18.9714, -13.8811],\n",
      "        [ 19.2552,  14.1967,  15.2416, -17.4572,  18.6890, -13.6051],\n",
      "        [ 19.6260,  13.8923,  15.1223, -17.4208,  19.0639, -13.7545]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.9616751670837402\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8573, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4023, 13.9142, 15.5420],\n",
      "        [19.3910, 13.7342, 15.2286],\n",
      "        [19.4741, 14.3794, 15.4523],\n",
      "        [19.3070, 13.7562, 15.0609],\n",
      "        [19.1279, 13.5890, 15.1772],\n",
      "        [19.8689, 13.9903, 15.1890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.0228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1321,  19.4329, -14.3026],\n",
      "        [-17.3225,  19.0568, -13.8513],\n",
      "        [-17.5436,  19.0079, -13.5781],\n",
      "        [-17.4583,  18.7836, -13.6871],\n",
      "        [-17.5841,  18.9350, -13.8705],\n",
      "        [-17.8084,  19.1428, -13.7213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4023,  13.9142,  15.5420, -18.1321,  19.4329, -14.3026],\n",
      "        [ 19.3910,  13.7342,  15.2286, -17.3225,  19.0568, -13.8513],\n",
      "        [ 19.4741,  14.3794,  15.4523, -17.5436,  19.0079, -13.5781],\n",
      "        [ 19.3070,  13.7562,  15.0609, -17.4583,  18.7836, -13.6871],\n",
      "        [ 19.1279,  13.5890,  15.1772, -17.5841,  18.9350, -13.8705],\n",
      "        [ 19.8689,  13.9903,  15.1890, -17.8084,  19.1428, -13.7213]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.932265281677246\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9631, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4456, 13.7966, 15.4182],\n",
      "        [19.4682, 13.8632, 15.3032],\n",
      "        [18.8238, 13.4011, 15.2092],\n",
      "        [19.2324, 14.0224, 15.2600],\n",
      "        [19.9052, 14.0862, 15.3416],\n",
      "        [19.0873, 13.4389, 15.0963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3698, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7772,  19.1979, -13.8992],\n",
      "        [-17.5895,  18.9487, -13.8157],\n",
      "        [-17.8304,  19.1356, -13.6542],\n",
      "        [-17.3840,  18.9943, -13.9542],\n",
      "        [-17.8756,  19.3637, -14.0878],\n",
      "        [-17.4877,  18.9535, -14.0543]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4456,  13.7966,  15.4182, -17.7772,  19.1979, -13.8992],\n",
      "        [ 19.4682,  13.8632,  15.3032, -17.5895,  18.9487, -13.8157],\n",
      "        [ 18.8238,  13.4011,  15.2092, -17.8304,  19.1356, -13.6542],\n",
      "        [ 19.2324,  14.0224,  15.2600, -17.3840,  18.9943, -13.9542],\n",
      "        [ 19.9052,  14.0862,  15.3416, -17.8756,  19.3637, -14.0878],\n",
      "        [ 19.0873,  13.4389,  15.0963, -17.4877,  18.9535, -14.0543]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9065847396850586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1576, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4698, 13.8558, 15.2947],\n",
      "        [19.4805, 13.9221, 15.1408],\n",
      "        [19.8390, 13.9182, 15.1175],\n",
      "        [19.3020, 13.4352, 14.8196],\n",
      "        [19.4972, 14.3898, 15.4694],\n",
      "        [20.0168, 14.2026, 15.1652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6280,  19.2748, -14.1095],\n",
      "        [-17.8038,  19.2282, -13.9487],\n",
      "        [-17.3270,  18.6964, -13.7730],\n",
      "        [-17.4052,  19.0678, -13.9720],\n",
      "        [-17.7811,  18.9675, -13.7021],\n",
      "        [-17.6139,  19.2963, -13.6791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4698,  13.8558,  15.2947, -17.6280,  19.2748, -14.1095],\n",
      "        [ 19.4805,  13.9221,  15.1408, -17.8038,  19.2282, -13.9487],\n",
      "        [ 19.8390,  13.9182,  15.1175, -17.3270,  18.6964, -13.7730],\n",
      "        [ 19.3020,  13.4352,  14.8196, -17.4052,  19.0678, -13.9720],\n",
      "        [ 19.4972,  14.3898,  15.4694, -17.7811,  18.9675, -13.7021],\n",
      "        [ 20.0168,  14.2026,  15.1652, -17.6139,  19.2963, -13.6791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.908181667327881\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7395, 14.1070, 15.4401],\n",
      "        [19.4169, 14.0673, 15.4340],\n",
      "        [19.4930, 13.8900, 15.0671],\n",
      "        [19.8662, 14.1775, 15.2703],\n",
      "        [19.7990, 14.0573, 15.0419],\n",
      "        [19.7308, 14.0899, 15.2377]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5043,  19.1902, -13.8244],\n",
      "        [-17.9994,  19.1804, -14.0015],\n",
      "        [-17.7811,  19.0739, -14.0035],\n",
      "        [-17.4973,  18.7106, -13.4018],\n",
      "        [-17.9374,  19.0705, -13.3551],\n",
      "        [-17.5967,  19.0989, -13.7244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7395,  14.1070,  15.4401, -17.5043,  19.1902, -13.8244],\n",
      "        [ 19.4169,  14.0673,  15.4340, -17.9994,  19.1804, -14.0015],\n",
      "        [ 19.4930,  13.8900,  15.0671, -17.7811,  19.0739, -14.0035],\n",
      "        [ 19.8662,  14.1775,  15.2703, -17.4973,  18.7106, -13.4018],\n",
      "        [ 19.7990,  14.0573,  15.0419, -17.9374,  19.0705, -13.3551],\n",
      "        [ 19.7308,  14.0899,  15.2377, -17.5967,  19.0989, -13.7244]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9223926067352295\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5678, 13.7635, 15.2519],\n",
      "        [19.6970, 14.0068, 14.9538],\n",
      "        [19.4579, 13.7744, 14.9987],\n",
      "        [19.6673, 14.1270, 15.1477],\n",
      "        [19.0929, 13.8235, 15.4029],\n",
      "        [19.5647, 13.9471, 15.2080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4665,  18.9602, -13.9494],\n",
      "        [-17.9075,  19.5498, -14.2302],\n",
      "        [-17.6054,  19.0185, -13.9656],\n",
      "        [-17.7452,  19.0769, -14.1278],\n",
      "        [-17.2936,  18.5326, -13.1530],\n",
      "        [-17.6107,  19.1152, -13.8203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5678,  13.7635,  15.2519, -17.4665,  18.9602, -13.9494],\n",
      "        [ 19.6970,  14.0068,  14.9538, -17.9075,  19.5498, -14.2302],\n",
      "        [ 19.4579,  13.7744,  14.9987, -17.6054,  19.0185, -13.9656],\n",
      "        [ 19.6673,  14.1270,  15.1477, -17.7452,  19.0769, -14.1278],\n",
      "        [ 19.0929,  13.8235,  15.4029, -17.2936,  18.5326, -13.1530],\n",
      "        [ 19.5647,  13.9471,  15.2080, -17.6107,  19.1152, -13.8203]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.8964474201202393\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2697, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5914, 14.1254, 15.7680],\n",
      "        [19.2833, 14.2016, 14.7971],\n",
      "        [19.0173, 13.6931, 15.1720],\n",
      "        [19.5954, 13.8252, 15.3013],\n",
      "        [19.2062, 13.8679, 14.9784],\n",
      "        [19.5032, 14.4001, 15.3220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.0210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-16.8919,  18.4212, -13.3537],\n",
      "        [-18.2481,  19.2112, -14.1598],\n",
      "        [-17.2945,  18.5740, -13.7101],\n",
      "        [-17.7089,  18.8986, -14.0025],\n",
      "        [-17.3199,  18.7511, -13.6200],\n",
      "        [-17.9170,  19.2159, -14.1848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5914,  14.1254,  15.7680, -16.8919,  18.4212, -13.3537],\n",
      "        [ 19.2833,  14.2016,  14.7971, -18.2481,  19.2112, -14.1598],\n",
      "        [ 19.0173,  13.6931,  15.1720, -17.2945,  18.5740, -13.7101],\n",
      "        [ 19.5954,  13.8252,  15.3013, -17.7089,  18.8986, -14.0025],\n",
      "        [ 19.2062,  13.8679,  14.9784, -17.3199,  18.7511, -13.6200],\n",
      "        [ 19.5032,  14.4001,  15.3220, -17.9170,  19.2159, -14.1848]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.8871803283691406\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4379, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5338, 13.8814, 15.4416],\n",
      "        [19.6064, 14.0841, 15.0937],\n",
      "        [20.0578, 14.3365, 15.4005],\n",
      "        [19.7484, 14.0391, 15.3455],\n",
      "        [19.3790, 13.9724, 15.1725],\n",
      "        [19.7673, 14.0356, 15.1634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5388,  19.0143, -13.9424],\n",
      "        [-17.9850,  19.4254, -14.3518],\n",
      "        [-18.0526,  18.9884, -13.8078],\n",
      "        [-17.7479,  18.9908, -13.4874],\n",
      "        [-17.9646,  18.9611, -13.7215],\n",
      "        [-17.5896,  18.9920, -14.0857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5338,  13.8814,  15.4416, -17.5388,  19.0143, -13.9424],\n",
      "        [ 19.6064,  14.0841,  15.0937, -17.9850,  19.4254, -14.3518],\n",
      "        [ 20.0578,  14.3365,  15.4005, -18.0526,  18.9884, -13.8078],\n",
      "        [ 19.7484,  14.0391,  15.3455, -17.7479,  18.9908, -13.4874],\n",
      "        [ 19.3790,  13.9724,  15.1725, -17.9646,  18.9611, -13.7215],\n",
      "        [ 19.7673,  14.0356,  15.1634, -17.5896,  18.9920, -14.0857]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.91013240814209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9856, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7209, 13.6761, 15.2845],\n",
      "        [19.3794, 14.2184, 15.1408],\n",
      "        [20.0424, 14.2822, 15.5162],\n",
      "        [19.9022, 14.3706, 15.5030],\n",
      "        [19.4836, 13.6790, 15.0137],\n",
      "        [19.1726, 14.1751, 15.4396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.7241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5465,  19.0620, -13.5966],\n",
      "        [-17.5409,  19.1454, -13.7659],\n",
      "        [-17.5646,  18.8980, -14.2457],\n",
      "        [-17.8847,  19.3389, -14.1341],\n",
      "        [-17.4993,  19.5667, -13.9254],\n",
      "        [-17.2526,  18.7782, -13.7341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7209,  13.6761,  15.2845, -17.5465,  19.0620, -13.5966],\n",
      "        [ 19.3794,  14.2184,  15.1408, -17.5409,  19.1454, -13.7659],\n",
      "        [ 20.0424,  14.2822,  15.5162, -17.5646,  18.8980, -14.2457],\n",
      "        [ 19.9022,  14.3706,  15.5030, -17.8847,  19.3389, -14.1341],\n",
      "        [ 19.4836,  13.6790,  15.0137, -17.4993,  19.5667, -13.9254],\n",
      "        [ 19.1726,  14.1751,  15.4396, -17.2526,  18.7782, -13.7341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9046213626861572\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9076, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2561, 13.8085, 15.3564],\n",
      "        [19.7478, 14.4701, 15.4247],\n",
      "        [19.4342, 13.8575, 15.1777],\n",
      "        [19.3297, 14.0635, 15.2694],\n",
      "        [19.7330, 13.6755, 15.1928],\n",
      "        [19.8213, 13.5351, 15.5108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1289, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9299,  19.1121, -13.5412],\n",
      "        [-17.6003,  18.9972, -13.8499],\n",
      "        [-17.8990,  18.8354, -13.8716],\n",
      "        [-17.9729,  19.3161, -14.4714],\n",
      "        [-17.6616,  19.0573, -13.9490],\n",
      "        [-17.5426,  18.8740, -14.1148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2561,  13.8085,  15.3564, -17.9299,  19.1121, -13.5412],\n",
      "        [ 19.7478,  14.4701,  15.4247, -17.6003,  18.9972, -13.8499],\n",
      "        [ 19.4342,  13.8575,  15.1777, -17.8990,  18.8354, -13.8716],\n",
      "        [ 19.3297,  14.0635,  15.2694, -17.9729,  19.3161, -14.4714],\n",
      "        [ 19.7330,  13.6755,  15.1928, -17.6616,  19.0573, -13.9490],\n",
      "        [ 19.8213,  13.5351,  15.5108, -17.5426,  18.8740, -14.1148]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.900712013244629\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6726, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6006, 13.9574, 15.2270],\n",
      "        [19.0846, 13.4279, 14.8462],\n",
      "        [19.7600, 13.9535, 15.2588],\n",
      "        [19.1979, 14.2588, 15.7612],\n",
      "        [19.6281, 13.7544, 15.0340],\n",
      "        [19.7763, 14.1341, 15.5191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.1911, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9297,  19.3387, -13.9739],\n",
      "        [-17.7687,  19.2727, -13.9120],\n",
      "        [-17.3381,  18.6467, -13.5467],\n",
      "        [-17.7782,  18.9969, -14.2541],\n",
      "        [-17.5166,  19.3764, -13.6781],\n",
      "        [-17.9285,  19.1505, -13.6370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6006,  13.9574,  15.2270, -17.9297,  19.3387, -13.9739],\n",
      "        [ 19.0846,  13.4279,  14.8462, -17.7687,  19.2727, -13.9120],\n",
      "        [ 19.7600,  13.9535,  15.2588, -17.3381,  18.6467, -13.5467],\n",
      "        [ 19.1979,  14.2588,  15.7612, -17.7782,  18.9969, -14.2541],\n",
      "        [ 19.6281,  13.7544,  15.0340, -17.5166,  19.3764, -13.6781],\n",
      "        [ 19.7763,  14.1341,  15.5191, -17.9285,  19.1505, -13.6370]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9298994541168213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4664, 14.5366, 15.3276],\n",
      "        [19.7997, 13.9348, 15.3732],\n",
      "        [19.5196, 13.9549, 15.2229],\n",
      "        [19.4253, 14.0028, 15.2835],\n",
      "        [19.3050, 14.0562, 15.3997],\n",
      "        [19.2434, 13.6229, 14.7981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1424, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6479,  18.7448, -13.6992],\n",
      "        [-18.0210,  18.8728, -13.9353],\n",
      "        [-18.0072,  19.2406, -14.0382],\n",
      "        [-17.3818,  19.3594, -14.0537],\n",
      "        [-17.8696,  19.5653, -14.4246],\n",
      "        [-18.3124,  19.8313, -14.4060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4664,  14.5366,  15.3276, -17.6479,  18.7448, -13.6992],\n",
      "        [ 19.7997,  13.9348,  15.3732, -18.0210,  18.8728, -13.9353],\n",
      "        [ 19.5196,  13.9549,  15.2229, -18.0072,  19.2406, -14.0382],\n",
      "        [ 19.4253,  14.0028,  15.2835, -17.3818,  19.3594, -14.0537],\n",
      "        [ 19.3050,  14.0562,  15.3997, -17.8696,  19.5653, -14.4246],\n",
      "        [ 19.2434,  13.6229,  14.7981, -18.3124,  19.8313, -14.4060]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9155285358428955\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6767, 13.9341, 15.3408],\n",
      "        [19.2918, 13.9332, 15.1643],\n",
      "        [19.6190, 14.3231, 14.8979],\n",
      "        [19.7865, 14.1424, 15.3128],\n",
      "        [20.4280, 14.3271, 15.8162],\n",
      "        [19.6837, 13.9717, 15.2031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7869,  19.3617, -13.5917],\n",
      "        [-17.8368,  18.6671, -13.9743],\n",
      "        [-17.5324,  18.7601, -13.8098],\n",
      "        [-17.6418,  19.1981, -13.9685],\n",
      "        [-17.8334,  19.3902, -14.0182],\n",
      "        [-17.7801,  19.2610, -14.3736]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6767,  13.9341,  15.3408, -17.7869,  19.3617, -13.5917],\n",
      "        [ 19.2918,  13.9332,  15.1643, -17.8368,  18.6671, -13.9743],\n",
      "        [ 19.6190,  14.3231,  14.8979, -17.5324,  18.7601, -13.8098],\n",
      "        [ 19.7865,  14.1424,  15.3128, -17.6418,  19.1981, -13.9685],\n",
      "        [ 20.4280,  14.3271,  15.8162, -17.8334,  19.3902, -14.0182],\n",
      "        [ 19.6837,  13.9717,  15.2031, -17.7801,  19.2610, -14.3736]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.9297962188720703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0054, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0472, 14.1573, 15.3701],\n",
      "        [19.3656, 14.0668, 15.0682],\n",
      "        [19.6826, 14.0411, 15.3320],\n",
      "        [19.7574, 14.2288, 14.7535],\n",
      "        [19.7275, 14.2244, 15.5525],\n",
      "        [19.6248, 14.4821, 15.6954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9867, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6689,  19.2381, -13.9317],\n",
      "        [-17.7094,  19.4595, -14.0049],\n",
      "        [-17.2856,  18.8222, -14.0436],\n",
      "        [-17.3802,  19.2613, -13.9761],\n",
      "        [-17.5103,  18.7031, -13.8680],\n",
      "        [-17.8160,  18.9834, -13.6642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0472,  14.1573,  15.3701, -17.6689,  19.2381, -13.9317],\n",
      "        [ 19.3656,  14.0668,  15.0682, -17.7094,  19.4595, -14.0049],\n",
      "        [ 19.6826,  14.0411,  15.3320, -17.2856,  18.8222, -14.0436],\n",
      "        [ 19.7574,  14.2288,  14.7535, -17.3802,  19.2613, -13.9761],\n",
      "        [ 19.7275,  14.2244,  15.5525, -17.5103,  18.7031, -13.8680],\n",
      "        [ 19.6248,  14.4821,  15.6954, -17.8160,  18.9834, -13.6642]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9538252353668213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8419, 14.2353, 14.9842],\n",
      "        [19.9447, 13.9393, 15.8328],\n",
      "        [20.0928, 14.5217, 15.7454],\n",
      "        [19.5534, 14.4522, 15.1275],\n",
      "        [19.8021, 13.9195, 15.3961],\n",
      "        [19.5416, 13.8291, 15.0984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3884, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7753,  19.2683, -14.0174],\n",
      "        [-17.6964,  19.0509, -13.8905],\n",
      "        [-17.5975,  18.8285, -14.0152],\n",
      "        [-18.0280,  19.2051, -14.1236],\n",
      "        [-17.6214,  18.9212, -13.5789],\n",
      "        [-17.4209,  18.9201, -14.1644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8419,  14.2353,  14.9842, -17.7753,  19.2683, -14.0174],\n",
      "        [ 19.9447,  13.9393,  15.8328, -17.6964,  19.0509, -13.8905],\n",
      "        [ 20.0928,  14.5217,  15.7454, -17.5975,  18.8285, -14.0152],\n",
      "        [ 19.5534,  14.4522,  15.1275, -18.0280,  19.2051, -14.1236],\n",
      "        [ 19.8021,  13.9195,  15.3961, -17.6214,  18.9212, -13.5789],\n",
      "        [ 19.5416,  13.8291,  15.0984, -17.4209,  18.9201, -14.1644]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9392518997192383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5515, 14.0825, 15.6393],\n",
      "        [19.7101, 14.1161, 15.7947],\n",
      "        [19.7166, 14.2509, 15.3099],\n",
      "        [19.1544, 14.0742, 14.9567],\n",
      "        [19.8975, 14.3946, 15.6312],\n",
      "        [19.7452, 13.8192, 15.6119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0164,  19.5574, -14.1974],\n",
      "        [-17.6197,  19.0933, -14.1416],\n",
      "        [-17.7238,  19.4640, -14.1340],\n",
      "        [-17.5213,  18.9183, -13.7230],\n",
      "        [-17.7956,  19.1543, -13.9499],\n",
      "        [-17.5990,  19.0095, -13.8727]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5515,  14.0825,  15.6393, -18.0164,  19.5574, -14.1974],\n",
      "        [ 19.7101,  14.1161,  15.7947, -17.6197,  19.0933, -14.1416],\n",
      "        [ 19.7166,  14.2509,  15.3099, -17.7238,  19.4640, -14.1340],\n",
      "        [ 19.1544,  14.0742,  14.9567, -17.5213,  18.9183, -13.7230],\n",
      "        [ 19.8975,  14.3946,  15.6312, -17.7956,  19.1543, -13.9499],\n",
      "        [ 19.7452,  13.8192,  15.6119, -17.5990,  19.0095, -13.8727]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.963763952255249\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6312, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0946, 14.2092, 15.9720],\n",
      "        [19.7210, 13.5839, 15.2257],\n",
      "        [19.8713, 14.0961, 15.3500],\n",
      "        [19.8657, 14.1089, 15.2850],\n",
      "        [19.7684, 14.1967, 15.5273],\n",
      "        [19.6405, 14.1293, 15.2176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1777,  19.5041, -14.4048],\n",
      "        [-18.0690,  19.1882, -14.0938],\n",
      "        [-17.9702,  18.7459, -13.8970],\n",
      "        [-17.2098,  18.5846, -13.4337],\n",
      "        [-17.5927,  18.6870, -13.8424],\n",
      "        [-17.7133,  19.1271, -13.7432]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0946,  14.2092,  15.9720, -18.1777,  19.5041, -14.4048],\n",
      "        [ 19.7210,  13.5839,  15.2257, -18.0690,  19.1882, -14.0938],\n",
      "        [ 19.8713,  14.0961,  15.3500, -17.9702,  18.7459, -13.8970],\n",
      "        [ 19.8657,  14.1089,  15.2850, -17.2098,  18.5846, -13.4337],\n",
      "        [ 19.7684,  14.1967,  15.5273, -17.5927,  18.6870, -13.8424],\n",
      "        [ 19.6405,  14.1293,  15.2176, -17.7133,  19.1271, -13.7432]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.010122299194336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9125, 14.0688, 15.4783],\n",
      "        [19.3067, 13.9565, 15.1027],\n",
      "        [19.4703, 14.2776, 15.2958],\n",
      "        [19.7550, 14.6464, 15.6364],\n",
      "        [19.5073, 13.8290, 14.7288],\n",
      "        [19.6086, 13.9374, 15.4397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5863,  18.5829, -13.9592],\n",
      "        [-17.8644,  19.4293, -14.1349],\n",
      "        [-17.8061,  19.3454, -13.9794],\n",
      "        [-17.6347,  19.2067, -13.6242],\n",
      "        [-17.7371,  19.2800, -14.0493],\n",
      "        [-17.8850,  19.4987, -14.3040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9125,  14.0688,  15.4783, -17.5863,  18.5829, -13.9592],\n",
      "        [ 19.3067,  13.9565,  15.1027, -17.8644,  19.4293, -14.1349],\n",
      "        [ 19.4703,  14.2776,  15.2958, -17.8061,  19.3454, -13.9794],\n",
      "        [ 19.7550,  14.6464,  15.6364, -17.6347,  19.2067, -13.6242],\n",
      "        [ 19.5073,  13.8290,  14.7288, -17.7371,  19.2800, -14.0493],\n",
      "        [ 19.6086,  13.9374,  15.4397, -17.8850,  19.4987, -14.3040]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.935962677001953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8549, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5794, 14.5514, 15.4581],\n",
      "        [20.0963, 14.1383, 15.1234],\n",
      "        [19.7408, 14.0760, 15.6148],\n",
      "        [20.0937, 14.0538, 15.4006],\n",
      "        [20.1601, 14.3323, 15.6151],\n",
      "        [19.4798, 14.2809, 15.5685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.8398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1376,  19.4933, -14.2982],\n",
      "        [-18.0571,  18.8389, -13.8281],\n",
      "        [-17.6791,  19.3525, -14.2716],\n",
      "        [-18.0419,  19.2467, -14.1228],\n",
      "        [-17.7529,  19.1539, -13.6344],\n",
      "        [-18.1415,  19.3663, -14.1464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5794,  14.5514,  15.4581, -18.1376,  19.4933, -14.2982],\n",
      "        [ 20.0963,  14.1383,  15.1234, -18.0571,  18.8389, -13.8281],\n",
      "        [ 19.7408,  14.0760,  15.6148, -17.6791,  19.3525, -14.2716],\n",
      "        [ 20.0937,  14.0538,  15.4006, -18.0419,  19.2467, -14.1228],\n",
      "        [ 20.1601,  14.3323,  15.6151, -17.7529,  19.1539, -13.6344],\n",
      "        [ 19.4798,  14.2809,  15.5685, -18.1415,  19.3663, -14.1464]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.977074146270752\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4690, 14.0606, 15.0783],\n",
      "        [19.9286, 14.0159, 15.4820],\n",
      "        [19.8205, 14.3978, 15.3910],\n",
      "        [19.9943, 14.2066, 15.5279],\n",
      "        [19.9653, 14.4096, 15.6085],\n",
      "        [19.4877, 14.0466, 15.3890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5217,  19.2094, -14.0285],\n",
      "        [-18.0594,  19.1477, -14.3470],\n",
      "        [-17.6331,  19.1880, -14.1406],\n",
      "        [-17.5702,  18.9620, -13.7046],\n",
      "        [-17.4672,  18.7289, -13.8263],\n",
      "        [-18.1979,  19.5888, -14.2056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4690,  14.0606,  15.0783, -17.5217,  19.2094, -14.0285],\n",
      "        [ 19.9286,  14.0159,  15.4820, -18.0594,  19.1477, -14.3470],\n",
      "        [ 19.8205,  14.3978,  15.3910, -17.6331,  19.1880, -14.1406],\n",
      "        [ 19.9943,  14.2066,  15.5279, -17.5702,  18.9620, -13.7046],\n",
      "        [ 19.9653,  14.4096,  15.6085, -17.4672,  18.7289, -13.8263],\n",
      "        [ 19.4877,  14.0466,  15.3890, -18.1979,  19.5888, -14.2056]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9209237098693848\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9887, 14.3537, 15.7710],\n",
      "        [19.9156, 14.0555, 15.5410],\n",
      "        [19.8513, 14.3460, 15.8319],\n",
      "        [19.4534, 14.0944, 14.9784],\n",
      "        [19.8150, 14.4643, 15.1960],\n",
      "        [20.0628, 14.3462, 15.6957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4767, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1180,  19.3151, -14.1788],\n",
      "        [-17.7709,  19.1675, -14.0019],\n",
      "        [-18.1337,  19.1934, -14.2351],\n",
      "        [-17.8930,  19.1045, -13.8861],\n",
      "        [-17.4475,  19.1964, -13.9274],\n",
      "        [-18.0927,  19.3262, -14.3465]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9887,  14.3537,  15.7710, -18.1180,  19.3151, -14.1788],\n",
      "        [ 19.9156,  14.0555,  15.5410, -17.7709,  19.1675, -14.0019],\n",
      "        [ 19.8513,  14.3460,  15.8319, -18.1337,  19.1934, -14.2351],\n",
      "        [ 19.4534,  14.0944,  14.9784, -17.8930,  19.1045, -13.8861],\n",
      "        [ 19.8150,  14.4643,  15.1960, -17.4475,  19.1964, -13.9274],\n",
      "        [ 20.0628,  14.3462,  15.6957, -18.0927,  19.3262, -14.3465]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.996835231781006\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5669, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9129, 14.3248, 15.5822],\n",
      "        [20.2344, 14.2228, 15.8842],\n",
      "        [19.6666, 14.2189, 15.6577],\n",
      "        [19.4114, 14.2709, 15.5652],\n",
      "        [19.5906, 14.0524, 14.9500],\n",
      "        [19.8520, 14.3369, 15.1766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9568, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5184,  19.0960, -14.0880],\n",
      "        [-17.3288,  19.2130, -13.8701],\n",
      "        [-17.9950,  19.2351, -14.1027],\n",
      "        [-17.9518,  18.6514, -13.7245],\n",
      "        [-17.5650,  19.2105, -14.0119],\n",
      "        [-18.1281,  18.9578, -14.0922]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9129,  14.3248,  15.5822, -17.5184,  19.0960, -14.0880],\n",
      "        [ 20.2344,  14.2228,  15.8842, -17.3288,  19.2130, -13.8701],\n",
      "        [ 19.6666,  14.2189,  15.6577, -17.9950,  19.2351, -14.1027],\n",
      "        [ 19.4114,  14.2709,  15.5652, -17.9518,  18.6514, -13.7245],\n",
      "        [ 19.5906,  14.0524,  14.9500, -17.5650,  19.2105, -14.0119],\n",
      "        [ 19.8520,  14.3369,  15.1766, -18.1281,  18.9578, -14.0922]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9654600620269775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7162, 14.1563, 15.6797],\n",
      "        [20.0602, 14.8602, 15.6860],\n",
      "        [20.0059, 14.3516, 15.8865],\n",
      "        [19.6998, 14.0218, 15.0930],\n",
      "        [20.0070, 14.3598, 15.7370],\n",
      "        [19.3362, 13.8017, 15.4278]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.4398,  18.5317, -14.0126],\n",
      "        [-18.1991,  19.1163, -14.0192],\n",
      "        [-17.8732,  19.0928, -14.2680],\n",
      "        [-18.2600,  19.4957, -14.3530],\n",
      "        [-17.8655,  19.2735, -13.9814],\n",
      "        [-17.9555,  19.5761, -13.9761]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7162,  14.1563,  15.6797, -17.4398,  18.5317, -14.0126],\n",
      "        [ 20.0602,  14.8602,  15.6860, -18.1991,  19.1163, -14.0192],\n",
      "        [ 20.0059,  14.3516,  15.8865, -17.8732,  19.0928, -14.2680],\n",
      "        [ 19.6998,  14.0218,  15.0930, -18.2600,  19.4957, -14.3530],\n",
      "        [ 20.0070,  14.3598,  15.7370, -17.8655,  19.2735, -13.9814],\n",
      "        [ 19.3362,  13.8017,  15.4278, -17.9555,  19.5761, -13.9761]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9391531944274902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7832, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.4703, 14.2923, 15.1586],\n",
      "        [20.1710, 14.3507, 15.7688],\n",
      "        [19.9065, 14.3671, 15.4749],\n",
      "        [19.6871, 14.4444, 15.2430],\n",
      "        [20.1816, 14.4097, 15.4970],\n",
      "        [19.4299, 13.9574, 15.1825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7837, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7036,  19.2450, -13.7465],\n",
      "        [-17.9548,  19.4409, -14.4192],\n",
      "        [-17.3407,  19.0757, -13.9021],\n",
      "        [-17.2661,  18.5071, -13.3879],\n",
      "        [-17.9383,  19.3120, -14.2021],\n",
      "        [-17.5441,  19.0111, -13.8396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.4703,  14.2923,  15.1586, -17.7036,  19.2450, -13.7465],\n",
      "        [ 20.1710,  14.3507,  15.7688, -17.9548,  19.4409, -14.4192],\n",
      "        [ 19.9065,  14.3671,  15.4749, -17.3407,  19.0757, -13.9021],\n",
      "        [ 19.6871,  14.4444,  15.2430, -17.2661,  18.5071, -13.3879],\n",
      "        [ 20.1816,  14.4097,  15.4970, -17.9383,  19.3120, -14.2021],\n",
      "        [ 19.4299,  13.9574,  15.1825, -17.5441,  19.0111, -13.8396]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9351279735565186\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9851, 14.4199, 15.7842],\n",
      "        [19.5369, 13.3815, 15.3366],\n",
      "        [19.8877, 14.4631, 16.0757],\n",
      "        [19.8691, 14.0581, 15.5086],\n",
      "        [20.2248, 14.5690, 15.4846],\n",
      "        [19.3114, 14.1095, 15.4904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.3646,  18.9866, -13.7523],\n",
      "        [-17.4424,  19.0344, -13.9046],\n",
      "        [-17.7790,  19.0789, -14.1324],\n",
      "        [-18.0477,  19.0475, -13.8975],\n",
      "        [-18.0201,  19.7376, -14.4539],\n",
      "        [-17.7268,  19.1537, -13.4597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9851,  14.4199,  15.7842, -17.3646,  18.9866, -13.7523],\n",
      "        [ 19.5369,  13.3815,  15.3366, -17.4424,  19.0344, -13.9046],\n",
      "        [ 19.8877,  14.4631,  16.0757, -17.7790,  19.0789, -14.1324],\n",
      "        [ 19.8691,  14.0581,  15.5086, -18.0477,  19.0475, -13.8975],\n",
      "        [ 20.2248,  14.5690,  15.4846, -18.0201,  19.7376, -14.4539],\n",
      "        [ 19.3114,  14.1095,  15.4904, -17.7268,  19.1537, -13.4597]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.9695184230804443\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9240, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7102, 14.2751, 15.6994],\n",
      "        [19.5710, 14.0320, 15.0482],\n",
      "        [19.8810, 14.2692, 15.7102],\n",
      "        [19.3366, 13.7192, 15.1502],\n",
      "        [19.8308, 14.0370, 15.4209],\n",
      "        [19.6033, 14.2678, 15.3815]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8352,  18.8388, -14.3209],\n",
      "        [-17.8006,  19.5017, -14.1467],\n",
      "        [-17.5109,  19.3245, -14.3912],\n",
      "        [-17.4684,  18.6758, -13.6412],\n",
      "        [-17.7678,  19.2552, -14.1223],\n",
      "        [-17.4765,  19.1538, -13.7125]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7102,  14.2751,  15.6994, -17.8352,  18.8388, -14.3209],\n",
      "        [ 19.5710,  14.0320,  15.0482, -17.8006,  19.5017, -14.1467],\n",
      "        [ 19.8810,  14.2692,  15.7102, -17.5109,  19.3245, -14.3912],\n",
      "        [ 19.3366,  13.7192,  15.1502, -17.4684,  18.6758, -13.6412],\n",
      "        [ 19.8308,  14.0370,  15.4209, -17.7678,  19.2552, -14.1223],\n",
      "        [ 19.6033,  14.2678,  15.3815, -17.4765,  19.1538, -13.7125]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.969735860824585\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0140, 14.2533, 15.6941],\n",
      "        [19.6707, 13.9968, 15.3653],\n",
      "        [19.6102, 13.8056, 15.1428],\n",
      "        [19.5441, 14.0952, 15.3571],\n",
      "        [19.6194, 14.3335, 15.3525],\n",
      "        [20.2505, 14.6476, 15.5914]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4480, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9648,  19.1506, -14.4544],\n",
      "        [-17.8509,  19.3724, -14.0389],\n",
      "        [-17.8454,  19.0872, -13.9223],\n",
      "        [-17.7064,  18.8561, -14.1914],\n",
      "        [-18.0466,  18.7281, -14.0901],\n",
      "        [-17.8211,  19.0809, -14.3560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0140,  14.2533,  15.6941, -17.9648,  19.1506, -14.4544],\n",
      "        [ 19.6707,  13.9968,  15.3653, -17.8509,  19.3724, -14.0389],\n",
      "        [ 19.6102,  13.8056,  15.1428, -17.8454,  19.0872, -13.9223],\n",
      "        [ 19.5441,  14.0952,  15.3571, -17.7064,  18.8561, -14.1914],\n",
      "        [ 19.6194,  14.3335,  15.3525, -18.0466,  18.7281, -14.0901],\n",
      "        [ 20.2505,  14.6476,  15.5914, -17.8211,  19.0809, -14.3560]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9976906776428223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6412, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0285, 14.6950, 15.4941],\n",
      "        [19.9336, 14.1791, 15.4478],\n",
      "        [20.0995, 14.4572, 15.6759],\n",
      "        [19.8916, 14.0945, 15.5798],\n",
      "        [19.6241, 14.2174, 15.4097],\n",
      "        [19.9513, 14.6246, 15.5164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7694, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5359,  19.7383, -14.3568],\n",
      "        [-17.8807,  19.6942, -14.3040],\n",
      "        [-17.4592,  19.1304, -14.1704],\n",
      "        [-17.6961,  19.1737, -13.8883],\n",
      "        [-18.2031,  19.9926, -14.0632],\n",
      "        [-17.7688,  19.3972, -14.0769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0285,  14.6950,  15.4941, -18.5359,  19.7383, -14.3568],\n",
      "        [ 19.9336,  14.1791,  15.4478, -17.8807,  19.6942, -14.3040],\n",
      "        [ 20.0995,  14.4572,  15.6759, -17.4592,  19.1304, -14.1704],\n",
      "        [ 19.8916,  14.0945,  15.5798, -17.6961,  19.1737, -13.8883],\n",
      "        [ 19.6241,  14.2174,  15.4097, -18.2031,  19.9926, -14.0632],\n",
      "        [ 19.9513,  14.6246,  15.5164, -17.7688,  19.3972, -14.0769]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.031248092651367\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3039, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9947, 14.5250, 16.0227],\n",
      "        [20.0062, 14.0934, 15.3920],\n",
      "        [20.1176, 14.7815, 15.4969],\n",
      "        [19.1121, 13.6359, 14.9945],\n",
      "        [19.8106, 14.1923, 15.5488],\n",
      "        [18.8515, 13.9261, 14.8645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2483, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0749,  19.4310, -14.3149],\n",
      "        [-18.1117,  19.1497, -13.8393],\n",
      "        [-18.3112,  19.1989, -14.2853],\n",
      "        [-17.6570,  18.9571, -14.1267],\n",
      "        [-17.9214,  19.0283, -13.8262],\n",
      "        [-17.5750,  19.0159, -14.1425]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9947,  14.5250,  16.0227, -18.0749,  19.4310, -14.3149],\n",
      "        [ 20.0062,  14.0934,  15.3920, -18.1117,  19.1497, -13.8393],\n",
      "        [ 20.1176,  14.7815,  15.4969, -18.3112,  19.1989, -14.2853],\n",
      "        [ 19.1121,  13.6359,  14.9945, -17.6570,  18.9571, -14.1267],\n",
      "        [ 19.8106,  14.1923,  15.5488, -17.9214,  19.0283, -13.8262],\n",
      "        [ 18.8515,  13.9261,  14.8645, -17.5750,  19.0159, -14.1425]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0254931449890137\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1876, 14.7265, 15.5371],\n",
      "        [19.5787, 14.3768, 15.9367],\n",
      "        [19.6876, 14.3730, 15.2353],\n",
      "        [20.2428, 14.3022, 15.9528],\n",
      "        [19.7798, 14.4781, 16.0112],\n",
      "        [19.3783, 13.7789, 15.4887]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.0896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6409,  19.3865, -14.0320],\n",
      "        [-17.9210,  19.8262, -14.2472],\n",
      "        [-17.8689,  19.0118, -14.5230],\n",
      "        [-17.6832,  18.9402, -13.8698],\n",
      "        [-17.9132,  19.3426, -13.9592],\n",
      "        [-18.0609,  19.3651, -14.3733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1876,  14.7265,  15.5371, -17.6409,  19.3865, -14.0320],\n",
      "        [ 19.5787,  14.3768,  15.9367, -17.9210,  19.8262, -14.2472],\n",
      "        [ 19.6876,  14.3730,  15.2353, -17.8689,  19.0118, -14.5230],\n",
      "        [ 20.2428,  14.3022,  15.9528, -17.6832,  18.9402, -13.8698],\n",
      "        [ 19.7798,  14.4781,  16.0112, -17.9132,  19.3426, -13.9592],\n",
      "        [ 19.3783,  13.7789,  15.4887, -18.0609,  19.3651, -14.3733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0063514709472656\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9222, 14.1857, 15.7303],\n",
      "        [20.2540, 14.5264, 15.9738],\n",
      "        [20.1016, 14.1145, 15.4070],\n",
      "        [19.8450, 14.3193, 15.5167],\n",
      "        [19.4687, 14.1598, 15.3662],\n",
      "        [19.8174, 14.0523, 15.2498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1729,  19.4118, -14.4492],\n",
      "        [-18.1428,  18.8893, -13.8173],\n",
      "        [-18.0692,  19.3413, -14.4537],\n",
      "        [-17.4931,  19.4685, -13.9205],\n",
      "        [-17.4995,  19.3383, -13.8473],\n",
      "        [-18.1698,  19.1291, -14.1478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9222,  14.1857,  15.7303, -18.1729,  19.4118, -14.4492],\n",
      "        [ 20.2540,  14.5264,  15.9738, -18.1428,  18.8893, -13.8173],\n",
      "        [ 20.1016,  14.1145,  15.4070, -18.0692,  19.3413, -14.4537],\n",
      "        [ 19.8450,  14.3193,  15.5167, -17.4931,  19.4685, -13.9205],\n",
      "        [ 19.4687,  14.1598,  15.3662, -17.4995,  19.3383, -13.8473],\n",
      "        [ 19.8174,  14.0523,  15.2498, -18.1698,  19.1291, -14.1478]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.0106008052825928\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1990, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8325, 14.3057, 16.0878],\n",
      "        [19.8772, 14.4936, 15.6021],\n",
      "        [19.9989, 14.2531, 15.8124],\n",
      "        [19.3591, 14.3858, 15.2714],\n",
      "        [19.8729, 14.4059, 15.2631],\n",
      "        [19.5479, 14.1808, 15.4564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.3634, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8340,  18.9060, -14.2112],\n",
      "        [-17.5067,  18.9030, -13.9949],\n",
      "        [-17.7826,  19.4379, -14.6759],\n",
      "        [-17.5562,  18.7309, -13.7142],\n",
      "        [-17.9296,  19.0334, -14.1521],\n",
      "        [-18.2567,  19.4101, -14.2812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8325,  14.3057,  16.0878, -17.8340,  18.9060, -14.2112],\n",
      "        [ 19.8772,  14.4936,  15.6021, -17.5067,  18.9030, -13.9949],\n",
      "        [ 19.9989,  14.2531,  15.8124, -17.7826,  19.4379, -14.6759],\n",
      "        [ 19.3591,  14.3858,  15.2714, -17.5562,  18.7309, -13.7142],\n",
      "        [ 19.8729,  14.4059,  15.2631, -17.9296,  19.0334, -14.1521],\n",
      "        [ 19.5479,  14.1808,  15.4564, -18.2567,  19.4101, -14.2812]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9975483417510986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3115, 13.5899, 15.3105],\n",
      "        [19.7633, 14.3258, 15.3291],\n",
      "        [19.5078, 13.7295, 15.1841],\n",
      "        [19.5065, 13.8365, 15.4481],\n",
      "        [19.2659, 13.8947, 15.1732],\n",
      "        [19.6837, 14.2560, 15.6199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9386, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8165,  19.8246, -14.4015],\n",
      "        [-18.1914,  19.1530, -14.3151],\n",
      "        [-17.8573,  19.2394, -14.0549],\n",
      "        [-17.8799,  19.6696, -13.9227],\n",
      "        [-17.7658,  19.5048, -14.3295],\n",
      "        [-17.9824,  19.0339, -14.2154]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3115,  13.5899,  15.3105, -17.8165,  19.8246, -14.4015],\n",
      "        [ 19.7633,  14.3258,  15.3291, -18.1914,  19.1530, -14.3151],\n",
      "        [ 19.5078,  13.7295,  15.1841, -17.8573,  19.2394, -14.0549],\n",
      "        [ 19.5065,  13.8365,  15.4481, -17.8799,  19.6696, -13.9227],\n",
      "        [ 19.2659,  13.8947,  15.1732, -17.7658,  19.5048, -14.3295],\n",
      "        [ 19.6837,  14.2560,  15.6199, -17.9824,  19.0339, -14.2154]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.958111047744751\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8709, 13.9875, 15.4280],\n",
      "        [20.0172, 14.3719, 15.8321],\n",
      "        [19.8874, 14.3644, 15.5613],\n",
      "        [20.2437, 14.3001, 15.6392],\n",
      "        [19.8858, 14.7791, 15.6471],\n",
      "        [19.5456, 13.8939, 15.6535]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0682,  19.0367, -13.9817],\n",
      "        [-17.9764,  19.6449, -14.3942],\n",
      "        [-17.8154,  19.1203, -14.3134],\n",
      "        [-18.0469,  18.9054, -13.7655],\n",
      "        [-18.4014,  19.3221, -14.4042],\n",
      "        [-17.7808,  18.9057, -13.9571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8709,  13.9875,  15.4280, -18.0682,  19.0367, -13.9817],\n",
      "        [ 20.0172,  14.3719,  15.8321, -17.9764,  19.6449, -14.3942],\n",
      "        [ 19.8874,  14.3644,  15.5613, -17.8154,  19.1203, -14.3134],\n",
      "        [ 20.2437,  14.3001,  15.6392, -18.0469,  18.9054, -13.7655],\n",
      "        [ 19.8858,  14.7791,  15.6471, -18.4014,  19.3221, -14.4042],\n",
      "        [ 19.5456,  13.8939,  15.6535, -17.7808,  18.9057, -13.9571]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.975853443145752\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1094, 14.6486, 15.4036],\n",
      "        [20.0071, 14.3540, 15.6488],\n",
      "        [19.6908, 14.2884, 15.6773],\n",
      "        [19.7877, 14.4275, 15.9053],\n",
      "        [19.9286, 14.3464, 15.5709],\n",
      "        [19.7384, 13.8807, 15.2530]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.5566, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0348,  19.7816, -14.2180],\n",
      "        [-18.0150,  19.0533, -14.4536],\n",
      "        [-18.0854,  19.0489, -14.5557],\n",
      "        [-18.7990,  19.7254, -15.0439],\n",
      "        [-17.9601,  19.4834, -14.2614],\n",
      "        [-18.1725,  19.1800, -14.0818]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1094,  14.6486,  15.4036, -18.0348,  19.7816, -14.2180],\n",
      "        [ 20.0071,  14.3540,  15.6488, -18.0150,  19.0533, -14.4536],\n",
      "        [ 19.6908,  14.2884,  15.6773, -18.0854,  19.0489, -14.5557],\n",
      "        [ 19.7877,  14.4275,  15.9053, -18.7990,  19.7254, -15.0439],\n",
      "        [ 19.9286,  14.3464,  15.5709, -17.9601,  19.4834, -14.2614],\n",
      "        [ 19.7384,  13.8807,  15.2530, -18.1725,  19.1800, -14.0818]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.026514768600464\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6279, 14.4844, 15.8282],\n",
      "        [19.6549, 14.4139, 15.6661],\n",
      "        [19.6355, 14.3680, 16.0348],\n",
      "        [19.6556, 14.2053, 15.3495],\n",
      "        [19.8284, 14.1665, 15.5066],\n",
      "        [19.8997, 14.6526, 15.5903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1630,  19.4444, -13.9974],\n",
      "        [-18.0294,  19.3985, -14.4285],\n",
      "        [-18.0654,  19.1280, -14.3972],\n",
      "        [-17.8200,  19.3277, -14.1687],\n",
      "        [-17.7428,  19.0350, -13.8589],\n",
      "        [-17.6311,  19.1329, -14.3247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6279,  14.4844,  15.8282, -18.1630,  19.4444, -13.9974],\n",
      "        [ 19.6549,  14.4139,  15.6661, -18.0294,  19.3985, -14.4285],\n",
      "        [ 19.6355,  14.3680,  16.0348, -18.0654,  19.1280, -14.3972],\n",
      "        [ 19.6556,  14.2053,  15.3495, -17.8200,  19.3277, -14.1687],\n",
      "        [ 19.8284,  14.1665,  15.5066, -17.7428,  19.0350, -13.8589],\n",
      "        [ 19.8997,  14.6526,  15.5903, -17.6311,  19.1329, -14.3247]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0076239109039307\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0811, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1465, 14.2655, 15.6845],\n",
      "        [19.4778, 14.4955, 15.5468],\n",
      "        [19.8439, 14.0597, 15.3606],\n",
      "        [19.8203, 14.2014, 15.2789],\n",
      "        [19.9923, 14.1951, 15.1461],\n",
      "        [19.9446, 14.8150, 15.4390]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0068, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2919,  19.5778, -14.4010],\n",
      "        [-18.6737,  19.8707, -14.7817],\n",
      "        [-17.7561,  19.1287, -14.1192],\n",
      "        [-17.5575,  19.5112, -14.6561],\n",
      "        [-17.6185,  18.9508, -13.9303],\n",
      "        [-17.8670,  19.1064, -14.1334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1465,  14.2655,  15.6845, -18.2919,  19.5778, -14.4010],\n",
      "        [ 19.4778,  14.4955,  15.5468, -18.6737,  19.8707, -14.7817],\n",
      "        [ 19.8439,  14.0597,  15.3606, -17.7561,  19.1287, -14.1192],\n",
      "        [ 19.8203,  14.2014,  15.2789, -17.5575,  19.5112, -14.6561],\n",
      "        [ 19.9923,  14.1951,  15.1461, -17.6185,  18.9508, -13.9303],\n",
      "        [ 19.9446,  14.8150,  15.4390, -17.8670,  19.1064, -14.1334]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.035569667816162\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.5976, 14.4338, 15.6961],\n",
      "        [20.0677, 14.3821, 15.7926],\n",
      "        [20.1732, 14.5567, 15.7506],\n",
      "        [19.6911, 14.2339, 15.3697],\n",
      "        [19.3707, 14.0192, 15.3042],\n",
      "        [19.8334, 14.2555, 15.8847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.3525, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7595,  19.2911, -14.3788],\n",
      "        [-18.0443,  19.2783, -14.3641],\n",
      "        [-18.1665,  19.3804, -14.1326],\n",
      "        [-17.7418,  18.9858, -14.3598],\n",
      "        [-17.6806,  19.1689, -14.0352],\n",
      "        [-17.7624,  19.2512, -14.0557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.5976,  14.4338,  15.6961, -17.7595,  19.2911, -14.3788],\n",
      "        [ 20.0677,  14.3821,  15.7926, -18.0443,  19.2783, -14.3641],\n",
      "        [ 20.1732,  14.5567,  15.7506, -18.1665,  19.3804, -14.1326],\n",
      "        [ 19.6911,  14.2339,  15.3697, -17.7418,  18.9858, -14.3598],\n",
      "        [ 19.3707,  14.0192,  15.3042, -17.6806,  19.1689, -14.0352],\n",
      "        [ 19.8334,  14.2555,  15.8847, -17.7624,  19.2512, -14.0557]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9959073066711426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3768, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.3178, 14.1937, 14.7857],\n",
      "        [19.8938, 14.3716, 15.4237],\n",
      "        [19.7223, 14.5977, 15.8611],\n",
      "        [19.7218, 14.3744, 15.6442],\n",
      "        [19.6833, 14.2332, 15.7019],\n",
      "        [19.9212, 14.4974, 15.4048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5528,  19.5261, -14.0570],\n",
      "        [-17.9572,  18.9035, -14.2766],\n",
      "        [-18.0924,  19.3989, -13.9658],\n",
      "        [-18.4521,  19.9150, -14.5234],\n",
      "        [-17.4298,  18.7477, -13.9666],\n",
      "        [-17.7510,  19.1568, -14.1479]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.3178,  14.1937,  14.7857, -17.5528,  19.5261, -14.0570],\n",
      "        [ 19.8938,  14.3716,  15.4237, -17.9572,  18.9035, -14.2766],\n",
      "        [ 19.7223,  14.5977,  15.8611, -18.0924,  19.3989, -13.9658],\n",
      "        [ 19.7218,  14.3744,  15.6442, -18.4521,  19.9150, -14.5234],\n",
      "        [ 19.6833,  14.2332,  15.7019, -17.4298,  18.7477, -13.9666],\n",
      "        [ 19.9212,  14.4974,  15.4048, -17.7510,  19.1568, -14.1479]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.9419641494750977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8171, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0414, 14.5565, 15.7961],\n",
      "        [19.9194, 14.0901, 15.6962],\n",
      "        [19.9466, 14.6332, 15.4723],\n",
      "        [20.1509, 14.7250, 15.6487],\n",
      "        [20.0686, 14.4711, 15.4288],\n",
      "        [19.6716, 14.5540, 15.6438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9606, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5492,  18.9974, -13.7864],\n",
      "        [-17.8212,  18.7540, -14.0567],\n",
      "        [-17.8439,  19.0906, -14.1958],\n",
      "        [-17.7358,  19.4257, -14.2814],\n",
      "        [-17.5425,  19.0872, -14.1010],\n",
      "        [-18.0662,  19.2737, -13.9915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0414,  14.5565,  15.7961, -17.5492,  18.9974, -13.7864],\n",
      "        [ 19.9194,  14.0901,  15.6962, -17.8212,  18.7540, -14.0567],\n",
      "        [ 19.9466,  14.6332,  15.4723, -17.8439,  19.0906, -14.1958],\n",
      "        [ 20.1509,  14.7250,  15.6487, -17.7358,  19.4257, -14.2814],\n",
      "        [ 20.0686,  14.4711,  15.4288, -17.5425,  19.0872, -14.1010],\n",
      "        [ 19.6716,  14.5540,  15.6438, -18.0662,  19.2737, -13.9915]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.001282215118408\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1902, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7173, 14.8545, 16.1009],\n",
      "        [19.7563, 13.9785, 15.4486],\n",
      "        [19.8509, 14.2322, 15.5772],\n",
      "        [20.2253, 14.7435, 15.6578],\n",
      "        [19.3192, 14.1952, 15.4163],\n",
      "        [19.8820, 14.5497, 15.6493]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.3012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5572,  19.4927, -14.5254],\n",
      "        [-18.0066,  18.7430, -14.4302],\n",
      "        [-17.9276,  19.0586, -14.3916],\n",
      "        [-17.4889,  18.9287, -13.9700],\n",
      "        [-17.7342,  18.8152, -13.8979],\n",
      "        [-17.6646,  19.2261, -14.5426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7173,  14.8545,  16.1009, -18.5572,  19.4927, -14.5254],\n",
      "        [ 19.7563,  13.9785,  15.4486, -18.0066,  18.7430, -14.4302],\n",
      "        [ 19.8509,  14.2322,  15.5772, -17.9276,  19.0586, -14.3916],\n",
      "        [ 20.2253,  14.7435,  15.6578, -17.4889,  18.9287, -13.9700],\n",
      "        [ 19.3192,  14.1952,  15.4163, -17.7342,  18.8152, -13.8979],\n",
      "        [ 19.8820,  14.5497,  15.6493, -17.6646,  19.2261, -14.5426]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1022627353668213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6153, 14.1939, 15.7546],\n",
      "        [20.1993, 14.5764, 15.4283],\n",
      "        [19.8915, 14.3403, 15.7697],\n",
      "        [20.2812, 14.7800, 16.2534],\n",
      "        [19.8143, 14.5233, 15.5086],\n",
      "        [19.8842, 14.1531, 15.3178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0304, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5797,  19.0793, -14.1114],\n",
      "        [-18.2453,  19.4153, -14.4194],\n",
      "        [-17.9904,  19.1543, -14.0465],\n",
      "        [-18.0774,  19.7011, -14.3008],\n",
      "        [-17.7968,  19.4042, -14.2232],\n",
      "        [-17.8689,  19.5298, -14.3228]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6153,  14.1939,  15.7546, -17.5797,  19.0793, -14.1114],\n",
      "        [ 20.1993,  14.5764,  15.4283, -18.2453,  19.4153, -14.4194],\n",
      "        [ 19.8915,  14.3403,  15.7697, -17.9904,  19.1543, -14.0465],\n",
      "        [ 20.2812,  14.7800,  16.2534, -18.0774,  19.7011, -14.3008],\n",
      "        [ 19.8143,  14.5233,  15.5086, -17.7968,  19.4042, -14.2232],\n",
      "        [ 19.8842,  14.1531,  15.3178, -17.8689,  19.5298, -14.3228]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.983335018157959\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0882, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1830, 14.2673, 15.2310],\n",
      "        [19.8175, 14.6222, 15.4750],\n",
      "        [20.2564, 14.7542, 15.6243],\n",
      "        [19.5074, 14.2390, 15.8225],\n",
      "        [19.9092, 14.4531, 15.5884],\n",
      "        [19.7627, 14.2658, 15.8731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.8823,  19.0999, -14.4296],\n",
      "        [-17.7972,  19.2040, -14.1369],\n",
      "        [-17.7996,  19.0338, -14.3991],\n",
      "        [-17.9174,  19.8499, -14.4072],\n",
      "        [-17.9114,  19.6950, -14.5034],\n",
      "        [-18.0139,  19.2055, -14.6035]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1830,  14.2673,  15.2310, -17.8823,  19.0999, -14.4296],\n",
      "        [ 19.8175,  14.6222,  15.4750, -17.7972,  19.2040, -14.1369],\n",
      "        [ 20.2564,  14.7542,  15.6243, -17.7996,  19.0338, -14.3991],\n",
      "        [ 19.5074,  14.2390,  15.8225, -17.9174,  19.8499, -14.4072],\n",
      "        [ 19.9092,  14.4531,  15.5884, -17.9114,  19.6950, -14.5034],\n",
      "        [ 19.7627,  14.2658,  15.8731, -18.0139,  19.2055, -14.6035]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.962273359298706\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6050, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2042, 14.4542, 15.7437],\n",
      "        [20.0521, 14.2855, 15.7645],\n",
      "        [19.8036, 14.2712, 15.8861],\n",
      "        [19.8798, 14.1373, 15.8003],\n",
      "        [19.8227, 14.6387, 15.8288],\n",
      "        [19.7773, 14.5271, 15.6263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9856, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.6449,  19.6029, -14.3668],\n",
      "        [-18.1838,  19.7103, -14.4939],\n",
      "        [-18.4812,  20.0523, -14.9537],\n",
      "        [-17.9642,  19.3233, -13.8137],\n",
      "        [-17.9219,  19.2426, -14.4394],\n",
      "        [-18.1471,  19.1666, -14.3057]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2042,  14.4542,  15.7437, -17.6449,  19.6029, -14.3668],\n",
      "        [ 20.0521,  14.2855,  15.7645, -18.1838,  19.7103, -14.4939],\n",
      "        [ 19.8036,  14.2712,  15.8861, -18.4812,  20.0523, -14.9537],\n",
      "        [ 19.8798,  14.1373,  15.8003, -17.9642,  19.3233, -13.8137],\n",
      "        [ 19.8227,  14.6387,  15.8288, -17.9219,  19.2426, -14.4394],\n",
      "        [ 19.7773,  14.5271,  15.6263, -18.1471,  19.1666, -14.3057]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0385992527008057\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8217, 14.0679, 15.2940],\n",
      "        [19.5095, 14.0482, 15.3182],\n",
      "        [19.9632, 14.4763, 15.8653],\n",
      "        [19.4091, 13.8954, 15.4595],\n",
      "        [20.0248, 14.5190, 15.7440],\n",
      "        [20.0169, 14.2358, 16.0690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5733, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.5571,  19.1966, -13.9830],\n",
      "        [-17.9976,  19.3572, -14.2310],\n",
      "        [-17.8666,  19.2700, -14.3391],\n",
      "        [-17.8780,  19.1647, -14.1934],\n",
      "        [-18.3168,  19.8542, -14.5465],\n",
      "        [-17.7781,  19.7106, -14.3814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8217,  14.0679,  15.2940, -17.5571,  19.1966, -13.9830],\n",
      "        [ 19.5095,  14.0482,  15.3182, -17.9976,  19.3572, -14.2310],\n",
      "        [ 19.9632,  14.4763,  15.8653, -17.8666,  19.2700, -14.3391],\n",
      "        [ 19.4091,  13.8954,  15.4595, -17.8780,  19.1647, -14.1934],\n",
      "        [ 20.0248,  14.5190,  15.7440, -18.3168,  19.8542, -14.5465],\n",
      "        [ 20.0169,  14.2358,  16.0690, -17.7781,  19.7106, -14.3814]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-2.977303981781006\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9224, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1061, 14.2853, 15.9986],\n",
      "        [19.7072, 14.0601, 15.5125],\n",
      "        [19.9220, 14.3387, 15.8242],\n",
      "        [19.6037, 14.5714, 15.7053],\n",
      "        [19.4117, 14.2114, 15.5188],\n",
      "        [20.2811, 14.8678, 16.1602]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3380,  19.3825, -14.4081],\n",
      "        [-17.7246,  18.9475, -13.7180],\n",
      "        [-18.1711,  19.2784, -14.0933],\n",
      "        [-17.9635,  19.4804, -14.4994],\n",
      "        [-17.9062,  19.4256, -14.5398],\n",
      "        [-17.9582,  19.5487, -14.0102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1061,  14.2853,  15.9986, -18.3380,  19.3825, -14.4081],\n",
      "        [ 19.7072,  14.0601,  15.5125, -17.7246,  18.9475, -13.7180],\n",
      "        [ 19.9220,  14.3387,  15.8242, -18.1711,  19.2784, -14.0933],\n",
      "        [ 19.6037,  14.5714,  15.7053, -17.9635,  19.4804, -14.4994],\n",
      "        [ 19.4117,  14.2114,  15.5188, -17.9062,  19.4256, -14.5398],\n",
      "        [ 20.2811,  14.8678,  16.1602, -17.9582,  19.5487, -14.0102]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.053708553314209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5818, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0036, 14.6306, 15.7453],\n",
      "        [20.1483, 14.7049, 15.7534],\n",
      "        [19.7278, 14.2298, 15.6304],\n",
      "        [20.3655, 14.9187, 15.9548],\n",
      "        [19.6768, 13.6785, 15.2337],\n",
      "        [19.9871, 14.4269, 15.6559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1796, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3377,  19.4863, -14.2758],\n",
      "        [-17.7708,  19.6523, -14.1944],\n",
      "        [-18.0360,  19.2973, -14.4042],\n",
      "        [-18.0791,  19.6946, -14.5433],\n",
      "        [-17.8914,  19.2519, -13.9028],\n",
      "        [-18.0893,  19.9069, -14.4484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0036,  14.6306,  15.7453, -18.3377,  19.4863, -14.2758],\n",
      "        [ 20.1483,  14.7049,  15.7534, -17.7708,  19.6523, -14.1944],\n",
      "        [ 19.7278,  14.2298,  15.6304, -18.0360,  19.2973, -14.4042],\n",
      "        [ 20.3655,  14.9187,  15.9548, -18.0791,  19.6946, -14.5433],\n",
      "        [ 19.6768,  13.6785,  15.2337, -17.8914,  19.2519, -13.9028],\n",
      "        [ 19.9871,  14.4269,  15.6559, -18.0893,  19.9069, -14.4484]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.050387382507324\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0145, 14.2915, 15.9121],\n",
      "        [20.0342, 14.8153, 15.4367],\n",
      "        [20.0659, 14.8319, 15.6502],\n",
      "        [19.9056, 14.3020, 15.8270],\n",
      "        [20.1162, 14.3897, 15.5468],\n",
      "        [19.1222, 14.2932, 15.4130]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0101,  19.1998, -14.1777],\n",
      "        [-17.6083,  18.8807, -13.6730],\n",
      "        [-17.5023,  18.7462, -14.1481],\n",
      "        [-18.3093,  19.6324, -14.6304],\n",
      "        [-18.0926,  18.9172, -14.0654],\n",
      "        [-18.3189,  19.6870, -14.3525]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0145,  14.2915,  15.9121, -18.0101,  19.1998, -14.1777],\n",
      "        [ 20.0342,  14.8153,  15.4367, -17.6083,  18.8807, -13.6730],\n",
      "        [ 20.0659,  14.8319,  15.6502, -17.5023,  18.7462, -14.1481],\n",
      "        [ 19.9056,  14.3020,  15.8270, -18.3093,  19.6324, -14.6304],\n",
      "        [ 20.1162,  14.3897,  15.5468, -18.0926,  18.9172, -14.0654],\n",
      "        [ 19.1222,  14.2932,  15.4130, -18.3189,  19.6870, -14.3525]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0322394371032715\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4666, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.2837, 13.9714, 14.9158],\n",
      "        [19.5639, 14.3080, 15.0911],\n",
      "        [19.8444, 14.1619, 15.4736],\n",
      "        [20.1933, 14.6151, 15.6863],\n",
      "        [20.0049, 14.3004, 15.5850],\n",
      "        [19.9208, 14.3881, 15.5859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7330,  19.0177, -13.9989],\n",
      "        [-18.3333,  19.8025, -14.4397],\n",
      "        [-17.6808,  19.1930, -13.9868],\n",
      "        [-18.2955,  19.3993, -14.4056],\n",
      "        [-17.9896,  18.8808, -14.1607],\n",
      "        [-17.9480,  19.6987, -14.5283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.2837,  13.9714,  14.9158, -17.7330,  19.0177, -13.9989],\n",
      "        [ 19.5639,  14.3080,  15.0911, -18.3333,  19.8025, -14.4397],\n",
      "        [ 19.8444,  14.1619,  15.4736, -17.6808,  19.1930, -13.9868],\n",
      "        [ 20.1933,  14.6151,  15.6863, -18.2955,  19.3993, -14.4056],\n",
      "        [ 20.0049,  14.3004,  15.5850, -17.9896,  18.8808, -14.1607],\n",
      "        [ 19.9208,  14.3881,  15.5859, -17.9480,  19.6987, -14.5283]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-2.942486047744751\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7012, 14.6914, 16.0968],\n",
      "        [19.6922, 14.0231, 15.3189],\n",
      "        [19.8628, 14.2470, 15.6222],\n",
      "        [20.2539, 14.8969, 15.7119],\n",
      "        [19.6050, 14.2912, 15.7928],\n",
      "        [19.9791, 14.5382, 15.8102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0189, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3834,  19.3301, -14.4054],\n",
      "        [-18.4228,  19.7657, -14.6806],\n",
      "        [-17.6408,  19.5516, -14.3636],\n",
      "        [-18.3411,  19.1115, -14.4662],\n",
      "        [-18.1604,  19.5714, -14.5087],\n",
      "        [-18.0707,  19.5060, -14.6175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7012,  14.6914,  16.0968, -18.3834,  19.3301, -14.4054],\n",
      "        [ 19.6922,  14.0231,  15.3189, -18.4228,  19.7657, -14.6806],\n",
      "        [ 19.8628,  14.2470,  15.6222, -17.6408,  19.5516, -14.3636],\n",
      "        [ 20.2539,  14.8969,  15.7119, -18.3411,  19.1115, -14.4662],\n",
      "        [ 19.6050,  14.2912,  15.7928, -18.1604,  19.5714, -14.5087],\n",
      "        [ 19.9791,  14.5382,  15.8102, -18.0707,  19.5060, -14.6175]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0542640686035156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4172, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6874, 14.2490, 15.7669],\n",
      "        [20.1314, 14.1350, 15.7111],\n",
      "        [20.0489, 14.0648, 15.5594],\n",
      "        [19.6399, 14.7156, 15.9185],\n",
      "        [20.2267, 14.7219, 15.9299],\n",
      "        [20.4471, 14.9093, 16.3259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4825,  19.4010, -14.8636],\n",
      "        [-18.2697,  19.4558, -14.6956],\n",
      "        [-18.2985,  20.0030, -14.7515],\n",
      "        [-18.2496,  19.6800, -14.4909],\n",
      "        [-18.6239,  20.0808, -15.2984],\n",
      "        [-17.9438,  19.2747, -14.2742]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6874,  14.2490,  15.7669, -18.4825,  19.4010, -14.8636],\n",
      "        [ 20.1314,  14.1350,  15.7111, -18.2697,  19.4558, -14.6956],\n",
      "        [ 20.0489,  14.0648,  15.5594, -18.2985,  20.0030, -14.7515],\n",
      "        [ 19.6399,  14.7156,  15.9185, -18.2496,  19.6800, -14.4909],\n",
      "        [ 20.2267,  14.7219,  15.9299, -18.6239,  20.0808, -15.2984],\n",
      "        [ 20.4471,  14.9093,  16.3259, -17.9438,  19.2747, -14.2742]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.044931411743164\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9047, 14.2207, 15.4541],\n",
      "        [19.7530, 14.5691, 15.7444],\n",
      "        [19.8339, 14.4112, 15.6095],\n",
      "        [19.9717, 14.6386, 15.5328],\n",
      "        [19.7366, 14.7762, 15.7521],\n",
      "        [19.5483, 14.0822, 15.4444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.7502, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9795,  19.6058, -14.0777],\n",
      "        [-18.3572,  19.8412, -14.7104],\n",
      "        [-18.4677,  19.4025, -14.3888],\n",
      "        [-17.8801,  19.0170, -14.2308],\n",
      "        [-18.3102,  19.6756, -14.7171],\n",
      "        [-17.8987,  19.1380, -14.3317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9047,  14.2207,  15.4541, -17.9795,  19.6058, -14.0777],\n",
      "        [ 19.7530,  14.5691,  15.7444, -18.3572,  19.8412, -14.7104],\n",
      "        [ 19.8339,  14.4112,  15.6095, -18.4677,  19.4025, -14.3888],\n",
      "        [ 19.9717,  14.6386,  15.5328, -17.8801,  19.0170, -14.2308],\n",
      "        [ 19.7366,  14.7762,  15.7521, -18.3102,  19.6756, -14.7171],\n",
      "        [ 19.5483,  14.0822,  15.4444, -17.8987,  19.1380, -14.3317]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.022977590560913\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6479, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9907, 14.2384, 15.8809],\n",
      "        [20.0980, 14.7355, 16.0718],\n",
      "        [19.5861, 14.5347, 15.5307],\n",
      "        [20.1390, 14.3974, 15.6252],\n",
      "        [19.5946, 14.0799, 15.7490],\n",
      "        [20.5166, 14.8590, 16.0860]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1163,  19.2981, -14.3020],\n",
      "        [-18.0497,  19.7142, -14.6431],\n",
      "        [-18.0423,  19.5963, -14.5347],\n",
      "        [-18.2716,  19.4878, -14.3186],\n",
      "        [-18.0369,  19.1848, -14.4837],\n",
      "        [-18.1437,  19.5049, -14.0697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9907,  14.2384,  15.8809, -18.1163,  19.2981, -14.3020],\n",
      "        [ 20.0980,  14.7355,  16.0718, -18.0497,  19.7142, -14.6431],\n",
      "        [ 19.5861,  14.5347,  15.5307, -18.0423,  19.5963, -14.5347],\n",
      "        [ 20.1390,  14.3974,  15.6252, -18.2716,  19.4878, -14.3186],\n",
      "        [ 19.5946,  14.0799,  15.7490, -18.0369,  19.1848, -14.4837],\n",
      "        [ 20.5166,  14.8590,  16.0860, -18.1437,  19.5049, -14.0697]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.043013334274292\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.4879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1810, 14.8938, 15.8079],\n",
      "        [20.4504, 14.6873, 16.0358],\n",
      "        [20.2577, 14.7776, 15.5994],\n",
      "        [20.5837, 14.5844, 16.0995],\n",
      "        [19.7637, 14.8197, 15.8290],\n",
      "        [20.1278, 14.2855, 15.6652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1312,  19.6524, -14.4833],\n",
      "        [-18.1591,  19.5190, -14.3545],\n",
      "        [-18.4185,  19.8456, -14.5411],\n",
      "        [-18.3380,  19.5004, -14.3286],\n",
      "        [-18.1641,  19.4318, -14.5233],\n",
      "        [-17.8936,  19.2751, -14.0910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1810,  14.8938,  15.8079, -18.1312,  19.6524, -14.4833],\n",
      "        [ 20.4504,  14.6873,  16.0358, -18.1591,  19.5190, -14.3545],\n",
      "        [ 20.2577,  14.7776,  15.5994, -18.4185,  19.8456, -14.5411],\n",
      "        [ 20.5837,  14.5844,  16.0995, -18.3380,  19.5004, -14.3286],\n",
      "        [ 19.7637,  14.8197,  15.8290, -18.1641,  19.4318, -14.5233],\n",
      "        [ 20.1278,  14.2855,  15.6652, -17.8936,  19.2751, -14.0910]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.079758882522583\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4795, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8951, 14.4793, 15.5412],\n",
      "        [20.0551, 14.6998, 16.0339],\n",
      "        [19.9897, 14.7167, 15.7840],\n",
      "        [20.1037, 14.3180, 15.7908],\n",
      "        [19.5560, 14.1288, 15.6453],\n",
      "        [20.3032, 14.6407, 15.8267]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1057, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0013,  19.4554, -14.5143],\n",
      "        [-18.2122,  19.7537, -14.5838],\n",
      "        [-17.6410,  19.5327, -14.4492],\n",
      "        [-18.2699,  19.3692, -14.0026],\n",
      "        [-17.6962,  19.4481, -14.2757],\n",
      "        [-18.1376,  19.6226, -14.7521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8951,  14.4793,  15.5412, -18.0013,  19.4554, -14.5143],\n",
      "        [ 20.0551,  14.6998,  16.0339, -18.2122,  19.7537, -14.5838],\n",
      "        [ 19.9897,  14.7167,  15.7840, -17.6410,  19.5327, -14.4492],\n",
      "        [ 20.1037,  14.3180,  15.7908, -18.2699,  19.3692, -14.0026],\n",
      "        [ 19.5560,  14.1288,  15.6453, -17.6962,  19.4481, -14.2757],\n",
      "        [ 20.3032,  14.6407,  15.8267, -18.1376,  19.6226, -14.7521]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.0405333042144775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9841, 14.7402, 16.0534],\n",
      "        [19.9484, 14.8155, 16.2501],\n",
      "        [20.3307, 14.7506, 15.7760],\n",
      "        [19.7860, 14.5318, 15.7457],\n",
      "        [20.2317, 14.2356, 15.8319],\n",
      "        [19.8721, 14.5470, 16.0941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.6589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1674,  19.8817, -14.5617],\n",
      "        [-18.1798,  19.4717, -14.6963],\n",
      "        [-18.0654,  19.4626, -14.3145],\n",
      "        [-18.4218,  19.4371, -14.5469],\n",
      "        [-17.6931,  19.2815, -14.1021],\n",
      "        [-18.2367,  19.6407, -14.6814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9841,  14.7402,  16.0534, -18.1674,  19.8817, -14.5617],\n",
      "        [ 19.9484,  14.8155,  16.2501, -18.1798,  19.4717, -14.6963],\n",
      "        [ 20.3307,  14.7506,  15.7760, -18.0654,  19.4626, -14.3145],\n",
      "        [ 19.7860,  14.5318,  15.7457, -18.4218,  19.4371, -14.5469],\n",
      "        [ 20.2317,  14.2356,  15.8319, -17.6931,  19.2815, -14.1021],\n",
      "        [ 19.8721,  14.5470,  16.0941, -18.2367,  19.6407, -14.6814]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0871596336364746\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4150, 14.5242, 15.6765],\n",
      "        [20.2096, 14.7074, 16.0120],\n",
      "        [19.9278, 14.6375, 15.7421],\n",
      "        [19.9199, 14.4604, 15.1407],\n",
      "        [19.5855, 14.3901, 15.8927],\n",
      "        [20.1381, 14.7123, 16.3076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3901,  19.6612, -14.3901],\n",
      "        [-18.0308,  19.3291, -13.9885],\n",
      "        [-17.8275,  19.2455, -14.1813],\n",
      "        [-17.9102,  18.9379, -14.0671],\n",
      "        [-18.3251,  19.4370, -14.7638],\n",
      "        [-18.0151,  19.5369, -14.8120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4150,  14.5242,  15.6765, -18.3901,  19.6612, -14.3901],\n",
      "        [ 20.2096,  14.7074,  16.0120, -18.0308,  19.3291, -13.9885],\n",
      "        [ 19.9278,  14.6375,  15.7421, -17.8275,  19.2455, -14.1813],\n",
      "        [ 19.9199,  14.4604,  15.1407, -17.9102,  18.9379, -14.0671],\n",
      "        [ 19.5855,  14.3901,  15.8927, -18.3251,  19.4370, -14.7638],\n",
      "        [ 20.1381,  14.7123,  16.3076, -18.0151,  19.5369, -14.8120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0854055881500244\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8358, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1469, 14.5383, 15.5843],\n",
      "        [19.7909, 14.2994, 15.4853],\n",
      "        [20.4485, 14.6123, 15.9729],\n",
      "        [19.4381, 14.4694, 15.5588],\n",
      "        [20.0487, 14.6371, 15.6829],\n",
      "        [19.8981, 14.5789, 15.8371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.4339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9633,  19.5519, -14.2997],\n",
      "        [-17.7820,  19.3555, -14.2728],\n",
      "        [-17.8945,  19.2572, -14.5817],\n",
      "        [-17.8865,  19.7199, -14.3963],\n",
      "        [-18.1616,  19.8041, -14.5615],\n",
      "        [-17.5889,  19.1148, -14.1245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1469,  14.5383,  15.5843, -17.9633,  19.5519, -14.2997],\n",
      "        [ 19.7909,  14.2994,  15.4853, -17.7820,  19.3555, -14.2728],\n",
      "        [ 20.4485,  14.6123,  15.9729, -17.8945,  19.2572, -14.5817],\n",
      "        [ 19.4381,  14.4694,  15.5588, -17.8865,  19.7199, -14.3963],\n",
      "        [ 20.0487,  14.6371,  15.6829, -18.1616,  19.8041, -14.5615],\n",
      "        [ 19.8981,  14.5789,  15.8371, -17.5889,  19.1148, -14.1245]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0566375255584717\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7255, 14.0891, 15.4576],\n",
      "        [20.0540, 14.4824, 16.0970],\n",
      "        [20.0297, 14.6230, 15.9593],\n",
      "        [19.7864, 14.3453, 15.5387],\n",
      "        [20.0063, 14.1181, 15.6413],\n",
      "        [19.8022, 14.4377, 15.6072]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7203, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7625,  19.9807, -14.9529],\n",
      "        [-17.9376,  19.5818, -14.3847],\n",
      "        [-18.5492,  19.9993, -14.6861],\n",
      "        [-17.8477,  19.1872, -14.1965],\n",
      "        [-18.6133,  19.8497, -14.7023],\n",
      "        [-18.1134,  19.5722, -14.8422]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7255,  14.0891,  15.4576, -18.7625,  19.9807, -14.9529],\n",
      "        [ 20.0540,  14.4824,  16.0970, -17.9376,  19.5818, -14.3847],\n",
      "        [ 20.0297,  14.6230,  15.9593, -18.5492,  19.9993, -14.6861],\n",
      "        [ 19.7864,  14.3453,  15.5387, -17.8477,  19.1872, -14.1965],\n",
      "        [ 20.0063,  14.1181,  15.6413, -18.6133,  19.8497, -14.7023],\n",
      "        [ 19.8022,  14.4377,  15.6072, -18.1134,  19.5722, -14.8422]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.066707134246826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7101, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0346, 14.3522, 15.7955],\n",
      "        [20.1166, 14.4532, 15.4120],\n",
      "        [19.9379, 14.0421, 15.7594],\n",
      "        [20.3047, 14.3185, 15.8726],\n",
      "        [20.2985, 14.9164, 15.9357],\n",
      "        [20.0623, 14.9413, 16.2874]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4727, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2768,  19.7994, -14.8078],\n",
      "        [-17.8705,  19.1994, -14.3629],\n",
      "        [-18.3339,  19.6931, -14.6804],\n",
      "        [-18.0650,  19.5173, -14.3638],\n",
      "        [-18.4412,  19.5332, -14.6167],\n",
      "        [-17.7981,  19.2244, -14.5784]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0346,  14.3522,  15.7955, -18.2768,  19.7994, -14.8078],\n",
      "        [ 20.1166,  14.4532,  15.4120, -17.8705,  19.1994, -14.3629],\n",
      "        [ 19.9379,  14.0421,  15.7594, -18.3339,  19.6931, -14.6804],\n",
      "        [ 20.3047,  14.3185,  15.8726, -18.0650,  19.5173, -14.3638],\n",
      "        [ 20.2985,  14.9164,  15.9357, -18.4412,  19.5332, -14.6167],\n",
      "        [ 20.0623,  14.9413,  16.2874, -17.7981,  19.2244, -14.5784]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.08099627494812\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8759, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9936, 14.5025, 15.5921],\n",
      "        [20.0637, 14.6597, 15.6483],\n",
      "        [20.2015, 14.6642, 16.2009],\n",
      "        [19.6333, 14.1022, 15.8378],\n",
      "        [20.2400, 14.6113, 15.5919],\n",
      "        [19.8520, 14.3359, 15.5166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5799,  19.6498, -14.8715],\n",
      "        [-17.8820,  19.5202, -14.3668],\n",
      "        [-18.2261,  19.5739, -14.5225],\n",
      "        [-17.8941,  19.7899, -14.2012],\n",
      "        [-18.1673,  19.4223, -14.2647],\n",
      "        [-18.2241,  19.5850, -14.3107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9936,  14.5025,  15.5921, -18.5799,  19.6498, -14.8715],\n",
      "        [ 20.0637,  14.6597,  15.6483, -17.8820,  19.5202, -14.3668],\n",
      "        [ 20.2015,  14.6642,  16.2009, -18.2261,  19.5739, -14.5225],\n",
      "        [ 19.6333,  14.1022,  15.8378, -17.8941,  19.7899, -14.2012],\n",
      "        [ 20.2400,  14.6113,  15.5919, -18.1673,  19.4223, -14.2647],\n",
      "        [ 19.8520,  14.3359,  15.5166, -18.2241,  19.5850, -14.3107]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.081613540649414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9261, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1178, 14.5241, 15.8779],\n",
      "        [19.9274, 14.5244, 15.8105],\n",
      "        [20.1643, 14.6297, 15.8151],\n",
      "        [19.9783, 14.2318, 15.4049],\n",
      "        [20.5503, 14.8385, 16.1558],\n",
      "        [20.3611, 14.4302, 15.8703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.5402, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2200,  19.6240, -14.4907],\n",
      "        [-18.2507,  19.7651, -14.3777],\n",
      "        [-17.8262,  19.5996, -14.2981],\n",
      "        [-18.0050,  19.9300, -14.9008],\n",
      "        [-18.4453,  19.2918, -14.6853],\n",
      "        [-18.0933,  19.6161, -14.5569]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1178,  14.5241,  15.8779, -18.2200,  19.6240, -14.4907],\n",
      "        [ 19.9274,  14.5244,  15.8105, -18.2507,  19.7651, -14.3777],\n",
      "        [ 20.1643,  14.6297,  15.8151, -17.8262,  19.5996, -14.2981],\n",
      "        [ 19.9783,  14.2318,  15.4049, -18.0050,  19.9300, -14.9008],\n",
      "        [ 20.5503,  14.8385,  16.1558, -18.4453,  19.2918, -14.6853],\n",
      "        [ 20.3611,  14.4302,  15.8703, -18.0933,  19.6161, -14.5569]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0827479362487793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7933, 14.3821, 15.6253],\n",
      "        [20.3352, 14.3474, 15.9725],\n",
      "        [20.2783, 14.6539, 16.0206],\n",
      "        [20.2473, 14.4629, 15.6773],\n",
      "        [19.5891, 14.2707, 15.6426],\n",
      "        [20.3933, 14.6077, 16.2547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0605,  19.3001, -14.7578],\n",
      "        [-18.3011,  19.6409, -14.6223],\n",
      "        [-18.1953,  19.3467, -14.6681],\n",
      "        [-17.5959,  19.4651, -14.8233],\n",
      "        [-18.2029,  19.7358, -14.9624],\n",
      "        [-17.9157,  19.4702, -14.3268]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7933,  14.3821,  15.6253, -18.0605,  19.3001, -14.7578],\n",
      "        [ 20.3352,  14.3474,  15.9725, -18.3011,  19.6409, -14.6223],\n",
      "        [ 20.2783,  14.6539,  16.0206, -18.1953,  19.3467, -14.6681],\n",
      "        [ 20.2473,  14.4629,  15.6773, -17.5959,  19.4651, -14.8233],\n",
      "        [ 19.5891,  14.2707,  15.6426, -18.2029,  19.7358, -14.9624],\n",
      "        [ 20.3933,  14.6077,  16.2547, -17.9157,  19.4702, -14.3268]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.049104690551758\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6753, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0664, 14.5701, 15.6122],\n",
      "        [20.3977, 15.2027, 15.8322],\n",
      "        [20.2625, 14.8335, 15.8088],\n",
      "        [20.1811, 14.6800, 15.8403],\n",
      "        [20.0487, 14.2255, 15.9430],\n",
      "        [20.0306, 15.1425, 15.6564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4730,  19.6614, -14.7271],\n",
      "        [-18.1393,  19.8393, -14.3045],\n",
      "        [-17.8079,  19.3524, -14.1302],\n",
      "        [-17.8753,  19.2422, -14.5434],\n",
      "        [-18.3610,  19.2703, -14.4928],\n",
      "        [-18.0643,  19.4195, -14.2951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0664,  14.5701,  15.6122, -18.4730,  19.6614, -14.7271],\n",
      "        [ 20.3977,  15.2027,  15.8322, -18.1393,  19.8393, -14.3045],\n",
      "        [ 20.2625,  14.8335,  15.8088, -17.8079,  19.3524, -14.1302],\n",
      "        [ 20.1811,  14.6800,  15.8403, -17.8753,  19.2422, -14.5434],\n",
      "        [ 20.0487,  14.2255,  15.9430, -18.3610,  19.2703, -14.4928],\n",
      "        [ 20.0306,  15.1425,  15.6564, -18.0643,  19.4195, -14.2951]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.086423635482788\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8352, 14.9600, 15.9228],\n",
      "        [19.9356, 14.6238, 15.5824],\n",
      "        [19.9046, 14.2232, 15.9506],\n",
      "        [20.0134, 14.8889, 15.8384],\n",
      "        [19.8877, 14.5161, 15.5602],\n",
      "        [20.0907, 14.5950, 16.0840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.5170, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6798,  19.5141, -14.6235],\n",
      "        [-17.9846,  20.0397, -14.9473],\n",
      "        [-18.4946,  19.6886, -14.3165],\n",
      "        [-17.5777,  19.4425, -14.5424],\n",
      "        [-18.2524,  19.9446, -14.8010],\n",
      "        [-17.5760,  19.3228, -14.2134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8352,  14.9600,  15.9228, -18.6798,  19.5141, -14.6235],\n",
      "        [ 19.9356,  14.6238,  15.5824, -17.9846,  20.0397, -14.9473],\n",
      "        [ 19.9046,  14.2232,  15.9506, -18.4946,  19.6886, -14.3165],\n",
      "        [ 20.0134,  14.8889,  15.8384, -17.5777,  19.4425, -14.5424],\n",
      "        [ 19.8877,  14.5161,  15.5602, -18.2524,  19.9446, -14.8010],\n",
      "        [ 20.0907,  14.5950,  16.0840, -17.5760,  19.3228, -14.2134]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.097536087036133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7987, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3599, 14.4733, 15.5974],\n",
      "        [20.4682, 14.8952, 16.0403],\n",
      "        [20.2295, 14.6093, 15.7057],\n",
      "        [19.9280, 14.7581, 16.0463],\n",
      "        [19.9358, 14.5409, 15.7387],\n",
      "        [20.0880, 14.2493, 15.4483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2373, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1166,  19.6354, -15.1056],\n",
      "        [-18.3211,  19.1916, -14.6399],\n",
      "        [-17.9852,  19.5885, -14.4163],\n",
      "        [-18.4711,  19.9949, -14.6715],\n",
      "        [-18.1978,  19.6401, -14.5092],\n",
      "        [-17.9331,  19.6994, -14.5897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3599,  14.4733,  15.5974, -18.1166,  19.6354, -15.1056],\n",
      "        [ 20.4682,  14.8952,  16.0403, -18.3211,  19.1916, -14.6399],\n",
      "        [ 20.2295,  14.6093,  15.7057, -17.9852,  19.5885, -14.4163],\n",
      "        [ 19.9280,  14.7581,  16.0463, -18.4711,  19.9949, -14.6715],\n",
      "        [ 19.9358,  14.5409,  15.7387, -18.1978,  19.6401, -14.5092],\n",
      "        [ 20.0880,  14.2493,  15.4483, -17.9331,  19.6994, -14.5897]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.096781015396118\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1456, 14.6589, 16.1252],\n",
      "        [20.0736, 14.6993, 16.1824],\n",
      "        [20.3039, 14.5121, 15.9630],\n",
      "        [20.4177, 14.4785, 16.1173],\n",
      "        [19.9228, 14.5652, 15.9760],\n",
      "        [19.8826, 13.7431, 15.4476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(6.2288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1553,  18.9608, -14.0354],\n",
      "        [-18.6358,  19.5977, -14.7116],\n",
      "        [-18.4482,  19.9114, -14.5853],\n",
      "        [-18.1068,  19.3229, -14.4375],\n",
      "        [-18.2069,  19.1658, -14.1111],\n",
      "        [-18.3267,  19.2724, -14.5563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1456,  14.6589,  16.1252, -18.1553,  18.9608, -14.0354],\n",
      "        [ 20.0736,  14.6993,  16.1824, -18.6358,  19.5977, -14.7116],\n",
      "        [ 20.3039,  14.5121,  15.9630, -18.4482,  19.9114, -14.5853],\n",
      "        [ 20.4177,  14.4785,  16.1173, -18.1068,  19.3229, -14.4375],\n",
      "        [ 19.9228,  14.5652,  15.9760, -18.2069,  19.1658, -14.1111],\n",
      "        [ 19.8826,  13.7431,  15.4476, -18.3267,  19.2724, -14.5563]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.0750958919525146\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7079, 14.2308, 15.7561],\n",
      "        [20.1023, 14.5965, 16.0438],\n",
      "        [20.4161, 14.6703, 15.5467],\n",
      "        [20.1468, 14.5189, 15.7116],\n",
      "        [19.7377, 14.4495, 15.6247],\n",
      "        [20.7024, 14.9342, 16.3452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0635, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1024,  19.3089, -14.4679],\n",
      "        [-18.2972,  19.7637, -14.8670],\n",
      "        [-18.4718,  20.1758, -14.9628],\n",
      "        [-18.2358,  19.4983, -14.5007],\n",
      "        [-18.5713,  19.7954, -14.8962],\n",
      "        [-18.3376,  19.9004, -14.5942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7079,  14.2308,  15.7561, -18.1024,  19.3089, -14.4679],\n",
      "        [ 20.1023,  14.5965,  16.0438, -18.2972,  19.7637, -14.8670],\n",
      "        [ 20.4161,  14.6703,  15.5467, -18.4718,  20.1758, -14.9628],\n",
      "        [ 20.1468,  14.5189,  15.7116, -18.2358,  19.4983, -14.5007],\n",
      "        [ 19.7377,  14.4495,  15.6247, -18.5713,  19.7954, -14.8962],\n",
      "        [ 20.7024,  14.9342,  16.3452, -18.3376,  19.9004, -14.5942]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.048902750015259\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7993, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3457, 14.6164, 16.2114],\n",
      "        [19.6457, 14.4840, 15.8235],\n",
      "        [19.9442, 14.8034, 16.2049],\n",
      "        [19.5906, 14.6049, 15.7231],\n",
      "        [20.1660, 14.8889, 15.7824],\n",
      "        [20.3829, 14.4494, 16.0262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5818,  19.5720, -14.4431],\n",
      "        [-18.6300,  19.6226, -14.9877],\n",
      "        [-17.8337,  19.2219, -14.0770],\n",
      "        [-17.9692,  19.5681, -14.5997],\n",
      "        [-18.2871,  19.6114, -14.7922],\n",
      "        [-18.4815,  19.8560, -14.5409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3457,  14.6164,  16.2114, -18.5818,  19.5720, -14.4431],\n",
      "        [ 19.6457,  14.4840,  15.8235, -18.6300,  19.6226, -14.9877],\n",
      "        [ 19.9442,  14.8034,  16.2049, -17.8337,  19.2219, -14.0770],\n",
      "        [ 19.5906,  14.6049,  15.7231, -17.9692,  19.5681, -14.5997],\n",
      "        [ 20.1660,  14.8889,  15.7824, -18.2871,  19.6114, -14.7922],\n",
      "        [ 20.3829,  14.4494,  16.0262, -18.4815,  19.8560, -14.5409]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.123572826385498\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7797, 14.3575, 15.9837],\n",
      "        [19.9044, 14.6259, 16.0047],\n",
      "        [19.9930, 14.7510, 16.0734],\n",
      "        [20.6601, 15.1207, 16.1091],\n",
      "        [20.0804, 14.4638, 15.6093],\n",
      "        [20.0183, 14.4876, 15.5261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3113,  19.5806, -14.7279],\n",
      "        [-18.2688,  19.6142, -14.4024],\n",
      "        [-18.3005,  19.4306, -14.4495],\n",
      "        [-18.0755,  19.4640, -14.7449],\n",
      "        [-18.7687,  19.9131, -14.6397],\n",
      "        [-18.3830,  19.0353, -14.4428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7797,  14.3575,  15.9837, -18.3113,  19.5806, -14.7279],\n",
      "        [ 19.9044,  14.6259,  16.0047, -18.2688,  19.6142, -14.4024],\n",
      "        [ 19.9930,  14.7510,  16.0734, -18.3005,  19.4306, -14.4495],\n",
      "        [ 20.6601,  15.1207,  16.1091, -18.0755,  19.4640, -14.7449],\n",
      "        [ 20.0804,  14.4638,  15.6093, -18.7687,  19.9131, -14.6397],\n",
      "        [ 20.0183,  14.4876,  15.5261, -18.3830,  19.0353, -14.4428]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0835673809051514\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2861, 14.6605, 16.2023],\n",
      "        [19.5392, 14.3673, 15.5294],\n",
      "        [20.3486, 14.8568, 16.1002],\n",
      "        [20.6818, 14.9243, 16.2053],\n",
      "        [20.4478, 15.0077, 16.1779],\n",
      "        [19.7364, 14.3467, 16.0052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2299,  19.8569, -14.6805],\n",
      "        [-18.3710,  19.3950, -14.6755],\n",
      "        [-18.3616,  19.5103, -14.0427],\n",
      "        [-18.6323,  19.6786, -14.6565],\n",
      "        [-18.4173,  19.5149, -14.4879],\n",
      "        [-18.3845,  19.8189, -14.4174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2861,  14.6605,  16.2023, -18.2299,  19.8569, -14.6805],\n",
      "        [ 19.5392,  14.3673,  15.5294, -18.3710,  19.3950, -14.6755],\n",
      "        [ 20.3486,  14.8568,  16.1002, -18.3616,  19.5103, -14.0427],\n",
      "        [ 20.6818,  14.9243,  16.2053, -18.6323,  19.6786, -14.6565],\n",
      "        [ 20.4478,  15.0077,  16.1779, -18.4173,  19.5149, -14.4879],\n",
      "        [ 19.7364,  14.3467,  16.0052, -18.3845,  19.8189, -14.4174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1277780532836914\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4946, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2779, 14.9573, 15.9421],\n",
      "        [20.1780, 14.5603, 15.7085],\n",
      "        [19.9823, 14.8727, 15.4442],\n",
      "        [20.7225, 15.0974, 15.7919],\n",
      "        [20.3081, 14.8809, 15.8903],\n",
      "        [20.3059, 14.9948, 15.9382]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1232,  19.4961, -14.6203],\n",
      "        [-18.3624,  19.7115, -14.6459],\n",
      "        [-18.4213,  19.9149, -14.7486],\n",
      "        [-18.1772,  19.3076, -14.3072],\n",
      "        [-18.4457,  19.6222, -14.3974],\n",
      "        [-18.2039,  19.7654, -14.4690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2779,  14.9573,  15.9421, -18.1232,  19.4961, -14.6203],\n",
      "        [ 20.1780,  14.5603,  15.7085, -18.3624,  19.7115, -14.6459],\n",
      "        [ 19.9823,  14.8727,  15.4442, -18.4213,  19.9149, -14.7486],\n",
      "        [ 20.7225,  15.0974,  15.7919, -18.1772,  19.3076, -14.3072],\n",
      "        [ 20.3081,  14.8809,  15.8903, -18.4457,  19.6222, -14.3974],\n",
      "        [ 20.3059,  14.9948,  15.9382, -18.2039,  19.7654, -14.4690]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1132819652557373\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8976, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1105, 14.6772, 15.8298],\n",
      "        [19.5484, 14.7371, 15.4822],\n",
      "        [19.9436, 14.4314, 15.8221],\n",
      "        [20.6070, 14.7666, 15.4635],\n",
      "        [20.3910, 14.9124, 16.0489],\n",
      "        [19.8109, 14.3110, 15.8610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.7009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1873,  19.2114, -14.7380],\n",
      "        [-18.1381,  19.8636, -14.6334],\n",
      "        [-18.0617,  19.4511, -14.3579],\n",
      "        [-18.3001,  19.6254, -14.6183],\n",
      "        [-18.0167,  19.1778, -14.1915],\n",
      "        [-18.5093,  19.6630, -14.5295]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1105,  14.6772,  15.8298, -18.1873,  19.2114, -14.7380],\n",
      "        [ 19.5484,  14.7371,  15.4822, -18.1381,  19.8636, -14.6334],\n",
      "        [ 19.9436,  14.4314,  15.8221, -18.0617,  19.4511, -14.3579],\n",
      "        [ 20.6070,  14.7666,  15.4635, -18.3001,  19.6254, -14.6183],\n",
      "        [ 20.3910,  14.9124,  16.0489, -18.0167,  19.1778, -14.1915],\n",
      "        [ 19.8109,  14.3110,  15.8610, -18.5093,  19.6630, -14.5295]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.0920677185058594\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3142, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.6945, 14.2090, 15.6472],\n",
      "        [20.2312, 14.6780, 15.8660],\n",
      "        [19.6775, 14.8231, 15.7464],\n",
      "        [20.0282, 14.8435, 15.6667],\n",
      "        [20.1890, 14.8536, 16.1124],\n",
      "        [19.8410, 14.6455, 15.7834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5469, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2961,  19.7693, -14.5711],\n",
      "        [-17.9707,  19.8156, -14.4070],\n",
      "        [-18.1649,  19.2926, -14.4742],\n",
      "        [-18.4050,  19.6374, -14.9453],\n",
      "        [-17.5531,  19.2479, -14.0992],\n",
      "        [-18.6155,  19.4632, -14.6365]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.6945,  14.2090,  15.6472, -18.2961,  19.7693, -14.5711],\n",
      "        [ 20.2312,  14.6780,  15.8660, -17.9707,  19.8156, -14.4070],\n",
      "        [ 19.6775,  14.8231,  15.7464, -18.1649,  19.2926, -14.4742],\n",
      "        [ 20.0282,  14.8435,  15.6667, -18.4050,  19.6374, -14.9453],\n",
      "        [ 20.1890,  14.8536,  16.1124, -17.5531,  19.2479, -14.0992],\n",
      "        [ 19.8410,  14.6455,  15.7834, -18.6155,  19.4632, -14.6365]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0712108612060547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8427, 14.8868, 16.2787],\n",
      "        [20.3484, 14.4993, 15.8282],\n",
      "        [20.0590, 14.5458, 16.0067],\n",
      "        [20.2623, 15.0538, 16.2789],\n",
      "        [20.1218, 14.7422, 16.1466],\n",
      "        [20.1312, 14.4029, 15.6249]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.3788, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4757,  19.7539, -14.5140],\n",
      "        [-18.4474,  19.6128, -14.6643],\n",
      "        [-18.4288,  20.0955, -15.1187],\n",
      "        [-18.1221,  19.1990, -14.1747],\n",
      "        [-18.4345,  19.7278, -14.4390],\n",
      "        [-18.1797,  19.7430, -14.7704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8427,  14.8868,  16.2787, -18.4757,  19.7539, -14.5140],\n",
      "        [ 20.3484,  14.4993,  15.8282, -18.4474,  19.6128, -14.6643],\n",
      "        [ 20.0590,  14.5458,  16.0067, -18.4288,  20.0955, -15.1187],\n",
      "        [ 20.2623,  15.0538,  16.2789, -18.1221,  19.1990, -14.1747],\n",
      "        [ 20.1218,  14.7422,  16.1466, -18.4345,  19.7278, -14.4390],\n",
      "        [ 20.1312,  14.4029,  15.6249, -18.1797,  19.7430, -14.7704]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1670451164245605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4213, 14.6674, 15.9017],\n",
      "        [19.4660, 14.5529, 15.7790],\n",
      "        [20.2920, 14.6421, 15.9944],\n",
      "        [19.5981, 14.0829, 15.3871],\n",
      "        [19.9505, 14.3756, 15.7655],\n",
      "        [19.8803, 14.7023, 15.7696]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6953, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0153,  19.6892, -14.5908],\n",
      "        [-18.0724,  19.6239, -14.4318],\n",
      "        [-17.7868,  19.1967, -14.8806],\n",
      "        [-18.2483,  19.1104, -14.2282],\n",
      "        [-18.2532,  19.7927, -14.5184],\n",
      "        [-18.1460,  19.9234, -14.3592]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4213,  14.6674,  15.9017, -18.0153,  19.6892, -14.5908],\n",
      "        [ 19.4660,  14.5529,  15.7790, -18.0724,  19.6239, -14.4318],\n",
      "        [ 20.2920,  14.6421,  15.9944, -17.7868,  19.1967, -14.8806],\n",
      "        [ 19.5981,  14.0829,  15.3871, -18.2483,  19.1104, -14.2282],\n",
      "        [ 19.9505,  14.3756,  15.7655, -18.2532,  19.7927, -14.5184],\n",
      "        [ 19.8803,  14.7023,  15.7696, -18.1460,  19.9234, -14.3592]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.118504285812378\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3388, 14.9562, 16.0572],\n",
      "        [20.4530, 15.0278, 16.3021],\n",
      "        [19.7036, 14.4220, 16.0789],\n",
      "        [19.9339, 14.6551, 15.9901],\n",
      "        [20.0912, 14.5715, 15.9622],\n",
      "        [20.3655, 15.2111, 16.2509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3469,  19.4604, -14.5745],\n",
      "        [-17.9408,  19.2775, -14.3896],\n",
      "        [-18.3364,  19.7270, -14.7589],\n",
      "        [-18.2392,  19.5217, -14.6516],\n",
      "        [-18.4032,  19.9899, -14.9232],\n",
      "        [-18.1183,  19.7447, -14.7200]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3388,  14.9562,  16.0572, -18.3469,  19.4604, -14.5745],\n",
      "        [ 20.4530,  15.0278,  16.3021, -17.9408,  19.2775, -14.3896],\n",
      "        [ 19.7036,  14.4220,  16.0789, -18.3364,  19.7270, -14.7589],\n",
      "        [ 19.9339,  14.6551,  15.9901, -18.2392,  19.5217, -14.6516],\n",
      "        [ 20.0912,  14.5715,  15.9622, -18.4032,  19.9899, -14.9232],\n",
      "        [ 20.3655,  15.2111,  16.2509, -18.1183,  19.7447, -14.7200]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1307833194732666\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8753, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4735, 14.8416, 16.0490],\n",
      "        [20.1210, 14.9195, 15.9759],\n",
      "        [19.9744, 14.1995, 15.7148],\n",
      "        [20.6026, 14.8475, 16.3590],\n",
      "        [20.0149, 14.8704, 15.5960],\n",
      "        [20.1145, 14.6501, 15.8714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4702, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5089,  19.5721, -14.3934],\n",
      "        [-18.1606,  19.5419, -14.9492],\n",
      "        [-17.9708,  19.3625, -14.4068],\n",
      "        [-18.1309,  19.2432, -14.4561],\n",
      "        [-18.3164,  19.3038, -14.4609],\n",
      "        [-18.5944,  19.4153, -14.7089]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4735,  14.8416,  16.0490, -18.5089,  19.5721, -14.3934],\n",
      "        [ 20.1210,  14.9195,  15.9759, -18.1606,  19.5419, -14.9492],\n",
      "        [ 19.9744,  14.1995,  15.7148, -17.9708,  19.3625, -14.4068],\n",
      "        [ 20.6026,  14.8475,  16.3590, -18.1309,  19.2432, -14.4561],\n",
      "        [ 20.0149,  14.8704,  15.5960, -18.3164,  19.3038, -14.4609],\n",
      "        [ 20.1145,  14.6501,  15.8714, -18.5944,  19.4153, -14.7089]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1387858390808105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5534, 14.6868, 16.0770],\n",
      "        [20.3600, 14.5838, 15.6199],\n",
      "        [20.3599, 14.7260, 16.0068],\n",
      "        [20.5588, 14.5844, 15.5942],\n",
      "        [20.2133, 14.3631, 15.9221],\n",
      "        [19.6350, 14.0292, 15.2679]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9774,  19.3450, -14.3461],\n",
      "        [-18.5415,  19.9652, -14.7894],\n",
      "        [-18.2133,  19.4683, -14.4783],\n",
      "        [-18.1906,  19.5774, -14.5129],\n",
      "        [-18.8394,  19.5129, -14.8591],\n",
      "        [-18.0762,  19.5426, -14.5281]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5534,  14.6868,  16.0770, -17.9774,  19.3450, -14.3461],\n",
      "        [ 20.3600,  14.5838,  15.6199, -18.5415,  19.9652, -14.7894],\n",
      "        [ 20.3599,  14.7260,  16.0068, -18.2133,  19.4683, -14.4783],\n",
      "        [ 20.5588,  14.5844,  15.5942, -18.1906,  19.5774, -14.5129],\n",
      "        [ 20.2133,  14.3631,  15.9221, -18.8394,  19.5129, -14.8591],\n",
      "        [ 19.6350,  14.0292,  15.2679, -18.0762,  19.5426, -14.5281]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.1205036640167236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5865, 14.9169, 16.1666],\n",
      "        [20.6934, 14.4865, 15.9215],\n",
      "        [20.3165, 14.6342, 16.1316],\n",
      "        [20.0406, 14.5752, 15.7718],\n",
      "        [19.9637, 14.4448, 15.8580],\n",
      "        [20.2485, 15.2116, 16.0650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9432,  20.0083, -14.9764],\n",
      "        [-18.5066,  19.3916, -14.7560],\n",
      "        [-18.4456,  19.6207, -14.8100],\n",
      "        [-18.4020,  19.5672, -14.4671],\n",
      "        [-18.4814,  19.7608, -14.6503],\n",
      "        [-18.5005,  20.0612, -14.5495]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5865,  14.9169,  16.1666, -18.9432,  20.0083, -14.9764],\n",
      "        [ 20.6934,  14.4865,  15.9215, -18.5066,  19.3916, -14.7560],\n",
      "        [ 20.3165,  14.6342,  16.1316, -18.4456,  19.6207, -14.8100],\n",
      "        [ 20.0406,  14.5752,  15.7718, -18.4020,  19.5672, -14.4671],\n",
      "        [ 19.9637,  14.4448,  15.8580, -18.4814,  19.7608, -14.6503],\n",
      "        [ 20.2485,  15.2116,  16.0650, -18.5005,  20.0612, -14.5495]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.186401128768921\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6172, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4588, 14.6910, 16.0636],\n",
      "        [20.6879, 14.7461, 16.0476],\n",
      "        [20.2871, 14.8937, 15.8850],\n",
      "        [19.8738, 14.2654, 15.9791],\n",
      "        [19.7651, 14.4320, 15.4379],\n",
      "        [20.4340, 15.2369, 16.0624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5454,  19.7493, -14.5223],\n",
      "        [-18.3763,  20.0759, -14.9921],\n",
      "        [-18.4722,  19.4252, -14.7889],\n",
      "        [-17.9089,  19.7350, -14.6279],\n",
      "        [-18.2217,  19.2052, -14.5231],\n",
      "        [-18.1955,  19.8586, -14.9701]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4588,  14.6910,  16.0636, -18.5454,  19.7493, -14.5223],\n",
      "        [ 20.6879,  14.7461,  16.0476, -18.3763,  20.0759, -14.9921],\n",
      "        [ 20.2871,  14.8937,  15.8850, -18.4722,  19.4252, -14.7889],\n",
      "        [ 19.8738,  14.2654,  15.9791, -17.9089,  19.7350, -14.6279],\n",
      "        [ 19.7651,  14.4320,  15.4379, -18.2217,  19.2052, -14.5231],\n",
      "        [ 20.4340,  15.2369,  16.0624, -18.1955,  19.8586, -14.9701]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.147151470184326\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3654, 14.7331, 15.8104],\n",
      "        [20.4605, 14.8587, 16.0370],\n",
      "        [19.8252, 14.9799, 16.0465],\n",
      "        [19.7353, 14.7571, 15.3340],\n",
      "        [20.2411, 15.2581, 16.3980],\n",
      "        [20.3816, 14.4831, 16.0551]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2817,  19.7196, -14.7363],\n",
      "        [-18.4142,  19.7294, -14.3259],\n",
      "        [-18.3748,  19.5109, -14.4387],\n",
      "        [-18.4611,  19.5344, -14.6111],\n",
      "        [-18.6106,  20.1492, -15.0785],\n",
      "        [-18.2885,  19.6490, -14.6312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3654,  14.7331,  15.8104, -18.2817,  19.7196, -14.7363],\n",
      "        [ 20.4605,  14.8587,  16.0370, -18.4142,  19.7294, -14.3259],\n",
      "        [ 19.8252,  14.9799,  16.0465, -18.3748,  19.5109, -14.4387],\n",
      "        [ 19.7353,  14.7571,  15.3340, -18.4611,  19.5344, -14.6111],\n",
      "        [ 20.2411,  15.2581,  16.3980, -18.6106,  20.1492, -15.0785],\n",
      "        [ 20.3816,  14.4831,  16.0551, -18.2885,  19.6490, -14.6312]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1327896118164062\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4302, 15.0462, 16.0984],\n",
      "        [20.7737, 15.2622, 16.2875],\n",
      "        [19.7093, 14.8267, 15.6046],\n",
      "        [19.8378, 14.6715, 15.9542],\n",
      "        [20.3580, 14.8885, 15.7304],\n",
      "        [19.6705, 14.7273, 15.5424]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.6711, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3228,  19.5605, -14.3802],\n",
      "        [-18.0246,  19.5222, -14.3794],\n",
      "        [-18.2769,  19.2501, -14.5861],\n",
      "        [-18.5956,  19.7914, -14.9197],\n",
      "        [-18.0153,  19.3247, -14.6007],\n",
      "        [-18.6038,  19.8597, -14.8413]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4302,  15.0462,  16.0984, -18.3228,  19.5605, -14.3802],\n",
      "        [ 20.7737,  15.2622,  16.2875, -18.0246,  19.5222, -14.3794],\n",
      "        [ 19.7093,  14.8267,  15.6046, -18.2769,  19.2501, -14.5861],\n",
      "        [ 19.8378,  14.6715,  15.9542, -18.5956,  19.7914, -14.9197],\n",
      "        [ 20.3580,  14.8885,  15.7304, -18.0153,  19.3247, -14.6007],\n",
      "        [ 19.6705,  14.7273,  15.5424, -18.6038,  19.8597, -14.8413]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.145446538925171\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7479, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.1056, 13.7930, 15.0456],\n",
      "        [20.0299, 14.5853, 15.6556],\n",
      "        [20.5740, 15.1516, 16.2345],\n",
      "        [20.2131, 14.7706, 16.1865],\n",
      "        [20.0407, 14.8916, 15.9406],\n",
      "        [20.6374, 14.9664, 15.9813]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.7079, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3522,  19.9865, -14.6104],\n",
      "        [-18.1759,  19.7330, -14.4765],\n",
      "        [-18.1336,  19.7136, -14.4966],\n",
      "        [-18.7536,  20.0868, -15.1226],\n",
      "        [-18.8278,  19.5966, -14.4575],\n",
      "        [-17.9316,  19.8182, -14.8222]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.1056,  13.7930,  15.0456, -18.3522,  19.9865, -14.6104],\n",
      "        [ 20.0299,  14.5853,  15.6556, -18.1759,  19.7330, -14.4765],\n",
      "        [ 20.5740,  15.1516,  16.2345, -18.1336,  19.7136, -14.4966],\n",
      "        [ 20.2131,  14.7706,  16.1865, -18.7536,  20.0868, -15.1226],\n",
      "        [ 20.0407,  14.8916,  15.9406, -18.8278,  19.5966, -14.4575],\n",
      "        [ 20.6374,  14.9664,  15.9813, -17.9316,  19.8182, -14.8222]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.0340328216552734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6547, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0764, 14.4464, 15.8055],\n",
      "        [20.4072, 14.8571, 15.9861],\n",
      "        [20.4793, 15.0378, 16.0230],\n",
      "        [19.9807, 14.5158, 16.0289],\n",
      "        [20.4978, 14.8355, 16.0956],\n",
      "        [20.1552, 14.7338, 15.7496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9901, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7715,  19.6544, -15.0492],\n",
      "        [-17.9511,  18.8877, -14.4132],\n",
      "        [-18.1665,  19.6185, -14.7249],\n",
      "        [-18.4584,  19.5964, -14.8467],\n",
      "        [-18.3309,  19.6221, -14.5729],\n",
      "        [-18.6116,  20.2559, -15.1080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0764,  14.4464,  15.8055, -18.7715,  19.6544, -15.0492],\n",
      "        [ 20.4072,  14.8571,  15.9861, -17.9511,  18.8877, -14.4132],\n",
      "        [ 20.4793,  15.0378,  16.0230, -18.1665,  19.6185, -14.7249],\n",
      "        [ 19.9807,  14.5158,  16.0289, -18.4584,  19.5964, -14.8467],\n",
      "        [ 20.4978,  14.8355,  16.0956, -18.3309,  19.6221, -14.5729],\n",
      "        [ 20.1552,  14.7338,  15.7496, -18.6116,  20.2559, -15.1080]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.1328017711639404\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4696, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2750, 15.0266, 16.1676],\n",
      "        [20.0638, 14.8975, 15.4636],\n",
      "        [20.0997, 14.7951, 15.6840],\n",
      "        [20.4483, 14.9417, 16.1538],\n",
      "        [20.0822, 14.7053, 15.8702],\n",
      "        [20.3756, 14.9618, 15.9814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5050,  20.0494, -14.6072],\n",
      "        [-18.2034,  19.9926, -14.7795],\n",
      "        [-18.7906,  20.1296, -15.2551],\n",
      "        [-17.9014,  19.5890, -14.4020],\n",
      "        [-18.6731,  19.7127, -14.8322],\n",
      "        [-18.3967,  19.9435, -14.6335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2750,  15.0266,  16.1676, -18.5050,  20.0494, -14.6072],\n",
      "        [ 20.0638,  14.8975,  15.4636, -18.2034,  19.9926, -14.7795],\n",
      "        [ 20.0997,  14.7951,  15.6840, -18.7906,  20.1296, -15.2551],\n",
      "        [ 20.4483,  14.9417,  16.1538, -17.9014,  19.5890, -14.4020],\n",
      "        [ 20.0822,  14.7053,  15.8702, -18.6731,  19.7127, -14.8322],\n",
      "        [ 20.3756,  14.9618,  15.9814, -18.3967,  19.9435, -14.6335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.166775941848755\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6890, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0895, 15.0829, 15.9274],\n",
      "        [20.2054, 14.7375, 16.5332],\n",
      "        [20.4779, 14.5942, 16.2610],\n",
      "        [19.8324, 14.8442, 16.0871],\n",
      "        [20.4517, 14.8743, 16.1759],\n",
      "        [19.9829, 14.6184, 15.9876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.6617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8028,  20.0128, -15.0880],\n",
      "        [-18.9054,  20.5379, -15.3857],\n",
      "        [-18.6410,  19.5703, -15.0088],\n",
      "        [-18.5026,  20.2357, -15.0169],\n",
      "        [-18.5868,  19.8927, -15.1790],\n",
      "        [-18.3808,  19.5207, -15.0213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0895,  15.0829,  15.9274, -18.8028,  20.0128, -15.0880],\n",
      "        [ 20.2054,  14.7375,  16.5332, -18.9054,  20.5379, -15.3857],\n",
      "        [ 20.4779,  14.5942,  16.2610, -18.6410,  19.5703, -15.0088],\n",
      "        [ 19.8324,  14.8442,  16.0871, -18.5026,  20.2357, -15.0169],\n",
      "        [ 20.4517,  14.8743,  16.1759, -18.5868,  19.8927, -15.1790],\n",
      "        [ 19.9829,  14.6184,  15.9876, -18.3808,  19.5207, -15.0213]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1679775714874268\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8078, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1941, 14.7757, 15.9795],\n",
      "        [20.1705, 15.1237, 16.0491],\n",
      "        [20.6850, 14.8462, 15.9626],\n",
      "        [19.8741, 14.2700, 15.9434],\n",
      "        [20.2221, 15.1736, 16.4123],\n",
      "        [19.7598, 14.0458, 15.6913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.7918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7285,  19.7705, -14.4395],\n",
      "        [-18.3804,  19.8458, -14.9967],\n",
      "        [-18.1460,  19.5815, -14.9543],\n",
      "        [-18.6191,  19.8134, -14.9079],\n",
      "        [-18.3038,  19.5616, -15.0434],\n",
      "        [-18.1388,  19.8041, -14.6908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1941,  14.7757,  15.9795, -18.7285,  19.7705, -14.4395],\n",
      "        [ 20.1705,  15.1237,  16.0491, -18.3804,  19.8458, -14.9967],\n",
      "        [ 20.6850,  14.8462,  15.9626, -18.1460,  19.5815, -14.9543],\n",
      "        [ 19.8741,  14.2700,  15.9434, -18.6191,  19.8134, -14.9079],\n",
      "        [ 20.2221,  15.1736,  16.4123, -18.3038,  19.5616, -15.0434],\n",
      "        [ 19.7598,  14.0458,  15.6913, -18.1388,  19.8041, -14.6908]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1475830078125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2818, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0794, 14.5390, 16.2501],\n",
      "        [19.7398, 14.4006, 15.8244],\n",
      "        [20.0396, 14.3352, 16.1258],\n",
      "        [20.2884, 15.0757, 16.3061],\n",
      "        [19.6326, 14.7136, 16.0069],\n",
      "        [20.5074, 14.9399, 16.3692]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4655, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4965,  20.0465, -14.8326],\n",
      "        [-18.4704,  19.6514, -14.7393],\n",
      "        [-18.2261,  19.5772, -14.3661],\n",
      "        [-18.5805,  19.7131, -14.4491],\n",
      "        [-18.3781,  19.7748, -14.9803],\n",
      "        [-18.2281,  20.0300, -14.8456]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0794,  14.5390,  16.2501, -18.4965,  20.0465, -14.8326],\n",
      "        [ 19.7398,  14.4006,  15.8244, -18.4704,  19.6514, -14.7393],\n",
      "        [ 20.0396,  14.3352,  16.1258, -18.2261,  19.5772, -14.3661],\n",
      "        [ 20.2884,  15.0757,  16.3061, -18.5805,  19.7131, -14.4491],\n",
      "        [ 19.6326,  14.7136,  16.0069, -18.3781,  19.7748, -14.9803],\n",
      "        [ 20.5074,  14.9399,  16.3692, -18.2281,  20.0300, -14.8456]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.156668186187744\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5643, 15.2325, 16.4643],\n",
      "        [20.1613, 15.1226, 16.2307],\n",
      "        [20.0667, 14.8364, 16.2607],\n",
      "        [20.4006, 14.5870, 16.0543],\n",
      "        [20.0346, 14.6671, 15.5907],\n",
      "        [20.4039, 14.9566, 15.9778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4814, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8840,  20.0742, -14.8806],\n",
      "        [-18.3607,  19.7030, -14.6021],\n",
      "        [-18.5027,  19.8210, -15.0739],\n",
      "        [-18.8050,  20.2886, -15.3742],\n",
      "        [-18.4937,  20.0025, -14.9750],\n",
      "        [-18.8057,  19.9996, -15.0454]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5643,  15.2325,  16.4643, -18.8840,  20.0742, -14.8806],\n",
      "        [ 20.1613,  15.1226,  16.2307, -18.3607,  19.7030, -14.6021],\n",
      "        [ 20.0667,  14.8364,  16.2607, -18.5027,  19.8210, -15.0739],\n",
      "        [ 20.4006,  14.5870,  16.0543, -18.8050,  20.2886, -15.3742],\n",
      "        [ 20.0346,  14.6671,  15.5907, -18.4937,  20.0025, -14.9750],\n",
      "        [ 20.4039,  14.9566,  15.9778, -18.8057,  19.9996, -15.0454]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2167093753814697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3216, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1516, 14.3998, 15.5636],\n",
      "        [20.4783, 15.0208, 16.1124],\n",
      "        [20.4397, 14.6772, 16.1910],\n",
      "        [20.5769, 14.7808, 16.1734],\n",
      "        [20.2501, 14.9606, 16.0800],\n",
      "        [20.5577, 14.8163, 16.1243]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2058,  19.3585, -14.6358],\n",
      "        [-18.3603,  19.6540, -14.7514],\n",
      "        [-18.0217,  19.4141, -14.5711],\n",
      "        [-18.0253,  19.8193, -14.5457],\n",
      "        [-18.6036,  19.8464, -14.3799],\n",
      "        [-18.8353,  20.0165, -14.8575]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1516,  14.3998,  15.5636, -18.2058,  19.3585, -14.6358],\n",
      "        [ 20.4783,  15.0208,  16.1124, -18.3603,  19.6540, -14.7514],\n",
      "        [ 20.4397,  14.6772,  16.1910, -18.0217,  19.4141, -14.5711],\n",
      "        [ 20.5769,  14.7808,  16.1734, -18.0253,  19.8193, -14.5457],\n",
      "        [ 20.2501,  14.9606,  16.0800, -18.6036,  19.8464, -14.3799],\n",
      "        [ 20.5577,  14.8163,  16.1243, -18.8353,  20.0165, -14.8575]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.1044037342071533\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9273, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9613, 14.8516, 16.1345],\n",
      "        [20.3396, 15.0378, 16.1358],\n",
      "        [20.3422, 15.0479, 16.2232],\n",
      "        [20.3854, 14.9481, 16.0779],\n",
      "        [20.5731, 15.1308, 16.2474],\n",
      "        [20.2434, 15.2087, 16.1608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6527,  19.8265, -14.9893],\n",
      "        [-18.2137,  19.6072, -14.8622],\n",
      "        [-18.6005,  19.9550, -14.7908],\n",
      "        [-18.7912,  19.9418, -14.7809],\n",
      "        [-18.2189,  19.4858, -14.7374],\n",
      "        [-18.4115,  20.0007, -14.7748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9613,  14.8516,  16.1345, -18.6527,  19.8265, -14.9893],\n",
      "        [ 20.3396,  15.0378,  16.1358, -18.2137,  19.6072, -14.8622],\n",
      "        [ 20.3422,  15.0479,  16.2232, -18.6005,  19.9550, -14.7908],\n",
      "        [ 20.3854,  14.9481,  16.0779, -18.7912,  19.9418, -14.7809],\n",
      "        [ 20.5731,  15.1308,  16.2474, -18.2189,  19.4858, -14.7374],\n",
      "        [ 20.2434,  15.2087,  16.1608, -18.4115,  20.0007, -14.7748]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1600353717803955\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7828, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2907, 15.0732, 16.2337],\n",
      "        [20.5292, 14.9870, 16.1479],\n",
      "        [20.4095, 14.7488, 15.9302],\n",
      "        [19.7457, 14.7631, 15.6897],\n",
      "        [20.8515, 14.9087, 16.1603],\n",
      "        [19.8555, 14.6749, 15.7475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.7969, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2822,  19.9748, -15.1710],\n",
      "        [-18.3286,  19.2876, -14.7610],\n",
      "        [-18.5420,  19.6737, -14.4359],\n",
      "        [-18.3529,  19.9074, -15.0832],\n",
      "        [-18.8148,  20.3854, -14.9209],\n",
      "        [-18.5150,  20.0919, -14.8396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2907,  15.0732,  16.2337, -18.2822,  19.9748, -15.1710],\n",
      "        [ 20.5292,  14.9870,  16.1479, -18.3286,  19.2876, -14.7610],\n",
      "        [ 20.4095,  14.7488,  15.9302, -18.5420,  19.6737, -14.4359],\n",
      "        [ 19.7457,  14.7631,  15.6897, -18.3529,  19.9074, -15.0832],\n",
      "        [ 20.8515,  14.9087,  16.1603, -18.8148,  20.3854, -14.9209],\n",
      "        [ 19.8555,  14.6749,  15.7475, -18.5150,  20.0919, -14.8396]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.183690071105957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4203, 14.8735, 16.2791],\n",
      "        [20.0198, 14.9082, 15.8584],\n",
      "        [20.6566, 14.9719, 16.4514],\n",
      "        [20.3689, 15.0531, 15.8857],\n",
      "        [20.7263, 15.3714, 16.0745],\n",
      "        [20.0388, 15.0166, 16.5231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3808,  20.1483, -14.9488],\n",
      "        [-18.1958,  19.4360, -14.3561],\n",
      "        [-18.4448,  19.8203, -14.7368],\n",
      "        [-18.4008,  20.0917, -14.9695],\n",
      "        [-18.9701,  20.3573, -15.0940],\n",
      "        [-18.6585,  20.1364, -15.0656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4203,  14.8735,  16.2791, -18.3808,  20.1483, -14.9488],\n",
      "        [ 20.0198,  14.9082,  15.8584, -18.1958,  19.4360, -14.3561],\n",
      "        [ 20.6566,  14.9719,  16.4514, -18.4448,  19.8203, -14.7368],\n",
      "        [ 20.3689,  15.0531,  15.8857, -18.4008,  20.0917, -14.9695],\n",
      "        [ 20.7263,  15.3714,  16.0745, -18.9701,  20.3573, -15.0940],\n",
      "        [ 20.0388,  15.0166,  16.5231, -18.6585,  20.1364, -15.0656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1906192302703857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5177, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2558, 14.6318, 16.1489],\n",
      "        [19.8766, 14.6659, 15.7430],\n",
      "        [20.2214, 14.9272, 16.0782],\n",
      "        [20.6740, 15.0395, 16.3785],\n",
      "        [20.6247, 14.9888, 16.1030],\n",
      "        [20.2662, 14.3230, 16.1104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4273,  19.4117, -14.3665],\n",
      "        [-18.5659,  19.8598, -15.1118],\n",
      "        [-18.5746,  19.7976, -14.7504],\n",
      "        [-18.8322,  20.1944, -15.2948],\n",
      "        [-18.5614,  19.8463, -14.5876],\n",
      "        [-18.6863,  20.0569, -15.1512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2558,  14.6318,  16.1489, -18.4273,  19.4117, -14.3665],\n",
      "        [ 19.8766,  14.6659,  15.7430, -18.5659,  19.8598, -15.1118],\n",
      "        [ 20.2214,  14.9272,  16.0782, -18.5746,  19.7976, -14.7504],\n",
      "        [ 20.6740,  15.0395,  16.3785, -18.8322,  20.1944, -15.2948],\n",
      "        [ 20.6247,  14.9888,  16.1030, -18.5614,  19.8463, -14.5876],\n",
      "        [ 20.2662,  14.3230,  16.1104, -18.6863,  20.0569, -15.1512]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.143674612045288\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9947, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7057, 14.8476, 15.7673],\n",
      "        [20.3668, 14.8935, 15.7815],\n",
      "        [20.4561, 14.6416, 16.0406],\n",
      "        [20.3179, 14.4980, 16.4401],\n",
      "        [20.2762, 14.5489, 16.1646],\n",
      "        [20.4695, 14.6041, 16.4554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2094,  19.8531, -14.5442],\n",
      "        [-18.2522,  19.6875, -14.6508],\n",
      "        [-18.9301,  20.1614, -15.1304],\n",
      "        [-18.4212,  19.8917, -14.7597],\n",
      "        [-18.2485,  19.0758, -14.8061],\n",
      "        [-18.4176,  19.9906, -14.4815]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7057,  14.8476,  15.7673, -18.2094,  19.8531, -14.5442],\n",
      "        [ 20.3668,  14.8935,  15.7815, -18.2522,  19.6875, -14.6508],\n",
      "        [ 20.4561,  14.6416,  16.0406, -18.9301,  20.1614, -15.1304],\n",
      "        [ 20.3179,  14.4980,  16.4401, -18.4212,  19.8917, -14.7597],\n",
      "        [ 20.2762,  14.5489,  16.1646, -18.2485,  19.0758, -14.8061],\n",
      "        [ 20.4695,  14.6041,  16.4554, -18.4176,  19.9906, -14.4815]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1670379638671875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8067, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2104, 14.0918, 15.4719],\n",
      "        [20.6372, 15.0016, 16.1229],\n",
      "        [20.5720, 15.1642, 16.0874],\n",
      "        [20.6678, 15.2245, 16.4559],\n",
      "        [19.9463, 14.5186, 15.4104],\n",
      "        [20.0979, 14.7941, 15.7908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.7840,  20.0344, -14.6567],\n",
      "        [-18.5701,  19.4471, -14.7005],\n",
      "        [-18.8616,  20.0753, -15.0372],\n",
      "        [-18.3091,  19.7849, -14.9069],\n",
      "        [-18.6865,  19.6424, -14.8823],\n",
      "        [-18.8575,  19.7809, -14.9962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2104,  14.0918,  15.4719, -17.7840,  20.0344, -14.6567],\n",
      "        [ 20.6372,  15.0016,  16.1229, -18.5701,  19.4471, -14.7005],\n",
      "        [ 20.5720,  15.1642,  16.0874, -18.8616,  20.0753, -15.0372],\n",
      "        [ 20.6678,  15.2245,  16.4559, -18.3091,  19.7849, -14.9069],\n",
      "        [ 19.9463,  14.5186,  15.4104, -18.6865,  19.6424, -14.8823],\n",
      "        [ 20.0979,  14.7941,  15.7908, -18.8575,  19.7809, -14.9962]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.112396478652954\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9034, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5349, 14.8410, 16.2600],\n",
      "        [20.2966, 14.9936, 16.1710],\n",
      "        [20.2255, 15.0741, 16.1765],\n",
      "        [20.1565, 14.5863, 15.9765],\n",
      "        [20.5125, 15.1610, 16.2170],\n",
      "        [20.3777, 14.9096, 16.1764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.0930,  19.6064, -14.5222],\n",
      "        [-18.4411,  20.1903, -15.1355],\n",
      "        [-18.3182,  20.0343, -14.5798],\n",
      "        [-18.3316,  19.5751, -15.0076],\n",
      "        [-18.6536,  19.9199, -15.0287],\n",
      "        [-18.6620,  20.1860, -15.1773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5349,  14.8410,  16.2600, -18.0930,  19.6064, -14.5222],\n",
      "        [ 20.2966,  14.9936,  16.1710, -18.4411,  20.1903, -15.1355],\n",
      "        [ 20.2255,  15.0741,  16.1765, -18.3182,  20.0343, -14.5798],\n",
      "        [ 20.1565,  14.5863,  15.9765, -18.3316,  19.5751, -15.0076],\n",
      "        [ 20.5125,  15.1610,  16.2170, -18.6536,  19.9199, -15.0287],\n",
      "        [ 20.3777,  14.9096,  16.1764, -18.6620,  20.1860, -15.1773]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1696255207061768\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6549, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0331, 14.6922, 16.2279],\n",
      "        [20.4390, 14.5405, 16.0316],\n",
      "        [20.3143, 14.9426, 16.3978],\n",
      "        [20.3671, 14.3276, 15.8830],\n",
      "        [20.0133, 14.8663, 16.2516],\n",
      "        [20.4186, 15.0410, 15.9551]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-17.9747,  19.7744, -14.5680],\n",
      "        [-18.1917,  19.5799, -14.7186],\n",
      "        [-18.3486,  19.8536, -14.7782],\n",
      "        [-19.0703,  20.0572, -15.1312],\n",
      "        [-18.7196,  20.2507, -15.0607],\n",
      "        [-18.8399,  20.3126, -14.9649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0331,  14.6922,  16.2279, -17.9747,  19.7744, -14.5680],\n",
      "        [ 20.4390,  14.5405,  16.0316, -18.1917,  19.5799, -14.7186],\n",
      "        [ 20.3143,  14.9426,  16.3978, -18.3486,  19.8536, -14.7782],\n",
      "        [ 20.3671,  14.3276,  15.8830, -19.0703,  20.0572, -15.1312],\n",
      "        [ 20.0133,  14.8663,  16.2516, -18.7196,  20.2507, -15.0607],\n",
      "        [ 20.4186,  15.0410,  15.9551, -18.8399,  20.3126, -14.9649]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1457958221435547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6784, 14.7902, 15.7920],\n",
      "        [20.1067, 15.1663, 15.7346],\n",
      "        [20.7672, 15.1307, 16.3575],\n",
      "        [20.3606, 14.5564, 15.8671],\n",
      "        [20.8035, 15.1686, 16.3287],\n",
      "        [20.5702, 15.1342, 16.0223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.0731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6151,  19.5952, -14.7842],\n",
      "        [-18.2716,  19.6704, -14.6337],\n",
      "        [-17.9710,  19.8633, -14.5567],\n",
      "        [-18.7201,  19.7762, -15.2325],\n",
      "        [-18.4913,  19.8260, -14.7498],\n",
      "        [-18.5917,  19.5873, -14.9328]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6784,  14.7902,  15.7920, -18.6151,  19.5952, -14.7842],\n",
      "        [ 20.1067,  15.1663,  15.7346, -18.2716,  19.6704, -14.6337],\n",
      "        [ 20.7672,  15.1307,  16.3575, -17.9710,  19.8633, -14.5567],\n",
      "        [ 20.3606,  14.5564,  15.8671, -18.7201,  19.7762, -15.2325],\n",
      "        [ 20.8035,  15.1686,  16.3287, -18.4913,  19.8260, -14.7498],\n",
      "        [ 20.5702,  15.1342,  16.0223, -18.5917,  19.5873, -14.9328]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.178412914276123\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2874, 14.9056, 16.0766],\n",
      "        [20.3590, 14.6594, 15.7832],\n",
      "        [20.5228, 15.3082, 16.3537],\n",
      "        [20.3681, 15.0480, 15.8982],\n",
      "        [20.6244, 15.0901, 16.7920],\n",
      "        [20.0686, 14.6507, 16.2218]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5733,  19.2536, -14.3849],\n",
      "        [-18.6100,  20.1277, -14.8855],\n",
      "        [-18.3044,  19.5879, -14.7924],\n",
      "        [-18.4911,  19.7487, -15.0530],\n",
      "        [-18.6543,  19.9905, -14.8875],\n",
      "        [-18.9524,  20.5348, -15.2056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2874,  14.9056,  16.0766, -18.5733,  19.2536, -14.3849],\n",
      "        [ 20.3590,  14.6594,  15.7832, -18.6100,  20.1277, -14.8855],\n",
      "        [ 20.5228,  15.3082,  16.3537, -18.3044,  19.5879, -14.7924],\n",
      "        [ 20.3681,  15.0480,  15.8982, -18.4911,  19.7487, -15.0530],\n",
      "        [ 20.6244,  15.0901,  16.7920, -18.6543,  19.9905, -14.8875],\n",
      "        [ 20.0686,  14.6507,  16.2218, -18.9524,  20.5348, -15.2056]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1573262214660645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.8809, 14.8151, 15.8865],\n",
      "        [20.2158, 14.9560, 16.0020],\n",
      "        [20.7645, 15.0238, 16.5041],\n",
      "        [20.8089, 15.0955, 16.3638],\n",
      "        [20.5910, 14.9977, 16.3253],\n",
      "        [20.2908, 14.5944, 15.9864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.2282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.2533,  20.3788, -15.0463],\n",
      "        [-17.3706,  18.9711, -14.8788],\n",
      "        [-18.1985,  20.0392, -14.9984],\n",
      "        [-18.8079,  20.0312, -14.8165],\n",
      "        [-18.6894,  20.1371, -14.9676],\n",
      "        [-18.4591,  19.6482, -14.5662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.8809,  14.8151,  15.8865, -18.2533,  20.3788, -15.0463],\n",
      "        [ 20.2158,  14.9560,  16.0020, -17.3706,  18.9711, -14.8788],\n",
      "        [ 20.7645,  15.0238,  16.5041, -18.1985,  20.0392, -14.9984],\n",
      "        [ 20.8089,  15.0955,  16.3638, -18.8079,  20.0312, -14.8165],\n",
      "        [ 20.5910,  14.9977,  16.3253, -18.6894,  20.1371, -14.9676],\n",
      "        [ 20.2908,  14.5944,  15.9864, -18.4591,  19.6482, -14.5662]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.166468381881714\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3459, 14.5224, 16.4411],\n",
      "        [20.5260, 14.9691, 15.7487],\n",
      "        [19.5180, 14.3910, 15.8198],\n",
      "        [20.1184, 14.7838, 16.0998],\n",
      "        [20.0771, 14.6918, 16.1783],\n",
      "        [20.1571, 14.6919, 16.5005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.4599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2119,  20.4999, -15.5339],\n",
      "        [-18.6514,  19.9461, -14.6273],\n",
      "        [-18.7217,  19.8351, -15.1405],\n",
      "        [-18.7822,  20.4522, -15.4350],\n",
      "        [-18.5766,  20.0192, -15.2611],\n",
      "        [-18.5905,  20.0297, -14.8749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3459,  14.5224,  16.4411, -19.2119,  20.4999, -15.5339],\n",
      "        [ 20.5260,  14.9691,  15.7487, -18.6514,  19.9461, -14.6273],\n",
      "        [ 19.5180,  14.3910,  15.8198, -18.7217,  19.8351, -15.1405],\n",
      "        [ 20.1184,  14.7838,  16.0998, -18.7822,  20.4522, -15.4350],\n",
      "        [ 20.0771,  14.6918,  16.1783, -18.5766,  20.0192, -15.2611],\n",
      "        [ 20.1571,  14.6919,  16.5005, -18.5905,  20.0297, -14.8749]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.2385170459747314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.9979, 15.0763, 16.1209],\n",
      "        [20.9089, 15.7501, 16.2535],\n",
      "        [19.8433, 14.6033, 15.9177],\n",
      "        [20.2582, 14.7222, 16.5203],\n",
      "        [20.3923, 15.1801, 16.4675],\n",
      "        [20.3554, 14.9649, 15.8448]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4530, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1155,  19.4421, -14.7696],\n",
      "        [-18.4880,  20.1829, -15.3930],\n",
      "        [-18.0586,  19.5979, -14.7180],\n",
      "        [-18.7290,  20.2273, -15.4106],\n",
      "        [-19.2455,  20.5059, -15.2247],\n",
      "        [-18.8267,  20.1452, -14.8888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.9979,  15.0763,  16.1209, -18.1155,  19.4421, -14.7696],\n",
      "        [ 20.9089,  15.7501,  16.2535, -18.4880,  20.1829, -15.3930],\n",
      "        [ 19.8433,  14.6033,  15.9177, -18.0586,  19.5979, -14.7180],\n",
      "        [ 20.2582,  14.7222,  16.5203, -18.7290,  20.2273, -15.4106],\n",
      "        [ 20.3923,  15.1801,  16.4675, -19.2455,  20.5059, -15.2247],\n",
      "        [ 20.3554,  14.9649,  15.8448, -18.8267,  20.1452, -14.8888]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.15513014793396\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8179, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5932, 14.7137, 16.4021],\n",
      "        [20.4450, 14.9089, 16.0375],\n",
      "        [20.5965, 14.8681, 16.4406],\n",
      "        [20.5829, 14.8034, 16.3162],\n",
      "        [20.3045, 14.8706, 16.1724],\n",
      "        [20.1562, 14.7923, 15.9901]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0889,  20.0766, -15.1374],\n",
      "        [-18.4640,  20.1385, -15.1797],\n",
      "        [-18.6065,  19.6792, -14.5119],\n",
      "        [-18.9711,  19.9754, -15.0886],\n",
      "        [-18.3098,  19.8499, -14.4953],\n",
      "        [-19.0098,  20.2903, -15.3897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5932,  14.7137,  16.4021, -19.0889,  20.0766, -15.1374],\n",
      "        [ 20.4450,  14.9089,  16.0375, -18.4640,  20.1385, -15.1797],\n",
      "        [ 20.5965,  14.8681,  16.4406, -18.6065,  19.6792, -14.5119],\n",
      "        [ 20.5829,  14.8034,  16.3162, -18.9711,  19.9754, -15.0886],\n",
      "        [ 20.3045,  14.8706,  16.1724, -18.3098,  19.8499, -14.4953],\n",
      "        [ 20.1562,  14.7923,  15.9901, -19.0098,  20.2903, -15.3897]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.23370099067688\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4429, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3584, 14.9042, 16.0533],\n",
      "        [20.0649, 14.9001, 16.0710],\n",
      "        [20.2457, 14.8390, 15.8443],\n",
      "        [20.8951, 15.1620, 16.2665],\n",
      "        [20.6249, 15.0775, 16.0955],\n",
      "        [20.2650, 14.5265, 15.9942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6199,  19.8727, -14.9166],\n",
      "        [-18.4305,  20.1507, -14.9352],\n",
      "        [-18.9107,  19.9253, -15.2700],\n",
      "        [-18.6082,  19.9419, -15.1781],\n",
      "        [-18.7045,  20.2241, -15.0769],\n",
      "        [-18.6015,  20.3154, -15.3225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3584,  14.9042,  16.0533, -18.6199,  19.8727, -14.9166],\n",
      "        [ 20.0649,  14.9001,  16.0710, -18.4305,  20.1507, -14.9352],\n",
      "        [ 20.2457,  14.8390,  15.8443, -18.9107,  19.9253, -15.2700],\n",
      "        [ 20.8951,  15.1620,  16.2665, -18.6082,  19.9419, -15.1781],\n",
      "        [ 20.6249,  15.0775,  16.0955, -18.7045,  20.2241, -15.0769],\n",
      "        [ 20.2650,  14.5265,  15.9942, -18.6015,  20.3154, -15.3225]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1948699951171875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0414, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6273, 14.9165, 16.3745],\n",
      "        [20.3920, 14.9491, 15.9645],\n",
      "        [20.2836, 14.8767, 16.1412],\n",
      "        [20.2667, 15.0443, 16.3687],\n",
      "        [19.9971, 14.8282, 16.2283],\n",
      "        [20.6445, 14.9804, 16.1207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5567,  19.4940, -14.9976],\n",
      "        [-18.4516,  19.8419, -14.7357],\n",
      "        [-18.5489,  19.9698, -14.8876],\n",
      "        [-18.8609,  20.4299, -15.2175],\n",
      "        [-18.6374,  19.3762, -15.0473],\n",
      "        [-18.3023,  19.9325, -14.7248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6273,  14.9165,  16.3745, -18.5567,  19.4940, -14.9976],\n",
      "        [ 20.3920,  14.9491,  15.9645, -18.4516,  19.8419, -14.7357],\n",
      "        [ 20.2836,  14.8767,  16.1412, -18.5489,  19.9698, -14.8876],\n",
      "        [ 20.2667,  15.0443,  16.3687, -18.8609,  20.4299, -15.2175],\n",
      "        [ 19.9971,  14.8282,  16.2283, -18.6374,  19.3762, -15.0473],\n",
      "        [ 20.6445,  14.9804,  16.1207, -18.3023,  19.9325, -14.7248]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2099521160125732\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4498, 14.7432, 16.1276],\n",
      "        [20.3374, 15.1298, 16.3802],\n",
      "        [20.5055, 14.9708, 16.2045],\n",
      "        [20.4939, 14.8823, 16.3185],\n",
      "        [20.5705, 15.0723, 16.5074],\n",
      "        [20.5470, 15.0649, 16.4670]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.0232, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8900,  19.9957, -14.7640],\n",
      "        [-18.9480,  20.0568, -15.2508],\n",
      "        [-18.5014,  20.0139, -14.3084],\n",
      "        [-18.7646,  20.1525, -14.8065],\n",
      "        [-18.4275,  19.8514, -15.0752],\n",
      "        [-18.7026,  20.1732, -14.6945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4498,  14.7432,  16.1276, -18.8900,  19.9957, -14.7640],\n",
      "        [ 20.3374,  15.1298,  16.3802, -18.9480,  20.0568, -15.2508],\n",
      "        [ 20.5055,  14.9708,  16.2045, -18.5014,  20.0139, -14.3084],\n",
      "        [ 20.4939,  14.8823,  16.3185, -18.7646,  20.1525, -14.8065],\n",
      "        [ 20.5705,  15.0723,  16.5074, -18.4275,  19.8514, -15.0752],\n",
      "        [ 20.5470,  15.0649,  16.4670, -18.7026,  20.1732, -14.6945]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2077600955963135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[19.7608, 15.2518, 16.0680],\n",
      "        [20.0785, 14.7867, 16.1454],\n",
      "        [20.4604, 15.1525, 16.3256],\n",
      "        [20.4454, 15.1128, 16.2632],\n",
      "        [20.6983, 15.2739, 16.7508],\n",
      "        [20.5121, 15.0413, 16.2986]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6272, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1343,  20.0870, -14.6873],\n",
      "        [-19.0360,  20.6160, -15.5492],\n",
      "        [-18.3672,  19.9023, -14.7234],\n",
      "        [-18.5441,  19.9799, -14.9045],\n",
      "        [-18.4976,  20.2727, -15.5167],\n",
      "        [-18.6443,  20.3021, -14.7407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 19.7608,  15.2518,  16.0680, -18.1343,  20.0870, -14.6873],\n",
      "        [ 20.0785,  14.7867,  16.1454, -19.0360,  20.6160, -15.5492],\n",
      "        [ 20.4604,  15.1525,  16.3256, -18.3672,  19.9023, -14.7234],\n",
      "        [ 20.4454,  15.1128,  16.2632, -18.5441,  19.9799, -14.9045],\n",
      "        [ 20.6983,  15.2739,  16.7508, -18.4976,  20.2727, -15.5167],\n",
      "        [ 20.5121,  15.0413,  16.2986, -18.6443,  20.3021, -14.7407]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.1705269813537598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7183, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3030, 14.7589, 16.1196],\n",
      "        [20.1527, 15.3279, 16.1735],\n",
      "        [20.6276, 15.2235, 16.3287],\n",
      "        [20.1526, 15.0936, 16.6108],\n",
      "        [20.3923, 14.8009, 15.7987],\n",
      "        [20.6100, 14.9996, 16.1053]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5450,  20.0662, -15.0667],\n",
      "        [-18.7655,  20.3533, -15.0802],\n",
      "        [-18.2898,  19.9359, -14.7919],\n",
      "        [-18.8896,  20.1456, -14.9579],\n",
      "        [-18.9182,  19.8837, -14.8444],\n",
      "        [-18.5020,  20.1332, -15.3134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3030,  14.7589,  16.1196, -18.5450,  20.0662, -15.0667],\n",
      "        [ 20.1527,  15.3279,  16.1735, -18.7655,  20.3533, -15.0802],\n",
      "        [ 20.6276,  15.2235,  16.3287, -18.2898,  19.9359, -14.7919],\n",
      "        [ 20.1526,  15.0936,  16.6108, -18.8896,  20.1456, -14.9579],\n",
      "        [ 20.3923,  14.8009,  15.7987, -18.9182,  19.8837, -14.8444],\n",
      "        [ 20.6100,  14.9996,  16.1053, -18.5020,  20.1332, -15.3134]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2029006481170654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7375, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0615, 14.2841, 15.6960],\n",
      "        [20.3039, 14.8533, 16.1746],\n",
      "        [20.9734, 15.3994, 16.6540],\n",
      "        [20.5585, 15.2637, 16.0578],\n",
      "        [20.2089, 14.9804, 16.1032],\n",
      "        [20.9616, 15.1958, 16.5429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6377, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9966,  20.1949, -15.2935],\n",
      "        [-18.6196,  20.1281, -15.2068],\n",
      "        [-18.2960,  19.6554, -14.7267],\n",
      "        [-18.6530,  19.6644, -14.9370],\n",
      "        [-18.6169,  19.7487, -15.1194],\n",
      "        [-18.8172,  20.1051, -15.2936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0615,  14.2841,  15.6960, -18.9966,  20.1949, -15.2935],\n",
      "        [ 20.3039,  14.8533,  16.1746, -18.6196,  20.1281, -15.2068],\n",
      "        [ 20.9734,  15.3994,  16.6540, -18.2960,  19.6554, -14.7267],\n",
      "        [ 20.5585,  15.2637,  16.0578, -18.6530,  19.6644, -14.9370],\n",
      "        [ 20.2089,  14.9804,  16.1032, -18.6169,  19.7487, -15.1194],\n",
      "        [ 20.9616,  15.1958,  16.5429, -18.8172,  20.1051, -15.2936]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.1850523948669434\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6675, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4076, 14.9814, 16.2611],\n",
      "        [20.8045, 15.3094, 16.4161],\n",
      "        [20.6507, 14.3924, 15.7511],\n",
      "        [20.6341, 15.0313, 16.7511],\n",
      "        [20.7222, 15.2075, 16.3490],\n",
      "        [20.2095, 14.7194, 15.7754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9534, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3899,  20.0630, -14.8241],\n",
      "        [-18.7848,  20.2684, -15.2247],\n",
      "        [-18.5444,  19.8436, -14.8727],\n",
      "        [-18.3002,  19.8817, -14.9641],\n",
      "        [-18.4421,  19.6497, -14.6169],\n",
      "        [-18.9341,  20.3334, -15.2353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4076,  14.9814,  16.2611, -18.3899,  20.0630, -14.8241],\n",
      "        [ 20.8045,  15.3094,  16.4161, -18.7848,  20.2684, -15.2247],\n",
      "        [ 20.6507,  14.3924,  15.7511, -18.5444,  19.8436, -14.8727],\n",
      "        [ 20.6341,  15.0313,  16.7511, -18.3002,  19.8817, -14.9641],\n",
      "        [ 20.7222,  15.2075,  16.3490, -18.4421,  19.6497, -14.6169],\n",
      "        [ 20.2095,  14.7194,  15.7754, -18.9341,  20.3334, -15.2353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2126402854919434\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4399, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.0730, 14.6106, 16.0280],\n",
      "        [20.3303, 14.8903, 16.4427],\n",
      "        [20.5822, 14.9211, 16.1036],\n",
      "        [20.3147, 15.1863, 16.5556],\n",
      "        [19.9576, 15.0122, 16.4089],\n",
      "        [20.6759, 15.2749, 16.5646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0234, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6660,  20.2000, -15.2068],\n",
      "        [-18.6772,  20.0337, -15.1743],\n",
      "        [-19.0206,  20.2480, -14.9846],\n",
      "        [-18.4705,  19.7148, -15.2327],\n",
      "        [-19.1054,  20.1893, -15.3713],\n",
      "        [-18.7365,  20.2821, -15.3407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.0730,  14.6106,  16.0280, -18.6660,  20.2000, -15.2068],\n",
      "        [ 20.3303,  14.8903,  16.4427, -18.6772,  20.0337, -15.1743],\n",
      "        [ 20.5822,  14.9211,  16.1036, -19.0206,  20.2480, -14.9846],\n",
      "        [ 20.3147,  15.1863,  16.5556, -18.4705,  19.7148, -15.2327],\n",
      "        [ 19.9576,  15.0122,  16.4089, -19.1054,  20.1893, -15.3713],\n",
      "        [ 20.6759,  15.2749,  16.5646, -18.7365,  20.2821, -15.3407]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.19889760017395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.3518, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8956, 15.3526, 16.5498],\n",
      "        [20.3004, 14.9173, 16.1032],\n",
      "        [20.5074, 15.3813, 16.3057],\n",
      "        [20.3440, 14.7621, 16.0872],\n",
      "        [20.3434, 14.7943, 16.0933],\n",
      "        [20.5815, 15.2020, 16.4661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1298, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6348,  20.2376, -15.4384],\n",
      "        [-18.3944,  20.0393, -14.8158],\n",
      "        [-18.4949,  20.1361, -15.1197],\n",
      "        [-18.4551,  19.9975, -14.9084],\n",
      "        [-18.9482,  20.2125, -15.1147],\n",
      "        [-18.8618,  20.1691, -15.3456]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8956,  15.3526,  16.5498, -18.6348,  20.2376, -15.4384],\n",
      "        [ 20.3004,  14.9173,  16.1032, -18.3944,  20.0393, -14.8158],\n",
      "        [ 20.5074,  15.3813,  16.3057, -18.4949,  20.1361, -15.1197],\n",
      "        [ 20.3440,  14.7621,  16.0872, -18.4551,  19.9975, -14.9084],\n",
      "        [ 20.3434,  14.7943,  16.0933, -18.9482,  20.2125, -15.1147],\n",
      "        [ 20.5815,  15.2020,  16.4661, -18.8618,  20.1691, -15.3456]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2804882526397705\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9006, 15.2417, 16.4781],\n",
      "        [20.4834, 15.1815, 16.5801],\n",
      "        [20.4453, 15.3305, 16.3488],\n",
      "        [20.8251, 15.1135, 16.4047],\n",
      "        [20.4955, 15.3403, 16.1045],\n",
      "        [20.4736, 14.9318, 15.9717]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6860,  19.9082, -15.1313],\n",
      "        [-18.7232,  20.3400, -14.9195],\n",
      "        [-18.5630,  20.1897, -15.0773],\n",
      "        [-18.3902,  19.6179, -14.4812],\n",
      "        [-18.7997,  20.1518, -14.9430],\n",
      "        [-18.8293,  19.7348, -14.9298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9006,  15.2417,  16.4781, -18.6860,  19.9082, -15.1313],\n",
      "        [ 20.4834,  15.1815,  16.5801, -18.7232,  20.3400, -14.9195],\n",
      "        [ 20.4453,  15.3305,  16.3488, -18.5630,  20.1897, -15.0773],\n",
      "        [ 20.8251,  15.1135,  16.4047, -18.3902,  19.6179, -14.4812],\n",
      "        [ 20.4955,  15.3403,  16.1045, -18.7997,  20.1518, -14.9430],\n",
      "        [ 20.4736,  14.9318,  15.9717, -18.8293,  19.7348, -14.9298]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.2629685401916504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3746, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5665, 15.0443, 16.1476],\n",
      "        [20.5442, 14.7801, 16.1753],\n",
      "        [20.7624, 14.7690, 16.1822],\n",
      "        [20.2689, 14.9509, 16.1456],\n",
      "        [20.9061, 15.1511, 16.4478],\n",
      "        [20.3778, 14.8812, 16.3981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8159,  19.6462, -15.0823],\n",
      "        [-18.2898,  20.0027, -15.2353],\n",
      "        [-18.4538,  19.9257, -14.7878],\n",
      "        [-18.3516,  20.0148, -14.8387],\n",
      "        [-19.0208,  20.2467, -14.6103],\n",
      "        [-18.5384,  19.9511, -14.9300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5665,  15.0443,  16.1476, -18.8159,  19.6462, -15.0823],\n",
      "        [ 20.5442,  14.7801,  16.1753, -18.2898,  20.0027, -15.2353],\n",
      "        [ 20.7624,  14.7690,  16.1822, -18.4538,  19.9257, -14.7878],\n",
      "        [ 20.2689,  14.9509,  16.1456, -18.3516,  20.0148, -14.8387],\n",
      "        [ 20.9061,  15.1511,  16.4478, -19.0208,  20.2467, -14.6103],\n",
      "        [ 20.3778,  14.8812,  16.3981, -18.5384,  19.9511, -14.9300]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2271080017089844\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8768, 15.3321, 16.7662],\n",
      "        [20.5453, 15.1310, 16.2903],\n",
      "        [20.3200, 15.0624, 16.3532],\n",
      "        [20.5531, 15.1672, 16.4672],\n",
      "        [20.4108, 14.7887, 16.3556],\n",
      "        [20.4521, 15.1547, 16.2500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.3558, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.4100,  20.2843, -14.9250],\n",
      "        [-18.6298,  20.0613, -15.3597],\n",
      "        [-18.6797,  20.0578, -15.3647],\n",
      "        [-18.8322,  20.4850, -15.4496],\n",
      "        [-18.7338,  20.3637, -15.0514],\n",
      "        [-18.4957,  19.9161, -14.8866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8768,  15.3321,  16.7662, -18.4100,  20.2843, -14.9250],\n",
      "        [ 20.5453,  15.1310,  16.2903, -18.6298,  20.0613, -15.3597],\n",
      "        [ 20.3200,  15.0624,  16.3532, -18.6797,  20.0578, -15.3647],\n",
      "        [ 20.5531,  15.1672,  16.4672, -18.8322,  20.4850, -15.4496],\n",
      "        [ 20.4108,  14.7887,  16.3556, -18.7338,  20.3637, -15.0514],\n",
      "        [ 20.4521,  15.1547,  16.2500, -18.4957,  19.9161, -14.8866]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2770280838012695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4744, 14.9471, 16.3438],\n",
      "        [20.5089, 15.2050, 16.3275],\n",
      "        [20.4887, 15.2464, 16.1566],\n",
      "        [20.1272, 14.8866, 16.0268],\n",
      "        [20.5786, 15.1280, 16.3865],\n",
      "        [20.9493, 15.1426, 16.4304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.6712, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3787,  20.1906, -15.3498],\n",
      "        [-18.5408,  19.8263, -15.0204],\n",
      "        [-18.4574,  19.9425, -15.3790],\n",
      "        [-18.4695,  19.9076, -14.7714],\n",
      "        [-18.7804,  20.1453, -15.0910],\n",
      "        [-18.7654,  20.2704, -14.9652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4744,  14.9471,  16.3438, -18.3787,  20.1906, -15.3498],\n",
      "        [ 20.5089,  15.2050,  16.3275, -18.5408,  19.8263, -15.0204],\n",
      "        [ 20.4887,  15.2464,  16.1566, -18.4574,  19.9425, -15.3790],\n",
      "        [ 20.1272,  14.8866,  16.0268, -18.4695,  19.9076, -14.7714],\n",
      "        [ 20.5786,  15.1280,  16.3865, -18.7804,  20.1453, -15.0910],\n",
      "        [ 20.9493,  15.1426,  16.4304, -18.7654,  20.2704, -14.9652]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.239468812942505\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1137, 15.0032, 16.3112],\n",
      "        [20.4908, 15.0801, 15.8827],\n",
      "        [20.7319, 15.5146, 16.7301],\n",
      "        [20.4583, 15.0652, 16.3920],\n",
      "        [20.5028, 15.1762, 16.2280],\n",
      "        [20.5535, 15.0921, 16.4741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.7276, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7486,  20.3036, -15.5337],\n",
      "        [-18.2004,  19.6833, -14.6795],\n",
      "        [-18.1235,  20.1236, -14.7975],\n",
      "        [-18.2737,  19.5571, -14.8353],\n",
      "        [-19.2365,  20.5958, -15.7775],\n",
      "        [-18.7363,  20.1347, -15.2270]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1137,  15.0032,  16.3112, -18.7486,  20.3036, -15.5337],\n",
      "        [ 20.4908,  15.0801,  15.8827, -18.2004,  19.6833, -14.6795],\n",
      "        [ 20.7319,  15.5146,  16.7301, -18.1235,  20.1236, -14.7975],\n",
      "        [ 20.4583,  15.0652,  16.3920, -18.2737,  19.5571, -14.8353],\n",
      "        [ 20.5028,  15.1762,  16.2280, -19.2365,  20.5958, -15.7775],\n",
      "        [ 20.5535,  15.0921,  16.4741, -18.7363,  20.1347, -15.2270]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.286372184753418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6490, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4484, 15.2119, 16.3494],\n",
      "        [21.0108, 15.1374, 16.6552],\n",
      "        [20.0619, 14.6793, 16.0655],\n",
      "        [21.0155, 15.3919, 16.6143],\n",
      "        [20.8386, 15.3195, 16.6375],\n",
      "        [20.7098, 14.6947, 16.4049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8461,  20.0127, -14.7306],\n",
      "        [-18.5750,  20.2784, -15.1396],\n",
      "        [-18.4967,  20.2406, -15.3237],\n",
      "        [-18.8882,  20.1042, -14.9730],\n",
      "        [-18.8084,  20.0121, -15.1715],\n",
      "        [-18.4621,  19.9178, -14.7900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4484,  15.2119,  16.3494, -18.8461,  20.0127, -14.7306],\n",
      "        [ 21.0108,  15.1374,  16.6552, -18.5750,  20.2784, -15.1396],\n",
      "        [ 20.0619,  14.6793,  16.0655, -18.4967,  20.2406, -15.3237],\n",
      "        [ 21.0155,  15.3919,  16.6143, -18.8882,  20.1042, -14.9730],\n",
      "        [ 20.8386,  15.3195,  16.6375, -18.8084,  20.0121, -15.1715],\n",
      "        [ 20.7098,  14.6947,  16.4049, -18.4621,  19.9178, -14.7900]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2432446479797363\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.1872, 15.1761, 16.1289],\n",
      "        [21.0066, 14.7296, 16.2666],\n",
      "        [20.7798, 15.0987, 16.4194],\n",
      "        [20.7927, 15.2370, 16.4180],\n",
      "        [20.8493, 15.1940, 16.4171],\n",
      "        [20.2827, 15.0078, 16.1571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5662, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6453,  19.6661, -14.9713],\n",
      "        [-18.5191,  19.8905, -15.1086],\n",
      "        [-18.8012,  20.1358, -15.2250],\n",
      "        [-18.9030,  19.7408, -15.4203],\n",
      "        [-18.7305,  19.9908, -15.0072],\n",
      "        [-18.3298,  20.0444, -14.5387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.1872,  15.1761,  16.1289, -18.6453,  19.6661, -14.9713],\n",
      "        [ 21.0066,  14.7296,  16.2666, -18.5191,  19.8905, -15.1086],\n",
      "        [ 20.7798,  15.0987,  16.4194, -18.8012,  20.1358, -15.2250],\n",
      "        [ 20.7927,  15.2370,  16.4180, -18.9030,  19.7408, -15.4203],\n",
      "        [ 20.8493,  15.1940,  16.4171, -18.7305,  19.9908, -15.0072],\n",
      "        [ 20.2827,  15.0078,  16.1571, -18.3298,  20.0444, -14.5387]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.213564872741699\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8757, 15.2834, 16.3238],\n",
      "        [20.6509, 15.1938, 16.1498],\n",
      "        [20.8024, 15.2895, 16.5486],\n",
      "        [20.1737, 14.7248, 16.0156],\n",
      "        [20.9560, 15.1960, 16.5297],\n",
      "        [20.2319, 14.9066, 16.1538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3640,  19.6618, -15.0087],\n",
      "        [-19.0147,  20.2610, -14.9933],\n",
      "        [-18.8548,  19.8277, -15.1999],\n",
      "        [-18.5167,  20.2787, -15.0502],\n",
      "        [-19.3543,  20.7134, -15.4012],\n",
      "        [-18.3904,  19.7059, -15.1105]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8757,  15.2834,  16.3238, -18.3640,  19.6618, -15.0087],\n",
      "        [ 20.6509,  15.1938,  16.1498, -19.0147,  20.2610, -14.9933],\n",
      "        [ 20.8024,  15.2895,  16.5486, -18.8548,  19.8277, -15.1999],\n",
      "        [ 20.1737,  14.7248,  16.0156, -18.5167,  20.2787, -15.0502],\n",
      "        [ 20.9560,  15.1960,  16.5297, -19.3543,  20.7134, -15.4012],\n",
      "        [ 20.2319,  14.9066,  16.1538, -18.3904,  19.7059, -15.1105]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2496602535247803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0081, 15.2854, 16.6656],\n",
      "        [20.2845, 15.1273, 16.3464],\n",
      "        [20.5313, 14.8088, 16.0832],\n",
      "        [20.7252, 15.4819, 16.7169],\n",
      "        [20.7833, 15.3788, 16.9130],\n",
      "        [20.2234, 14.9037, 16.1918]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.9818, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9966,  19.9879, -15.3904],\n",
      "        [-18.2406,  19.7228, -15.1404],\n",
      "        [-18.8230,  19.8364, -14.9512],\n",
      "        [-18.3754,  19.5041, -14.4709],\n",
      "        [-18.5347,  20.0223, -15.0330],\n",
      "        [-19.2509,  20.3557, -15.4914]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0081,  15.2854,  16.6656, -18.9966,  19.9879, -15.3904],\n",
      "        [ 20.2845,  15.1273,  16.3464, -18.2406,  19.7228, -15.1404],\n",
      "        [ 20.5313,  14.8088,  16.0832, -18.8230,  19.8364, -14.9512],\n",
      "        [ 20.7252,  15.4819,  16.7169, -18.3754,  19.5041, -14.4709],\n",
      "        [ 20.7833,  15.3788,  16.9130, -18.5347,  20.0223, -15.0330],\n",
      "        [ 20.2234,  14.9037,  16.1918, -19.2509,  20.3557, -15.4914]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.302294969558716\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4746, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7134, 15.3215, 16.2438],\n",
      "        [20.6830, 15.1193, 16.1460],\n",
      "        [20.4256, 15.0398, 15.9751],\n",
      "        [21.0248, 15.3667, 16.2953],\n",
      "        [20.0915, 15.3625, 16.3721],\n",
      "        [20.3377, 14.5650, 15.7027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.9775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6085,  20.1901, -15.0352],\n",
      "        [-18.4660,  20.0094, -15.2585],\n",
      "        [-19.0591,  20.1065, -14.9192],\n",
      "        [-18.6297,  19.8423, -15.0662],\n",
      "        [-18.9298,  19.7745, -15.1058],\n",
      "        [-18.4508,  19.7397, -14.6276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7134,  15.3215,  16.2438, -18.6085,  20.1901, -15.0352],\n",
      "        [ 20.6830,  15.1193,  16.1460, -18.4660,  20.0094, -15.2585],\n",
      "        [ 20.4256,  15.0398,  15.9751, -19.0591,  20.1065, -14.9192],\n",
      "        [ 21.0248,  15.3667,  16.2953, -18.6297,  19.8423, -15.0662],\n",
      "        [ 20.0915,  15.3625,  16.3721, -18.9298,  19.7745, -15.1058],\n",
      "        [ 20.3377,  14.5650,  15.7027, -18.4508,  19.7397, -14.6276]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.264600992202759\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9121, 15.3055, 16.7028],\n",
      "        [20.4870, 15.1556, 16.3646],\n",
      "        [20.5715, 15.0256, 16.1196],\n",
      "        [20.8661, 15.4134, 16.5810],\n",
      "        [20.9555, 15.5862, 16.7833],\n",
      "        [20.1733, 14.8411, 15.9516]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.5693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.3040,  19.7660, -15.0974],\n",
      "        [-18.6880,  19.8746, -15.1921],\n",
      "        [-18.5403,  20.1730, -15.2207],\n",
      "        [-18.7283,  20.0105, -15.0207],\n",
      "        [-18.6562,  20.0821, -15.1893],\n",
      "        [-18.6340,  20.2292, -15.0251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9121,  15.3055,  16.7028, -18.3040,  19.7660, -15.0974],\n",
      "        [ 20.4870,  15.1556,  16.3646, -18.6880,  19.8746, -15.1921],\n",
      "        [ 20.5715,  15.0256,  16.1196, -18.5403,  20.1730, -15.2207],\n",
      "        [ 20.8661,  15.4134,  16.5810, -18.7283,  20.0105, -15.0207],\n",
      "        [ 20.9555,  15.5862,  16.7833, -18.6562,  20.0821, -15.1893],\n",
      "        [ 20.1733,  14.8411,  15.9516, -18.6340,  20.2292, -15.0251]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2730696201324463\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8454, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6419, 15.4499, 16.3842],\n",
      "        [20.4543, 15.0248, 16.3326],\n",
      "        [20.9131, 15.4512, 16.7030],\n",
      "        [20.5207, 14.8959, 16.5870],\n",
      "        [20.7795, 15.2694, 16.4573],\n",
      "        [20.4517, 14.9523, 15.6471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1552,  19.7264, -14.9719],\n",
      "        [-18.3246,  20.2585, -15.2858],\n",
      "        [-18.9359,  20.6650, -15.4061],\n",
      "        [-18.5520,  20.3386, -15.0590],\n",
      "        [-18.7553,  19.8326, -14.8316],\n",
      "        [-18.6338,  19.8450, -14.9678]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6419,  15.4499,  16.3842, -18.1552,  19.7264, -14.9719],\n",
      "        [ 20.4543,  15.0248,  16.3326, -18.3246,  20.2585, -15.2858],\n",
      "        [ 20.9131,  15.4512,  16.7030, -18.9359,  20.6650, -15.4061],\n",
      "        [ 20.5207,  14.8959,  16.5870, -18.5520,  20.3386, -15.0590],\n",
      "        [ 20.7795,  15.2694,  16.4573, -18.7553,  19.8326, -14.8316],\n",
      "        [ 20.4517,  14.9523,  15.6471, -18.6338,  19.8450, -14.9678]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.246835470199585\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4974, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4631, 15.0527, 16.5188],\n",
      "        [20.5943, 15.0707, 16.6209],\n",
      "        [20.8197, 15.3919, 16.5244],\n",
      "        [20.8276, 15.3326, 16.5415],\n",
      "        [20.7332, 15.4393, 16.5921],\n",
      "        [20.7624, 15.4258, 16.2053]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2102,  20.2643, -15.2865],\n",
      "        [-19.3206,  20.5861, -15.1180],\n",
      "        [-18.3316,  19.7213, -14.9082],\n",
      "        [-18.5741,  20.1229, -14.9422],\n",
      "        [-18.8016,  20.5874, -15.0279],\n",
      "        [-18.1555,  19.5903, -14.6293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4631,  15.0527,  16.5188, -19.2102,  20.2643, -15.2865],\n",
      "        [ 20.5943,  15.0707,  16.6209, -19.3206,  20.5861, -15.1180],\n",
      "        [ 20.8197,  15.3919,  16.5244, -18.3316,  19.7213, -14.9082],\n",
      "        [ 20.8276,  15.3326,  16.5415, -18.5741,  20.1229, -14.9422],\n",
      "        [ 20.7332,  15.4393,  16.5921, -18.8016,  20.5874, -15.0279],\n",
      "        [ 20.7624,  15.4258,  16.2053, -18.1555,  19.5903, -14.6293]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.2828867435455322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4567, 15.0733, 16.2594],\n",
      "        [20.6515, 15.0529, 16.4334],\n",
      "        [21.3032, 15.6282, 16.5105],\n",
      "        [20.7207, 15.1471, 16.0738],\n",
      "        [20.4980, 14.9990, 16.5448],\n",
      "        [20.4383, 14.9992, 16.1987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8560, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.1271,  19.7729, -14.9087],\n",
      "        [-18.9759,  20.1032, -15.4807],\n",
      "        [-18.1830,  19.4613, -14.9049],\n",
      "        [-18.7645,  19.6013, -15.3550],\n",
      "        [-18.5579,  20.1910, -15.1835],\n",
      "        [-18.1128,  19.9322, -14.6049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4567,  15.0733,  16.2594, -18.1271,  19.7729, -14.9087],\n",
      "        [ 20.6515,  15.0529,  16.4334, -18.9759,  20.1032, -15.4807],\n",
      "        [ 21.3032,  15.6282,  16.5105, -18.1830,  19.4613, -14.9049],\n",
      "        [ 20.7207,  15.1471,  16.0738, -18.7645,  19.6013, -15.3550],\n",
      "        [ 20.4980,  14.9990,  16.5448, -18.5579,  20.1910, -15.1835],\n",
      "        [ 20.4383,  14.9992,  16.1987, -18.1128,  19.9322, -14.6049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2262070178985596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5630, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6707, 15.2746, 16.6682],\n",
      "        [20.7549, 15.3598, 16.6307],\n",
      "        [20.5013, 15.1093, 16.1361],\n",
      "        [20.4208, 14.8913, 16.6397],\n",
      "        [21.2011, 15.7431, 16.6814],\n",
      "        [21.0799, 15.3483, 16.4430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1941,  19.8999, -15.0374],\n",
      "        [-19.3540,  20.7865, -15.4108],\n",
      "        [-18.7607,  19.7794, -14.8814],\n",
      "        [-18.7371,  20.3724, -15.1535],\n",
      "        [-18.8411,  20.1698, -15.4085],\n",
      "        [-18.6651,  20.0049, -15.0650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6707,  15.2746,  16.6682, -19.1941,  19.8999, -15.0374],\n",
      "        [ 20.7549,  15.3598,  16.6307, -19.3540,  20.7865, -15.4108],\n",
      "        [ 20.5013,  15.1093,  16.1361, -18.7607,  19.7794, -14.8814],\n",
      "        [ 20.4208,  14.8913,  16.6397, -18.7371,  20.3724, -15.1535],\n",
      "        [ 21.2011,  15.7431,  16.6814, -18.8411,  20.1698, -15.4085],\n",
      "        [ 21.0799,  15.3483,  16.4430, -18.6651,  20.0049, -15.0650]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.291027545928955\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7353, 15.1281, 16.7353],\n",
      "        [20.6771, 15.3778, 16.7840],\n",
      "        [20.9316, 15.2674, 16.4985],\n",
      "        [20.5295, 15.2996, 16.1682],\n",
      "        [20.8243, 15.4016, 16.9411],\n",
      "        [20.6543, 15.0870, 16.2022]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2317, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8313,  20.6494, -15.5351],\n",
      "        [-18.7445,  19.9763, -15.2852],\n",
      "        [-18.9963,  20.2507, -15.3078],\n",
      "        [-18.5090,  19.8766, -14.9124],\n",
      "        [-19.1120,  20.2847, -15.4856],\n",
      "        [-18.5775,  20.0384, -15.1665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7353,  15.1281,  16.7353, -18.8313,  20.6494, -15.5351],\n",
      "        [ 20.6771,  15.3778,  16.7840, -18.7445,  19.9763, -15.2852],\n",
      "        [ 20.9316,  15.2674,  16.4985, -18.9963,  20.2507, -15.3078],\n",
      "        [ 20.5295,  15.2996,  16.1682, -18.5090,  19.8766, -14.9124],\n",
      "        [ 20.8243,  15.4016,  16.9411, -19.1120,  20.2847, -15.4856],\n",
      "        [ 20.6543,  15.0870,  16.2022, -18.5775,  20.0384, -15.1665]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3153011798858643\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0970, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5600, 15.4754, 16.4667],\n",
      "        [20.9533, 15.4780, 16.2594],\n",
      "        [20.9598, 15.7022, 16.8351],\n",
      "        [19.9728, 14.8134, 16.3162],\n",
      "        [20.6757, 15.4127, 16.4348],\n",
      "        [20.0796, 14.6398, 15.7545]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.0049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9922,  20.1059, -15.1078],\n",
      "        [-18.6361,  20.3060, -15.4387],\n",
      "        [-19.1912,  20.3864, -15.4403],\n",
      "        [-19.0205,  20.1622, -15.4845],\n",
      "        [-18.7139,  20.0408, -15.4723],\n",
      "        [-18.5300,  19.9441, -15.0857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5600,  15.4754,  16.4667, -18.9922,  20.1059, -15.1078],\n",
      "        [ 20.9533,  15.4780,  16.2594, -18.6361,  20.3060, -15.4387],\n",
      "        [ 20.9598,  15.7022,  16.8351, -19.1912,  20.3864, -15.4403],\n",
      "        [ 19.9728,  14.8134,  16.3162, -19.0205,  20.1622, -15.4845],\n",
      "        [ 20.6757,  15.4127,  16.4348, -18.7139,  20.0408, -15.4723],\n",
      "        [ 20.0796,  14.6398,  15.7545, -18.5300,  19.9441, -15.0857]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2885148525238037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.4559, 15.1771, 16.4020],\n",
      "        [20.8538, 15.4741, 16.4641],\n",
      "        [21.3231, 15.6418, 16.6723],\n",
      "        [19.8857, 14.8948, 16.1568],\n",
      "        [20.8017, 15.1263, 16.7844],\n",
      "        [20.6226, 15.0694, 16.4374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3971, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7224,  20.0332, -15.3261],\n",
      "        [-18.8310,  19.8268, -14.8951],\n",
      "        [-18.7635,  20.4573, -15.3602],\n",
      "        [-18.7187,  20.1767, -15.1551],\n",
      "        [-18.8041,  19.8343, -15.0677],\n",
      "        [-19.0281,  20.5899, -15.6076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.4559,  15.1771,  16.4020, -18.7224,  20.0332, -15.3261],\n",
      "        [ 20.8538,  15.4741,  16.4641, -18.8310,  19.8268, -14.8951],\n",
      "        [ 21.3231,  15.6418,  16.6723, -18.7635,  20.4573, -15.3602],\n",
      "        [ 19.8857,  14.8948,  16.1568, -18.7187,  20.1767, -15.1551],\n",
      "        [ 20.8017,  15.1263,  16.7844, -18.8041,  19.8343, -15.0677],\n",
      "        [ 20.6226,  15.0694,  16.4374, -19.0281,  20.5899, -15.6076]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.2703025341033936\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0815, 15.5010, 16.5709],\n",
      "        [20.1797, 15.2639, 16.6899],\n",
      "        [20.1613, 14.6638, 16.0109],\n",
      "        [20.9564, 15.4026, 16.8454],\n",
      "        [20.7046, 15.2520, 16.7768],\n",
      "        [20.9275, 15.1413, 16.3283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.3995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6956,  20.2992, -15.2524],\n",
      "        [-19.1506,  20.5602, -15.4819],\n",
      "        [-19.0718,  20.0716, -15.3760],\n",
      "        [-18.3976,  20.0326, -15.0519],\n",
      "        [-18.7335,  20.3450, -15.0508],\n",
      "        [-18.6755,  20.2967, -15.2327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0815,  15.5010,  16.5709, -18.6956,  20.2992, -15.2524],\n",
      "        [ 20.1797,  15.2639,  16.6899, -19.1506,  20.5602, -15.4819],\n",
      "        [ 20.1613,  14.6638,  16.0109, -19.0718,  20.0716, -15.3760],\n",
      "        [ 20.9564,  15.4026,  16.8454, -18.3976,  20.0326, -15.0519],\n",
      "        [ 20.7046,  15.2520,  16.7768, -18.7335,  20.3450, -15.0508],\n",
      "        [ 20.9275,  15.1413,  16.3283, -18.6755,  20.2967, -15.2327]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.3202743530273438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6035, 15.3468, 16.3049],\n",
      "        [20.4410, 15.0752, 16.1175],\n",
      "        [21.0782, 15.6579, 16.6285],\n",
      "        [20.8741, 15.1626, 16.6862],\n",
      "        [20.4473, 15.2669, 16.0752],\n",
      "        [20.5553, 15.2619, 16.1123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6136, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7478,  20.2617, -15.1506],\n",
      "        [-18.6618,  19.9770, -15.4079],\n",
      "        [-19.0507,  20.1220, -15.1103],\n",
      "        [-18.8119,  19.9583, -14.9027],\n",
      "        [-18.7891,  20.3301, -14.9216],\n",
      "        [-18.8454,  19.9023, -15.1330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6035,  15.3468,  16.3049, -18.7478,  20.2617, -15.1506],\n",
      "        [ 20.4410,  15.0752,  16.1175, -18.6618,  19.9770, -15.4079],\n",
      "        [ 21.0782,  15.6579,  16.6285, -19.0507,  20.1220, -15.1103],\n",
      "        [ 20.8741,  15.1626,  16.6862, -18.8119,  19.9583, -14.9027],\n",
      "        [ 20.4473,  15.2669,  16.0752, -18.7891,  20.3301, -14.9216],\n",
      "        [ 20.5553,  15.2619,  16.1123, -18.8454,  19.9023, -15.1330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.284360647201538\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0474, 15.4717, 16.6106],\n",
      "        [20.5066, 15.2897, 16.5221],\n",
      "        [20.5452, 15.3483, 16.6871],\n",
      "        [20.3008, 15.5218, 16.3589],\n",
      "        [20.6583, 15.5037, 16.6871],\n",
      "        [19.9640, 15.0902, 16.2172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.7706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7893,  20.3037, -15.2341],\n",
      "        [-18.5835,  19.9294, -15.1974],\n",
      "        [-18.7443,  19.8741, -15.0237],\n",
      "        [-18.7837,  19.9043, -15.2342],\n",
      "        [-18.8421,  19.7769, -15.1882],\n",
      "        [-18.8148,  20.5110, -15.2990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0474,  15.4717,  16.6106, -18.7893,  20.3037, -15.2341],\n",
      "        [ 20.5066,  15.2897,  16.5221, -18.5835,  19.9294, -15.1974],\n",
      "        [ 20.5452,  15.3483,  16.6871, -18.7443,  19.8741, -15.0237],\n",
      "        [ 20.3008,  15.5218,  16.3589, -18.7837,  19.9043, -15.2342],\n",
      "        [ 20.6583,  15.5037,  16.6871, -18.8421,  19.7769, -15.1882],\n",
      "        [ 19.9640,  15.0902,  16.2172, -18.8148,  20.5110, -15.2990]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.324448823928833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9040, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7073, 15.3869, 16.5554],\n",
      "        [20.8036, 15.1339, 16.2250],\n",
      "        [21.0266, 15.0936, 16.4878],\n",
      "        [20.6551, 15.2913, 16.4542],\n",
      "        [20.6333, 15.4721, 16.3875],\n",
      "        [20.8369, 15.3330, 16.4820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.9570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6980,  20.0999, -14.9786],\n",
      "        [-18.5698,  20.6309, -15.1817],\n",
      "        [-18.9125,  20.3770, -14.9986],\n",
      "        [-18.5108,  19.9097, -15.3312],\n",
      "        [-18.9730,  20.2397, -15.5239],\n",
      "        [-18.5909,  19.7955, -15.5470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7073,  15.3869,  16.5554, -18.6980,  20.0999, -14.9786],\n",
      "        [ 20.8036,  15.1339,  16.2250, -18.5698,  20.6309, -15.1817],\n",
      "        [ 21.0266,  15.0936,  16.4878, -18.9125,  20.3770, -14.9986],\n",
      "        [ 20.6551,  15.2913,  16.4542, -18.5108,  19.9097, -15.3312],\n",
      "        [ 20.6333,  15.4721,  16.3875, -18.9730,  20.2397, -15.5239],\n",
      "        [ 20.8369,  15.3330,  16.4820, -18.5909,  19.7955, -15.5470]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.293051242828369\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3539, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7346, 15.0674, 16.5062],\n",
      "        [20.7096, 15.3790, 16.4829],\n",
      "        [20.6514, 14.9437, 16.1303],\n",
      "        [20.9976, 15.9690, 16.3985],\n",
      "        [20.8495, 15.3316, 16.6099],\n",
      "        [20.7293, 15.7225, 16.6628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5767,  19.8632, -15.2802],\n",
      "        [-19.1161,  20.5033, -15.5010],\n",
      "        [-19.3641,  20.6237, -15.8084],\n",
      "        [-18.7597,  20.0467, -14.8815],\n",
      "        [-19.0862,  20.2861, -15.2673],\n",
      "        [-18.7666,  20.0343, -14.9402]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7346,  15.0674,  16.5062, -18.5767,  19.8632, -15.2802],\n",
      "        [ 20.7096,  15.3790,  16.4829, -19.1161,  20.5033, -15.5010],\n",
      "        [ 20.6514,  14.9437,  16.1303, -19.3641,  20.6237, -15.8084],\n",
      "        [ 20.9976,  15.9690,  16.3985, -18.7597,  20.0467, -14.8815],\n",
      "        [ 20.8495,  15.3316,  16.6099, -19.0862,  20.2861, -15.2673],\n",
      "        [ 20.7293,  15.7225,  16.6628, -18.7666,  20.0343, -14.9402]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.281684160232544\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8949, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5839, 15.2734, 16.5786],\n",
      "        [20.8584, 15.5793, 16.6165],\n",
      "        [20.9622, 15.7125, 16.8455],\n",
      "        [20.1985, 14.8564, 15.7869],\n",
      "        [21.0007, 15.4579, 16.4215],\n",
      "        [20.1045, 15.0029, 16.1712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.2849, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6264,  19.7470, -14.8633],\n",
      "        [-19.1467,  20.1867, -15.1375],\n",
      "        [-18.9667,  19.9947, -15.0380],\n",
      "        [-19.1248,  20.2664, -15.6522],\n",
      "        [-18.6963,  20.2629, -14.8363],\n",
      "        [-18.9048,  20.3704, -15.3714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5839,  15.2734,  16.5786, -18.6264,  19.7470, -14.8633],\n",
      "        [ 20.8584,  15.5793,  16.6165, -19.1467,  20.1867, -15.1375],\n",
      "        [ 20.9622,  15.7125,  16.8455, -18.9667,  19.9947, -15.0380],\n",
      "        [ 20.1985,  14.8564,  15.7869, -19.1248,  20.2664, -15.6522],\n",
      "        [ 21.0007,  15.4579,  16.4215, -18.6963,  20.2629, -14.8363],\n",
      "        [ 20.1045,  15.0029,  16.1712, -18.9048,  20.3704, -15.3714]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.274134635925293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7333, 15.5842, 16.3380],\n",
      "        [20.0643, 14.8313, 16.3258],\n",
      "        [21.0419, 15.5279, 16.6366],\n",
      "        [20.3292, 15.4901, 16.3889],\n",
      "        [21.3824, 15.2914, 16.9315],\n",
      "        [20.6266, 15.1445, 16.5312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9323,  20.2006, -15.5847],\n",
      "        [-19.0273,  20.3574, -15.8430],\n",
      "        [-18.5509,  19.8530, -14.9358],\n",
      "        [-18.8923,  20.4218, -15.3408],\n",
      "        [-18.7778,  20.1846, -15.0973],\n",
      "        [-19.1401,  20.7165, -15.8700]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7333,  15.5842,  16.3380, -18.9323,  20.2006, -15.5847],\n",
      "        [ 20.0643,  14.8313,  16.3258, -19.0273,  20.3574, -15.8430],\n",
      "        [ 21.0419,  15.5279,  16.6366, -18.5509,  19.8530, -14.9358],\n",
      "        [ 20.3292,  15.4901,  16.3889, -18.8923,  20.4218, -15.3408],\n",
      "        [ 21.3824,  15.2914,  16.9315, -18.7778,  20.1846, -15.0973],\n",
      "        [ 20.6266,  15.1445,  16.5312, -19.1401,  20.7165, -15.8700]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.316230535507202\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7749, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3481, 15.7554, 16.8098],\n",
      "        [21.1564, 15.7026, 16.7742],\n",
      "        [21.2601, 15.2190, 16.7172],\n",
      "        [20.7422, 15.4113, 16.3599],\n",
      "        [20.3930, 15.4152, 16.5929],\n",
      "        [20.6049, 14.9371, 16.2762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.0849, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.6296,  20.0774, -15.2903],\n",
      "        [-18.7712,  20.2207, -15.2226],\n",
      "        [-18.8238,  20.2822, -15.0306],\n",
      "        [-19.3722,  20.4077, -15.4148],\n",
      "        [-18.9303,  20.4059, -15.1616],\n",
      "        [-18.5626,  20.0260, -14.9154]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3481,  15.7554,  16.8098, -18.6296,  20.0774, -15.2903],\n",
      "        [ 21.1564,  15.7026,  16.7742, -18.7712,  20.2207, -15.2226],\n",
      "        [ 21.2601,  15.2190,  16.7172, -18.8238,  20.2822, -15.0306],\n",
      "        [ 20.7422,  15.4113,  16.3599, -19.3722,  20.4077, -15.4148],\n",
      "        [ 20.3930,  15.4152,  16.5929, -18.9303,  20.4059, -15.1616],\n",
      "        [ 20.6049,  14.9371,  16.2762, -18.5626,  20.0260, -14.9154]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3506922721862793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2339, 15.9444, 16.8197],\n",
      "        [21.0521, 15.3087, 16.7512],\n",
      "        [20.8857, 15.1113, 16.7395],\n",
      "        [20.9400, 15.3831, 16.5705],\n",
      "        [20.8318, 15.2231, 16.6145],\n",
      "        [20.7343, 15.2478, 15.9442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.9568, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0332,  20.2558, -15.7323],\n",
      "        [-19.0386,  20.3345, -15.1400],\n",
      "        [-18.5022,  20.1205, -14.8921],\n",
      "        [-18.6669,  20.1409, -15.0100],\n",
      "        [-18.9074,  20.3071, -15.1879],\n",
      "        [-18.8966,  20.0639, -15.1733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2339,  15.9444,  16.8197, -19.0332,  20.2558, -15.7323],\n",
      "        [ 21.0521,  15.3087,  16.7512, -19.0386,  20.3345, -15.1400],\n",
      "        [ 20.8857,  15.1113,  16.7395, -18.5022,  20.1205, -14.8921],\n",
      "        [ 20.9400,  15.3831,  16.5705, -18.6669,  20.1409, -15.0100],\n",
      "        [ 20.8318,  15.2231,  16.6145, -18.9074,  20.3071, -15.1879],\n",
      "        [ 20.7343,  15.2478,  15.9442, -18.8966,  20.0639, -15.1733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.376213550567627\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4709, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6311, 15.7894, 16.7658],\n",
      "        [20.3362, 15.4231, 16.6302],\n",
      "        [20.3977, 15.1239, 16.2700],\n",
      "        [20.9334, 14.6845, 16.0515],\n",
      "        [20.4223, 15.4373, 16.2644],\n",
      "        [20.8543, 15.5490, 16.8033]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2219, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.5285,  20.1587, -15.1259],\n",
      "        [-19.1082,  20.2568, -15.3940],\n",
      "        [-19.1504,  20.3859, -15.2621],\n",
      "        [-19.3604,  20.3639, -15.5328],\n",
      "        [-19.0111,  20.2472, -15.3818],\n",
      "        [-19.1967,  20.7470, -15.6018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6311,  15.7894,  16.7658, -18.5285,  20.1587, -15.1259],\n",
      "        [ 20.3362,  15.4231,  16.6302, -19.1082,  20.2568, -15.3940],\n",
      "        [ 20.3977,  15.1239,  16.2700, -19.1504,  20.3859, -15.2621],\n",
      "        [ 20.9334,  14.6845,  16.0515, -19.3604,  20.3639, -15.5328],\n",
      "        [ 20.4223,  15.4373,  16.2644, -19.0111,  20.2472, -15.3818],\n",
      "        [ 20.8543,  15.5490,  16.8033, -19.1967,  20.7470, -15.6018]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.316403865814209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5916, 15.1474, 16.3693],\n",
      "        [20.5781, 15.2025, 16.1534],\n",
      "        [20.4285, 15.1069, 16.8722],\n",
      "        [20.3896, 15.2765, 16.2452],\n",
      "        [20.8792, 15.3371, 16.4855],\n",
      "        [20.6519, 15.1401, 16.5921]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5841, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0868,  20.5790, -15.4596],\n",
      "        [-19.0047,  20.1857, -15.4402],\n",
      "        [-18.8630,  19.9266, -15.2890],\n",
      "        [-18.5323,  19.9632, -15.3122],\n",
      "        [-19.1417,  20.6873, -15.5692],\n",
      "        [-18.8347,  20.3266, -15.1141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5916,  15.1474,  16.3693, -19.0868,  20.5790, -15.4596],\n",
      "        [ 20.5781,  15.2025,  16.1534, -19.0047,  20.1857, -15.4402],\n",
      "        [ 20.4285,  15.1069,  16.8722, -18.8630,  19.9266, -15.2890],\n",
      "        [ 20.3896,  15.2765,  16.2452, -18.5323,  19.9632, -15.3122],\n",
      "        [ 20.8792,  15.3371,  16.4855, -19.1417,  20.6873, -15.5692],\n",
      "        [ 20.6519,  15.1401,  16.5921, -18.8347,  20.3266, -15.1141]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3174045085906982\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0090, 15.7996, 16.4307],\n",
      "        [20.7268, 15.3454, 16.6385],\n",
      "        [20.9822, 15.3857, 16.6206],\n",
      "        [20.9066, 15.4410, 16.7112],\n",
      "        [20.4881, 14.9955, 16.3631],\n",
      "        [20.2698, 15.1473, 16.0430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.5194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9492,  20.6303, -15.4776],\n",
      "        [-18.6647,  20.0896, -15.1499],\n",
      "        [-18.8646,  20.3356, -15.2873],\n",
      "        [-19.0057,  20.5774, -15.2309],\n",
      "        [-19.2496,  20.4758, -15.5565],\n",
      "        [-19.2586,  20.6081, -15.5166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0090,  15.7996,  16.4307, -18.9492,  20.6303, -15.4776],\n",
      "        [ 20.7268,  15.3454,  16.6385, -18.6647,  20.0896, -15.1499],\n",
      "        [ 20.9822,  15.3857,  16.6206, -18.8646,  20.3356, -15.2873],\n",
      "        [ 20.9066,  15.4410,  16.7112, -19.0057,  20.5774, -15.2309],\n",
      "        [ 20.4881,  14.9955,  16.3631, -19.2496,  20.4758, -15.5565],\n",
      "        [ 20.2698,  15.1473,  16.0430, -19.2586,  20.6081, -15.5166]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3554859161376953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6913, 15.6570, 16.6912],\n",
      "        [20.3783, 15.4991, 16.0548],\n",
      "        [20.6425, 15.2591, 16.5130],\n",
      "        [20.6803, 15.4974, 16.5514],\n",
      "        [20.7191, 15.1915, 16.3701],\n",
      "        [20.7457, 15.2968, 16.5883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.1979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7648,  20.2721, -15.4850],\n",
      "        [-18.8793,  20.6011, -15.2999],\n",
      "        [-19.1138,  20.4455, -15.2880],\n",
      "        [-18.9890,  20.4489, -15.3870],\n",
      "        [-19.2535,  20.9673, -15.5647],\n",
      "        [-18.7246,  19.8887, -14.7890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6913,  15.6570,  16.6912, -18.7648,  20.2721, -15.4850],\n",
      "        [ 20.3783,  15.4991,  16.0548, -18.8793,  20.6011, -15.2999],\n",
      "        [ 20.6425,  15.2591,  16.5130, -19.1138,  20.4455, -15.2880],\n",
      "        [ 20.6803,  15.4974,  16.5514, -18.9890,  20.4489, -15.3870],\n",
      "        [ 20.7191,  15.1915,  16.3701, -19.2535,  20.9673, -15.5647],\n",
      "        [ 20.7457,  15.2968,  16.5883, -18.7246,  19.8887, -14.7890]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.3335378170013428\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5864, 15.1089, 16.4002],\n",
      "        [21.1595, 15.6974, 16.6519],\n",
      "        [20.9564, 15.5429, 16.7673],\n",
      "        [20.2124, 15.2598, 16.3504],\n",
      "        [20.7571, 15.3839, 16.7744],\n",
      "        [20.9881, 15.4172, 16.7530]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.0554, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4306,  20.6007, -15.4610],\n",
      "        [-18.7467,  20.4886, -15.3559],\n",
      "        [-18.7368,  20.3477, -14.8675],\n",
      "        [-19.0349,  20.7320, -15.5415],\n",
      "        [-18.8463,  20.4424, -15.3293],\n",
      "        [-19.2742,  20.4851, -15.3440]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5864,  15.1089,  16.4002, -19.4306,  20.6007, -15.4610],\n",
      "        [ 21.1595,  15.6974,  16.6519, -18.7467,  20.4886, -15.3559],\n",
      "        [ 20.9564,  15.5429,  16.7673, -18.7368,  20.3477, -14.8675],\n",
      "        [ 20.2124,  15.2598,  16.3504, -19.0349,  20.7320, -15.5415],\n",
      "        [ 20.7571,  15.3839,  16.7744, -18.8463,  20.4424, -15.3293],\n",
      "        [ 20.9881,  15.4172,  16.7530, -19.2742,  20.4851, -15.3440]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3311195373535156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1034, 15.3048, 16.3883],\n",
      "        [21.0068, 15.5285, 16.6368],\n",
      "        [20.2964, 14.9706, 16.0487],\n",
      "        [21.2752, 16.0879, 16.6621],\n",
      "        [20.8534, 15.3132, 16.6736],\n",
      "        [20.9268, 15.4968, 16.6686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5274, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0109,  20.3465, -15.3138],\n",
      "        [-18.8807,  19.6807, -14.7132],\n",
      "        [-19.0090,  20.3828, -15.3853],\n",
      "        [-18.6093,  19.9560, -15.2971],\n",
      "        [-19.1201,  20.3755, -15.4077],\n",
      "        [-19.1210,  20.3845, -15.5499]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1034,  15.3048,  16.3883, -19.0109,  20.3465, -15.3138],\n",
      "        [ 21.0068,  15.5285,  16.6368, -18.8807,  19.6807, -14.7132],\n",
      "        [ 20.2964,  14.9706,  16.0487, -19.0090,  20.3828, -15.3853],\n",
      "        [ 21.2752,  16.0879,  16.6621, -18.6093,  19.9560, -15.2971],\n",
      "        [ 20.8534,  15.3132,  16.6736, -19.1201,  20.3755, -15.4077],\n",
      "        [ 20.9268,  15.4968,  16.6686, -19.1210,  20.3845, -15.5499]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3400511741638184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7736, 15.5587, 16.9901],\n",
      "        [21.2501, 15.5698, 17.0989],\n",
      "        [20.1209, 15.0715, 16.2684],\n",
      "        [20.4121, 15.1708, 16.1548],\n",
      "        [20.7555, 15.1643, 16.2919],\n",
      "        [20.6103, 15.3546, 16.5807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2477, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9177,  19.8514, -15.5500],\n",
      "        [-18.9949,  20.1348, -15.1889],\n",
      "        [-18.6938,  19.8109, -15.1063],\n",
      "        [-18.7871,  20.0098, -15.1026],\n",
      "        [-18.5987,  19.8777, -15.2158],\n",
      "        [-19.0677,  20.1243, -15.3395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7736,  15.5587,  16.9901, -18.9177,  19.8514, -15.5500],\n",
      "        [ 21.2501,  15.5698,  17.0989, -18.9949,  20.1348, -15.1889],\n",
      "        [ 20.1209,  15.0715,  16.2684, -18.6938,  19.8109, -15.1063],\n",
      "        [ 20.4121,  15.1708,  16.1548, -18.7871,  20.0098, -15.1026],\n",
      "        [ 20.7555,  15.1643,  16.2919, -18.5987,  19.8777, -15.2158],\n",
      "        [ 20.6103,  15.3546,  16.5807, -19.0677,  20.1243, -15.3395]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.343473196029663\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5376, 15.4844, 16.5077],\n",
      "        [20.7603, 15.2222, 16.3918],\n",
      "        [20.2541, 14.9783, 16.4771],\n",
      "        [21.5914, 15.7037, 16.7460],\n",
      "        [21.0297, 15.7415, 16.5577],\n",
      "        [20.7226, 15.1672, 16.4767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(13.3128, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6200,  20.7467, -15.8917],\n",
      "        [-19.2982,  20.6112, -15.6596],\n",
      "        [-18.7967,  20.5700, -15.3139],\n",
      "        [-19.4542,  20.5130, -15.8608],\n",
      "        [-18.7695,  20.3620, -15.1184],\n",
      "        [-18.7072,  19.7173, -15.2924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5376,  15.4844,  16.5077, -19.6200,  20.7467, -15.8917],\n",
      "        [ 20.7603,  15.2222,  16.3918, -19.2982,  20.6112, -15.6596],\n",
      "        [ 20.2541,  14.9783,  16.4771, -18.7967,  20.5700, -15.3139],\n",
      "        [ 21.5914,  15.7037,  16.7460, -19.4542,  20.5130, -15.8608],\n",
      "        [ 21.0297,  15.7415,  16.5577, -18.7695,  20.3620, -15.1184],\n",
      "        [ 20.7226,  15.1672,  16.4767, -18.7072,  19.7173, -15.2924]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3644115924835205\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7954, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5797, 15.4585, 16.4197],\n",
      "        [21.0859, 15.4990, 16.7975],\n",
      "        [20.1888, 15.1121, 16.5394],\n",
      "        [20.8372, 15.4765, 16.7266],\n",
      "        [20.9570, 15.3883, 17.0550],\n",
      "        [21.1072, 14.9897, 16.5194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2891, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3815,  20.6272, -15.5667],\n",
      "        [-18.8812,  20.6922, -15.7606],\n",
      "        [-19.2017,  20.1783, -15.5514],\n",
      "        [-18.5288,  19.9303, -14.7670],\n",
      "        [-19.4684,  20.5150, -15.9578],\n",
      "        [-19.0566,  20.2087, -15.2029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5797,  15.4585,  16.4197, -19.3815,  20.6272, -15.5667],\n",
      "        [ 21.0859,  15.4990,  16.7975, -18.8812,  20.6922, -15.7606],\n",
      "        [ 20.1888,  15.1121,  16.5394, -19.2017,  20.1783, -15.5514],\n",
      "        [ 20.8372,  15.4765,  16.7266, -18.5288,  19.9303, -14.7670],\n",
      "        [ 20.9570,  15.3883,  17.0550, -19.4684,  20.5150, -15.9578],\n",
      "        [ 21.1072,  14.9897,  16.5194, -19.0566,  20.2087, -15.2029]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.347931385040283\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8161, 15.1151, 16.6446],\n",
      "        [20.7087, 15.5184, 16.7463],\n",
      "        [20.8891, 15.1331, 16.4960],\n",
      "        [20.5979, 14.9100, 16.4298],\n",
      "        [20.7535, 15.3158, 16.2250],\n",
      "        [20.7612, 15.3025, 16.4276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.1478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4650,  20.9521, -16.1497],\n",
      "        [-18.8640,  20.0562, -15.0688],\n",
      "        [-19.0539,  20.4714, -15.1817],\n",
      "        [-19.0849,  20.0907, -15.5793],\n",
      "        [-19.4478,  20.8981, -15.6491],\n",
      "        [-18.9282,  20.4946, -15.6714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8161,  15.1151,  16.6446, -19.4650,  20.9521, -16.1497],\n",
      "        [ 20.7087,  15.5184,  16.7463, -18.8640,  20.0562, -15.0688],\n",
      "        [ 20.8891,  15.1331,  16.4960, -19.0539,  20.4714, -15.1817],\n",
      "        [ 20.5979,  14.9100,  16.4298, -19.0849,  20.0907, -15.5793],\n",
      "        [ 20.7535,  15.3158,  16.2250, -19.4478,  20.8981, -15.6491],\n",
      "        [ 20.7612,  15.3025,  16.4276, -18.9282,  20.4946, -15.6714]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.3823418617248535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8058, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5792, 15.3565, 16.7844],\n",
      "        [21.0845, 15.5920, 16.3797],\n",
      "        [21.0402, 15.3484, 16.8795],\n",
      "        [21.1866, 15.6205, 16.8560],\n",
      "        [20.4061, 15.2595, 16.1726],\n",
      "        [20.6361, 15.1766, 16.6775]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0133, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9366,  20.5275, -15.7568],\n",
      "        [-18.3077,  20.0331, -15.4015],\n",
      "        [-18.6094,  19.9668, -15.0230],\n",
      "        [-19.3739,  20.3623, -15.4461],\n",
      "        [-19.0455,  20.3433, -15.4070],\n",
      "        [-18.8242,  20.2537, -15.3589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5792,  15.3565,  16.7844, -18.9366,  20.5275, -15.7568],\n",
      "        [ 21.0845,  15.5920,  16.3797, -18.3077,  20.0331, -15.4015],\n",
      "        [ 21.0402,  15.3484,  16.8795, -18.6094,  19.9668, -15.0230],\n",
      "        [ 21.1866,  15.6205,  16.8560, -19.3739,  20.3623, -15.4461],\n",
      "        [ 20.4061,  15.2595,  16.1726, -19.0455,  20.3433, -15.4070],\n",
      "        [ 20.6361,  15.1766,  16.6775, -18.8242,  20.2537, -15.3589]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3509745597839355\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3069, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3666, 15.1043, 16.7123],\n",
      "        [20.6497, 15.4483, 16.8640],\n",
      "        [20.2027, 15.2646, 16.4889],\n",
      "        [20.4402, 15.3597, 16.9800],\n",
      "        [20.3627, 14.6945, 16.1502],\n",
      "        [20.2242, 15.5481, 16.0465]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2209,  20.2001, -15.3166],\n",
      "        [-18.7467,  20.3775, -15.6504],\n",
      "        [-19.0891,  21.0678, -15.3938],\n",
      "        [-19.0042,  20.4488, -15.5022],\n",
      "        [-19.6049,  20.7922, -15.8727],\n",
      "        [-19.2391,  20.6486, -15.6232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3666,  15.1043,  16.7123, -19.2209,  20.2001, -15.3166],\n",
      "        [ 20.6497,  15.4483,  16.8640, -18.7467,  20.3775, -15.6504],\n",
      "        [ 20.2027,  15.2646,  16.4889, -19.0891,  21.0678, -15.3938],\n",
      "        [ 20.4402,  15.3597,  16.9800, -19.0042,  20.4488, -15.5022],\n",
      "        [ 20.3627,  14.6945,  16.1502, -19.6049,  20.7922, -15.8727],\n",
      "        [ 20.2242,  15.5481,  16.0465, -19.2391,  20.6486, -15.6232]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.32285737991333\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5319, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.2407, 15.1660, 16.4157],\n",
      "        [20.6514, 15.6263, 16.9511],\n",
      "        [20.9253, 15.3166, 16.5666],\n",
      "        [21.0368, 15.6616, 16.7141],\n",
      "        [20.8359, 15.2654, 16.7985],\n",
      "        [20.5929, 14.9727, 16.1522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.8551, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7648,  19.9246, -15.5723],\n",
      "        [-19.2987,  20.4931, -15.5282],\n",
      "        [-18.8052,  20.0504, -15.2776],\n",
      "        [-18.9212,  20.6161, -15.4602],\n",
      "        [-18.8614,  20.0390, -15.3874],\n",
      "        [-19.4485,  20.7635, -15.6663]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.2407,  15.1660,  16.4157, -18.7648,  19.9246, -15.5723],\n",
      "        [ 20.6514,  15.6263,  16.9511, -19.2987,  20.4931, -15.5282],\n",
      "        [ 20.9253,  15.3166,  16.5666, -18.8052,  20.0504, -15.2776],\n",
      "        [ 21.0368,  15.6616,  16.7141, -18.9212,  20.6161, -15.4602],\n",
      "        [ 20.8359,  15.2654,  16.7985, -18.8614,  20.0390, -15.3874],\n",
      "        [ 20.5929,  14.9727,  16.1522, -19.4485,  20.7635, -15.6663]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.294478416442871\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6729, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3886, 15.9219, 16.8366],\n",
      "        [20.6733, 15.2978, 16.3573],\n",
      "        [20.8591, 15.4290, 16.6538],\n",
      "        [21.1760, 16.0132, 17.0535],\n",
      "        [20.9252, 15.3866, 16.3416],\n",
      "        [20.5807, 15.5399, 16.4756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9360,  20.8916, -15.3932],\n",
      "        [-19.4609,  20.6830, -15.5493],\n",
      "        [-19.3408,  20.4367, -15.7433],\n",
      "        [-18.8209,  20.8468, -15.7137],\n",
      "        [-19.1575,  20.5885, -15.5777],\n",
      "        [-19.4961,  20.8734, -15.6991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3886,  15.9219,  16.8366, -18.9360,  20.8916, -15.3932],\n",
      "        [ 20.6733,  15.2978,  16.3573, -19.4609,  20.6830, -15.5493],\n",
      "        [ 20.8591,  15.4290,  16.6538, -19.3408,  20.4367, -15.7433],\n",
      "        [ 21.1760,  16.0132,  17.0535, -18.8209,  20.8468, -15.7137],\n",
      "        [ 20.9252,  15.3866,  16.3416, -19.1575,  20.5885, -15.5777],\n",
      "        [ 20.5807,  15.5399,  16.4756, -19.4961,  20.8734, -15.6991]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4124319553375244\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5555, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7293, 15.2988, 16.7904],\n",
      "        [20.8807, 15.4772, 16.4609],\n",
      "        [20.8651, 15.4162, 16.4639],\n",
      "        [20.6448, 15.2964, 16.4639],\n",
      "        [21.0897, 15.5653, 16.7441],\n",
      "        [21.5996, 16.0039, 17.1024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9769,  20.0380, -15.4835],\n",
      "        [-18.6893,  20.2162, -14.9131],\n",
      "        [-19.4360,  20.2855, -15.6020],\n",
      "        [-19.1988,  20.7370, -15.7684],\n",
      "        [-18.9976,  20.4300, -15.7319],\n",
      "        [-19.0272,  20.7878, -15.3730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7293,  15.2988,  16.7904, -18.9769,  20.0380, -15.4835],\n",
      "        [ 20.8807,  15.4772,  16.4609, -18.6893,  20.2162, -14.9131],\n",
      "        [ 20.8651,  15.4162,  16.4639, -19.4360,  20.2855, -15.6020],\n",
      "        [ 20.6448,  15.2964,  16.4639, -19.1988,  20.7370, -15.7684],\n",
      "        [ 21.0897,  15.5653,  16.7441, -18.9976,  20.4300, -15.7319],\n",
      "        [ 21.5996,  16.0039,  17.1024, -19.0272,  20.7878, -15.3730]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3441646099090576\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7282, 15.7816, 16.5986],\n",
      "        [20.6434, 15.1058, 16.1856],\n",
      "        [20.9572, 15.4815, 16.7706],\n",
      "        [21.5258, 16.0457, 16.8213],\n",
      "        [21.2176, 15.7303, 16.3668],\n",
      "        [20.3158, 15.4741, 16.4329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0237, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0995,  20.2122, -15.3162],\n",
      "        [-19.4265,  20.4554, -15.2624],\n",
      "        [-19.1450,  20.7760, -15.4292],\n",
      "        [-19.3023,  20.6378, -15.2262],\n",
      "        [-19.1280,  20.7447, -15.6542],\n",
      "        [-19.2626,  20.7128, -15.5907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7282,  15.7816,  16.5986, -19.0995,  20.2122, -15.3162],\n",
      "        [ 20.6434,  15.1058,  16.1856, -19.4265,  20.4554, -15.2624],\n",
      "        [ 20.9572,  15.4815,  16.7706, -19.1450,  20.7760, -15.4292],\n",
      "        [ 21.5258,  16.0457,  16.8213, -19.3023,  20.6378, -15.2262],\n",
      "        [ 21.2176,  15.7303,  16.3668, -19.1280,  20.7447, -15.6542],\n",
      "        [ 20.3158,  15.4741,  16.4329, -19.2626,  20.7128, -15.5907]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.3559255599975586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7156, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1116, 15.9055, 16.9435],\n",
      "        [21.2335, 15.6534, 17.1485],\n",
      "        [20.8916, 15.6780, 16.7675],\n",
      "        [19.9533, 14.8377, 16.2142],\n",
      "        [21.0823, 15.7526, 16.7871],\n",
      "        [20.8806, 15.8272, 16.1835]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2790, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9391,  20.4625, -15.4661],\n",
      "        [-19.4904,  20.4066, -15.6778],\n",
      "        [-18.5930,  19.9334, -14.9678],\n",
      "        [-18.7025,  20.1859, -15.3203],\n",
      "        [-19.0866,  20.2183, -15.6149],\n",
      "        [-19.0860,  20.5700, -15.6561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1116,  15.9055,  16.9435, -18.9391,  20.4625, -15.4661],\n",
      "        [ 21.2335,  15.6534,  17.1485, -19.4904,  20.4066, -15.6778],\n",
      "        [ 20.8916,  15.6780,  16.7675, -18.5930,  19.9334, -14.9678],\n",
      "        [ 19.9533,  14.8377,  16.2142, -18.7025,  20.1859, -15.3203],\n",
      "        [ 21.0823,  15.7526,  16.7871, -19.0866,  20.2183, -15.6149],\n",
      "        [ 20.8806,  15.8272,  16.1835, -19.0860,  20.5700, -15.6561]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3969333171844482\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6467, 15.2891, 16.5493],\n",
      "        [20.8513, 15.4211, 16.3952],\n",
      "        [20.5621, 15.4991, 16.8379],\n",
      "        [20.9119, 15.5042, 16.7761],\n",
      "        [21.2822, 15.4988, 16.7026],\n",
      "        [20.8239, 15.5727, 16.9467]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.8896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9375,  20.5831, -15.6608],\n",
      "        [-18.6967,  19.9365, -15.6947],\n",
      "        [-18.9587,  20.6804, -15.6164],\n",
      "        [-19.0621,  20.3268, -15.4084],\n",
      "        [-19.5054,  20.6505, -15.7932],\n",
      "        [-19.3150,  20.7200, -15.6243]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6467,  15.2891,  16.5493, -18.9375,  20.5831, -15.6608],\n",
      "        [ 20.8513,  15.4211,  16.3952, -18.6967,  19.9365, -15.6947],\n",
      "        [ 20.5621,  15.4991,  16.8379, -18.9587,  20.6804, -15.6164],\n",
      "        [ 20.9119,  15.5042,  16.7761, -19.0621,  20.3268, -15.4084],\n",
      "        [ 21.2822,  15.4988,  16.7026, -19.5054,  20.6505, -15.7932],\n",
      "        [ 20.8239,  15.5727,  16.9467, -19.3150,  20.7200, -15.6243]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.353323221206665\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8239, 15.3043, 16.6399],\n",
      "        [21.3158, 15.9646, 17.0785],\n",
      "        [20.6601, 15.5378, 16.4317],\n",
      "        [21.0732, 15.5281, 16.9771],\n",
      "        [20.9043, 15.2536, 16.5768],\n",
      "        [21.2040, 16.1971, 16.6894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2618, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9422,  20.5418, -15.4528],\n",
      "        [-19.1125,  20.4494, -15.7197],\n",
      "        [-19.4735,  20.4028, -15.5789],\n",
      "        [-19.3165,  20.4650, -15.7725],\n",
      "        [-19.3051,  20.3979, -15.3422],\n",
      "        [-18.9305,  20.2428, -15.6523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8239,  15.3043,  16.6399, -18.9422,  20.5418, -15.4528],\n",
      "        [ 21.3158,  15.9646,  17.0785, -19.1125,  20.4494, -15.7197],\n",
      "        [ 20.6601,  15.5378,  16.4317, -19.4735,  20.4028, -15.5789],\n",
      "        [ 21.0732,  15.5281,  16.9771, -19.3165,  20.4650, -15.7725],\n",
      "        [ 20.9043,  15.2536,  16.5768, -19.3051,  20.3979, -15.3422],\n",
      "        [ 21.2040,  16.1971,  16.6894, -18.9305,  20.2428, -15.6523]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3615334033966064\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2312, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.3176, 14.9448, 16.4377],\n",
      "        [20.9340, 15.7149, 16.6840],\n",
      "        [20.6494, 15.4850, 16.9380],\n",
      "        [21.5972, 15.5032, 16.9243],\n",
      "        [21.2673, 15.2578, 16.5743],\n",
      "        [20.9527, 15.2144, 16.6223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.2584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3564,  20.7968, -15.5706],\n",
      "        [-19.1624,  20.4915, -15.5943],\n",
      "        [-18.7703,  20.2612, -15.6477],\n",
      "        [-19.6648,  20.8553, -15.9348],\n",
      "        [-19.2273,  20.9244, -15.6819],\n",
      "        [-19.5048,  20.9707, -15.4329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.3176,  14.9448,  16.4377, -19.3564,  20.7968, -15.5706],\n",
      "        [ 20.9340,  15.7149,  16.6840, -19.1624,  20.4915, -15.5943],\n",
      "        [ 20.6494,  15.4850,  16.9380, -18.7703,  20.2612, -15.6477],\n",
      "        [ 21.5972,  15.5032,  16.9243, -19.6648,  20.8553, -15.9348],\n",
      "        [ 21.2673,  15.2578,  16.5743, -19.2273,  20.9244, -15.6819],\n",
      "        [ 20.9527,  15.2144,  16.6223, -19.5048,  20.9707, -15.4329]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.343014717102051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0076, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9973, 15.8848, 16.8414],\n",
      "        [21.7354, 15.4271, 17.1220],\n",
      "        [20.7273, 15.6363, 16.6071],\n",
      "        [20.8638, 15.2398, 16.4006],\n",
      "        [20.9719, 15.7272, 16.3807],\n",
      "        [20.5425, 15.5392, 16.6938]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.3438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1052,  20.7326, -15.3088],\n",
      "        [-19.6295,  21.0676, -15.9840],\n",
      "        [-19.0988,  20.2252, -15.1797],\n",
      "        [-19.2248,  20.7121, -15.7954],\n",
      "        [-19.0674,  20.9615, -15.4388],\n",
      "        [-18.7097,  19.7430, -14.9947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9973,  15.8848,  16.8414, -19.1052,  20.7326, -15.3088],\n",
      "        [ 21.7354,  15.4271,  17.1220, -19.6295,  21.0676, -15.9840],\n",
      "        [ 20.7273,  15.6363,  16.6071, -19.0988,  20.2252, -15.1797],\n",
      "        [ 20.8638,  15.2398,  16.4006, -19.2248,  20.7121, -15.7954],\n",
      "        [ 20.9719,  15.7272,  16.3807, -19.0674,  20.9615, -15.4388],\n",
      "        [ 20.5425,  15.5392,  16.6938, -18.7097,  19.7430, -14.9947]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4019882678985596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7113, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7898, 15.3941, 16.7652],\n",
      "        [21.2713, 15.8979, 17.1828],\n",
      "        [20.6847, 15.5746, 16.7761],\n",
      "        [21.1435, 15.8061, 17.0013],\n",
      "        [20.8674, 15.5807, 16.5643],\n",
      "        [21.1635, 15.4201, 16.9214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.7543,  20.5163, -15.4369],\n",
      "        [-18.9630,  20.2535, -15.6187],\n",
      "        [-19.4875,  20.8660, -15.8321],\n",
      "        [-18.5955,  20.0383, -15.4238],\n",
      "        [-18.9626,  20.3225, -15.6224],\n",
      "        [-19.0798,  20.7676, -15.4775]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7898,  15.3941,  16.7652, -18.7543,  20.5163, -15.4369],\n",
      "        [ 21.2713,  15.8979,  17.1828, -18.9630,  20.2535, -15.6187],\n",
      "        [ 20.6847,  15.5746,  16.7761, -19.4875,  20.8660, -15.8321],\n",
      "        [ 21.1435,  15.8061,  17.0013, -18.5955,  20.0383, -15.4238],\n",
      "        [ 20.8674,  15.5807,  16.5643, -18.9626,  20.3225, -15.6224],\n",
      "        [ 21.1635,  15.4201,  16.9214, -19.0798,  20.7676, -15.4775]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.3653271198272705\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5688, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0995, 15.3982, 16.6125],\n",
      "        [20.8920, 15.6318, 16.9758],\n",
      "        [21.0077, 15.6413, 16.6678],\n",
      "        [21.1734, 15.6585, 17.2332],\n",
      "        [21.0502, 16.0416, 17.0413],\n",
      "        [21.0332, 15.5287, 16.8916]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2058, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9923,  20.5630, -15.7554],\n",
      "        [-19.3995,  20.6431, -15.6945],\n",
      "        [-19.3659,  20.7209, -15.6254],\n",
      "        [-18.7769,  20.3090, -15.2799],\n",
      "        [-18.9996,  20.6702, -15.7920],\n",
      "        [-19.3043,  20.6975, -15.7565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0995,  15.3982,  16.6125, -18.9923,  20.5630, -15.7554],\n",
      "        [ 20.8920,  15.6318,  16.9758, -19.3995,  20.6431, -15.6945],\n",
      "        [ 21.0077,  15.6413,  16.6678, -19.3659,  20.7209, -15.6254],\n",
      "        [ 21.1734,  15.6585,  17.2332, -18.7769,  20.3090, -15.2799],\n",
      "        [ 21.0502,  16.0416,  17.0413, -18.9996,  20.6702, -15.7920],\n",
      "        [ 21.0332,  15.5287,  16.8916, -19.3043,  20.6975, -15.7565]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3893165588378906\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7047, 15.1784, 16.4137],\n",
      "        [21.0546, 15.3686, 16.9393],\n",
      "        [20.6138, 15.5621, 16.8969],\n",
      "        [21.0950, 15.6656, 17.1326],\n",
      "        [20.6047, 15.1173, 16.7967],\n",
      "        [20.9407, 15.7898, 16.5678]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.4279, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.9076,  20.4487, -15.7312],\n",
      "        [-19.2343,  20.4466, -15.4183],\n",
      "        [-18.9700,  20.3451, -15.6575],\n",
      "        [-19.0781,  20.2657, -15.1574],\n",
      "        [-19.0680,  20.6473, -15.4961],\n",
      "        [-19.5025,  20.6814, -15.7724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7047,  15.1784,  16.4137, -18.9076,  20.4487, -15.7312],\n",
      "        [ 21.0546,  15.3686,  16.9393, -19.2343,  20.4466, -15.4183],\n",
      "        [ 20.6138,  15.5621,  16.8969, -18.9700,  20.3451, -15.6575],\n",
      "        [ 21.0950,  15.6656,  17.1326, -19.0781,  20.2657, -15.1574],\n",
      "        [ 20.6047,  15.1173,  16.7967, -19.0680,  20.6473, -15.4961],\n",
      "        [ 20.9407,  15.7898,  16.5678, -19.5025,  20.6814, -15.7724]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3533995151519775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7421, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.5383, 15.3855, 17.1452],\n",
      "        [20.4809, 15.8034, 16.8890],\n",
      "        [21.0482, 15.8969, 16.9062],\n",
      "        [21.1090, 15.4139, 17.0477],\n",
      "        [21.1929, 15.5857, 16.5020],\n",
      "        [20.5203, 15.1132, 16.3264]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.9026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4004,  20.5906, -15.5361],\n",
      "        [-19.1820,  20.6641, -15.3129],\n",
      "        [-19.0940,  21.0488, -15.6425],\n",
      "        [-19.4819,  21.1687, -16.0680],\n",
      "        [-19.2631,  20.6262, -15.4853],\n",
      "        [-19.3345,  20.9958, -15.6778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.5383,  15.3855,  17.1452, -19.4004,  20.5906, -15.5361],\n",
      "        [ 20.4809,  15.8034,  16.8890, -19.1820,  20.6641, -15.3129],\n",
      "        [ 21.0482,  15.8969,  16.9062, -19.0940,  21.0488, -15.6425],\n",
      "        [ 21.1090,  15.4139,  17.0477, -19.4819,  21.1687, -16.0680],\n",
      "        [ 21.1929,  15.5857,  16.5020, -19.2631,  20.6262, -15.4853],\n",
      "        [ 20.5203,  15.1132,  16.3264, -19.3345,  20.9958, -15.6778]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3928937911987305\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9226, 15.8380, 17.1166],\n",
      "        [21.1293, 16.1046, 16.9836],\n",
      "        [21.1477, 15.6075, 17.1048],\n",
      "        [20.8726, 15.6501, 16.2090],\n",
      "        [21.0617, 15.4052, 16.8525],\n",
      "        [20.9112, 15.7159, 16.9284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8131,  20.3266, -15.2633],\n",
      "        [-19.2252,  20.7033, -15.9381],\n",
      "        [-19.2979,  20.7245, -15.5141],\n",
      "        [-19.3641,  20.4066, -15.6587],\n",
      "        [-19.6694,  20.3831, -15.6466],\n",
      "        [-19.3464,  20.6318, -15.7358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9226,  15.8380,  17.1166, -18.8131,  20.3266, -15.2633],\n",
      "        [ 21.1293,  16.1046,  16.9836, -19.2252,  20.7033, -15.9381],\n",
      "        [ 21.1477,  15.6075,  17.1048, -19.2979,  20.7245, -15.5141],\n",
      "        [ 20.8726,  15.6501,  16.2090, -19.3641,  20.4066, -15.6587],\n",
      "        [ 21.0617,  15.4052,  16.8525, -19.6694,  20.3831, -15.6466],\n",
      "        [ 20.9112,  15.7159,  16.9284, -19.3464,  20.6318, -15.7358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.394665479660034\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1055, 15.8045, 16.8579],\n",
      "        [21.1312, 16.0545, 16.6350],\n",
      "        [20.9330, 16.1548, 16.5998],\n",
      "        [21.1753, 15.9069, 17.1916],\n",
      "        [21.4666, 16.0169, 17.2761],\n",
      "        [21.0362, 15.8385, 16.6203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6675, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2596,  20.5354, -15.5345],\n",
      "        [-19.1494,  20.4388, -15.4153],\n",
      "        [-19.0340,  20.7422, -15.5288],\n",
      "        [-19.0731,  20.3362, -15.8143],\n",
      "        [-19.4087,  20.5545, -15.3554],\n",
      "        [-19.6603,  20.7271, -15.8346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1055,  15.8045,  16.8579, -19.2596,  20.5354, -15.5345],\n",
      "        [ 21.1312,  16.0545,  16.6350, -19.1494,  20.4388, -15.4153],\n",
      "        [ 20.9330,  16.1548,  16.5998, -19.0340,  20.7422, -15.5288],\n",
      "        [ 21.1753,  15.9069,  17.1916, -19.0731,  20.3362, -15.8143],\n",
      "        [ 21.4666,  16.0169,  17.2761, -19.4087,  20.5545, -15.3554],\n",
      "        [ 21.0362,  15.8385,  16.6203, -19.6603,  20.7271, -15.8346]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4170379638671875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7191, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4566, 15.6883, 16.9797],\n",
      "        [20.7949, 15.0496, 16.7204],\n",
      "        [21.4065, 15.8722, 16.8454],\n",
      "        [21.2018, 15.4540, 16.7633],\n",
      "        [20.7433, 15.5483, 16.7970],\n",
      "        [20.8443, 15.5197, 16.6631]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.9639, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8257,  19.6501, -15.2573],\n",
      "        [-18.8342,  20.3095, -15.2331],\n",
      "        [-19.5449,  20.9232, -15.8972],\n",
      "        [-19.6286,  20.9304, -15.9235],\n",
      "        [-19.3158,  20.6642, -15.9107],\n",
      "        [-19.3143,  20.2022, -15.9624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4566,  15.6883,  16.9797, -18.8257,  19.6501, -15.2573],\n",
      "        [ 20.7949,  15.0496,  16.7204, -18.8342,  20.3095, -15.2331],\n",
      "        [ 21.4065,  15.8722,  16.8454, -19.5449,  20.9232, -15.8972],\n",
      "        [ 21.2018,  15.4540,  16.7633, -19.6286,  20.9304, -15.9235],\n",
      "        [ 20.7433,  15.5483,  16.7970, -19.3158,  20.6642, -15.9107],\n",
      "        [ 20.8443,  15.5197,  16.6631, -19.3143,  20.2022, -15.9624]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.394116163253784\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8689, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6467, 15.5369, 16.2146],\n",
      "        [21.5078, 15.8778, 16.8833],\n",
      "        [20.8928, 15.4808, 16.9457],\n",
      "        [21.1518, 15.0735, 17.0055],\n",
      "        [21.0310, 15.4280, 16.5084],\n",
      "        [20.5214, 15.1190, 16.1038]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3508, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-18.8590,  20.7442, -15.5756],\n",
      "        [-19.2815,  20.7589, -15.3701],\n",
      "        [-19.0759,  20.9905, -15.5578],\n",
      "        [-19.0595,  20.5607, -15.6971],\n",
      "        [-19.4230,  21.0342, -15.5518],\n",
      "        [-19.2251,  20.6955, -15.6395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6467,  15.5369,  16.2146, -18.8590,  20.7442, -15.5756],\n",
      "        [ 21.5078,  15.8778,  16.8833, -19.2815,  20.7589, -15.3701],\n",
      "        [ 20.8928,  15.4808,  16.9457, -19.0759,  20.9905, -15.5578],\n",
      "        [ 21.1518,  15.0735,  17.0055, -19.0595,  20.5607, -15.6971],\n",
      "        [ 21.0310,  15.4280,  16.5084, -19.4230,  21.0342, -15.5518],\n",
      "        [ 20.5214,  15.1190,  16.1038, -19.2251,  20.6955, -15.6395]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3639204502105713\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7234, 15.2812, 16.8565],\n",
      "        [21.5030, 15.9452, 16.8323],\n",
      "        [20.4522, 15.4913, 16.6001],\n",
      "        [20.9122, 15.4448, 16.5345],\n",
      "        [20.9863, 15.6655, 16.6869],\n",
      "        [21.1064, 15.3069, 16.6343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0873, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1727,  20.7353, -16.0356],\n",
      "        [-19.3517,  20.2999, -15.7529],\n",
      "        [-19.4051,  20.9303, -15.6421],\n",
      "        [-19.3238,  20.4672, -15.7626],\n",
      "        [-19.1500,  20.4102, -15.6811],\n",
      "        [-19.6555,  20.4806, -15.7939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7234,  15.2812,  16.8565, -19.1727,  20.7353, -16.0356],\n",
      "        [ 21.5030,  15.9452,  16.8323, -19.3517,  20.2999, -15.7529],\n",
      "        [ 20.4522,  15.4913,  16.6001, -19.4051,  20.9303, -15.6421],\n",
      "        [ 20.9122,  15.4448,  16.5345, -19.3238,  20.4672, -15.7626],\n",
      "        [ 20.9863,  15.6655,  16.6869, -19.1500,  20.4102, -15.6811],\n",
      "        [ 21.1064,  15.3069,  16.6343, -19.6555,  20.4806, -15.7939]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.403188467025757\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7582, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.6215, 15.4215, 16.7438],\n",
      "        [21.4143, 15.5648, 16.9797],\n",
      "        [21.1915, 15.9344, 16.6147],\n",
      "        [20.9279, 15.6926, 16.8004],\n",
      "        [21.3962, 15.7330, 16.8086],\n",
      "        [21.0201, 15.7090, 17.0449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.0932, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4154,  20.4559, -16.0096],\n",
      "        [-19.2287,  20.1632, -15.4977],\n",
      "        [-19.0508,  20.7950, -15.4218],\n",
      "        [-19.4759,  20.4495, -15.7913],\n",
      "        [-19.0234,  20.5016, -15.3371],\n",
      "        [-19.0541,  20.4703, -15.5274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.6215,  15.4215,  16.7438, -19.4154,  20.4559, -16.0096],\n",
      "        [ 21.4143,  15.5648,  16.9797, -19.2287,  20.1632, -15.4977],\n",
      "        [ 21.1915,  15.9344,  16.6147, -19.0508,  20.7950, -15.4218],\n",
      "        [ 20.9279,  15.6926,  16.8004, -19.4759,  20.4495, -15.7913],\n",
      "        [ 21.3962,  15.7330,  16.8086, -19.0234,  20.5016, -15.3371],\n",
      "        [ 21.0201,  15.7090,  17.0449, -19.0541,  20.4703, -15.5274]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.3973162174224854\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9920, 15.4765, 16.9428],\n",
      "        [20.5551, 15.3520, 16.6061],\n",
      "        [20.8871, 15.2334, 16.4497],\n",
      "        [20.5666, 15.5032, 16.9345],\n",
      "        [20.9946, 15.5083, 16.6664],\n",
      "        [21.0834, 15.7381, 16.7474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3174,  20.4407, -15.5366],\n",
      "        [-19.0143,  20.2038, -15.1830],\n",
      "        [-19.5937,  20.9378, -15.8875],\n",
      "        [-19.2936,  20.2257, -15.6260],\n",
      "        [-19.3218,  20.8880, -16.0858],\n",
      "        [-19.3383,  20.8436, -16.0036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9920,  15.4765,  16.9428, -19.3174,  20.4407, -15.5366],\n",
      "        [ 20.5551,  15.3520,  16.6061, -19.0143,  20.2038, -15.1830],\n",
      "        [ 20.8871,  15.2334,  16.4497, -19.5937,  20.9378, -15.8875],\n",
      "        [ 20.5666,  15.5032,  16.9345, -19.2936,  20.2257, -15.6260],\n",
      "        [ 20.9946,  15.5083,  16.6664, -19.3218,  20.8880, -16.0858],\n",
      "        [ 21.0834,  15.7381,  16.7474, -19.3383,  20.8436, -16.0036]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4123549461364746\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9555, 15.6757, 16.8064],\n",
      "        [20.7899, 15.4875, 16.4857],\n",
      "        [21.3329, 15.9204, 17.1501],\n",
      "        [20.7700, 15.5674, 16.6459],\n",
      "        [20.9119, 15.5645, 16.6198],\n",
      "        [20.4231, 15.6128, 16.5418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0566, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6354,  20.9655, -16.2012],\n",
      "        [-19.0104,  20.6537, -15.8481],\n",
      "        [-18.9825,  20.5323, -15.1092],\n",
      "        [-19.0853,  20.6049, -15.6570],\n",
      "        [-19.3084,  20.8948, -15.7891],\n",
      "        [-19.1276,  20.7301, -15.5561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9555,  15.6757,  16.8064, -19.6354,  20.9655, -16.2012],\n",
      "        [ 20.7899,  15.4875,  16.4857, -19.0104,  20.6537, -15.8481],\n",
      "        [ 21.3329,  15.9204,  17.1501, -18.9825,  20.5323, -15.1092],\n",
      "        [ 20.7700,  15.5674,  16.6459, -19.0853,  20.6049, -15.6570],\n",
      "        [ 20.9119,  15.5645,  16.6198, -19.3084,  20.8948, -15.7891],\n",
      "        [ 20.4231,  15.6128,  16.5418, -19.1276,  20.7301, -15.5561]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.448845863342285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3946, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1520, 16.0388, 16.7893],\n",
      "        [20.8940, 15.6365, 16.4370],\n",
      "        [21.2026, 15.4546, 16.9696],\n",
      "        [21.1987, 15.6356, 17.0780],\n",
      "        [20.7084, 15.5437, 16.7306],\n",
      "        [21.0235, 15.3306, 16.8019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.2194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6473,  20.7618, -15.6726],\n",
      "        [-19.3112,  20.7785, -15.6393],\n",
      "        [-19.0731,  20.5811, -15.3217],\n",
      "        [-19.0925,  20.3599, -15.5623],\n",
      "        [-19.2276,  20.4837, -15.8001],\n",
      "        [-19.2361,  20.6466, -15.6120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1520,  16.0388,  16.7893, -19.6473,  20.7618, -15.6726],\n",
      "        [ 20.8940,  15.6365,  16.4370, -19.3112,  20.7785, -15.6393],\n",
      "        [ 21.2026,  15.4546,  16.9696, -19.0731,  20.5811, -15.3217],\n",
      "        [ 21.1987,  15.6356,  17.0780, -19.0925,  20.3599, -15.5623],\n",
      "        [ 20.7084,  15.5437,  16.7306, -19.2276,  20.4837, -15.8001],\n",
      "        [ 21.0235,  15.3306,  16.8019, -19.2361,  20.6466, -15.6120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.452342987060547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0582, 15.8701, 16.5148],\n",
      "        [20.9986, 15.6670, 16.5075],\n",
      "        [20.4320, 15.4312, 17.0067],\n",
      "        [20.5535, 15.4533, 16.2148],\n",
      "        [21.8525, 15.9434, 17.0996],\n",
      "        [20.7741, 15.9411, 16.6105]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0693,  20.4258, -15.6040],\n",
      "        [-19.3668,  20.5698, -15.7787],\n",
      "        [-19.0429,  20.6358, -15.7774],\n",
      "        [-19.5036,  21.1800, -15.9849],\n",
      "        [-19.0977,  20.6634, -15.6234],\n",
      "        [-18.8759,  20.0804, -15.3479]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0582,  15.8701,  16.5148, -19.0693,  20.4258, -15.6040],\n",
      "        [ 20.9986,  15.6670,  16.5075, -19.3668,  20.5698, -15.7787],\n",
      "        [ 20.4320,  15.4312,  17.0067, -19.0429,  20.6358, -15.7774],\n",
      "        [ 20.5535,  15.4533,  16.2148, -19.5036,  21.1800, -15.9849],\n",
      "        [ 21.8525,  15.9434,  17.0996, -19.0977,  20.6634, -15.6234],\n",
      "        [ 20.7741,  15.9411,  16.6105, -18.8759,  20.0804, -15.3479]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.408573627471924\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8944, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8256, 15.6334, 17.0845],\n",
      "        [20.7167, 15.3526, 16.4924],\n",
      "        [21.1112, 16.0122, 16.8025],\n",
      "        [21.1788, 16.1242, 16.9802],\n",
      "        [21.0149, 15.6727, 16.7938],\n",
      "        [21.1902, 15.9062, 16.7942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3055,  20.4558, -15.6543],\n",
      "        [-19.3971,  20.6359, -15.5743],\n",
      "        [-19.7036,  20.9098, -15.9179],\n",
      "        [-19.1955,  20.5814, -15.8588],\n",
      "        [-19.1585,  20.7167, -15.5215],\n",
      "        [-18.8066,  20.4678, -15.4883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8256,  15.6334,  17.0845, -19.3055,  20.4558, -15.6543],\n",
      "        [ 20.7167,  15.3526,  16.4924, -19.3971,  20.6359, -15.5743],\n",
      "        [ 21.1112,  16.0122,  16.8025, -19.7036,  20.9098, -15.9179],\n",
      "        [ 21.1788,  16.1242,  16.9802, -19.1955,  20.5814, -15.8588],\n",
      "        [ 21.0149,  15.6727,  16.7938, -19.1585,  20.7167, -15.5215],\n",
      "        [ 21.1902,  15.9062,  16.7942, -18.8066,  20.4678, -15.4883]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4223268032073975\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3930, 15.6914, 16.8170],\n",
      "        [21.1227, 15.6544, 16.6636],\n",
      "        [20.7810, 15.3238, 16.7934],\n",
      "        [21.1949, 15.7715, 16.8884],\n",
      "        [21.1886, 15.5994, 17.0325],\n",
      "        [21.2843, 15.9029, 17.0371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0854, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4667,  20.6522, -15.6691],\n",
      "        [-19.5239,  20.8370, -15.9225],\n",
      "        [-19.5945,  20.2989, -15.6691],\n",
      "        [-19.3208,  20.5608, -15.8014],\n",
      "        [-19.1567,  20.3645, -15.5989],\n",
      "        [-19.0475,  20.7296, -15.4583]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3930,  15.6914,  16.8170, -19.4667,  20.6522, -15.6691],\n",
      "        [ 21.1227,  15.6544,  16.6636, -19.5239,  20.8370, -15.9225],\n",
      "        [ 20.7810,  15.3238,  16.7934, -19.5945,  20.2989, -15.6691],\n",
      "        [ 21.1949,  15.7715,  16.8884, -19.3208,  20.5608, -15.8014],\n",
      "        [ 21.1886,  15.5994,  17.0325, -19.1567,  20.3645, -15.5989],\n",
      "        [ 21.2843,  15.9029,  17.0371, -19.0475,  20.7296, -15.4583]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4517440795898438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7215, 15.5855, 16.6784],\n",
      "        [21.2678, 15.9393, 16.9563],\n",
      "        [20.8019, 15.6408, 17.0092],\n",
      "        [20.9510, 15.8259, 16.7488],\n",
      "        [21.5466, 16.0875, 17.1833],\n",
      "        [20.6444, 15.7539, 16.2881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.5876, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6542,  20.7084, -15.9000],\n",
      "        [-18.9857,  20.6055, -15.6882],\n",
      "        [-19.1961,  20.6905, -15.6009],\n",
      "        [-19.6072,  20.9960, -15.8192],\n",
      "        [-19.6558,  20.7853, -15.8921],\n",
      "        [-19.5876,  20.9761, -16.0635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7215,  15.5855,  16.6784, -19.6542,  20.7084, -15.9000],\n",
      "        [ 21.2678,  15.9393,  16.9563, -18.9857,  20.6055, -15.6882],\n",
      "        [ 20.8019,  15.6408,  17.0092, -19.1961,  20.6905, -15.6009],\n",
      "        [ 20.9510,  15.8259,  16.7488, -19.6072,  20.9960, -15.8192],\n",
      "        [ 21.5466,  16.0875,  17.1833, -19.6558,  20.7853, -15.8921],\n",
      "        [ 20.6444,  15.7539,  16.2881, -19.5876,  20.9761, -16.0635]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4252514839172363\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9062, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3449, 16.2337, 17.0159],\n",
      "        [20.6428, 15.3377, 16.9016],\n",
      "        [20.9535, 15.7061, 16.9142],\n",
      "        [21.5549, 15.8983, 17.3377],\n",
      "        [20.8047, 15.4615, 16.9974],\n",
      "        [21.2208, 15.9178, 16.8711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5098,  20.6644, -16.2711],\n",
      "        [-19.0756,  20.6509, -15.8859],\n",
      "        [-19.2758,  20.5024, -15.8445],\n",
      "        [-19.8798,  20.6346, -15.8281],\n",
      "        [-19.5059,  20.6289, -15.8734],\n",
      "        [-18.9552,  20.5976, -15.4757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3449,  16.2337,  17.0159, -19.5098,  20.6644, -16.2711],\n",
      "        [ 20.6428,  15.3377,  16.9016, -19.0756,  20.6509, -15.8859],\n",
      "        [ 20.9535,  15.7061,  16.9142, -19.2758,  20.5024, -15.8445],\n",
      "        [ 21.5549,  15.8983,  17.3377, -19.8798,  20.6346, -15.8281],\n",
      "        [ 20.8047,  15.4615,  16.9974, -19.5059,  20.6289, -15.8734],\n",
      "        [ 21.2208,  15.9178,  16.8711, -18.9552,  20.5976, -15.4757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.487807035446167\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6476, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1138, 15.9253, 16.7832],\n",
      "        [21.3829, 15.7611, 16.6414],\n",
      "        [21.5712, 16.1552, 17.1716],\n",
      "        [20.6846, 15.4732, 16.6409],\n",
      "        [20.9616, 15.9269, 16.8080],\n",
      "        [21.1541, 15.8038, 16.8098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9067, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8262,  21.1215, -15.9342],\n",
      "        [-19.5050,  20.8634, -15.7216],\n",
      "        [-19.8296,  20.9700, -16.0134],\n",
      "        [-18.8126,  19.7895, -15.2803],\n",
      "        [-19.1848,  20.5966, -15.7229],\n",
      "        [-18.8036,  20.7998, -15.3093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1138,  15.9253,  16.7832, -19.8262,  21.1215, -15.9342],\n",
      "        [ 21.3829,  15.7611,  16.6414, -19.5050,  20.8634, -15.7216],\n",
      "        [ 21.5712,  16.1552,  17.1716, -19.8296,  20.9700, -16.0134],\n",
      "        [ 20.6846,  15.4732,  16.6409, -18.8126,  19.7895, -15.2803],\n",
      "        [ 20.9616,  15.9269,  16.8080, -19.1848,  20.5966, -15.7229],\n",
      "        [ 21.1541,  15.8038,  16.8098, -18.8036,  20.7998, -15.3093]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.4763267040252686\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0532, 15.2594, 16.3951],\n",
      "        [21.0128, 15.6943, 16.8111],\n",
      "        [20.8863, 15.1425, 16.5714],\n",
      "        [20.8813, 16.0975, 16.9632],\n",
      "        [20.6247, 15.4978, 16.7112],\n",
      "        [21.4470, 15.7058, 17.2352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.8138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1385,  20.6491, -15.5838],\n",
      "        [-18.7711,  20.9486, -15.8541],\n",
      "        [-19.4846,  20.8972, -15.6756],\n",
      "        [-18.8101,  20.4809, -15.5945],\n",
      "        [-19.8042,  21.1365, -15.8311],\n",
      "        [-19.0305,  20.4359, -15.5711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0532,  15.2594,  16.3951, -19.1385,  20.6491, -15.5838],\n",
      "        [ 21.0128,  15.6943,  16.8111, -18.7711,  20.9486, -15.8541],\n",
      "        [ 20.8863,  15.1425,  16.5714, -19.4846,  20.8972, -15.6756],\n",
      "        [ 20.8813,  16.0975,  16.9632, -18.8101,  20.4809, -15.5945],\n",
      "        [ 20.6247,  15.4978,  16.7112, -19.8042,  21.1365, -15.8311],\n",
      "        [ 21.4470,  15.7058,  17.2352, -19.0305,  20.4359, -15.5711]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4040603637695312\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1527, 15.6237, 16.8230],\n",
      "        [21.0740, 15.5850, 16.8192],\n",
      "        [21.3123, 16.1742, 16.8863],\n",
      "        [20.8812, 15.2005, 16.5272],\n",
      "        [21.1225, 15.4865, 17.2700],\n",
      "        [20.8182, 15.5886, 16.6657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.4512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0289,  20.6022, -15.6580],\n",
      "        [-18.9538,  20.2161, -15.6150],\n",
      "        [-19.1374,  20.2766, -15.5935],\n",
      "        [-18.9229,  20.6563, -15.5736],\n",
      "        [-19.1418,  20.4134, -15.5294],\n",
      "        [-19.3768,  20.9612, -15.8998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1527,  15.6237,  16.8230, -19.0289,  20.6022, -15.6580],\n",
      "        [ 21.0740,  15.5850,  16.8192, -18.9538,  20.2161, -15.6150],\n",
      "        [ 21.3123,  16.1742,  16.8863, -19.1374,  20.2766, -15.5935],\n",
      "        [ 20.8812,  15.2005,  16.5272, -18.9229,  20.6563, -15.5736],\n",
      "        [ 21.1225,  15.4865,  17.2700, -19.1418,  20.4134, -15.5294],\n",
      "        [ 20.8182,  15.5886,  16.6657, -19.3768,  20.9612, -15.8998]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4330828189849854\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9211, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9633, 15.2332, 16.6881],\n",
      "        [21.0253, 15.6281, 16.8360],\n",
      "        [21.0087, 15.7400, 16.9932],\n",
      "        [21.2530, 15.6363, 16.9629],\n",
      "        [21.0335, 15.2358, 16.7744],\n",
      "        [21.1202, 15.4733, 16.9180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.9979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1731,  20.7898, -15.8901],\n",
      "        [-19.5366,  20.8369, -16.1915],\n",
      "        [-19.0726,  20.3671, -15.5212],\n",
      "        [-19.4747,  20.6257, -15.8595],\n",
      "        [-18.6458,  20.2621, -15.6693],\n",
      "        [-19.5055,  20.6624, -15.3206]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9633,  15.2332,  16.6881, -19.1731,  20.7898, -15.8901],\n",
      "        [ 21.0253,  15.6281,  16.8360, -19.5366,  20.8369, -16.1915],\n",
      "        [ 21.0087,  15.7400,  16.9932, -19.0726,  20.3671, -15.5212],\n",
      "        [ 21.2530,  15.6363,  16.9629, -19.4747,  20.6257, -15.8595],\n",
      "        [ 21.0335,  15.2358,  16.7744, -18.6458,  20.2621, -15.6693],\n",
      "        [ 21.1202,  15.4733,  16.9180, -19.5055,  20.6624, -15.3206]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.424133062362671\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2677, 16.2705, 16.9018],\n",
      "        [21.1291, 15.7275, 16.8539],\n",
      "        [21.4706, 16.2524, 17.2208],\n",
      "        [21.5254, 15.8553, 16.9202],\n",
      "        [21.2574, 15.4837, 17.4944],\n",
      "        [21.2054, 15.7778, 16.7272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4386,  20.8712, -15.8447],\n",
      "        [-19.4393,  20.8702, -15.8690],\n",
      "        [-18.9862,  20.5175, -15.5178],\n",
      "        [-19.2877,  20.5487, -15.9682],\n",
      "        [-19.2677,  20.6403, -15.9029],\n",
      "        [-19.8077,  20.7312, -15.9742]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2677,  16.2705,  16.9018, -19.4386,  20.8712, -15.8447],\n",
      "        [ 21.1291,  15.7275,  16.8539, -19.4393,  20.8702, -15.8690],\n",
      "        [ 21.4706,  16.2524,  17.2208, -18.9862,  20.5175, -15.5178],\n",
      "        [ 21.5254,  15.8553,  16.9202, -19.2877,  20.5487, -15.9682],\n",
      "        [ 21.2574,  15.4837,  17.4944, -19.2677,  20.6403, -15.9029],\n",
      "        [ 21.2054,  15.7778,  16.7272, -19.8077,  20.7312, -15.9742]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4837701320648193\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4236, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3200, 15.6190, 17.0045],\n",
      "        [21.0083, 15.9817, 16.5096],\n",
      "        [20.7265, 15.6988, 16.7455],\n",
      "        [21.5164, 16.1111, 17.6696],\n",
      "        [20.9460, 15.8748, 16.9650],\n",
      "        [21.2811, 15.7455, 17.6508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.4972, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0138,  20.6486, -15.4596],\n",
      "        [-19.4586,  20.6040, -15.7881],\n",
      "        [-19.3562,  21.1811, -15.9749],\n",
      "        [-19.7229,  21.2962, -16.4836],\n",
      "        [-19.5409,  20.7643, -16.1486],\n",
      "        [-19.3299,  20.2817, -16.1017]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3200,  15.6190,  17.0045, -19.0138,  20.6486, -15.4596],\n",
      "        [ 21.0083,  15.9817,  16.5096, -19.4586,  20.6040, -15.7881],\n",
      "        [ 20.7265,  15.6988,  16.7455, -19.3562,  21.1811, -15.9749],\n",
      "        [ 21.5164,  16.1111,  17.6696, -19.7229,  21.2962, -16.4836],\n",
      "        [ 20.9460,  15.8748,  16.9650, -19.5409,  20.7643, -16.1486],\n",
      "        [ 21.2811,  15.7455,  17.6508, -19.3299,  20.2817, -16.1017]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.448803186416626\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2524, 15.6974, 17.0680],\n",
      "        [21.1662, 15.8001, 16.7146],\n",
      "        [21.3495, 15.9390, 16.8358],\n",
      "        [21.0290, 15.8967, 16.6914],\n",
      "        [21.3611, 16.2874, 17.3066],\n",
      "        [21.3212, 16.0853, 17.0101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5567,  20.6033, -15.6031],\n",
      "        [-19.9328,  21.2527, -16.2516],\n",
      "        [-19.4437,  20.9203, -15.9953],\n",
      "        [-19.5290,  20.4890, -16.1273],\n",
      "        [-19.2837,  20.0693, -15.4855],\n",
      "        [-19.2841,  20.4944, -15.7483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2524,  15.6974,  17.0680, -19.5567,  20.6033, -15.6031],\n",
      "        [ 21.1662,  15.8001,  16.7146, -19.9328,  21.2527, -16.2516],\n",
      "        [ 21.3495,  15.9390,  16.8358, -19.4437,  20.9203, -15.9953],\n",
      "        [ 21.0290,  15.8967,  16.6914, -19.5290,  20.4890, -16.1273],\n",
      "        [ 21.3611,  16.2874,  17.3066, -19.2837,  20.0693, -15.4855],\n",
      "        [ 21.3212,  16.0853,  17.0101, -19.2841,  20.4944, -15.7483]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.467524766921997\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4811, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4524, 15.7588, 16.9880],\n",
      "        [20.5252, 15.0735, 16.7208],\n",
      "        [21.0526, 15.7047, 17.2744],\n",
      "        [20.7803, 15.5856, 16.8526],\n",
      "        [21.1088, 15.3821, 16.8523],\n",
      "        [21.5246, 15.8761, 17.2120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.8259, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5127,  21.0352, -15.6962],\n",
      "        [-19.1347,  20.6976, -15.5201],\n",
      "        [-19.0537,  20.3640, -15.8539],\n",
      "        [-19.4037,  21.0404, -15.8304],\n",
      "        [-19.4102,  20.5030, -16.1472],\n",
      "        [-19.2519,  20.6232, -15.8432]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4524,  15.7588,  16.9880, -19.5127,  21.0352, -15.6962],\n",
      "        [ 20.5252,  15.0735,  16.7208, -19.1347,  20.6976, -15.5201],\n",
      "        [ 21.0526,  15.7047,  17.2744, -19.0537,  20.3640, -15.8539],\n",
      "        [ 20.7803,  15.5856,  16.8526, -19.4037,  21.0404, -15.8304],\n",
      "        [ 21.1088,  15.3821,  16.8523, -19.4102,  20.5030, -16.1472],\n",
      "        [ 21.5246,  15.8761,  17.2120, -19.2519,  20.6232, -15.8432]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4900102615356445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7983, 15.4475, 16.4421],\n",
      "        [21.3173, 15.6492, 16.7084],\n",
      "        [21.3364, 15.9640, 17.4392],\n",
      "        [21.3596, 15.7844, 16.9565],\n",
      "        [20.9537, 15.6705, 16.6437],\n",
      "        [20.7189, 15.6900, 16.9294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5414,  20.7293, -16.0014],\n",
      "        [-19.0593,  20.5156, -15.5991],\n",
      "        [-19.0810,  20.4638, -15.7057],\n",
      "        [-19.1412,  20.2622, -15.6425],\n",
      "        [-19.5984,  20.5329, -15.5080],\n",
      "        [-19.4502,  20.9995, -16.2056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7983,  15.4475,  16.4421, -19.5414,  20.7293, -16.0014],\n",
      "        [ 21.3173,  15.6492,  16.7084, -19.0593,  20.5156, -15.5991],\n",
      "        [ 21.3364,  15.9640,  17.4392, -19.0810,  20.4638, -15.7057],\n",
      "        [ 21.3596,  15.7844,  16.9565, -19.1412,  20.2622, -15.6425],\n",
      "        [ 20.9537,  15.6705,  16.6437, -19.5984,  20.5329, -15.5080],\n",
      "        [ 20.7189,  15.6900,  16.9294, -19.4502,  20.9995, -16.2056]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.430405855178833\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1285, 15.6702, 16.6717],\n",
      "        [21.3346, 16.0043, 17.1398],\n",
      "        [21.2475, 15.7823, 17.1100],\n",
      "        [20.9714, 15.6035, 17.1776],\n",
      "        [21.3373, 15.7992, 16.9758],\n",
      "        [21.3757, 15.9065, 17.2413]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4981,  20.4634, -15.7982],\n",
      "        [-19.6452,  20.8008, -15.8571],\n",
      "        [-19.2918,  20.8759, -15.8395],\n",
      "        [-19.3644,  20.8537, -15.7892],\n",
      "        [-19.4077,  20.9583, -16.0153],\n",
      "        [-19.7709,  20.7956, -16.0429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1285,  15.6702,  16.6717, -19.4981,  20.4634, -15.7982],\n",
      "        [ 21.3346,  16.0043,  17.1398, -19.6452,  20.8008, -15.8571],\n",
      "        [ 21.2475,  15.7823,  17.1100, -19.2918,  20.8759, -15.8395],\n",
      "        [ 20.9714,  15.6035,  17.1776, -19.3644,  20.8537, -15.7892],\n",
      "        [ 21.3373,  15.7992,  16.9758, -19.4077,  20.9583, -16.0153],\n",
      "        [ 21.3757,  15.9065,  17.2413, -19.7709,  20.7956, -16.0429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.448887348175049\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8039, 15.7009, 17.1669],\n",
      "        [21.2409, 16.0348, 17.1904],\n",
      "        [20.9987, 15.5818, 16.8779],\n",
      "        [21.0532, 15.6580, 16.7092],\n",
      "        [21.4449, 16.0007, 17.0052],\n",
      "        [20.9209, 15.9559, 16.8739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8600,  21.1092, -16.2763],\n",
      "        [-18.7347,  20.4043, -15.7578],\n",
      "        [-19.4626,  21.0081, -15.6193],\n",
      "        [-19.4742,  20.7370, -15.6294],\n",
      "        [-19.8351,  20.7254, -15.9746],\n",
      "        [-19.1066,  20.3515, -15.5633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8039,  15.7009,  17.1669, -19.8600,  21.1092, -16.2763],\n",
      "        [ 21.2409,  16.0348,  17.1904, -18.7347,  20.4043, -15.7578],\n",
      "        [ 20.9987,  15.5818,  16.8779, -19.4626,  21.0081, -15.6193],\n",
      "        [ 21.0532,  15.6580,  16.7092, -19.4742,  20.7370, -15.6294],\n",
      "        [ 21.4449,  16.0007,  17.0052, -19.8351,  20.7254, -15.9746],\n",
      "        [ 20.9209,  15.9559,  16.8739, -19.1066,  20.3515, -15.5633]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4924542903900146\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4973, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3492, 15.9335, 16.9120],\n",
      "        [21.2555, 15.5502, 16.7898],\n",
      "        [21.0789, 15.6695, 17.0911],\n",
      "        [21.2603, 15.7244, 16.8783],\n",
      "        [21.4534, 16.1395, 17.4303],\n",
      "        [21.2023, 15.6434, 16.8942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9403,  21.1808, -16.2833],\n",
      "        [-19.7341,  20.8383, -16.0146],\n",
      "        [-19.3981,  21.0952, -15.8749],\n",
      "        [-19.6818,  21.2634, -15.8944],\n",
      "        [-19.1963,  20.8862, -16.0163],\n",
      "        [-19.7400,  20.8616, -16.2646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3492,  15.9335,  16.9120, -19.9403,  21.1808, -16.2833],\n",
      "        [ 21.2555,  15.5502,  16.7898, -19.7341,  20.8383, -16.0146],\n",
      "        [ 21.0789,  15.6695,  17.0911, -19.3981,  21.0952, -15.8749],\n",
      "        [ 21.2603,  15.7244,  16.8783, -19.6818,  21.2634, -15.8944],\n",
      "        [ 21.4534,  16.1395,  17.4303, -19.1963,  20.8862, -16.0163],\n",
      "        [ 21.2023,  15.6434,  16.8942, -19.7400,  20.8616, -16.2646]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.520242929458618\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5782, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9162, 15.9052, 16.8467],\n",
      "        [20.7270, 15.3596, 16.7388],\n",
      "        [21.2079, 16.1941, 17.4417],\n",
      "        [21.0661, 15.8781, 16.8462],\n",
      "        [20.7871, 15.7702, 16.6867],\n",
      "        [21.1171, 15.5651, 17.1565]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.2502, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4045,  20.6528, -16.0251],\n",
      "        [-19.2825,  20.2861, -15.5043],\n",
      "        [-18.8359,  20.5683, -15.6176],\n",
      "        [-19.8616,  21.0459, -15.9738],\n",
      "        [-18.9587,  20.4085, -15.4351],\n",
      "        [-19.8350,  21.1504, -15.9941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9162,  15.9052,  16.8467, -19.4045,  20.6528, -16.0251],\n",
      "        [ 20.7270,  15.3596,  16.7388, -19.2825,  20.2861, -15.5043],\n",
      "        [ 21.2079,  16.1941,  17.4417, -18.8359,  20.5683, -15.6176],\n",
      "        [ 21.0661,  15.8781,  16.8462, -19.8616,  21.0459, -15.9738],\n",
      "        [ 20.7871,  15.7702,  16.6867, -18.9587,  20.4085, -15.4351],\n",
      "        [ 21.1171,  15.5651,  17.1565, -19.8350,  21.1504, -15.9941]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.4637691974639893\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6543, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4071, 15.9597, 17.2520],\n",
      "        [21.3093, 15.6977, 17.5191],\n",
      "        [21.0344, 15.7933, 16.9959],\n",
      "        [20.9997, 15.5943, 17.0014],\n",
      "        [21.1716, 15.7290, 17.1605],\n",
      "        [21.0064, 16.1716, 16.7872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5062, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1658,  20.5912, -15.7580],\n",
      "        [-18.9472,  20.4659, -15.7032],\n",
      "        [-18.3757,  20.0314, -15.2056],\n",
      "        [-20.0013,  20.9550, -16.0598],\n",
      "        [-19.2634,  20.8142, -15.7877],\n",
      "        [-19.3543,  20.4906, -15.6922]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4071,  15.9597,  17.2520, -19.1658,  20.5912, -15.7580],\n",
      "        [ 21.3093,  15.6977,  17.5191, -18.9472,  20.4659, -15.7032],\n",
      "        [ 21.0344,  15.7933,  16.9959, -18.3757,  20.0314, -15.2056],\n",
      "        [ 20.9997,  15.5943,  17.0014, -20.0013,  20.9550, -16.0598],\n",
      "        [ 21.1716,  15.7290,  17.1605, -19.2634,  20.8142, -15.7877],\n",
      "        [ 21.0064,  16.1716,  16.7872, -19.3543,  20.4906, -15.6922]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.491252899169922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0127, 16.0775, 16.8652],\n",
      "        [20.9256, 15.9596, 16.8989],\n",
      "        [21.1763, 15.8761, 16.6942],\n",
      "        [21.7617, 15.8620, 17.0097],\n",
      "        [21.4142, 15.7674, 17.1577],\n",
      "        [21.6315, 16.3749, 17.3861]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5729, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6527,  20.6424, -15.8110],\n",
      "        [-19.8408,  21.1694, -16.3562],\n",
      "        [-19.5771,  20.9711, -16.2474],\n",
      "        [-19.6061,  21.1572, -16.0859],\n",
      "        [-19.2831,  20.5169, -15.6623],\n",
      "        [-19.1048,  20.4642, -16.2219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0127,  16.0775,  16.8652, -19.6527,  20.6424, -15.8110],\n",
      "        [ 20.9256,  15.9596,  16.8989, -19.8408,  21.1694, -16.3562],\n",
      "        [ 21.1763,  15.8761,  16.6942, -19.5771,  20.9711, -16.2474],\n",
      "        [ 21.7617,  15.8620,  17.0097, -19.6061,  21.1572, -16.0859],\n",
      "        [ 21.4142,  15.7674,  17.1577, -19.2831,  20.5169, -15.6623],\n",
      "        [ 21.6315,  16.3749,  17.3861, -19.1048,  20.4642, -16.2219]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.47843861579895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2273, 15.9054, 16.9503],\n",
      "        [21.4157, 15.8200, 17.1586],\n",
      "        [20.7855, 15.7344, 16.8145],\n",
      "        [21.6576, 16.0051, 17.0026],\n",
      "        [21.0866, 16.0285, 16.6409],\n",
      "        [21.0964, 15.9961, 17.0686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5261, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6147,  20.7124, -15.8628],\n",
      "        [-19.5654,  21.3141, -16.0202],\n",
      "        [-19.1965,  21.0155, -16.0367],\n",
      "        [-19.5431,  20.9282, -15.9973],\n",
      "        [-18.9776,  20.3100, -16.0046],\n",
      "        [-19.4450,  21.0050, -15.9865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2273,  15.9054,  16.9503, -19.6147,  20.7124, -15.8628],\n",
      "        [ 21.4157,  15.8200,  17.1586, -19.5654,  21.3141, -16.0202],\n",
      "        [ 20.7855,  15.7344,  16.8145, -19.1965,  21.0155, -16.0367],\n",
      "        [ 21.6576,  16.0051,  17.0026, -19.5431,  20.9282, -15.9973],\n",
      "        [ 21.0866,  16.0285,  16.6409, -18.9776,  20.3100, -16.0046],\n",
      "        [ 21.0964,  15.9961,  17.0686, -19.4450,  21.0050, -15.9865]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4905319213867188\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5285, 16.1181, 17.0702],\n",
      "        [21.5551, 16.2153, 16.9132],\n",
      "        [21.1770, 16.0713, 17.2456],\n",
      "        [21.1581, 15.4405, 16.8771],\n",
      "        [21.3723, 15.9373, 17.0437],\n",
      "        [21.1798, 15.9613, 17.0919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4032,  20.6872, -16.3140],\n",
      "        [-18.8530,  20.6374, -15.9497],\n",
      "        [-19.9375,  20.8611, -16.2696],\n",
      "        [-19.6297,  20.7988, -15.9859],\n",
      "        [-19.7648,  21.1898, -16.2052],\n",
      "        [-19.7704,  20.5601, -16.2132]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5285,  16.1181,  17.0702, -19.4032,  20.6872, -16.3140],\n",
      "        [ 21.5551,  16.2153,  16.9132, -18.8530,  20.6374, -15.9497],\n",
      "        [ 21.1770,  16.0713,  17.2456, -19.9375,  20.8611, -16.2696],\n",
      "        [ 21.1581,  15.4405,  16.8771, -19.6297,  20.7988, -15.9859],\n",
      "        [ 21.3723,  15.9373,  17.0437, -19.7648,  21.1898, -16.2052],\n",
      "        [ 21.1798,  15.9613,  17.0919, -19.7704,  20.5601, -16.2132]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.519023895263672\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.7575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7855, 15.9384, 17.5813],\n",
      "        [21.1075, 15.9414, 17.1459],\n",
      "        [21.4442, 16.1257, 16.9252],\n",
      "        [20.8574, 15.8418, 16.8161],\n",
      "        [20.9792, 15.7633, 16.7081],\n",
      "        [21.0295, 15.7818, 16.8463]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5039, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3441,  20.6737, -15.7430],\n",
      "        [-19.3838,  21.1819, -16.2281],\n",
      "        [-19.4910,  20.7860, -15.7845],\n",
      "        [-19.5889,  20.6655, -15.9371],\n",
      "        [-19.4615,  21.0064, -16.2025],\n",
      "        [-19.9041,  21.1668, -16.3934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7855,  15.9384,  17.5813, -19.3441,  20.6737, -15.7430],\n",
      "        [ 21.1075,  15.9414,  17.1459, -19.3838,  21.1819, -16.2281],\n",
      "        [ 21.4442,  16.1257,  16.9252, -19.4910,  20.7860, -15.7845],\n",
      "        [ 20.8574,  15.8418,  16.8161, -19.5889,  20.6655, -15.9371],\n",
      "        [ 20.9792,  15.7633,  16.7081, -19.4615,  21.0064, -16.2025],\n",
      "        [ 21.0295,  15.7818,  16.8463, -19.9041,  21.1668, -16.3934]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5333571434020996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7446, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.7687, 15.5578, 16.4188],\n",
      "        [21.0400, 15.8766, 16.8832],\n",
      "        [21.3124, 15.9068, 17.2357],\n",
      "        [21.5891, 15.5908, 16.7406],\n",
      "        [21.1742, 15.9174, 17.2811],\n",
      "        [21.2051, 16.2839, 16.9691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.1078, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6211,  21.1260, -15.9061],\n",
      "        [-19.4606,  20.8159, -16.1774],\n",
      "        [-19.4133,  21.1191, -16.0173],\n",
      "        [-19.6381,  20.9937, -16.0740],\n",
      "        [-19.4453,  20.8780, -15.5946],\n",
      "        [-18.9697,  20.2981, -15.2723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.7687,  15.5578,  16.4188, -19.6211,  21.1260, -15.9061],\n",
      "        [ 21.0400,  15.8766,  16.8832, -19.4606,  20.8159, -16.1774],\n",
      "        [ 21.3124,  15.9068,  17.2357, -19.4133,  21.1191, -16.0173],\n",
      "        [ 21.5891,  15.5908,  16.7406, -19.6381,  20.9937, -16.0740],\n",
      "        [ 21.1742,  15.9174,  17.2811, -19.4453,  20.8780, -15.5946],\n",
      "        [ 21.2051,  16.2839,  16.9691, -18.9697,  20.2981, -15.2723]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.4571874141693115\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2507, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3917, 16.0582, 17.0304],\n",
      "        [21.6831, 15.9913, 17.3725],\n",
      "        [21.0821, 15.6802, 16.7839],\n",
      "        [21.0386, 15.9528, 17.1092],\n",
      "        [21.0355, 15.4439, 16.9868],\n",
      "        [21.6803, 15.9335, 16.9515]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1621, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0958,  20.7425, -15.6335],\n",
      "        [-19.6366,  20.6683, -15.6270],\n",
      "        [-19.9712,  21.0535, -16.2411],\n",
      "        [-19.6028,  21.1759, -16.0103],\n",
      "        [-19.1231,  20.8262, -15.6274],\n",
      "        [-19.8318,  20.8473, -15.8246]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3917,  16.0582,  17.0304, -19.0958,  20.7425, -15.6335],\n",
      "        [ 21.6831,  15.9913,  17.3725, -19.6366,  20.6683, -15.6270],\n",
      "        [ 21.0821,  15.6802,  16.7839, -19.9712,  21.0535, -16.2411],\n",
      "        [ 21.0386,  15.9528,  17.1092, -19.6028,  21.1759, -16.0103],\n",
      "        [ 21.0355,  15.4439,  16.9868, -19.1231,  20.8262, -15.6274],\n",
      "        [ 21.6803,  15.9335,  16.9515, -19.8318,  20.8473, -15.8246]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4935662746429443\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2931, 16.0336, 17.0482],\n",
      "        [21.1293, 16.0778, 16.8490],\n",
      "        [21.3544, 15.7856, 16.7809],\n",
      "        [21.5690, 16.3012, 17.1276],\n",
      "        [21.0214, 16.0315, 16.7939],\n",
      "        [20.7797, 15.6574, 16.6006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.6839, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4305,  20.7201, -15.9364],\n",
      "        [-19.7303,  21.4263, -16.4001],\n",
      "        [-20.0374,  21.0296, -15.9916],\n",
      "        [-19.2737,  20.2322, -15.4589],\n",
      "        [-19.0412,  20.4711, -16.0033],\n",
      "        [-19.7026,  20.5146, -15.9108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2931,  16.0336,  17.0482, -19.4305,  20.7201, -15.9364],\n",
      "        [ 21.1293,  16.0778,  16.8490, -19.7303,  21.4263, -16.4001],\n",
      "        [ 21.3544,  15.7856,  16.7809, -20.0374,  21.0296, -15.9916],\n",
      "        [ 21.5690,  16.3012,  17.1276, -19.2737,  20.2322, -15.4589],\n",
      "        [ 21.0214,  16.0315,  16.7939, -19.0412,  20.4711, -16.0033],\n",
      "        [ 20.7797,  15.6574,  16.6006, -19.7026,  20.5146, -15.9108]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5048606395721436\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7482, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0553, 16.0402, 16.9366],\n",
      "        [21.0850, 15.9004, 16.7107],\n",
      "        [21.3177, 16.1719, 16.8306],\n",
      "        [21.3151, 16.0356, 17.2223],\n",
      "        [21.5137, 15.8324, 17.3993],\n",
      "        [21.3014, 16.1178, 16.7349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.7830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3518,  20.6115, -15.7342],\n",
      "        [-20.0285,  21.0242, -16.2139],\n",
      "        [-20.0607,  21.3666, -16.2190],\n",
      "        [-19.3025,  21.0842, -15.8602],\n",
      "        [-19.0633,  20.4282, -15.5244],\n",
      "        [-19.3252,  20.5652, -15.8455]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0553,  16.0402,  16.9366, -19.3518,  20.6115, -15.7342],\n",
      "        [ 21.0850,  15.9004,  16.7107, -20.0285,  21.0242, -16.2139],\n",
      "        [ 21.3177,  16.1719,  16.8306, -20.0607,  21.3666, -16.2190],\n",
      "        [ 21.3151,  16.0356,  17.2223, -19.3025,  21.0842, -15.8602],\n",
      "        [ 21.5137,  15.8324,  17.3993, -19.0633,  20.4282, -15.5244],\n",
      "        [ 21.3014,  16.1178,  16.7349, -19.3252,  20.5652, -15.8455]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4818551540374756\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0693, 16.1633, 17.2210],\n",
      "        [21.4375, 15.7724, 17.1654],\n",
      "        [21.3174, 15.4262, 17.1540],\n",
      "        [21.1301, 16.2681, 17.1695],\n",
      "        [21.0841, 15.9643, 16.9584],\n",
      "        [20.9205, 15.3322, 16.7166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5502, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4683,  20.9492, -16.2335],\n",
      "        [-19.5382,  20.9556, -16.1470],\n",
      "        [-19.6696,  21.1917, -16.0205],\n",
      "        [-19.4664,  20.6136, -16.0765],\n",
      "        [-19.5971,  20.9424, -15.8976],\n",
      "        [-19.2646,  20.5742, -15.3555]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0693,  16.1633,  17.2210, -19.4683,  20.9492, -16.2335],\n",
      "        [ 21.4375,  15.7724,  17.1654, -19.5382,  20.9556, -16.1470],\n",
      "        [ 21.3174,  15.4262,  17.1540, -19.6696,  21.1917, -16.0205],\n",
      "        [ 21.1301,  16.2681,  17.1695, -19.4664,  20.6136, -16.0765],\n",
      "        [ 21.0841,  15.9643,  16.9584, -19.5971,  20.9424, -15.8976],\n",
      "        [ 20.9205,  15.3322,  16.7166, -19.2646,  20.5742, -15.3555]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.521021604537964\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4936, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1774, 15.6066, 17.1903],\n",
      "        [21.4646, 16.0844, 17.2739],\n",
      "        [20.7923, 15.3780, 16.4684],\n",
      "        [20.8104, 15.6926, 16.4390],\n",
      "        [21.5991, 16.0434, 17.3648],\n",
      "        [21.2040, 15.6668, 17.1095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.8786, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7302,  21.0491, -16.0183],\n",
      "        [-19.2357,  20.5753, -16.0453],\n",
      "        [-19.5044,  21.1342, -16.0185],\n",
      "        [-19.4893,  20.7150, -15.8383],\n",
      "        [-19.3862,  21.0808, -16.0184],\n",
      "        [-19.6359,  21.0752, -16.1959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1774,  15.6066,  17.1903, -19.7302,  21.0491, -16.0183],\n",
      "        [ 21.4646,  16.0844,  17.2739, -19.2357,  20.5753, -16.0453],\n",
      "        [ 20.7923,  15.3780,  16.4684, -19.5044,  21.1342, -16.0185],\n",
      "        [ 20.8104,  15.6926,  16.4390, -19.4893,  20.7150, -15.8383],\n",
      "        [ 21.5991,  16.0434,  17.3648, -19.3862,  21.0808, -16.0184],\n",
      "        [ 21.2040,  15.6668,  17.1095, -19.6359,  21.0752, -16.1959]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.516890287399292\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8747, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0275, 15.5460, 17.0242],\n",
      "        [21.6232, 15.6968, 17.1317],\n",
      "        [21.3547, 16.1444, 17.2923],\n",
      "        [20.7976, 16.0302, 16.5207],\n",
      "        [21.9434, 16.4845, 17.5732],\n",
      "        [21.7300, 16.0634, 17.2062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.0468, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5548,  20.6429, -16.0706],\n",
      "        [-19.6212,  21.3942, -16.0991],\n",
      "        [-19.1763,  20.7139, -15.8552],\n",
      "        [-19.5977,  20.9149, -16.1045],\n",
      "        [-19.4487,  21.0092, -16.1061],\n",
      "        [-19.5808,  20.6030, -15.7894]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0275,  15.5460,  17.0242, -19.5548,  20.6429, -16.0706],\n",
      "        [ 21.6232,  15.6968,  17.1317, -19.6212,  21.3942, -16.0991],\n",
      "        [ 21.3547,  16.1444,  17.2923, -19.1763,  20.7139, -15.8552],\n",
      "        [ 20.7976,  16.0302,  16.5207, -19.5977,  20.9149, -16.1045],\n",
      "        [ 21.9434,  16.4845,  17.5732, -19.4487,  21.0092, -16.1061],\n",
      "        [ 21.7300,  16.0634,  17.2062, -19.5808,  20.6030, -15.7894]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.4881088733673096\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1293, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4069, 15.5948, 16.8416],\n",
      "        [21.0041, 15.3841, 16.6281],\n",
      "        [21.1402, 16.1498, 17.4151],\n",
      "        [21.6056, 16.2169, 16.8380],\n",
      "        [21.4442, 16.1173, 16.9942],\n",
      "        [21.0282, 15.5931, 16.8909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.3909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6171,  20.8496, -15.6024],\n",
      "        [-20.2089,  21.0091, -16.3502],\n",
      "        [-19.7427,  20.9233, -16.2181],\n",
      "        [-19.5794,  20.4364, -16.0150],\n",
      "        [-19.1917,  20.4160, -15.5660],\n",
      "        [-19.5404,  20.8306, -16.1818]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4069,  15.5948,  16.8416, -19.6171,  20.8496, -15.6024],\n",
      "        [ 21.0041,  15.3841,  16.6281, -20.2089,  21.0091, -16.3502],\n",
      "        [ 21.1402,  16.1498,  17.4151, -19.7427,  20.9233, -16.2181],\n",
      "        [ 21.6056,  16.2169,  16.8380, -19.5794,  20.4364, -16.0150],\n",
      "        [ 21.4442,  16.1173,  16.9942, -19.1917,  20.4160, -15.5660],\n",
      "        [ 21.0282,  15.5931,  16.8909, -19.5404,  20.8306, -16.1818]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.4997782707214355\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2954, 15.7401, 16.7540],\n",
      "        [21.4727, 15.9657, 17.2930],\n",
      "        [21.7926, 15.9157, 17.2465],\n",
      "        [21.4259, 16.2547, 16.8069],\n",
      "        [21.5427, 16.5035, 17.0600],\n",
      "        [20.8886, 15.8387, 17.1584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.0879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4172,  20.9003, -16.0905],\n",
      "        [-19.3879,  20.6884, -15.6284],\n",
      "        [-19.5163,  20.9139, -16.2346],\n",
      "        [-19.2720,  20.5400, -15.6441],\n",
      "        [-19.4879,  20.4265, -16.0122],\n",
      "        [-19.7525,  21.4205, -16.4330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2954,  15.7401,  16.7540, -19.4172,  20.9003, -16.0905],\n",
      "        [ 21.4727,  15.9657,  17.2930, -19.3879,  20.6884, -15.6284],\n",
      "        [ 21.7926,  15.9157,  17.2465, -19.5163,  20.9139, -16.2346],\n",
      "        [ 21.4259,  16.2547,  16.8069, -19.2720,  20.5400, -15.6441],\n",
      "        [ 21.5427,  16.5035,  17.0600, -19.4879,  20.4265, -16.0122],\n",
      "        [ 20.8886,  15.8387,  17.1584, -19.7525,  21.4205, -16.4330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.502720594406128\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5930, 15.8688, 17.3502],\n",
      "        [21.0325, 15.5560, 16.7638],\n",
      "        [20.9636, 15.7366, 16.8103],\n",
      "        [20.9874, 15.4953, 16.8377],\n",
      "        [21.9023, 16.2349, 17.6240],\n",
      "        [21.3075, 15.8057, 17.3491]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4100,  20.9476, -15.9105],\n",
      "        [-19.3248,  20.5417, -16.1503],\n",
      "        [-19.0520,  20.6484, -15.6722],\n",
      "        [-20.1447,  21.3807, -16.5142],\n",
      "        [-19.3009,  20.5927, -15.7568],\n",
      "        [-19.8133,  21.2852, -16.3194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5930,  15.8688,  17.3502, -19.4100,  20.9476, -15.9105],\n",
      "        [ 21.0325,  15.5560,  16.7638, -19.3248,  20.5417, -16.1503],\n",
      "        [ 20.9636,  15.7366,  16.8103, -19.0520,  20.6484, -15.6722],\n",
      "        [ 20.9874,  15.4953,  16.8377, -20.1447,  21.3807, -16.5142],\n",
      "        [ 21.9023,  16.2349,  17.6240, -19.3009,  20.5927, -15.7568],\n",
      "        [ 21.3075,  15.8057,  17.3491, -19.8133,  21.2852, -16.3194]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5415775775909424\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3486, 15.9757, 17.1833],\n",
      "        [21.2449, 15.6514, 16.8889],\n",
      "        [21.8461, 16.3177, 17.2341],\n",
      "        [20.7490, 15.7117, 16.7335],\n",
      "        [21.2302, 15.9554, 17.4977],\n",
      "        [21.8071, 16.4428, 17.4030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1848, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2535,  21.1595, -15.7745],\n",
      "        [-20.1411,  21.1979, -16.7585],\n",
      "        [-20.3233,  21.2368, -16.2022],\n",
      "        [-19.4679,  20.9882, -16.4527],\n",
      "        [-19.1428,  20.6111, -16.1579],\n",
      "        [-19.2321,  20.7982, -16.2531]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3486,  15.9757,  17.1833, -19.2535,  21.1595, -15.7745],\n",
      "        [ 21.2449,  15.6514,  16.8889, -20.1411,  21.1979, -16.7585],\n",
      "        [ 21.8461,  16.3177,  17.2341, -20.3233,  21.2368, -16.2022],\n",
      "        [ 20.7490,  15.7117,  16.7335, -19.4679,  20.9882, -16.4527],\n",
      "        [ 21.2302,  15.9554,  17.4977, -19.1428,  20.6111, -16.1579],\n",
      "        [ 21.8071,  16.4428,  17.4030, -19.2321,  20.7982, -16.2531]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.527378797531128\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1868, 15.8992, 17.1925],\n",
      "        [20.8432, 15.9139, 17.0476],\n",
      "        [20.9067, 15.7678, 16.5115],\n",
      "        [21.3145, 16.0456, 17.1673],\n",
      "        [21.1141, 15.9197, 16.9177],\n",
      "        [21.7022, 15.9208, 17.1636]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4370, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4347,  20.7141, -16.0590],\n",
      "        [-19.5710,  21.2474, -16.0978],\n",
      "        [-19.8189,  21.2875, -16.2883],\n",
      "        [-19.6209,  20.9062, -16.2587],\n",
      "        [-19.6292,  21.2405, -16.2707],\n",
      "        [-20.1431,  21.2402, -16.0973]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1868,  15.8992,  17.1925, -19.4347,  20.7141, -16.0590],\n",
      "        [ 20.8432,  15.9139,  17.0476, -19.5710,  21.2474, -16.0978],\n",
      "        [ 20.9067,  15.7678,  16.5115, -19.8189,  21.2875, -16.2883],\n",
      "        [ 21.3145,  16.0456,  17.1673, -19.6209,  20.9062, -16.2587],\n",
      "        [ 21.1141,  15.9197,  16.9177, -19.6292,  21.2405, -16.2707],\n",
      "        [ 21.7022,  15.9208,  17.1636, -20.1431,  21.2402, -16.0973]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5173263549804688\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7204, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6647, 16.1486, 17.6269],\n",
      "        [21.8465, 16.4291, 17.0339],\n",
      "        [21.4724, 15.9743, 16.9234],\n",
      "        [21.1028, 15.9930, 16.9892],\n",
      "        [21.3429, 16.0478, 17.3722],\n",
      "        [21.7018, 16.2270, 17.4138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5369, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.5610,  20.8499, -16.1280],\n",
      "        [-19.8957,  21.0333, -16.1665],\n",
      "        [-19.6457,  21.1788, -16.3189],\n",
      "        [-20.0833,  21.3437, -16.0715],\n",
      "        [-19.2487,  20.8462, -15.9234],\n",
      "        [-19.9073,  21.4524, -16.3275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6647,  16.1486,  17.6269, -19.5610,  20.8499, -16.1280],\n",
      "        [ 21.8465,  16.4291,  17.0339, -19.8957,  21.0333, -16.1665],\n",
      "        [ 21.4724,  15.9743,  16.9234, -19.6457,  21.1788, -16.3189],\n",
      "        [ 21.1028,  15.9930,  16.9892, -20.0833,  21.3437, -16.0715],\n",
      "        [ 21.3429,  16.0478,  17.3722, -19.2487,  20.8462, -15.9234],\n",
      "        [ 21.7018,  16.2270,  17.4138, -19.9073,  21.4524, -16.3275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.573012113571167\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8791, 15.8448, 16.9055],\n",
      "        [21.2983, 15.8630, 16.9113],\n",
      "        [21.2209, 15.9418, 17.3301],\n",
      "        [20.7717, 15.5164, 16.5820],\n",
      "        [21.5278, 16.3681, 17.6048],\n",
      "        [21.0511, 15.9369, 17.2840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8877,  20.8875, -16.1367],\n",
      "        [-19.4030,  20.6007, -15.9744],\n",
      "        [-19.9900,  21.3463, -16.8700],\n",
      "        [-19.8638,  20.9848, -16.1030],\n",
      "        [-19.0548,  20.6927, -15.5729],\n",
      "        [-19.9455,  21.2125, -16.4885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8791,  15.8448,  16.9055, -19.8877,  20.8875, -16.1367],\n",
      "        [ 21.2983,  15.8630,  16.9113, -19.4030,  20.6007, -15.9744],\n",
      "        [ 21.2209,  15.9418,  17.3301, -19.9900,  21.3463, -16.8700],\n",
      "        [ 20.7717,  15.5164,  16.5820, -19.8638,  20.9848, -16.1030],\n",
      "        [ 21.5278,  16.3681,  17.6048, -19.0548,  20.6927, -15.5729],\n",
      "        [ 21.0511,  15.9369,  17.2840, -19.9455,  21.2125, -16.4885]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.512281894683838\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0345, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6778, 16.1205, 17.4487],\n",
      "        [21.4916, 16.1762, 17.3399],\n",
      "        [21.2116, 16.0296, 17.2655],\n",
      "        [21.1720, 15.4222, 16.9097],\n",
      "        [21.2276, 16.1029, 16.7104],\n",
      "        [21.1182, 16.0325, 17.4065]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3402, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2454,  20.7478, -15.5768],\n",
      "        [-19.8167,  20.7653, -15.6444],\n",
      "        [-19.2008,  21.0147, -15.9043],\n",
      "        [-19.7703,  21.0551, -15.9969],\n",
      "        [-19.8674,  20.7661, -16.1809],\n",
      "        [-19.1322,  20.7026, -16.0760]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6778,  16.1205,  17.4487, -19.2454,  20.7478, -15.5768],\n",
      "        [ 21.4916,  16.1762,  17.3399, -19.8167,  20.7653, -15.6444],\n",
      "        [ 21.2116,  16.0296,  17.2655, -19.2008,  21.0147, -15.9043],\n",
      "        [ 21.1720,  15.4222,  16.9097, -19.7703,  21.0551, -15.9969],\n",
      "        [ 21.2276,  16.1029,  16.7104, -19.8674,  20.7661, -16.1809],\n",
      "        [ 21.1182,  16.0325,  17.4065, -19.1322,  20.7026, -16.0760]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5463719367980957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6698, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4603, 16.0834, 17.0397],\n",
      "        [21.2715, 16.1191, 16.9856],\n",
      "        [20.7528, 16.0165, 17.0670],\n",
      "        [21.5234, 15.9185, 17.4040],\n",
      "        [20.8438, 16.0167, 17.1713],\n",
      "        [21.4834, 16.1463, 17.2096]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6619,  20.7364, -15.8217],\n",
      "        [-19.7160,  20.7924, -16.2291],\n",
      "        [-19.7311,  21.2153, -15.9975],\n",
      "        [-19.5992,  20.8181, -16.0814],\n",
      "        [-19.6362,  20.8994, -16.1067],\n",
      "        [-19.6710,  20.7135, -16.1094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4603,  16.0834,  17.0397, -19.6619,  20.7364, -15.8217],\n",
      "        [ 21.2715,  16.1191,  16.9856, -19.7160,  20.7924, -16.2291],\n",
      "        [ 20.7528,  16.0165,  17.0670, -19.7311,  21.2153, -15.9975],\n",
      "        [ 21.5234,  15.9185,  17.4040, -19.5992,  20.8181, -16.0814],\n",
      "        [ 20.8438,  16.0167,  17.1713, -19.6362,  20.8994, -16.1067],\n",
      "        [ 21.4834,  16.1463,  17.2096, -19.6710,  20.7135, -16.1094]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5370213985443115\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2908, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3978, 16.1143, 16.9789],\n",
      "        [21.1757, 16.1235, 16.7994],\n",
      "        [21.1451, 16.3254, 16.7654],\n",
      "        [21.2089, 15.9953, 17.0934],\n",
      "        [21.2321, 15.8966, 16.9390],\n",
      "        [21.1122, 15.6587, 16.9540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.3968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.0983,  20.8531, -15.6918],\n",
      "        [-19.3902,  20.9063, -15.9803],\n",
      "        [-19.7509,  20.7603, -16.0348],\n",
      "        [-19.2428,  20.9463, -16.0394],\n",
      "        [-19.8756,  21.0571, -16.2423],\n",
      "        [-19.7128,  21.2413, -16.0869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3978,  16.1143,  16.9789, -19.0983,  20.8531, -15.6918],\n",
      "        [ 21.1757,  16.1235,  16.7994, -19.3902,  20.9063, -15.9803],\n",
      "        [ 21.1451,  16.3254,  16.7654, -19.7509,  20.7603, -16.0348],\n",
      "        [ 21.2089,  15.9953,  17.0934, -19.2428,  20.9463, -16.0394],\n",
      "        [ 21.2321,  15.8966,  16.9390, -19.8756,  21.0571, -16.2423],\n",
      "        [ 21.1122,  15.6587,  16.9540, -19.7128,  21.2413, -16.0869]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.519712448120117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8122, 15.5651, 16.6120],\n",
      "        [21.4323, 16.1303, 17.3228],\n",
      "        [21.2787, 15.9390, 17.0793],\n",
      "        [21.0520, 16.1090, 16.9171],\n",
      "        [21.3262, 16.1379, 16.9561],\n",
      "        [21.3125, 16.0213, 17.0731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(12.9499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6514,  20.7067, -16.3054],\n",
      "        [-19.7183,  20.9624, -16.5208],\n",
      "        [-19.1365,  20.6181, -16.0126],\n",
      "        [-19.5402,  21.1122, -16.2289],\n",
      "        [-19.6950,  21.5003, -16.0484],\n",
      "        [-19.4903,  20.5219, -16.0968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8122,  15.5651,  16.6120, -19.6514,  20.7067, -16.3054],\n",
      "        [ 21.4323,  16.1303,  17.3228, -19.7183,  20.9624, -16.5208],\n",
      "        [ 21.2787,  15.9390,  17.0793, -19.1365,  20.6181, -16.0126],\n",
      "        [ 21.0520,  16.1090,  16.9171, -19.5402,  21.1122, -16.2289],\n",
      "        [ 21.3262,  16.1379,  16.9561, -19.6950,  21.5003, -16.0484],\n",
      "        [ 21.3125,  16.0213,  17.0731, -19.4903,  20.5219, -16.0968]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.488173246383667\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2662, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.0858, 16.1420, 17.1313],\n",
      "        [21.7240, 16.3708, 17.5133],\n",
      "        [21.3356, 15.7783, 16.9095],\n",
      "        [21.7781, 16.3984, 17.3488],\n",
      "        [21.0426, 15.7873, 16.6613],\n",
      "        [20.9487, 16.0316, 16.7514]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3079, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9134,  21.3716, -16.3621],\n",
      "        [-19.6783,  20.8907, -16.1958],\n",
      "        [-19.5660,  20.9070, -16.2394],\n",
      "        [-19.3116,  20.5101, -15.7258],\n",
      "        [-19.7566,  21.2886, -16.6058],\n",
      "        [-19.5660,  20.8448, -16.2814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.0858,  16.1420,  17.1313, -19.9134,  21.3716, -16.3621],\n",
      "        [ 21.7240,  16.3708,  17.5133, -19.6783,  20.8907, -16.1958],\n",
      "        [ 21.3356,  15.7783,  16.9095, -19.5660,  20.9070, -16.2394],\n",
      "        [ 21.7781,  16.3984,  17.3488, -19.3116,  20.5101, -15.7258],\n",
      "        [ 21.0426,  15.7873,  16.6613, -19.7566,  21.2886, -16.6058],\n",
      "        [ 20.9487,  16.0316,  16.7514, -19.5660,  20.8448, -16.2814]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.565258264541626\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6206, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0239, 16.3714, 17.8054],\n",
      "        [21.4077, 16.6536, 17.4675],\n",
      "        [21.6649, 16.1102, 17.4483],\n",
      "        [20.9012, 16.0847, 16.9794],\n",
      "        [21.8618, 16.2489, 17.5818],\n",
      "        [21.8049, 16.5018, 17.4150]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2498,  20.6565, -15.7069],\n",
      "        [-19.5378,  21.2587, -16.2308],\n",
      "        [-19.4861,  20.7698, -15.9526],\n",
      "        [-19.7245,  21.4545, -16.6294],\n",
      "        [-19.8471,  21.3684, -16.6095],\n",
      "        [-19.3645,  20.7839, -15.2532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0239,  16.3714,  17.8054, -19.2498,  20.6565, -15.7069],\n",
      "        [ 21.4077,  16.6536,  17.4675, -19.5378,  21.2587, -16.2308],\n",
      "        [ 21.6649,  16.1102,  17.4483, -19.4861,  20.7698, -15.9526],\n",
      "        [ 20.9012,  16.0847,  16.9794, -19.7245,  21.4545, -16.6294],\n",
      "        [ 21.8618,  16.2489,  17.5818, -19.8471,  21.3684, -16.6095],\n",
      "        [ 21.8049,  16.5018,  17.4150, -19.3645,  20.7839, -15.2532]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.59035325050354\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4278, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5359, 16.3410, 17.5503],\n",
      "        [21.8480, 16.4261, 17.2151],\n",
      "        [21.8308, 16.2361, 17.5532],\n",
      "        [20.9532, 16.0862, 16.9535],\n",
      "        [21.4885, 16.0116, 17.5151],\n",
      "        [21.4152, 16.0290, 17.2231]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9741, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9174,  21.2864, -16.5383],\n",
      "        [-19.7700,  21.1274, -16.1259],\n",
      "        [-19.1610,  20.9512, -15.9739],\n",
      "        [-20.0658,  21.3078, -16.5659],\n",
      "        [-19.5225,  21.0371, -16.2944],\n",
      "        [-19.4052,  20.8704, -16.1518]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5359,  16.3410,  17.5503, -19.9174,  21.2864, -16.5383],\n",
      "        [ 21.8480,  16.4261,  17.2151, -19.7700,  21.1274, -16.1259],\n",
      "        [ 21.8308,  16.2361,  17.5532, -19.1610,  20.9512, -15.9739],\n",
      "        [ 20.9532,  16.0862,  16.9535, -20.0658,  21.3078, -16.5659],\n",
      "        [ 21.4885,  16.0116,  17.5151, -19.5225,  21.0371, -16.2944],\n",
      "        [ 21.4152,  16.0290,  17.2231, -19.4052,  20.8704, -16.1518]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6118366718292236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4793, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4548, 15.9716, 17.0442],\n",
      "        [21.3078, 15.9179, 17.2224],\n",
      "        [21.5544, 16.0638, 17.6395],\n",
      "        [20.9196, 15.8728, 16.8904],\n",
      "        [21.6516, 16.4364, 17.3869],\n",
      "        [21.3805, 16.5435, 17.7312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7500,  21.0203, -15.6308],\n",
      "        [-19.8992,  21.1944, -16.1053],\n",
      "        [-19.7478,  21.0191, -16.0955],\n",
      "        [-20.1398,  21.2120, -16.4245],\n",
      "        [-19.6983,  21.1095, -16.4185],\n",
      "        [-19.6023,  20.8736, -15.9068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4548,  15.9716,  17.0442, -19.7500,  21.0203, -15.6308],\n",
      "        [ 21.3078,  15.9179,  17.2224, -19.8992,  21.1944, -16.1053],\n",
      "        [ 21.5544,  16.0638,  17.6395, -19.7478,  21.0191, -16.0955],\n",
      "        [ 20.9196,  15.8728,  16.8904, -20.1398,  21.2120, -16.4245],\n",
      "        [ 21.6516,  16.4364,  17.3869, -19.6983,  21.1095, -16.4185],\n",
      "        [ 21.3805,  16.5435,  17.7312, -19.6023,  20.8736, -15.9068]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5493805408477783\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4879, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9281, 15.7048, 16.7573],\n",
      "        [21.5024, 16.2954, 17.2398],\n",
      "        [21.6078, 16.4312, 17.4153],\n",
      "        [21.8843, 16.1343, 16.9993],\n",
      "        [20.6912, 15.7992, 16.7990],\n",
      "        [21.2591, 16.0649, 16.8786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.4264, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8583,  20.9325, -15.7759],\n",
      "        [-20.0879,  21.2539, -16.6790],\n",
      "        [-19.5670,  20.5850, -16.2089],\n",
      "        [-19.5731,  21.1803, -16.1695],\n",
      "        [-19.9421,  21.4486, -16.6533],\n",
      "        [-20.0161,  21.5224, -16.5701]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9281,  15.7048,  16.7573, -19.8583,  20.9325, -15.7759],\n",
      "        [ 21.5024,  16.2954,  17.2398, -20.0879,  21.2539, -16.6790],\n",
      "        [ 21.6078,  16.4312,  17.4153, -19.5670,  20.5850, -16.2089],\n",
      "        [ 21.8843,  16.1343,  16.9993, -19.5731,  21.1803, -16.1695],\n",
      "        [ 20.6912,  15.7992,  16.7990, -19.9421,  21.4486, -16.6533],\n",
      "        [ 21.2591,  16.0649,  16.8786, -20.0161,  21.5224, -16.5701]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5113840103149414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5655, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.1544, 15.9891, 17.1081],\n",
      "        [21.5144, 16.0570, 16.6964],\n",
      "        [21.0699, 15.6903, 16.8463],\n",
      "        [21.4912, 16.5973, 17.0990],\n",
      "        [21.5130, 16.6727, 17.2947],\n",
      "        [21.3811, 15.4927, 17.5691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4198, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8783,  20.9266, -16.0582],\n",
      "        [-20.0790,  20.9170, -16.1565],\n",
      "        [-19.7322,  21.0804, -16.3679],\n",
      "        [-19.9165,  21.1628, -16.1307],\n",
      "        [-19.0979,  20.8171, -15.8289],\n",
      "        [-19.8000,  20.8345, -16.3174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.1544,  15.9891,  17.1081, -19.8783,  20.9266, -16.0582],\n",
      "        [ 21.5144,  16.0570,  16.6964, -20.0790,  20.9170, -16.1565],\n",
      "        [ 21.0699,  15.6903,  16.8463, -19.7322,  21.0804, -16.3679],\n",
      "        [ 21.4912,  16.5973,  17.0990, -19.9165,  21.1628, -16.1307],\n",
      "        [ 21.5130,  16.6727,  17.2947, -19.0979,  20.8171, -15.8289],\n",
      "        [ 21.3811,  15.4927,  17.5691, -19.8000,  20.8345, -16.3174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5506691932678223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6159, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3537, 16.2474, 17.2150],\n",
      "        [21.8865, 16.2553, 17.3176],\n",
      "        [20.9955, 16.0096, 17.0101],\n",
      "        [21.6168, 16.4415, 17.2617],\n",
      "        [21.2575, 16.0039, 16.6821],\n",
      "        [20.8618, 16.0205, 16.6309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.0946, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2938,  20.8588, -16.0087],\n",
      "        [-19.7906,  21.0029, -16.0797],\n",
      "        [-19.7203,  21.0143, -16.3178],\n",
      "        [-19.5987,  21.0309, -16.2069],\n",
      "        [-19.2985,  20.7616, -15.9049],\n",
      "        [-19.1017,  20.5788, -16.0500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3537,  16.2474,  17.2150, -19.2938,  20.8588, -16.0087],\n",
      "        [ 21.8865,  16.2553,  17.3176, -19.7906,  21.0029, -16.0797],\n",
      "        [ 20.9955,  16.0096,  17.0101, -19.7203,  21.0143, -16.3178],\n",
      "        [ 21.6168,  16.4415,  17.2617, -19.5987,  21.0309, -16.2069],\n",
      "        [ 21.2575,  16.0039,  16.6821, -19.2985,  20.7616, -15.9049],\n",
      "        [ 20.8618,  16.0205,  16.6309, -19.1017,  20.5788, -16.0500]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.5538313388824463\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5281, 16.2712, 17.0036],\n",
      "        [21.2601, 16.2745, 17.5286],\n",
      "        [21.4600, 16.0403, 17.4664],\n",
      "        [21.2254, 16.3600, 17.4401],\n",
      "        [21.4680, 16.1023, 17.6691],\n",
      "        [21.3989, 16.0717, 17.0425]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.9845, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9430,  21.4172, -16.5012],\n",
      "        [-19.4873,  21.0673, -16.2014],\n",
      "        [-20.0554,  20.8358, -16.3844],\n",
      "        [-19.6110,  20.8340, -16.2978],\n",
      "        [-19.8987,  21.3174, -16.5857],\n",
      "        [-20.1596,  21.0732, -16.2577]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5281,  16.2712,  17.0036, -19.9430,  21.4172, -16.5012],\n",
      "        [ 21.2601,  16.2745,  17.5286, -19.4873,  21.0673, -16.2014],\n",
      "        [ 21.4600,  16.0403,  17.4664, -20.0554,  20.8358, -16.3844],\n",
      "        [ 21.2254,  16.3600,  17.4401, -19.6110,  20.8340, -16.2978],\n",
      "        [ 21.4680,  16.1023,  17.6691, -19.8987,  21.3174, -16.5857],\n",
      "        [ 21.3989,  16.0717,  17.0425, -20.1596,  21.0732, -16.2577]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6000170707702637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5984, 16.4752, 17.2215],\n",
      "        [21.2607, 16.2187, 16.9961],\n",
      "        [21.5586, 16.2248, 17.4898],\n",
      "        [20.9422, 15.8124, 17.2901],\n",
      "        [21.1779, 16.2566, 16.9185],\n",
      "        [21.4765, 16.1443, 17.6439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7749,  20.9033, -16.1997],\n",
      "        [-20.1947,  21.1031, -16.6177],\n",
      "        [-19.6611,  21.0314, -16.4740],\n",
      "        [-20.0282,  21.2415, -16.4844],\n",
      "        [-19.9272,  21.4076, -16.3302],\n",
      "        [-19.9935,  21.0783, -16.2538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5984,  16.4752,  17.2215, -19.7749,  20.9033, -16.1997],\n",
      "        [ 21.2607,  16.2187,  16.9961, -20.1947,  21.1031, -16.6177],\n",
      "        [ 21.5586,  16.2248,  17.4898, -19.6611,  21.0314, -16.4740],\n",
      "        [ 20.9422,  15.8124,  17.2901, -20.0282,  21.2415, -16.4844],\n",
      "        [ 21.1779,  16.2566,  16.9185, -19.9272,  21.4076, -16.3302],\n",
      "        [ 21.4765,  16.1443,  17.6439, -19.9935,  21.0783, -16.2538]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5928852558135986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4582, 15.8842, 17.0940],\n",
      "        [21.6807, 16.1507, 17.3161],\n",
      "        [21.6445, 16.3742, 17.5074],\n",
      "        [21.6017, 16.1342, 17.3260],\n",
      "        [21.3667, 16.1349, 17.2850],\n",
      "        [21.9641, 16.3434, 17.6028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.3197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6102,  21.3933, -16.3356],\n",
      "        [-19.7049,  20.9618, -16.4774],\n",
      "        [-19.4698,  21.1320, -15.7765],\n",
      "        [-19.3102,  20.6263, -15.7575],\n",
      "        [-19.9827,  21.5506, -16.5997],\n",
      "        [-19.7609,  21.5542, -16.3095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4582,  15.8842,  17.0940, -19.6102,  21.3933, -16.3356],\n",
      "        [ 21.6807,  16.1507,  17.3161, -19.7049,  20.9618, -16.4774],\n",
      "        [ 21.6445,  16.3742,  17.5074, -19.4698,  21.1320, -15.7765],\n",
      "        [ 21.6017,  16.1342,  17.3260, -19.3102,  20.6263, -15.7575],\n",
      "        [ 21.3667,  16.1349,  17.2850, -19.9827,  21.5506, -16.5997],\n",
      "        [ 21.9641,  16.3434,  17.6028, -19.7609,  21.5542, -16.3095]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5795340538024902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9380, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1892, 16.5509, 17.7745],\n",
      "        [21.2646, 15.9148, 17.4155],\n",
      "        [21.3950, 15.9738, 16.8192],\n",
      "        [21.5465, 16.0371, 16.8044],\n",
      "        [21.1700, 15.8715, 17.2531],\n",
      "        [20.9912, 16.1389, 16.9810]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(19.7281, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0301,  21.4070, -16.2101],\n",
      "        [-20.0709,  21.2182, -16.2450],\n",
      "        [-19.1206,  20.7166, -15.6216],\n",
      "        [-19.8742,  21.4728, -16.5330],\n",
      "        [-19.8723,  21.1992, -16.4697],\n",
      "        [-19.8858,  21.2214, -16.0211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1892,  16.5509,  17.7745, -20.0301,  21.4070, -16.2101],\n",
      "        [ 21.2646,  15.9148,  17.4155, -20.0709,  21.2182, -16.2450],\n",
      "        [ 21.3950,  15.9738,  16.8192, -19.1206,  20.7166, -15.6216],\n",
      "        [ 21.5465,  16.0371,  16.8044, -19.8742,  21.4728, -16.5330],\n",
      "        [ 21.1700,  15.8715,  17.2531, -19.8723,  21.1992, -16.4697],\n",
      "        [ 20.9912,  16.1389,  16.9810, -19.8858,  21.2214, -16.0211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.668475866317749\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6836, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8324, 16.3874, 17.4693],\n",
      "        [21.2484, 16.0585, 17.4031],\n",
      "        [21.7365, 16.2282, 17.5984],\n",
      "        [21.9429, 16.3847, 17.6794],\n",
      "        [21.1073, 16.0547, 17.2307],\n",
      "        [21.6294, 16.2875, 17.2410]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9446,  20.9714, -15.9264],\n",
      "        [-19.9657,  21.2372, -15.9209],\n",
      "        [-19.4478,  20.9622, -16.4343],\n",
      "        [-19.7787,  21.1908, -15.9389],\n",
      "        [-20.0422,  21.4364, -16.6137],\n",
      "        [-19.4550,  21.2459, -16.1052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8324,  16.3874,  17.4693, -19.9446,  20.9714, -15.9264],\n",
      "        [ 21.2484,  16.0585,  17.4031, -19.9657,  21.2372, -15.9209],\n",
      "        [ 21.7365,  16.2282,  17.5984, -19.4478,  20.9622, -16.4343],\n",
      "        [ 21.9429,  16.3847,  17.6794, -19.7787,  21.1908, -15.9389],\n",
      "        [ 21.1073,  16.0547,  17.2307, -20.0422,  21.4364, -16.6137],\n",
      "        [ 21.6294,  16.2875,  17.2410, -19.4550,  21.2459, -16.1052]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.616265058517456\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6533, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6804, 16.5725, 17.7870],\n",
      "        [20.9841, 15.1851, 16.3278],\n",
      "        [21.6593, 16.3876, 17.4731],\n",
      "        [21.7914, 16.3383, 17.4859],\n",
      "        [21.2700, 16.3693, 17.2528],\n",
      "        [21.9236, 16.0304, 17.0923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8218, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3600,  21.1132, -16.2859],\n",
      "        [-20.0670,  21.0332, -16.3399],\n",
      "        [-19.5160,  20.8536, -16.2571],\n",
      "        [-19.2115,  20.7011, -16.0082],\n",
      "        [-19.4856,  20.8453, -16.1386],\n",
      "        [-19.2987,  21.0190, -15.8536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6804,  16.5725,  17.7870, -20.3600,  21.1132, -16.2859],\n",
      "        [ 20.9841,  15.1851,  16.3278, -20.0670,  21.0332, -16.3399],\n",
      "        [ 21.6593,  16.3876,  17.4731, -19.5160,  20.8536, -16.2571],\n",
      "        [ 21.7914,  16.3383,  17.4859, -19.2115,  20.7011, -16.0082],\n",
      "        [ 21.2700,  16.3693,  17.2528, -19.4856,  20.8453, -16.1386],\n",
      "        [ 21.9236,  16.0304,  17.0923, -19.2987,  21.0190, -15.8536]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.650567054748535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9106, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6382, 16.4020, 17.3117],\n",
      "        [21.9916, 16.6624, 17.8238],\n",
      "        [20.8089, 16.0176, 17.2363],\n",
      "        [21.7521, 16.3020, 17.7797],\n",
      "        [21.4579, 15.9123, 17.2636],\n",
      "        [21.5217, 16.3943, 17.1613]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7402, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2048,  21.1166, -15.6420],\n",
      "        [-19.6208,  21.0571, -16.2543],\n",
      "        [-19.8261,  21.4440, -16.5947],\n",
      "        [-19.4304,  20.5419, -15.6806],\n",
      "        [-19.7889,  20.9318, -16.4325],\n",
      "        [-19.6288,  21.0000, -16.0314]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6382,  16.4020,  17.3117, -19.2048,  21.1166, -15.6420],\n",
      "        [ 21.9916,  16.6624,  17.8238, -19.6208,  21.0571, -16.2543],\n",
      "        [ 20.8089,  16.0176,  17.2363, -19.8261,  21.4440, -16.5947],\n",
      "        [ 21.7521,  16.3020,  17.7797, -19.4304,  20.5419, -15.6806],\n",
      "        [ 21.4579,  15.9123,  17.2636, -19.7889,  20.9318, -16.4325],\n",
      "        [ 21.5217,  16.3943,  17.1613, -19.6288,  21.0000, -16.0314]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5829012393951416\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2800, 15.9308, 16.7793],\n",
      "        [21.4191, 16.3023, 17.2742],\n",
      "        [20.9708, 16.1403, 17.2027],\n",
      "        [21.8190, 16.2899, 17.4297],\n",
      "        [21.3024, 16.2491, 17.2035],\n",
      "        [21.0610, 16.1362, 17.0292]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.9616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.1881,  20.6966, -15.8294],\n",
      "        [-19.5530,  20.8670, -16.0469],\n",
      "        [-19.8287,  21.1883, -16.1628],\n",
      "        [-19.8894,  21.3353, -16.4179],\n",
      "        [-19.6830,  21.2881, -16.5692],\n",
      "        [-19.5444,  21.2041, -16.2054]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2800,  15.9308,  16.7793, -19.1881,  20.6966, -15.8294],\n",
      "        [ 21.4191,  16.3023,  17.2742, -19.5530,  20.8670, -16.0469],\n",
      "        [ 20.9708,  16.1403,  17.2027, -19.8287,  21.1883, -16.1628],\n",
      "        [ 21.8190,  16.2899,  17.4297, -19.8894,  21.3353, -16.4179],\n",
      "        [ 21.3024,  16.2491,  17.2035, -19.6830,  21.2881, -16.5692],\n",
      "        [ 21.0610,  16.1362,  17.0292, -19.5444,  21.2041, -16.2054]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.5255632400512695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5357, 16.1661, 17.1192],\n",
      "        [21.0432, 15.7903, 17.0662],\n",
      "        [21.6956, 16.4063, 17.5386],\n",
      "        [21.1571, 16.1412, 16.9763],\n",
      "        [21.7525, 16.4918, 17.5690],\n",
      "        [21.8427, 16.4684, 17.4259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9562,  21.3345, -15.9739],\n",
      "        [-19.9167,  21.3958, -16.4934],\n",
      "        [-20.0378,  21.5016, -16.7491],\n",
      "        [-19.8923,  21.2966, -16.1868],\n",
      "        [-19.3783,  21.0931, -16.0027],\n",
      "        [-20.0173,  21.1172, -16.5032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5357,  16.1661,  17.1192, -19.9562,  21.3345, -15.9739],\n",
      "        [ 21.0432,  15.7903,  17.0662, -19.9167,  21.3958, -16.4934],\n",
      "        [ 21.6956,  16.4063,  17.5386, -20.0378,  21.5016, -16.7491],\n",
      "        [ 21.1571,  16.1412,  16.9763, -19.8923,  21.2966, -16.1868],\n",
      "        [ 21.7525,  16.4918,  17.5690, -19.3783,  21.0931, -16.0027],\n",
      "        [ 21.8427,  16.4684,  17.4259, -20.0173,  21.1172, -16.5032]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.600827693939209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5942, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2782, 16.0419, 16.8119],\n",
      "        [21.8745, 16.1260, 17.4518],\n",
      "        [21.1283, 15.9480, 17.1279],\n",
      "        [21.2760, 15.6804, 17.5840],\n",
      "        [21.5860, 16.2391, 17.1292],\n",
      "        [21.5166, 16.1326, 17.3141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.8767, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.3890,  20.5478, -15.6962],\n",
      "        [-19.8160,  21.2166, -16.1778],\n",
      "        [-19.2958,  20.6677, -16.1082],\n",
      "        [-20.0747,  21.0880, -16.5807],\n",
      "        [-20.3180,  21.1686, -16.5801],\n",
      "        [-20.0216,  21.1429, -16.3915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2782,  16.0419,  16.8119, -19.3890,  20.5478, -15.6962],\n",
      "        [ 21.8745,  16.1260,  17.4518, -19.8160,  21.2166, -16.1778],\n",
      "        [ 21.1283,  15.9480,  17.1279, -19.2958,  20.6677, -16.1082],\n",
      "        [ 21.2760,  15.6804,  17.5840, -20.0747,  21.0880, -16.5807],\n",
      "        [ 21.5860,  16.2391,  17.1292, -20.3180,  21.1686, -16.5801],\n",
      "        [ 21.5166,  16.1326,  17.3141, -20.0216,  21.1429, -16.3915]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.530975341796875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8297, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2789, 16.3004, 17.4007],\n",
      "        [21.6662, 16.0963, 17.2534],\n",
      "        [21.1044, 16.1830, 17.2706],\n",
      "        [21.3335, 16.0445, 16.8151],\n",
      "        [21.5092, 15.9375, 16.8377],\n",
      "        [21.5078, 16.0578, 17.2763]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9686, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8677,  21.4249, -16.1035],\n",
      "        [-19.0730,  21.0976, -16.3104],\n",
      "        [-19.7997,  21.0075, -16.1096],\n",
      "        [-19.5713,  21.3401, -16.1948],\n",
      "        [-20.1293,  21.0767, -16.5218],\n",
      "        [-19.7610,  20.8686, -16.5164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2789,  16.3004,  17.4007, -19.8677,  21.4249, -16.1035],\n",
      "        [ 21.6662,  16.0963,  17.2534, -19.0730,  21.0976, -16.3104],\n",
      "        [ 21.1044,  16.1830,  17.2706, -19.7997,  21.0075, -16.1096],\n",
      "        [ 21.3335,  16.0445,  16.8151, -19.5713,  21.3401, -16.1948],\n",
      "        [ 21.5092,  15.9375,  16.8377, -20.1293,  21.0767, -16.5218],\n",
      "        [ 21.5078,  16.0578,  17.2763, -19.7610,  20.8686, -16.5164]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6090681552886963\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3394, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3181, 16.2794, 17.5262],\n",
      "        [21.1726, 15.9161, 17.3802],\n",
      "        [21.6249, 16.6302, 17.1481],\n",
      "        [21.7246, 16.4895, 17.7232],\n",
      "        [21.6005, 16.1731, 17.4845],\n",
      "        [22.0938, 16.3845, 17.4641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7355,  21.3297, -16.6187],\n",
      "        [-19.3505,  20.6369, -16.0290],\n",
      "        [-20.1346,  21.2380, -16.2977],\n",
      "        [-20.2122,  21.5535, -16.7234],\n",
      "        [-19.9629,  20.8993, -16.4717],\n",
      "        [-19.8318,  20.8726, -16.1306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3181,  16.2794,  17.5262, -19.7355,  21.3297, -16.6187],\n",
      "        [ 21.1726,  15.9161,  17.3802, -19.3505,  20.6369, -16.0290],\n",
      "        [ 21.6249,  16.6302,  17.1481, -20.1346,  21.2380, -16.2977],\n",
      "        [ 21.7246,  16.4895,  17.7232, -20.2122,  21.5535, -16.7234],\n",
      "        [ 21.6005,  16.1731,  17.4845, -19.9629,  20.8993, -16.4717],\n",
      "        [ 22.0938,  16.3845,  17.4641, -19.8318,  20.8726, -16.1306]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.6209604740142822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7524, 16.2620, 17.7782],\n",
      "        [21.5445, 16.2285, 17.5612],\n",
      "        [21.7134, 16.5457, 17.2067],\n",
      "        [21.9914, 16.4568, 17.4130],\n",
      "        [21.1923, 16.4998, 17.1378],\n",
      "        [21.8348, 16.8111, 17.7509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8539, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7064,  20.3513, -15.7483],\n",
      "        [-19.8633,  21.4025, -16.3409],\n",
      "        [-19.8705,  21.0602, -16.6473],\n",
      "        [-19.4632,  21.1882, -16.5101],\n",
      "        [-19.6913,  21.5038, -16.2525],\n",
      "        [-19.7621,  21.4918, -16.0873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7524,  16.2620,  17.7782, -19.7064,  20.3513, -15.7483],\n",
      "        [ 21.5445,  16.2285,  17.5612, -19.8633,  21.4025, -16.3409],\n",
      "        [ 21.7134,  16.5457,  17.2067, -19.8705,  21.0602, -16.6473],\n",
      "        [ 21.9914,  16.4568,  17.4130, -19.4632,  21.1882, -16.5101],\n",
      "        [ 21.1923,  16.4998,  17.1378, -19.6913,  21.5038, -16.2525],\n",
      "        [ 21.8348,  16.8111,  17.7509, -19.7621,  21.4918, -16.0873]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6044373512268066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5746, 16.3579, 17.4006],\n",
      "        [21.4057, 15.7768, 17.0181],\n",
      "        [21.8572, 16.3000, 17.3804],\n",
      "        [21.5968, 16.4425, 17.1342],\n",
      "        [21.5790, 16.0916, 17.5160],\n",
      "        [21.5655, 16.0811, 17.3388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.2207,  20.9379, -16.0311],\n",
      "        [-19.5456,  21.2025, -16.5101],\n",
      "        [-19.8801,  20.8879, -15.9005],\n",
      "        [-19.7447,  21.3813, -16.1947],\n",
      "        [-19.8196,  21.0048, -16.2960],\n",
      "        [-19.8571,  21.8097, -16.3903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5746,  16.3579,  17.4006, -19.2207,  20.9379, -16.0311],\n",
      "        [ 21.4057,  15.7768,  17.0181, -19.5456,  21.2025, -16.5101],\n",
      "        [ 21.8572,  16.3000,  17.3804, -19.8801,  20.8879, -15.9005],\n",
      "        [ 21.5968,  16.4425,  17.1342, -19.7447,  21.3813, -16.1947],\n",
      "        [ 21.5790,  16.0916,  17.5160, -19.8196,  21.0048, -16.2960],\n",
      "        [ 21.5655,  16.0811,  17.3388, -19.8571,  21.8097, -16.3903]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.595686197280884\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4929, 15.7748, 17.6715],\n",
      "        [21.0869, 15.4914, 16.9468],\n",
      "        [21.0741, 16.0231, 17.2812],\n",
      "        [21.6940, 16.3799, 17.6583],\n",
      "        [21.8563, 16.3463, 17.7647],\n",
      "        [21.8628, 16.2557, 17.6652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.4914, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0536,  21.1303, -16.3353],\n",
      "        [-19.8699,  21.4271, -16.5288],\n",
      "        [-19.5760,  21.1882, -16.3565],\n",
      "        [-19.7896,  20.9930, -16.1058],\n",
      "        [-19.8755,  21.1247, -16.5661],\n",
      "        [-19.5836,  21.0621, -16.0740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4929,  15.7748,  17.6715, -20.0536,  21.1303, -16.3353],\n",
      "        [ 21.0869,  15.4914,  16.9468, -19.8699,  21.4271, -16.5288],\n",
      "        [ 21.0741,  16.0231,  17.2812, -19.5760,  21.1882, -16.3565],\n",
      "        [ 21.6940,  16.3799,  17.6583, -19.7896,  20.9930, -16.1058],\n",
      "        [ 21.8563,  16.3463,  17.7647, -19.8755,  21.1247, -16.5661],\n",
      "        [ 21.8628,  16.2557,  17.6652, -19.5836,  21.0621, -16.0740]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.622251510620117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7291, 16.1518, 17.6632],\n",
      "        [21.7385, 16.6097, 17.7196],\n",
      "        [21.3826, 16.1860, 17.1276],\n",
      "        [21.6233, 16.1960, 17.4747],\n",
      "        [20.8748, 16.0781, 17.3549],\n",
      "        [21.6994, 16.2159, 17.2863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.3456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.4441,  21.1395, -16.2286],\n",
      "        [-19.7018,  21.2610, -16.3166],\n",
      "        [-19.7193,  20.9556, -16.4369],\n",
      "        [-19.5853,  20.8891, -15.8960],\n",
      "        [-20.1712,  21.7157, -16.4546],\n",
      "        [-20.0673,  21.2238, -16.2675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7291,  16.1518,  17.6632, -19.4441,  21.1395, -16.2286],\n",
      "        [ 21.7385,  16.6097,  17.7196, -19.7018,  21.2610, -16.3166],\n",
      "        [ 21.3826,  16.1860,  17.1276, -19.7193,  20.9556, -16.4369],\n",
      "        [ 21.6233,  16.1960,  17.4747, -19.5853,  20.8891, -15.8960],\n",
      "        [ 20.8748,  16.0781,  17.3549, -20.1712,  21.7157, -16.4546],\n",
      "        [ 21.6994,  16.2159,  17.2863, -20.0673,  21.2238, -16.2675]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6263859272003174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6431, 16.6473, 17.1525],\n",
      "        [22.1106, 16.5399, 17.5975],\n",
      "        [21.8391, 16.6073, 17.4877],\n",
      "        [21.3676, 16.2986, 17.5302],\n",
      "        [21.9177, 15.9525, 17.3176],\n",
      "        [21.7866, 16.4444, 17.4762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6290, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.6736,  21.2906, -16.2806],\n",
      "        [-19.8203,  21.1759, -16.5138],\n",
      "        [-19.5758,  21.0636, -16.2812],\n",
      "        [-19.9450,  20.8934, -15.9934],\n",
      "        [-19.9679,  20.9949, -16.4776],\n",
      "        [-19.6642,  20.8348, -16.2690]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6431,  16.6473,  17.1525, -19.6736,  21.2906, -16.2806],\n",
      "        [ 22.1106,  16.5399,  17.5975, -19.8203,  21.1759, -16.5138],\n",
      "        [ 21.8391,  16.6073,  17.4877, -19.5758,  21.0636, -16.2812],\n",
      "        [ 21.3676,  16.2986,  17.5302, -19.9450,  20.8934, -15.9934],\n",
      "        [ 21.9177,  15.9525,  17.3176, -19.9679,  20.9949, -16.4776],\n",
      "        [ 21.7866,  16.4444,  17.4762, -19.6642,  20.8348, -16.2690]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.6296274662017822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7822, 16.3653, 17.3792],\n",
      "        [21.4765, 16.4285, 17.4291],\n",
      "        [21.4938, 16.0835, 17.5703],\n",
      "        [21.4720, 16.1509, 17.5285],\n",
      "        [21.5411, 16.1525, 17.2860],\n",
      "        [22.0535, 16.3997, 17.1683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.4652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9407,  21.0535, -16.6496],\n",
      "        [-20.3105,  21.3739, -16.7399],\n",
      "        [-19.4970,  21.2490, -16.2201],\n",
      "        [-20.0336,  21.2706, -16.4815],\n",
      "        [-19.1095,  20.8695, -16.0817],\n",
      "        [-20.0232,  21.3514, -16.0051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7822,  16.3653,  17.3792, -19.9407,  21.0535, -16.6496],\n",
      "        [ 21.4765,  16.4285,  17.4291, -20.3105,  21.3739, -16.7399],\n",
      "        [ 21.4938,  16.0835,  17.5703, -19.4970,  21.2490, -16.2201],\n",
      "        [ 21.4720,  16.1509,  17.5285, -20.0336,  21.2706, -16.4815],\n",
      "        [ 21.5411,  16.1525,  17.2860, -19.1095,  20.8695, -16.0817],\n",
      "        [ 22.0535,  16.3997,  17.1683, -20.0232,  21.3514, -16.0051]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:-3.6465952396392822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6171, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5578, 16.2414, 17.2381],\n",
      "        [21.4583, 16.1100, 16.8497],\n",
      "        [21.7914, 16.5056, 17.8176],\n",
      "        [21.3800, 16.0534, 17.1964],\n",
      "        [21.7753, 16.0525, 17.4720],\n",
      "        [21.4731, 16.5484, 17.1371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1271, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9799,  21.2507, -16.1820],\n",
      "        [-19.7652,  20.9526, -16.4307],\n",
      "        [-19.5823,  21.0657, -16.2334],\n",
      "        [-19.9638,  21.4216, -16.6649],\n",
      "        [-19.5537,  20.8978, -16.0448],\n",
      "        [-19.7529,  21.1924, -16.3889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5578,  16.2414,  17.2381, -19.9799,  21.2507, -16.1820],\n",
      "        [ 21.4583,  16.1100,  16.8497, -19.7652,  20.9526, -16.4307],\n",
      "        [ 21.7914,  16.5056,  17.8176, -19.5823,  21.0657, -16.2334],\n",
      "        [ 21.3800,  16.0534,  17.1964, -19.9638,  21.4216, -16.6649],\n",
      "        [ 21.7753,  16.0525,  17.4720, -19.5537,  20.8978, -16.0448],\n",
      "        [ 21.4731,  16.5484,  17.1371, -19.7529,  21.1924, -16.3889]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.625810146331787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.9027, 16.0191, 16.8225],\n",
      "        [21.4160, 16.1549, 17.2285],\n",
      "        [21.3653, 15.9537, 17.2311],\n",
      "        [22.2849, 16.6256, 17.8366],\n",
      "        [21.4157, 16.3357, 17.4530],\n",
      "        [21.9212, 16.5478, 17.6418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1477,  21.6865, -16.5523],\n",
      "        [-20.1930,  21.4369, -16.5938],\n",
      "        [-19.4625,  21.2656, -16.6763],\n",
      "        [-20.0524,  21.3850, -16.2668],\n",
      "        [-19.6377,  21.0929, -16.2273],\n",
      "        [-19.8837,  21.1623, -16.6136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.9027,  16.0191,  16.8225, -20.1477,  21.6865, -16.5523],\n",
      "        [ 21.4160,  16.1549,  17.2285, -20.1930,  21.4369, -16.5938],\n",
      "        [ 21.3653,  15.9537,  17.2311, -19.4625,  21.2656, -16.6763],\n",
      "        [ 22.2849,  16.6256,  17.8366, -20.0524,  21.3850, -16.2668],\n",
      "        [ 21.4157,  16.3357,  17.4530, -19.6377,  21.0929, -16.2273],\n",
      "        [ 21.9212,  16.5478,  17.6418, -19.8837,  21.1623, -16.6136]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.59953236579895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.2278, 16.1494, 17.1629],\n",
      "        [21.4912, 16.4303, 17.3319],\n",
      "        [20.7932, 15.9410, 17.0327],\n",
      "        [21.4318, 16.1166, 17.4351],\n",
      "        [21.5192, 16.2130, 17.1409],\n",
      "        [21.3203, 15.9328, 17.9631]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4273, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2120,  21.5568, -16.5498],\n",
      "        [-19.9711,  21.5552, -16.6468],\n",
      "        [-19.5729,  21.4518, -16.4800],\n",
      "        [-19.8313,  21.3920, -16.0138],\n",
      "        [-20.1385,  21.3750, -16.7309],\n",
      "        [-19.8645,  21.4116, -16.7241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.2278,  16.1494,  17.1629, -20.2120,  21.5568, -16.5498],\n",
      "        [ 21.4912,  16.4303,  17.3319, -19.9711,  21.5552, -16.6468],\n",
      "        [ 20.7932,  15.9410,  17.0327, -19.5729,  21.4518, -16.4800],\n",
      "        [ 21.4318,  16.1166,  17.4351, -19.8313,  21.3920, -16.0138],\n",
      "        [ 21.5192,  16.2130,  17.1409, -20.1385,  21.3750, -16.7309],\n",
      "        [ 21.3203,  15.9328,  17.9631, -19.8645,  21.4116, -16.7241]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:0, loss:-3.630826950073242\n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1130, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4173, 16.0324, 17.1749],\n",
      "        [21.5436, 16.1130, 17.3675],\n",
      "        [22.1160, 16.6459, 17.7496],\n",
      "        [21.2241, 16.4689, 17.6244],\n",
      "        [21.7608, 16.9388, 17.5300],\n",
      "        [21.6876, 16.3864, 17.3750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.1098, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9348,  21.6878, -16.7358],\n",
      "        [-20.1009,  21.6346, -16.4622],\n",
      "        [-20.3300,  21.5974, -16.8630],\n",
      "        [-19.4327,  21.1193, -15.9781],\n",
      "        [-20.0576,  21.5175, -16.6934],\n",
      "        [-20.1260,  21.3109, -16.2886]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4173,  16.0324,  17.1749, -19.9348,  21.6878, -16.7358],\n",
      "        [ 21.5436,  16.1130,  17.3675, -20.1009,  21.6346, -16.4622],\n",
      "        [ 22.1160,  16.6459,  17.7496, -20.3300,  21.5974, -16.8630],\n",
      "        [ 21.2241,  16.4689,  17.6244, -19.4327,  21.1193, -15.9781],\n",
      "        [ 21.7608,  16.9388,  17.5300, -20.0576,  21.5175, -16.6934],\n",
      "        [ 21.6876,  16.3864,  17.3750, -20.1260,  21.3109, -16.2886]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6387062072753906\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3034, 16.3718, 17.6699],\n",
      "        [21.9681, 16.7047, 17.9255],\n",
      "        [21.1998, 16.2914, 16.8223],\n",
      "        [21.8936, 16.0278, 17.5059],\n",
      "        [21.9911, 16.4855, 17.8368],\n",
      "        [21.1290, 16.2725, 17.0299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.1682, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0970,  21.6642, -16.6772],\n",
      "        [-19.7260,  20.8175, -16.1883],\n",
      "        [-19.9841,  21.4609, -16.7869],\n",
      "        [-19.8613,  21.3514, -16.4949],\n",
      "        [-20.2108,  21.3045, -16.6519],\n",
      "        [-19.6230,  20.6694, -15.9444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3034,  16.3718,  17.6699, -20.0970,  21.6642, -16.6772],\n",
      "        [ 21.9681,  16.7047,  17.9255, -19.7260,  20.8175, -16.1883],\n",
      "        [ 21.1998,  16.2914,  16.8223, -19.9841,  21.4609, -16.7869],\n",
      "        [ 21.8936,  16.0278,  17.5059, -19.8613,  21.3514, -16.4949],\n",
      "        [ 21.9911,  16.4855,  17.8368, -20.2108,  21.3045, -16.6519],\n",
      "        [ 21.1290,  16.2725,  17.0299, -19.6230,  20.6694, -15.9444]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6656064987182617\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6097, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6614, 16.0619, 17.2395],\n",
      "        [21.3345, 15.5782, 17.3830],\n",
      "        [21.7040, 16.4688, 17.5189],\n",
      "        [21.7117, 16.1826, 17.2501],\n",
      "        [21.8460, 16.1939, 17.7586],\n",
      "        [21.6710, 16.1860, 17.0023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.3615, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0347,  21.4851, -16.7524],\n",
      "        [-20.3816,  21.9306, -16.8198],\n",
      "        [-20.2858,  21.6485, -16.6857],\n",
      "        [-19.9168,  21.2501, -16.6999],\n",
      "        [-19.9542,  21.0933, -16.6125],\n",
      "        [-19.7257,  21.2413, -16.0871]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6614,  16.0619,  17.2395, -20.0347,  21.4851, -16.7524],\n",
      "        [ 21.3345,  15.5782,  17.3830, -20.3816,  21.9306, -16.8198],\n",
      "        [ 21.7040,  16.4688,  17.5189, -20.2858,  21.6485, -16.6857],\n",
      "        [ 21.7117,  16.1826,  17.2501, -19.9168,  21.2501, -16.6999],\n",
      "        [ 21.8460,  16.1939,  17.7586, -19.9542,  21.0933, -16.6125],\n",
      "        [ 21.6710,  16.1860,  17.0023, -19.7257,  21.2413, -16.0871]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.6536009311676025\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5856, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5682, 16.5071, 17.2744],\n",
      "        [21.6116, 16.4594, 17.5756],\n",
      "        [21.7194, 16.5364, 16.9638],\n",
      "        [21.9738, 16.5871, 17.8582],\n",
      "        [21.4053, 16.6165, 17.5030],\n",
      "        [21.7252, 16.5132, 17.4893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.5189, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9107,  21.6378, -16.5507],\n",
      "        [-20.1238,  21.3274, -16.5558],\n",
      "        [-20.0626,  21.4031, -16.2631],\n",
      "        [-19.7426,  20.6329, -15.8756],\n",
      "        [-20.2352,  20.9023, -16.5126],\n",
      "        [-19.6910,  20.8037, -16.2109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5682,  16.5071,  17.2744, -19.9107,  21.6378, -16.5507],\n",
      "        [ 21.6116,  16.4594,  17.5756, -20.1238,  21.3274, -16.5558],\n",
      "        [ 21.7194,  16.5364,  16.9638, -20.0626,  21.4031, -16.2631],\n",
      "        [ 21.9738,  16.5871,  17.8582, -19.7426,  20.6329, -15.8756],\n",
      "        [ 21.4053,  16.6165,  17.5030, -20.2352,  20.9023, -16.5126],\n",
      "        [ 21.7252,  16.5132,  17.4893, -19.6910,  20.8037, -16.2109]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6611666679382324\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7238, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6864, 16.2249, 17.4693],\n",
      "        [21.3713, 16.6982, 17.4205],\n",
      "        [21.6788, 16.0399, 17.0016],\n",
      "        [21.6499, 16.2578, 17.5122],\n",
      "        [21.5101, 15.9896, 17.3758],\n",
      "        [21.2102, 15.9957, 17.3208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7648, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7711,  20.8278, -16.1736],\n",
      "        [-20.2577,  21.0660, -16.2099],\n",
      "        [-19.9319,  21.3108, -16.3789],\n",
      "        [-19.8314,  21.3019, -16.4709],\n",
      "        [-19.7230,  21.2515, -16.6465],\n",
      "        [-19.8584,  21.2720, -16.6117]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6864,  16.2249,  17.4693, -19.7711,  20.8278, -16.1736],\n",
      "        [ 21.3713,  16.6982,  17.4205, -20.2577,  21.0660, -16.2099],\n",
      "        [ 21.6788,  16.0399,  17.0016, -19.9319,  21.3108, -16.3789],\n",
      "        [ 21.6499,  16.2578,  17.5122, -19.8314,  21.3019, -16.4709],\n",
      "        [ 21.5101,  15.9896,  17.3758, -19.7230,  21.2515, -16.6465],\n",
      "        [ 21.2102,  15.9957,  17.3208, -19.8584,  21.2720, -16.6117]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6323535442352295\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9399, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8171, 16.2971, 17.3544],\n",
      "        [21.9482, 16.5815, 17.5544],\n",
      "        [21.1270, 16.0355, 16.9585],\n",
      "        [21.9309, 16.6722, 17.7649],\n",
      "        [21.7886, 16.2439, 17.4924],\n",
      "        [21.2948, 15.9600, 17.5393]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0761,  21.2544, -16.3551],\n",
      "        [-20.2288,  21.9123, -16.8359],\n",
      "        [-19.8243,  21.4732, -16.6271],\n",
      "        [-19.9288,  21.4867, -16.3242],\n",
      "        [-19.8214,  21.3705, -16.3387],\n",
      "        [-20.2480,  21.5105, -16.3844]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8171,  16.2971,  17.3544, -20.0761,  21.2544, -16.3551],\n",
      "        [ 21.9482,  16.5815,  17.5544, -20.2288,  21.9123, -16.8359],\n",
      "        [ 21.1270,  16.0355,  16.9585, -19.8243,  21.4732, -16.6271],\n",
      "        [ 21.9309,  16.6722,  17.7649, -19.9288,  21.4867, -16.3242],\n",
      "        [ 21.7886,  16.2439,  17.4924, -19.8214,  21.3705, -16.3387],\n",
      "        [ 21.2948,  15.9600,  17.5393, -20.2480,  21.5105, -16.3844]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6623013019561768\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7352, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9504, 16.5967, 17.8784],\n",
      "        [21.4587, 15.9281, 17.2111],\n",
      "        [21.7971, 16.1051, 17.7050],\n",
      "        [21.3118, 16.5589, 17.4791],\n",
      "        [21.8188, 16.2234, 17.5143],\n",
      "        [21.5910, 16.5815, 17.3879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.7184, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1514,  21.0930, -16.6727],\n",
      "        [-20.0575,  21.1668, -16.6244],\n",
      "        [-19.9054,  21.3729, -16.5975],\n",
      "        [-20.4904,  21.8095, -16.8631],\n",
      "        [-19.6770,  21.0969, -16.2150],\n",
      "        [-20.3845,  21.4574, -16.9205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9504,  16.5967,  17.8784, -20.1514,  21.0930, -16.6727],\n",
      "        [ 21.4587,  15.9281,  17.2111, -20.0575,  21.1668, -16.6244],\n",
      "        [ 21.7971,  16.1051,  17.7050, -19.9054,  21.3729, -16.5975],\n",
      "        [ 21.3118,  16.5589,  17.4791, -20.4904,  21.8095, -16.8631],\n",
      "        [ 21.8188,  16.2234,  17.5143, -19.6770,  21.0969, -16.2150],\n",
      "        [ 21.5910,  16.5815,  17.3879, -20.3845,  21.4574, -16.9205]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7024154663085938\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7889, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7827, 16.4373, 17.9608],\n",
      "        [21.8987, 16.6129, 17.6955],\n",
      "        [21.5261, 16.1967, 17.2785],\n",
      "        [21.7916, 16.7032, 17.4553],\n",
      "        [21.8136, 16.0596, 17.3750],\n",
      "        [21.9706, 16.4469, 17.9679]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8891,  21.6503, -16.2365],\n",
      "        [-20.0499,  21.6549, -16.7227],\n",
      "        [-19.5139,  21.1144, -16.3711],\n",
      "        [-19.5316,  21.1878, -16.2693],\n",
      "        [-20.0880,  21.5356, -16.5934],\n",
      "        [-20.2601,  21.4456, -16.9566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7827,  16.4373,  17.9608, -19.8891,  21.6503, -16.2365],\n",
      "        [ 21.8987,  16.6129,  17.6955, -20.0499,  21.6549, -16.7227],\n",
      "        [ 21.5261,  16.1967,  17.2785, -19.5139,  21.1144, -16.3711],\n",
      "        [ 21.7916,  16.7032,  17.4553, -19.5316,  21.1878, -16.2693],\n",
      "        [ 21.8136,  16.0596,  17.3750, -20.0880,  21.5356, -16.5934],\n",
      "        [ 21.9706,  16.4469,  17.9679, -20.2601,  21.4456, -16.9566]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6948843002319336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6646, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3672, 16.0408, 17.1462],\n",
      "        [21.3772, 16.0722, 17.1018],\n",
      "        [21.4997, 16.2423, 17.8434],\n",
      "        [21.5284, 16.3747, 17.3928],\n",
      "        [21.6521, 16.0086, 17.2757],\n",
      "        [21.8570, 16.7715, 17.3649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.2922, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7280,  21.5530, -16.6775],\n",
      "        [-20.0525,  21.7769, -16.7082],\n",
      "        [-20.2610,  21.3735, -16.8366],\n",
      "        [-20.0315,  20.9389, -16.5114],\n",
      "        [-20.5210,  21.9998, -16.8417],\n",
      "        [-19.7195,  21.1207, -16.5220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3672,  16.0408,  17.1462, -20.7280,  21.5530, -16.6775],\n",
      "        [ 21.3772,  16.0722,  17.1018, -20.0525,  21.7769, -16.7082],\n",
      "        [ 21.4997,  16.2423,  17.8434, -20.2610,  21.3735, -16.8366],\n",
      "        [ 21.5284,  16.3747,  17.3928, -20.0315,  20.9389, -16.5114],\n",
      "        [ 21.6521,  16.0086,  17.2757, -20.5210,  21.9998, -16.8417],\n",
      "        [ 21.8570,  16.7715,  17.3649, -19.7195,  21.1207, -16.5220]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.6638739109039307\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6372, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5886, 16.1255, 16.9930],\n",
      "        [21.9733, 16.4421, 17.6535],\n",
      "        [21.5854, 16.2035, 17.7454],\n",
      "        [21.8109, 16.5514, 17.7753],\n",
      "        [21.6459, 16.5533, 17.3831],\n",
      "        [21.6436, 16.2949, 17.5807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9142, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1554,  21.5647, -16.9849],\n",
      "        [-20.0277,  21.1067, -16.1491],\n",
      "        [-19.7219,  21.4836, -15.9653],\n",
      "        [-19.6106,  21.2636, -16.8690],\n",
      "        [-19.9881,  21.2340, -16.0851],\n",
      "        [-19.8044,  21.4360, -16.3743]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5886,  16.1255,  16.9930, -20.1554,  21.5647, -16.9849],\n",
      "        [ 21.9733,  16.4421,  17.6535, -20.0277,  21.1067, -16.1491],\n",
      "        [ 21.5854,  16.2035,  17.7454, -19.7219,  21.4836, -15.9653],\n",
      "        [ 21.8109,  16.5514,  17.7753, -19.6106,  21.2636, -16.8690],\n",
      "        [ 21.6459,  16.5533,  17.3831, -19.9881,  21.2340, -16.0851],\n",
      "        [ 21.6436,  16.2949,  17.5807, -19.8044,  21.4360, -16.3743]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.663477897644043\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6574, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6593, 16.3890, 17.9756],\n",
      "        [21.8236, 16.5307, 17.5908],\n",
      "        [22.1017, 16.6502, 17.6231],\n",
      "        [21.7880, 16.7056, 17.5746],\n",
      "        [21.8845, 16.4859, 17.6922],\n",
      "        [22.1206, 16.3380, 17.4623]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9136, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7595,  21.3021, -16.1069],\n",
      "        [-19.4766,  20.9416, -16.0690],\n",
      "        [-20.4496,  21.8262, -16.8533],\n",
      "        [-20.0183,  21.4556, -16.5792],\n",
      "        [-20.2724,  21.3872, -16.5115],\n",
      "        [-19.9086,  21.0525, -16.0859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6593,  16.3890,  17.9756, -19.7595,  21.3021, -16.1069],\n",
      "        [ 21.8236,  16.5307,  17.5908, -19.4766,  20.9416, -16.0690],\n",
      "        [ 22.1017,  16.6502,  17.6231, -20.4496,  21.8262, -16.8533],\n",
      "        [ 21.7880,  16.7056,  17.5746, -20.0183,  21.4556, -16.5792],\n",
      "        [ 21.8845,  16.4859,  17.6922, -20.2724,  21.3872, -16.5115],\n",
      "        [ 22.1206,  16.3380,  17.4623, -19.9086,  21.0525, -16.0859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.67624568939209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3949, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3556, 16.7865, 18.1014],\n",
      "        [21.9651, 16.5538, 17.8009],\n",
      "        [22.0941, 16.8801, 17.6329],\n",
      "        [22.0320, 16.6728, 17.5920],\n",
      "        [22.3712, 16.8637, 18.0402],\n",
      "        [21.5132, 16.8027, 17.4587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9011,  21.4491, -16.4318],\n",
      "        [-20.1641,  21.3178, -16.4290],\n",
      "        [-19.8808,  21.5394, -16.8163],\n",
      "        [-19.9968,  21.5956, -16.5699],\n",
      "        [-20.0638,  21.2777, -16.8129],\n",
      "        [-20.0266,  21.4208, -16.6275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3556,  16.7865,  18.1014, -19.9011,  21.4491, -16.4318],\n",
      "        [ 21.9651,  16.5538,  17.8009, -20.1641,  21.3178, -16.4290],\n",
      "        [ 22.0941,  16.8801,  17.6329, -19.8808,  21.5394, -16.8163],\n",
      "        [ 22.0320,  16.6728,  17.5920, -19.9968,  21.5956, -16.5699],\n",
      "        [ 22.3712,  16.8637,  18.0402, -20.0638,  21.2777, -16.8129],\n",
      "        [ 21.5132,  16.8027,  17.4587, -20.0266,  21.4208, -16.6275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7415590286254883\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1770, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6827, 16.3113, 17.7299],\n",
      "        [22.4779, 16.9157, 18.1431],\n",
      "        [22.1135, 16.4255, 17.9398],\n",
      "        [21.3200, 16.5365, 17.0913],\n",
      "        [22.4164, 16.7541, 17.7773],\n",
      "        [22.0832, 16.3927, 17.4529]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2549,  21.6958, -16.9975],\n",
      "        [-20.2310,  21.2356, -16.0323],\n",
      "        [-20.0204,  21.2230, -16.5615],\n",
      "        [-20.4022,  21.3397, -16.7639],\n",
      "        [-20.1358,  21.4478, -16.5499],\n",
      "        [-20.3932,  22.0234, -16.8733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6827,  16.3113,  17.7299, -20.2549,  21.6958, -16.9975],\n",
      "        [ 22.4779,  16.9157,  18.1431, -20.2310,  21.2356, -16.0323],\n",
      "        [ 22.1135,  16.4255,  17.9398, -20.0204,  21.2230, -16.5615],\n",
      "        [ 21.3200,  16.5365,  17.0913, -20.4022,  21.3397, -16.7639],\n",
      "        [ 22.4164,  16.7541,  17.7773, -20.1358,  21.4478, -16.5499],\n",
      "        [ 22.0832,  16.3927,  17.4529, -20.3932,  22.0234, -16.8733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.712754726409912\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7708, 16.5269, 17.5687],\n",
      "        [21.8997, 16.1326, 17.8079],\n",
      "        [21.9244, 16.5558, 17.5076],\n",
      "        [21.4134, 16.0328, 17.3318],\n",
      "        [21.5112, 16.5976, 17.5576],\n",
      "        [22.2470, 16.7203, 18.0622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2173, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9919,  20.8234, -16.3312],\n",
      "        [-19.8867,  21.4604, -16.5782],\n",
      "        [-19.8144,  21.3110, -16.7724],\n",
      "        [-20.1447,  21.3543, -16.5275],\n",
      "        [-20.5844,  21.8192, -17.1216],\n",
      "        [-19.9741,  21.4258, -16.3046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7708,  16.5269,  17.5687, -19.9919,  20.8234, -16.3312],\n",
      "        [ 21.8997,  16.1326,  17.8079, -19.8867,  21.4604, -16.5782],\n",
      "        [ 21.9244,  16.5558,  17.5076, -19.8144,  21.3110, -16.7724],\n",
      "        [ 21.4134,  16.0328,  17.3318, -20.1447,  21.3543, -16.5275],\n",
      "        [ 21.5112,  16.5976,  17.5576, -20.5844,  21.8192, -17.1216],\n",
      "        [ 22.2470,  16.7203,  18.0622, -19.9741,  21.4258, -16.3046]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6711182594299316\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4379, 15.9974, 17.2617],\n",
      "        [21.9544, 16.5363, 17.5143],\n",
      "        [22.0936, 16.8565, 17.1458],\n",
      "        [21.7828, 16.6197, 17.6568],\n",
      "        [22.0880, 16.3114, 17.3223],\n",
      "        [22.2998, 16.8049, 17.7940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9343,  21.3254, -16.4911],\n",
      "        [-19.7803,  21.4208, -16.4603],\n",
      "        [-20.1836,  21.7066, -16.8273],\n",
      "        [-19.6904,  21.2602, -16.5443],\n",
      "        [-20.5910,  21.8555, -16.9678],\n",
      "        [-20.0680,  21.4568, -16.6960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4379,  15.9974,  17.2617, -19.9343,  21.3254, -16.4911],\n",
      "        [ 21.9544,  16.5363,  17.5143, -19.7803,  21.4208, -16.4603],\n",
      "        [ 22.0936,  16.8565,  17.1458, -20.1836,  21.7066, -16.8273],\n",
      "        [ 21.7828,  16.6197,  17.6568, -19.6904,  21.2602, -16.5443],\n",
      "        [ 22.0880,  16.3114,  17.3223, -20.5910,  21.8555, -16.9678],\n",
      "        [ 22.2998,  16.8049,  17.7940, -20.0680,  21.4568, -16.6960]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.6470632553100586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4466, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7174, 16.4843, 17.4529],\n",
      "        [21.5365, 16.3463, 17.2156],\n",
      "        [21.7649, 16.6685, 17.5014],\n",
      "        [21.2815, 16.0035, 16.9739],\n",
      "        [21.4102, 16.3252, 17.3956],\n",
      "        [21.5340, 16.5775, 17.6429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6323,  21.9911, -17.0343],\n",
      "        [-19.9164,  21.3351, -16.8989],\n",
      "        [-20.3796,  21.5277, -16.9240],\n",
      "        [-20.2082,  21.5331, -16.8496],\n",
      "        [-20.4029,  21.7086, -17.1701],\n",
      "        [-20.1077,  21.6441, -17.2081]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7174,  16.4843,  17.4529, -20.6323,  21.9911, -17.0343],\n",
      "        [ 21.5365,  16.3463,  17.2156, -19.9164,  21.3351, -16.8989],\n",
      "        [ 21.7649,  16.6685,  17.5014, -20.3796,  21.5277, -16.9240],\n",
      "        [ 21.2815,  16.0035,  16.9739, -20.2082,  21.5331, -16.8496],\n",
      "        [ 21.4102,  16.3252,  17.3956, -20.4029,  21.7086, -17.1701],\n",
      "        [ 21.5340,  16.5775,  17.6429, -20.1077,  21.6441, -17.2081]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7329483032226562\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6803, 16.2851, 17.3938],\n",
      "        [22.2959, 16.8255, 18.3168],\n",
      "        [22.1972, 16.7924, 18.1194],\n",
      "        [22.1035, 16.7302, 17.8996],\n",
      "        [21.8896, 16.5669, 17.5323],\n",
      "        [21.6497, 16.5757, 17.7000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2396,  21.5867, -16.5526],\n",
      "        [-20.5474,  21.7671, -17.2171],\n",
      "        [-20.1958,  21.5899, -16.6413],\n",
      "        [-20.5677,  21.4706, -16.8300],\n",
      "        [-19.7123,  21.3144, -16.2047],\n",
      "        [-19.7808,  21.2905, -16.2268]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6803,  16.2851,  17.3938, -20.2396,  21.5867, -16.5526],\n",
      "        [ 22.2959,  16.8255,  18.3168, -20.5474,  21.7671, -17.2171],\n",
      "        [ 22.1972,  16.7924,  18.1194, -20.1958,  21.5899, -16.6413],\n",
      "        [ 22.1035,  16.7302,  17.8996, -20.5677,  21.4706, -16.8300],\n",
      "        [ 21.8896,  16.5669,  17.5323, -19.7123,  21.3144, -16.2047],\n",
      "        [ 21.6497,  16.5757,  17.7000, -19.7808,  21.2905, -16.2268]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.691988706588745\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.6279, 16.6103, 17.4901],\n",
      "        [22.0325, 16.5500, 17.7863],\n",
      "        [21.3532, 16.2540, 17.6257],\n",
      "        [22.0663, 16.5965, 17.7376],\n",
      "        [21.7444, 16.7711, 17.3846],\n",
      "        [21.4889, 16.6239, 17.3571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.7810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2389,  21.5057, -16.8384],\n",
      "        [-20.2828,  21.4127, -16.9519],\n",
      "        [-20.0435,  21.4360, -16.8977],\n",
      "        [-20.3464,  21.6439, -16.7739],\n",
      "        [-20.5070,  21.5068, -17.0780],\n",
      "        [-19.9666,  21.2750, -16.4039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.6279,  16.6103,  17.4901, -20.2389,  21.5057, -16.8384],\n",
      "        [ 22.0325,  16.5500,  17.7863, -20.2828,  21.4127, -16.9519],\n",
      "        [ 21.3532,  16.2540,  17.6257, -20.0435,  21.4360, -16.8977],\n",
      "        [ 22.0663,  16.5965,  17.7376, -20.3464,  21.6439, -16.7739],\n",
      "        [ 21.7444,  16.7711,  17.3846, -20.5070,  21.5068, -17.0780],\n",
      "        [ 21.4889,  16.6239,  17.3571, -19.9666,  21.2750, -16.4039]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.707362174987793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3732, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9291, 16.2975, 17.7783],\n",
      "        [21.5008, 16.2681, 17.7190],\n",
      "        [21.6021, 16.4854, 17.8295],\n",
      "        [21.8459, 16.6080, 17.9078],\n",
      "        [21.9357, 16.5536, 17.9840],\n",
      "        [21.8903, 16.2619, 17.2216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1965, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2857,  21.7587, -16.9449],\n",
      "        [-19.7183,  21.3645, -16.6202],\n",
      "        [-20.6113,  22.1552, -17.0550],\n",
      "        [-19.6731,  21.0116, -16.3032],\n",
      "        [-19.8275,  21.0672, -16.3059],\n",
      "        [-20.2086,  21.1097, -16.9287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9291,  16.2975,  17.7783, -20.2857,  21.7587, -16.9449],\n",
      "        [ 21.5008,  16.2681,  17.7190, -19.7183,  21.3645, -16.6202],\n",
      "        [ 21.6021,  16.4854,  17.8295, -20.6113,  22.1552, -17.0550],\n",
      "        [ 21.8459,  16.6080,  17.9078, -19.6731,  21.0116, -16.3032],\n",
      "        [ 21.9357,  16.5536,  17.9840, -19.8275,  21.0672, -16.3059],\n",
      "        [ 21.8903,  16.2619,  17.2216, -20.2086,  21.1097, -16.9287]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.736619472503662\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2168, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2894, 16.4921, 17.5135],\n",
      "        [21.6023, 16.5053, 17.5273],\n",
      "        [22.0024, 16.7801, 17.8183],\n",
      "        [21.8440, 16.6057, 18.0243],\n",
      "        [21.4260, 16.2452, 17.4120],\n",
      "        [21.5943, 16.5688, 17.9118]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.5805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3316,  21.5010, -16.7033],\n",
      "        [-19.9179,  21.2915, -16.3288],\n",
      "        [-20.0650,  21.4823, -16.5999],\n",
      "        [-20.0199,  20.9239, -16.1423],\n",
      "        [-20.5945,  21.6991, -16.8156],\n",
      "        [-19.9585,  21.5305, -16.4898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2894,  16.4921,  17.5135, -20.3316,  21.5010, -16.7033],\n",
      "        [ 21.6023,  16.5053,  17.5273, -19.9179,  21.2915, -16.3288],\n",
      "        [ 22.0024,  16.7801,  17.8183, -20.0650,  21.4823, -16.5999],\n",
      "        [ 21.8440,  16.6057,  18.0243, -20.0199,  20.9239, -16.1423],\n",
      "        [ 21.4260,  16.2452,  17.4120, -20.5945,  21.6991, -16.8156],\n",
      "        [ 21.5943,  16.5688,  17.9118, -19.9585,  21.5305, -16.4898]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7389073371887207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2517, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5249, 16.7670, 17.6527],\n",
      "        [21.7938, 16.2262, 17.5302],\n",
      "        [21.9746, 16.3966, 17.6974],\n",
      "        [21.9495, 16.6805, 17.6093],\n",
      "        [21.7161, 16.9156, 17.5821],\n",
      "        [22.2098, 16.8320, 17.4921]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9050,  21.5325, -16.7476],\n",
      "        [-20.0252,  21.4170, -16.8155],\n",
      "        [-19.8440,  21.4822, -16.5176],\n",
      "        [-19.9080,  21.3423, -16.5000],\n",
      "        [-20.3417,  21.5610, -16.6097],\n",
      "        [-20.4220,  21.6580, -16.8576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5249,  16.7670,  17.6527, -19.9050,  21.5325, -16.7476],\n",
      "        [ 21.7938,  16.2262,  17.5302, -20.0252,  21.4170, -16.8155],\n",
      "        [ 21.9746,  16.3966,  17.6974, -19.8440,  21.4822, -16.5176],\n",
      "        [ 21.9495,  16.6805,  17.6093, -19.9080,  21.3423, -16.5000],\n",
      "        [ 21.7161,  16.9156,  17.5821, -20.3417,  21.5610, -16.6097],\n",
      "        [ 22.2098,  16.8320,  17.4921, -20.4220,  21.6580, -16.8576]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.707339286804199\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9748, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4099, 15.8731, 16.9137],\n",
      "        [21.9983, 16.8234, 17.4995],\n",
      "        [22.1157, 16.6126, 17.4702],\n",
      "        [21.7320, 16.7049, 17.6669],\n",
      "        [21.8120, 16.0645, 17.2902],\n",
      "        [22.0847, 16.8158, 17.7865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9356,  21.1497, -16.7287],\n",
      "        [-19.9693,  21.3541, -16.4574],\n",
      "        [-20.5274,  21.1997, -16.7818],\n",
      "        [-20.5132,  22.0686, -17.2375],\n",
      "        [-20.4986,  21.6886, -16.7430],\n",
      "        [-19.9868,  21.2469, -16.7884]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4099,  15.8731,  16.9137, -19.9356,  21.1497, -16.7287],\n",
      "        [ 21.9983,  16.8234,  17.4995, -19.9693,  21.3541, -16.4574],\n",
      "        [ 22.1157,  16.6126,  17.4702, -20.5274,  21.1997, -16.7818],\n",
      "        [ 21.7320,  16.7049,  17.6669, -20.5132,  22.0686, -17.2375],\n",
      "        [ 21.8120,  16.0645,  17.2902, -20.4986,  21.6886, -16.7430],\n",
      "        [ 22.0847,  16.8158,  17.7865, -19.9868,  21.2469, -16.7884]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.639162063598633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6495, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[20.8946, 15.9335, 17.3081],\n",
      "        [21.8888, 16.8990, 17.4712],\n",
      "        [22.5260, 16.7874, 18.0811],\n",
      "        [21.6876, 16.1741, 17.2337],\n",
      "        [21.6429, 16.5792, 17.2672],\n",
      "        [22.2486, 16.9167, 17.9618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.3816, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4242,  21.5696, -16.9690],\n",
      "        [-20.0202,  21.2637, -16.9103],\n",
      "        [-20.2381,  21.8486, -16.9983],\n",
      "        [-20.5467,  22.1577, -16.9754],\n",
      "        [-19.9996,  21.4550, -16.2576],\n",
      "        [-20.6746,  21.6231, -16.7498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 20.8946,  15.9335,  17.3081, -20.4242,  21.5696, -16.9690],\n",
      "        [ 21.8888,  16.8990,  17.4712, -20.0202,  21.2637, -16.9103],\n",
      "        [ 22.5260,  16.7874,  18.0811, -20.2381,  21.8486, -16.9983],\n",
      "        [ 21.6876,  16.1741,  17.2337, -20.5467,  22.1577, -16.9754],\n",
      "        [ 21.6429,  16.5792,  17.2672, -19.9996,  21.4550, -16.2576],\n",
      "        [ 22.2486,  16.9167,  17.9618, -20.6746,  21.6231, -16.7498]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.6641042232513428\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.5648, 16.4946, 17.7660],\n",
      "        [21.6295, 16.4712, 17.3621],\n",
      "        [21.8528, 16.2277, 17.3920],\n",
      "        [21.8844, 16.4748, 17.6954],\n",
      "        [21.9546, 16.7729, 17.7633],\n",
      "        [21.5558, 16.1813, 17.5982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7633, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.0867,  21.6872, -16.4663],\n",
      "        [-19.6786,  21.3828, -16.5563],\n",
      "        [-20.2940,  21.4274, -16.8653],\n",
      "        [-19.8684,  21.1699, -15.9610],\n",
      "        [-19.4242,  21.1130, -16.4426],\n",
      "        [-19.9065,  21.6330, -16.4994]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.5648,  16.4946,  17.7660, -20.0867,  21.6872, -16.4663],\n",
      "        [ 21.6295,  16.4712,  17.3621, -19.6786,  21.3828, -16.5563],\n",
      "        [ 21.8528,  16.2277,  17.3920, -20.2940,  21.4274, -16.8653],\n",
      "        [ 21.8844,  16.4748,  17.6954, -19.8684,  21.1699, -15.9610],\n",
      "        [ 21.9546,  16.7729,  17.7633, -19.4242,  21.1130, -16.4426],\n",
      "        [ 21.5558,  16.1813,  17.5982, -19.9065,  21.6330, -16.4994]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.714179277420044\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3378, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8024, 16.6365, 17.4910],\n",
      "        [21.2553, 16.1506, 17.3259],\n",
      "        [21.8617, 16.5147, 17.6001],\n",
      "        [22.3208, 16.8274, 18.0521],\n",
      "        [21.8965, 16.3855, 17.3500],\n",
      "        [21.6643, 16.7848, 17.1601]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5998,  21.9022, -17.1242],\n",
      "        [-20.3204,  21.7796, -16.9522],\n",
      "        [-20.0989,  21.5616, -16.9797],\n",
      "        [-20.0134,  21.3508, -16.7868],\n",
      "        [-20.3050,  21.7229, -16.7274],\n",
      "        [-20.3574,  21.3953, -17.0638]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8024,  16.6365,  17.4910, -20.5998,  21.9022, -17.1242],\n",
      "        [ 21.2553,  16.1506,  17.3259, -20.3204,  21.7796, -16.9522],\n",
      "        [ 21.8617,  16.5147,  17.6001, -20.0989,  21.5616, -16.9797],\n",
      "        [ 22.3208,  16.8274,  18.0521, -20.0134,  21.3508, -16.7868],\n",
      "        [ 21.8965,  16.3855,  17.3500, -20.3050,  21.7229, -16.7274],\n",
      "        [ 21.6643,  16.7848,  17.1601, -20.3574,  21.3953, -17.0638]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.754802703857422\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0493, 16.8011, 17.9235],\n",
      "        [21.7236, 16.4291, 17.5689],\n",
      "        [21.7281, 16.6468, 17.5483],\n",
      "        [21.4274, 16.7608, 17.4307],\n",
      "        [21.8773, 16.7079, 18.0962],\n",
      "        [21.4238, 16.4559, 17.7172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.1916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9839,  21.2122, -16.8862],\n",
      "        [-20.3858,  21.8530, -17.0206],\n",
      "        [-20.1502,  21.4775, -16.7035],\n",
      "        [-20.2605,  21.8290, -16.9139],\n",
      "        [-20.1407,  21.2634, -16.9338],\n",
      "        [-20.2285,  21.8998, -16.8611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0493,  16.8011,  17.9235, -19.9839,  21.2122, -16.8862],\n",
      "        [ 21.7236,  16.4291,  17.5689, -20.3858,  21.8530, -17.0206],\n",
      "        [ 21.7281,  16.6468,  17.5483, -20.1502,  21.4775, -16.7035],\n",
      "        [ 21.4274,  16.7608,  17.4307, -20.2605,  21.8290, -16.9139],\n",
      "        [ 21.8773,  16.7079,  18.0962, -20.1407,  21.2634, -16.9338],\n",
      "        [ 21.4238,  16.4559,  17.7172, -20.2285,  21.8998, -16.8611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.746788501739502\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5546, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0433, 16.7244, 17.8717],\n",
      "        [21.6729, 16.3247, 17.4495],\n",
      "        [21.8461, 16.8172, 17.4804],\n",
      "        [22.1069, 16.8856, 17.9664],\n",
      "        [21.2751, 15.9109, 17.3443],\n",
      "        [21.9610, 16.6080, 17.9977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0994, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4281,  21.5318, -16.8239],\n",
      "        [-19.7580,  21.0621, -16.4367],\n",
      "        [-19.9565,  21.3425, -16.5554],\n",
      "        [-20.4198,  21.6199, -16.8978],\n",
      "        [-19.3672,  21.1677, -16.6559],\n",
      "        [-20.1163,  21.8735, -16.7283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0433,  16.7244,  17.8717, -20.4281,  21.5318, -16.8239],\n",
      "        [ 21.6729,  16.3247,  17.4495, -19.7580,  21.0621, -16.4367],\n",
      "        [ 21.8461,  16.8172,  17.4804, -19.9565,  21.3425, -16.5554],\n",
      "        [ 22.1069,  16.8856,  17.9664, -20.4198,  21.6199, -16.8978],\n",
      "        [ 21.2751,  15.9109,  17.3443, -19.3672,  21.1677, -16.6559],\n",
      "        [ 21.9610,  16.6080,  17.9977, -20.1163,  21.8735, -16.7283]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.76430082321167\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8932, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2224, 16.3225, 17.9483],\n",
      "        [21.8722, 16.8537, 18.2292],\n",
      "        [22.0349, 16.7056, 17.9755],\n",
      "        [21.8153, 16.5585, 17.7873],\n",
      "        [21.7952, 16.2493, 17.7498],\n",
      "        [21.9805, 16.3382, 17.5477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.6904, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.8538,  21.2166, -16.6286],\n",
      "        [-19.5422,  21.3895, -16.5547],\n",
      "        [-20.3508,  21.0336, -16.8185],\n",
      "        [-20.0793,  21.6084, -16.6261],\n",
      "        [-20.3644,  21.5515, -16.9097],\n",
      "        [-20.1802,  21.3348, -16.6012]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2224,  16.3225,  17.9483, -19.8538,  21.2166, -16.6286],\n",
      "        [ 21.8722,  16.8537,  18.2292, -19.5422,  21.3895, -16.5547],\n",
      "        [ 22.0349,  16.7056,  17.9755, -20.3508,  21.0336, -16.8185],\n",
      "        [ 21.8153,  16.5585,  17.7873, -20.0793,  21.6084, -16.6261],\n",
      "        [ 21.7952,  16.2493,  17.7498, -20.3644,  21.5515, -16.9097],\n",
      "        [ 21.9805,  16.3382,  17.5477, -20.1802,  21.3348, -16.6012]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.736732006072998\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2380, 16.7228, 17.4264],\n",
      "        [22.2379, 16.8900, 18.1794],\n",
      "        [21.9487, 16.7551, 17.7673],\n",
      "        [22.0804, 16.7921, 18.1598],\n",
      "        [21.6538, 16.3994, 17.2221],\n",
      "        [22.0958, 16.3879, 17.3613]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5279, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1076,  21.6040, -16.4680],\n",
      "        [-19.8189,  21.1415, -16.6261],\n",
      "        [-20.3797,  21.5920, -17.0840],\n",
      "        [-20.0141,  21.5339, -16.2234],\n",
      "        [-19.8007,  21.0678, -16.4732],\n",
      "        [-20.1263,  21.2403, -16.0840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2380,  16.7228,  17.4264, -20.1076,  21.6040, -16.4680],\n",
      "        [ 22.2379,  16.8900,  18.1794, -19.8189,  21.1415, -16.6261],\n",
      "        [ 21.9487,  16.7551,  17.7673, -20.3797,  21.5920, -17.0840],\n",
      "        [ 22.0804,  16.7921,  18.1598, -20.0141,  21.5339, -16.2234],\n",
      "        [ 21.6538,  16.3994,  17.2221, -19.8007,  21.0678, -16.4732],\n",
      "        [ 22.0958,  16.3879,  17.3613, -20.1263,  21.2403, -16.0840]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7450714111328125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2509, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2353, 17.0718, 18.0663],\n",
      "        [21.9075, 16.8104, 17.9011],\n",
      "        [21.7117, 16.7653, 18.2642],\n",
      "        [21.9777, 16.7034, 18.0047],\n",
      "        [21.6090, 16.2933, 17.6993],\n",
      "        [21.6368, 16.2530, 17.2626]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.4985, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1601,  20.9205, -16.7296],\n",
      "        [-19.9882,  21.1819, -16.5918],\n",
      "        [-20.0899,  21.4888, -16.7979],\n",
      "        [-20.1926,  21.6158, -16.8837],\n",
      "        [-19.9174,  21.5138, -16.5291],\n",
      "        [-20.1688,  21.7532, -16.8578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2353,  17.0718,  18.0663, -20.1601,  20.9205, -16.7296],\n",
      "        [ 21.9075,  16.8104,  17.9011, -19.9882,  21.1819, -16.5918],\n",
      "        [ 21.7117,  16.7653,  18.2642, -20.0899,  21.4888, -16.7979],\n",
      "        [ 21.9777,  16.7034,  18.0047, -20.1926,  21.6158, -16.8837],\n",
      "        [ 21.6090,  16.2933,  17.6993, -19.9174,  21.5138, -16.5291],\n",
      "        [ 21.6368,  16.2530,  17.2626, -20.1688,  21.7532, -16.8578]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7675983905792236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0130, 16.6069, 17.7372],\n",
      "        [22.3153, 17.0250, 18.0311],\n",
      "        [21.7425, 16.7867, 18.0406],\n",
      "        [21.9229, 16.8415, 17.6140],\n",
      "        [21.8355, 16.0533, 17.3299],\n",
      "        [21.4852, 16.4003, 17.7633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.0486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1058,  21.6448, -16.6052],\n",
      "        [-20.3818,  21.5499, -16.5097],\n",
      "        [-19.9968,  21.3220, -16.8691],\n",
      "        [-20.3695,  21.8978, -17.2378],\n",
      "        [-20.3319,  21.3343, -16.7825],\n",
      "        [-20.7001,  22.1749, -16.9107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0130,  16.6069,  17.7372, -20.1058,  21.6448, -16.6052],\n",
      "        [ 22.3153,  17.0250,  18.0311, -20.3818,  21.5499, -16.5097],\n",
      "        [ 21.7425,  16.7867,  18.0406, -19.9968,  21.3220, -16.8691],\n",
      "        [ 21.9229,  16.8415,  17.6140, -20.3695,  21.8978, -17.2378],\n",
      "        [ 21.8355,  16.0533,  17.3299, -20.3319,  21.3343, -16.7825],\n",
      "        [ 21.4852,  16.4003,  17.7633, -20.7001,  22.1749, -16.9107]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.750302791595459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.3793, 16.3451, 18.0500],\n",
      "        [22.0650, 16.7957, 17.7496],\n",
      "        [21.4075, 16.2025, 17.3356],\n",
      "        [21.7022, 16.4922, 17.8440],\n",
      "        [21.9438, 16.5991, 17.6286],\n",
      "        [21.7089, 15.9028, 17.4806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.9714, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2656,  21.6193, -16.9113],\n",
      "        [-20.4399,  21.7546, -16.6078],\n",
      "        [-19.6428,  21.3124, -16.5660],\n",
      "        [-20.0893,  21.5295, -16.7093],\n",
      "        [-20.2043,  21.4097, -16.4599],\n",
      "        [-20.0889,  22.0410, -17.0991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.3793,  16.3451,  18.0500, -20.2656,  21.6193, -16.9113],\n",
      "        [ 22.0650,  16.7957,  17.7496, -20.4399,  21.7546, -16.6078],\n",
      "        [ 21.4075,  16.2025,  17.3356, -19.6428,  21.3124, -16.5660],\n",
      "        [ 21.7022,  16.4922,  17.8440, -20.0893,  21.5295, -16.7093],\n",
      "        [ 21.9438,  16.5991,  17.6286, -20.2043,  21.4097, -16.4599],\n",
      "        [ 21.7089,  15.9028,  17.4806, -20.0889,  22.0410, -17.0991]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7366886138916016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2685, 16.8739, 18.0103],\n",
      "        [22.0227, 17.0076, 18.0143],\n",
      "        [21.6631, 16.6787, 17.4073],\n",
      "        [21.7320, 16.3947, 17.2568],\n",
      "        [21.7936, 16.3186, 17.5572],\n",
      "        [21.9871, 16.7254, 17.9772]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.1686, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3798,  21.7448, -16.4854],\n",
      "        [-19.9765,  21.6858, -16.7005],\n",
      "        [-20.0608,  21.4429, -16.3870],\n",
      "        [-20.1563,  21.7093, -16.9586],\n",
      "        [-20.4416,  21.6292, -16.8526],\n",
      "        [-20.6047,  21.7564, -16.8933]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2685,  16.8739,  18.0103, -20.3798,  21.7448, -16.4854],\n",
      "        [ 22.0227,  17.0076,  18.0143, -19.9765,  21.6858, -16.7005],\n",
      "        [ 21.6631,  16.6787,  17.4073, -20.0608,  21.4429, -16.3870],\n",
      "        [ 21.7320,  16.3947,  17.2568, -20.1563,  21.7093, -16.9586],\n",
      "        [ 21.7936,  16.3186,  17.5572, -20.4416,  21.6292, -16.8526],\n",
      "        [ 21.9871,  16.7254,  17.9772, -20.6047,  21.7564, -16.8933]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.791496753692627\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1424, 16.8065, 18.0277],\n",
      "        [22.2178, 16.6571, 17.6068],\n",
      "        [22.0635, 16.4268, 17.6500],\n",
      "        [21.8298, 16.9549, 18.0793],\n",
      "        [22.3054, 16.5752, 18.0813],\n",
      "        [21.4111, 16.2918, 17.4622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0652, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1587,  21.3537, -16.8918],\n",
      "        [-20.6245,  22.1682, -16.8997],\n",
      "        [-20.3327,  21.3869, -17.0136],\n",
      "        [-20.3471,  21.5428, -16.9203],\n",
      "        [-20.2330,  21.6260, -16.8153],\n",
      "        [-20.4414,  21.9252, -16.9605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1424,  16.8065,  18.0277, -20.1587,  21.3537, -16.8918],\n",
      "        [ 22.2178,  16.6571,  17.6068, -20.6245,  22.1682, -16.8997],\n",
      "        [ 22.0635,  16.4268,  17.6500, -20.3327,  21.3869, -17.0136],\n",
      "        [ 21.8298,  16.9549,  18.0793, -20.3471,  21.5428, -16.9203],\n",
      "        [ 22.3054,  16.5752,  18.0813, -20.2330,  21.6260, -16.8153],\n",
      "        [ 21.4111,  16.2918,  17.4622, -20.4414,  21.9252, -16.9605]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.776745319366455\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9744, 16.8574, 18.0414],\n",
      "        [22.3883, 17.0767, 18.2210],\n",
      "        [21.9043, 16.4365, 17.6793],\n",
      "        [21.8990, 16.5776, 17.6082],\n",
      "        [22.0894, 16.4383, 17.9097],\n",
      "        [21.9636, 16.8851, 17.6236]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.5356, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1719,  21.7776, -16.6105],\n",
      "        [-20.5110,  21.9468, -17.0678],\n",
      "        [-20.2867,  21.3942, -16.6645],\n",
      "        [-20.4514,  22.0717, -17.2984],\n",
      "        [-20.3455,  21.6094, -16.9655],\n",
      "        [-20.3570,  21.6706, -16.7005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9744,  16.8574,  18.0414, -20.1719,  21.7776, -16.6105],\n",
      "        [ 22.3883,  17.0767,  18.2210, -20.5110,  21.9468, -17.0678],\n",
      "        [ 21.9043,  16.4365,  17.6793, -20.2867,  21.3942, -16.6645],\n",
      "        [ 21.8990,  16.5776,  17.6082, -20.4514,  22.0717, -17.2984],\n",
      "        [ 22.0894,  16.4383,  17.9097, -20.3455,  21.6094, -16.9655],\n",
      "        [ 21.9636,  16.8851,  17.6236, -20.3570,  21.6706, -16.7005]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.779231309890747\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1206, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3059, 16.5010, 18.0776],\n",
      "        [22.1154, 16.3822, 17.9084],\n",
      "        [21.7996, 17.1790, 17.8671],\n",
      "        [22.0285, 16.5726, 17.6658],\n",
      "        [21.8864, 16.5730, 17.8719],\n",
      "        [21.1906, 16.2392, 17.0494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7814,  21.2420, -16.7747],\n",
      "        [-20.5258,  21.7875, -17.1688],\n",
      "        [-20.2848,  21.5156, -16.6616],\n",
      "        [-20.1085,  21.8152, -17.0676],\n",
      "        [-20.5106,  21.6005, -17.2778],\n",
      "        [-20.7421,  21.8278, -16.9549]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3059,  16.5010,  18.0776, -19.7814,  21.2420, -16.7747],\n",
      "        [ 22.1154,  16.3822,  17.9084, -20.5258,  21.7875, -17.1688],\n",
      "        [ 21.7996,  17.1790,  17.8671, -20.2848,  21.5156, -16.6616],\n",
      "        [ 22.0285,  16.5726,  17.6658, -20.1085,  21.8152, -17.0676],\n",
      "        [ 21.8864,  16.5730,  17.8719, -20.5106,  21.6005, -17.2778],\n",
      "        [ 21.1906,  16.2392,  17.0494, -20.7421,  21.8278, -16.9549]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7646961212158203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8431, 16.6204, 17.6713],\n",
      "        [21.7145, 16.3638, 17.7817],\n",
      "        [22.2579, 16.4771, 18.0766],\n",
      "        [21.7287, 16.1970, 17.6239],\n",
      "        [21.4906, 16.2940, 17.9691],\n",
      "        [22.2993, 16.6331, 17.7943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2281, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6226,  21.8122, -17.1265],\n",
      "        [-20.3227,  21.1734, -16.5776],\n",
      "        [-20.2604,  21.2037, -16.8329],\n",
      "        [-19.7817,  21.0079, -16.0939],\n",
      "        [-20.4249,  21.4651, -16.5241],\n",
      "        [-20.5025,  21.7834, -16.5960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8431,  16.6204,  17.6713, -20.6226,  21.8122, -17.1265],\n",
      "        [ 21.7145,  16.3638,  17.7817, -20.3227,  21.1734, -16.5776],\n",
      "        [ 22.2579,  16.4771,  18.0766, -20.2604,  21.2037, -16.8329],\n",
      "        [ 21.7287,  16.1970,  17.6239, -19.7817,  21.0079, -16.0939],\n",
      "        [ 21.4906,  16.2940,  17.9691, -20.4249,  21.4651, -16.5241],\n",
      "        [ 22.2993,  16.6331,  17.7943, -20.5025,  21.7834, -16.5960]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7796430587768555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1041, 16.5564, 17.4811],\n",
      "        [21.9390, 16.8786, 17.5201],\n",
      "        [21.8393, 16.8183, 17.7655],\n",
      "        [21.6912, 16.4997, 17.6359],\n",
      "        [21.7507, 16.4514, 17.3055],\n",
      "        [21.8213, 16.2663, 17.8201]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.3243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1011,  21.1740, -17.0731],\n",
      "        [-20.2134,  21.6171, -17.0161],\n",
      "        [-20.5612,  21.6783, -16.6646],\n",
      "        [-20.2396,  21.2063, -17.2001],\n",
      "        [-20.7115,  22.1798, -17.2125],\n",
      "        [-20.2996,  21.3064, -17.0522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1041,  16.5564,  17.4811, -20.1011,  21.1740, -17.0731],\n",
      "        [ 21.9390,  16.8786,  17.5201, -20.2134,  21.6171, -17.0161],\n",
      "        [ 21.8393,  16.8183,  17.7655, -20.5612,  21.6783, -16.6646],\n",
      "        [ 21.6912,  16.4997,  17.6359, -20.2396,  21.2063, -17.2001],\n",
      "        [ 21.7507,  16.4514,  17.3055, -20.7115,  22.1798, -17.2125],\n",
      "        [ 21.8213,  16.2663,  17.8201, -20.2996,  21.3064, -17.0522]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7497756481170654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4833, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0475, 17.0628, 18.0326],\n",
      "        [21.8068, 16.5808, 17.3503],\n",
      "        [22.1127, 16.5751, 17.7570],\n",
      "        [21.8253, 16.6823, 17.5646],\n",
      "        [21.9251, 16.4304, 17.7739],\n",
      "        [22.0444, 16.4769, 17.8802]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.2129, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2484,  21.5519, -17.2120],\n",
      "        [-20.2858,  21.6074, -16.7439],\n",
      "        [-20.7128,  21.4213, -16.9697],\n",
      "        [-20.1169,  21.0759, -16.6930],\n",
      "        [-20.8331,  22.3001, -17.0065],\n",
      "        [-19.7975,  20.9137, -16.2570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0475,  17.0628,  18.0326, -20.2484,  21.5519, -17.2120],\n",
      "        [ 21.8068,  16.5808,  17.3503, -20.2858,  21.6074, -16.7439],\n",
      "        [ 22.1127,  16.5751,  17.7570, -20.7128,  21.4213, -16.9697],\n",
      "        [ 21.8253,  16.6823,  17.5646, -20.1169,  21.0759, -16.6930],\n",
      "        [ 21.9251,  16.4304,  17.7739, -20.8331,  22.3001, -17.0065],\n",
      "        [ 22.0444,  16.4769,  17.8802, -19.7975,  20.9137, -16.2570]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.802527666091919\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5939, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9125, 16.7481, 18.0307],\n",
      "        [21.8143, 16.8302, 18.1123],\n",
      "        [22.3118, 17.3745, 18.1352],\n",
      "        [21.9705, 16.4822, 17.9863],\n",
      "        [21.8500, 16.7164, 17.7462],\n",
      "        [22.3120, 16.9917, 17.7987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.6805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7195,  21.7855, -16.8762],\n",
      "        [-20.2044,  21.6524, -16.7165],\n",
      "        [-20.4216,  21.5463, -16.3680],\n",
      "        [-20.1687,  21.2602, -16.7481],\n",
      "        [-20.3070,  21.6977, -16.6039],\n",
      "        [-20.4184,  21.6551, -16.7941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9125,  16.7481,  18.0307, -20.7195,  21.7855, -16.8762],\n",
      "        [ 21.8143,  16.8302,  18.1123, -20.2044,  21.6524, -16.7165],\n",
      "        [ 22.3118,  17.3745,  18.1352, -20.4216,  21.5463, -16.3680],\n",
      "        [ 21.9705,  16.4822,  17.9863, -20.1687,  21.2602, -16.7481],\n",
      "        [ 21.8500,  16.7164,  17.7462, -20.3070,  21.6977, -16.6039],\n",
      "        [ 22.3120,  16.9917,  17.7987, -20.4184,  21.6551, -16.7941]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8015716075897217\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4931, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8664, 16.9527, 17.6192],\n",
      "        [22.3967, 16.9135, 18.0665],\n",
      "        [21.7340, 17.1213, 17.5510],\n",
      "        [21.4595, 16.3378, 17.5372],\n",
      "        [22.0046, 16.5222, 17.8485],\n",
      "        [22.3245, 16.8018, 17.7596]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.1814,  21.5345, -16.8700],\n",
      "        [-20.1237,  22.0857, -16.9190],\n",
      "        [-20.8280,  22.2266, -17.2709],\n",
      "        [-20.3506,  21.6002, -16.7808],\n",
      "        [-20.5770,  21.7010, -16.9092],\n",
      "        [-20.8568,  21.5142, -17.4167]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8664,  16.9527,  17.6192, -20.1814,  21.5345, -16.8700],\n",
      "        [ 22.3967,  16.9135,  18.0665, -20.1237,  22.0857, -16.9190],\n",
      "        [ 21.7340,  17.1213,  17.5510, -20.8280,  22.2266, -17.2709],\n",
      "        [ 21.4595,  16.3378,  17.5372, -20.3506,  21.6002, -16.7808],\n",
      "        [ 22.0046,  16.5222,  17.8485, -20.5770,  21.7010, -16.9092],\n",
      "        [ 22.3245,  16.8018,  17.7596, -20.8568,  21.5142, -17.4167]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.768111228942871\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7572, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0173, 16.6586, 17.4431],\n",
      "        [22.3512, 17.1319, 17.9751],\n",
      "        [22.4962, 16.7151, 18.0604],\n",
      "        [22.3729, 16.7936, 17.8245],\n",
      "        [21.7638, 16.6394, 17.7638],\n",
      "        [21.9208, 16.5325, 17.8632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.7473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3005,  22.0550, -17.2062],\n",
      "        [-19.9578,  21.5597, -17.2370],\n",
      "        [-19.8648,  21.4719, -17.0713],\n",
      "        [-20.0179,  21.2559, -16.8268],\n",
      "        [-20.1501,  21.5381, -16.8489],\n",
      "        [-20.6834,  22.0900, -17.0505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0173,  16.6586,  17.4431, -20.3005,  22.0550, -17.2062],\n",
      "        [ 22.3512,  17.1319,  17.9751, -19.9578,  21.5597, -17.2370],\n",
      "        [ 22.4962,  16.7151,  18.0604, -19.8648,  21.4719, -17.0713],\n",
      "        [ 22.3729,  16.7936,  17.8245, -20.0179,  21.2559, -16.8268],\n",
      "        [ 21.7638,  16.6394,  17.7638, -20.1501,  21.5381, -16.8489],\n",
      "        [ 21.9208,  16.5325,  17.8632, -20.6834,  22.0900, -17.0505]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7878775596618652\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9901, 16.3922, 17.5981],\n",
      "        [22.0872, 16.7514, 17.7696],\n",
      "        [22.1191, 16.8647, 18.1549],\n",
      "        [22.1497, 16.5107, 17.6138],\n",
      "        [21.2147, 16.4961, 17.1590],\n",
      "        [21.8759, 16.7824, 17.5979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8954, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2851,  21.4489, -16.8027],\n",
      "        [-20.3964,  22.0454, -17.0415],\n",
      "        [-19.8955,  21.1721, -16.0997],\n",
      "        [-20.3446,  21.6527, -16.8157],\n",
      "        [-20.4609,  21.7067, -16.8248],\n",
      "        [-20.4191,  21.5811, -17.1006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9901,  16.3922,  17.5981, -20.2851,  21.4489, -16.8027],\n",
      "        [ 22.0872,  16.7514,  17.7696, -20.3964,  22.0454, -17.0415],\n",
      "        [ 22.1191,  16.8647,  18.1549, -19.8955,  21.1721, -16.0997],\n",
      "        [ 22.1497,  16.5107,  17.6138, -20.3446,  21.6527, -16.8157],\n",
      "        [ 21.2147,  16.4961,  17.1590, -20.4609,  21.7067, -16.8248],\n",
      "        [ 21.8759,  16.7824,  17.5979, -20.4191,  21.5811, -17.1006]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.75937819480896\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6185, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9064, 16.9079, 17.7543],\n",
      "        [21.4759, 16.5956, 17.9188],\n",
      "        [21.7139, 16.7608, 18.4182],\n",
      "        [22.1754, 16.7975, 17.6889],\n",
      "        [21.6294, 16.3366, 17.6907],\n",
      "        [22.0756, 16.8437, 17.7897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2531, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2480,  21.5948, -17.2138],\n",
      "        [-20.3617,  21.7977, -17.0704],\n",
      "        [-20.2355,  21.7717, -16.4151],\n",
      "        [-20.5226,  21.7632, -16.9058],\n",
      "        [-20.4876,  21.9699, -17.3849],\n",
      "        [-20.9047,  22.3860, -17.6997]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9064,  16.9079,  17.7543, -20.2480,  21.5948, -17.2138],\n",
      "        [ 21.4759,  16.5956,  17.9188, -20.3617,  21.7977, -17.0704],\n",
      "        [ 21.7139,  16.7608,  18.4182, -20.2355,  21.7717, -16.4151],\n",
      "        [ 22.1754,  16.7975,  17.6889, -20.5226,  21.7632, -16.9058],\n",
      "        [ 21.6294,  16.3366,  17.6907, -20.4876,  21.9699, -17.3849],\n",
      "        [ 22.0756,  16.8437,  17.7897, -20.9047,  22.3860, -17.6997]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.789653778076172\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5489, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1037, 17.1704, 17.9532],\n",
      "        [22.3440, 17.0063, 17.9030],\n",
      "        [22.0859, 16.8833, 17.8534],\n",
      "        [22.0765, 16.8716, 18.0167],\n",
      "        [22.1872, 17.0760, 17.9268],\n",
      "        [21.7896, 16.8300, 17.5491]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.6182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2551,  22.0112, -17.1427],\n",
      "        [-20.7294,  21.9945, -17.0125],\n",
      "        [-20.3968,  21.5209, -16.4769],\n",
      "        [-19.9956,  21.3978, -16.6476],\n",
      "        [-20.3389,  21.6260, -16.7945],\n",
      "        [-20.3825,  21.8785, -17.1418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1037,  17.1704,  17.9532, -20.2551,  22.0112, -17.1427],\n",
      "        [ 22.3440,  17.0063,  17.9030, -20.7294,  21.9945, -17.0125],\n",
      "        [ 22.0859,  16.8833,  17.8534, -20.3968,  21.5209, -16.4769],\n",
      "        [ 22.0765,  16.8716,  18.0167, -19.9956,  21.3978, -16.6476],\n",
      "        [ 22.1872,  17.0760,  17.9268, -20.3389,  21.6260, -16.7945],\n",
      "        [ 21.7896,  16.8300,  17.5491, -20.3825,  21.8785, -17.1418]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.8268468379974365\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4342, 17.2778, 18.4588],\n",
      "        [21.5881, 16.6064, 17.4904],\n",
      "        [22.3330, 16.8661, 18.1641],\n",
      "        [22.1225, 17.1994, 17.4176],\n",
      "        [22.1558, 16.7025, 18.0752],\n",
      "        [21.9993, 17.0828, 18.1540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.4886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4744,  21.4568, -16.7194],\n",
      "        [-20.4204,  21.8993, -16.9717],\n",
      "        [-20.3267,  21.7546, -17.0259],\n",
      "        [-20.3429,  22.1429, -16.9726],\n",
      "        [-20.3662,  21.7586, -17.1646],\n",
      "        [-20.2629,  21.4972, -17.0002]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4342,  17.2778,  18.4588, -20.4744,  21.4568, -16.7194],\n",
      "        [ 21.5881,  16.6064,  17.4904, -20.4204,  21.8993, -16.9717],\n",
      "        [ 22.3330,  16.8661,  18.1641, -20.3267,  21.7546, -17.0259],\n",
      "        [ 22.1225,  17.1994,  17.4176, -20.3429,  22.1429, -16.9726],\n",
      "        [ 22.1558,  16.7025,  18.0752, -20.3662,  21.7586, -17.1646],\n",
      "        [ 21.9993,  17.0828,  18.1540, -20.2629,  21.4972, -17.0002]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8471670150756836\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6481, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4083, 17.1822, 18.2851],\n",
      "        [21.5702, 16.5814, 17.7192],\n",
      "        [21.9496, 16.9029, 17.8382],\n",
      "        [22.0570, 16.9672, 17.6282],\n",
      "        [22.3757, 17.0369, 17.9695],\n",
      "        [22.3889, 16.6975, 17.9097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9074, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2976,  21.9137, -16.8888],\n",
      "        [-20.4348,  21.7265, -16.8512],\n",
      "        [-20.4110,  21.1809, -16.5012],\n",
      "        [-20.8601,  22.0955, -17.2922],\n",
      "        [-19.9656,  21.7723, -16.7090],\n",
      "        [-20.0563,  21.2989, -16.8327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4083,  17.1822,  18.2851, -20.2976,  21.9137, -16.8888],\n",
      "        [ 21.5702,  16.5814,  17.7192, -20.4348,  21.7265, -16.8512],\n",
      "        [ 21.9496,  16.9029,  17.8382, -20.4110,  21.1809, -16.5012],\n",
      "        [ 22.0570,  16.9672,  17.6282, -20.8601,  22.0955, -17.2922],\n",
      "        [ 22.3757,  17.0369,  17.9695, -19.9656,  21.7723, -16.7090],\n",
      "        [ 22.3889,  16.6975,  17.9097, -20.0563,  21.2989, -16.8327]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8504889011383057\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5453, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9557, 17.0008, 17.9605],\n",
      "        [22.0273, 16.8301, 17.9501],\n",
      "        [22.0399, 16.8774, 17.8487],\n",
      "        [22.5572, 17.0512, 18.3268],\n",
      "        [21.5978, 16.4318, 17.7388],\n",
      "        [22.5108, 16.5058, 17.9661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2691, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2949,  21.3677, -16.9638],\n",
      "        [-20.7130,  21.6184, -17.1981],\n",
      "        [-20.3039,  21.7749, -17.0795],\n",
      "        [-20.0215,  21.4504, -16.8871],\n",
      "        [-19.9490,  21.6384, -17.0924],\n",
      "        [-20.3499,  21.8224, -17.1881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9557,  17.0008,  17.9605, -20.2949,  21.3677, -16.9638],\n",
      "        [ 22.0273,  16.8301,  17.9501, -20.7130,  21.6184, -17.1981],\n",
      "        [ 22.0399,  16.8774,  17.8487, -20.3039,  21.7749, -17.0795],\n",
      "        [ 22.5572,  17.0512,  18.3268, -20.0215,  21.4504, -16.8871],\n",
      "        [ 21.5978,  16.4318,  17.7388, -19.9490,  21.6384, -17.0924],\n",
      "        [ 22.5108,  16.5058,  17.9661, -20.3499,  21.8224, -17.1881]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7978575229644775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.4127, 16.6377, 17.4595],\n",
      "        [21.0466, 15.7993, 16.9234],\n",
      "        [22.6279, 17.4075, 18.2001],\n",
      "        [21.8540, 16.8128, 17.5218],\n",
      "        [21.7408, 16.7627, 17.8053],\n",
      "        [22.1742, 16.9724, 17.8052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6625, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8700,  22.2533, -17.3635],\n",
      "        [-21.0435,  22.3357, -17.3936],\n",
      "        [-20.3905,  21.5714, -16.9131],\n",
      "        [-20.3316,  21.6127, -17.1838],\n",
      "        [-20.5363,  21.6308, -17.3250],\n",
      "        [-20.7053,  21.5939, -17.1463]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.4127,  16.6377,  17.4595, -20.8700,  22.2533, -17.3635],\n",
      "        [ 21.0466,  15.7993,  16.9234, -21.0435,  22.3357, -17.3936],\n",
      "        [ 22.6279,  17.4075,  18.2001, -20.3905,  21.5714, -16.9131],\n",
      "        [ 21.8540,  16.8128,  17.5218, -20.3316,  21.6127, -17.1838],\n",
      "        [ 21.7408,  16.7627,  17.8053, -20.5363,  21.6308, -17.3250],\n",
      "        [ 22.1742,  16.9724,  17.8052, -20.7053,  21.5939, -17.1463]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7949955463409424\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0982, 17.0287, 17.7923],\n",
      "        [21.9727, 16.8708, 17.9527],\n",
      "        [21.6865, 16.3936, 17.5275],\n",
      "        [21.6991, 16.5235, 17.5467],\n",
      "        [22.1246, 16.9416, 17.9553],\n",
      "        [21.4916, 16.0126, 17.3285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.7677, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5965,  21.9212, -17.3896],\n",
      "        [-20.6041,  21.9138, -16.9461],\n",
      "        [-20.1753,  22.0670, -16.9361],\n",
      "        [-20.3273,  22.0633, -17.1602],\n",
      "        [-20.8163,  22.1108, -16.9986],\n",
      "        [-20.0589,  21.5817, -16.9430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0982,  17.0287,  17.7923, -20.5965,  21.9212, -17.3896],\n",
      "        [ 21.9727,  16.8708,  17.9527, -20.6041,  21.9138, -16.9461],\n",
      "        [ 21.6865,  16.3936,  17.5275, -20.1753,  22.0670, -16.9361],\n",
      "        [ 21.6991,  16.5235,  17.5467, -20.3273,  22.0633, -17.1602],\n",
      "        [ 22.1246,  16.9416,  17.9553, -20.8163,  22.1108, -16.9986],\n",
      "        [ 21.4916,  16.0126,  17.3285, -20.0589,  21.5817, -16.9430]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8362202644348145\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3376, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3622, 16.9946, 17.8196],\n",
      "        [22.2249, 17.3667, 18.1571],\n",
      "        [22.4729, 17.1130, 18.1260],\n",
      "        [21.9398, 16.6943, 17.8513],\n",
      "        [22.0998, 16.8252, 18.0187],\n",
      "        [21.9479, 16.7179, 17.6762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2537,  22.0746, -17.1641],\n",
      "        [-20.4251,  21.4573, -17.0297],\n",
      "        [-20.4207,  21.6553, -16.9976],\n",
      "        [-20.4879,  21.9136, -17.0882],\n",
      "        [-20.5389,  21.5202, -17.2786],\n",
      "        [-20.6328,  21.5812, -17.2187]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3622,  16.9946,  17.8196, -20.2537,  22.0746, -17.1641],\n",
      "        [ 22.2249,  17.3667,  18.1571, -20.4251,  21.4573, -17.0297],\n",
      "        [ 22.4729,  17.1130,  18.1260, -20.4207,  21.6553, -16.9976],\n",
      "        [ 21.9398,  16.6943,  17.8513, -20.4879,  21.9136, -17.0882],\n",
      "        [ 22.0998,  16.8252,  18.0187, -20.5389,  21.5202, -17.2786],\n",
      "        [ 21.9479,  16.7179,  17.6762, -20.6328,  21.5812, -17.2187]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.8406624794006348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5337, 17.0919, 18.1823],\n",
      "        [22.4549, 16.8409, 17.9307],\n",
      "        [22.1682, 16.8371, 17.7879],\n",
      "        [22.0149, 16.8402, 17.9948],\n",
      "        [21.5687, 16.1324, 17.4716],\n",
      "        [21.6584, 16.7621, 17.6505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2205,  22.0042, -16.8717],\n",
      "        [-20.4386,  21.9188, -17.6161],\n",
      "        [-20.6465,  21.7783, -16.8587],\n",
      "        [-20.5942,  21.8376, -17.0960],\n",
      "        [-20.2630,  21.7278, -17.0763],\n",
      "        [-20.0316,  21.5144, -16.6717]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5337,  17.0919,  18.1823, -20.2205,  22.0042, -16.8717],\n",
      "        [ 22.4549,  16.8409,  17.9307, -20.4386,  21.9188, -17.6161],\n",
      "        [ 22.1682,  16.8371,  17.7879, -20.6465,  21.7783, -16.8587],\n",
      "        [ 22.0149,  16.8402,  17.9948, -20.5942,  21.8376, -17.0960],\n",
      "        [ 21.5687,  16.1324,  17.4716, -20.2630,  21.7278, -17.0763],\n",
      "        [ 21.6584,  16.7621,  17.6505, -20.0316,  21.5144, -16.6717]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8579022884368896\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7139, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0450, 16.6512, 17.9824],\n",
      "        [22.2550, 17.1305, 18.1001],\n",
      "        [21.9438, 16.6312, 17.8957],\n",
      "        [21.6331, 16.6123, 17.5455],\n",
      "        [22.1071, 17.1673, 18.0459],\n",
      "        [22.2632, 17.1969, 17.6734]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9900,  21.3538, -16.8522],\n",
      "        [-20.2294,  21.3939, -16.8784],\n",
      "        [-20.5455,  21.8589, -16.9108],\n",
      "        [-20.6781,  21.6613, -17.1539],\n",
      "        [-20.4045,  21.5906, -16.7266],\n",
      "        [-20.3047,  21.5070, -16.8070]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0450,  16.6512,  17.9824, -19.9900,  21.3538, -16.8522],\n",
      "        [ 22.2550,  17.1305,  18.1001, -20.2294,  21.3939, -16.8784],\n",
      "        [ 21.9438,  16.6312,  17.8957, -20.5455,  21.8589, -16.9108],\n",
      "        [ 21.6331,  16.6123,  17.5455, -20.6781,  21.6613, -17.1539],\n",
      "        [ 22.1071,  17.1673,  18.0459, -20.4045,  21.5906, -16.7266],\n",
      "        [ 22.2632,  17.1969,  17.6734, -20.3047,  21.5070, -16.8070]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.7894628047943115\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.8926, 16.9522, 17.8250],\n",
      "        [22.1010, 16.7860, 17.6453],\n",
      "        [22.1234, 16.7509, 17.5234],\n",
      "        [22.6919, 17.1129, 18.4798],\n",
      "        [21.8835, 16.9538, 18.1774],\n",
      "        [22.6106, 17.2835, 18.2994]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0699, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7848,  22.2147, -17.5029],\n",
      "        [-20.0771,  21.2138, -17.1299],\n",
      "        [-20.1562,  21.7072, -16.8715],\n",
      "        [-20.2511,  21.9375, -16.8463],\n",
      "        [-20.4437,  21.6779, -16.8107],\n",
      "        [-20.3310,  21.8303, -17.2289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.8926,  16.9522,  17.8250, -20.7848,  22.2147, -17.5029],\n",
      "        [ 22.1010,  16.7860,  17.6453, -20.0771,  21.2138, -17.1299],\n",
      "        [ 22.1234,  16.7509,  17.5234, -20.1562,  21.7072, -16.8715],\n",
      "        [ 22.6919,  17.1129,  18.4798, -20.2511,  21.9375, -16.8463],\n",
      "        [ 21.8835,  16.9538,  18.1774, -20.4437,  21.6779, -16.8107],\n",
      "        [ 22.6106,  17.2835,  18.2994, -20.3310,  21.8303, -17.2289]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8482491970062256\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2999, 17.2739, 18.1972],\n",
      "        [22.2531, 16.5941, 17.9262],\n",
      "        [21.9097, 17.1368, 18.0075],\n",
      "        [22.1167, 16.7086, 17.3864],\n",
      "        [22.1241, 17.2683, 18.0794],\n",
      "        [22.6511, 17.3081, 18.2310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.8785, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4040,  21.8445, -17.1413],\n",
      "        [-20.2835,  21.2387, -16.7107],\n",
      "        [-20.7207,  22.0082, -17.0360],\n",
      "        [-20.2888,  21.7467, -16.9451],\n",
      "        [-19.8537,  21.0176, -16.6388],\n",
      "        [-20.4242,  22.0205, -17.1425]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2999,  17.2739,  18.1972, -20.4040,  21.8445, -17.1413],\n",
      "        [ 22.2531,  16.5941,  17.9262, -20.2835,  21.2387, -16.7107],\n",
      "        [ 21.9097,  17.1368,  18.0075, -20.7207,  22.0082, -17.0360],\n",
      "        [ 22.1167,  16.7086,  17.3864, -20.2888,  21.7467, -16.9451],\n",
      "        [ 22.1241,  17.2683,  18.0794, -19.8537,  21.0176, -16.6388],\n",
      "        [ 22.6511,  17.3081,  18.2310, -20.4242,  22.0205, -17.1425]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8632497787475586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9777, 16.8663, 18.2849],\n",
      "        [21.9272, 16.7433, 17.8918],\n",
      "        [22.1384, 17.5473, 18.0223],\n",
      "        [22.2378, 16.7367, 18.0934],\n",
      "        [21.5191, 15.9575, 17.5655],\n",
      "        [21.7562, 17.1894, 18.0387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2909,  21.4961, -16.6850],\n",
      "        [-19.7919,  21.4616, -17.1566],\n",
      "        [-20.5625,  21.8508, -17.2654],\n",
      "        [-20.5115,  21.8320, -17.1577],\n",
      "        [-20.8449,  22.6752, -17.5038],\n",
      "        [-19.9732,  21.2561, -16.7566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9777,  16.8663,  18.2849, -20.2909,  21.4961, -16.6850],\n",
      "        [ 21.9272,  16.7433,  17.8918, -19.7919,  21.4616, -17.1566],\n",
      "        [ 22.1384,  17.5473,  18.0223, -20.5625,  21.8508, -17.2654],\n",
      "        [ 22.2378,  16.7367,  18.0934, -20.5115,  21.8320, -17.1577],\n",
      "        [ 21.5191,  15.9575,  17.5655, -20.8449,  22.6752, -17.5038],\n",
      "        [ 21.7562,  17.1894,  18.0387, -19.9732,  21.2561, -16.7566]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8177406787872314\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.7405, 17.0787, 17.6976],\n",
      "        [22.1429, 16.5343, 18.3146],\n",
      "        [22.5880, 17.0434, 18.0445],\n",
      "        [22.1397, 17.0824, 17.9603],\n",
      "        [22.3585, 16.9857, 18.3439],\n",
      "        [22.3220, 17.0970, 17.9892]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.7061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6412,  21.9357, -17.3854],\n",
      "        [-20.6296,  22.0251, -17.0631],\n",
      "        [-20.1236,  21.8232, -17.1650],\n",
      "        [-20.2204,  21.4343, -16.7599],\n",
      "        [-20.6663,  22.2509, -17.0995],\n",
      "        [-20.4069,  21.8518, -16.9885]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.7405,  17.0787,  17.6976, -20.6412,  21.9357, -17.3854],\n",
      "        [ 22.1429,  16.5343,  18.3146, -20.6296,  22.0251, -17.0631],\n",
      "        [ 22.5880,  17.0434,  18.0445, -20.1236,  21.8232, -17.1650],\n",
      "        [ 22.1397,  17.0824,  17.9603, -20.2204,  21.4343, -16.7599],\n",
      "        [ 22.3585,  16.9857,  18.3439, -20.6663,  22.2509, -17.0995],\n",
      "        [ 22.3220,  17.0970,  17.9892, -20.4069,  21.8518, -16.9885]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.829265832901001\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7124, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2121, 17.2337, 18.3495],\n",
      "        [22.2703, 16.9845, 18.1211],\n",
      "        [22.0589, 16.5313, 18.0612],\n",
      "        [22.3784, 16.8037, 18.0452],\n",
      "        [22.0420, 16.6328, 18.1365],\n",
      "        [22.1394, 16.7854, 17.4535]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.0968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7170,  21.8345, -17.2748],\n",
      "        [-20.4021,  21.8030, -16.4568],\n",
      "        [-20.4186,  21.8579, -17.2456],\n",
      "        [-20.0145,  21.5960, -16.8939],\n",
      "        [-20.0638,  21.4967, -16.6370],\n",
      "        [-20.2802,  21.6574, -16.9192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2121,  17.2337,  18.3495, -20.7170,  21.8345, -17.2748],\n",
      "        [ 22.2703,  16.9845,  18.1211, -20.4021,  21.8030, -16.4568],\n",
      "        [ 22.0589,  16.5313,  18.0612, -20.4186,  21.8579, -17.2456],\n",
      "        [ 22.3784,  16.8037,  18.0452, -20.0145,  21.5960, -16.8939],\n",
      "        [ 22.0420,  16.6328,  18.1365, -20.0638,  21.4967, -16.6370],\n",
      "        [ 22.1394,  16.7854,  17.4535, -20.2802,  21.6574, -16.9192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.879875898361206\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1431, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4301, 16.7434, 18.3368],\n",
      "        [21.9704, 16.8850, 18.1013],\n",
      "        [21.3408, 16.2287, 17.5816],\n",
      "        [22.1833, 17.4531, 17.9550],\n",
      "        [21.7398, 16.8165, 17.7463],\n",
      "        [21.8611, 16.6046, 17.8737]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.3738, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.9856,  21.2574, -16.6135],\n",
      "        [-20.3540,  21.5675, -16.8867],\n",
      "        [-19.7583,  21.0146, -16.6644],\n",
      "        [-20.7899,  21.9007, -17.1612],\n",
      "        [-20.6004,  21.8865, -16.9603],\n",
      "        [-20.7397,  22.0650, -16.9527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4301,  16.7434,  18.3368, -19.9856,  21.2574, -16.6135],\n",
      "        [ 21.9704,  16.8850,  18.1013, -20.3540,  21.5675, -16.8867],\n",
      "        [ 21.3408,  16.2287,  17.5816, -19.7583,  21.0146, -16.6644],\n",
      "        [ 22.1833,  17.4531,  17.9550, -20.7899,  21.9007, -17.1612],\n",
      "        [ 21.7398,  16.8165,  17.7463, -20.6004,  21.8865, -16.9603],\n",
      "        [ 21.8611,  16.6046,  17.8737, -20.7397,  22.0650, -16.9527]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.825270414352417\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.9465, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9440, 16.7013, 17.8638],\n",
      "        [21.8205, 15.9376, 17.5833],\n",
      "        [22.1928, 16.9570, 18.3121],\n",
      "        [22.1112, 17.0613, 17.9246],\n",
      "        [21.6230, 16.7643, 17.8104],\n",
      "        [22.4388, 16.9421, 17.9373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1766, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8910,  21.4956, -17.4388],\n",
      "        [-20.7241,  21.9594, -17.3209],\n",
      "        [-20.6108,  22.0079, -16.8945],\n",
      "        [-20.3362,  21.4516, -16.8711],\n",
      "        [-20.7865,  22.1094, -17.8881],\n",
      "        [-20.2126,  21.7768, -17.0697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9440,  16.7013,  17.8638, -20.8910,  21.4956, -17.4388],\n",
      "        [ 21.8205,  15.9376,  17.5833, -20.7241,  21.9594, -17.3209],\n",
      "        [ 22.1928,  16.9570,  18.3121, -20.6108,  22.0079, -16.8945],\n",
      "        [ 22.1112,  17.0613,  17.9246, -20.3362,  21.4516, -16.8711],\n",
      "        [ 21.6230,  16.7643,  17.8104, -20.7865,  22.1094, -17.8881],\n",
      "        [ 22.4388,  16.9421,  17.9373, -20.2126,  21.7768, -17.0697]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8343396186828613\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0951, 17.0586, 18.2309],\n",
      "        [22.5636, 17.2071, 18.1130],\n",
      "        [22.0978, 16.5648, 17.9897],\n",
      "        [21.8708, 16.7679, 18.1316],\n",
      "        [22.2128, 16.8770, 18.5184],\n",
      "        [22.7775, 17.2789, 18.3443]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2341, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2384,  21.9117, -17.0270],\n",
      "        [-21.0507,  22.2424, -17.5015],\n",
      "        [-20.6145,  22.1806, -17.2884],\n",
      "        [-20.0687,  21.2467, -16.7945],\n",
      "        [-20.4032,  21.6200, -16.9157],\n",
      "        [-20.4531,  21.5247, -16.8423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0951,  17.0586,  18.2309, -20.2384,  21.9117, -17.0270],\n",
      "        [ 22.5636,  17.2071,  18.1130, -21.0507,  22.2424, -17.5015],\n",
      "        [ 22.0978,  16.5648,  17.9897, -20.6145,  22.1806, -17.2884],\n",
      "        [ 21.8708,  16.7679,  18.1316, -20.0687,  21.2467, -16.7945],\n",
      "        [ 22.2128,  16.8770,  18.5184, -20.4032,  21.6200, -16.9157],\n",
      "        [ 22.7775,  17.2789,  18.3443, -20.4531,  21.5247, -16.8423]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8528997898101807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1860, 16.6664, 17.8490],\n",
      "        [22.5433, 17.4904, 18.7732],\n",
      "        [22.2677, 16.9525, 18.2360],\n",
      "        [22.1515, 16.8209, 18.1965],\n",
      "        [22.3917, 17.3163, 18.1793],\n",
      "        [22.0736, 16.7956, 17.7040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.3730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5035,  21.5291, -16.5457],\n",
      "        [-21.0493,  22.3812, -17.6384],\n",
      "        [-20.3104,  21.8009, -16.8249],\n",
      "        [-20.7573,  22.1659, -17.4164],\n",
      "        [-20.3002,  22.0278, -17.1820],\n",
      "        [-20.8996,  22.0621, -17.3079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1860,  16.6664,  17.8490, -20.5035,  21.5291, -16.5457],\n",
      "        [ 22.5433,  17.4904,  18.7732, -21.0493,  22.3812, -17.6384],\n",
      "        [ 22.2677,  16.9525,  18.2360, -20.3104,  21.8009, -16.8249],\n",
      "        [ 22.1515,  16.8209,  18.1965, -20.7573,  22.1659, -17.4164],\n",
      "        [ 22.3917,  17.3163,  18.1793, -20.3002,  22.0278, -17.1820],\n",
      "        [ 22.0736,  16.7956,  17.7040, -20.8996,  22.0621, -17.3079]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8181324005126953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9075, 17.2294, 17.7099],\n",
      "        [22.1248, 16.6666, 17.7497],\n",
      "        [21.7703, 16.7385, 17.4397],\n",
      "        [21.8173, 16.8353, 18.0209],\n",
      "        [22.1443, 16.7993, 18.1968],\n",
      "        [22.6789, 17.0102, 18.3505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.6701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8657,  21.7842, -17.3986],\n",
      "        [-20.3174,  21.7949, -16.9307],\n",
      "        [-20.3676,  21.3839, -16.7467],\n",
      "        [-20.3646,  21.6368, -17.2559],\n",
      "        [-20.3353,  21.7769, -17.0794],\n",
      "        [-20.5540,  21.9480, -17.2222]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9075,  17.2294,  17.7099, -20.8657,  21.7842, -17.3986],\n",
      "        [ 22.1248,  16.6666,  17.7497, -20.3174,  21.7949, -16.9307],\n",
      "        [ 21.7703,  16.7385,  17.4397, -20.3676,  21.3839, -16.7467],\n",
      "        [ 21.8173,  16.8353,  18.0209, -20.3646,  21.6368, -17.2559],\n",
      "        [ 22.1443,  16.7993,  18.1968, -20.3353,  21.7769, -17.0794],\n",
      "        [ 22.6789,  17.0102,  18.3505, -20.5540,  21.9480, -17.2222]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.8532912731170654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5416, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4704, 17.3218, 18.1223],\n",
      "        [22.4116, 16.8363, 17.9655],\n",
      "        [22.6615, 17.3305, 18.5010],\n",
      "        [22.2103, 17.1491, 17.8876],\n",
      "        [22.1256, 17.0850, 18.3323],\n",
      "        [21.3341, 16.5737, 17.8595]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5043,  21.6268, -16.9269],\n",
      "        [-20.7204,  21.6040, -16.7949],\n",
      "        [-20.5095,  21.8663, -17.3261],\n",
      "        [-20.5561,  21.6366, -16.9820],\n",
      "        [-20.3852,  21.7281, -17.1789],\n",
      "        [-20.6468,  21.8397, -17.2721]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4704,  17.3218,  18.1223, -20.5043,  21.6268, -16.9269],\n",
      "        [ 22.4116,  16.8363,  17.9655, -20.7204,  21.6040, -16.7949],\n",
      "        [ 22.6615,  17.3305,  18.5010, -20.5095,  21.8663, -17.3261],\n",
      "        [ 22.2103,  17.1491,  17.8876, -20.5561,  21.6366, -16.9820],\n",
      "        [ 22.1256,  17.0850,  18.3323, -20.3852,  21.7281, -17.1789],\n",
      "        [ 21.3341,  16.5737,  17.8595, -20.6468,  21.8397, -17.2721]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8753862380981445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9566, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4559, 16.9198, 18.0810],\n",
      "        [22.2989, 16.6725, 17.9073],\n",
      "        [22.2985, 17.5533, 18.1111],\n",
      "        [22.2294, 17.0348, 17.9661],\n",
      "        [22.3855, 17.3121, 18.2065],\n",
      "        [22.5837, 17.1554, 18.1743]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.1919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7452,  21.9469, -17.1121],\n",
      "        [-20.1483,  21.7556, -17.0895],\n",
      "        [-20.5316,  21.3565, -17.0688],\n",
      "        [-21.0127,  21.8810, -17.4050],\n",
      "        [-20.4358,  21.8056, -16.9570],\n",
      "        [-20.1049,  21.6325, -16.8467]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4559,  16.9198,  18.0810, -20.7452,  21.9469, -17.1121],\n",
      "        [ 22.2989,  16.6725,  17.9073, -20.1483,  21.7556, -17.0895],\n",
      "        [ 22.2985,  17.5533,  18.1111, -20.5316,  21.3565, -17.0688],\n",
      "        [ 22.2294,  17.0348,  17.9661, -21.0127,  21.8810, -17.4050],\n",
      "        [ 22.3855,  17.3121,  18.2065, -20.4358,  21.8056, -16.9570],\n",
      "        [ 22.5837,  17.1554,  18.1743, -20.1049,  21.6325, -16.8467]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8837075233459473\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5084, 17.0123, 17.9835],\n",
      "        [22.1491, 16.7929, 17.9635],\n",
      "        [22.0871, 17.2051, 18.3029],\n",
      "        [21.8844, 16.4448, 17.7674],\n",
      "        [22.3480, 16.8523, 18.3117],\n",
      "        [21.7923, 16.7761, 17.6724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5271,  22.0058, -17.0600],\n",
      "        [-20.6131,  21.9702, -17.5448],\n",
      "        [-20.5992,  21.3327, -17.0322],\n",
      "        [-21.1111,  22.2767, -17.3102],\n",
      "        [-20.3835,  22.3432, -17.2590],\n",
      "        [-20.5225,  21.8227, -17.2562]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5084,  17.0123,  17.9835, -20.5271,  22.0058, -17.0600],\n",
      "        [ 22.1491,  16.7929,  17.9635, -20.6131,  21.9702, -17.5448],\n",
      "        [ 22.0871,  17.2051,  18.3029, -20.5992,  21.3327, -17.0322],\n",
      "        [ 21.8844,  16.4448,  17.7674, -21.1111,  22.2767, -17.3102],\n",
      "        [ 22.3480,  16.8523,  18.3117, -20.3835,  22.3432, -17.2590],\n",
      "        [ 21.7923,  16.7761,  17.6724, -20.5225,  21.8227, -17.2562]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8811144828796387\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8708, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5360, 17.4275, 18.1310],\n",
      "        [22.2241, 17.1494, 18.4595],\n",
      "        [22.3319, 16.7534, 17.5970],\n",
      "        [22.1385, 16.5658, 17.5064],\n",
      "        [22.2350, 17.2051, 18.2932],\n",
      "        [22.0589, 16.6381, 17.7293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9662, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0111,  22.0472, -17.5320],\n",
      "        [-19.6027,  21.8399, -16.9815],\n",
      "        [-20.2985,  21.2266, -16.6916],\n",
      "        [-20.4260,  22.0083, -17.3819],\n",
      "        [-20.4655,  21.8260, -17.1665],\n",
      "        [-20.4954,  21.6085, -16.9144]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5360,  17.4275,  18.1310, -21.0111,  22.0472, -17.5320],\n",
      "        [ 22.2241,  17.1494,  18.4595, -19.6027,  21.8399, -16.9815],\n",
      "        [ 22.3319,  16.7534,  17.5970, -20.2985,  21.2266, -16.6916],\n",
      "        [ 22.1385,  16.5658,  17.5064, -20.4260,  22.0083, -17.3819],\n",
      "        [ 22.2350,  17.2051,  18.2932, -20.4655,  21.8260, -17.1665],\n",
      "        [ 22.0589,  16.6381,  17.7293, -20.4954,  21.6085, -16.9144]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9267196655273438\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9912, 16.9952, 18.2249],\n",
      "        [22.6001, 17.0204, 18.1350],\n",
      "        [22.4530, 16.9349, 18.2542],\n",
      "        [22.0845, 16.6519, 17.5965],\n",
      "        [21.9740, 16.7585, 18.1340],\n",
      "        [22.0765, 16.8472, 17.7526]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.3565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5099,  21.9120, -17.2163],\n",
      "        [-20.3482,  21.6234, -16.8190],\n",
      "        [-20.7729,  21.7586, -17.1010],\n",
      "        [-20.7434,  21.7918, -17.0001],\n",
      "        [-20.7353,  22.0888, -17.6132],\n",
      "        [-20.6359,  21.7259, -17.1984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9912,  16.9952,  18.2249, -20.5099,  21.9120, -17.2163],\n",
      "        [ 22.6001,  17.0204,  18.1350, -20.3482,  21.6234, -16.8190],\n",
      "        [ 22.4530,  16.9349,  18.2542, -20.7729,  21.7586, -17.1010],\n",
      "        [ 22.0845,  16.6519,  17.5965, -20.7434,  21.7918, -17.0001],\n",
      "        [ 21.9740,  16.7585,  18.1340, -20.7353,  22.0888, -17.6132],\n",
      "        [ 22.0765,  16.8472,  17.7526, -20.6359,  21.7259, -17.1984]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8684659004211426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4544, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1677, 17.3914, 18.0545],\n",
      "        [22.1078, 16.4716, 17.9034],\n",
      "        [22.1403, 17.1923, 18.2965],\n",
      "        [22.4567, 16.9103, 17.9648],\n",
      "        [22.7365, 17.3528, 18.5585],\n",
      "        [21.7677, 16.7214, 18.0460]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.1028, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9890,  21.8582, -17.1013],\n",
      "        [-20.5011,  22.3026, -16.9846],\n",
      "        [-20.3970,  21.9711, -17.3343],\n",
      "        [-20.8347,  21.8943, -17.2509],\n",
      "        [-21.0093,  21.8489, -17.3108],\n",
      "        [-20.9502,  21.9478, -17.3360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1677,  17.3914,  18.0545, -20.9890,  21.8582, -17.1013],\n",
      "        [ 22.1078,  16.4716,  17.9034, -20.5011,  22.3026, -16.9846],\n",
      "        [ 22.1403,  17.1923,  18.2965, -20.3970,  21.9711, -17.3343],\n",
      "        [ 22.4567,  16.9103,  17.9648, -20.8347,  21.8943, -17.2509],\n",
      "        [ 22.7365,  17.3528,  18.5585, -21.0093,  21.8489, -17.3108],\n",
      "        [ 21.7677,  16.7214,  18.0460, -20.9502,  21.9478, -17.3360]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.8923745155334473\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8647, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9959, 16.9195, 17.7819],\n",
      "        [21.7787, 16.7321, 17.7438],\n",
      "        [22.0014, 17.2496, 18.0256],\n",
      "        [22.1827, 16.8324, 17.9035],\n",
      "        [22.2584, 17.0065, 18.2884],\n",
      "        [21.9082, 16.6412, 18.1383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.4721, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6212,  22.1393, -17.3296],\n",
      "        [-20.8298,  21.9668, -17.1534],\n",
      "        [-20.6081,  22.3204, -17.1387],\n",
      "        [-20.5929,  21.8252, -17.1583],\n",
      "        [-20.7110,  21.6305, -17.0927],\n",
      "        [-20.3795,  22.1178, -17.6158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9959,  16.9195,  17.7819, -20.6212,  22.1393, -17.3296],\n",
      "        [ 21.7787,  16.7321,  17.7438, -20.8298,  21.9668, -17.1534],\n",
      "        [ 22.0014,  17.2496,  18.0256, -20.6081,  22.3204, -17.1387],\n",
      "        [ 22.1827,  16.8324,  17.9035, -20.5929,  21.8252, -17.1583],\n",
      "        [ 22.2584,  17.0065,  18.2884, -20.7110,  21.6305, -17.0927],\n",
      "        [ 21.9082,  16.6412,  18.1383, -20.3795,  22.1178, -17.6158]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8647780418395996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5150, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2335, 17.0827, 18.0492],\n",
      "        [22.0739, 16.9172, 18.3390],\n",
      "        [22.3920, 17.0852, 18.1520],\n",
      "        [22.8013, 17.3073, 18.4076],\n",
      "        [22.0355, 16.7615, 18.4147],\n",
      "        [22.0327, 17.0068, 17.7965]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4796,  21.9248, -16.9053],\n",
      "        [-20.6243,  21.5456, -16.9545],\n",
      "        [-21.2695,  22.3452, -17.3400],\n",
      "        [-20.9744,  21.8722, -17.4766],\n",
      "        [-20.4112,  21.7137, -17.0133],\n",
      "        [-20.1152,  21.7938, -16.7839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2335,  17.0827,  18.0492, -20.4796,  21.9248, -16.9053],\n",
      "        [ 22.0739,  16.9172,  18.3390, -20.6243,  21.5456, -16.9545],\n",
      "        [ 22.3920,  17.0852,  18.1520, -21.2695,  22.3452, -17.3400],\n",
      "        [ 22.8013,  17.3073,  18.4076, -20.9744,  21.8722, -17.4766],\n",
      "        [ 22.0355,  16.7615,  18.4147, -20.4112,  21.7137, -17.0133],\n",
      "        [ 22.0327,  17.0068,  17.7965, -20.1152,  21.7938, -16.7839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.873063564300537\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6269, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6564, 16.8062, 17.5336],\n",
      "        [22.1595, 17.0474, 18.0440],\n",
      "        [22.1781, 16.5789, 17.7530],\n",
      "        [21.8883, 16.6197, 17.6599],\n",
      "        [21.9223, 16.8471, 17.8776],\n",
      "        [22.1044, 17.0063, 18.2924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.7354, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3075,  21.1567, -16.5363],\n",
      "        [-20.4454,  21.7664, -17.3183],\n",
      "        [-20.5655,  21.5527, -17.0576],\n",
      "        [-20.4196,  21.7590, -17.2771],\n",
      "        [-21.0348,  22.4242, -17.9814],\n",
      "        [-20.7976,  21.9544, -17.3426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6564,  16.8062,  17.5336, -20.3075,  21.1567, -16.5363],\n",
      "        [ 22.1595,  17.0474,  18.0440, -20.4454,  21.7664, -17.3183],\n",
      "        [ 22.1781,  16.5789,  17.7530, -20.5655,  21.5527, -17.0576],\n",
      "        [ 21.8883,  16.6197,  17.6599, -20.4196,  21.7590, -17.2771],\n",
      "        [ 21.9223,  16.8471,  17.8776, -21.0348,  22.4242, -17.9814],\n",
      "        [ 22.1044,  17.0063,  18.2924, -20.7976,  21.9544, -17.3426]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8305978775024414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2860, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3317, 16.8227, 18.2509],\n",
      "        [21.7920, 16.5489, 18.0211],\n",
      "        [22.7522, 17.1357, 18.3331],\n",
      "        [22.3033, 16.9062, 17.7091],\n",
      "        [22.7331, 17.5210, 18.4096],\n",
      "        [21.7173, 16.9516, 17.9668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.8573, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5518,  21.9739, -17.2494],\n",
      "        [-20.2581,  21.6675, -16.7667],\n",
      "        [-21.3045,  22.5010, -17.8325],\n",
      "        [-20.9462,  22.1680, -17.1733],\n",
      "        [-20.5430,  21.8355, -17.3309],\n",
      "        [-20.6640,  21.7168, -16.6688]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3317,  16.8227,  18.2509, -20.5518,  21.9739, -17.2494],\n",
      "        [ 21.7920,  16.5489,  18.0211, -20.2581,  21.6675, -16.7667],\n",
      "        [ 22.7522,  17.1357,  18.3331, -21.3045,  22.5010, -17.8325],\n",
      "        [ 22.3033,  16.9062,  17.7091, -20.9462,  22.1680, -17.1733],\n",
      "        [ 22.7331,  17.5210,  18.4096, -20.5430,  21.8355, -17.3309],\n",
      "        [ 21.7173,  16.9516,  17.9668, -20.6640,  21.7168, -16.6688]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.892468214035034\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4326, 17.1068, 18.3002],\n",
      "        [22.3592, 16.9582, 18.0262],\n",
      "        [21.8993, 16.7836, 18.4672],\n",
      "        [22.5841, 17.3724, 18.5801],\n",
      "        [22.5016, 16.9531, 17.9930],\n",
      "        [22.1020, 16.6672, 18.1356]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.0603, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4776,  21.9488, -17.3428],\n",
      "        [-20.6207,  22.0127, -17.5793],\n",
      "        [-20.0583,  21.7767, -17.2124],\n",
      "        [-20.7046,  22.1821, -17.5945],\n",
      "        [-21.0940,  22.2718, -17.7586],\n",
      "        [-20.5106,  22.0200, -17.4088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4326,  17.1068,  18.3002, -20.4776,  21.9488, -17.3428],\n",
      "        [ 22.3592,  16.9582,  18.0262, -20.6207,  22.0127, -17.5793],\n",
      "        [ 21.8993,  16.7836,  18.4672, -20.0583,  21.7767, -17.2124],\n",
      "        [ 22.5841,  17.3724,  18.5801, -20.7046,  22.1821, -17.5945],\n",
      "        [ 22.5016,  16.9531,  17.9930, -21.0940,  22.2718, -17.7586],\n",
      "        [ 22.1020,  16.6672,  18.1356, -20.5106,  22.0200, -17.4088]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9081006050109863\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4471, 17.2426, 17.8228],\n",
      "        [22.2049, 17.0455, 17.8558],\n",
      "        [22.4076, 17.0693, 17.7063],\n",
      "        [22.4492, 17.4333, 18.5582],\n",
      "        [21.6674, 17.0546, 17.9972],\n",
      "        [22.4246, 17.2409, 17.8083]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8666,  22.0919, -17.4665],\n",
      "        [-20.8272,  22.1175, -17.2779],\n",
      "        [-20.8449,  22.2866, -17.6038],\n",
      "        [-21.1573,  22.1366, -17.2947],\n",
      "        [-20.5624,  22.2068, -17.4408],\n",
      "        [-20.8897,  22.3381, -17.5322]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4471,  17.2426,  17.8228, -20.8666,  22.0919, -17.4665],\n",
      "        [ 22.2049,  17.0455,  17.8558, -20.8272,  22.1175, -17.2779],\n",
      "        [ 22.4076,  17.0693,  17.7063, -20.8449,  22.2866, -17.6038],\n",
      "        [ 22.4492,  17.4333,  18.5582, -21.1573,  22.1366, -17.2947],\n",
      "        [ 21.6674,  17.0546,  17.9972, -20.5624,  22.2068, -17.4408],\n",
      "        [ 22.4246,  17.2409,  17.8083, -20.8897,  22.3381, -17.5322]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.913505792617798\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1470, 17.0352, 18.0458],\n",
      "        [22.7819, 17.5077, 18.2378],\n",
      "        [22.5632, 17.1612, 18.5086],\n",
      "        [21.9783, 17.0303, 17.7136],\n",
      "        [22.7607, 16.8987, 18.4490],\n",
      "        [21.4351, 16.3696, 17.6683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7408,  21.7886, -17.1006],\n",
      "        [-20.3497,  21.8320, -17.3393],\n",
      "        [-20.5313,  22.0923, -17.4126],\n",
      "        [-20.5753,  22.1066, -17.0697],\n",
      "        [-20.5928,  21.8093, -17.4520],\n",
      "        [-20.4750,  21.8412, -17.2796]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1470,  17.0352,  18.0458, -20.7408,  21.7886, -17.1006],\n",
      "        [ 22.7819,  17.5077,  18.2378, -20.3497,  21.8320, -17.3393],\n",
      "        [ 22.5632,  17.1612,  18.5086, -20.5313,  22.0923, -17.4126],\n",
      "        [ 21.9783,  17.0303,  17.7136, -20.5753,  22.1066, -17.0697],\n",
      "        [ 22.7607,  16.8987,  18.4490, -20.5928,  21.8093, -17.4520],\n",
      "        [ 21.4351,  16.3696,  17.6683, -20.4750,  21.8412, -17.2796]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.8826563358306885\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4771, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9773, 16.8833, 18.2091],\n",
      "        [22.3913, 17.1852, 17.8675],\n",
      "        [22.2454, 17.2900, 18.3023],\n",
      "        [22.0434, 17.1206, 17.7964],\n",
      "        [22.1751, 17.0070, 18.4536],\n",
      "        [22.6682, 17.1030, 18.3276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8232,  22.1784, -17.5395],\n",
      "        [-20.9890,  21.9565, -17.2560],\n",
      "        [-20.3584,  21.5851, -17.2324],\n",
      "        [-20.4264,  21.9948, -17.2412],\n",
      "        [-20.3959,  21.6663, -17.1858],\n",
      "        [-20.6094,  21.5068, -17.4326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9773,  16.8833,  18.2091, -20.8232,  22.1784, -17.5395],\n",
      "        [ 22.3913,  17.1852,  17.8675, -20.9890,  21.9565, -17.2560],\n",
      "        [ 22.2454,  17.2900,  18.3023, -20.3584,  21.5851, -17.2324],\n",
      "        [ 22.0434,  17.1206,  17.7964, -20.4264,  21.9948, -17.2412],\n",
      "        [ 22.1751,  17.0070,  18.4536, -20.3959,  21.6663, -17.1858],\n",
      "        [ 22.6682,  17.1030,  18.3276, -20.6094,  21.5068, -17.4326]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.901965618133545\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0640, 17.2095, 17.9698],\n",
      "        [22.4899, 17.2033, 18.4657],\n",
      "        [22.4271, 17.3207, 17.8800],\n",
      "        [22.2410, 17.1380, 18.3499],\n",
      "        [22.4810, 17.0482, 18.4211],\n",
      "        [22.3429, 17.0401, 18.3967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5213, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8031,  22.4306, -17.6739],\n",
      "        [-20.3754,  21.9957, -17.2915],\n",
      "        [-20.7338,  22.1465, -17.4558],\n",
      "        [-20.9639,  22.4070, -17.3680],\n",
      "        [-20.6426,  22.0432, -17.2017],\n",
      "        [-20.6925,  21.8132, -16.8011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0640,  17.2095,  17.9698, -20.8031,  22.4306, -17.6739],\n",
      "        [ 22.4899,  17.2033,  18.4657, -20.3754,  21.9957, -17.2915],\n",
      "        [ 22.4271,  17.3207,  17.8800, -20.7338,  22.1465, -17.4558],\n",
      "        [ 22.2410,  17.1380,  18.3499, -20.9639,  22.4070, -17.3680],\n",
      "        [ 22.4810,  17.0482,  18.4211, -20.6426,  22.0432, -17.2017],\n",
      "        [ 22.3429,  17.0401,  18.3967, -20.6925,  21.8132, -16.8011]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.917659044265747\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4380, 16.9675, 18.4825],\n",
      "        [22.1421, 17.2259, 18.3936],\n",
      "        [22.1978, 16.9767, 18.2106],\n",
      "        [21.8509, 16.5413, 18.1473],\n",
      "        [22.2511, 16.9615, 18.0921],\n",
      "        [21.7355, 16.3431, 17.7222]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1487, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.3746,  21.6175, -16.5291],\n",
      "        [-20.9414,  22.3426, -17.3620],\n",
      "        [-20.6996,  22.3420, -17.1512],\n",
      "        [-20.8006,  21.5577, -17.2164],\n",
      "        [-20.7588,  22.0106, -17.6593],\n",
      "        [-20.8475,  22.2248, -17.2142]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4380,  16.9675,  18.4825, -20.3746,  21.6175, -16.5291],\n",
      "        [ 22.1421,  17.2259,  18.3936, -20.9414,  22.3426, -17.3620],\n",
      "        [ 22.1978,  16.9767,  18.2106, -20.6996,  22.3420, -17.1512],\n",
      "        [ 21.8509,  16.5413,  18.1473, -20.8006,  21.5577, -17.2164],\n",
      "        [ 22.2511,  16.9615,  18.0921, -20.7588,  22.0106, -17.6593],\n",
      "        [ 21.7355,  16.3431,  17.7222, -20.8475,  22.2248, -17.2142]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.888392448425293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4766, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4284, 17.2133, 18.2334],\n",
      "        [22.6374, 17.3785, 18.4999],\n",
      "        [22.3606, 16.4985, 17.6633],\n",
      "        [22.5730, 17.0155, 18.5035],\n",
      "        [22.3398, 17.2815, 18.2319],\n",
      "        [22.5303, 17.4814, 18.2788]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6250,  22.0141, -17.2241],\n",
      "        [-20.7613,  21.7687, -17.4946],\n",
      "        [-20.5852,  21.9879, -17.1664],\n",
      "        [-20.5716,  22.2428, -17.4162],\n",
      "        [-20.4008,  21.7205, -16.8617],\n",
      "        [-20.3124,  21.8118, -17.0029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4284,  17.2133,  18.2334, -20.6250,  22.0141, -17.2241],\n",
      "        [ 22.6374,  17.3785,  18.4999, -20.7613,  21.7687, -17.4946],\n",
      "        [ 22.3606,  16.4985,  17.6633, -20.5852,  21.9879, -17.1664],\n",
      "        [ 22.5730,  17.0155,  18.5035, -20.5716,  22.2428, -17.4162],\n",
      "        [ 22.3398,  17.2815,  18.2319, -20.4008,  21.7205, -16.8617],\n",
      "        [ 22.5303,  17.4814,  18.2788, -20.3124,  21.8118, -17.0029]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.921175003051758\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4164, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6772, 17.4969, 18.7117],\n",
      "        [21.8044, 16.4373, 17.6289],\n",
      "        [21.6748, 16.9679, 18.5230],\n",
      "        [22.2147, 17.3379, 18.1985],\n",
      "        [22.0160, 16.7824, 18.1780],\n",
      "        [22.1743, 17.2174, 17.8163]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.4182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-19.7900,  21.6054, -16.7089],\n",
      "        [-20.1102,  21.9564, -17.0373],\n",
      "        [-20.9223,  22.1719, -17.3441],\n",
      "        [-20.5048,  22.0185, -17.4949],\n",
      "        [-20.4411,  21.9253, -16.9300],\n",
      "        [-20.5101,  22.5533, -17.5599]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6772,  17.4969,  18.7117, -19.7900,  21.6054, -16.7089],\n",
      "        [ 21.8044,  16.4373,  17.6289, -20.1102,  21.9564, -17.0373],\n",
      "        [ 21.6748,  16.9679,  18.5230, -20.9223,  22.1719, -17.3441],\n",
      "        [ 22.2147,  17.3379,  18.1985, -20.5048,  22.0185, -17.4949],\n",
      "        [ 22.0160,  16.7824,  18.1780, -20.4411,  21.9253, -16.9300],\n",
      "        [ 22.1743,  17.2174,  17.8163, -20.5101,  22.5533, -17.5599]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.9142279624938965\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6710, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4562, 17.0564, 17.9221],\n",
      "        [22.2569, 17.2941, 18.4238],\n",
      "        [22.4698, 17.4452, 18.4900],\n",
      "        [21.8040, 17.2505, 17.8919],\n",
      "        [22.3285, 17.5974, 18.6300],\n",
      "        [22.4095, 17.2643, 18.0572]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.1904, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.2022,  21.8754, -17.0343],\n",
      "        [-21.0054,  22.7270, -17.5438],\n",
      "        [-20.9782,  22.3492, -17.7077],\n",
      "        [-20.8082,  22.2461, -17.2433],\n",
      "        [-20.9015,  21.8560, -17.0496],\n",
      "        [-20.7390,  21.9598, -16.9926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4562,  17.0564,  17.9221, -20.2022,  21.8754, -17.0343],\n",
      "        [ 22.2569,  17.2941,  18.4238, -21.0054,  22.7270, -17.5438],\n",
      "        [ 22.4698,  17.4452,  18.4900, -20.9782,  22.3492, -17.7077],\n",
      "        [ 21.8040,  17.2505,  17.8919, -20.8082,  22.2461, -17.2433],\n",
      "        [ 22.3285,  17.5974,  18.6300, -20.9015,  21.8560, -17.0496],\n",
      "        [ 22.4095,  17.2643,  18.0572, -20.7390,  21.9598, -16.9926]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.888524293899536\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2416, 17.4975, 17.8912],\n",
      "        [21.9967, 16.7931, 18.0326],\n",
      "        [22.4538, 17.1410, 18.0774],\n",
      "        [22.2353, 17.2321, 18.0422],\n",
      "        [22.3484, 16.9208, 18.1605],\n",
      "        [22.8820, 17.4369, 18.8146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9702, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8848,  22.1204, -17.6560],\n",
      "        [-20.3141,  21.8453, -16.7122],\n",
      "        [-20.1129,  21.6460, -17.1980],\n",
      "        [-20.8881,  21.9973, -17.3410],\n",
      "        [-20.5167,  21.6052, -16.8635],\n",
      "        [-20.8098,  22.1179, -17.7337]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2416,  17.4975,  17.8912, -20.8848,  22.1204, -17.6560],\n",
      "        [ 21.9967,  16.7931,  18.0326, -20.3141,  21.8453, -16.7122],\n",
      "        [ 22.4538,  17.1410,  18.0774, -20.1129,  21.6460, -17.1980],\n",
      "        [ 22.2353,  17.2321,  18.0422, -20.8881,  21.9973, -17.3410],\n",
      "        [ 22.3484,  16.9208,  18.1605, -20.5167,  21.6052, -16.8635],\n",
      "        [ 22.8820,  17.4369,  18.8146, -20.8098,  22.1179, -17.7337]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.931640625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1469, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3072, 16.8784, 18.1432],\n",
      "        [21.9828, 16.8137, 17.7962],\n",
      "        [22.4485, 16.8222, 18.6499],\n",
      "        [22.6884, 17.2059, 18.4497],\n",
      "        [22.4040, 16.9856, 18.6514],\n",
      "        [22.6584, 17.3879, 18.6213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9374,  22.3256, -17.4902],\n",
      "        [-20.2128,  21.1499, -16.6604],\n",
      "        [-20.4130,  21.8513, -17.5933],\n",
      "        [-20.9314,  22.5633, -17.4312],\n",
      "        [-20.8049,  22.1057, -17.3927],\n",
      "        [-20.7080,  22.0798, -17.0849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3072,  16.8784,  18.1432, -20.9374,  22.3256, -17.4902],\n",
      "        [ 21.9828,  16.8137,  17.7962, -20.2128,  21.1499, -16.6604],\n",
      "        [ 22.4485,  16.8222,  18.6499, -20.4130,  21.8513, -17.5933],\n",
      "        [ 22.6884,  17.2059,  18.4497, -20.9314,  22.5633, -17.4312],\n",
      "        [ 22.4040,  16.9856,  18.6514, -20.8049,  22.1057, -17.3927],\n",
      "        [ 22.6584,  17.3879,  18.6213, -20.7080,  22.0798, -17.0849]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.932642936706543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0432, 16.6025, 17.4327],\n",
      "        [22.2740, 17.1942, 18.5233],\n",
      "        [22.6036, 17.6685, 18.0071],\n",
      "        [22.5690, 17.5553, 18.4418],\n",
      "        [22.7845, 17.6577, 18.4986],\n",
      "        [22.9408, 17.7417, 17.8453]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9726,  21.9266, -17.3489],\n",
      "        [-21.1898,  22.2541, -17.6961],\n",
      "        [-20.7163,  22.3468, -17.4812],\n",
      "        [-20.9471,  22.0202, -17.4882],\n",
      "        [-20.4321,  21.7624, -17.0540],\n",
      "        [-20.8245,  21.9668, -17.3371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0432,  16.6025,  17.4327, -20.9726,  21.9266, -17.3489],\n",
      "        [ 22.2740,  17.1942,  18.5233, -21.1898,  22.2541, -17.6961],\n",
      "        [ 22.6036,  17.6685,  18.0071, -20.7163,  22.3468, -17.4812],\n",
      "        [ 22.5690,  17.5553,  18.4418, -20.9471,  22.0202, -17.4882],\n",
      "        [ 22.7845,  17.6577,  18.4986, -20.4321,  21.7624, -17.0540],\n",
      "        [ 22.9408,  17.7417,  17.8453, -20.8245,  21.9668, -17.3371]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.871281147003174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5915, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4863, 16.9402, 18.2540],\n",
      "        [22.0090, 17.3146, 18.1323],\n",
      "        [22.5895, 17.0248, 17.8829],\n",
      "        [22.4815, 17.2718, 18.3140],\n",
      "        [21.7328, 16.8178, 17.9842],\n",
      "        [22.7077, 17.1690, 18.1879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.5917, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2555,  22.2221, -17.2561],\n",
      "        [-20.8192,  22.3165, -17.4384],\n",
      "        [-20.2239,  21.7219, -16.9562],\n",
      "        [-20.5553,  21.8969, -17.2590],\n",
      "        [-20.8065,  21.6965, -17.3540],\n",
      "        [-20.6402,  21.8483, -17.1327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4863,  16.9402,  18.2540, -21.2555,  22.2221, -17.2561],\n",
      "        [ 22.0090,  17.3146,  18.1323, -20.8192,  22.3165, -17.4384],\n",
      "        [ 22.5895,  17.0248,  17.8829, -20.2239,  21.7219, -16.9562],\n",
      "        [ 22.4815,  17.2718,  18.3140, -20.5553,  21.8969, -17.2590],\n",
      "        [ 21.7328,  16.8178,  17.9842, -20.8065,  21.6965, -17.3540],\n",
      "        [ 22.7077,  17.1690,  18.1879, -20.6402,  21.8483, -17.1327]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9511983394622803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5266, 17.5370, 18.4729],\n",
      "        [22.6500, 17.3005, 18.1222],\n",
      "        [22.7595, 17.4905, 18.7873],\n",
      "        [23.0514, 17.6440, 18.7835],\n",
      "        [22.8484, 17.4015, 18.3628],\n",
      "        [22.6284, 17.0176, 18.5153]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2744, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5973,  22.0518, -17.2838],\n",
      "        [-20.9731,  22.6173, -18.0094],\n",
      "        [-20.8009,  22.6319, -17.6336],\n",
      "        [-20.7551,  22.1321, -17.4307],\n",
      "        [-21.2109,  22.5144, -17.6500],\n",
      "        [-20.4707,  21.8052, -16.9892]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5266,  17.5370,  18.4729, -20.5973,  22.0518, -17.2838],\n",
      "        [ 22.6500,  17.3005,  18.1222, -20.9731,  22.6173, -18.0094],\n",
      "        [ 22.7595,  17.4905,  18.7873, -20.8009,  22.6319, -17.6336],\n",
      "        [ 23.0514,  17.6440,  18.7835, -20.7551,  22.1321, -17.4307],\n",
      "        [ 22.8484,  17.4015,  18.3628, -21.2109,  22.5144, -17.6500],\n",
      "        [ 22.6284,  17.0176,  18.5153, -20.4707,  21.8052, -16.9892]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.957214832305908\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7443, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6914, 17.1671, 18.3460],\n",
      "        [22.2611, 17.2705, 17.8016],\n",
      "        [22.9540, 17.2027, 18.3526],\n",
      "        [22.4225, 17.2496, 18.1908],\n",
      "        [21.7096, 16.8217, 17.9993],\n",
      "        [22.1818, 17.0830, 17.9736]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6545, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8181,  22.2216, -17.2372],\n",
      "        [-21.4574,  22.6808, -17.9832],\n",
      "        [-20.5986,  22.1871, -17.1093],\n",
      "        [-21.4436,  22.4059, -18.0749],\n",
      "        [-20.8871,  22.1144, -17.6246],\n",
      "        [-20.1787,  21.5638, -16.9323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6914,  17.1671,  18.3460, -20.8181,  22.2216, -17.2372],\n",
      "        [ 22.2611,  17.2705,  17.8016, -21.4574,  22.6808, -17.9832],\n",
      "        [ 22.9540,  17.2027,  18.3526, -20.5986,  22.1871, -17.1093],\n",
      "        [ 22.4225,  17.2496,  18.1908, -21.4436,  22.4059, -18.0749],\n",
      "        [ 21.7096,  16.8217,  17.9993, -20.8871,  22.1144, -17.6246],\n",
      "        [ 22.1818,  17.0830,  17.9736, -20.1787,  21.5638, -16.9323]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9615259170532227\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3735, 17.2072, 18.1206],\n",
      "        [22.6850, 17.3041, 18.0396],\n",
      "        [22.2246, 17.3039, 18.1140],\n",
      "        [22.6552, 17.1394, 17.9834],\n",
      "        [21.8509, 16.3926, 17.7243],\n",
      "        [22.5387, 17.1232, 18.1076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.5742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8109,  21.8456, -17.4761],\n",
      "        [-21.2106,  22.3649, -17.5347],\n",
      "        [-21.3407,  22.7764, -17.6478],\n",
      "        [-20.8311,  22.2896, -17.4657],\n",
      "        [-20.8442,  21.9285, -17.0905],\n",
      "        [-20.8923,  21.9860, -17.0714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3735,  17.2072,  18.1206, -20.8109,  21.8456, -17.4761],\n",
      "        [ 22.6850,  17.3041,  18.0396, -21.2106,  22.3649, -17.5347],\n",
      "        [ 22.2246,  17.3039,  18.1140, -21.3407,  22.7764, -17.6478],\n",
      "        [ 22.6552,  17.1394,  17.9834, -20.8311,  22.2896, -17.4657],\n",
      "        [ 21.8509,  16.3926,  17.7243, -20.8442,  21.9285, -17.0905],\n",
      "        [ 22.5387,  17.1232,  18.1076, -20.8923,  21.9860, -17.0714]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.933624744415283\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1603, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.0360, 17.1484, 18.2143],\n",
      "        [22.3377, 17.2907, 18.0217],\n",
      "        [22.7730, 17.4664, 18.5459],\n",
      "        [21.9496, 16.5939, 17.5989],\n",
      "        [22.5140, 17.3020, 18.5730],\n",
      "        [22.0358, 16.6152, 17.4966]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4882, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9277,  22.1693, -17.3258],\n",
      "        [-20.3207,  21.7420, -16.9472],\n",
      "        [-20.6425,  22.0079, -17.2802],\n",
      "        [-21.1234,  22.5273, -17.8044],\n",
      "        [-20.2332,  21.1719, -16.7457],\n",
      "        [-21.2611,  22.5153, -17.7356]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.0360,  17.1484,  18.2143, -20.9277,  22.1693, -17.3258],\n",
      "        [ 22.3377,  17.2907,  18.0217, -20.3207,  21.7420, -16.9472],\n",
      "        [ 22.7730,  17.4664,  18.5459, -20.6425,  22.0079, -17.2802],\n",
      "        [ 21.9496,  16.5939,  17.5989, -21.1234,  22.5273, -17.8044],\n",
      "        [ 22.5140,  17.3020,  18.5730, -20.2332,  21.1719, -16.7457],\n",
      "        [ 22.0358,  16.6152,  17.4966, -21.2611,  22.5153, -17.7356]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.93076753616333\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3390, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2522, 16.9445, 18.0676],\n",
      "        [22.1085, 16.8403, 18.4533],\n",
      "        [22.3085, 16.8525, 18.0771],\n",
      "        [22.0197, 16.8448, 18.0918],\n",
      "        [22.7483, 17.2535, 18.5218],\n",
      "        [22.2156, 17.0232, 17.8517]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6999,  21.8607, -17.6761],\n",
      "        [-20.1752,  21.6531, -17.0045],\n",
      "        [-21.1895,  22.1625, -17.9289],\n",
      "        [-20.8488,  22.0713, -17.2349],\n",
      "        [-20.9151,  21.8110, -17.3001],\n",
      "        [-20.2691,  21.8371, -16.8490]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2522,  16.9445,  18.0676, -20.6999,  21.8607, -17.6761],\n",
      "        [ 22.1085,  16.8403,  18.4533, -20.1752,  21.6531, -17.0045],\n",
      "        [ 22.3085,  16.8525,  18.0771, -21.1895,  22.1625, -17.9289],\n",
      "        [ 22.0197,  16.8448,  18.0918, -20.8488,  22.0713, -17.2349],\n",
      "        [ 22.7483,  17.2535,  18.5218, -20.9151,  21.8110, -17.3001],\n",
      "        [ 22.2156,  17.0232,  17.8517, -20.2691,  21.8371, -16.8490]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.923001766204834\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9814, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5842, 17.3454, 18.1277],\n",
      "        [22.6951, 17.3291, 18.5809],\n",
      "        [22.3230, 17.3783, 17.6870],\n",
      "        [23.2330, 17.4602, 18.6148],\n",
      "        [22.3377, 17.2398, 18.4290],\n",
      "        [22.3356, 17.4884, 18.1443]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6739, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9645,  22.5624, -17.3750],\n",
      "        [-20.9696,  22.2262, -17.4725],\n",
      "        [-20.6083,  22.1521, -17.4214],\n",
      "        [-20.4807,  22.0795, -17.1250],\n",
      "        [-21.1627,  22.2075, -17.4534],\n",
      "        [-20.7509,  21.8508, -17.3014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5842,  17.3454,  18.1277, -20.9645,  22.5624, -17.3750],\n",
      "        [ 22.6951,  17.3291,  18.5809, -20.9696,  22.2262, -17.4725],\n",
      "        [ 22.3230,  17.3783,  17.6870, -20.6083,  22.1521, -17.4214],\n",
      "        [ 23.2330,  17.4602,  18.6148, -20.4807,  22.0795, -17.1250],\n",
      "        [ 22.3377,  17.2398,  18.4290, -21.1627,  22.2075, -17.4534],\n",
      "        [ 22.3356,  17.4884,  18.1443, -20.7509,  21.8508, -17.3014]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.976764678955078\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7577, 17.4007, 18.2637],\n",
      "        [22.3227, 17.3548, 18.4816],\n",
      "        [21.8529, 16.9740, 18.2303],\n",
      "        [22.3507, 17.3271, 18.1385],\n",
      "        [22.6963, 17.4017, 18.1231],\n",
      "        [22.7195, 17.1831, 18.6741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.1535, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2330,  22.5314, -17.7635],\n",
      "        [-20.8240,  21.8864, -17.4427],\n",
      "        [-20.6113,  22.1283, -17.3807],\n",
      "        [-20.8189,  21.8633, -17.1195],\n",
      "        [-21.0429,  22.5131, -17.8355],\n",
      "        [-21.4472,  22.0214, -17.5944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7577,  17.4007,  18.2637, -21.2330,  22.5314, -17.7635],\n",
      "        [ 22.3227,  17.3548,  18.4816, -20.8240,  21.8864, -17.4427],\n",
      "        [ 21.8529,  16.9740,  18.2303, -20.6113,  22.1283, -17.3807],\n",
      "        [ 22.3507,  17.3271,  18.1385, -20.8189,  21.8633, -17.1195],\n",
      "        [ 22.6963,  17.4017,  18.1231, -21.0429,  22.5131, -17.8355],\n",
      "        [ 22.7195,  17.1831,  18.6741, -21.4472,  22.0214, -17.5944]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.009000301361084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4829, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6050, 17.4389, 18.5936],\n",
      "        [22.4155, 17.3387, 18.3745],\n",
      "        [22.8977, 16.9496, 18.2586],\n",
      "        [22.3808, 17.4816, 18.6827],\n",
      "        [22.7143, 17.0445, 18.1793],\n",
      "        [22.9707, 17.5487, 18.6373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9392, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2417,  22.3550, -17.5806],\n",
      "        [-20.6270,  22.1922, -17.1104],\n",
      "        [-20.9734,  22.2557, -17.6437],\n",
      "        [-20.9994,  22.0058, -17.1241],\n",
      "        [-20.7889,  21.6516, -17.0507],\n",
      "        [-20.6675,  22.1931, -17.4049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6050,  17.4389,  18.5936, -21.2417,  22.3550, -17.5806],\n",
      "        [ 22.4155,  17.3387,  18.3745, -20.6270,  22.1922, -17.1104],\n",
      "        [ 22.8977,  16.9496,  18.2586, -20.9734,  22.2557, -17.6437],\n",
      "        [ 22.3808,  17.4816,  18.6827, -20.9994,  22.0058, -17.1241],\n",
      "        [ 22.7143,  17.0445,  18.1793, -20.7889,  21.6516, -17.0507],\n",
      "        [ 22.9707,  17.5487,  18.6373, -20.6675,  22.1931, -17.4049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.008115768432617\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4047, 17.1518, 18.0927],\n",
      "        [22.7538, 17.2351, 18.0432],\n",
      "        [22.6890, 17.3565, 18.2845],\n",
      "        [22.4310, 17.4753, 18.2014],\n",
      "        [21.9714, 17.0684, 18.2034],\n",
      "        [22.2563, 17.1765, 17.7489]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1316,  22.2465, -17.7695],\n",
      "        [-20.8150,  21.5376, -17.3638],\n",
      "        [-21.0650,  21.8190, -17.4582],\n",
      "        [-20.7331,  21.9642, -17.5534],\n",
      "        [-20.6133,  22.4915, -17.5141],\n",
      "        [-21.1351,  21.9888, -17.3405]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4047,  17.1518,  18.0927, -21.1316,  22.2465, -17.7695],\n",
      "        [ 22.7538,  17.2351,  18.0432, -20.8150,  21.5376, -17.3638],\n",
      "        [ 22.6890,  17.3565,  18.2845, -21.0650,  21.8190, -17.4582],\n",
      "        [ 22.4310,  17.4753,  18.2014, -20.7331,  21.9642, -17.5534],\n",
      "        [ 21.9714,  17.0684,  18.2034, -20.6133,  22.4915, -17.5141],\n",
      "        [ 22.2563,  17.1765,  17.7489, -21.1351,  21.9888, -17.3405]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9697179794311523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1809, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4284, 17.6240, 18.1296],\n",
      "        [22.5481, 17.2188, 18.2841],\n",
      "        [22.4428, 17.3325, 18.5128],\n",
      "        [22.4323, 17.3135, 18.3252],\n",
      "        [22.4127, 17.1625, 18.7033],\n",
      "        [21.9038, 16.6645, 17.6409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7609,  22.2686, -17.5944],\n",
      "        [-20.6978,  22.1436, -17.0542],\n",
      "        [-20.4659,  21.8914, -17.1129],\n",
      "        [-20.8832,  22.5020, -17.5122],\n",
      "        [-21.0684,  21.4404, -17.0354],\n",
      "        [-20.5187,  21.9945, -17.0200]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4284,  17.6240,  18.1296, -20.7609,  22.2686, -17.5944],\n",
      "        [ 22.5481,  17.2188,  18.2841, -20.6978,  22.1436, -17.0542],\n",
      "        [ 22.4428,  17.3325,  18.5128, -20.4659,  21.8914, -17.1129],\n",
      "        [ 22.4323,  17.3135,  18.3252, -20.8832,  22.5020, -17.5122],\n",
      "        [ 22.4127,  17.1625,  18.7033, -21.0684,  21.4404, -17.0354],\n",
      "        [ 21.9038,  16.6645,  17.6409, -20.5187,  21.9945, -17.0200]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9737191200256348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6153, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7080, 17.5275, 18.5681],\n",
      "        [22.6966, 17.3105, 18.1397],\n",
      "        [22.7417, 17.3131, 18.3461],\n",
      "        [22.5656, 17.4296, 18.3105],\n",
      "        [22.0779, 17.0935, 18.1965],\n",
      "        [22.2430, 17.3275, 18.1505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8907,  22.3355, -17.5620],\n",
      "        [-20.9078,  22.4969, -17.5101],\n",
      "        [-21.1384,  22.2780, -17.6116],\n",
      "        [-21.0168,  22.0956, -17.6423],\n",
      "        [-20.8189,  22.0531, -17.6116],\n",
      "        [-20.5070,  21.5560, -16.9315]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7080,  17.5275,  18.5681, -20.8907,  22.3355, -17.5620],\n",
      "        [ 22.6966,  17.3105,  18.1397, -20.9078,  22.4969, -17.5101],\n",
      "        [ 22.7417,  17.3131,  18.3461, -21.1384,  22.2780, -17.6116],\n",
      "        [ 22.5656,  17.4296,  18.3105, -21.0168,  22.0956, -17.6423],\n",
      "        [ 22.0779,  17.0935,  18.1965, -20.8189,  22.0531, -17.6116],\n",
      "        [ 22.2430,  17.3275,  18.1505, -20.5070,  21.5560, -16.9315]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.008403778076172\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8748, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3434, 17.4804, 18.1361],\n",
      "        [22.6376, 16.9907, 18.2168],\n",
      "        [22.5383, 17.0629, 18.0054],\n",
      "        [22.0675, 17.1680, 18.2155],\n",
      "        [22.1014, 17.0028, 18.4066],\n",
      "        [22.7269, 16.7124, 18.3598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.2984, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9052,  21.8042, -17.2798],\n",
      "        [-20.8679,  22.2729, -17.1747],\n",
      "        [-21.1511,  21.9181, -17.5440],\n",
      "        [-20.6123,  21.9643, -17.0132],\n",
      "        [-20.7013,  21.9547, -17.1467],\n",
      "        [-20.9037,  22.2138, -17.5564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3434,  17.4804,  18.1361, -20.9052,  21.8042, -17.2798],\n",
      "        [ 22.6376,  16.9907,  18.2168, -20.8679,  22.2729, -17.1747],\n",
      "        [ 22.5383,  17.0629,  18.0054, -21.1511,  21.9181, -17.5440],\n",
      "        [ 22.0675,  17.1680,  18.2155, -20.6123,  21.9643, -17.0132],\n",
      "        [ 22.1014,  17.0028,  18.4066, -20.7013,  21.9547, -17.1467],\n",
      "        [ 22.7269,  16.7124,  18.3598, -20.9037,  22.2138, -17.5564]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9517173767089844\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6132, 17.1942, 17.8972],\n",
      "        [22.6910, 17.5318, 18.1217],\n",
      "        [22.1927, 17.2130, 18.2294],\n",
      "        [22.0477, 17.1009, 17.9246],\n",
      "        [22.1113, 17.0193, 17.7461],\n",
      "        [22.5218, 17.2482, 18.2857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.5131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0413,  22.2717, -17.4556],\n",
      "        [-20.5905,  22.4027, -17.6980],\n",
      "        [-21.1696,  22.6692, -17.8884],\n",
      "        [-21.1060,  22.3279, -17.6471],\n",
      "        [-20.5791,  21.9817, -17.4989],\n",
      "        [-20.1277,  21.8916, -17.0644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6132,  17.1942,  17.8972, -21.0413,  22.2717, -17.4556],\n",
      "        [ 22.6910,  17.5318,  18.1217, -20.5905,  22.4027, -17.6980],\n",
      "        [ 22.1927,  17.2130,  18.2294, -21.1696,  22.6692, -17.8884],\n",
      "        [ 22.0477,  17.1009,  17.9246, -21.1060,  22.3279, -17.6471],\n",
      "        [ 22.1113,  17.0193,  17.7461, -20.5791,  21.9817, -17.4989],\n",
      "        [ 22.5218,  17.2482,  18.2857, -20.1277,  21.8916, -17.0644]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-3.970778465270996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6407, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0925, 17.6230, 18.9577],\n",
      "        [22.5633, 17.2525, 18.6686],\n",
      "        [22.6778, 17.5091, 18.6331],\n",
      "        [22.6331, 17.0497, 18.2622],\n",
      "        [22.3271, 17.5066, 18.5267],\n",
      "        [22.6106, 17.2703, 18.3471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6028, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8297,  21.9749, -17.5015],\n",
      "        [-20.9185,  22.1242, -17.6908],\n",
      "        [-20.9398,  22.3006, -17.5550],\n",
      "        [-20.9448,  22.3687, -17.3085],\n",
      "        [-21.0309,  21.9239, -17.6105],\n",
      "        [-21.2316,  22.4493, -17.7346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0925,  17.6230,  18.9577, -20.8297,  21.9749, -17.5015],\n",
      "        [ 22.5633,  17.2525,  18.6686, -20.9185,  22.1242, -17.6908],\n",
      "        [ 22.6778,  17.5091,  18.6331, -20.9398,  22.3006, -17.5550],\n",
      "        [ 22.6331,  17.0497,  18.2622, -20.9448,  22.3687, -17.3085],\n",
      "        [ 22.3271,  17.5066,  18.5267, -21.0309,  21.9239, -17.6105],\n",
      "        [ 22.6106,  17.2703,  18.3471, -21.2316,  22.4493, -17.7346]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.035784721374512\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2224, 16.5368, 18.1167],\n",
      "        [22.8973, 17.4431, 18.5644],\n",
      "        [22.3993, 17.2039, 18.6642],\n",
      "        [22.3193, 17.3366, 18.3018],\n",
      "        [22.6399, 17.1521, 18.0661],\n",
      "        [22.5192, 17.9373, 18.4729]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.3285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.6703,  22.1950, -17.3276],\n",
      "        [-21.2659,  22.0196, -17.6830],\n",
      "        [-21.3540,  22.3220, -17.5310],\n",
      "        [-20.4930,  21.9066, -17.4541],\n",
      "        [-21.2879,  22.6787, -17.9012],\n",
      "        [-21.4888,  22.2895, -17.8325]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2224,  16.5368,  18.1167, -20.6703,  22.1950, -17.3276],\n",
      "        [ 22.8973,  17.4431,  18.5644, -21.2659,  22.0196, -17.6830],\n",
      "        [ 22.3993,  17.2039,  18.6642, -21.3540,  22.3220, -17.5310],\n",
      "        [ 22.3193,  17.3366,  18.3018, -20.4930,  21.9066, -17.4541],\n",
      "        [ 22.6399,  17.1521,  18.0661, -21.2879,  22.6787, -17.9012],\n",
      "        [ 22.5192,  17.9373,  18.4729, -21.4888,  22.2895, -17.8325]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.928927421569824\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7568, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6306, 17.5380, 18.4820],\n",
      "        [22.7082, 17.5662, 18.5503],\n",
      "        [22.5493, 17.4475, 18.7259],\n",
      "        [22.3701, 17.2075, 17.9568],\n",
      "        [22.6549, 17.3179, 18.3320],\n",
      "        [21.9696, 17.3208, 17.5560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.2164, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9075,  22.3479, -17.4720],\n",
      "        [-21.0549,  22.2423, -17.4326],\n",
      "        [-20.6472,  22.0026, -17.5057],\n",
      "        [-20.8128,  22.0186, -17.0375],\n",
      "        [-21.1083,  22.4918, -18.0282],\n",
      "        [-20.9826,  22.3290, -17.7564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6306,  17.5380,  18.4820, -20.9075,  22.3479, -17.4720],\n",
      "        [ 22.7082,  17.5662,  18.5503, -21.0549,  22.2423, -17.4326],\n",
      "        [ 22.5493,  17.4475,  18.7259, -20.6472,  22.0026, -17.5057],\n",
      "        [ 22.3701,  17.2075,  17.9568, -20.8128,  22.0186, -17.0375],\n",
      "        [ 22.6549,  17.3179,  18.3320, -21.1083,  22.4918, -18.0282],\n",
      "        [ 21.9696,  17.3208,  17.5560, -20.9826,  22.3290, -17.7564]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.008311748504639\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5200, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8632, 17.2946, 18.0794],\n",
      "        [22.4371, 17.4544, 18.6958],\n",
      "        [22.6604, 17.6016, 18.5350],\n",
      "        [22.4695, 17.2636, 18.5327],\n",
      "        [22.0390, 17.0872, 17.9175],\n",
      "        [22.6399, 17.3759, 18.0007]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2489, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.4426,  22.0187, -17.1238],\n",
      "        [-21.1763,  22.2052, -17.6075],\n",
      "        [-20.9995,  22.6554, -17.8539],\n",
      "        [-20.1378,  21.9183, -17.4085],\n",
      "        [-21.1705,  22.5370, -17.6784],\n",
      "        [-21.3161,  22.3818, -17.5580]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8632,  17.2946,  18.0794, -20.4426,  22.0187, -17.1238],\n",
      "        [ 22.4371,  17.4544,  18.6958, -21.1763,  22.2052, -17.6075],\n",
      "        [ 22.6604,  17.6016,  18.5350, -20.9995,  22.6554, -17.8539],\n",
      "        [ 22.4695,  17.2636,  18.5327, -20.1378,  21.9183, -17.4085],\n",
      "        [ 22.0390,  17.0872,  17.9175, -21.1705,  22.5370, -17.6784],\n",
      "        [ 22.6399,  17.3759,  18.0007, -21.3161,  22.3818, -17.5580]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.966991662979126\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4729, 17.1862, 18.7707],\n",
      "        [22.3270, 17.2758, 18.3436],\n",
      "        [22.5336, 17.4689, 18.4360],\n",
      "        [22.6276, 17.3602, 18.5580],\n",
      "        [22.5462, 17.2460, 18.2518],\n",
      "        [22.8403, 17.7503, 18.5328]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4609, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9404,  22.3244, -17.4041],\n",
      "        [-20.9941,  22.1979, -17.5277],\n",
      "        [-21.3293,  22.3636, -17.6146],\n",
      "        [-21.3126,  22.2519, -17.6968],\n",
      "        [-21.4577,  22.4396, -17.9795],\n",
      "        [-21.2193,  22.2452, -17.3656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4729,  17.1862,  18.7707, -20.9404,  22.3244, -17.4041],\n",
      "        [ 22.3270,  17.2758,  18.3436, -20.9941,  22.1979, -17.5277],\n",
      "        [ 22.5336,  17.4689,  18.4360, -21.3293,  22.3636, -17.6146],\n",
      "        [ 22.6276,  17.3602,  18.5580, -21.3126,  22.2519, -17.6968],\n",
      "        [ 22.5462,  17.2460,  18.2518, -21.4577,  22.4396, -17.9795],\n",
      "        [ 22.8403,  17.7503,  18.5328, -21.2193,  22.2452, -17.3656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.003800868988037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5405, 17.5592, 18.4336],\n",
      "        [22.4395, 17.2759, 18.6960],\n",
      "        [22.6618, 17.2198, 18.3379],\n",
      "        [22.6774, 17.1092, 18.5253],\n",
      "        [22.8485, 17.8082, 18.1559],\n",
      "        [22.2908, 17.2927, 18.3460]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8192, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0313,  22.2889, -17.6441],\n",
      "        [-21.0365,  22.3092, -17.4555],\n",
      "        [-21.0309,  22.5355, -17.9693],\n",
      "        [-21.0308,  22.7885, -17.8551],\n",
      "        [-21.4898,  22.4663, -17.9329],\n",
      "        [-21.0151,  22.3883, -17.3039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5405,  17.5592,  18.4336, -21.0313,  22.2889, -17.6441],\n",
      "        [ 22.4395,  17.2759,  18.6960, -21.0365,  22.3092, -17.4555],\n",
      "        [ 22.6618,  17.2198,  18.3379, -21.0309,  22.5355, -17.9693],\n",
      "        [ 22.6774,  17.1092,  18.5253, -21.0308,  22.7885, -17.8551],\n",
      "        [ 22.8485,  17.8082,  18.1559, -21.4898,  22.4663, -17.9329],\n",
      "        [ 22.2908,  17.2927,  18.3460, -21.0151,  22.3883, -17.3039]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.0129570960998535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6306, 17.7130, 18.3845],\n",
      "        [22.5393, 17.2048, 18.1126],\n",
      "        [22.1773, 17.0093, 18.4335],\n",
      "        [22.0967, 17.5257, 18.2710],\n",
      "        [22.1601, 16.6673, 18.2124],\n",
      "        [22.4941, 17.1893, 17.7192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8928, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0005,  22.2841, -17.3364],\n",
      "        [-20.4794,  21.7325, -17.2710],\n",
      "        [-20.7066,  22.1898, -17.7463],\n",
      "        [-20.7117,  22.2659, -17.5310],\n",
      "        [-21.0574,  22.2057, -17.4495],\n",
      "        [-21.2322,  22.4684, -17.5348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6306,  17.7130,  18.3845, -21.0005,  22.2841, -17.3364],\n",
      "        [ 22.5393,  17.2048,  18.1126, -20.4794,  21.7325, -17.2710],\n",
      "        [ 22.1773,  17.0093,  18.4335, -20.7066,  22.1898, -17.7463],\n",
      "        [ 22.0967,  17.5257,  18.2710, -20.7117,  22.2659, -17.5310],\n",
      "        [ 22.1601,  16.6673,  18.2124, -21.0574,  22.2057, -17.4495],\n",
      "        [ 22.4941,  17.1893,  17.7192, -21.2322,  22.4684, -17.5348]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.013471603393555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6857, 17.5110, 18.5569],\n",
      "        [22.6904, 17.1912, 18.6350],\n",
      "        [22.5490, 17.2899, 18.1708],\n",
      "        [21.9517, 17.0338, 18.3741],\n",
      "        [22.2375, 17.5363, 18.3740],\n",
      "        [22.3343, 17.0091, 17.7433]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6721, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5651,  22.2338, -17.2876],\n",
      "        [-20.4238,  21.4649, -16.7562],\n",
      "        [-20.1485,  21.8529, -17.1303],\n",
      "        [-21.1387,  22.6753, -17.6883],\n",
      "        [-20.2769,  22.0777, -17.4853],\n",
      "        [-20.9265,  22.2497, -17.5007]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6857,  17.5110,  18.5569, -20.5651,  22.2338, -17.2876],\n",
      "        [ 22.6904,  17.1912,  18.6350, -20.4238,  21.4649, -16.7562],\n",
      "        [ 22.5490,  17.2899,  18.1708, -20.1485,  21.8529, -17.1303],\n",
      "        [ 21.9517,  17.0338,  18.3741, -21.1387,  22.6753, -17.6883],\n",
      "        [ 22.2375,  17.5363,  18.3740, -20.2769,  22.0777, -17.4853],\n",
      "        [ 22.3343,  17.0091,  17.7433, -20.9265,  22.2497, -17.5007]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.003632545471191\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8142, 17.4904, 18.2426],\n",
      "        [22.7527, 17.9255, 18.6694],\n",
      "        [22.4548, 17.3768, 18.4776],\n",
      "        [22.8111, 17.5349, 18.7952],\n",
      "        [23.0339, 17.7202, 18.7146],\n",
      "        [22.1350, 17.3446, 17.8675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.7321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2163,  22.3545, -17.7287],\n",
      "        [-20.6641,  22.0213, -17.3500],\n",
      "        [-21.1238,  22.3234, -17.6644],\n",
      "        [-21.1865,  22.5461, -17.9599],\n",
      "        [-20.8567,  22.4038, -17.8006],\n",
      "        [-21.0846,  22.5481, -17.8335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8142,  17.4904,  18.2426, -21.2163,  22.3545, -17.7287],\n",
      "        [ 22.7527,  17.9255,  18.6694, -20.6641,  22.0213, -17.3500],\n",
      "        [ 22.4548,  17.3768,  18.4776, -21.1238,  22.3234, -17.6644],\n",
      "        [ 22.8111,  17.5349,  18.7952, -21.1865,  22.5461, -17.9599],\n",
      "        [ 23.0339,  17.7202,  18.7146, -20.8567,  22.4038, -17.8006],\n",
      "        [ 22.1350,  17.3446,  17.8675, -21.0846,  22.5481, -17.8335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.03061056137085\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6852, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1669, 17.0328, 18.2622],\n",
      "        [22.6054, 17.7203, 18.5768],\n",
      "        [22.8463, 17.5911, 18.5644],\n",
      "        [22.9248, 17.5270, 18.1643],\n",
      "        [22.4179, 16.8911, 18.4223],\n",
      "        [22.2645, 16.9939, 17.8016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8772, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1876,  23.0226, -17.8284],\n",
      "        [-20.6816,  21.8373, -17.4602],\n",
      "        [-21.0876,  22.2423, -17.4138],\n",
      "        [-20.8819,  22.1578, -17.3870],\n",
      "        [-20.8093,  22.1154, -17.5440],\n",
      "        [-21.6931,  22.6916, -17.7746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1669,  17.0328,  18.2622, -21.1876,  23.0226, -17.8284],\n",
      "        [ 22.6054,  17.7203,  18.5768, -20.6816,  21.8373, -17.4602],\n",
      "        [ 22.8463,  17.5911,  18.5644, -21.0876,  22.2423, -17.4138],\n",
      "        [ 22.9248,  17.5270,  18.1643, -20.8819,  22.1578, -17.3870],\n",
      "        [ 22.4179,  16.8911,  18.4223, -20.8093,  22.1154, -17.5440],\n",
      "        [ 22.2645,  16.9939,  17.8016, -21.6931,  22.6916, -17.7746]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.010317325592041\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5596, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4198, 16.9482, 17.8176],\n",
      "        [22.7691, 17.4511, 18.7852],\n",
      "        [22.3823, 17.2239, 17.9757],\n",
      "        [22.4432, 17.6832, 18.2060],\n",
      "        [22.2777, 17.4984, 18.3638],\n",
      "        [22.9387, 17.4834, 18.7738]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.3663, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8784,  22.3294, -17.8823],\n",
      "        [-21.0656,  22.0973, -17.7506],\n",
      "        [-20.6691,  22.2750, -17.6588],\n",
      "        [-21.3430,  22.1838, -17.8221],\n",
      "        [-21.0266,  22.5174, -17.7693],\n",
      "        [-21.3357,  22.5609, -17.7223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4198,  16.9482,  17.8176, -20.8784,  22.3294, -17.8823],\n",
      "        [ 22.7691,  17.4511,  18.7852, -21.0656,  22.0973, -17.7506],\n",
      "        [ 22.3823,  17.2239,  17.9757, -20.6691,  22.2750, -17.6588],\n",
      "        [ 22.4432,  17.6832,  18.2060, -21.3430,  22.1838, -17.8221],\n",
      "        [ 22.2777,  17.4984,  18.3638, -21.0266,  22.5174, -17.7693],\n",
      "        [ 22.9387,  17.4834,  18.7738, -21.3357,  22.5609, -17.7223]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9750614166259766\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7981, 17.5839, 18.3445],\n",
      "        [22.6529, 17.3210, 18.4194],\n",
      "        [22.6426, 17.5773, 18.2902],\n",
      "        [22.5155, 17.5097, 18.7691],\n",
      "        [23.2027, 17.7843, 18.9197],\n",
      "        [22.6117, 17.4866, 18.2382]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.4974, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7461,  21.7856, -17.4535],\n",
      "        [-21.2562,  22.5119, -18.3034],\n",
      "        [-21.3295,  22.7207, -18.0506],\n",
      "        [-20.8159,  22.4234, -17.6010],\n",
      "        [-20.5755,  21.6702, -17.3326],\n",
      "        [-20.6047,  22.0840, -17.2161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7981,  17.5839,  18.3445, -20.7461,  21.7856, -17.4535],\n",
      "        [ 22.6529,  17.3210,  18.4194, -21.2562,  22.5119, -18.3034],\n",
      "        [ 22.6426,  17.5773,  18.2902, -21.3295,  22.7207, -18.0506],\n",
      "        [ 22.5155,  17.5097,  18.7691, -20.8159,  22.4234, -17.6010],\n",
      "        [ 23.2027,  17.7843,  18.9197, -20.5755,  21.6702, -17.3326],\n",
      "        [ 22.6117,  17.4866,  18.2382, -20.6047,  22.0840, -17.2161]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.004147052764893\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5235, 17.2291, 17.9918],\n",
      "        [22.6031, 17.4152, 18.2814],\n",
      "        [22.7254, 17.7815, 18.7496],\n",
      "        [22.3174, 16.9915, 18.2590],\n",
      "        [22.6177, 17.4218, 18.5077],\n",
      "        [22.6112, 17.5000, 18.7105]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.9244, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3070,  22.5815, -17.7246],\n",
      "        [-21.2941,  22.4072, -17.3241],\n",
      "        [-21.1343,  22.4945, -18.0220],\n",
      "        [-20.3987,  22.0378, -17.3957],\n",
      "        [-20.9768,  22.2160, -17.7521],\n",
      "        [-21.0460,  22.4744, -17.8715]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5235,  17.2291,  17.9918, -21.3070,  22.5815, -17.7246],\n",
      "        [ 22.6031,  17.4152,  18.2814, -21.2941,  22.4072, -17.3241],\n",
      "        [ 22.7254,  17.7815,  18.7496, -21.1343,  22.4945, -18.0220],\n",
      "        [ 22.3174,  16.9915,  18.2590, -20.3987,  22.0378, -17.3957],\n",
      "        [ 22.6177,  17.4218,  18.5077, -20.9768,  22.2160, -17.7521],\n",
      "        [ 22.6112,  17.5000,  18.7105, -21.0460,  22.4744, -17.8715]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.014790058135986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4809, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9417, 17.9044, 18.4281],\n",
      "        [22.6721, 17.2970, 18.7075],\n",
      "        [22.2608, 17.2258, 18.2350],\n",
      "        [22.6293, 17.4578, 19.0309],\n",
      "        [22.4612, 17.4868, 18.4425],\n",
      "        [22.2312, 17.3793, 18.0749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.3822, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0741,  22.4273, -17.9617],\n",
      "        [-21.3626,  23.0617, -18.2576],\n",
      "        [-21.5255,  22.4999, -17.9595],\n",
      "        [-21.0241,  21.8896, -17.6285],\n",
      "        [-21.2290,  22.5447, -17.7767],\n",
      "        [-20.7307,  22.4255, -17.3686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9417,  17.9044,  18.4281, -21.0741,  22.4273, -17.9617],\n",
      "        [ 22.6721,  17.2970,  18.7075, -21.3626,  23.0617, -18.2576],\n",
      "        [ 22.2608,  17.2258,  18.2350, -21.5255,  22.4999, -17.9595],\n",
      "        [ 22.6293,  17.4578,  19.0309, -21.0241,  21.8896, -17.6285],\n",
      "        [ 22.4612,  17.4868,  18.4425, -21.2290,  22.5447, -17.7767],\n",
      "        [ 22.2312,  17.3793,  18.0749, -20.7307,  22.4255, -17.3686]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.067543029785156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6873, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7351, 17.4631, 18.5305],\n",
      "        [22.6732, 17.8540, 18.6823],\n",
      "        [22.5177, 17.0634, 18.1530],\n",
      "        [23.2586, 17.5453, 18.8565],\n",
      "        [23.0035, 17.5662, 18.9290],\n",
      "        [22.3797, 17.5102, 18.7338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.8374, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3421,  22.4680, -17.9718],\n",
      "        [-21.0028,  22.2984, -17.9791],\n",
      "        [-21.1721,  22.3455, -17.3050],\n",
      "        [-21.2288,  22.3211, -17.5177],\n",
      "        [-20.6022,  21.8201, -17.5304],\n",
      "        [-21.2264,  22.2688, -17.7124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7351,  17.4631,  18.5305, -21.3421,  22.4680, -17.9718],\n",
      "        [ 22.6732,  17.8540,  18.6823, -21.0028,  22.2984, -17.9791],\n",
      "        [ 22.5177,  17.0634,  18.1530, -21.1721,  22.3455, -17.3050],\n",
      "        [ 23.2586,  17.5453,  18.8565, -21.2288,  22.3211, -17.5177],\n",
      "        [ 23.0035,  17.5662,  18.9290, -20.6022,  21.8201, -17.5304],\n",
      "        [ 22.3797,  17.5102,  18.7338, -21.2264,  22.2688, -17.7124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.059528350830078\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4231, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7538, 17.6001, 18.5885],\n",
      "        [22.6245, 17.5682, 18.5220],\n",
      "        [22.3762, 17.1589, 18.2560],\n",
      "        [22.9761, 17.3465, 18.4814],\n",
      "        [23.0620, 17.8167, 18.8497],\n",
      "        [22.8128, 17.4869, 18.8605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.1872, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1024,  22.7147, -18.1624],\n",
      "        [-21.2021,  22.9509, -17.8592],\n",
      "        [-20.9597,  22.2964, -17.3152],\n",
      "        [-21.6255,  22.7892, -17.7683],\n",
      "        [-20.5146,  22.0487, -17.4484],\n",
      "        [-21.0988,  22.5837, -17.5596]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7538,  17.6001,  18.5885, -21.1024,  22.7147, -18.1624],\n",
      "        [ 22.6245,  17.5682,  18.5220, -21.2021,  22.9509, -17.8592],\n",
      "        [ 22.3762,  17.1589,  18.2560, -20.9597,  22.2964, -17.3152],\n",
      "        [ 22.9761,  17.3465,  18.4814, -21.6255,  22.7892, -17.7683],\n",
      "        [ 23.0620,  17.8167,  18.8497, -20.5146,  22.0487, -17.4484],\n",
      "        [ 22.8128,  17.4869,  18.8605, -21.0988,  22.5837, -17.5596]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.073369979858398\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9094, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5227, 17.5289, 18.5016],\n",
      "        [22.6906, 17.7869, 18.6523],\n",
      "        [22.7567, 17.4472, 18.0799],\n",
      "        [22.5904, 17.4131, 18.3888],\n",
      "        [22.3403, 17.3189, 18.2253],\n",
      "        [22.3969, 17.5622, 19.0005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8141, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8808,  22.3030, -17.6299],\n",
      "        [-21.3113,  22.9334, -17.8786],\n",
      "        [-20.5340,  21.6809, -17.2192],\n",
      "        [-21.2997,  22.6659, -17.6701],\n",
      "        [-20.9618,  22.5047, -17.7835],\n",
      "        [-21.2252,  22.0161, -17.7588]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5227,  17.5289,  18.5016, -20.8808,  22.3030, -17.6299],\n",
      "        [ 22.6906,  17.7869,  18.6523, -21.3113,  22.9334, -17.8786],\n",
      "        [ 22.7567,  17.4472,  18.0799, -20.5340,  21.6809, -17.2192],\n",
      "        [ 22.5904,  17.4131,  18.3888, -21.2997,  22.6659, -17.6701],\n",
      "        [ 22.3403,  17.3189,  18.2253, -20.9618,  22.5047, -17.7835],\n",
      "        [ 22.3969,  17.5622,  19.0005, -21.2252,  22.0161, -17.7588]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.027101516723633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8286, 17.8152, 18.4183],\n",
      "        [22.6605, 17.4163, 18.3308],\n",
      "        [22.6815, 17.5630, 18.2439],\n",
      "        [23.0054, 17.3797, 18.6139],\n",
      "        [23.3034, 17.7096, 18.8136],\n",
      "        [22.7628, 17.6831, 18.7005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.7179, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7510,  22.5027, -17.5036],\n",
      "        [-20.9640,  22.4756, -17.8273],\n",
      "        [-20.6512,  22.1125, -17.9155],\n",
      "        [-21.2704,  22.4411, -17.6906],\n",
      "        [-21.4463,  22.8323, -18.0625],\n",
      "        [-21.6576,  23.2029, -18.3111]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8286,  17.8152,  18.4183, -20.7510,  22.5027, -17.5036],\n",
      "        [ 22.6605,  17.4163,  18.3308, -20.9640,  22.4756, -17.8273],\n",
      "        [ 22.6815,  17.5630,  18.2439, -20.6512,  22.1125, -17.9155],\n",
      "        [ 23.0054,  17.3797,  18.6139, -21.2704,  22.4411, -17.6906],\n",
      "        [ 23.3034,  17.7096,  18.8136, -21.4463,  22.8323, -18.0625],\n",
      "        [ 22.7628,  17.6831,  18.7005, -21.6576,  23.2029, -18.3111]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.0481486320495605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7432, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.2683, 17.3424, 18.5646],\n",
      "        [22.5639, 17.4333, 18.3614],\n",
      "        [23.3157, 17.9319, 18.8566],\n",
      "        [22.6657, 17.5187, 18.8842],\n",
      "        [22.5873, 17.5779, 18.9323],\n",
      "        [22.4806, 17.1593, 18.3695]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3759, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0082,  22.3792, -17.8992],\n",
      "        [-21.1131,  22.6795, -17.5484],\n",
      "        [-21.0907,  22.6388, -17.9512],\n",
      "        [-21.3872,  22.5216, -17.9900],\n",
      "        [-21.3487,  22.7232, -17.5397],\n",
      "        [-21.6255,  23.1050, -17.8966]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.2683,  17.3424,  18.5646, -21.0082,  22.3792, -17.8992],\n",
      "        [ 22.5639,  17.4333,  18.3614, -21.1131,  22.6795, -17.5484],\n",
      "        [ 23.3157,  17.9319,  18.8566, -21.0907,  22.6388, -17.9512],\n",
      "        [ 22.6657,  17.5187,  18.8842, -21.3872,  22.5216, -17.9900],\n",
      "        [ 22.5873,  17.5779,  18.9323, -21.3487,  22.7232, -17.5397],\n",
      "        [ 22.4806,  17.1593,  18.3695, -21.6255,  23.1050, -17.8966]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.027082443237305\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7053, 17.1776, 18.7402],\n",
      "        [23.4040, 17.6926, 18.8291],\n",
      "        [22.6887, 17.3556, 18.5225],\n",
      "        [22.6237, 17.1995, 18.1704],\n",
      "        [22.9596, 17.5745, 18.8454],\n",
      "        [22.1602, 17.7959, 18.5524]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7497,  22.1567, -18.0486],\n",
      "        [-20.8184,  21.9616, -17.3145],\n",
      "        [-21.0701,  22.2685, -17.2988],\n",
      "        [-20.7126,  22.0683, -17.3420],\n",
      "        [-20.7136,  22.5952, -17.5864],\n",
      "        [-20.9920,  22.2027, -17.4304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7053,  17.1776,  18.7402, -20.7497,  22.1567, -18.0486],\n",
      "        [ 23.4040,  17.6926,  18.8291, -20.8184,  21.9616, -17.3145],\n",
      "        [ 22.6887,  17.3556,  18.5225, -21.0701,  22.2685, -17.2988],\n",
      "        [ 22.6237,  17.1995,  18.1704, -20.7126,  22.0683, -17.3420],\n",
      "        [ 22.9596,  17.5745,  18.8454, -20.7136,  22.5952, -17.5864],\n",
      "        [ 22.1602,  17.7959,  18.5524, -20.9920,  22.2027, -17.4304]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.041193962097168\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6087, 17.4884, 18.4245],\n",
      "        [22.5908, 17.3719, 18.6633],\n",
      "        [22.5246, 17.5001, 18.6050],\n",
      "        [22.6162, 17.6243, 18.9435],\n",
      "        [22.4954, 17.6811, 18.5622],\n",
      "        [22.7673, 17.3605, 18.6050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1355, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9973,  22.3566, -17.6642],\n",
      "        [-21.3312,  22.9105, -17.5231],\n",
      "        [-20.4162,  22.0533, -17.1900],\n",
      "        [-21.2079,  22.3041, -17.5112],\n",
      "        [-21.2086,  22.8522, -17.8627],\n",
      "        [-20.5127,  21.8108, -17.3229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6087,  17.4884,  18.4245, -20.9973,  22.3566, -17.6642],\n",
      "        [ 22.5908,  17.3719,  18.6633, -21.3312,  22.9105, -17.5231],\n",
      "        [ 22.5246,  17.5001,  18.6050, -20.4162,  22.0533, -17.1900],\n",
      "        [ 22.6162,  17.6243,  18.9435, -21.2079,  22.3041, -17.5112],\n",
      "        [ 22.4954,  17.6811,  18.5622, -21.2086,  22.8522, -17.8627],\n",
      "        [ 22.7673,  17.3605,  18.6050, -20.5127,  21.8108, -17.3229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.039142608642578\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5244, 17.2583, 18.0477],\n",
      "        [22.7842, 17.5979, 18.8387],\n",
      "        [23.1182, 17.6167, 18.5168],\n",
      "        [22.2495, 17.4303, 18.4890],\n",
      "        [22.5524, 17.5746, 18.6680],\n",
      "        [22.2530, 17.5391, 18.4318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2200, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3619,  22.8785, -17.8596],\n",
      "        [-20.8889,  21.9322, -17.6657],\n",
      "        [-21.2767,  22.7467, -17.9671],\n",
      "        [-20.8007,  22.1856, -17.5656],\n",
      "        [-21.1210,  22.5918, -17.6902],\n",
      "        [-21.0951,  22.6981, -17.8208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5244,  17.2583,  18.0477, -21.3619,  22.8785, -17.8596],\n",
      "        [ 22.7842,  17.5979,  18.8387, -20.8889,  21.9322, -17.6657],\n",
      "        [ 23.1182,  17.6167,  18.5168, -21.2767,  22.7467, -17.9671],\n",
      "        [ 22.2495,  17.4303,  18.4890, -20.8007,  22.1856, -17.5656],\n",
      "        [ 22.5524,  17.5746,  18.6680, -21.1210,  22.5918, -17.6902],\n",
      "        [ 22.2530,  17.5391,  18.4318, -21.0951,  22.6981, -17.8208]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.045965194702148\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6216, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.1040, 16.9645, 18.2667],\n",
      "        [22.6817, 17.5623, 18.3653],\n",
      "        [22.2554, 17.4343, 17.9838],\n",
      "        [22.0990, 17.5161, 18.0851],\n",
      "        [22.2852, 17.3579, 18.7097],\n",
      "        [22.2445, 17.3183, 18.1417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1169, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0530,  22.5051, -17.5365],\n",
      "        [-21.0190,  22.8711, -18.0542],\n",
      "        [-21.2799,  22.4565, -17.5017],\n",
      "        [-21.1810,  22.7119, -18.1181],\n",
      "        [-21.5528,  23.0362, -18.2449],\n",
      "        [-21.3771,  22.5750, -18.1358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.1040,  16.9645,  18.2667, -21.0530,  22.5051, -17.5365],\n",
      "        [ 22.6817,  17.5623,  18.3653, -21.0190,  22.8711, -18.0542],\n",
      "        [ 22.2554,  17.4343,  17.9838, -21.2799,  22.4565, -17.5017],\n",
      "        [ 22.0990,  17.5161,  18.0851, -21.1810,  22.7119, -18.1181],\n",
      "        [ 22.2852,  17.3579,  18.7097, -21.5528,  23.0362, -18.2449],\n",
      "        [ 22.2445,  17.3183,  18.1417, -21.3771,  22.5750, -18.1358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-3.9994847774505615\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8782, 17.9562, 18.7805],\n",
      "        [22.4319, 17.0101, 18.2276],\n",
      "        [22.6957, 17.5924, 18.7780],\n",
      "        [23.0716, 17.5116, 18.7720],\n",
      "        [22.9728, 17.3898, 18.9485],\n",
      "        [22.1013, 17.3767, 18.6628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.3505, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1172,  22.0011, -17.6643],\n",
      "        [-21.0435,  21.7082, -17.2625],\n",
      "        [-21.1619,  22.3336, -17.9631],\n",
      "        [-21.0928,  22.4334, -17.8100],\n",
      "        [-21.4275,  22.9103, -18.1712],\n",
      "        [-21.3180,  22.5950, -18.4148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8782,  17.9562,  18.7805, -21.1172,  22.0011, -17.6643],\n",
      "        [ 22.4319,  17.0101,  18.2276, -21.0435,  21.7082, -17.2625],\n",
      "        [ 22.6957,  17.5924,  18.7780, -21.1619,  22.3336, -17.9631],\n",
      "        [ 23.0716,  17.5116,  18.7720, -21.0928,  22.4334, -17.8100],\n",
      "        [ 22.9728,  17.3898,  18.9485, -21.4275,  22.9103, -18.1712],\n",
      "        [ 22.1013,  17.3767,  18.6628, -21.3180,  22.5950, -18.4148]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.077288627624512\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9256, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7001, 17.8893, 18.7522],\n",
      "        [22.6658, 17.2427, 18.6633],\n",
      "        [23.0499, 17.8303, 18.4532],\n",
      "        [22.9686, 17.6732, 18.0531],\n",
      "        [23.0861, 17.8003, 18.8845],\n",
      "        [22.0769, 17.4796, 18.3381]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.5334, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5034,  22.6603, -18.0027],\n",
      "        [-21.3794,  22.4931, -18.1915],\n",
      "        [-21.3135,  22.3372, -17.7699],\n",
      "        [-21.1757,  22.4062, -17.6986],\n",
      "        [-20.3798,  22.0174, -17.3406],\n",
      "        [-21.0101,  22.1653, -17.7704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7001,  17.8893,  18.7522, -21.5034,  22.6603, -18.0027],\n",
      "        [ 22.6658,  17.2427,  18.6633, -21.3794,  22.4931, -18.1915],\n",
      "        [ 23.0499,  17.8303,  18.4532, -21.3135,  22.3372, -17.7699],\n",
      "        [ 22.9686,  17.6732,  18.0531, -21.1757,  22.4062, -17.6986],\n",
      "        [ 23.0861,  17.8003,  18.8845, -20.3798,  22.0174, -17.3406],\n",
      "        [ 22.0769,  17.4796,  18.3381, -21.0101,  22.1653, -17.7704]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.106358528137207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4713, 17.1142, 18.1950],\n",
      "        [23.0798, 17.6354, 18.9314],\n",
      "        [23.1316, 17.7732, 18.8849],\n",
      "        [21.9247, 17.0767, 18.5494],\n",
      "        [22.6677, 17.9250, 18.2966],\n",
      "        [22.6153, 17.3336, 18.2872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.2498, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4685,  22.8199, -17.8521],\n",
      "        [-20.7755,  22.2598, -17.7597],\n",
      "        [-21.4671,  22.9012, -17.7221],\n",
      "        [-21.5845,  23.0978, -18.0526],\n",
      "        [-21.1199,  22.2471, -17.4308],\n",
      "        [-21.0252,  22.0557, -17.4888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4713,  17.1142,  18.1950, -21.4685,  22.8199, -17.8521],\n",
      "        [ 23.0798,  17.6354,  18.9314, -20.7755,  22.2598, -17.7597],\n",
      "        [ 23.1316,  17.7732,  18.8849, -21.4671,  22.9012, -17.7221],\n",
      "        [ 21.9247,  17.0767,  18.5494, -21.5845,  23.0978, -18.0526],\n",
      "        [ 22.6677,  17.9250,  18.2966, -21.1199,  22.2471, -17.4308],\n",
      "        [ 22.6153,  17.3336,  18.2872, -21.0252,  22.0557, -17.4888]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.052478790283203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4131, 16.9799, 18.3267],\n",
      "        [22.3405, 17.0591, 18.3265],\n",
      "        [22.4901, 17.2710, 18.3536],\n",
      "        [22.7215, 17.8111, 18.5376],\n",
      "        [22.6791, 17.3950, 17.9338],\n",
      "        [22.3495, 17.3186, 18.3872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.3114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2149,  22.6833, -17.8631],\n",
      "        [-20.8770,  22.1390, -17.3690],\n",
      "        [-21.0106,  22.2328, -17.4250],\n",
      "        [-20.9373,  22.3591, -17.3274],\n",
      "        [-20.9502,  22.0252, -17.6810],\n",
      "        [-20.8267,  22.1184, -17.4237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4131,  16.9799,  18.3267, -21.2149,  22.6833, -17.8631],\n",
      "        [ 22.3405,  17.0591,  18.3265, -20.8770,  22.1390, -17.3690],\n",
      "        [ 22.4901,  17.2710,  18.3536, -21.0106,  22.2328, -17.4250],\n",
      "        [ 22.7215,  17.8111,  18.5376, -20.9373,  22.3591, -17.3274],\n",
      "        [ 22.6791,  17.3950,  17.9338, -20.9502,  22.0252, -17.6810],\n",
      "        [ 22.3495,  17.3186,  18.3872, -20.8267,  22.1184, -17.4237]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.0412678718566895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6095, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0123, 17.8323, 18.9479],\n",
      "        [22.6356, 17.6743, 18.7572],\n",
      "        [23.0680, 17.6378, 18.4660],\n",
      "        [23.0422, 17.6625, 18.5515],\n",
      "        [22.8161, 17.3273, 18.4782],\n",
      "        [22.4571, 16.8331, 18.0076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.5479,  22.0435, -17.4175],\n",
      "        [-21.1978,  22.8331, -17.9605],\n",
      "        [-21.2977,  22.5777, -17.6000],\n",
      "        [-21.4200,  22.5424, -18.0920],\n",
      "        [-21.2749,  22.5139, -17.9778],\n",
      "        [-21.3959,  22.7685, -18.3981]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0123,  17.8323,  18.9479, -20.5479,  22.0435, -17.4175],\n",
      "        [ 22.6356,  17.6743,  18.7572, -21.1978,  22.8331, -17.9605],\n",
      "        [ 23.0680,  17.6378,  18.4660, -21.2977,  22.5777, -17.6000],\n",
      "        [ 23.0422,  17.6625,  18.5515, -21.4200,  22.5424, -18.0920],\n",
      "        [ 22.8161,  17.3273,  18.4782, -21.2749,  22.5139, -17.9778],\n",
      "        [ 22.4571,  16.8331,  18.0076, -21.3959,  22.7685, -18.3981]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.0725417137146\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4705, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[21.9506, 17.5778, 18.3905],\n",
      "        [22.5407, 17.1610, 18.3880],\n",
      "        [23.0788, 17.6555, 18.3069],\n",
      "        [22.6547, 17.6642, 18.7796],\n",
      "        [22.6991, 17.3760, 18.7488],\n",
      "        [22.8843, 17.7330, 18.6793]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1898, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0701,  22.3569, -18.0988],\n",
      "        [-21.0307,  22.5261, -18.0811],\n",
      "        [-20.9068,  22.3686, -17.8498],\n",
      "        [-21.8041,  22.4175, -18.0839],\n",
      "        [-21.2991,  22.5756, -17.7846],\n",
      "        [-20.4409,  21.9553, -17.3120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 21.9506,  17.5778,  18.3905, -21.0701,  22.3569, -18.0988],\n",
      "        [ 22.5407,  17.1610,  18.3880, -21.0307,  22.5261, -18.0811],\n",
      "        [ 23.0788,  17.6555,  18.3069, -20.9068,  22.3686, -17.8498],\n",
      "        [ 22.6547,  17.6642,  18.7796, -21.8041,  22.4175, -18.0839],\n",
      "        [ 22.6991,  17.3760,  18.7488, -21.2991,  22.5756, -17.7846],\n",
      "        [ 22.8843,  17.7330,  18.6793, -20.4409,  21.9553, -17.3120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.032947063446045\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2860, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4795, 17.9347, 18.7461],\n",
      "        [23.1959, 17.9965, 18.8223],\n",
      "        [22.7711, 17.6945, 18.7161],\n",
      "        [22.6423, 17.6973, 18.3768],\n",
      "        [23.2993, 17.5522, 18.4323],\n",
      "        [22.6043, 17.3347, 18.6407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5846, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7919,  22.9117, -18.2094],\n",
      "        [-21.3893,  23.0658, -17.9711],\n",
      "        [-21.1686,  22.7639, -18.2299],\n",
      "        [-20.8687,  21.9386, -17.7703],\n",
      "        [-21.4958,  22.7620, -17.9859],\n",
      "        [-21.0505,  22.2335, -18.0489]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4795,  17.9347,  18.7461, -21.7919,  22.9117, -18.2094],\n",
      "        [ 23.1959,  17.9965,  18.8223, -21.3893,  23.0658, -17.9711],\n",
      "        [ 22.7711,  17.6945,  18.7161, -21.1686,  22.7639, -18.2299],\n",
      "        [ 22.6423,  17.6973,  18.3768, -20.8687,  21.9386, -17.7703],\n",
      "        [ 23.2993,  17.5522,  18.4323, -21.4958,  22.7620, -17.9859],\n",
      "        [ 22.6043,  17.3347,  18.6407, -21.0505,  22.2335, -18.0489]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.125563621520996\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2302, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4604, 17.8096, 18.6873],\n",
      "        [23.2737, 18.0087, 18.7915],\n",
      "        [22.4961, 17.3387, 17.9545],\n",
      "        [22.3311, 17.4314, 18.5911],\n",
      "        [22.4559, 17.4291, 18.4607],\n",
      "        [22.3804, 17.3049, 18.4618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.3644, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8103,  22.0872, -17.0749],\n",
      "        [-20.8671,  22.4220, -17.2138],\n",
      "        [-21.5517,  23.0145, -18.3969],\n",
      "        [-21.5740,  22.6656, -18.1427],\n",
      "        [-21.4369,  22.5458, -17.7167],\n",
      "        [-20.8515,  22.1952, -17.4778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4604,  17.8096,  18.6873, -20.8103,  22.0872, -17.0749],\n",
      "        [ 23.2737,  18.0087,  18.7915, -20.8671,  22.4220, -17.2138],\n",
      "        [ 22.4961,  17.3387,  17.9545, -21.5517,  23.0145, -18.3969],\n",
      "        [ 22.3311,  17.4314,  18.5911, -21.5740,  22.6656, -18.1427],\n",
      "        [ 22.4559,  17.4291,  18.4607, -21.4369,  22.5458, -17.7167],\n",
      "        [ 22.3804,  17.3049,  18.4618, -20.8515,  22.1952, -17.4778]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.040406703948975\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6506, 17.8315, 18.9736],\n",
      "        [23.1817, 18.3125, 18.9176],\n",
      "        [22.7549, 17.7828, 18.7163],\n",
      "        [22.8637, 17.7643, 18.5408],\n",
      "        [22.9624, 17.6695, 18.8338],\n",
      "        [23.0103, 17.8091, 18.9078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1195, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9124,  22.1283, -17.7866],\n",
      "        [-20.8782,  22.2121, -17.5861],\n",
      "        [-21.1108,  22.3016, -17.8703],\n",
      "        [-21.0704,  22.7714, -18.0426],\n",
      "        [-20.6317,  22.4051, -17.0107],\n",
      "        [-21.0855,  22.3000, -17.6049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6506,  17.8315,  18.9736, -20.9124,  22.1283, -17.7866],\n",
      "        [ 23.1817,  18.3125,  18.9176, -20.8782,  22.2121, -17.5861],\n",
      "        [ 22.7549,  17.7828,  18.7163, -21.1108,  22.3016, -17.8703],\n",
      "        [ 22.8637,  17.7643,  18.5408, -21.0704,  22.7714, -18.0426],\n",
      "        [ 22.9624,  17.6695,  18.8338, -20.6317,  22.4051, -17.0107],\n",
      "        [ 23.0103,  17.8091,  18.9078, -21.0855,  22.3000, -17.6049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.083810329437256\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4025, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0205, 17.5001, 18.9691],\n",
      "        [22.8244, 18.1036, 18.9672],\n",
      "        [22.4163, 17.7425, 18.6457],\n",
      "        [23.4315, 18.0686, 18.9980],\n",
      "        [22.3788, 17.2946, 18.4464],\n",
      "        [22.8556, 17.9808, 18.5585]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0144, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8378,  22.1827, -17.6083],\n",
      "        [-21.0676,  22.4275, -17.8000],\n",
      "        [-21.7323,  22.9305, -18.2702],\n",
      "        [-21.7475,  23.0499, -18.4861],\n",
      "        [-20.9839,  22.7104, -17.6595],\n",
      "        [-21.1010,  22.5772, -17.8172]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0205,  17.5001,  18.9691, -20.8378,  22.1827, -17.6083],\n",
      "        [ 22.8244,  18.1036,  18.9672, -21.0676,  22.4275, -17.8000],\n",
      "        [ 22.4163,  17.7425,  18.6457, -21.7323,  22.9305, -18.2702],\n",
      "        [ 23.4315,  18.0686,  18.9980, -21.7475,  23.0499, -18.4861],\n",
      "        [ 22.3788,  17.2946,  18.4464, -20.9839,  22.7104, -17.6595],\n",
      "        [ 22.8556,  17.9808,  18.5585, -21.1010,  22.5772, -17.8172]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.0890326499938965\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1303, 17.7818, 18.7876],\n",
      "        [22.1830, 17.6842, 18.8691],\n",
      "        [22.6419, 17.9309, 19.1276],\n",
      "        [22.6831, 17.6805, 18.5540],\n",
      "        [22.7598, 17.5428, 18.8322],\n",
      "        [22.7787, 17.5169, 18.8196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.5557, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3609,  22.5153, -18.1426],\n",
      "        [-21.2235,  21.9677, -17.6872],\n",
      "        [-21.4090,  22.5425, -18.0495],\n",
      "        [-20.5413,  22.1646, -17.6270],\n",
      "        [-20.8864,  22.2704, -17.4777],\n",
      "        [-21.6877,  22.7651, -18.0554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1303,  17.7818,  18.7876, -21.3609,  22.5153, -18.1426],\n",
      "        [ 22.1830,  17.6842,  18.8691, -21.2235,  21.9677, -17.6872],\n",
      "        [ 22.6419,  17.9309,  19.1276, -21.4090,  22.5425, -18.0495],\n",
      "        [ 22.6831,  17.6805,  18.5540, -20.5413,  22.1646, -17.6270],\n",
      "        [ 22.7598,  17.5428,  18.8322, -20.8864,  22.2704, -17.4777],\n",
      "        [ 22.7787,  17.5169,  18.8196, -21.6877,  22.7651, -18.0554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.134640216827393\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0515, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8616, 18.1055, 18.8722],\n",
      "        [22.8693, 18.0515, 18.7752],\n",
      "        [22.8942, 17.8565, 18.8475],\n",
      "        [22.3562, 17.4318, 18.3871],\n",
      "        [22.8382, 17.8376, 18.3218],\n",
      "        [22.9108, 17.6887, 18.4218]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6252, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6154,  22.6756, -17.8780],\n",
      "        [-20.7124,  22.2084, -17.6352],\n",
      "        [-20.8157,  22.2690, -17.6664],\n",
      "        [-20.8970,  22.7515, -17.6789],\n",
      "        [-20.4489,  21.9486, -17.5048],\n",
      "        [-21.4230,  22.0189, -17.7511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8616,  18.1055,  18.8722, -21.6154,  22.6756, -17.8780],\n",
      "        [ 22.8693,  18.0515,  18.7752, -20.7124,  22.2084, -17.6352],\n",
      "        [ 22.8942,  17.8565,  18.8475, -20.8157,  22.2690, -17.6664],\n",
      "        [ 22.3562,  17.4318,  18.3871, -20.8970,  22.7515, -17.6789],\n",
      "        [ 22.8382,  17.8376,  18.3218, -20.4489,  21.9486, -17.5048],\n",
      "        [ 22.9108,  17.6887,  18.4218, -21.4230,  22.0189, -17.7511]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.142312049865723\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8533, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8853, 17.8161, 18.3189],\n",
      "        [22.9753, 17.5950, 18.9144],\n",
      "        [22.7041, 17.7197, 18.7058],\n",
      "        [22.6127, 17.6275, 19.0168],\n",
      "        [22.9266, 17.8639, 18.8338],\n",
      "        [22.9566, 17.5435, 18.4032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.0719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9946,  22.7456, -18.1012],\n",
      "        [-21.3059,  22.9714, -17.8844],\n",
      "        [-21.0233,  22.4882, -17.6073],\n",
      "        [-21.6117,  22.8548, -18.2227],\n",
      "        [-21.5077,  22.8016, -18.0234],\n",
      "        [-20.8245,  22.5802, -17.3624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8853,  17.8161,  18.3189, -20.9946,  22.7456, -18.1012],\n",
      "        [ 22.9753,  17.5950,  18.9144, -21.3059,  22.9714, -17.8844],\n",
      "        [ 22.7041,  17.7197,  18.7058, -21.0233,  22.4882, -17.6073],\n",
      "        [ 22.6127,  17.6275,  19.0168, -21.6117,  22.8548, -18.2227],\n",
      "        [ 22.9266,  17.8639,  18.8338, -21.5077,  22.8016, -18.0234],\n",
      "        [ 22.9566,  17.5435,  18.4032, -20.8245,  22.5802, -17.3624]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.103748798370361\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8638, 17.6612, 18.6743],\n",
      "        [23.0347, 17.6361, 19.0978],\n",
      "        [22.5015, 17.2862, 18.3832],\n",
      "        [22.5817, 17.6820, 18.7027],\n",
      "        [22.8054, 18.1650, 19.1338],\n",
      "        [22.7782, 17.8192, 19.1261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2427,  22.7292, -18.2242],\n",
      "        [-20.5395,  22.0503, -17.6827],\n",
      "        [-21.2530,  22.5322, -17.8010],\n",
      "        [-21.1683,  22.5243, -17.7538],\n",
      "        [-21.1961,  22.6919, -17.8254],\n",
      "        [-21.7264,  23.1265, -18.4617]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8638,  17.6612,  18.6743, -21.2427,  22.7292, -18.2242],\n",
      "        [ 23.0347,  17.6361,  19.0978, -20.5395,  22.0503, -17.6827],\n",
      "        [ 22.5015,  17.2862,  18.3832, -21.2530,  22.5322, -17.8010],\n",
      "        [ 22.5817,  17.6820,  18.7027, -21.1683,  22.5243, -17.7538],\n",
      "        [ 22.8054,  18.1650,  19.1338, -21.1961,  22.6919, -17.8254],\n",
      "        [ 22.7782,  17.8192,  19.1261, -21.7264,  23.1265, -18.4617]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.123477458953857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2094, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6445, 17.8426, 18.5905],\n",
      "        [23.1138, 18.1890, 18.8709],\n",
      "        [22.9618, 17.9339, 18.6910],\n",
      "        [23.1130, 18.3237, 19.0086],\n",
      "        [22.3533, 17.2986, 18.4434],\n",
      "        [22.5438, 17.3789, 18.5666]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0845, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4817,  22.4940, -17.9936],\n",
      "        [-21.1696,  22.3321, -18.0670],\n",
      "        [-20.8785,  22.6731, -17.7710],\n",
      "        [-21.1233,  22.5544, -17.9190],\n",
      "        [-21.3060,  22.4745, -18.0210],\n",
      "        [-21.1658,  22.3424, -17.6016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6445,  17.8426,  18.5905, -21.4817,  22.4940, -17.9936],\n",
      "        [ 23.1138,  18.1890,  18.8709, -21.1696,  22.3321, -18.0670],\n",
      "        [ 22.9618,  17.9339,  18.6910, -20.8785,  22.6731, -17.7710],\n",
      "        [ 23.1130,  18.3237,  19.0086, -21.1233,  22.5544, -17.9190],\n",
      "        [ 22.3533,  17.2986,  18.4434, -21.3060,  22.4745, -18.0210],\n",
      "        [ 22.5438,  17.3789,  18.5666, -21.1658,  22.3424, -17.6016]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.110649108886719\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9029, 18.0674, 18.6573],\n",
      "        [22.9739, 17.6462, 19.1035],\n",
      "        [22.9029, 17.5166, 18.8716],\n",
      "        [22.9274, 17.6460, 18.9311],\n",
      "        [22.6966, 17.3949, 18.5868],\n",
      "        [23.0954, 17.7196, 19.0937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5980, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0425,  22.4739, -17.6720],\n",
      "        [-21.3282,  22.9080, -18.1227],\n",
      "        [-20.9048,  22.3689, -17.8980],\n",
      "        [-21.4734,  22.8666, -17.9087],\n",
      "        [-21.4152,  22.5418, -17.8652],\n",
      "        [-21.4795,  22.7422, -17.8644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9029,  18.0674,  18.6573, -21.0425,  22.4739, -17.6720],\n",
      "        [ 22.9739,  17.6462,  19.1035, -21.3282,  22.9080, -18.1227],\n",
      "        [ 22.9029,  17.5166,  18.8716, -20.9048,  22.3689, -17.8980],\n",
      "        [ 22.9274,  17.6460,  18.9311, -21.4734,  22.8666, -17.9087],\n",
      "        [ 22.6966,  17.3949,  18.5868, -21.4152,  22.5418, -17.8652],\n",
      "        [ 23.0954,  17.7196,  19.0937, -21.4795,  22.7422, -17.8644]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.113440036773682\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3081, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4119, 17.9190, 19.0876],\n",
      "        [22.7416, 17.7567, 18.7115],\n",
      "        [23.2957, 17.9431, 19.0184],\n",
      "        [22.5513, 17.7278, 18.6021],\n",
      "        [22.8586, 18.0637, 18.9126],\n",
      "        [22.7976, 17.8020, 18.3481]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.7060, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7877,  22.8335, -18.3994],\n",
      "        [-21.5598,  22.8670, -18.1516],\n",
      "        [-21.5181,  22.9602, -18.2692],\n",
      "        [-20.9189,  22.1357, -17.5608],\n",
      "        [-20.8193,  22.2393, -17.8181],\n",
      "        [-21.4477,  22.6749, -18.0998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4119,  17.9190,  19.0876, -21.7877,  22.8335, -18.3994],\n",
      "        [ 22.7416,  17.7567,  18.7115, -21.5598,  22.8670, -18.1516],\n",
      "        [ 23.2957,  17.9431,  19.0184, -21.5181,  22.9602, -18.2692],\n",
      "        [ 22.5513,  17.7278,  18.6021, -20.9189,  22.1357, -17.5608],\n",
      "        [ 22.8586,  18.0637,  18.9126, -20.8193,  22.2393, -17.8181],\n",
      "        [ 22.7976,  17.8020,  18.3481, -21.4477,  22.6749, -18.0998]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.202315330505371\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9401, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9686, 17.8799, 18.7007],\n",
      "        [22.1167, 17.5765, 18.2513],\n",
      "        [22.8223, 17.8208, 18.9170],\n",
      "        [23.0893, 18.1665, 18.8284],\n",
      "        [22.8684, 17.5132, 18.6033],\n",
      "        [22.5103, 17.7348, 18.7464]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(20.9563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8228,  22.5437, -17.7324],\n",
      "        [-21.0374,  22.1949, -17.7205],\n",
      "        [-21.8214,  22.6493, -18.1516],\n",
      "        [-21.6111,  22.5456, -17.9915],\n",
      "        [-21.6174,  22.7826, -17.9352],\n",
      "        [-21.0293,  22.2309, -18.2269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9686,  17.8799,  18.7007, -20.8228,  22.5437, -17.7324],\n",
      "        [ 22.1167,  17.5765,  18.2513, -21.0374,  22.1949, -17.7205],\n",
      "        [ 22.8223,  17.8208,  18.9170, -21.8214,  22.6493, -18.1516],\n",
      "        [ 23.0893,  18.1665,  18.8284, -21.6111,  22.5456, -17.9915],\n",
      "        [ 22.8684,  17.5132,  18.6033, -21.6174,  22.7826, -17.9352],\n",
      "        [ 22.5103,  17.7348,  18.7464, -21.0293,  22.2309, -18.2269]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.113265514373779\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3983, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4185, 17.5935, 18.5194],\n",
      "        [22.9969, 17.9875, 19.2360],\n",
      "        [22.7782, 17.4954, 18.5585],\n",
      "        [22.1513, 17.4545, 18.3783],\n",
      "        [22.7323, 17.3506, 18.6091],\n",
      "        [23.0355, 17.5942, 18.9185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1074,  22.6892, -17.8434],\n",
      "        [-21.6464,  22.5767, -18.1900],\n",
      "        [-21.2563,  22.3344, -17.6880],\n",
      "        [-21.0005,  22.1868, -17.5883],\n",
      "        [-20.9649,  22.4423, -17.7275],\n",
      "        [-20.5105,  22.5686, -17.2862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4185,  17.5935,  18.5194, -21.1074,  22.6892, -17.8434],\n",
      "        [ 22.9969,  17.9875,  19.2360, -21.6464,  22.5767, -18.1900],\n",
      "        [ 22.7782,  17.4954,  18.5585, -21.2563,  22.3344, -17.6880],\n",
      "        [ 22.1513,  17.4545,  18.3783, -21.0005,  22.1868, -17.5883],\n",
      "        [ 22.7323,  17.3506,  18.6091, -20.9649,  22.4423, -17.7275],\n",
      "        [ 23.0355,  17.5942,  18.9185, -20.5105,  22.5686, -17.2862]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.087610244750977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5321, 17.2700, 18.4727],\n",
      "        [23.0148, 17.9914, 18.6361],\n",
      "        [23.0331, 17.7194, 18.8500],\n",
      "        [22.8638, 18.1196, 18.7493],\n",
      "        [23.0942, 17.9494, 18.8636],\n",
      "        [22.9957, 17.8120, 18.6524]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.4640, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2164,  22.3963, -17.7193],\n",
      "        [-21.4159,  22.7977, -17.7062],\n",
      "        [-21.2246,  22.6854, -17.9867],\n",
      "        [-21.0292,  22.3443, -17.8816],\n",
      "        [-21.6836,  22.8793, -18.3332],\n",
      "        [-21.3934,  22.8657, -18.1824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5321,  17.2700,  18.4727, -21.2164,  22.3963, -17.7193],\n",
      "        [ 23.0148,  17.9914,  18.6361, -21.4159,  22.7977, -17.7062],\n",
      "        [ 23.0331,  17.7194,  18.8500, -21.2246,  22.6854, -17.9867],\n",
      "        [ 22.8638,  18.1196,  18.7493, -21.0292,  22.3443, -17.8816],\n",
      "        [ 23.0942,  17.9494,  18.8636, -21.6836,  22.8793, -18.3332],\n",
      "        [ 22.9957,  17.8120,  18.6524, -21.3934,  22.8657, -18.1824]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.074538707733154\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2888, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8185, 17.8021, 18.7998],\n",
      "        [22.7251, 17.4480, 18.4588],\n",
      "        [23.5553, 17.9691, 19.0016],\n",
      "        [22.6915, 17.7864, 18.5498],\n",
      "        [23.3249, 17.5946, 18.7333],\n",
      "        [22.4779, 17.7736, 18.9511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8756,  22.1661, -17.3774],\n",
      "        [-21.1476,  22.9795, -18.1372],\n",
      "        [-21.1709,  22.5742, -17.6980],\n",
      "        [-20.9886,  22.4515, -17.6096],\n",
      "        [-21.2795,  22.3730, -18.0205],\n",
      "        [-20.8234,  22.1704, -17.7470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8185,  17.8021,  18.7998, -20.8756,  22.1661, -17.3774],\n",
      "        [ 22.7251,  17.4480,  18.4588, -21.1476,  22.9795, -18.1372],\n",
      "        [ 23.5553,  17.9691,  19.0016, -21.1709,  22.5742, -17.6980],\n",
      "        [ 22.6915,  17.7864,  18.5498, -20.9886,  22.4515, -17.6096],\n",
      "        [ 23.3249,  17.5946,  18.7333, -21.2795,  22.3730, -18.0205],\n",
      "        [ 22.4779,  17.7736,  18.9511, -20.8234,  22.1704, -17.7470]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.093982219696045\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.5856, 17.7557, 18.8283],\n",
      "        [22.8062, 17.9419, 19.0299],\n",
      "        [22.7502, 17.4935, 18.4118],\n",
      "        [22.3307, 17.3822, 18.4115],\n",
      "        [23.5258, 17.7750, 18.9405],\n",
      "        [22.3630, 17.2796, 18.2560]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5839, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6451,  23.0343, -18.1852],\n",
      "        [-20.9539,  22.5983, -17.7363],\n",
      "        [-21.0194,  22.3132, -17.7845],\n",
      "        [-21.6589,  22.6685, -18.2903],\n",
      "        [-21.3121,  22.6294, -17.9554],\n",
      "        [-21.2970,  22.6151, -18.0041]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.5856,  17.7557,  18.8283, -21.6451,  23.0343, -18.1852],\n",
      "        [ 22.8062,  17.9419,  19.0299, -20.9539,  22.5983, -17.7363],\n",
      "        [ 22.7502,  17.4935,  18.4118, -21.0194,  22.3132, -17.7845],\n",
      "        [ 22.3307,  17.3822,  18.4115, -21.6589,  22.6685, -18.2903],\n",
      "        [ 23.5258,  17.7750,  18.9405, -21.3121,  22.6294, -17.9554],\n",
      "        [ 22.3630,  17.2796,  18.2560, -21.2970,  22.6151, -18.0041]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.15201473236084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6805, 17.0923, 18.8013],\n",
      "        [22.8558, 17.7096, 19.0446],\n",
      "        [23.0401, 17.9319, 18.8218],\n",
      "        [22.4791, 17.7599, 18.6386],\n",
      "        [22.7315, 17.3704, 18.8202],\n",
      "        [22.8696, 18.1212, 18.6333]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1036, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7975,  22.5693, -17.8123],\n",
      "        [-21.3410,  22.5225, -17.7597],\n",
      "        [-21.2599,  22.7008, -18.0405],\n",
      "        [-21.3607,  23.1092, -18.1380],\n",
      "        [-21.4122,  22.2735, -18.1422],\n",
      "        [-21.3906,  22.2861, -17.9964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6805,  17.0923,  18.8013, -20.7975,  22.5693, -17.8123],\n",
      "        [ 22.8558,  17.7096,  19.0446, -21.3410,  22.5225, -17.7597],\n",
      "        [ 23.0401,  17.9319,  18.8218, -21.2599,  22.7008, -18.0405],\n",
      "        [ 22.4791,  17.7599,  18.6386, -21.3607,  23.1092, -18.1380],\n",
      "        [ 22.7315,  17.3704,  18.8202, -21.4122,  22.2735, -18.1422],\n",
      "        [ 22.8696,  18.1212,  18.6333, -21.3906,  22.2861, -17.9964]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.089876174926758\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8878, 17.5472, 18.8055],\n",
      "        [23.4200, 17.7173, 19.0064],\n",
      "        [22.6917, 17.6015, 18.9198],\n",
      "        [22.3633, 18.0533, 18.6375],\n",
      "        [22.1735, 17.0880, 18.2703],\n",
      "        [23.3259, 18.1958, 19.0732]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.8347,  22.4529, -17.6757],\n",
      "        [-21.0934,  22.9387, -18.2971],\n",
      "        [-21.3528,  22.6901, -17.8605],\n",
      "        [-21.4894,  22.8316, -18.2065],\n",
      "        [-21.3507,  22.6330, -18.3453],\n",
      "        [-20.9762,  22.5141, -18.1567]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8878,  17.5472,  18.8055, -20.8347,  22.4529, -17.6757],\n",
      "        [ 23.4200,  17.7173,  19.0064, -21.0934,  22.9387, -18.2971],\n",
      "        [ 22.6917,  17.6015,  18.9198, -21.3528,  22.6901, -17.8605],\n",
      "        [ 22.3633,  18.0533,  18.6375, -21.4894,  22.8316, -18.2065],\n",
      "        [ 22.1735,  17.0880,  18.2703, -21.3507,  22.6330, -18.3453],\n",
      "        [ 23.3259,  18.1958,  19.0732, -20.9762,  22.5141, -18.1567]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.109478950500488\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0469, 17.8257, 19.2482],\n",
      "        [22.6979, 17.4518, 18.6950],\n",
      "        [22.7823, 17.8037, 18.8889],\n",
      "        [22.7107, 17.7992, 19.1606],\n",
      "        [23.3209, 18.1268, 19.0871],\n",
      "        [22.6471, 17.5751, 18.4498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.0538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1924,  22.2633, -17.9078],\n",
      "        [-21.4574,  23.1278, -18.5712],\n",
      "        [-21.2042,  22.3670, -17.8883],\n",
      "        [-21.0260,  22.9355, -17.9212],\n",
      "        [-21.9120,  22.6730, -18.4367],\n",
      "        [-21.3763,  22.9055, -18.1648]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0469,  17.8257,  19.2482, -21.1924,  22.2633, -17.9078],\n",
      "        [ 22.6979,  17.4518,  18.6950, -21.4574,  23.1278, -18.5712],\n",
      "        [ 22.7823,  17.8037,  18.8889, -21.2042,  22.3670, -17.8883],\n",
      "        [ 22.7107,  17.7992,  19.1606, -21.0260,  22.9355, -17.9212],\n",
      "        [ 23.3209,  18.1268,  19.0871, -21.9120,  22.6730, -18.4367],\n",
      "        [ 22.6471,  17.5751,  18.4498, -21.3763,  22.9055, -18.1648]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.154701232910156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1750, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7045, 17.5478, 18.7008],\n",
      "        [23.0465, 17.8245, 19.0949],\n",
      "        [23.4805, 18.0123, 19.0169],\n",
      "        [23.1900, 18.1117, 19.0515],\n",
      "        [22.5874, 17.2585, 18.5188],\n",
      "        [22.8747, 18.0439, 18.6168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.7016,  22.3065, -17.6422],\n",
      "        [-21.5966,  22.8978, -18.0311],\n",
      "        [-22.0498,  23.0353, -18.4052],\n",
      "        [-20.8458,  21.9342, -17.5713],\n",
      "        [-20.8739,  22.2042, -17.9208],\n",
      "        [-21.0511,  22.5558, -18.1149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7045,  17.5478,  18.7008, -20.7016,  22.3065, -17.6422],\n",
      "        [ 23.0465,  17.8245,  19.0949, -21.5966,  22.8978, -18.0311],\n",
      "        [ 23.4805,  18.0123,  19.0169, -22.0498,  23.0353, -18.4052],\n",
      "        [ 23.1900,  18.1117,  19.0515, -20.8458,  21.9342, -17.5713],\n",
      "        [ 22.5874,  17.2585,  18.5188, -20.8739,  22.2042, -17.9208],\n",
      "        [ 22.8747,  18.0439,  18.6168, -21.0511,  22.5558, -18.1149]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.0902485847473145\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8779, 17.5315, 18.4015],\n",
      "        [22.3533, 17.1118, 17.9685],\n",
      "        [23.1695, 17.9708, 19.2151],\n",
      "        [23.1587, 17.9755, 18.9643],\n",
      "        [22.5256, 17.6573, 18.4572],\n",
      "        [23.1721, 18.0773, 18.8746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.5464, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7603,  22.8963, -18.4206],\n",
      "        [-21.7005,  22.5849, -18.1878],\n",
      "        [-20.9237,  22.4225, -17.9659],\n",
      "        [-21.0987,  22.7092, -17.9219],\n",
      "        [-21.7469,  22.9217, -18.0015],\n",
      "        [-21.4528,  22.9411, -17.9913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8779,  17.5315,  18.4015, -21.7603,  22.8963, -18.4206],\n",
      "        [ 22.3533,  17.1118,  17.9685, -21.7005,  22.5849, -18.1878],\n",
      "        [ 23.1695,  17.9708,  19.2151, -20.9237,  22.4225, -17.9659],\n",
      "        [ 23.1587,  17.9755,  18.9643, -21.0987,  22.7092, -17.9219],\n",
      "        [ 22.5256,  17.6573,  18.4572, -21.7469,  22.9217, -18.0015],\n",
      "        [ 23.1721,  18.0773,  18.8746, -21.4528,  22.9411, -17.9913]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.155062198638916\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0752, 18.0313, 18.8405],\n",
      "        [23.0065, 18.0855, 19.0956],\n",
      "        [23.0032, 17.5946, 18.8467],\n",
      "        [23.1418, 17.9054, 19.0531],\n",
      "        [22.9202, 17.3406, 18.7885],\n",
      "        [22.7030, 17.3576, 18.5609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4269,  22.9221, -18.1691],\n",
      "        [-21.3979,  22.8351, -18.1432],\n",
      "        [-21.2616,  22.5776, -17.9425],\n",
      "        [-20.9495,  22.2160, -17.8766],\n",
      "        [-21.0152,  22.0232, -17.7098],\n",
      "        [-21.4713,  22.4190, -17.8652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0752,  18.0313,  18.8405, -21.4269,  22.9221, -18.1691],\n",
      "        [ 23.0065,  18.0855,  19.0956, -21.3979,  22.8351, -18.1432],\n",
      "        [ 23.0032,  17.5946,  18.8467, -21.2616,  22.5776, -17.9425],\n",
      "        [ 23.1418,  17.9054,  19.0531, -20.9495,  22.2160, -17.8766],\n",
      "        [ 22.9202,  17.3406,  18.7885, -21.0152,  22.0232, -17.7098],\n",
      "        [ 22.7030,  17.3576,  18.5609, -21.4713,  22.4190, -17.8652]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.184051513671875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0625, 17.7856, 18.8527],\n",
      "        [23.1185, 18.1016, 19.1098],\n",
      "        [22.8711, 17.4671, 18.4461],\n",
      "        [23.3990, 18.2195, 19.6550],\n",
      "        [22.6333, 17.3514, 18.3132],\n",
      "        [23.1411, 18.0398, 18.9810]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.8857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9636,  22.4294, -17.7448],\n",
      "        [-21.3348,  22.6773, -17.9415],\n",
      "        [-21.2856,  22.2039, -17.9937],\n",
      "        [-21.1404,  22.4480, -17.9204],\n",
      "        [-21.4385,  22.3366, -17.9831],\n",
      "        [-20.5787,  21.8705, -17.4998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0625,  17.7856,  18.8527, -20.9636,  22.4294, -17.7448],\n",
      "        [ 23.1185,  18.1016,  19.1098, -21.3348,  22.6773, -17.9415],\n",
      "        [ 22.8711,  17.4671,  18.4461, -21.2856,  22.2039, -17.9937],\n",
      "        [ 23.3990,  18.2195,  19.6550, -21.1404,  22.4480, -17.9204],\n",
      "        [ 22.6333,  17.3514,  18.3132, -21.4385,  22.3366, -17.9831],\n",
      "        [ 23.1411,  18.0398,  18.9810, -20.5787,  21.8705, -17.4998]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.139529228210449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8226, 17.4408, 18.6483],\n",
      "        [22.7881, 17.3039, 18.7511],\n",
      "        [23.0727, 17.6817, 19.0727],\n",
      "        [22.7361, 17.4117, 18.8240],\n",
      "        [22.9168, 18.2533, 19.0152],\n",
      "        [23.1128, 17.9599, 18.6769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3023,  22.3172, -17.5939],\n",
      "        [-21.7737,  22.8801, -18.5359],\n",
      "        [-21.6383,  22.9751, -18.0399],\n",
      "        [-21.4385,  22.6449, -18.5033],\n",
      "        [-21.2798,  22.6865, -17.8306],\n",
      "        [-21.9372,  23.5792, -18.7290]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8226,  17.4408,  18.6483, -21.3023,  22.3172, -17.5939],\n",
      "        [ 22.7881,  17.3039,  18.7511, -21.7737,  22.8801, -18.5359],\n",
      "        [ 23.0727,  17.6817,  19.0727, -21.6383,  22.9751, -18.0399],\n",
      "        [ 22.7361,  17.4117,  18.8240, -21.4385,  22.6449, -18.5033],\n",
      "        [ 22.9168,  18.2533,  19.0152, -21.2798,  22.6865, -17.8306],\n",
      "        [ 23.1128,  17.9599,  18.6769, -21.9372,  23.5792, -18.7290]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.11380672454834\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3884, 18.5340, 19.3872],\n",
      "        [23.0550, 18.1400, 18.8536],\n",
      "        [22.8941, 17.4782, 18.7740],\n",
      "        [22.1518, 17.4021, 18.2570],\n",
      "        [23.1747, 17.7722, 19.2258],\n",
      "        [23.1089, 18.2112, 19.2101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2867,  22.6558, -17.8579],\n",
      "        [-20.9681,  22.6658, -17.5721],\n",
      "        [-21.2649,  22.8486, -18.1850],\n",
      "        [-20.0085,  22.1154, -17.1554],\n",
      "        [-21.1589,  22.5139, -17.9668],\n",
      "        [-21.4232,  22.9606, -18.5739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3884,  18.5340,  19.3872, -21.2867,  22.6558, -17.8579],\n",
      "        [ 23.0550,  18.1400,  18.8536, -20.9681,  22.6658, -17.5721],\n",
      "        [ 22.8941,  17.4782,  18.7740, -21.2649,  22.8486, -18.1850],\n",
      "        [ 22.1518,  17.4021,  18.2570, -20.0085,  22.1154, -17.1554],\n",
      "        [ 23.1747,  17.7722,  19.2258, -21.1589,  22.5139, -17.9668],\n",
      "        [ 23.1089,  18.2112,  19.2101, -21.4232,  22.9606, -18.5739]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.221515655517578\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5252, 18.0050, 19.2166],\n",
      "        [23.1700, 17.7396, 19.0810],\n",
      "        [22.5625, 17.5378, 18.9450],\n",
      "        [23.0659, 17.9909, 19.0700],\n",
      "        [22.7210, 17.5546, 18.4564],\n",
      "        [22.7744, 17.6013, 18.5730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.1048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3645,  22.4693, -17.9245],\n",
      "        [-21.4049,  22.2489, -17.8572],\n",
      "        [-21.5182,  22.4770, -17.7117],\n",
      "        [-20.9155,  22.6512, -17.7544],\n",
      "        [-20.7974,  22.4619, -18.0997],\n",
      "        [-21.3899,  22.5975, -17.7225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5252,  18.0050,  19.2166, -21.3645,  22.4693, -17.9245],\n",
      "        [ 23.1700,  17.7396,  19.0810, -21.4049,  22.2489, -17.8572],\n",
      "        [ 22.5625,  17.5378,  18.9450, -21.5182,  22.4770, -17.7117],\n",
      "        [ 23.0659,  17.9909,  19.0700, -20.9155,  22.6512, -17.7544],\n",
      "        [ 22.7210,  17.5546,  18.4564, -20.7974,  22.4619, -18.0997],\n",
      "        [ 22.7744,  17.6013,  18.5730, -21.3899,  22.5975, -17.7225]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.205289363861084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3306, 17.2521, 18.7406],\n",
      "        [23.1210, 18.4652, 18.9407],\n",
      "        [22.2957, 17.9242, 18.8375],\n",
      "        [22.7405, 17.5062, 18.9036],\n",
      "        [22.9516, 18.2415, 18.8957],\n",
      "        [22.5723, 18.0851, 18.5740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7766, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3574,  22.8504, -17.8594],\n",
      "        [-21.2148,  22.5622, -18.0545],\n",
      "        [-21.3915,  22.3495, -17.8294],\n",
      "        [-21.1480,  22.5449, -17.9426],\n",
      "        [-21.3407,  22.6799, -18.1404],\n",
      "        [-21.4552,  22.9994, -18.1214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3306,  17.2521,  18.7406, -21.3574,  22.8504, -17.8594],\n",
      "        [ 23.1210,  18.4652,  18.9407, -21.2148,  22.5622, -18.0545],\n",
      "        [ 22.2957,  17.9242,  18.8375, -21.3915,  22.3495, -17.8294],\n",
      "        [ 22.7405,  17.5062,  18.9036, -21.1480,  22.5449, -17.9426],\n",
      "        [ 22.9516,  18.2415,  18.8957, -21.3407,  22.6799, -18.1404],\n",
      "        [ 22.5723,  18.0851,  18.5740, -21.4552,  22.9994, -18.1214]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.117032527923584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4334, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7091, 18.2537, 18.6023],\n",
      "        [23.1936, 17.9923, 19.3238],\n",
      "        [23.0835, 17.6475, 18.9816],\n",
      "        [22.6555, 17.6785, 18.9005],\n",
      "        [23.0234, 18.0839, 18.9156],\n",
      "        [22.8430, 17.5803, 18.5768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9840, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7001,  23.2124, -18.5434],\n",
      "        [-21.6461,  22.6141, -18.1701],\n",
      "        [-21.8658,  22.7684, -18.3745],\n",
      "        [-21.2516,  22.5721, -18.1346],\n",
      "        [-21.5669,  22.8681, -18.0700],\n",
      "        [-21.8750,  22.8762, -18.1229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7091,  18.2537,  18.6023, -21.7001,  23.2124, -18.5434],\n",
      "        [ 23.1936,  17.9923,  19.3238, -21.6461,  22.6141, -18.1701],\n",
      "        [ 23.0835,  17.6475,  18.9816, -21.8658,  22.7684, -18.3745],\n",
      "        [ 22.6555,  17.6785,  18.9005, -21.2516,  22.5721, -18.1346],\n",
      "        [ 23.0234,  18.0839,  18.9156, -21.5669,  22.8681, -18.0700],\n",
      "        [ 22.8430,  17.5803,  18.5768, -21.8750,  22.8762, -18.1229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.198508262634277\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4959, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6200, 17.3465, 18.0225],\n",
      "        [23.4257, 18.4988, 19.0844],\n",
      "        [23.2162, 17.7227, 19.0402],\n",
      "        [23.2647, 18.3761, 19.3262],\n",
      "        [22.7410, 17.9397, 19.1176],\n",
      "        [22.6656, 17.9304, 19.0071]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6505,  22.5226, -17.8740],\n",
      "        [-21.1122,  22.7192, -17.5979],\n",
      "        [-21.5626,  23.0681, -18.3809],\n",
      "        [-21.5885,  23.3201, -18.3612],\n",
      "        [-21.8146,  22.8843, -17.9675],\n",
      "        [-21.3336,  22.8425, -17.9839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6200,  17.3465,  18.0225, -21.6505,  22.5226, -17.8740],\n",
      "        [ 23.4257,  18.4988,  19.0844, -21.1122,  22.7192, -17.5979],\n",
      "        [ 23.2162,  17.7227,  19.0402, -21.5626,  23.0681, -18.3809],\n",
      "        [ 23.2647,  18.3761,  19.3262, -21.5885,  23.3201, -18.3612],\n",
      "        [ 22.7410,  17.9397,  19.1176, -21.8146,  22.8843, -17.9675],\n",
      "        [ 22.6656,  17.9304,  19.0071, -21.3336,  22.8425, -17.9839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.106849670410156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9034, 17.7394, 18.8039],\n",
      "        [22.5636, 17.4941, 18.6906],\n",
      "        [22.9464, 17.6656, 18.9312],\n",
      "        [23.1736, 18.1011, 19.2157],\n",
      "        [23.6113, 18.1706, 19.1278],\n",
      "        [23.0366, 17.3385, 18.5704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1499,  22.7082, -18.3335],\n",
      "        [-21.6227,  23.0851, -18.3653],\n",
      "        [-21.5774,  22.9183, -18.2881],\n",
      "        [-21.4431,  22.9062, -18.5952],\n",
      "        [-21.3068,  23.0107, -18.3275],\n",
      "        [-21.4145,  22.7175, -18.0116]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9034,  17.7394,  18.8039, -21.1499,  22.7082, -18.3335],\n",
      "        [ 22.5636,  17.4941,  18.6906, -21.6227,  23.0851, -18.3653],\n",
      "        [ 22.9464,  17.6656,  18.9312, -21.5774,  22.9183, -18.2881],\n",
      "        [ 23.1736,  18.1011,  19.2157, -21.4431,  22.9062, -18.5952],\n",
      "        [ 23.6113,  18.1706,  19.1278, -21.3068,  23.0107, -18.3275],\n",
      "        [ 23.0366,  17.3385,  18.5704, -21.4145,  22.7175, -18.0116]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.167389869689941\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7605, 17.6878, 18.9632],\n",
      "        [23.2529, 17.7843, 18.9473],\n",
      "        [22.9408, 17.6716, 18.7109],\n",
      "        [23.4340, 17.9849, 19.0879],\n",
      "        [22.9446, 17.5985, 19.0364],\n",
      "        [23.5661, 18.2082, 19.1065]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7620,  22.8865, -17.8697],\n",
      "        [-21.6268,  23.1060, -18.4301],\n",
      "        [-21.3299,  22.6146, -18.0726],\n",
      "        [-21.5163,  22.8634, -18.4800],\n",
      "        [-21.3299,  22.7931, -17.4930],\n",
      "        [-21.8931,  23.6801, -18.6954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7605,  17.6878,  18.9632, -21.7620,  22.8865, -17.8697],\n",
      "        [ 23.2529,  17.7843,  18.9473, -21.6268,  23.1060, -18.4301],\n",
      "        [ 22.9408,  17.6716,  18.7109, -21.3299,  22.6146, -18.0726],\n",
      "        [ 23.4340,  17.9849,  19.0879, -21.5163,  22.8634, -18.4800],\n",
      "        [ 22.9446,  17.5985,  19.0364, -21.3299,  22.7931, -17.4930],\n",
      "        [ 23.5661,  18.2082,  19.1065, -21.8931,  23.6801, -18.6954]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.179627895355225\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2979, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6674, 17.6470, 18.9683],\n",
      "        [22.6426, 17.8831, 18.9037],\n",
      "        [22.9475, 17.9636, 18.9270],\n",
      "        [23.2551, 18.0417, 18.9059],\n",
      "        [22.7725, 17.9675, 19.0193],\n",
      "        [23.0743, 18.2241, 19.1333]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.5891, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9854,  22.4731, -17.9463],\n",
      "        [-21.2626,  22.7632, -18.1690],\n",
      "        [-20.9774,  22.6667, -17.7612],\n",
      "        [-21.4181,  22.9560, -18.0395],\n",
      "        [-21.8996,  23.2565, -18.1693],\n",
      "        [-21.3234,  22.5920, -17.8321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6674,  17.6470,  18.9683, -20.9854,  22.4731, -17.9463],\n",
      "        [ 22.6426,  17.8831,  18.9037, -21.2626,  22.7632, -18.1690],\n",
      "        [ 22.9475,  17.9636,  18.9270, -20.9774,  22.6667, -17.7612],\n",
      "        [ 23.2551,  18.0417,  18.9059, -21.4181,  22.9560, -18.0395],\n",
      "        [ 22.7725,  17.9675,  19.0193, -21.8996,  23.2565, -18.1693],\n",
      "        [ 23.0743,  18.2241,  19.1333, -21.3234,  22.5920, -17.8321]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.1416916847229\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0112, 17.6993, 18.6962],\n",
      "        [23.1930, 18.1601, 19.1241],\n",
      "        [22.3169, 17.8299, 18.7857],\n",
      "        [23.1691, 17.8340, 19.1286],\n",
      "        [23.2807, 18.0566, 18.7798],\n",
      "        [23.1340, 18.0110, 19.0321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8394, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6876,  22.6371, -18.3060],\n",
      "        [-21.5774,  23.4104, -18.3965],\n",
      "        [-21.7352,  22.8750, -18.2007],\n",
      "        [-21.2396,  22.0427, -17.9492],\n",
      "        [-21.7799,  22.7083, -18.1463],\n",
      "        [-20.9814,  22.6865, -18.0707]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0112,  17.6993,  18.6962, -21.6876,  22.6371, -18.3060],\n",
      "        [ 23.1930,  18.1601,  19.1241, -21.5774,  23.4104, -18.3965],\n",
      "        [ 22.3169,  17.8299,  18.7857, -21.7352,  22.8750, -18.2007],\n",
      "        [ 23.1691,  17.8340,  19.1286, -21.2396,  22.0427, -17.9492],\n",
      "        [ 23.2807,  18.0566,  18.7798, -21.7799,  22.7083, -18.1463],\n",
      "        [ 23.1340,  18.0110,  19.0321, -20.9814,  22.6865, -18.0707]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.184823989868164\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.5622, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0960, 18.0722, 18.7882],\n",
      "        [23.1182, 18.0249, 18.7703],\n",
      "        [23.3996, 17.9998, 19.0143],\n",
      "        [22.5629, 17.2786, 18.1482],\n",
      "        [23.4665, 18.0419, 19.3089],\n",
      "        [22.6673, 17.7385, 18.5323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8809,  23.2241, -18.4326],\n",
      "        [-21.9040,  23.3586, -18.5473],\n",
      "        [-22.0310,  23.3422, -18.6370],\n",
      "        [-21.5604,  23.2110, -18.4722],\n",
      "        [-21.2370,  22.6305, -18.0036],\n",
      "        [-21.5315,  22.7194, -17.9876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0960,  18.0722,  18.7882, -21.8809,  23.2241, -18.4326],\n",
      "        [ 23.1182,  18.0249,  18.7703, -21.9040,  23.3586, -18.5473],\n",
      "        [ 23.3996,  17.9998,  19.0143, -22.0310,  23.3422, -18.6370],\n",
      "        [ 22.5629,  17.2786,  18.1482, -21.5604,  23.2110, -18.4722],\n",
      "        [ 23.4665,  18.0419,  19.3089, -21.2370,  22.6305, -18.0036],\n",
      "        [ 22.6673,  17.7385,  18.5323, -21.5315,  22.7194, -17.9876]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.232475280761719\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5794, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3199, 17.9423, 19.0113],\n",
      "        [23.5339, 17.9945, 18.8800],\n",
      "        [22.9623, 17.8345, 18.8142],\n",
      "        [22.7021, 17.7444, 18.6642],\n",
      "        [23.2864, 18.0978, 19.3275],\n",
      "        [22.3643, 17.7615, 18.8101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.1176,  22.5520, -18.3123],\n",
      "        [-20.8721,  22.4766, -18.1555],\n",
      "        [-21.4772,  22.7398, -18.0006],\n",
      "        [-21.2032,  22.7488, -17.8642],\n",
      "        [-21.7649,  22.9007, -18.7267],\n",
      "        [-21.3650,  22.7054, -17.9939]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3199,  17.9423,  19.0113, -21.1176,  22.5520, -18.3123],\n",
      "        [ 23.5339,  17.9945,  18.8800, -20.8721,  22.4766, -18.1555],\n",
      "        [ 22.9623,  17.8345,  18.8142, -21.4772,  22.7398, -18.0006],\n",
      "        [ 22.7021,  17.7444,  18.6642, -21.2032,  22.7488, -17.8642],\n",
      "        [ 23.2864,  18.0978,  19.3275, -21.7649,  22.9007, -18.7267],\n",
      "        [ 22.3643,  17.7615,  18.8101, -21.3650,  22.7054, -17.9939]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.203939914703369\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0088, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.4316, 17.6808, 18.4992],\n",
      "        [23.2439, 18.0899, 19.0229],\n",
      "        [22.6865, 17.1676, 18.2639],\n",
      "        [23.3415, 18.0453, 19.1575],\n",
      "        [22.5021, 17.8981, 18.6300],\n",
      "        [22.8266, 17.5809, 18.4762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4068, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7904,  23.2130, -18.4796],\n",
      "        [-21.1607,  22.6547, -17.9413],\n",
      "        [-21.5714,  23.0363, -18.3649],\n",
      "        [-22.0777,  23.4501, -18.5971],\n",
      "        [-21.5769,  22.8169, -17.8308],\n",
      "        [-21.4007,  22.7488, -18.2983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.4316,  17.6808,  18.4992, -21.7904,  23.2130, -18.4796],\n",
      "        [ 23.2439,  18.0899,  19.0229, -21.1607,  22.6547, -17.9413],\n",
      "        [ 22.6865,  17.1676,  18.2639, -21.5714,  23.0363, -18.3649],\n",
      "        [ 23.3415,  18.0453,  19.1575, -22.0777,  23.4501, -18.5971],\n",
      "        [ 22.5021,  17.8981,  18.6300, -21.5769,  22.8169, -17.8308],\n",
      "        [ 22.8266,  17.5809,  18.4762, -21.4007,  22.7488, -18.2983]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.177811145782471\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3695, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9585, 17.7526, 18.6788],\n",
      "        [22.6057, 17.4908, 18.5961],\n",
      "        [22.7753, 17.9549, 18.8072],\n",
      "        [23.0039, 18.0911, 19.3184],\n",
      "        [23.1118, 17.9359, 19.0924],\n",
      "        [22.8510, 17.9867, 18.8238]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.6909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9046,  23.0724, -18.2815],\n",
      "        [-22.0328,  23.2985, -18.5654],\n",
      "        [-21.7220,  22.8918, -18.1589],\n",
      "        [-21.5803,  22.3448, -18.2096],\n",
      "        [-21.1912,  22.2605, -18.1388],\n",
      "        [-21.1317,  23.0048, -18.0702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9585,  17.7526,  18.6788, -21.9046,  23.0724, -18.2815],\n",
      "        [ 22.6057,  17.4908,  18.5961, -22.0328,  23.2985, -18.5654],\n",
      "        [ 22.7753,  17.9549,  18.8072, -21.7220,  22.8918, -18.1589],\n",
      "        [ 23.0039,  18.0911,  19.3184, -21.5803,  22.3448, -18.2096],\n",
      "        [ 23.1118,  17.9359,  19.0924, -21.1912,  22.2605, -18.1388],\n",
      "        [ 22.8510,  17.9867,  18.8238, -21.1317,  23.0048, -18.0702]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.20905876159668\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6244, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8804, 17.9753, 18.8247],\n",
      "        [23.2584, 18.1650, 19.0863],\n",
      "        [23.3765, 18.1400, 19.2820],\n",
      "        [22.6495, 18.2972, 19.2540],\n",
      "        [23.1664, 18.0614, 18.8469],\n",
      "        [22.6055, 17.7349, 18.6064]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9079,  23.3205, -18.9742],\n",
      "        [-21.5941,  22.8820, -18.0881],\n",
      "        [-21.6745,  22.6675, -17.8847],\n",
      "        [-21.1546,  22.5891, -18.2890],\n",
      "        [-21.0627,  22.7170, -18.4696],\n",
      "        [-21.3069,  22.8192, -18.0101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8804,  17.9753,  18.8247, -21.9079,  23.3205, -18.9742],\n",
      "        [ 23.2584,  18.1650,  19.0863, -21.5941,  22.8820, -18.0881],\n",
      "        [ 23.3765,  18.1400,  19.2820, -21.6745,  22.6675, -17.8847],\n",
      "        [ 22.6495,  18.2972,  19.2540, -21.1546,  22.5891, -18.2890],\n",
      "        [ 23.1664,  18.0614,  18.8469, -21.0627,  22.7170, -18.4696],\n",
      "        [ 22.6055,  17.7349,  18.6064, -21.3069,  22.8192, -18.0101]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.243420600891113\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2639, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0264, 17.8522, 19.1008],\n",
      "        [23.1591, 17.9398, 18.9363],\n",
      "        [22.0561, 17.3003, 18.4061],\n",
      "        [23.2612, 17.8705, 18.9912],\n",
      "        [22.7536, 18.0049, 18.9521],\n",
      "        [22.7021, 17.5349, 18.7805]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2154, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4660,  22.8437, -17.9038],\n",
      "        [-21.5648,  22.5968, -18.2598],\n",
      "        [-21.7149,  22.6049, -17.9198],\n",
      "        [-20.4935,  22.6740, -17.9503],\n",
      "        [-21.9286,  22.7355, -18.6459],\n",
      "        [-21.8577,  22.7686, -18.3063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0264,  17.8522,  19.1008, -21.4660,  22.8437, -17.9038],\n",
      "        [ 23.1591,  17.9398,  18.9363, -21.5648,  22.5968, -18.2598],\n",
      "        [ 22.0561,  17.3003,  18.4061, -21.7149,  22.6049, -17.9198],\n",
      "        [ 23.2612,  17.8705,  18.9912, -20.4935,  22.6740, -17.9503],\n",
      "        [ 22.7536,  18.0049,  18.9521, -21.9286,  22.7355, -18.6459],\n",
      "        [ 22.7021,  17.5349,  18.7805, -21.8577,  22.7686, -18.3063]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.206787109375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9089, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3598, 18.0480, 18.9095],\n",
      "        [23.2476, 18.5064, 19.0029],\n",
      "        [22.9706, 17.9138, 19.2073],\n",
      "        [23.4145, 18.0985, 19.3109],\n",
      "        [23.0459, 18.4440, 19.0925],\n",
      "        [23.0623, 17.8782, 19.0497]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9119, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2216,  22.2308, -18.1360],\n",
      "        [-21.9753,  23.2252, -18.6592],\n",
      "        [-21.5874,  22.9666, -18.5239],\n",
      "        [-21.0729,  22.9749, -17.7828],\n",
      "        [-21.3437,  22.7927, -18.2248],\n",
      "        [-21.1678,  22.3649, -18.1032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3598,  18.0480,  18.9095, -21.2216,  22.2308, -18.1360],\n",
      "        [ 23.2476,  18.5064,  19.0029, -21.9753,  23.2252, -18.6592],\n",
      "        [ 22.9706,  17.9138,  19.2073, -21.5874,  22.9666, -18.5239],\n",
      "        [ 23.4145,  18.0985,  19.3109, -21.0729,  22.9749, -17.7828],\n",
      "        [ 23.0459,  18.4440,  19.0925, -21.3437,  22.7927, -18.2248],\n",
      "        [ 23.0623,  17.8782,  19.0497, -21.1678,  22.3649, -18.1032]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.201793670654297\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6068, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1915, 17.7353, 18.6391],\n",
      "        [23.6258, 18.1230, 19.1054],\n",
      "        [23.5375, 18.3445, 19.2242],\n",
      "        [23.3110, 17.9937, 18.7361],\n",
      "        [23.1210, 17.6214, 18.8182],\n",
      "        [23.0907, 18.2038, 18.9782]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9170,  23.3324, -18.4909],\n",
      "        [-21.3548,  23.1170, -18.5998],\n",
      "        [-21.4743,  22.7782, -17.7990],\n",
      "        [-21.9559,  23.1765, -18.5333],\n",
      "        [-21.4146,  22.5273, -18.2975],\n",
      "        [-21.3875,  23.1584, -18.4311]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1915,  17.7353,  18.6391, -21.9170,  23.3324, -18.4909],\n",
      "        [ 23.6258,  18.1230,  19.1054, -21.3548,  23.1170, -18.5998],\n",
      "        [ 23.5375,  18.3445,  19.2242, -21.4743,  22.7782, -17.7990],\n",
      "        [ 23.3110,  17.9937,  18.7361, -21.9559,  23.1765, -18.5333],\n",
      "        [ 23.1210,  17.6214,  18.8182, -21.4146,  22.5273, -18.2975],\n",
      "        [ 23.0907,  18.2038,  18.9782, -21.3875,  23.1584, -18.4311]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.238354682922363\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.3951, 17.5166, 18.6999],\n",
      "        [23.3799, 18.1676, 19.1055],\n",
      "        [22.9864, 17.6703, 19.0207],\n",
      "        [23.3613, 18.3051, 19.0882],\n",
      "        [22.9976, 17.4828, 18.9992],\n",
      "        [22.6027, 17.5265, 19.0060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(21.4841, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2186,  22.5724, -18.1953],\n",
      "        [-21.4635,  22.5913, -18.1791],\n",
      "        [-21.3026,  22.8961, -18.3317],\n",
      "        [-21.3242,  22.5862, -18.0460],\n",
      "        [-21.3112,  22.7387, -18.2008],\n",
      "        [-21.5487,  22.6837, -18.0067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.3951,  17.5166,  18.6999, -21.2186,  22.5724, -18.1953],\n",
      "        [ 23.3799,  18.1676,  19.1055, -21.4635,  22.5913, -18.1791],\n",
      "        [ 22.9864,  17.6703,  19.0207, -21.3026,  22.8961, -18.3317],\n",
      "        [ 23.3613,  18.3051,  19.0882, -21.3242,  22.5862, -18.0460],\n",
      "        [ 22.9976,  17.4828,  18.9992, -21.3112,  22.7387, -18.2008],\n",
      "        [ 22.6027,  17.5265,  19.0060, -21.5487,  22.6837, -18.0067]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.14523458480835\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5479, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4749, 17.8391, 18.8316],\n",
      "        [23.3670, 18.3557, 18.8486],\n",
      "        [22.0905, 17.6313, 18.1890],\n",
      "        [22.8819, 17.6469, 18.5899],\n",
      "        [23.1653, 17.9660, 18.8020],\n",
      "        [22.7839, 17.9170, 18.8718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.6417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.0938,  22.7763, -18.1702],\n",
      "        [-21.1191,  23.0051, -17.9715],\n",
      "        [-21.2321,  22.7171, -17.8488],\n",
      "        [-21.5549,  22.5461, -18.4806],\n",
      "        [-21.6283,  22.6780, -18.4030],\n",
      "        [-21.2338,  22.5718, -17.8063]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4749,  17.8391,  18.8316, -21.0938,  22.7763, -18.1702],\n",
      "        [ 23.3670,  18.3557,  18.8486, -21.1191,  23.0051, -17.9715],\n",
      "        [ 22.0905,  17.6313,  18.1890, -21.2321,  22.7171, -17.8488],\n",
      "        [ 22.8819,  17.6469,  18.5899, -21.5549,  22.5461, -18.4806],\n",
      "        [ 23.1653,  17.9660,  18.8020, -21.6283,  22.6780, -18.4030],\n",
      "        [ 22.7839,  17.9170,  18.8718, -21.2338,  22.5718, -17.8063]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.217188835144043\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0810, 18.1491, 18.7586],\n",
      "        [22.9875, 18.0124, 19.3618],\n",
      "        [23.1940, 17.7914, 18.6004],\n",
      "        [22.9616, 17.5009, 18.8100],\n",
      "        [22.8673, 18.2617, 18.9708],\n",
      "        [23.0300, 17.9011, 18.7101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-20.9789,  22.9595, -18.4402],\n",
      "        [-21.0467,  23.0485, -17.8033],\n",
      "        [-21.0858,  22.3831, -17.6665],\n",
      "        [-21.6033,  22.8945, -18.0516],\n",
      "        [-21.5843,  22.8228, -18.4222],\n",
      "        [-21.8273,  23.2031, -18.5369]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0810,  18.1491,  18.7586, -20.9789,  22.9595, -18.4402],\n",
      "        [ 22.9875,  18.0124,  19.3618, -21.0467,  23.0485, -17.8033],\n",
      "        [ 23.1940,  17.7914,  18.6004, -21.0858,  22.3831, -17.6665],\n",
      "        [ 22.9616,  17.5009,  18.8100, -21.6033,  22.8945, -18.0516],\n",
      "        [ 22.8673,  18.2617,  18.9708, -21.5843,  22.8228, -18.4222],\n",
      "        [ 23.0300,  17.9011,  18.7101, -21.8273,  23.2031, -18.5369]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.214389801025391\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5543, 18.3382, 19.3152],\n",
      "        [22.9088, 17.8269, 18.7708],\n",
      "        [23.0670, 18.0211, 18.8292],\n",
      "        [23.4195, 18.1771, 19.1705],\n",
      "        [23.2741, 18.2166, 19.0173],\n",
      "        [23.6194, 18.2766, 19.6266]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0969, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6327,  22.9267, -18.1811],\n",
      "        [-21.1326,  22.2258, -17.6664],\n",
      "        [-20.8753,  22.7987, -17.5088],\n",
      "        [-21.5765,  22.2278, -18.0978],\n",
      "        [-21.2859,  22.5464, -18.0769],\n",
      "        [-21.6495,  22.8439, -18.5419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5543,  18.3382,  19.3152, -21.6327,  22.9267, -18.1811],\n",
      "        [ 22.9088,  17.8269,  18.7708, -21.1326,  22.2258, -17.6664],\n",
      "        [ 23.0670,  18.0211,  18.8292, -20.8753,  22.7987, -17.5088],\n",
      "        [ 23.4195,  18.1771,  19.1705, -21.5765,  22.2278, -18.0978],\n",
      "        [ 23.2741,  18.2166,  19.0173, -21.2859,  22.5464, -18.0769],\n",
      "        [ 23.6194,  18.2766,  19.6266, -21.6495,  22.8439, -18.5419]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.279708385467529\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3520, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7890, 18.3496, 19.6117],\n",
      "        [23.0670, 17.9519, 19.2087],\n",
      "        [23.4223, 18.3633, 19.4284],\n",
      "        [23.2704, 17.5834, 18.9271],\n",
      "        [23.5000, 17.8789, 19.4204],\n",
      "        [23.3068, 17.7969, 18.8366]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8704, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3257,  22.6917, -18.4836],\n",
      "        [-21.8629,  23.2208, -18.5898],\n",
      "        [-21.5206,  22.9753, -18.2429],\n",
      "        [-20.9826,  22.8677, -18.1996],\n",
      "        [-21.5197,  23.3418, -18.4595],\n",
      "        [-21.1751,  22.8223, -18.0608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7890,  18.3496,  19.6117, -21.3257,  22.6917, -18.4836],\n",
      "        [ 23.0670,  17.9519,  19.2087, -21.8629,  23.2208, -18.5898],\n",
      "        [ 23.4223,  18.3633,  19.4284, -21.5206,  22.9753, -18.2429],\n",
      "        [ 23.2704,  17.5834,  18.9271, -20.9826,  22.8677, -18.1996],\n",
      "        [ 23.5000,  17.8789,  19.4204, -21.5197,  23.3418, -18.4595],\n",
      "        [ 23.3068,  17.7969,  18.8366, -21.1751,  22.8223, -18.0608]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.295894145965576\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7199, 17.6783, 18.8308],\n",
      "        [22.8894, 17.6496, 18.9240],\n",
      "        [22.9654, 17.9570, 18.9125],\n",
      "        [22.9883, 18.0420, 19.1520],\n",
      "        [22.7430, 17.9067, 19.1296],\n",
      "        [22.8147, 17.5507, 18.2813]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.2952, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5755,  23.2558, -18.0350],\n",
      "        [-21.5224,  23.0083, -18.3644],\n",
      "        [-21.6878,  22.7746, -18.6742],\n",
      "        [-21.5792,  22.7365, -18.3729],\n",
      "        [-21.6307,  23.0157, -17.8538],\n",
      "        [-21.9125,  23.2631, -18.6682]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7199,  17.6783,  18.8308, -21.5755,  23.2558, -18.0350],\n",
      "        [ 22.8894,  17.6496,  18.9240, -21.5224,  23.0083, -18.3644],\n",
      "        [ 22.9654,  17.9570,  18.9125, -21.6878,  22.7746, -18.6742],\n",
      "        [ 22.9883,  18.0420,  19.1520, -21.5792,  22.7365, -18.3729],\n",
      "        [ 22.7430,  17.9067,  19.1296, -21.6307,  23.0157, -17.8538],\n",
      "        [ 22.8147,  17.5507,  18.2813, -21.9125,  23.2631, -18.6682]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.207741737365723\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1761, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7857, 17.8284, 19.0213],\n",
      "        [22.6339, 17.8818, 18.8242],\n",
      "        [23.2414, 18.2541, 19.0233],\n",
      "        [23.3132, 18.3002, 19.0990],\n",
      "        [23.3467, 18.1911, 19.2193],\n",
      "        [23.5867, 18.2427, 19.1028]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0758, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7958,  23.1195, -18.7123],\n",
      "        [-21.8394,  22.8561, -18.5903],\n",
      "        [-21.4494,  23.2474, -18.5197],\n",
      "        [-21.6523,  22.7820, -18.1926],\n",
      "        [-21.7034,  22.7939, -18.3834],\n",
      "        [-21.8467,  23.2965, -18.4625]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7857,  17.8284,  19.0213, -21.7958,  23.1195, -18.7123],\n",
      "        [ 22.6339,  17.8818,  18.8242, -21.8394,  22.8561, -18.5903],\n",
      "        [ 23.2414,  18.2541,  19.0233, -21.4494,  23.2474, -18.5197],\n",
      "        [ 23.3132,  18.3002,  19.0990, -21.6523,  22.7820, -18.1926],\n",
      "        [ 23.3467,  18.1911,  19.2193, -21.7034,  22.7939, -18.3834],\n",
      "        [ 23.5867,  18.2427,  19.1028, -21.8467,  23.2965, -18.4625]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.242880344390869\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7758, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0658, 17.7291, 19.1527],\n",
      "        [23.2482, 17.8125, 18.7733],\n",
      "        [23.0963, 17.5597, 18.9651],\n",
      "        [23.2532, 18.1612, 19.0232],\n",
      "        [23.3714, 18.2325, 19.3060],\n",
      "        [22.9740, 17.6229, 19.0277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7915, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4513,  22.6794, -18.0423],\n",
      "        [-21.4950,  23.1676, -18.2324],\n",
      "        [-21.9073,  23.2455, -18.5330],\n",
      "        [-21.6810,  22.8738, -18.4041],\n",
      "        [-21.8249,  22.9780, -18.6140],\n",
      "        [-21.8182,  22.9916, -18.3967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0658,  17.7291,  19.1527, -21.4513,  22.6794, -18.0423],\n",
      "        [ 23.2482,  17.8125,  18.7733, -21.4950,  23.1676, -18.2324],\n",
      "        [ 23.0963,  17.5597,  18.9651, -21.9073,  23.2455, -18.5330],\n",
      "        [ 23.2532,  18.1612,  19.0232, -21.6810,  22.8738, -18.4041],\n",
      "        [ 23.3714,  18.2325,  19.3060, -21.8249,  22.9780, -18.6140],\n",
      "        [ 22.9740,  17.6229,  19.0277, -21.8182,  22.9916, -18.3967]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.22088623046875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7882, 18.5418, 19.6535],\n",
      "        [23.4692, 18.2653, 19.2565],\n",
      "        [23.9157, 18.3702, 19.5318],\n",
      "        [23.0121, 17.8569, 18.6529],\n",
      "        [22.8885, 17.8501, 18.7955],\n",
      "        [23.0405, 17.7420, 19.1511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8341, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2595,  23.6897, -18.9066],\n",
      "        [-21.4365,  22.8711, -18.2158],\n",
      "        [-21.9607,  23.4082, -18.6778],\n",
      "        [-21.7628,  22.8506, -17.8229],\n",
      "        [-21.7052,  23.0028, -18.5658],\n",
      "        [-21.5625,  22.9095, -18.2740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7882,  18.5418,  19.6535, -22.2595,  23.6897, -18.9066],\n",
      "        [ 23.4692,  18.2653,  19.2565, -21.4365,  22.8711, -18.2158],\n",
      "        [ 23.9157,  18.3702,  19.5318, -21.9607,  23.4082, -18.6778],\n",
      "        [ 23.0121,  17.8569,  18.6529, -21.7628,  22.8506, -17.8229],\n",
      "        [ 22.8885,  17.8501,  18.7955, -21.7052,  23.0028, -18.5658],\n",
      "        [ 23.0405,  17.7420,  19.1511, -21.5625,  22.9095, -18.2740]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.378973007202148\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7121, 18.0807, 18.8523],\n",
      "        [22.7871, 17.4395, 18.6052],\n",
      "        [23.4471, 17.9584, 19.2424],\n",
      "        [23.0213, 17.7964, 19.4306],\n",
      "        [23.1843, 17.9135, 18.9485],\n",
      "        [23.4790, 18.3792, 19.2909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5851, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6973,  22.6222, -18.5406],\n",
      "        [-21.9276,  23.0299, -18.4552],\n",
      "        [-21.6699,  23.0841, -18.3694],\n",
      "        [-21.2545,  22.3899, -18.0445],\n",
      "        [-21.4891,  23.3037, -18.3853],\n",
      "        [-21.7223,  22.9999, -18.5419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7121,  18.0807,  18.8523, -21.6973,  22.6222, -18.5406],\n",
      "        [ 22.7871,  17.4395,  18.6052, -21.9276,  23.0299, -18.4552],\n",
      "        [ 23.4471,  17.9584,  19.2424, -21.6699,  23.0841, -18.3694],\n",
      "        [ 23.0213,  17.7964,  19.4306, -21.2545,  22.3899, -18.0445],\n",
      "        [ 23.1843,  17.9135,  18.9485, -21.4891,  23.3037, -18.3853],\n",
      "        [ 23.4790,  18.3792,  19.2909, -21.7223,  22.9999, -18.5419]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.222103118896484\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.3717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0282, 17.9935, 19.0797],\n",
      "        [23.2140, 18.3980, 19.0330],\n",
      "        [23.1007, 17.7127, 18.9120],\n",
      "        [22.9132, 17.8795, 18.7423],\n",
      "        [23.6994, 18.4246, 19.3633],\n",
      "        [22.8778, 18.0219, 18.9703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6400,  22.9740, -18.3232],\n",
      "        [-22.4142,  23.7650, -18.8472],\n",
      "        [-21.2007,  22.5060, -17.8748],\n",
      "        [-21.1255,  22.9618, -18.4980],\n",
      "        [-20.9773,  22.6222, -17.9291],\n",
      "        [-21.4356,  23.0611, -18.4219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0282,  17.9935,  19.0797, -21.6400,  22.9740, -18.3232],\n",
      "        [ 23.2140,  18.3980,  19.0330, -22.4142,  23.7650, -18.8472],\n",
      "        [ 23.1007,  17.7127,  18.9120, -21.2007,  22.5060, -17.8748],\n",
      "        [ 22.9132,  17.8795,  18.7423, -21.1255,  22.9618, -18.4980],\n",
      "        [ 23.6994,  18.4246,  19.3633, -20.9773,  22.6222, -17.9291],\n",
      "        [ 22.8778,  18.0219,  18.9703, -21.4356,  23.0611, -18.4219]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.250331878662109\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8726, 17.8651, 18.8213],\n",
      "        [23.1532, 17.5754, 18.7873],\n",
      "        [23.1575, 18.3232, 19.0087],\n",
      "        [23.0113, 18.0688, 19.3289],\n",
      "        [22.9441, 17.7807, 18.6662],\n",
      "        [22.9850, 17.9665, 18.6735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.3817,  22.6095, -18.2073],\n",
      "        [-20.8727,  22.4820, -17.8645],\n",
      "        [-21.6524,  22.6842, -18.1698],\n",
      "        [-21.7796,  22.6203, -18.4653],\n",
      "        [-21.5227,  22.7081, -18.2389],\n",
      "        [-21.8049,  22.9400, -18.2186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8726,  17.8651,  18.8213, -21.3817,  22.6095, -18.2073],\n",
      "        [ 23.1532,  17.5754,  18.7873, -20.8727,  22.4820, -17.8645],\n",
      "        [ 23.1575,  18.3232,  19.0087, -21.6524,  22.6842, -18.1698],\n",
      "        [ 23.0113,  18.0688,  19.3289, -21.7796,  22.6203, -18.4653],\n",
      "        [ 22.9441,  17.7807,  18.6662, -21.5227,  22.7081, -18.2389],\n",
      "        [ 22.9850,  17.9665,  18.6735, -21.8049,  22.9400, -18.2186]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.207988262176514\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8859, 18.1643, 18.8406],\n",
      "        [22.9498, 18.3256, 19.0272],\n",
      "        [23.1203, 18.2411, 18.8709],\n",
      "        [23.0566, 17.9326, 18.8257],\n",
      "        [23.5664, 18.8721, 19.6804],\n",
      "        [22.8394, 18.1007, 19.0347]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.8220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4949,  23.1127, -18.2461],\n",
      "        [-21.6601,  23.5095, -18.5817],\n",
      "        [-22.1326,  23.2577, -18.4451],\n",
      "        [-21.2871,  22.6205, -18.1883],\n",
      "        [-21.5206,  22.9438, -18.2149],\n",
      "        [-21.7643,  22.8456, -18.2959]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8859,  18.1643,  18.8406, -21.4949,  23.1127, -18.2461],\n",
      "        [ 22.9498,  18.3256,  19.0272, -21.6601,  23.5095, -18.5817],\n",
      "        [ 23.1203,  18.2411,  18.8709, -22.1326,  23.2577, -18.4451],\n",
      "        [ 23.0566,  17.9326,  18.8257, -21.2871,  22.6205, -18.1883],\n",
      "        [ 23.5664,  18.8721,  19.6804, -21.5206,  22.9438, -18.2149],\n",
      "        [ 22.8394,  18.1007,  19.0347, -21.7643,  22.8456, -18.2959]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.240234375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6180, 17.4481, 18.3138],\n",
      "        [22.6949, 17.9167, 18.6117],\n",
      "        [23.3745, 18.1096, 19.0969],\n",
      "        [23.1883, 17.9810, 18.9856],\n",
      "        [22.7783, 17.8832, 18.8918],\n",
      "        [23.3814, 18.1358, 18.9223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.0514, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7300,  23.2041, -18.5507],\n",
      "        [-21.1359,  22.7769, -18.1588],\n",
      "        [-21.3111,  23.0216, -17.9402],\n",
      "        [-21.6005,  22.8992, -18.5320],\n",
      "        [-21.7264,  23.3045, -18.6331],\n",
      "        [-22.1056,  22.9580, -18.2124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6180,  17.4481,  18.3138, -21.7300,  23.2041, -18.5507],\n",
      "        [ 22.6949,  17.9167,  18.6117, -21.1359,  22.7769, -18.1588],\n",
      "        [ 23.3745,  18.1096,  19.0969, -21.3111,  23.0216, -17.9402],\n",
      "        [ 23.1883,  17.9810,  18.9856, -21.6005,  22.8992, -18.5320],\n",
      "        [ 22.7783,  17.8832,  18.8918, -21.7264,  23.3045, -18.6331],\n",
      "        [ 23.3814,  18.1358,  18.9223, -22.1056,  22.9580, -18.2124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.2027268409729\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7132, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9406, 18.0435, 19.2403],\n",
      "        [23.3982, 18.2037, 19.3331],\n",
      "        [23.3389, 18.2479, 18.7798],\n",
      "        [23.3736, 18.2840, 19.2264],\n",
      "        [23.2918, 18.2366, 19.0797],\n",
      "        [23.4055, 18.0688, 19.2817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.7421, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6449,  23.4431, -18.6232],\n",
      "        [-21.8082,  22.9727, -18.4396],\n",
      "        [-21.2727,  22.6794, -18.3101],\n",
      "        [-21.7236,  23.2554, -18.6581],\n",
      "        [-21.5765,  23.3102, -18.3930],\n",
      "        [-22.2769,  23.5315, -19.0675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9406,  18.0435,  19.2403, -21.6449,  23.4431, -18.6232],\n",
      "        [ 23.3982,  18.2037,  19.3331, -21.8082,  22.9727, -18.4396],\n",
      "        [ 23.3389,  18.2479,  18.7798, -21.2727,  22.6794, -18.3101],\n",
      "        [ 23.3736,  18.2840,  19.2264, -21.7236,  23.2554, -18.6581],\n",
      "        [ 23.2918,  18.2366,  19.0797, -21.5765,  23.3102, -18.3930],\n",
      "        [ 23.4055,  18.0688,  19.2817, -22.2769,  23.5315, -19.0675]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.282638072967529\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7480, 18.4537, 18.9634],\n",
      "        [22.6640, 17.6927, 18.6769],\n",
      "        [23.2993, 18.5356, 18.8808],\n",
      "        [23.5582, 18.4449, 19.5322],\n",
      "        [22.9259, 17.5791, 18.5734],\n",
      "        [22.8561, 17.6947, 18.5147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.2613, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8810,  23.0139, -18.4846],\n",
      "        [-21.6794,  22.8885, -18.5034],\n",
      "        [-21.7292,  22.6767, -18.5106],\n",
      "        [-21.5742,  23.1565, -18.6017],\n",
      "        [-22.0188,  23.2831, -19.1896],\n",
      "        [-21.4191,  22.9426, -18.3387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7480,  18.4537,  18.9634, -21.8810,  23.0139, -18.4846],\n",
      "        [ 22.6640,  17.6927,  18.6769, -21.6794,  22.8885, -18.5034],\n",
      "        [ 23.2993,  18.5356,  18.8808, -21.7292,  22.6767, -18.5106],\n",
      "        [ 23.5582,  18.4449,  19.5322, -21.5742,  23.1565, -18.6017],\n",
      "        [ 22.9259,  17.5791,  18.5734, -22.0188,  23.2831, -19.1896],\n",
      "        [ 22.8561,  17.6947,  18.5147, -21.4191,  22.9426, -18.3387]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.265862941741943\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2678, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2816, 18.1445, 18.8042],\n",
      "        [23.4418, 18.4103, 19.4920],\n",
      "        [22.9276, 17.8954, 19.1212],\n",
      "        [23.4928, 18.6014, 19.4156],\n",
      "        [22.8623, 17.6723, 18.9642],\n",
      "        [23.0557, 17.9038, 19.1029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.4667,  23.0647, -18.6854],\n",
      "        [-20.9324,  22.9264, -18.2266],\n",
      "        [-22.0862,  23.3848, -18.6858],\n",
      "        [-21.4162,  22.9793, -18.4274],\n",
      "        [-21.7725,  23.4969, -18.8274],\n",
      "        [-21.8057,  23.1479, -18.5026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2816,  18.1445,  18.8042, -21.4667,  23.0647, -18.6854],\n",
      "        [ 23.4418,  18.4103,  19.4920, -20.9324,  22.9264, -18.2266],\n",
      "        [ 22.9276,  17.8954,  19.1212, -22.0862,  23.3848, -18.6858],\n",
      "        [ 23.4928,  18.6014,  19.4156, -21.4162,  22.9793, -18.4274],\n",
      "        [ 22.8623,  17.6723,  18.9642, -21.7725,  23.4969, -18.8274],\n",
      "        [ 23.0557,  17.9038,  19.1029, -21.8057,  23.1479, -18.5026]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.272205829620361\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9945, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0509, 17.8889, 18.9487],\n",
      "        [23.3561, 18.1763, 19.2979],\n",
      "        [22.6851, 17.7628, 18.9303],\n",
      "        [23.6114, 18.0549, 19.4667],\n",
      "        [23.3724, 18.1177, 19.3708],\n",
      "        [23.2208, 17.9335, 19.4299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0807,  23.2947, -18.4139],\n",
      "        [-21.5449,  22.9496, -18.3779],\n",
      "        [-21.6800,  22.7440, -18.4125],\n",
      "        [-21.4752,  23.2856, -18.3799],\n",
      "        [-22.0972,  23.1286, -18.4296],\n",
      "        [-21.6538,  22.8287, -18.3447]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0509,  17.8889,  18.9487, -22.0807,  23.2947, -18.4139],\n",
      "        [ 23.3561,  18.1763,  19.2979, -21.5449,  22.9496, -18.3779],\n",
      "        [ 22.6851,  17.7628,  18.9303, -21.6800,  22.7440, -18.4125],\n",
      "        [ 23.6114,  18.0549,  19.4667, -21.4752,  23.2856, -18.3799],\n",
      "        [ 23.3724,  18.1177,  19.3708, -22.0972,  23.1286, -18.4296],\n",
      "        [ 23.2208,  17.9335,  19.4299, -21.6538,  22.8287, -18.3447]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.279727935791016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6391, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.6812, 17.9379, 18.4151],\n",
      "        [23.2309, 17.9922, 19.2741],\n",
      "        [22.9376, 18.4862, 19.2321],\n",
      "        [23.6368, 18.3681, 19.4366],\n",
      "        [23.2509, 18.0112, 19.2901],\n",
      "        [23.3867, 18.4058, 18.9386]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(7.4941, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5879,  23.1059, -17.9462],\n",
      "        [-21.9098,  23.6020, -18.7765],\n",
      "        [-21.5147,  23.1027, -18.2858],\n",
      "        [-21.9573,  23.0074, -18.7375],\n",
      "        [-21.9473,  23.1488, -18.7214],\n",
      "        [-21.6814,  23.2359, -18.3817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.6812,  17.9379,  18.4151, -21.5879,  23.1059, -17.9462],\n",
      "        [ 23.2309,  17.9922,  19.2741, -21.9098,  23.6020, -18.7765],\n",
      "        [ 22.9376,  18.4862,  19.2321, -21.5147,  23.1027, -18.2858],\n",
      "        [ 23.6368,  18.3681,  19.4366, -21.9573,  23.0074, -18.7375],\n",
      "        [ 23.2509,  18.0112,  19.2901, -21.9473,  23.1488, -18.7214],\n",
      "        [ 23.3867,  18.4058,  18.9386, -21.6814,  23.2359, -18.3817]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.211120128631592\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8132, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4406, 18.0816, 19.0767],\n",
      "        [23.7792, 18.7461, 19.4865],\n",
      "        [22.5550, 17.5517, 18.8984],\n",
      "        [23.2852, 18.0724, 19.2296],\n",
      "        [23.5791, 18.1662, 19.0147],\n",
      "        [23.1151, 18.3817, 19.6420]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6370, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9483,  22.8436, -18.2721],\n",
      "        [-21.5752,  22.5498, -18.2433],\n",
      "        [-21.5732,  23.2734, -18.7340],\n",
      "        [-21.6687,  22.8798, -18.2832],\n",
      "        [-22.0409,  23.4743, -18.7086],\n",
      "        [-22.1378,  22.9428, -18.1160]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4406,  18.0816,  19.0767, -21.9483,  22.8436, -18.2721],\n",
      "        [ 23.7792,  18.7461,  19.4865, -21.5752,  22.5498, -18.2433],\n",
      "        [ 22.5550,  17.5517,  18.8984, -21.5732,  23.2734, -18.7340],\n",
      "        [ 23.2852,  18.0724,  19.2296, -21.6687,  22.8798, -18.2832],\n",
      "        [ 23.5791,  18.1662,  19.0147, -22.0409,  23.4743, -18.7086],\n",
      "        [ 23.1151,  18.3817,  19.6420, -22.1378,  22.9428, -18.1160]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.291661739349365\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3762, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.8662, 18.1086, 19.1241],\n",
      "        [23.6432, 18.2432, 19.3566],\n",
      "        [23.7520, 18.7284, 18.9927],\n",
      "        [23.7547, 18.1522, 19.3370],\n",
      "        [23.7611, 18.2527, 19.3997],\n",
      "        [23.7632, 18.4418, 19.3998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5667, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8376,  23.2770, -18.1732],\n",
      "        [-21.6842,  23.2916, -18.6815],\n",
      "        [-21.9610,  23.4733, -18.8079],\n",
      "        [-21.2403,  22.3251, -17.9459],\n",
      "        [-21.3682,  22.6068, -18.1944],\n",
      "        [-22.2884,  23.5296, -18.5899]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.8662,  18.1086,  19.1241, -21.8376,  23.2770, -18.1732],\n",
      "        [ 23.6432,  18.2432,  19.3566, -21.6842,  23.2916, -18.6815],\n",
      "        [ 23.7520,  18.7284,  18.9927, -21.9610,  23.4733, -18.8079],\n",
      "        [ 23.7547,  18.1522,  19.3370, -21.2403,  22.3251, -17.9459],\n",
      "        [ 23.7611,  18.2527,  19.3997, -21.3682,  22.6068, -18.1944],\n",
      "        [ 23.7632,  18.4418,  19.3998, -22.2884,  23.5296, -18.5899]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.275755882263184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0589, 17.9159, 18.7659],\n",
      "        [23.2435, 18.2266, 19.2690],\n",
      "        [23.3900, 18.3516, 19.0750],\n",
      "        [23.3349, 18.0060, 19.3192],\n",
      "        [23.1079, 18.6986, 19.6022],\n",
      "        [22.9909, 18.0730, 18.6497]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1136, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5594,  23.4000, -18.6438],\n",
      "        [-21.5769,  23.1505, -18.5965],\n",
      "        [-21.9587,  23.1274, -18.4866],\n",
      "        [-21.7834,  22.4207, -18.2324],\n",
      "        [-21.8850,  23.4337, -18.5508],\n",
      "        [-21.4029,  22.5355, -18.3914]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0589,  17.9159,  18.7659, -21.5594,  23.4000, -18.6438],\n",
      "        [ 23.2435,  18.2266,  19.2690, -21.5769,  23.1505, -18.5965],\n",
      "        [ 23.3900,  18.3516,  19.0750, -21.9587,  23.1274, -18.4866],\n",
      "        [ 23.3349,  18.0060,  19.3192, -21.7834,  22.4207, -18.2324],\n",
      "        [ 23.1079,  18.6986,  19.6022, -21.8850,  23.4337, -18.5508],\n",
      "        [ 22.9909,  18.0730,  18.6497, -21.4029,  22.5355, -18.3914]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.273314476013184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7336, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0766, 17.7122, 18.5864],\n",
      "        [23.4380, 18.6744, 19.1508],\n",
      "        [23.2311, 18.2939, 19.4747],\n",
      "        [23.4894, 18.1615, 18.8500],\n",
      "        [23.5632, 18.6913, 19.1817],\n",
      "        [23.7079, 18.4832, 19.4274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.2482, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2841,  22.8545, -18.2552],\n",
      "        [-22.0186,  23.2771, -19.0655],\n",
      "        [-21.9526,  23.1911, -18.5288],\n",
      "        [-21.7256,  22.9479, -18.5573],\n",
      "        [-21.6076,  22.9368, -18.1881],\n",
      "        [-21.9796,  23.1378, -18.7954]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0766,  17.7122,  18.5864, -21.2841,  22.8545, -18.2552],\n",
      "        [ 23.4380,  18.6744,  19.1508, -22.0186,  23.2771, -19.0655],\n",
      "        [ 23.2311,  18.2939,  19.4747, -21.9526,  23.1911, -18.5288],\n",
      "        [ 23.4894,  18.1615,  18.8500, -21.7256,  22.9479, -18.5573],\n",
      "        [ 23.5632,  18.6913,  19.1817, -21.6076,  22.9368, -18.1881],\n",
      "        [ 23.7079,  18.4832,  19.4274, -21.9796,  23.1378, -18.7954]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.227599143981934\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2702, 18.4720, 19.3545],\n",
      "        [23.2930, 18.1626, 19.2229],\n",
      "        [23.7925, 18.3249, 19.4152],\n",
      "        [23.7191, 18.3002, 19.2504],\n",
      "        [23.5666, 18.0311, 19.3074],\n",
      "        [23.7379, 18.5677, 19.2107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5668,  22.8045, -18.0919],\n",
      "        [-21.1121,  22.2653, -17.8892],\n",
      "        [-21.3149,  22.6518, -18.0252],\n",
      "        [-21.8430,  22.7126, -18.3051],\n",
      "        [-22.2282,  23.1974, -18.9740],\n",
      "        [-21.7943,  23.3221, -18.8824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2702,  18.4720,  19.3545, -21.5668,  22.8045, -18.0919],\n",
      "        [ 23.2930,  18.1626,  19.2229, -21.1121,  22.2653, -17.8892],\n",
      "        [ 23.7925,  18.3249,  19.4152, -21.3149,  22.6518, -18.0252],\n",
      "        [ 23.7191,  18.3002,  19.2504, -21.8430,  22.7126, -18.3051],\n",
      "        [ 23.5666,  18.0311,  19.3074, -22.2282,  23.1974, -18.9740],\n",
      "        [ 23.7379,  18.5677,  19.2107, -21.7943,  23.3221, -18.8824]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.295975208282471\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7351, 18.5946, 19.5056],\n",
      "        [23.4103, 18.2432, 19.2392],\n",
      "        [23.0630, 18.1226, 19.0802],\n",
      "        [22.9980, 18.0192, 19.1738],\n",
      "        [23.5180, 18.3781, 19.3625],\n",
      "        [22.9658, 18.3838, 19.1227]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.4274, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7860,  23.2762, -18.5854],\n",
      "        [-22.0708,  23.1696, -18.8782],\n",
      "        [-21.5213,  22.9525, -18.1420],\n",
      "        [-21.9173,  23.3582, -18.3983],\n",
      "        [-21.7155,  23.3129, -18.7715],\n",
      "        [-21.6672,  22.6773, -18.3828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7351,  18.5946,  19.5056, -21.7860,  23.2762, -18.5854],\n",
      "        [ 23.4103,  18.2432,  19.2392, -22.0708,  23.1696, -18.8782],\n",
      "        [ 23.0630,  18.1226,  19.0802, -21.5213,  22.9525, -18.1420],\n",
      "        [ 22.9980,  18.0192,  19.1738, -21.9173,  23.3582, -18.3983],\n",
      "        [ 23.5180,  18.3781,  19.3625, -21.7155,  23.3129, -18.7715],\n",
      "        [ 22.9658,  18.3838,  19.1227, -21.6672,  22.6773, -18.3828]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.363764762878418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7809, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2820, 18.5174, 18.7899],\n",
      "        [23.6804, 18.1426, 19.3102],\n",
      "        [23.4366, 18.3389, 19.1130],\n",
      "        [23.7041, 18.3111, 19.2833],\n",
      "        [23.6873, 18.6546, 19.5748],\n",
      "        [23.6264, 18.3427, 19.4704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.8267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2883,  22.6332, -18.0576],\n",
      "        [-21.6459,  22.7908, -18.2663],\n",
      "        [-22.0217,  23.4430, -18.9189],\n",
      "        [-21.9216,  22.9234, -18.5676],\n",
      "        [-21.9164,  23.3130, -18.8974],\n",
      "        [-22.3016,  23.1597, -18.4778]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2820,  18.5174,  18.7899, -21.2883,  22.6332, -18.0576],\n",
      "        [ 23.6804,  18.1426,  19.3102, -21.6459,  22.7908, -18.2663],\n",
      "        [ 23.4366,  18.3389,  19.1130, -22.0217,  23.4430, -18.9189],\n",
      "        [ 23.7041,  18.3111,  19.2833, -21.9216,  22.9234, -18.5676],\n",
      "        [ 23.6873,  18.6546,  19.5748, -21.9164,  23.3130, -18.8974],\n",
      "        [ 23.6264,  18.3427,  19.4704, -22.3016,  23.1597, -18.4778]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.263555526733398\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5390, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0570, 18.1420, 18.9526],\n",
      "        [23.4892, 18.2868, 19.2790],\n",
      "        [23.6097, 18.3649, 19.3924],\n",
      "        [23.4534, 18.5927, 19.5633],\n",
      "        [23.6445, 18.2898, 19.4024],\n",
      "        [23.3649, 18.1976, 19.1863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1911, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5421,  22.5379, -18.2651],\n",
      "        [-21.6584,  22.6817, -18.2491],\n",
      "        [-21.7547,  22.5547, -18.5422],\n",
      "        [-21.9193,  23.2935, -18.3464],\n",
      "        [-21.8913,  23.3133, -18.5080],\n",
      "        [-21.6969,  22.9763, -18.4864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0570,  18.1420,  18.9526, -21.5421,  22.5379, -18.2651],\n",
      "        [ 23.4892,  18.2868,  19.2790, -21.6584,  22.6817, -18.2491],\n",
      "        [ 23.6097,  18.3649,  19.3924, -21.7547,  22.5547, -18.5422],\n",
      "        [ 23.4534,  18.5927,  19.5633, -21.9193,  23.2935, -18.3464],\n",
      "        [ 23.6445,  18.2898,  19.4024, -21.8913,  23.3133, -18.5080],\n",
      "        [ 23.3649,  18.1976,  19.1863, -21.6969,  22.9763, -18.4864]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.258754730224609\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3740, 18.0562, 19.3727],\n",
      "        [23.2033, 18.5204, 19.5263],\n",
      "        [23.4700, 18.1601, 19.0397],\n",
      "        [22.7906, 18.0401, 19.3824],\n",
      "        [23.3102, 18.1074, 19.1546],\n",
      "        [23.5001, 18.2358, 18.9995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9225,  23.7465, -19.0467],\n",
      "        [-21.8712,  23.1798, -18.5754],\n",
      "        [-21.7790,  23.3606, -18.4789],\n",
      "        [-21.1994,  22.0873, -18.1534],\n",
      "        [-21.5554,  22.6146, -18.2832],\n",
      "        [-21.4987,  22.7405, -18.4329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3740,  18.0562,  19.3727, -21.9225,  23.7465, -19.0467],\n",
      "        [ 23.2033,  18.5204,  19.5263, -21.8712,  23.1798, -18.5754],\n",
      "        [ 23.4700,  18.1601,  19.0397, -21.7790,  23.3606, -18.4789],\n",
      "        [ 22.7906,  18.0401,  19.3824, -21.1994,  22.0873, -18.1534],\n",
      "        [ 23.3102,  18.1074,  19.1546, -21.5554,  22.6146, -18.2832],\n",
      "        [ 23.5001,  18.2358,  18.9995, -21.4987,  22.7405, -18.4329]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.359147548675537\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5827, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4778, 18.2780, 19.5244],\n",
      "        [23.1839, 18.2858, 19.5451],\n",
      "        [23.1214, 17.8028, 18.8251],\n",
      "        [23.1229, 18.1385, 19.1606],\n",
      "        [23.6644, 18.5549, 19.0767],\n",
      "        [22.1612, 17.7155, 18.9900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.4372, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2999,  22.7179, -17.8700],\n",
      "        [-21.7715,  22.9056, -18.5506],\n",
      "        [-22.3069,  23.6690, -18.9767],\n",
      "        [-21.9433,  22.7930, -18.5083],\n",
      "        [-21.0076,  22.6618, -18.1124],\n",
      "        [-22.0099,  23.3182, -18.6310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4778,  18.2780,  19.5244, -21.2999,  22.7179, -17.8700],\n",
      "        [ 23.1839,  18.2858,  19.5451, -21.7715,  22.9056, -18.5506],\n",
      "        [ 23.1214,  17.8028,  18.8251, -22.3069,  23.6690, -18.9767],\n",
      "        [ 23.1229,  18.1385,  19.1606, -21.9433,  22.7930, -18.5083],\n",
      "        [ 23.6644,  18.5549,  19.0767, -21.0076,  22.6618, -18.1124],\n",
      "        [ 22.1612,  17.7155,  18.9900, -22.0099,  23.3182, -18.6310]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.299505233764648\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2752, 18.3561, 19.2194],\n",
      "        [23.2058, 17.8904, 19.0064],\n",
      "        [23.0548, 18.5067, 19.1036],\n",
      "        [23.4336, 18.7398, 19.4562],\n",
      "        [22.9605, 18.1766, 18.9928],\n",
      "        [23.2171, 17.9988, 19.2746]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6662, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6785,  23.0136, -18.2861],\n",
      "        [-21.6320,  22.9255, -18.3757],\n",
      "        [-21.8126,  23.1955, -18.5823],\n",
      "        [-22.0143,  23.4207, -18.6358],\n",
      "        [-22.1025,  23.3701, -18.9146],\n",
      "        [-21.5882,  22.8000, -18.4965]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2752,  18.3561,  19.2194, -21.6785,  23.0136, -18.2861],\n",
      "        [ 23.2058,  17.8904,  19.0064, -21.6320,  22.9255, -18.3757],\n",
      "        [ 23.0548,  18.5067,  19.1036, -21.8126,  23.1955, -18.5823],\n",
      "        [ 23.4336,  18.7398,  19.4562, -22.0143,  23.4207, -18.6358],\n",
      "        [ 22.9605,  18.1766,  18.9928, -22.1025,  23.3701, -18.9146],\n",
      "        [ 23.2171,  17.9988,  19.2746, -21.5882,  22.8000, -18.4965]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.311566352844238\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3678, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2190, 18.3543, 18.8960],\n",
      "        [23.3071, 18.1912, 19.2488],\n",
      "        [23.4474, 18.3041, 19.4757],\n",
      "        [23.1174, 17.9004, 18.6848],\n",
      "        [22.9390, 18.1625, 19.1967],\n",
      "        [23.1562, 18.1403, 19.1684]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4631, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6404,  23.4270, -18.6199],\n",
      "        [-21.8700,  23.3180, -18.7933],\n",
      "        [-21.9841,  23.5164, -18.7933],\n",
      "        [-21.5786,  23.0852, -18.4519],\n",
      "        [-22.0299,  23.2707, -18.7198],\n",
      "        [-21.5042,  23.1807, -18.2564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2190,  18.3543,  18.8960, -21.6404,  23.4270, -18.6199],\n",
      "        [ 23.3071,  18.1912,  19.2488, -21.8700,  23.3180, -18.7933],\n",
      "        [ 23.4474,  18.3041,  19.4757, -21.9841,  23.5164, -18.7933],\n",
      "        [ 23.1174,  17.9004,  18.6848, -21.5786,  23.0852, -18.4519],\n",
      "        [ 22.9390,  18.1625,  19.1967, -22.0299,  23.2707, -18.7198],\n",
      "        [ 23.1562,  18.1403,  19.1684, -21.5042,  23.1807, -18.2564]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.317133903503418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1365, 18.1985, 18.8528],\n",
      "        [23.0212, 18.1689, 19.0143],\n",
      "        [23.6215, 18.4431, 19.5088],\n",
      "        [23.6046, 18.3741, 19.1715],\n",
      "        [23.6964, 18.2480, 19.0077],\n",
      "        [23.5845, 18.8082, 19.5085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.9545, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8280,  23.3816, -18.5237],\n",
      "        [-22.1058,  23.2934, -18.6834],\n",
      "        [-22.1969,  23.1481, -18.8668],\n",
      "        [-21.9728,  23.2115, -18.5268],\n",
      "        [-21.9601,  23.4171, -18.8109],\n",
      "        [-21.4946,  22.8335, -17.9964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1365,  18.1985,  18.8528, -21.8280,  23.3816, -18.5237],\n",
      "        [ 23.0212,  18.1689,  19.0143, -22.1058,  23.2934, -18.6834],\n",
      "        [ 23.6215,  18.4431,  19.5088, -22.1969,  23.1481, -18.8668],\n",
      "        [ 23.6046,  18.3741,  19.1715, -21.9728,  23.2115, -18.5268],\n",
      "        [ 23.6964,  18.2480,  19.0077, -21.9601,  23.4171, -18.8109],\n",
      "        [ 23.5845,  18.8082,  19.5085, -21.4946,  22.8335, -17.9964]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.310044288635254\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.9286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6733, 18.2388, 19.1937],\n",
      "        [22.7814, 17.6653, 18.7356],\n",
      "        [23.4173, 18.2624, 18.9840],\n",
      "        [22.9050, 17.9010, 18.9675],\n",
      "        [23.2079, 18.3774, 19.6023],\n",
      "        [22.9960, 18.0727, 18.7024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.8047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3711,  23.5489, -19.0182],\n",
      "        [-21.0101,  23.2603, -18.1602],\n",
      "        [-21.6762,  22.9330, -18.4929],\n",
      "        [-22.5342,  23.1944, -19.0526],\n",
      "        [-21.6141,  22.6047, -18.0545],\n",
      "        [-22.2285,  23.0515, -18.4066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6733,  18.2388,  19.1937, -22.3711,  23.5489, -19.0182],\n",
      "        [ 22.7814,  17.6653,  18.7356, -21.0101,  23.2603, -18.1602],\n",
      "        [ 23.4173,  18.2624,  18.9840, -21.6762,  22.9330, -18.4929],\n",
      "        [ 22.9050,  17.9010,  18.9675, -22.5342,  23.1944, -19.0526],\n",
      "        [ 23.2079,  18.3774,  19.6023, -21.6141,  22.6047, -18.0545],\n",
      "        [ 22.9960,  18.0727,  18.7024, -22.2285,  23.0515, -18.4066]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.386835098266602\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6646, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2301, 17.9664, 18.9161],\n",
      "        [23.3051, 18.3137, 19.2763],\n",
      "        [23.3556, 18.1143, 19.1811],\n",
      "        [24.0566, 18.2695, 19.4415],\n",
      "        [22.9185, 18.0663, 18.7165],\n",
      "        [23.3847, 18.3707, 19.5227]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.9305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3123,  23.4067, -19.0855],\n",
      "        [-21.5994,  23.2973, -18.6897],\n",
      "        [-21.6406,  22.9536, -18.3420],\n",
      "        [-21.7723,  23.2462, -18.5543],\n",
      "        [-21.9277,  23.1138, -18.4803],\n",
      "        [-21.7924,  22.7172, -18.4014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2301,  17.9664,  18.9161, -22.3123,  23.4067, -19.0855],\n",
      "        [ 23.3051,  18.3137,  19.2763, -21.5994,  23.2973, -18.6897],\n",
      "        [ 23.3556,  18.1143,  19.1811, -21.6406,  22.9536, -18.3420],\n",
      "        [ 24.0566,  18.2695,  19.4415, -21.7723,  23.2462, -18.5543],\n",
      "        [ 22.9185,  18.0663,  18.7165, -21.9277,  23.1138, -18.4803],\n",
      "        [ 23.3847,  18.3707,  19.5227, -21.7924,  22.7172, -18.4014]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.342162609100342\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.7753, 17.7095, 18.7056],\n",
      "        [23.2125, 18.5738, 18.9859],\n",
      "        [23.3928, 18.2720, 19.4016],\n",
      "        [23.5188, 18.5723, 19.7528],\n",
      "        [23.8019, 18.4830, 19.4270],\n",
      "        [23.3064, 18.1187, 19.4374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7883,  22.9733, -18.3676],\n",
      "        [-21.8938,  23.2029, -18.8703],\n",
      "        [-22.1846,  23.5762, -19.0006],\n",
      "        [-21.6491,  23.1262, -18.6786],\n",
      "        [-21.3069,  22.5244, -18.3708],\n",
      "        [-22.0946,  23.2944, -18.5363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.7753,  17.7095,  18.7056, -21.7883,  22.9733, -18.3676],\n",
      "        [ 23.2125,  18.5738,  18.9859, -21.8938,  23.2029, -18.8703],\n",
      "        [ 23.3928,  18.2720,  19.4016, -22.1846,  23.5762, -19.0006],\n",
      "        [ 23.5188,  18.5723,  19.7528, -21.6491,  23.1262, -18.6786],\n",
      "        [ 23.8019,  18.4830,  19.4270, -21.3069,  22.5244, -18.3708],\n",
      "        [ 23.3064,  18.1187,  19.4374, -22.0946,  23.2944, -18.5363]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.258175849914551\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5560, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3054, 18.2778, 19.3323],\n",
      "        [23.8644, 18.4748, 19.6723],\n",
      "        [23.2104, 18.1604, 19.4234],\n",
      "        [23.1084, 18.3367, 19.0698],\n",
      "        [23.2819, 18.2736, 19.1067],\n",
      "        [23.0825, 18.2685, 19.0786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.6637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7594,  23.3807, -18.6480],\n",
      "        [-22.1801,  23.2994, -19.0672],\n",
      "        [-21.3722,  22.3799, -18.3094],\n",
      "        [-21.8708,  23.2735, -18.6704],\n",
      "        [-21.9656,  23.1027, -18.5544],\n",
      "        [-22.0787,  23.6266, -18.8997]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3054,  18.2778,  19.3323, -21.7594,  23.3807, -18.6480],\n",
      "        [ 23.8644,  18.4748,  19.6723, -22.1801,  23.2994, -19.0672],\n",
      "        [ 23.2104,  18.1604,  19.4234, -21.3722,  22.3799, -18.3094],\n",
      "        [ 23.1084,  18.3367,  19.0698, -21.8708,  23.2735, -18.6704],\n",
      "        [ 23.2819,  18.2736,  19.1067, -21.9656,  23.1027, -18.5544],\n",
      "        [ 23.0825,  18.2685,  19.0786, -22.0787,  23.6266, -18.8997]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.347902774810791\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3604, 18.4604, 19.0442],\n",
      "        [23.1078, 18.3063, 18.7163],\n",
      "        [23.1608, 17.6678, 18.6878],\n",
      "        [23.9183, 18.5477, 19.6257],\n",
      "        [23.8264, 18.5328, 19.6372],\n",
      "        [23.7168, 18.6006, 19.6459]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1636,  23.0753, -18.7016],\n",
      "        [-21.5015,  22.9603, -18.3892],\n",
      "        [-22.0839,  23.4246, -18.6786],\n",
      "        [-21.9451,  23.4002, -18.4006],\n",
      "        [-21.6120,  23.1725, -18.3057],\n",
      "        [-21.2579,  22.8785, -18.3123]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3604,  18.4604,  19.0442, -22.1636,  23.0753, -18.7016],\n",
      "        [ 23.1078,  18.3063,  18.7163, -21.5015,  22.9603, -18.3892],\n",
      "        [ 23.1608,  17.6678,  18.6878, -22.0839,  23.4246, -18.6786],\n",
      "        [ 23.9183,  18.5477,  19.6257, -21.9451,  23.4002, -18.4006],\n",
      "        [ 23.8264,  18.5328,  19.6372, -21.6120,  23.1725, -18.3057],\n",
      "        [ 23.7168,  18.6006,  19.6459, -21.2579,  22.8785, -18.3123]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.349563121795654\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7672, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8933, 18.4837, 19.2721],\n",
      "        [23.9170, 18.2173, 20.1223],\n",
      "        [24.1728, 18.7975, 20.0222],\n",
      "        [23.3978, 18.5263, 19.2840],\n",
      "        [23.2747, 17.9181, 18.8571],\n",
      "        [23.7483, 18.5967, 19.3769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.1454, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8614,  23.4293, -18.5830],\n",
      "        [-22.0763,  23.0590, -18.4244],\n",
      "        [-21.7755,  23.3664, -18.6583],\n",
      "        [-21.8166,  23.0134, -18.1450],\n",
      "        [-22.1589,  23.3183, -18.5564],\n",
      "        [-21.9989,  23.3054, -18.5875]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8933,  18.4837,  19.2721, -21.8614,  23.4293, -18.5830],\n",
      "        [ 23.9170,  18.2173,  20.1223, -22.0763,  23.0590, -18.4244],\n",
      "        [ 24.1728,  18.7975,  20.0222, -21.7755,  23.3664, -18.6583],\n",
      "        [ 23.3978,  18.5263,  19.2840, -21.8166,  23.0134, -18.1450],\n",
      "        [ 23.2747,  17.9181,  18.8571, -22.1589,  23.3183, -18.5564],\n",
      "        [ 23.7483,  18.5967,  19.3769, -21.9989,  23.3054, -18.5875]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.387251377105713\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8428, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1954, 18.2747, 18.9137],\n",
      "        [23.1231, 18.1535, 19.1178],\n",
      "        [23.1067, 17.9159, 19.0725],\n",
      "        [23.5079, 18.1653, 19.1938],\n",
      "        [23.0183, 18.1683, 19.1350],\n",
      "        [23.3255, 18.3583, 19.0918]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2426, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9635,  23.4271, -18.2581],\n",
      "        [-21.8895,  23.0994, -18.8043],\n",
      "        [-21.5904,  23.1554, -18.5433],\n",
      "        [-21.5957,  22.8075, -18.5934],\n",
      "        [-21.5730,  23.1447, -18.4223],\n",
      "        [-22.1880,  23.5796, -18.8523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1954,  18.2747,  18.9137, -21.9635,  23.4271, -18.2581],\n",
      "        [ 23.1231,  18.1535,  19.1178, -21.8895,  23.0994, -18.8043],\n",
      "        [ 23.1067,  17.9159,  19.0725, -21.5904,  23.1554, -18.5433],\n",
      "        [ 23.5079,  18.1653,  19.1938, -21.5957,  22.8075, -18.5934],\n",
      "        [ 23.0183,  18.1683,  19.1350, -21.5730,  23.1447, -18.4223],\n",
      "        [ 23.3255,  18.3583,  19.0918, -22.1880,  23.5796, -18.8523]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.328360080718994\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9392, 17.8795, 18.6850],\n",
      "        [23.5647, 18.4569, 19.5412],\n",
      "        [23.5319, 18.3254, 19.0663],\n",
      "        [23.5631, 18.0211, 19.1827],\n",
      "        [23.1590, 17.8649, 19.5943],\n",
      "        [23.7374, 18.6052, 19.4605]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1420, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5339,  23.4455, -19.2834],\n",
      "        [-22.2357,  23.4136, -18.7623],\n",
      "        [-21.7254,  23.3753, -18.4097],\n",
      "        [-21.8073,  22.6614, -18.5829],\n",
      "        [-21.7849,  23.1849, -18.9501],\n",
      "        [-21.9476,  23.1542, -18.6241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9392,  17.8795,  18.6850, -22.5339,  23.4455, -19.2834],\n",
      "        [ 23.5647,  18.4569,  19.5412, -22.2357,  23.4136, -18.7623],\n",
      "        [ 23.5319,  18.3254,  19.0663, -21.7254,  23.3753, -18.4097],\n",
      "        [ 23.5631,  18.0211,  19.1827, -21.8073,  22.6614, -18.5829],\n",
      "        [ 23.1590,  17.8649,  19.5943, -21.7849,  23.1849, -18.9501],\n",
      "        [ 23.7374,  18.6052,  19.4605, -21.9476,  23.1542, -18.6241]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.338036060333252\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9557, 18.6838, 19.6608],\n",
      "        [22.9425, 17.7881, 18.9848],\n",
      "        [23.7209, 18.6018, 19.1450],\n",
      "        [23.8082, 18.6562, 19.2702],\n",
      "        [23.1149, 18.1990, 18.9030],\n",
      "        [23.5417, 18.7063, 19.4286]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.5998, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3275,  23.5400, -18.8330],\n",
      "        [-22.0685,  23.2216, -18.5318],\n",
      "        [-22.1590,  23.3621, -18.8619],\n",
      "        [-21.9578,  23.2878, -18.7788],\n",
      "        [-22.0755,  23.5321, -18.9041],\n",
      "        [-21.0835,  22.5908, -18.0371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9557,  18.6838,  19.6608, -22.3275,  23.5400, -18.8330],\n",
      "        [ 22.9425,  17.7881,  18.9848, -22.0685,  23.2216, -18.5318],\n",
      "        [ 23.7209,  18.6018,  19.1450, -22.1590,  23.3621, -18.8619],\n",
      "        [ 23.8082,  18.6562,  19.2702, -21.9578,  23.2878, -18.7788],\n",
      "        [ 23.1149,  18.1990,  18.9030, -22.0755,  23.5321, -18.9041],\n",
      "        [ 23.5417,  18.7063,  19.4286, -21.0835,  22.5908, -18.0371]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.4408278465271\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6241, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0269, 18.4718, 18.9858],\n",
      "        [22.9785, 17.9178, 19.0883],\n",
      "        [23.2402, 18.3030, 19.0785],\n",
      "        [23.6672, 18.5873, 19.7787],\n",
      "        [23.5423, 17.7694, 19.1616],\n",
      "        [23.2699, 18.2232, 19.2573]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9715, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6911,  23.2258, -19.0036],\n",
      "        [-22.3248,  23.3046, -18.4002],\n",
      "        [-21.7030,  22.6637, -18.3260],\n",
      "        [-21.9069,  23.2640, -18.6018],\n",
      "        [-21.5840,  22.8716, -18.2030],\n",
      "        [-22.1372,  23.5887, -18.8716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0269,  18.4718,  18.9858, -21.6911,  23.2258, -19.0036],\n",
      "        [ 22.9785,  17.9178,  19.0883, -22.3248,  23.3046, -18.4002],\n",
      "        [ 23.2402,  18.3030,  19.0785, -21.7030,  22.6637, -18.3260],\n",
      "        [ 23.6672,  18.5873,  19.7787, -21.9069,  23.2640, -18.6018],\n",
      "        [ 23.5423,  17.7694,  19.1616, -21.5840,  22.8716, -18.2030],\n",
      "        [ 23.2699,  18.2232,  19.2573, -22.1372,  23.5887, -18.8716]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.337041854858398\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0882, 17.8135, 19.0649],\n",
      "        [23.6842, 18.5414, 19.1419],\n",
      "        [23.4914, 18.3212, 19.5345],\n",
      "        [23.8212, 18.3188, 19.4151],\n",
      "        [23.5083, 18.5261, 19.5366],\n",
      "        [23.4838, 18.1307, 19.2593]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.5700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.5019,  22.9515, -18.2268],\n",
      "        [-21.3113,  23.0107, -18.4745],\n",
      "        [-22.4716,  23.1853, -18.8520],\n",
      "        [-21.7225,  23.1240, -18.7175],\n",
      "        [-22.3053,  23.5511, -18.7465],\n",
      "        [-22.5017,  23.0373, -19.0632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0882,  17.8135,  19.0649, -21.5019,  22.9515, -18.2268],\n",
      "        [ 23.6842,  18.5414,  19.1419, -21.3113,  23.0107, -18.4745],\n",
      "        [ 23.4914,  18.3212,  19.5345, -22.4716,  23.1853, -18.8520],\n",
      "        [ 23.8212,  18.3188,  19.4151, -21.7225,  23.1240, -18.7175],\n",
      "        [ 23.5083,  18.5261,  19.5366, -22.3053,  23.5511, -18.7465],\n",
      "        [ 23.4838,  18.1307,  19.2593, -22.5017,  23.0373, -19.0632]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.291906356811523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1306, 18.4670, 19.2993],\n",
      "        [23.2163, 18.3983, 19.1686],\n",
      "        [23.0911, 18.4911, 19.2916],\n",
      "        [22.9851, 18.1459, 19.1883],\n",
      "        [23.4601, 18.4931, 19.6593],\n",
      "        [23.0285, 18.2453, 19.1463]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.7035, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9779,  23.2494, -18.5541],\n",
      "        [-21.9791,  23.8469, -18.8434],\n",
      "        [-22.0824,  23.2226, -18.8017],\n",
      "        [-21.7107,  23.2237, -18.8529],\n",
      "        [-21.8425,  23.0029, -18.3436],\n",
      "        [-21.8346,  23.1060, -18.8065]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1306,  18.4670,  19.2993, -21.9779,  23.2494, -18.5541],\n",
      "        [ 23.2163,  18.3983,  19.1686, -21.9791,  23.8469, -18.8434],\n",
      "        [ 23.0911,  18.4911,  19.2916, -22.0824,  23.2226, -18.8017],\n",
      "        [ 22.9851,  18.1459,  19.1883, -21.7107,  23.2237, -18.8529],\n",
      "        [ 23.4601,  18.4931,  19.6593, -21.8425,  23.0029, -18.3436],\n",
      "        [ 23.0285,  18.2453,  19.1463, -21.8346,  23.1060, -18.8065]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.3568034172058105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9415, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9584, 18.4024, 19.2583],\n",
      "        [23.7625, 18.8618, 19.7780],\n",
      "        [23.5079, 18.2922, 18.9144],\n",
      "        [23.1438, 18.1841, 19.7171],\n",
      "        [24.0563, 18.6610, 19.6788],\n",
      "        [23.3051, 18.2600, 19.1997]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0803, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3302,  23.3924, -19.0668],\n",
      "        [-21.5184,  22.7638, -18.3777],\n",
      "        [-22.0443,  23.0816, -18.9985],\n",
      "        [-21.8810,  23.2084, -18.6325],\n",
      "        [-21.5319,  23.0121, -18.6825],\n",
      "        [-21.9127,  23.0903, -18.9098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9584,  18.4024,  19.2583, -22.3302,  23.3924, -19.0668],\n",
      "        [ 23.7625,  18.8618,  19.7780, -21.5184,  22.7638, -18.3777],\n",
      "        [ 23.5079,  18.2922,  18.9144, -22.0443,  23.0816, -18.9985],\n",
      "        [ 23.1438,  18.1841,  19.7171, -21.8810,  23.2084, -18.6325],\n",
      "        [ 24.0563,  18.6610,  19.6788, -21.5319,  23.0121, -18.6825],\n",
      "        [ 23.3051,  18.2600,  19.1997, -21.9127,  23.0903, -18.9098]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.423486709594727\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.0881, 18.5415, 19.4488],\n",
      "        [23.5968, 18.3628, 19.1998],\n",
      "        [23.6867, 18.7695, 19.6082],\n",
      "        [23.4025, 18.1597, 19.5622],\n",
      "        [23.6395, 18.6646, 19.0330],\n",
      "        [23.7776, 18.7236, 19.2223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.7060, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1761,  23.2018, -18.9326],\n",
      "        [-21.6817,  23.4046, -19.1421],\n",
      "        [-21.9412,  23.2425, -18.7808],\n",
      "        [-21.1180,  22.4665, -18.3002],\n",
      "        [-22.2955,  23.7824, -19.1814],\n",
      "        [-21.6291,  22.8812, -18.2388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.0881,  18.5415,  19.4488, -22.1761,  23.2018, -18.9326],\n",
      "        [ 23.5968,  18.3628,  19.1998, -21.6817,  23.4046, -19.1421],\n",
      "        [ 23.6867,  18.7695,  19.6082, -21.9412,  23.2425, -18.7808],\n",
      "        [ 23.4025,  18.1597,  19.5622, -21.1180,  22.4665, -18.3002],\n",
      "        [ 23.6395,  18.6646,  19.0330, -22.2955,  23.7824, -19.1814],\n",
      "        [ 23.7776,  18.7236,  19.2223, -21.6291,  22.8812, -18.2388]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.379873752593994\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6529, 18.8888, 19.3072],\n",
      "        [23.7480, 18.6867, 19.4394],\n",
      "        [23.5393, 18.7698, 19.4060],\n",
      "        [23.1880, 18.0836, 19.0345],\n",
      "        [23.4206, 18.1415, 19.2335],\n",
      "        [23.4772, 18.2631, 19.3225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.0262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5207,  23.8644, -19.1626],\n",
      "        [-22.0615,  23.4488, -18.4336],\n",
      "        [-22.4398,  23.4558, -18.9247],\n",
      "        [-21.8814,  23.4555, -18.7293],\n",
      "        [-21.9733,  23.3518, -18.4381],\n",
      "        [-22.0187,  23.3132, -18.9704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6529,  18.8888,  19.3072, -22.5207,  23.8644, -19.1626],\n",
      "        [ 23.7480,  18.6867,  19.4394, -22.0615,  23.4488, -18.4336],\n",
      "        [ 23.5393,  18.7698,  19.4060, -22.4398,  23.4558, -18.9247],\n",
      "        [ 23.1880,  18.0836,  19.0345, -21.8814,  23.4555, -18.7293],\n",
      "        [ 23.4206,  18.1415,  19.2335, -21.9733,  23.3518, -18.4381],\n",
      "        [ 23.4772,  18.2631,  19.3225, -22.0187,  23.3132, -18.9704]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.451612949371338\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7034, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7611, 18.5888, 19.8455],\n",
      "        [23.2649, 18.0242, 19.2334],\n",
      "        [23.1170, 18.5093, 19.4478],\n",
      "        [23.6396, 18.1627, 18.8351],\n",
      "        [23.5004, 18.3312, 19.4787],\n",
      "        [23.1860, 17.8936, 19.1056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9481,  23.1371, -18.6682],\n",
      "        [-22.0663,  23.3034, -19.0572],\n",
      "        [-21.4960,  23.1003, -18.6893],\n",
      "        [-21.5130,  22.6387, -18.5718],\n",
      "        [-22.0390,  23.0339, -18.7132],\n",
      "        [-22.3065,  23.9842, -19.1429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7611,  18.5888,  19.8455, -21.9481,  23.1371, -18.6682],\n",
      "        [ 23.2649,  18.0242,  19.2334, -22.0663,  23.3034, -19.0572],\n",
      "        [ 23.1170,  18.5093,  19.4478, -21.4960,  23.1003, -18.6893],\n",
      "        [ 23.6396,  18.1627,  18.8351, -21.5130,  22.6387, -18.5718],\n",
      "        [ 23.5004,  18.3312,  19.4787, -22.0390,  23.0339, -18.7132],\n",
      "        [ 23.1860,  17.8936,  19.1056, -22.3065,  23.9842, -19.1429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.419227600097656\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6880, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9604, 18.7423, 19.6713],\n",
      "        [23.6929, 18.4979, 19.4850],\n",
      "        [23.2181, 18.4304, 19.0655],\n",
      "        [23.0397, 18.2093, 19.1718],\n",
      "        [22.9605, 18.2648, 19.2084],\n",
      "        [23.3608, 17.9916, 19.3121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.9334, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5794,  24.1541, -19.2492],\n",
      "        [-21.9207,  23.2261, -18.7688],\n",
      "        [-21.4682,  22.7341, -18.4148],\n",
      "        [-22.1610,  23.3173, -18.9477],\n",
      "        [-21.7915,  22.8479, -18.4192],\n",
      "        [-22.6660,  23.8810, -19.0310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9604,  18.7423,  19.6713, -22.5794,  24.1541, -19.2492],\n",
      "        [ 23.6929,  18.4979,  19.4850, -21.9207,  23.2261, -18.7688],\n",
      "        [ 23.2181,  18.4304,  19.0655, -21.4682,  22.7341, -18.4148],\n",
      "        [ 23.0397,  18.2093,  19.1718, -22.1610,  23.3173, -18.9477],\n",
      "        [ 22.9605,  18.2648,  19.2084, -21.7915,  22.8479, -18.4192],\n",
      "        [ 23.3608,  17.9916,  19.3121, -22.6660,  23.8810, -19.0310]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.49400520324707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3384, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7243, 18.4948, 19.4950],\n",
      "        [23.7264, 18.0895, 19.4437],\n",
      "        [23.4583, 18.4719, 19.1973],\n",
      "        [23.8339, 18.3411, 19.4251],\n",
      "        [23.2423, 17.9158, 19.1053],\n",
      "        [23.4361, 17.9703, 19.4856]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.6526, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5196,  23.7963, -19.4147],\n",
      "        [-21.6868,  23.1617, -18.9680],\n",
      "        [-22.2799,  23.2657, -18.9337],\n",
      "        [-21.7853,  23.3032, -18.9579],\n",
      "        [-21.6069,  23.1692, -18.6609],\n",
      "        [-22.0757,  23.1846, -18.7528]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7243,  18.4948,  19.4950, -22.5196,  23.7963, -19.4147],\n",
      "        [ 23.7264,  18.0895,  19.4437, -21.6868,  23.1617, -18.9680],\n",
      "        [ 23.4583,  18.4719,  19.1973, -22.2799,  23.2657, -18.9337],\n",
      "        [ 23.8339,  18.3411,  19.4251, -21.7853,  23.3032, -18.9579],\n",
      "        [ 23.2423,  17.9158,  19.1053, -21.6069,  23.1692, -18.6609],\n",
      "        [ 23.4361,  17.9703,  19.4856, -22.0757,  23.1846, -18.7528]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.459785461425781\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8297, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5461, 18.5265, 19.8564],\n",
      "        [22.7283, 18.2819, 19.0621],\n",
      "        [23.6502, 18.6781, 19.7202],\n",
      "        [23.2940, 17.8599, 19.1523],\n",
      "        [23.5659, 18.6502, 19.7422],\n",
      "        [23.7331, 18.5989, 19.7519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1419, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3145,  23.5056, -18.7652],\n",
      "        [-21.7082,  23.1642, -18.6021],\n",
      "        [-21.9663,  23.3294, -18.5330],\n",
      "        [-22.2569,  23.5829, -18.7748],\n",
      "        [-21.9388,  23.0172, -18.6664],\n",
      "        [-21.8940,  23.3688, -18.9168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5461,  18.5265,  19.8564, -22.3145,  23.5056, -18.7652],\n",
      "        [ 22.7283,  18.2819,  19.0621, -21.7082,  23.1642, -18.6021],\n",
      "        [ 23.6502,  18.6781,  19.7202, -21.9663,  23.3294, -18.5330],\n",
      "        [ 23.2940,  17.8599,  19.1523, -22.2569,  23.5829, -18.7748],\n",
      "        [ 23.5659,  18.6502,  19.7422, -21.9388,  23.0172, -18.6664],\n",
      "        [ 23.7331,  18.5989,  19.7519, -21.8940,  23.3688, -18.9168]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.437257766723633\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5659, 18.4446, 19.3827],\n",
      "        [24.1343, 18.7229, 19.9230],\n",
      "        [23.2480, 18.4962, 19.2615],\n",
      "        [24.0227, 19.0118, 19.8130],\n",
      "        [24.0962, 18.5650, 19.7935],\n",
      "        [23.8885, 18.6708, 19.9783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.4460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9568,  23.0583, -18.9182],\n",
      "        [-21.9976,  23.4594, -18.7952],\n",
      "        [-21.8797,  23.3863, -18.4649],\n",
      "        [-22.6830,  23.8970, -19.2821],\n",
      "        [-22.2584,  23.1347, -18.8055],\n",
      "        [-21.7651,  23.1998, -18.7168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5659,  18.4446,  19.3827, -21.9568,  23.0583, -18.9182],\n",
      "        [ 24.1343,  18.7229,  19.9230, -21.9976,  23.4594, -18.7952],\n",
      "        [ 23.2480,  18.4962,  19.2615, -21.8797,  23.3863, -18.4649],\n",
      "        [ 24.0227,  19.0118,  19.8130, -22.6830,  23.8970, -19.2821],\n",
      "        [ 24.0962,  18.5650,  19.7935, -22.2584,  23.1347, -18.8055],\n",
      "        [ 23.8885,  18.6708,  19.9783, -21.7651,  23.1998, -18.7168]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.39642333984375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1413, 18.5363, 19.3017],\n",
      "        [23.6038, 18.5931, 19.1572],\n",
      "        [23.2971, 18.5072, 19.2132],\n",
      "        [23.3186, 18.2344, 18.9490],\n",
      "        [23.4067, 18.5346, 19.1964],\n",
      "        [24.1248, 18.9920, 19.8164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.7556, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9078,  22.9625, -18.1829],\n",
      "        [-22.1392,  23.4077, -19.1631],\n",
      "        [-21.9651,  23.5387, -18.7315],\n",
      "        [-21.7730,  23.3469, -19.1228],\n",
      "        [-22.2313,  23.5446, -19.1200],\n",
      "        [-21.9560,  23.2474, -18.8355]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1413,  18.5363,  19.3017, -21.9078,  22.9625, -18.1829],\n",
      "        [ 23.6038,  18.5931,  19.1572, -22.1392,  23.4077, -19.1631],\n",
      "        [ 23.2971,  18.5072,  19.2132, -21.9651,  23.5387, -18.7315],\n",
      "        [ 23.3186,  18.2344,  18.9490, -21.7730,  23.3469, -19.1228],\n",
      "        [ 23.4067,  18.5346,  19.1964, -22.2313,  23.5446, -19.1200],\n",
      "        [ 24.1248,  18.9920,  19.8164, -21.9560,  23.2474, -18.8355]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.354068756103516\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2702, 19.1184, 19.9281],\n",
      "        [23.4363, 18.5772, 19.2630],\n",
      "        [23.4240, 18.3357, 19.4977],\n",
      "        [23.0720, 17.3899, 19.2846],\n",
      "        [23.4955, 18.4108, 19.7063],\n",
      "        [23.7225, 18.1143, 19.4677]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.4338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3711,  23.7573, -18.7183],\n",
      "        [-22.3710,  23.9305, -19.0868],\n",
      "        [-22.0951,  23.3274, -18.5544],\n",
      "        [-22.0299,  23.2617, -18.4754],\n",
      "        [-21.5959,  22.9124, -18.3988],\n",
      "        [-22.1735,  23.3187, -18.8095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2702,  19.1184,  19.9281, -22.3711,  23.7573, -18.7183],\n",
      "        [ 23.4363,  18.5772,  19.2630, -22.3710,  23.9305, -19.0868],\n",
      "        [ 23.4240,  18.3357,  19.4977, -22.0951,  23.3274, -18.5544],\n",
      "        [ 23.0720,  17.3899,  19.2846, -22.0299,  23.2617, -18.4754],\n",
      "        [ 23.4955,  18.4108,  19.7063, -21.5959,  22.9124, -18.3988],\n",
      "        [ 23.7225,  18.1143,  19.4677, -22.1735,  23.3187, -18.8095]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.50817346572876\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2480, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6535, 18.4747, 19.3943],\n",
      "        [23.3039, 18.1143, 19.1173],\n",
      "        [23.3529, 18.4521, 19.7497],\n",
      "        [23.2718, 18.3253, 19.1732],\n",
      "        [23.3305, 18.3264, 19.4308],\n",
      "        [23.6865, 18.6155, 19.1730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.0892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4330,  23.4056, -19.1275],\n",
      "        [-21.9662,  23.3783, -18.2827],\n",
      "        [-22.0593,  23.4209, -18.9325],\n",
      "        [-21.8897,  22.7891, -18.6473],\n",
      "        [-22.1527,  23.7035, -18.9499],\n",
      "        [-22.1021,  23.2338, -18.4478]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6535,  18.4747,  19.3943, -22.4330,  23.4056, -19.1275],\n",
      "        [ 23.3039,  18.1143,  19.1173, -21.9662,  23.3783, -18.2827],\n",
      "        [ 23.3529,  18.4521,  19.7497, -22.0593,  23.4209, -18.9325],\n",
      "        [ 23.2718,  18.3253,  19.1732, -21.8897,  22.7891, -18.6473],\n",
      "        [ 23.3305,  18.3264,  19.4308, -22.1527,  23.7035, -18.9499],\n",
      "        [ 23.6865,  18.6155,  19.1730, -22.1021,  23.2338, -18.4478]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.437771797180176\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5244, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9625, 18.7181, 19.0385],\n",
      "        [23.6399, 18.7985, 19.3432],\n",
      "        [23.9857, 18.7848, 19.5870],\n",
      "        [23.7624, 19.1822, 20.2416],\n",
      "        [23.3800, 18.5260, 19.7089],\n",
      "        [23.4589, 18.3327, 19.4146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8992, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5308,  23.5122, -18.8814],\n",
      "        [-21.5032,  23.1878, -18.7762],\n",
      "        [-21.9185,  23.2661, -18.3114],\n",
      "        [-22.1909,  23.4317, -18.8927],\n",
      "        [-22.7313,  24.1003, -19.2734],\n",
      "        [-22.0596,  23.0951, -18.6630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9625,  18.7181,  19.0385, -22.5308,  23.5122, -18.8814],\n",
      "        [ 23.6399,  18.7985,  19.3432, -21.5032,  23.1878, -18.7762],\n",
      "        [ 23.9857,  18.7848,  19.5870, -21.9185,  23.2661, -18.3114],\n",
      "        [ 23.7624,  19.1822,  20.2416, -22.1909,  23.4317, -18.8927],\n",
      "        [ 23.3800,  18.5260,  19.7089, -22.7313,  24.1003, -19.2734],\n",
      "        [ 23.4589,  18.3327,  19.4146, -22.0596,  23.0951, -18.6630]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.398132801055908\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7453, 18.1180, 19.1906],\n",
      "        [23.8095, 18.5345, 19.4722],\n",
      "        [23.9671, 18.4586, 19.8313],\n",
      "        [23.3340, 18.2238, 19.3511],\n",
      "        [23.8311, 18.7307, 19.6897],\n",
      "        [23.4270, 18.5972, 19.4285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2302, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1068,  23.2738, -18.3222],\n",
      "        [-22.1337,  23.2700, -18.7870],\n",
      "        [-22.2046,  23.0245, -18.5151],\n",
      "        [-21.9500,  23.4514, -19.0301],\n",
      "        [-22.0475,  23.3226, -18.8330],\n",
      "        [-22.3182,  23.6524, -18.5556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7453,  18.1180,  19.1906, -22.1068,  23.2738, -18.3222],\n",
      "        [ 23.8095,  18.5345,  19.4722, -22.1337,  23.2700, -18.7870],\n",
      "        [ 23.9671,  18.4586,  19.8313, -22.2046,  23.0245, -18.5151],\n",
      "        [ 23.3340,  18.2238,  19.3511, -21.9500,  23.4514, -19.0301],\n",
      "        [ 23.8311,  18.7307,  19.6897, -22.0475,  23.3226, -18.8330],\n",
      "        [ 23.4270,  18.5972,  19.4285, -22.3182,  23.6524, -18.5556]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.3928680419921875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.9792, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5779, 18.4095, 19.4117],\n",
      "        [23.6520, 18.4165, 18.9882],\n",
      "        [23.2949, 18.4445, 19.4899],\n",
      "        [23.5973, 18.7177, 19.6117],\n",
      "        [23.6749, 18.3070, 19.2643],\n",
      "        [23.8720, 18.9327, 19.6277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.1253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.2934,  23.2084, -18.2833],\n",
      "        [-22.2176,  23.4191, -19.0289],\n",
      "        [-21.9339,  23.5667, -19.2157],\n",
      "        [-22.5108,  23.7069, -19.0318],\n",
      "        [-22.1240,  23.4452, -19.1683],\n",
      "        [-21.5932,  22.8503, -18.5220]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5779,  18.4095,  19.4117, -21.2934,  23.2084, -18.2833],\n",
      "        [ 23.6520,  18.4165,  18.9882, -22.2176,  23.4191, -19.0289],\n",
      "        [ 23.2949,  18.4445,  19.4899, -21.9339,  23.5667, -19.2157],\n",
      "        [ 23.5973,  18.7177,  19.6117, -22.5108,  23.7069, -19.0318],\n",
      "        [ 23.6749,  18.3070,  19.2643, -22.1240,  23.4452, -19.1683],\n",
      "        [ 23.8720,  18.9327,  19.6277, -21.5932,  22.8503, -18.5220]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.376605033874512\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9722, 18.9627, 19.8988],\n",
      "        [23.3855, 18.3690, 19.4326],\n",
      "        [24.0931, 19.0306, 19.9499],\n",
      "        [23.4401, 18.7118, 19.3659],\n",
      "        [23.7617, 18.8343, 19.4795],\n",
      "        [23.7115, 18.6285, 19.9000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3294, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8778,  23.4860, -19.3562],\n",
      "        [-21.9108,  22.7437, -18.2305],\n",
      "        [-22.9277,  24.0443, -19.5113],\n",
      "        [-22.3072,  23.6211, -19.2880],\n",
      "        [-21.6228,  23.0609, -18.6964],\n",
      "        [-22.1090,  23.4208, -18.9527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9722,  18.9627,  19.8988, -21.8778,  23.4860, -19.3562],\n",
      "        [ 23.3855,  18.3690,  19.4326, -21.9108,  22.7437, -18.2305],\n",
      "        [ 24.0931,  19.0306,  19.9499, -22.9277,  24.0443, -19.5113],\n",
      "        [ 23.4401,  18.7118,  19.3659, -22.3072,  23.6211, -19.2880],\n",
      "        [ 23.7617,  18.8343,  19.4795, -21.6228,  23.0609, -18.6964],\n",
      "        [ 23.7115,  18.6285,  19.9000, -22.1090,  23.4208, -18.9527]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.487539291381836\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5811, 18.4245, 19.6074],\n",
      "        [23.3086, 18.2423, 19.2941],\n",
      "        [23.4238, 18.5287, 19.8686],\n",
      "        [23.4714, 18.5158, 19.5260],\n",
      "        [24.2266, 19.1106, 19.8106],\n",
      "        [23.0745, 18.7493, 19.2667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.5064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2096,  23.4473, -18.7711],\n",
      "        [-21.8933,  23.2384, -18.5905],\n",
      "        [-21.8579,  23.0758, -18.5378],\n",
      "        [-22.1636,  23.2958, -18.7787],\n",
      "        [-22.5641,  23.8272, -19.1880],\n",
      "        [-22.3164,  23.1402, -18.8731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5811,  18.4245,  19.6074, -22.2096,  23.4473, -18.7711],\n",
      "        [ 23.3086,  18.2423,  19.2941, -21.8933,  23.2384, -18.5905],\n",
      "        [ 23.4238,  18.5287,  19.8686, -21.8579,  23.0758, -18.5378],\n",
      "        [ 23.4714,  18.5158,  19.5260, -22.1636,  23.2958, -18.7787],\n",
      "        [ 24.2266,  19.1106,  19.8106, -22.5641,  23.8272, -19.1880],\n",
      "        [ 23.0745,  18.7493,  19.2667, -22.3164,  23.1402, -18.8731]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.435761451721191\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8545, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4028, 18.3065, 19.4681],\n",
      "        [23.0590, 17.9462, 19.2069],\n",
      "        [23.4412, 18.5823, 19.6434],\n",
      "        [23.9743, 19.0179, 19.7722],\n",
      "        [23.1549, 18.1844, 19.2497],\n",
      "        [23.6653, 18.5431, 19.7794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8091,  23.9100, -19.3781],\n",
      "        [-22.3232,  23.5458, -19.2677],\n",
      "        [-22.6655,  24.0070, -19.3820],\n",
      "        [-22.1256,  23.3016, -19.2080],\n",
      "        [-21.7542,  23.2545, -18.9544],\n",
      "        [-22.2927,  23.4671, -18.7085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4028,  18.3065,  19.4681, -22.8091,  23.9100, -19.3781],\n",
      "        [ 23.0590,  17.9462,  19.2069, -22.3232,  23.5458, -19.2677],\n",
      "        [ 23.4412,  18.5823,  19.6434, -22.6655,  24.0070, -19.3820],\n",
      "        [ 23.9743,  19.0179,  19.7722, -22.1256,  23.3016, -19.2080],\n",
      "        [ 23.1549,  18.1844,  19.2497, -21.7542,  23.2545, -18.9544],\n",
      "        [ 23.6653,  18.5431,  19.7794, -22.2927,  23.4671, -18.7085]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.466897010803223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4151, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5449, 18.8709, 19.7062],\n",
      "        [23.2516, 18.3022, 19.3988],\n",
      "        [23.3123, 18.4939, 19.1685],\n",
      "        [23.3606, 18.6281, 19.3142],\n",
      "        [23.4902, 18.2862, 19.3127],\n",
      "        [23.7495, 18.5491, 19.3416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.7967, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2459,  23.5879, -19.1658],\n",
      "        [-22.3514,  23.6993, -18.8619],\n",
      "        [-22.0836,  23.0969, -18.7774],\n",
      "        [-22.1850,  23.3641, -19.0796],\n",
      "        [-21.5410,  23.2381, -18.6884],\n",
      "        [-21.9588,  23.0283, -18.4495]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5449,  18.8709,  19.7062, -22.2459,  23.5879, -19.1658],\n",
      "        [ 23.2516,  18.3022,  19.3988, -22.3514,  23.6993, -18.8619],\n",
      "        [ 23.3123,  18.4939,  19.1685, -22.0836,  23.0969, -18.7774],\n",
      "        [ 23.3606,  18.6281,  19.3142, -22.1850,  23.3641, -19.0796],\n",
      "        [ 23.4902,  18.2862,  19.3127, -21.5410,  23.2381, -18.6884],\n",
      "        [ 23.7495,  18.5491,  19.3416, -21.9588,  23.0283, -18.4495]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.470249176025391\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1079, 18.8410, 19.6715],\n",
      "        [23.9082, 18.7774, 19.6948],\n",
      "        [23.6931, 18.5414, 19.4297],\n",
      "        [23.2052, 18.1676, 18.8794],\n",
      "        [23.9114, 18.6347, 19.7640],\n",
      "        [23.3203, 18.1602, 18.9155]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.4378, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1795,  23.1899, -18.6045],\n",
      "        [-22.1153,  23.3538, -19.0509],\n",
      "        [-22.7349,  24.2279, -19.4109],\n",
      "        [-22.1046,  23.4441, -19.2019],\n",
      "        [-21.8068,  22.6038, -18.7689],\n",
      "        [-22.0223,  23.7019, -19.1992]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1079,  18.8410,  19.6715, -22.1795,  23.1899, -18.6045],\n",
      "        [ 23.9082,  18.7774,  19.6948, -22.1153,  23.3538, -19.0509],\n",
      "        [ 23.6931,  18.5414,  19.4297, -22.7349,  24.2279, -19.4109],\n",
      "        [ 23.2052,  18.1676,  18.8794, -22.1046,  23.4441, -19.2019],\n",
      "        [ 23.9114,  18.6347,  19.7640, -21.8068,  22.6038, -18.7689],\n",
      "        [ 23.3203,  18.1602,  18.9155, -22.0223,  23.7019, -19.1992]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.469266414642334\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2707, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8206, 18.8008, 19.6249],\n",
      "        [22.9412, 18.0579, 18.9925],\n",
      "        [23.2998, 18.6609, 19.2466],\n",
      "        [23.0773, 18.0577, 19.0951],\n",
      "        [24.0108, 18.8921, 20.0494],\n",
      "        [24.1274, 18.5114, 19.7997]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1494, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6616,  23.1500, -18.7716],\n",
      "        [-22.4095,  23.7463, -19.3290],\n",
      "        [-21.9464,  23.3807, -18.7533],\n",
      "        [-22.0216,  23.4301, -18.8340],\n",
      "        [-22.1571,  23.1279, -18.8565],\n",
      "        [-21.9902,  23.6830, -18.7191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8206,  18.8008,  19.6249, -21.6616,  23.1500, -18.7716],\n",
      "        [ 22.9412,  18.0579,  18.9925, -22.4095,  23.7463, -19.3290],\n",
      "        [ 23.2998,  18.6609,  19.2466, -21.9464,  23.3807, -18.7533],\n",
      "        [ 23.0773,  18.0577,  19.0951, -22.0216,  23.4301, -18.8340],\n",
      "        [ 24.0108,  18.8921,  20.0494, -22.1571,  23.1279, -18.8565],\n",
      "        [ 24.1274,  18.5114,  19.7997, -21.9902,  23.6830, -18.7191]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.440499782562256\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3522, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7827, 18.4906, 19.9263],\n",
      "        [23.5568, 18.4296, 19.2437],\n",
      "        [23.3980, 17.9997, 19.5201],\n",
      "        [24.1268, 19.3749, 19.9584],\n",
      "        [23.7715, 18.6319, 19.4038],\n",
      "        [23.1898, 18.4819, 19.2608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1712, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4750,  24.0077, -19.3732],\n",
      "        [-22.2167,  23.2985, -19.1249],\n",
      "        [-22.0912,  23.7500, -18.7950],\n",
      "        [-21.6109,  23.4978, -18.4272],\n",
      "        [-22.1673,  23.5353, -19.0690],\n",
      "        [-22.7431,  23.7501, -19.0193]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7827,  18.4906,  19.9263, -22.4750,  24.0077, -19.3732],\n",
      "        [ 23.5568,  18.4296,  19.2437, -22.2167,  23.2985, -19.1249],\n",
      "        [ 23.3980,  17.9997,  19.5201, -22.0912,  23.7500, -18.7950],\n",
      "        [ 24.1268,  19.3749,  19.9584, -21.6109,  23.4978, -18.4272],\n",
      "        [ 23.7715,  18.6319,  19.4038, -22.1673,  23.5353, -19.0690],\n",
      "        [ 23.1898,  18.4819,  19.2608, -22.7431,  23.7501, -19.0193]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.510201454162598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4926, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.2837, 18.7673, 19.2420],\n",
      "        [23.7119, 18.8707, 19.6865],\n",
      "        [23.8765, 18.5465, 19.2755],\n",
      "        [23.6996, 18.2233, 19.7135],\n",
      "        [23.7838, 18.9625, 19.8531],\n",
      "        [23.7739, 18.8933, 19.7970]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.9925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9621,  24.3017, -19.7559],\n",
      "        [-21.7617,  23.4308, -18.5918],\n",
      "        [-22.6558,  24.0589, -19.2233],\n",
      "        [-22.4692,  23.2848, -18.4274],\n",
      "        [-22.1612,  23.5523, -18.8591],\n",
      "        [-22.0034,  23.3131, -18.5182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.2837,  18.7673,  19.2420, -22.9621,  24.3017, -19.7559],\n",
      "        [ 23.7119,  18.8707,  19.6865, -21.7617,  23.4308, -18.5918],\n",
      "        [ 23.8765,  18.5465,  19.2755, -22.6558,  24.0589, -19.2233],\n",
      "        [ 23.6996,  18.2233,  19.7135, -22.4692,  23.2848, -18.4274],\n",
      "        [ 23.7838,  18.9625,  19.8531, -22.1612,  23.5523, -18.8591],\n",
      "        [ 23.7739,  18.8933,  19.7970, -22.0034,  23.3131, -18.5182]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.500629425048828\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8881, 18.3049, 19.5741],\n",
      "        [23.8760, 18.8072, 19.6056],\n",
      "        [23.7301, 18.5824, 19.6073],\n",
      "        [23.5101, 18.6805, 19.2914],\n",
      "        [23.8043, 18.5904, 19.5575],\n",
      "        [23.8123, 19.0164, 19.8295]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7270,  23.3040, -19.1241],\n",
      "        [-22.7922,  24.0113, -19.5860],\n",
      "        [-22.7967,  23.7831, -19.2912],\n",
      "        [-22.2790,  23.6083, -19.0338],\n",
      "        [-22.2005,  23.4480, -19.1327],\n",
      "        [-22.0271,  23.1535, -18.4435]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8881,  18.3049,  19.5741, -21.7270,  23.3040, -19.1241],\n",
      "        [ 23.8760,  18.8072,  19.6056, -22.7922,  24.0113, -19.5860],\n",
      "        [ 23.7301,  18.5824,  19.6073, -22.7967,  23.7831, -19.2912],\n",
      "        [ 23.5101,  18.6805,  19.2914, -22.2790,  23.6083, -19.0338],\n",
      "        [ 23.8043,  18.5904,  19.5575, -22.2005,  23.4480, -19.1327],\n",
      "        [ 23.8123,  19.0164,  19.8295, -22.0271,  23.1535, -18.4435]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.447079658508301\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6419, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.3602, 18.4994, 19.4756],\n",
      "        [23.1680, 18.1929, 19.1419],\n",
      "        [24.0262, 18.4245, 19.7246],\n",
      "        [23.3976, 18.4090, 19.6912],\n",
      "        [23.5705, 18.3450, 19.6684],\n",
      "        [23.7663, 18.3609, 19.5712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7847, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2519,  23.7614, -19.0502],\n",
      "        [-22.4605,  23.7005, -18.9603],\n",
      "        [-21.8965,  23.4989, -18.6828],\n",
      "        [-22.0861,  23.3892, -19.0560],\n",
      "        [-22.2676,  23.7438, -19.3119],\n",
      "        [-21.8631,  23.1770, -18.8331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.3602,  18.4994,  19.4756, -22.2519,  23.7614, -19.0502],\n",
      "        [ 23.1680,  18.1929,  19.1419, -22.4605,  23.7005, -18.9603],\n",
      "        [ 24.0262,  18.4245,  19.7246, -21.8965,  23.4989, -18.6828],\n",
      "        [ 23.3976,  18.4090,  19.6912, -22.0861,  23.3892, -19.0560],\n",
      "        [ 23.5705,  18.3450,  19.6684, -22.2676,  23.7438, -19.3119],\n",
      "        [ 23.7663,  18.3609,  19.5712, -21.8631,  23.1770, -18.8331]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.453127384185791\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1935, 18.9048, 20.0162],\n",
      "        [23.5189, 18.7304, 19.4767],\n",
      "        [24.1067, 19.1598, 19.8169],\n",
      "        [23.6973, 18.6842, 19.5955],\n",
      "        [23.9419, 18.4813, 19.1990],\n",
      "        [23.5476, 18.7479, 19.3647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.0161, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7812,  23.3955, -18.6365],\n",
      "        [-22.3636,  23.7891, -18.9877],\n",
      "        [-21.9720,  23.7269, -19.0009],\n",
      "        [-21.8416,  23.2291, -18.9671],\n",
      "        [-22.4242,  23.5732, -19.0829],\n",
      "        [-22.4565,  23.8055, -19.3038]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1935,  18.9048,  20.0162, -21.7812,  23.3955, -18.6365],\n",
      "        [ 23.5189,  18.7304,  19.4767, -22.3636,  23.7891, -18.9877],\n",
      "        [ 24.1067,  19.1598,  19.8169, -21.9720,  23.7269, -19.0009],\n",
      "        [ 23.6973,  18.6842,  19.5955, -21.8416,  23.2291, -18.9671],\n",
      "        [ 23.9419,  18.4813,  19.1990, -22.4242,  23.5732, -19.0829],\n",
      "        [ 23.5476,  18.7479,  19.3647, -22.4565,  23.8055, -19.3038]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.495224475860596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9192, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7081, 18.5178, 19.9187],\n",
      "        [23.8190, 18.5664, 19.7440],\n",
      "        [23.7189, 18.3801, 19.2799],\n",
      "        [23.6907, 18.5289, 19.3430],\n",
      "        [24.1699, 18.9926, 19.8801],\n",
      "        [23.4903, 18.6901, 19.7396]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7623, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7762,  23.4642, -19.0307],\n",
      "        [-22.0119,  23.2763, -18.7852],\n",
      "        [-22.3260,  23.8918, -19.6217],\n",
      "        [-22.2127,  23.7921, -18.9948],\n",
      "        [-22.6678,  23.8339, -19.0794],\n",
      "        [-22.6673,  23.8231, -19.3399]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7081,  18.5178,  19.9187, -21.7762,  23.4642, -19.0307],\n",
      "        [ 23.8190,  18.5664,  19.7440, -22.0119,  23.2763, -18.7852],\n",
      "        [ 23.7189,  18.3801,  19.2799, -22.3260,  23.8918, -19.6217],\n",
      "        [ 23.6907,  18.5289,  19.3430, -22.2127,  23.7921, -18.9948],\n",
      "        [ 24.1699,  18.9926,  19.8801, -22.6678,  23.8339, -19.0794],\n",
      "        [ 23.4903,  18.6901,  19.7396, -22.6673,  23.8231, -19.3399]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.468293190002441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5794, 18.4553, 19.5472],\n",
      "        [23.6689, 18.5500, 19.5966],\n",
      "        [23.7081, 18.8789, 19.3655],\n",
      "        [23.3074, 18.0995, 19.7014],\n",
      "        [23.4538, 18.8911, 18.9185],\n",
      "        [23.6253, 18.6239, 19.7090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.0334, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.9394,  23.4669, -18.6197],\n",
      "        [-22.0374,  23.1539, -19.0355],\n",
      "        [-22.6339,  23.8947, -18.8332],\n",
      "        [-22.0330,  23.4185, -18.8432],\n",
      "        [-22.1133,  23.1490, -18.5735],\n",
      "        [-22.1379,  24.0841, -19.3067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5794,  18.4553,  19.5472, -21.9394,  23.4669, -18.6197],\n",
      "        [ 23.6689,  18.5500,  19.5966, -22.0374,  23.1539, -19.0355],\n",
      "        [ 23.7081,  18.8789,  19.3655, -22.6339,  23.8947, -18.8332],\n",
      "        [ 23.3074,  18.0995,  19.7014, -22.0330,  23.4185, -18.8432],\n",
      "        [ 23.4538,  18.8911,  18.9185, -22.1133,  23.1490, -18.5735],\n",
      "        [ 23.6253,  18.6239,  19.7090, -22.1379,  24.0841, -19.3067]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.441220283508301\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4654, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4325, 18.4707, 19.3777],\n",
      "        [23.7171, 18.4900, 19.2350],\n",
      "        [23.4115, 17.9770, 19.5240],\n",
      "        [24.0931, 19.3068, 19.7977],\n",
      "        [23.1869, 18.1539, 19.4974],\n",
      "        [23.4138, 18.1048, 19.0774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.3182, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6368,  23.2977, -18.4986],\n",
      "        [-21.6979,  23.0680, -18.5682],\n",
      "        [-22.6097,  24.1669, -19.5225],\n",
      "        [-22.1718,  23.5443, -19.1933],\n",
      "        [-22.0259,  23.5121, -19.1669],\n",
      "        [-22.2525,  23.3057, -18.8983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4325,  18.4707,  19.3777, -21.6368,  23.2977, -18.4986],\n",
      "        [ 23.7171,  18.4900,  19.2350, -21.6979,  23.0680, -18.5682],\n",
      "        [ 23.4115,  17.9770,  19.5240, -22.6097,  24.1669, -19.5225],\n",
      "        [ 24.0931,  19.3068,  19.7977, -22.1718,  23.5443, -19.1933],\n",
      "        [ 23.1869,  18.1539,  19.4974, -22.0259,  23.5121, -19.1669],\n",
      "        [ 23.4138,  18.1048,  19.0774, -22.2525,  23.3057, -18.8983]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.411327838897705\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.1061, 18.4641, 19.2127],\n",
      "        [23.8526, 18.5385, 19.4821],\n",
      "        [23.7429, 18.6777, 19.3316],\n",
      "        [23.3123, 18.2743, 19.4457],\n",
      "        [23.3349, 18.3616, 19.3522],\n",
      "        [23.7217, 19.2010, 19.7824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0076,  23.6717, -19.1070],\n",
      "        [-22.3243,  23.5036, -18.8644],\n",
      "        [-22.7255,  23.7232, -19.3128],\n",
      "        [-22.1522,  23.9553, -18.9894],\n",
      "        [-22.0533,  23.5461, -19.1976],\n",
      "        [-22.6130,  23.2473, -18.8500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.1061,  18.4641,  19.2127, -22.0076,  23.6717, -19.1070],\n",
      "        [ 23.8526,  18.5385,  19.4821, -22.3243,  23.5036, -18.8644],\n",
      "        [ 23.7429,  18.6777,  19.3316, -22.7255,  23.7232, -19.3128],\n",
      "        [ 23.3123,  18.2743,  19.4457, -22.1522,  23.9553, -18.9894],\n",
      "        [ 23.3349,  18.3616,  19.3522, -22.0533,  23.5461, -19.1976],\n",
      "        [ 23.7217,  19.2010,  19.7824, -22.6130,  23.2473, -18.8500]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.427781105041504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8956, 19.1227, 20.2984],\n",
      "        [23.9250, 18.9330, 19.3886],\n",
      "        [24.0451, 19.1583, 19.8379],\n",
      "        [23.6188, 18.3864, 19.3741],\n",
      "        [23.4766, 18.3656, 19.8343],\n",
      "        [23.9387, 18.8501, 19.5400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.1691, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3439,  23.2398, -19.1513],\n",
      "        [-22.2525,  23.4169, -19.0253],\n",
      "        [-22.4409,  23.4583, -18.8118],\n",
      "        [-22.7178,  23.7363, -19.3030],\n",
      "        [-22.4392,  23.8811, -19.1734],\n",
      "        [-22.0498,  23.4920, -18.9664]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8956,  19.1227,  20.2984, -22.3439,  23.2398, -19.1513],\n",
      "        [ 23.9250,  18.9330,  19.3886, -22.2525,  23.4169, -19.0253],\n",
      "        [ 24.0451,  19.1583,  19.8379, -22.4409,  23.4583, -18.8118],\n",
      "        [ 23.6188,  18.3864,  19.3741, -22.7178,  23.7363, -19.3030],\n",
      "        [ 23.4766,  18.3656,  19.8343, -22.4392,  23.8811, -19.1734],\n",
      "        [ 23.9387,  18.8501,  19.5400, -22.0498,  23.4920, -18.9664]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.53164005279541\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1091, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.4809, 18.7338, 19.2847],\n",
      "        [23.6580, 18.9505, 19.4832],\n",
      "        [23.2700, 18.1550, 19.4497],\n",
      "        [22.8555, 18.0476, 18.6494],\n",
      "        [23.6337, 18.4774, 19.3044],\n",
      "        [23.4969, 18.2129, 19.3589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.4425, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1815,  23.7084, -19.0849],\n",
      "        [-22.1801,  23.2572, -19.0606],\n",
      "        [-22.7163,  23.8753, -19.3834],\n",
      "        [-22.1187,  23.7377, -18.8872],\n",
      "        [-22.3526,  24.0126, -19.3611],\n",
      "        [-22.1410,  23.4931, -18.8331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.4809,  18.7338,  19.2847, -22.1815,  23.7084, -19.0849],\n",
      "        [ 23.6580,  18.9505,  19.4832, -22.1801,  23.2572, -19.0606],\n",
      "        [ 23.2700,  18.1550,  19.4497, -22.7163,  23.8753, -19.3834],\n",
      "        [ 22.8555,  18.0476,  18.6494, -22.1187,  23.7377, -18.8872],\n",
      "        [ 23.6337,  18.4774,  19.3044, -22.3526,  24.0126, -19.3611],\n",
      "        [ 23.4969,  18.2129,  19.3589, -22.1410,  23.4931, -18.8331]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.4671430587768555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6261, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6477, 18.8809, 19.7103],\n",
      "        [23.4383, 18.4105, 19.1227],\n",
      "        [23.5915, 18.3910, 19.6385],\n",
      "        [24.1255, 18.5435, 19.5519],\n",
      "        [23.6026, 18.6169, 19.4902],\n",
      "        [22.8571, 18.0313, 19.4330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.9479, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8865,  23.4699, -18.9819],\n",
      "        [-22.5951,  23.7755, -18.9699],\n",
      "        [-22.2461,  23.9302, -19.3681],\n",
      "        [-22.1738,  23.3072, -18.8094],\n",
      "        [-22.0773,  23.0631, -18.8592],\n",
      "        [-22.0021,  24.0055, -18.8929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6477,  18.8809,  19.7103, -21.8865,  23.4699, -18.9819],\n",
      "        [ 23.4383,  18.4105,  19.1227, -22.5951,  23.7755, -18.9699],\n",
      "        [ 23.5915,  18.3910,  19.6385, -22.2461,  23.9302, -19.3681],\n",
      "        [ 24.1255,  18.5435,  19.5519, -22.1738,  23.3072, -18.8094],\n",
      "        [ 23.6026,  18.6169,  19.4902, -22.0773,  23.0631, -18.8592],\n",
      "        [ 22.8571,  18.0313,  19.4330, -22.0021,  24.0055, -18.8929]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.48015022277832\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4841, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9637, 19.0828, 19.9546],\n",
      "        [23.8660, 18.7429, 19.6414],\n",
      "        [23.8034, 18.7442, 19.6269],\n",
      "        [24.0112, 18.6817, 19.6689],\n",
      "        [23.7392, 18.4068, 20.0367],\n",
      "        [23.8784, 18.6622, 19.4431]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9608, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.8624,  23.8706, -19.1948],\n",
      "        [-21.9271,  22.9022, -18.6803],\n",
      "        [-21.6514,  23.2594, -18.8578],\n",
      "        [-22.0815,  23.6051, -19.0011],\n",
      "        [-22.5854,  23.9244, -19.0339],\n",
      "        [-22.0227,  23.2559, -19.0254]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9637,  19.0828,  19.9546, -21.8624,  23.8706, -19.1948],\n",
      "        [ 23.8660,  18.7429,  19.6414, -21.9271,  22.9022, -18.6803],\n",
      "        [ 23.8034,  18.7442,  19.6269, -21.6514,  23.2594, -18.8578],\n",
      "        [ 24.0112,  18.6817,  19.6689, -22.0815,  23.6051, -19.0011],\n",
      "        [ 23.7392,  18.4068,  20.0367, -22.5854,  23.9244, -19.0339],\n",
      "        [ 23.8784,  18.6622,  19.4431, -22.0227,  23.2559, -19.0254]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.531582355499268\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8189, 18.8328, 19.8563],\n",
      "        [24.0636, 19.0591, 19.7351],\n",
      "        [23.3091, 18.3304, 19.7319],\n",
      "        [24.3761, 19.2365, 20.3740],\n",
      "        [24.0619, 19.3070, 20.0471],\n",
      "        [23.5202, 18.9035, 19.2336]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.5797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7826,  23.1596, -18.6103],\n",
      "        [-21.9709,  23.4035, -18.8019],\n",
      "        [-22.6180,  24.1269, -19.7202],\n",
      "        [-22.2544,  23.7905, -19.1750],\n",
      "        [-22.2263,  23.2007, -18.8131],\n",
      "        [-21.8000,  23.4171, -18.7587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8189,  18.8328,  19.8563, -21.7826,  23.1596, -18.6103],\n",
      "        [ 24.0636,  19.0591,  19.7351, -21.9709,  23.4035, -18.8019],\n",
      "        [ 23.3091,  18.3304,  19.7319, -22.6180,  24.1269, -19.7202],\n",
      "        [ 24.3761,  19.2365,  20.3740, -22.2544,  23.7905, -19.1750],\n",
      "        [ 24.0619,  19.3070,  20.0471, -22.2263,  23.2007, -18.8131],\n",
      "        [ 23.5202,  18.9035,  19.2336, -21.8000,  23.4171, -18.7587]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.474323749542236\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2076, 18.6822, 19.9282],\n",
      "        [23.9103, 18.7191, 19.9486],\n",
      "        [24.0258, 18.8224, 19.5933],\n",
      "        [23.2005, 18.4666, 19.3390],\n",
      "        [23.9757, 18.7301, 19.7675],\n",
      "        [23.3595, 18.3959, 18.9405]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.4208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2605,  23.4401, -19.1148],\n",
      "        [-22.2371,  23.4847, -18.9549],\n",
      "        [-22.3683,  23.8112, -19.5099],\n",
      "        [-21.3729,  22.9887, -18.4849],\n",
      "        [-22.1450,  23.8613, -19.7004],\n",
      "        [-22.2743,  23.9874, -19.1859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2076,  18.6822,  19.9282, -22.2605,  23.4401, -19.1148],\n",
      "        [ 23.9103,  18.7191,  19.9486, -22.2371,  23.4847, -18.9549],\n",
      "        [ 24.0258,  18.8224,  19.5933, -22.3683,  23.8112, -19.5099],\n",
      "        [ 23.2005,  18.4666,  19.3390, -21.3729,  22.9887, -18.4849],\n",
      "        [ 23.9757,  18.7301,  19.7675, -22.1450,  23.8613, -19.7004],\n",
      "        [ 23.3595,  18.3959,  18.9405, -22.2743,  23.9874, -19.1859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.5298686027526855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4635, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9061, 18.8208, 19.8646],\n",
      "        [23.8284, 18.7988, 20.2719],\n",
      "        [23.9203, 19.0643, 19.9295],\n",
      "        [23.5703, 18.6708, 19.5849],\n",
      "        [24.1158, 19.0759, 20.1125],\n",
      "        [23.7925, 19.1636, 19.7781]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.3892, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1719,  23.7890, -19.1424],\n",
      "        [-22.1015,  23.6942, -19.1331],\n",
      "        [-21.6644,  23.0469, -18.8578],\n",
      "        [-22.6900,  24.1404, -19.6879],\n",
      "        [-22.6545,  23.8144, -19.3653],\n",
      "        [-21.8495,  23.4957, -19.0747]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9061,  18.8208,  19.8646, -22.1719,  23.7890, -19.1424],\n",
      "        [ 23.8284,  18.7988,  20.2719, -22.1015,  23.6942, -19.1331],\n",
      "        [ 23.9203,  19.0643,  19.9295, -21.6644,  23.0469, -18.8578],\n",
      "        [ 23.5703,  18.6708,  19.5849, -22.6900,  24.1404, -19.6879],\n",
      "        [ 24.1158,  19.0759,  20.1125, -22.6545,  23.8144, -19.3653],\n",
      "        [ 23.7925,  19.1636,  19.7781, -21.8495,  23.4957, -19.0747]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.527385711669922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1055, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5855, 18.8401, 19.4277],\n",
      "        [23.6944, 18.3563, 19.4279],\n",
      "        [23.3473, 18.4534, 19.2995],\n",
      "        [23.9848, 18.7225, 19.4094],\n",
      "        [23.5187, 18.3567, 19.5102],\n",
      "        [24.1104, 19.2631, 19.9209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7575, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1592,  23.8935, -19.2230],\n",
      "        [-22.3679,  23.4916, -19.4082],\n",
      "        [-22.1830,  23.4355, -19.0468],\n",
      "        [-22.3031,  23.6181, -18.8703],\n",
      "        [-22.7493,  24.0453, -19.6343],\n",
      "        [-22.3974,  23.6819, -19.1722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5855,  18.8401,  19.4277, -22.1592,  23.8935, -19.2230],\n",
      "        [ 23.6944,  18.3563,  19.4279, -22.3679,  23.4916, -19.4082],\n",
      "        [ 23.3473,  18.4534,  19.2995, -22.1830,  23.4355, -19.0468],\n",
      "        [ 23.9848,  18.7225,  19.4094, -22.3031,  23.6181, -18.8703],\n",
      "        [ 23.5187,  18.3567,  19.5102, -22.7493,  24.0453, -19.6343],\n",
      "        [ 24.1104,  19.2631,  19.9209, -22.3974,  23.6819, -19.1722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.500374794006348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[22.9696, 17.9879, 19.0589],\n",
      "        [23.8673, 19.0664, 19.7999],\n",
      "        [23.3777, 18.7192, 19.8177],\n",
      "        [23.5486, 18.4897, 19.3896],\n",
      "        [23.6014, 18.6928, 19.5051],\n",
      "        [23.1244, 18.4896, 19.5069]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8168, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5137,  23.5419, -18.8815],\n",
      "        [-22.3507,  23.3917, -18.6879],\n",
      "        [-22.5661,  23.6302, -19.2735],\n",
      "        [-22.8238,  23.8072, -19.4120],\n",
      "        [-22.1187,  23.5366, -19.1438],\n",
      "        [-22.5886,  23.4990, -18.9398]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 22.9696,  17.9879,  19.0589, -22.5137,  23.5419, -18.8815],\n",
      "        [ 23.8673,  19.0664,  19.7999, -22.3507,  23.3917, -18.6879],\n",
      "        [ 23.3777,  18.7192,  19.8177, -22.5661,  23.6302, -19.2735],\n",
      "        [ 23.5486,  18.4897,  19.3896, -22.8238,  23.8072, -19.4120],\n",
      "        [ 23.6014,  18.6928,  19.5051, -22.1187,  23.5366, -19.1438],\n",
      "        [ 23.1244,  18.4896,  19.5069, -22.5886,  23.4990, -18.9398]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.420352935791016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4214, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5815, 18.8451, 19.3648],\n",
      "        [23.3846, 18.6462, 19.4121],\n",
      "        [23.8575, 18.9226, 19.4726],\n",
      "        [23.8669, 18.6881, 19.9422],\n",
      "        [24.1157, 18.7829, 20.3153],\n",
      "        [23.9979, 19.0626, 19.9929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2715,  23.3165, -18.5782],\n",
      "        [-22.2282,  23.7543, -19.0955],\n",
      "        [-22.4358,  23.7263, -19.0188],\n",
      "        [-22.9086,  24.0072, -19.5996],\n",
      "        [-22.2995,  23.5984, -19.0191],\n",
      "        [-22.0653,  23.5433, -18.8588]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5815,  18.8451,  19.3648, -22.2715,  23.3165, -18.5782],\n",
      "        [ 23.3846,  18.6462,  19.4121, -22.2282,  23.7543, -19.0955],\n",
      "        [ 23.8575,  18.9226,  19.4726, -22.4358,  23.7263, -19.0188],\n",
      "        [ 23.8669,  18.6881,  19.9422, -22.9086,  24.0072, -19.5996],\n",
      "        [ 24.1157,  18.7829,  20.3153, -22.2995,  23.5984, -19.0191],\n",
      "        [ 23.9979,  19.0626,  19.9929, -22.0653,  23.5433, -18.8588]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.469849109649658\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2043, 18.9600, 19.6991],\n",
      "        [24.2076, 19.0694, 19.9661],\n",
      "        [24.1451, 19.0470, 19.5277],\n",
      "        [24.0512, 18.9142, 20.2732],\n",
      "        [24.2509, 19.6080, 20.2239],\n",
      "        [23.5696, 18.5153, 19.3941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.0506, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2316,  23.3394, -19.2047],\n",
      "        [-22.1887,  23.9964, -19.1399],\n",
      "        [-22.2286,  23.8135, -19.2633],\n",
      "        [-22.3341,  24.0655, -19.1271],\n",
      "        [-22.2253,  23.4740, -18.9884],\n",
      "        [-21.9539,  23.6601, -19.0831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2043,  18.9600,  19.6991, -22.2316,  23.3394, -19.2047],\n",
      "        [ 24.2076,  19.0694,  19.9661, -22.1887,  23.9964, -19.1399],\n",
      "        [ 24.1451,  19.0470,  19.5277, -22.2286,  23.8135, -19.2633],\n",
      "        [ 24.0512,  18.9142,  20.2732, -22.3341,  24.0655, -19.1271],\n",
      "        [ 24.2509,  19.6080,  20.2239, -22.2253,  23.4740, -18.9884],\n",
      "        [ 23.5696,  18.5153,  19.3941, -21.9539,  23.6601, -19.0831]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.535206317901611\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7542, 18.7853, 19.6249],\n",
      "        [23.4885, 19.0340, 19.7304],\n",
      "        [24.0812, 19.1298, 19.8742],\n",
      "        [24.2242, 19.4530, 20.3037],\n",
      "        [24.0538, 19.0682, 20.1672],\n",
      "        [24.4026, 19.1445, 19.7890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3512,  23.2694, -18.8542],\n",
      "        [-22.1518,  23.3723, -18.4946],\n",
      "        [-22.2001,  23.2871, -18.9829],\n",
      "        [-22.2364,  23.2838, -19.2121],\n",
      "        [-22.6660,  23.6765, -18.8625],\n",
      "        [-22.2178,  23.6521, -19.0825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7542,  18.7853,  19.6249, -22.3512,  23.2694, -18.8542],\n",
      "        [ 23.4885,  19.0340,  19.7304, -22.1518,  23.3723, -18.4946],\n",
      "        [ 24.0812,  19.1298,  19.8742, -22.2001,  23.2871, -18.9829],\n",
      "        [ 24.2242,  19.4530,  20.3037, -22.2364,  23.2838, -19.2121],\n",
      "        [ 24.0538,  19.0682,  20.1672, -22.6660,  23.6765, -18.8625],\n",
      "        [ 24.4026,  19.1445,  19.7890, -22.2178,  23.6521, -19.0825]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.498493194580078\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5142, 18.7534, 19.7923],\n",
      "        [24.0295, 19.1265, 19.8146],\n",
      "        [24.1384, 18.8888, 19.6082],\n",
      "        [23.7336, 18.9867, 19.8581],\n",
      "        [23.8103, 18.3357, 19.5433],\n",
      "        [24.0900, 18.8941, 19.7451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7965, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4123,  23.6800, -18.9853],\n",
      "        [-22.6058,  23.8754, -19.3721],\n",
      "        [-22.4385,  23.6956, -19.0281],\n",
      "        [-22.6171,  23.6558, -19.2858],\n",
      "        [-22.0813,  23.8515, -19.4645],\n",
      "        [-22.4534,  23.7622, -19.5977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5142,  18.7534,  19.7923, -22.4123,  23.6800, -18.9853],\n",
      "        [ 24.0295,  19.1265,  19.8146, -22.6058,  23.8754, -19.3721],\n",
      "        [ 24.1384,  18.8888,  19.6082, -22.4385,  23.6956, -19.0281],\n",
      "        [ 23.7336,  18.9867,  19.8581, -22.6171,  23.6558, -19.2858],\n",
      "        [ 23.8103,  18.3357,  19.5433, -22.0813,  23.8515, -19.4645],\n",
      "        [ 24.0900,  18.8941,  19.7451, -22.4534,  23.7622, -19.5977]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.512554168701172\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6381, 19.4243, 20.4060],\n",
      "        [23.5617, 18.2284, 19.4376],\n",
      "        [23.9917, 18.6895, 19.5383],\n",
      "        [23.2913, 18.5861, 19.7555],\n",
      "        [23.6507, 18.2538, 19.7562],\n",
      "        [23.6270, 18.9415, 19.8794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2976, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8735,  23.9733, -19.3724],\n",
      "        [-23.1093,  24.5391, -19.7670],\n",
      "        [-21.7332,  23.0920, -18.8770],\n",
      "        [-22.2097,  23.9661, -19.0490],\n",
      "        [-22.3745,  23.9097, -19.6771],\n",
      "        [-22.4891,  23.5034, -19.1010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6381,  19.4243,  20.4060, -22.8735,  23.9733, -19.3724],\n",
      "        [ 23.5617,  18.2284,  19.4376, -23.1093,  24.5391, -19.7670],\n",
      "        [ 23.9917,  18.6895,  19.5383, -21.7332,  23.0920, -18.8770],\n",
      "        [ 23.2913,  18.5861,  19.7555, -22.2097,  23.9661, -19.0490],\n",
      "        [ 23.6507,  18.2538,  19.7562, -22.3745,  23.9097, -19.6771],\n",
      "        [ 23.6270,  18.9415,  19.8794, -22.4891,  23.5034, -19.1010]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.650350093841553\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4214, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5827, 18.3925, 19.3301],\n",
      "        [23.6891, 19.1246, 19.4718],\n",
      "        [23.9480, 19.1279, 20.2656],\n",
      "        [23.7961, 18.4493, 19.8200],\n",
      "        [23.8612, 19.2723, 20.3608],\n",
      "        [23.9625, 19.1618, 19.8064]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.4030, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.6352,  23.4316, -18.6641],\n",
      "        [-22.2764,  23.4454, -19.0905],\n",
      "        [-22.3455,  23.5897, -19.2923],\n",
      "        [-22.4744,  23.7102, -19.3114],\n",
      "        [-21.6580,  23.1574, -18.4783],\n",
      "        [-22.5013,  23.6330, -19.2791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5827,  18.3925,  19.3301, -21.6352,  23.4316, -18.6641],\n",
      "        [ 23.6891,  19.1246,  19.4718, -22.2764,  23.4454, -19.0905],\n",
      "        [ 23.9480,  19.1279,  20.2656, -22.3455,  23.5897, -19.2923],\n",
      "        [ 23.7961,  18.4493,  19.8200, -22.4744,  23.7102, -19.3114],\n",
      "        [ 23.8612,  19.2723,  20.3608, -21.6580,  23.1574, -18.4783],\n",
      "        [ 23.9625,  19.1618,  19.8064, -22.5013,  23.6330, -19.2791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.449155807495117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0923, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3273, 19.0641, 20.0666],\n",
      "        [24.2122, 18.8815, 19.5206],\n",
      "        [23.9951, 19.2197, 19.8396],\n",
      "        [24.3483, 19.3481, 19.9897],\n",
      "        [23.8377, 18.8967, 19.8624],\n",
      "        [24.0372, 18.5314, 19.8099]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.4269, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0379,  23.1367, -19.1526],\n",
      "        [-22.5333,  23.6940, -19.3043],\n",
      "        [-22.0624,  23.6551, -19.0758],\n",
      "        [-22.9818,  24.0290, -19.4765],\n",
      "        [-22.1177,  23.3315, -19.3311],\n",
      "        [-22.6269,  23.8605, -19.1528]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3273,  19.0641,  20.0666, -22.0379,  23.1367, -19.1526],\n",
      "        [ 24.2122,  18.8815,  19.5206, -22.5333,  23.6940, -19.3043],\n",
      "        [ 23.9951,  19.2197,  19.8396, -22.0624,  23.6551, -19.0758],\n",
      "        [ 24.3483,  19.3481,  19.9897, -22.9818,  24.0290, -19.4765],\n",
      "        [ 23.8377,  18.8967,  19.8624, -22.1177,  23.3315, -19.3311],\n",
      "        [ 24.0372,  18.5314,  19.8099, -22.6269,  23.8605, -19.1528]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.554510116577148\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8345, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8726, 18.7077, 19.8235],\n",
      "        [23.6144, 18.3709, 19.4286],\n",
      "        [23.6905, 18.4306, 19.4276],\n",
      "        [23.6025, 18.8782, 19.7184],\n",
      "        [23.9201, 18.8544, 19.5540],\n",
      "        [23.4148, 18.7890, 19.6338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.3022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4880,  23.9680, -19.0692],\n",
      "        [-22.6768,  23.9488, -19.4826],\n",
      "        [-22.8412,  23.9409, -19.2089],\n",
      "        [-22.4293,  23.6889, -19.3448],\n",
      "        [-22.1178,  23.4259, -19.3943],\n",
      "        [-22.1978,  23.8912, -19.2438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8726,  18.7077,  19.8235, -22.4880,  23.9680, -19.0692],\n",
      "        [ 23.6144,  18.3709,  19.4286, -22.6768,  23.9488, -19.4826],\n",
      "        [ 23.6905,  18.4306,  19.4276, -22.8412,  23.9409, -19.2089],\n",
      "        [ 23.6025,  18.8782,  19.7184, -22.4293,  23.6889, -19.3448],\n",
      "        [ 23.9201,  18.8544,  19.5540, -22.1178,  23.4259, -19.3943],\n",
      "        [ 23.4148,  18.7890,  19.6338, -22.1978,  23.8912, -19.2438]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.550995826721191\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6551, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6691, 18.8746, 19.8234],\n",
      "        [23.9671, 19.0722, 19.9456],\n",
      "        [23.7929, 19.0339, 19.8143],\n",
      "        [24.1026, 19.1176, 19.8800],\n",
      "        [24.0483, 19.1166, 20.2558],\n",
      "        [23.6475, 18.4679, 19.3623]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.7228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4469,  23.8332, -19.5646],\n",
      "        [-22.0799,  23.4389, -19.2660],\n",
      "        [-22.3828,  23.3893, -18.5487],\n",
      "        [-22.0658,  23.4811, -19.1543],\n",
      "        [-22.7719,  23.7855, -19.2371],\n",
      "        [-22.4122,  24.0482, -19.1591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6691,  18.8746,  19.8234, -22.4469,  23.8332, -19.5646],\n",
      "        [ 23.9671,  19.0722,  19.9456, -22.0799,  23.4389, -19.2660],\n",
      "        [ 23.7929,  19.0339,  19.8143, -22.3828,  23.3893, -18.5487],\n",
      "        [ 24.1026,  19.1176,  19.8800, -22.0658,  23.4811, -19.1543],\n",
      "        [ 24.0483,  19.1166,  20.2558, -22.7719,  23.7855, -19.2371],\n",
      "        [ 23.6475,  18.4679,  19.3623, -22.4122,  24.0482, -19.1591]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.554121971130371\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5959, 18.6646, 19.8224],\n",
      "        [24.1445, 18.9602, 19.8912],\n",
      "        [23.9413, 19.1085, 19.9819],\n",
      "        [23.7539, 18.9325, 20.1733],\n",
      "        [23.6556, 18.6173, 19.2969],\n",
      "        [23.8835, 18.7941, 19.9466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8758, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1195,  23.4533, -18.8791],\n",
      "        [-21.4766,  23.0022, -18.7119],\n",
      "        [-22.3677,  23.6193, -19.4268],\n",
      "        [-22.4848,  23.3584, -18.9643],\n",
      "        [-22.1540,  23.6806, -19.3368],\n",
      "        [-22.7354,  24.2202, -19.9112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5959,  18.6646,  19.8224, -22.1195,  23.4533, -18.8791],\n",
      "        [ 24.1445,  18.9602,  19.8912, -21.4766,  23.0022, -18.7119],\n",
      "        [ 23.9413,  19.1085,  19.9819, -22.3677,  23.6193, -19.4268],\n",
      "        [ 23.7539,  18.9325,  20.1733, -22.4848,  23.3584, -18.9643],\n",
      "        [ 23.6556,  18.6173,  19.2969, -22.1540,  23.6806, -19.3368],\n",
      "        [ 23.8835,  18.7941,  19.9466, -22.7354,  24.2202, -19.9112]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.5062127113342285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6459, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2024, 18.9476, 20.2765],\n",
      "        [23.3853, 18.7783, 19.5605],\n",
      "        [23.7089, 18.6053, 20.0252],\n",
      "        [23.8075, 19.0600, 20.0302],\n",
      "        [24.0723, 18.9709, 19.8728],\n",
      "        [23.4450, 18.4804, 19.4134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.0949, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5693,  24.1812, -19.4014],\n",
      "        [-22.4112,  23.7515, -19.1261],\n",
      "        [-23.2597,  24.5350, -20.1537],\n",
      "        [-22.4411,  23.6096, -19.1635],\n",
      "        [-21.8727,  23.6560, -19.1103],\n",
      "        [-22.2632,  23.1625, -18.6484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2024,  18.9476,  20.2765, -22.5693,  24.1812, -19.4014],\n",
      "        [ 23.3853,  18.7783,  19.5605, -22.4112,  23.7515, -19.1261],\n",
      "        [ 23.7089,  18.6053,  20.0252, -23.2597,  24.5350, -20.1537],\n",
      "        [ 23.8075,  19.0600,  20.0302, -22.4411,  23.6096, -19.1635],\n",
      "        [ 24.0723,  18.9709,  19.8728, -21.8727,  23.6560, -19.1103],\n",
      "        [ 23.4450,  18.4804,  19.4134, -22.2632,  23.1625, -18.6484]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.616699695587158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9375, 18.5881, 19.9352],\n",
      "        [23.9347, 18.3915, 19.7067],\n",
      "        [23.3454, 18.2086, 19.7417],\n",
      "        [23.9394, 18.5474, 19.8775],\n",
      "        [23.6554, 18.6466, 19.5082],\n",
      "        [23.8919, 19.0966, 19.6624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.6323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5239,  23.8409, -19.0528],\n",
      "        [-22.6509,  23.3376, -19.0703],\n",
      "        [-22.4452,  23.8037, -19.2843],\n",
      "        [-21.9310,  23.3929, -19.0180],\n",
      "        [-22.7146,  23.6533, -19.3042],\n",
      "        [-22.7708,  23.9670, -19.0502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9375,  18.5881,  19.9352, -22.5239,  23.8409, -19.0528],\n",
      "        [ 23.9347,  18.3915,  19.7067, -22.6509,  23.3376, -19.0703],\n",
      "        [ 23.3454,  18.2086,  19.7417, -22.4452,  23.8037, -19.2843],\n",
      "        [ 23.9394,  18.5474,  19.8775, -21.9310,  23.3929, -19.0180],\n",
      "        [ 23.6554,  18.6466,  19.5082, -22.7146,  23.6533, -19.3042],\n",
      "        [ 23.8919,  19.0966,  19.6624, -22.7708,  23.9670, -19.0502]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.558475971221924\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9869, 19.1190, 20.2080],\n",
      "        [23.6789, 18.9144, 19.5346],\n",
      "        [23.9511, 18.7933, 20.0392],\n",
      "        [24.3981, 19.3469, 20.4818],\n",
      "        [23.5530, 18.2467, 19.6531],\n",
      "        [24.1166, 18.7377, 19.7993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0912, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1028,  23.6750, -19.0124],\n",
      "        [-22.6065,  24.0407, -19.3479],\n",
      "        [-22.3369,  23.6387, -19.4732],\n",
      "        [-22.7112,  24.3771, -19.8264],\n",
      "        [-22.1778,  23.9473, -18.8082],\n",
      "        [-22.5535,  23.9646, -19.5722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9869,  19.1190,  20.2080, -22.1028,  23.6750, -19.0124],\n",
      "        [ 23.6789,  18.9144,  19.5346, -22.6065,  24.0407, -19.3479],\n",
      "        [ 23.9511,  18.7933,  20.0392, -22.3369,  23.6387, -19.4732],\n",
      "        [ 24.3981,  19.3469,  20.4818, -22.7112,  24.3771, -19.8264],\n",
      "        [ 23.5530,  18.2467,  19.6531, -22.1778,  23.9473, -18.8082],\n",
      "        [ 24.1166,  18.7377,  19.7993, -22.5535,  23.9646, -19.5722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.571218490600586\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2384, 19.2683, 20.1926],\n",
      "        [23.1791, 18.5410, 19.1629],\n",
      "        [23.6329, 19.0386, 19.5087],\n",
      "        [24.2779, 19.4630, 20.1303],\n",
      "        [24.2041, 18.9568, 20.0847],\n",
      "        [23.9061, 19.0474, 20.1272]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6054, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4670,  23.4799, -19.0263],\n",
      "        [-22.4385,  23.7618, -18.9778],\n",
      "        [-22.0656,  23.6372, -19.1626],\n",
      "        [-21.9769,  22.9555, -18.8059],\n",
      "        [-22.3383,  23.8791, -19.1814],\n",
      "        [-22.5594,  23.7311, -19.1949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2384,  19.2683,  20.1926, -22.4670,  23.4799, -19.0263],\n",
      "        [ 23.1791,  18.5410,  19.1629, -22.4385,  23.7618, -18.9778],\n",
      "        [ 23.6329,  19.0386,  19.5087, -22.0656,  23.6372, -19.1626],\n",
      "        [ 24.2779,  19.4630,  20.1303, -21.9769,  22.9555, -18.8059],\n",
      "        [ 24.2041,  18.9568,  20.0847, -22.3383,  23.8791, -19.1814],\n",
      "        [ 23.9061,  19.0474,  20.1272, -22.5594,  23.7311, -19.1949]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.594697952270508\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1922, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7875, 18.6382, 19.3546],\n",
      "        [24.1820, 18.9468, 19.8522],\n",
      "        [24.1638, 18.7378, 19.7035],\n",
      "        [24.0303, 18.9159, 20.1525],\n",
      "        [23.9306, 19.2029, 20.1214],\n",
      "        [24.2594, 19.1948, 19.8385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3269, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-21.7717,  23.6368, -19.2168],\n",
      "        [-22.6216,  24.0860, -19.7870],\n",
      "        [-22.5796,  23.8049, -19.3625],\n",
      "        [-22.5875,  23.8403, -19.2174],\n",
      "        [-22.5285,  23.7029, -19.1187],\n",
      "        [-22.7309,  24.0711, -19.7361]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7875,  18.6382,  19.3546, -21.7717,  23.6368, -19.2168],\n",
      "        [ 24.1820,  18.9468,  19.8522, -22.6216,  24.0860, -19.7870],\n",
      "        [ 24.1638,  18.7378,  19.7035, -22.5796,  23.8049, -19.3625],\n",
      "        [ 24.0303,  18.9159,  20.1525, -22.5875,  23.8403, -19.2174],\n",
      "        [ 23.9306,  19.2029,  20.1214, -22.5285,  23.7029, -19.1187],\n",
      "        [ 24.2594,  19.1948,  19.8385, -22.7309,  24.0711, -19.7361]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.507543563842773\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8712, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9042, 18.4310, 19.6729],\n",
      "        [23.7153, 18.0932, 19.7311],\n",
      "        [24.2004, 19.1311, 20.2229],\n",
      "        [23.9094, 19.0862, 19.7471],\n",
      "        [23.8718, 18.8972, 19.6406],\n",
      "        [23.7841, 18.7467, 19.4313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6393,  23.6948, -19.3572],\n",
      "        [-22.6467,  23.4098, -19.3839],\n",
      "        [-22.1936,  24.2118, -19.4348],\n",
      "        [-21.9716,  23.0657, -19.1315],\n",
      "        [-22.7691,  24.3116, -19.2883],\n",
      "        [-22.0999,  23.7491, -19.2189]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9042,  18.4310,  19.6729, -22.6393,  23.6948, -19.3572],\n",
      "        [ 23.7153,  18.0932,  19.7311, -22.6467,  23.4098, -19.3839],\n",
      "        [ 24.2004,  19.1311,  20.2229, -22.1936,  24.2118, -19.4348],\n",
      "        [ 23.9094,  19.0862,  19.7471, -21.9716,  23.0657, -19.1315],\n",
      "        [ 23.8718,  18.8972,  19.6406, -22.7691,  24.3116, -19.2883],\n",
      "        [ 23.7841,  18.7467,  19.4313, -22.0999,  23.7491, -19.2189]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.553940296173096\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6628, 18.7816, 19.5838],\n",
      "        [24.2714, 18.8811, 20.1361],\n",
      "        [22.9180, 18.1882, 18.9538],\n",
      "        [23.8424, 19.1642, 19.7958],\n",
      "        [23.8267, 19.0954, 19.3735],\n",
      "        [24.0531, 18.9373, 19.9505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.3322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1100,  23.5541, -19.1774],\n",
      "        [-22.3417,  23.6871, -19.1090],\n",
      "        [-22.2030,  22.9815, -18.9780],\n",
      "        [-22.0157,  23.7553, -19.1999],\n",
      "        [-22.6418,  23.6875, -18.9964],\n",
      "        [-22.7019,  23.4219, -19.1955]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6628,  18.7816,  19.5838, -22.1100,  23.5541, -19.1774],\n",
      "        [ 24.2714,  18.8811,  20.1361, -22.3417,  23.6871, -19.1090],\n",
      "        [ 22.9180,  18.1882,  18.9538, -22.2030,  22.9815, -18.9780],\n",
      "        [ 23.8424,  19.1642,  19.7958, -22.0157,  23.7553, -19.1999],\n",
      "        [ 23.8267,  19.0954,  19.3735, -22.6418,  23.6875, -18.9964],\n",
      "        [ 24.0531,  18.9373,  19.9505, -22.7019,  23.4219, -19.1955]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.525312900543213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9476, 19.3031, 19.9264],\n",
      "        [24.1732, 19.3259, 20.3416],\n",
      "        [24.3589, 19.1597, 20.1235],\n",
      "        [24.2948, 19.2217, 20.0682],\n",
      "        [24.3841, 19.2433, 19.8518],\n",
      "        [23.9197, 19.1143, 20.2242]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.9995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.1966,  23.3166, -18.9535],\n",
      "        [-22.5666,  24.1949, -19.3872],\n",
      "        [-22.7825,  24.0616, -19.5378],\n",
      "        [-22.6359,  23.7664, -18.9396],\n",
      "        [-22.0838,  23.2202, -18.7063],\n",
      "        [-23.1782,  23.8138, -19.7606]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9476,  19.3031,  19.9264, -22.1966,  23.3166, -18.9535],\n",
      "        [ 24.1732,  19.3259,  20.3416, -22.5666,  24.1949, -19.3872],\n",
      "        [ 24.3589,  19.1597,  20.1235, -22.7825,  24.0616, -19.5378],\n",
      "        [ 24.2948,  19.2217,  20.0682, -22.6359,  23.7664, -18.9396],\n",
      "        [ 24.3841,  19.2433,  19.8518, -22.0838,  23.2202, -18.7063],\n",
      "        [ 23.9197,  19.1143,  20.2242, -23.1782,  23.8138, -19.7606]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.561267852783203\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7092, 18.6154, 19.7494],\n",
      "        [23.7254, 19.0392, 20.2862],\n",
      "        [23.8392, 19.2257, 19.8336],\n",
      "        [23.9010, 18.6525, 19.4606],\n",
      "        [24.4228, 19.7812, 20.1359],\n",
      "        [24.1378, 18.8975, 20.0812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.9022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6450,  23.5593, -18.8726],\n",
      "        [-23.0532,  24.3473, -19.7963],\n",
      "        [-21.9534,  23.3630, -19.4080],\n",
      "        [-22.5599,  23.6144, -19.3501],\n",
      "        [-22.6048,  23.6746, -19.3739],\n",
      "        [-22.2261,  23.4083, -19.2085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7092,  18.6154,  19.7494, -22.6450,  23.5593, -18.8726],\n",
      "        [ 23.7254,  19.0392,  20.2862, -23.0532,  24.3473, -19.7963],\n",
      "        [ 23.8392,  19.2257,  19.8336, -21.9534,  23.3630, -19.4080],\n",
      "        [ 23.9010,  18.6525,  19.4606, -22.5599,  23.6144, -19.3501],\n",
      "        [ 24.4228,  19.7812,  20.1359, -22.6048,  23.6746, -19.3739],\n",
      "        [ 24.1378,  18.8975,  20.0812, -22.2261,  23.4083, -19.2085]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.541788101196289\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0921, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5482, 18.5918, 19.8928],\n",
      "        [23.7873, 19.1324, 19.9541],\n",
      "        [24.3489, 19.4778, 20.0905],\n",
      "        [24.0343, 18.9575, 19.9340],\n",
      "        [24.1847, 18.8121, 19.8698],\n",
      "        [24.1803, 18.9597, 19.7301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(14.7261, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2119,  23.6988, -19.1174],\n",
      "        [-22.2005,  23.1149, -19.3311],\n",
      "        [-22.7131,  23.6424, -19.0515],\n",
      "        [-22.4719,  23.7924, -19.4708],\n",
      "        [-22.4578,  23.9621, -19.5888],\n",
      "        [-22.5081,  23.8557, -19.1563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5482,  18.5918,  19.8928, -22.2119,  23.6988, -19.1174],\n",
      "        [ 23.7873,  19.1324,  19.9541, -22.2005,  23.1149, -19.3311],\n",
      "        [ 24.3489,  19.4778,  20.0905, -22.7131,  23.6424, -19.0515],\n",
      "        [ 24.0343,  18.9575,  19.9340, -22.4719,  23.7924, -19.4708],\n",
      "        [ 24.1847,  18.8121,  19.8698, -22.4578,  23.9621, -19.5888],\n",
      "        [ 24.1803,  18.9597,  19.7301, -22.5081,  23.8557, -19.1563]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.537933349609375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3671, 19.4342, 20.1951],\n",
      "        [23.8593, 19.1668, 20.0655],\n",
      "        [24.4353, 19.2449, 20.4921],\n",
      "        [24.4715, 19.1751, 20.3234],\n",
      "        [23.6617, 18.5848, 19.3359],\n",
      "        [24.3268, 18.9387, 20.0953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.7674, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6587,  24.0321, -19.6583],\n",
      "        [-23.1909,  24.3944, -19.9336],\n",
      "        [-22.7049,  23.7467, -19.3532],\n",
      "        [-22.7579,  23.6733, -19.5788],\n",
      "        [-22.4785,  24.0943, -19.2248],\n",
      "        [-22.5772,  23.2580, -19.0594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3671,  19.4342,  20.1951, -22.6587,  24.0321, -19.6583],\n",
      "        [ 23.8593,  19.1668,  20.0655, -23.1909,  24.3944, -19.9336],\n",
      "        [ 24.4353,  19.2449,  20.4921, -22.7049,  23.7467, -19.3532],\n",
      "        [ 24.4715,  19.1751,  20.3234, -22.7579,  23.6733, -19.5788],\n",
      "        [ 23.6617,  18.5848,  19.3359, -22.4785,  24.0943, -19.2248],\n",
      "        [ 24.3268,  18.9387,  20.0953, -22.5772,  23.2580, -19.0594]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.658047676086426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5333, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5332, 19.2283, 20.2927],\n",
      "        [23.8666, 18.9185, 19.8673],\n",
      "        [23.6730, 18.6646, 20.0422],\n",
      "        [23.6790, 19.2390, 19.6467],\n",
      "        [23.7059, 19.0795, 19.7989],\n",
      "        [24.0790, 18.8347, 20.0803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.2896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9137,  23.7048, -19.4262],\n",
      "        [-22.7023,  23.8856, -19.2316],\n",
      "        [-22.4001,  23.4978, -19.0839],\n",
      "        [-22.2732,  23.2969, -19.2403],\n",
      "        [-22.5789,  23.6793, -18.9584],\n",
      "        [-22.6241,  24.1808, -19.6733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5332,  19.2283,  20.2927, -22.9137,  23.7048, -19.4262],\n",
      "        [ 23.8666,  18.9185,  19.8673, -22.7023,  23.8856, -19.2316],\n",
      "        [ 23.6730,  18.6646,  20.0422, -22.4001,  23.4978, -19.0839],\n",
      "        [ 23.6790,  19.2390,  19.6467, -22.2732,  23.2969, -19.2403],\n",
      "        [ 23.7059,  19.0795,  19.7989, -22.5789,  23.6793, -18.9584],\n",
      "        [ 24.0790,  18.8347,  20.0803, -22.6241,  24.1808, -19.6733]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.657135009765625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6402, 18.6818, 19.8560],\n",
      "        [24.0039, 18.8209, 19.4255],\n",
      "        [23.9406, 19.2353, 20.0131],\n",
      "        [24.1381, 19.1137, 20.1624],\n",
      "        [23.6942, 18.8814, 19.8885],\n",
      "        [24.0355, 19.0362, 19.8475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0520, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2430,  23.7573, -19.5529],\n",
      "        [-22.9557,  24.3470, -19.4109],\n",
      "        [-22.6569,  23.9211, -19.3570],\n",
      "        [-22.4205,  23.8439, -19.5912],\n",
      "        [-22.4453,  24.1735, -19.1278],\n",
      "        [-22.8564,  23.7346, -19.2628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6402,  18.6818,  19.8560, -22.2430,  23.7573, -19.5529],\n",
      "        [ 24.0039,  18.8209,  19.4255, -22.9557,  24.3470, -19.4109],\n",
      "        [ 23.9406,  19.2353,  20.0131, -22.6569,  23.9211, -19.3570],\n",
      "        [ 24.1381,  19.1137,  20.1624, -22.4205,  23.8439, -19.5912],\n",
      "        [ 23.6942,  18.8814,  19.8885, -22.4453,  24.1735, -19.1278],\n",
      "        [ 24.0355,  19.0362,  19.8475, -22.8564,  23.7346, -19.2628]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.562559604644775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7292, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2367, 19.1180, 20.0065],\n",
      "        [23.8302, 19.0715, 19.5943],\n",
      "        [23.1014, 18.5549, 19.0977],\n",
      "        [24.0741, 18.8098, 19.8259],\n",
      "        [24.0014, 19.4759, 20.0127],\n",
      "        [24.3125, 19.3144, 19.9557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.8524, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0119,  23.2617, -19.2320],\n",
      "        [-22.2740,  23.2353, -19.3122],\n",
      "        [-22.2161,  23.8954, -19.5281],\n",
      "        [-22.4494,  23.5473, -19.1659],\n",
      "        [-22.0185,  23.7843, -19.3311],\n",
      "        [-22.4681,  23.9232, -19.2135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2367,  19.1180,  20.0065, -22.0119,  23.2617, -19.2320],\n",
      "        [ 23.8302,  19.0715,  19.5943, -22.2740,  23.2353, -19.3122],\n",
      "        [ 23.1014,  18.5549,  19.0977, -22.2161,  23.8954, -19.5281],\n",
      "        [ 24.0741,  18.8098,  19.8259, -22.4494,  23.5473, -19.1659],\n",
      "        [ 24.0014,  19.4759,  20.0127, -22.0185,  23.7843, -19.3311],\n",
      "        [ 24.3125,  19.3144,  19.9557, -22.4681,  23.9232, -19.2135]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.582952976226807\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3325, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.5628, 18.7914, 19.8534],\n",
      "        [23.6334, 19.1420, 19.6552],\n",
      "        [23.9777, 18.6701, 19.9316],\n",
      "        [23.7895, 18.4592, 19.5750],\n",
      "        [23.4395, 18.3007, 19.8196],\n",
      "        [23.7309, 18.6320, 19.7900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.9668, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7165,  23.7759, -18.9026],\n",
      "        [-22.8769,  24.2134, -19.5841],\n",
      "        [-22.0825,  23.9304, -19.4062],\n",
      "        [-22.7319,  23.6778, -18.6457],\n",
      "        [-22.3558,  23.9885, -19.3852],\n",
      "        [-22.6753,  23.7467, -19.5468]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.5628,  18.7914,  19.8534, -22.7165,  23.7759, -18.9026],\n",
      "        [ 23.6334,  19.1420,  19.6552, -22.8769,  24.2134, -19.5841],\n",
      "        [ 23.9777,  18.6701,  19.9316, -22.0825,  23.9304, -19.4062],\n",
      "        [ 23.7895,  18.4592,  19.5750, -22.7319,  23.6778, -18.6457],\n",
      "        [ 23.4395,  18.3007,  19.8196, -22.3558,  23.9885, -19.3852],\n",
      "        [ 23.7309,  18.6320,  19.7900, -22.6753,  23.7467, -19.5468]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.564350605010986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6137, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6921, 19.6725, 20.7949],\n",
      "        [23.7183, 18.8875, 19.6780],\n",
      "        [24.0045, 19.0694, 20.2531],\n",
      "        [23.8226, 18.6337, 19.9388],\n",
      "        [24.3506, 19.2965, 20.4790],\n",
      "        [24.2747, 19.0969, 19.9345]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.9026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7945,  24.1678, -19.7580],\n",
      "        [-22.6088,  23.5540, -19.0936],\n",
      "        [-22.9441,  23.7636, -19.6978],\n",
      "        [-22.5355,  23.2442, -19.5120],\n",
      "        [-22.0886,  23.7771, -19.3592],\n",
      "        [-22.5145,  23.3065, -18.8908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6921,  19.6725,  20.7949, -22.7945,  24.1678, -19.7580],\n",
      "        [ 23.7183,  18.8875,  19.6780, -22.6088,  23.5540, -19.0936],\n",
      "        [ 24.0045,  19.0694,  20.2531, -22.9441,  23.7636, -19.6978],\n",
      "        [ 23.8226,  18.6337,  19.9388, -22.5355,  23.2442, -19.5120],\n",
      "        [ 24.3506,  19.2965,  20.4790, -22.0886,  23.7771, -19.3592],\n",
      "        [ 24.2747,  19.0969,  19.9345, -22.5145,  23.3065, -18.8908]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.726805686950684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0343, 18.9366, 20.1669],\n",
      "        [24.1121, 19.0053, 19.9092],\n",
      "        [24.2806, 19.0188, 19.9231],\n",
      "        [23.8556, 18.7093, 19.9477],\n",
      "        [23.6449, 19.1546, 19.9461],\n",
      "        [23.8477, 18.8750, 19.8546]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.2009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8040,  23.8586, -19.5759],\n",
      "        [-22.6761,  23.9529, -19.4141],\n",
      "        [-22.5098,  23.7535, -19.1874],\n",
      "        [-22.1576,  23.2885, -18.9209],\n",
      "        [-22.4760,  23.7500, -19.3533],\n",
      "        [-22.5514,  23.8735, -19.4275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0343,  18.9366,  20.1669, -22.8040,  23.8586, -19.5759],\n",
      "        [ 24.1121,  19.0053,  19.9092, -22.6761,  23.9529, -19.4141],\n",
      "        [ 24.2806,  19.0188,  19.9231, -22.5098,  23.7535, -19.1874],\n",
      "        [ 23.8556,  18.7093,  19.9477, -22.1576,  23.2885, -18.9209],\n",
      "        [ 23.6449,  19.1546,  19.9461, -22.4760,  23.7500, -19.3533],\n",
      "        [ 23.8477,  18.8750,  19.8546, -22.5514,  23.8735, -19.4275]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.63144588470459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0862, 19.3922, 20.0428],\n",
      "        [24.0442, 19.0139, 19.9835],\n",
      "        [23.4508, 18.2931, 19.2982],\n",
      "        [24.2005, 18.9030, 19.7818],\n",
      "        [23.5947, 18.4919, 19.8848],\n",
      "        [23.8783, 18.6544, 19.8802]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.1048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6962,  23.4658, -19.4548],\n",
      "        [-22.1516,  23.8223, -19.5514],\n",
      "        [-22.6290,  23.5646, -19.3176],\n",
      "        [-22.6119,  24.0249, -19.4333],\n",
      "        [-22.8153,  23.9844, -19.5088],\n",
      "        [-22.6138,  23.6592, -19.3472]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0862,  19.3922,  20.0428, -22.6962,  23.4658, -19.4548],\n",
      "        [ 24.0442,  19.0139,  19.9835, -22.1516,  23.8223, -19.5514],\n",
      "        [ 23.4508,  18.2931,  19.2982, -22.6290,  23.5646, -19.3176],\n",
      "        [ 24.2005,  18.9030,  19.7818, -22.6119,  24.0249, -19.4333],\n",
      "        [ 23.5947,  18.4919,  19.8848, -22.8153,  23.9844, -19.5088],\n",
      "        [ 23.8783,  18.6544,  19.8802, -22.6138,  23.6592, -19.3472]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.6255388259887695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4281, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9802, 18.8928, 19.8539],\n",
      "        [23.7894, 18.8268, 19.9009],\n",
      "        [23.5719, 18.8200, 19.9085],\n",
      "        [24.3601, 19.1942, 20.2161],\n",
      "        [24.3343, 18.9533, 19.9137],\n",
      "        [23.9370, 19.2246, 19.5223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.5239, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4495,  23.7031, -19.7784],\n",
      "        [-22.8121,  24.0278, -19.8833],\n",
      "        [-22.0855,  23.0896, -19.0009],\n",
      "        [-22.4062,  23.5679, -19.2457],\n",
      "        [-22.6495,  23.9229, -19.3673],\n",
      "        [-23.2987,  24.3478, -19.6029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9802,  18.8928,  19.8539, -22.4495,  23.7031, -19.7784],\n",
      "        [ 23.7894,  18.8268,  19.9009, -22.8121,  24.0278, -19.8833],\n",
      "        [ 23.5719,  18.8200,  19.9085, -22.0855,  23.0896, -19.0009],\n",
      "        [ 24.3601,  19.1942,  20.2161, -22.4062,  23.5679, -19.2457],\n",
      "        [ 24.3343,  18.9533,  19.9137, -22.6495,  23.9229, -19.3673],\n",
      "        [ 23.9370,  19.2246,  19.5223, -23.2987,  24.3478, -19.6029]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.606584072113037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2876, 19.3481, 20.2614],\n",
      "        [24.0263, 18.6091, 19.3164],\n",
      "        [24.6315, 19.2828, 20.0847],\n",
      "        [24.1388, 19.0280, 20.2013],\n",
      "        [24.3659, 19.1660, 19.8066],\n",
      "        [24.0250, 18.7508, 20.0100]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.1072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0928,  23.2736, -19.2445],\n",
      "        [-22.4063,  23.3764, -18.8832],\n",
      "        [-22.7544,  24.1835, -19.2044],\n",
      "        [-22.1868,  23.5296, -19.4121],\n",
      "        [-22.4429,  23.6453, -19.3311],\n",
      "        [-23.1210,  24.1089, -19.5635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2876,  19.3481,  20.2614, -22.0928,  23.2736, -19.2445],\n",
      "        [ 24.0263,  18.6091,  19.3164, -22.4063,  23.3764, -18.8832],\n",
      "        [ 24.6315,  19.2828,  20.0847, -22.7544,  24.1835, -19.2044],\n",
      "        [ 24.1388,  19.0280,  20.2013, -22.1868,  23.5296, -19.4121],\n",
      "        [ 24.3659,  19.1660,  19.8066, -22.4429,  23.6453, -19.3311],\n",
      "        [ 24.0250,  18.7508,  20.0100, -23.1210,  24.1089, -19.5635]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.616743564605713\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3583, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0691, 18.9481, 20.0416],\n",
      "        [23.7515, 19.0050, 19.4800],\n",
      "        [23.9843, 18.5074, 19.7848],\n",
      "        [23.7711, 18.9371, 19.3948],\n",
      "        [24.1045, 19.4822, 19.9577],\n",
      "        [24.2446, 19.4222, 20.1738]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.9208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4093,  23.7368, -19.3078],\n",
      "        [-22.5750,  23.9394, -19.1494],\n",
      "        [-22.7850,  24.1217, -19.8562],\n",
      "        [-22.3292,  23.6504, -19.1578],\n",
      "        [-23.2396,  24.4552, -20.2501],\n",
      "        [-22.0291,  23.3070, -18.4845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0691,  18.9481,  20.0416, -22.4093,  23.7368, -19.3078],\n",
      "        [ 23.7515,  19.0050,  19.4800, -22.5750,  23.9394, -19.1494],\n",
      "        [ 23.9843,  18.5074,  19.7848, -22.7850,  24.1217, -19.8562],\n",
      "        [ 23.7711,  18.9371,  19.3948, -22.3292,  23.6504, -19.1578],\n",
      "        [ 24.1045,  19.4822,  19.9577, -23.2396,  24.4552, -20.2501],\n",
      "        [ 24.2446,  19.4222,  20.1738, -22.0291,  23.3070, -18.4845]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.612231731414795\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7453, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3045, 19.0016, 19.9503],\n",
      "        [24.4180, 19.3545, 20.0801],\n",
      "        [23.9728, 18.9362, 20.0513],\n",
      "        [24.4763, 19.4993, 19.9495],\n",
      "        [24.0814, 19.3401, 20.2774],\n",
      "        [24.5440, 19.2988, 20.1719]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.5650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2605,  23.7352, -18.9849],\n",
      "        [-22.8712,  24.3584, -19.6713],\n",
      "        [-22.6839,  23.9022, -19.7569],\n",
      "        [-22.3121,  23.6138, -19.0441],\n",
      "        [-22.6024,  23.9113, -19.4129],\n",
      "        [-22.3434,  23.9255, -19.0838]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3045,  19.0016,  19.9503, -22.2605,  23.7352, -18.9849],\n",
      "        [ 24.4180,  19.3545,  20.0801, -22.8712,  24.3584, -19.6713],\n",
      "        [ 23.9728,  18.9362,  20.0513, -22.6839,  23.9022, -19.7569],\n",
      "        [ 24.4763,  19.4993,  19.9495, -22.3121,  23.6138, -19.0441],\n",
      "        [ 24.0814,  19.3401,  20.2774, -22.6024,  23.9113, -19.4129],\n",
      "        [ 24.5440,  19.2988,  20.1719, -22.3434,  23.9255, -19.0838]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.611000061035156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7633, 19.3205, 19.8005],\n",
      "        [23.8557, 18.8801, 20.0204],\n",
      "        [23.9378, 18.8005, 19.8951],\n",
      "        [23.9151, 19.0215, 19.7343],\n",
      "        [23.2630, 18.8918, 19.4304],\n",
      "        [23.9633, 19.0086, 20.0368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2464, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6694,  23.9800, -19.6107],\n",
      "        [-22.5570,  23.7550, -19.6753],\n",
      "        [-23.0285,  24.4083, -19.7443],\n",
      "        [-22.2104,  23.1808, -18.7287],\n",
      "        [-22.8326,  23.8547, -19.8534],\n",
      "        [-22.6750,  23.9227, -19.3071]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7633,  19.3205,  19.8005, -22.6694,  23.9800, -19.6107],\n",
      "        [ 23.8557,  18.8801,  20.0204, -22.5570,  23.7550, -19.6753],\n",
      "        [ 23.9378,  18.8005,  19.8951, -23.0285,  24.4083, -19.7443],\n",
      "        [ 23.9151,  19.0215,  19.7343, -22.2104,  23.1808, -18.7287],\n",
      "        [ 23.2630,  18.8918,  19.4304, -22.8326,  23.8547, -19.8534],\n",
      "        [ 23.9633,  19.0086,  20.0368, -22.6750,  23.9227, -19.3071]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.625289440155029\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2309, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9809, 19.0224, 19.9764],\n",
      "        [23.8321, 18.9815, 19.6780],\n",
      "        [23.8122, 19.0235, 20.2464],\n",
      "        [23.8034, 18.6591, 19.7011],\n",
      "        [23.5452, 18.8428, 19.7524],\n",
      "        [23.9642, 18.9501, 19.7540]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.0801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7011,  23.9664, -19.5399],\n",
      "        [-22.5636,  24.0544, -19.5648],\n",
      "        [-23.3274,  24.5738, -19.5885],\n",
      "        [-23.0261,  24.5124, -19.6659],\n",
      "        [-22.6525,  24.2821, -19.3035],\n",
      "        [-22.8740,  23.9467, -19.3086]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9809,  19.0224,  19.9764, -22.7011,  23.9664, -19.5399],\n",
      "        [ 23.8321,  18.9815,  19.6780, -22.5636,  24.0544, -19.5648],\n",
      "        [ 23.8122,  19.0235,  20.2464, -23.3274,  24.5738, -19.5885],\n",
      "        [ 23.8034,  18.6591,  19.7011, -23.0261,  24.5124, -19.6659],\n",
      "        [ 23.5452,  18.8428,  19.7524, -22.6525,  24.2821, -19.3035],\n",
      "        [ 23.9642,  18.9501,  19.7540, -22.8740,  23.9467, -19.3086]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.634825229644775\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.6059, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8856, 18.5373, 19.3790],\n",
      "        [23.6297, 18.6958, 19.7479],\n",
      "        [24.4062, 19.7928, 20.4717],\n",
      "        [24.1098, 19.2325, 20.0327],\n",
      "        [24.6673, 19.6014, 20.3144],\n",
      "        [24.0796, 19.2314, 20.0429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8237, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6870,  23.9118, -19.7102],\n",
      "        [-22.1084,  23.2822, -19.0080],\n",
      "        [-22.4397,  24.2586, -19.0160],\n",
      "        [-22.7517,  23.6334, -19.5121],\n",
      "        [-22.5776,  23.8907, -19.5526],\n",
      "        [-22.5771,  23.8829, -19.3078]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8856,  18.5373,  19.3790, -22.6870,  23.9118, -19.7102],\n",
      "        [ 23.6297,  18.6958,  19.7479, -22.1084,  23.2822, -19.0080],\n",
      "        [ 24.4062,  19.7928,  20.4717, -22.4397,  24.2586, -19.0160],\n",
      "        [ 24.1098,  19.2325,  20.0327, -22.7517,  23.6334, -19.5121],\n",
      "        [ 24.6673,  19.6014,  20.3144, -22.5776,  23.8907, -19.5526],\n",
      "        [ 24.0796,  19.2314,  20.0429, -22.5771,  23.8829, -19.3078]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.593355178833008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8272, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1459, 19.2752, 19.7876],\n",
      "        [24.1884, 19.2080, 20.2267],\n",
      "        [24.2493, 18.9631, 20.2133],\n",
      "        [24.8225, 19.2844, 20.7175],\n",
      "        [24.2140, 19.0978, 20.3064],\n",
      "        [24.3295, 19.5014, 19.9740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4625, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0839,  23.4497, -19.0326],\n",
      "        [-22.6465,  24.1557, -19.4566],\n",
      "        [-22.7249,  23.8747, -19.0627],\n",
      "        [-22.5645,  23.2811, -19.0493],\n",
      "        [-22.6722,  23.8081, -19.2064],\n",
      "        [-22.6570,  23.6591, -19.2363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1459,  19.2752,  19.7876, -22.0839,  23.4497, -19.0326],\n",
      "        [ 24.1884,  19.2080,  20.2267, -22.6465,  24.1557, -19.4566],\n",
      "        [ 24.2493,  18.9631,  20.2133, -22.7249,  23.8747, -19.0627],\n",
      "        [ 24.8225,  19.2844,  20.7175, -22.5645,  23.2811, -19.0493],\n",
      "        [ 24.2140,  19.0978,  20.3064, -22.6722,  23.8081, -19.2064],\n",
      "        [ 24.3295,  19.5014,  19.9740, -22.6570,  23.6591, -19.2363]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.597728252410889\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3949, 18.9428, 19.9021],\n",
      "        [23.9886, 19.0465, 19.8258],\n",
      "        [24.4803, 19.3277, 20.1615],\n",
      "        [24.4103, 19.3168, 20.2673],\n",
      "        [24.6963, 19.1782, 20.5323],\n",
      "        [24.1850, 19.1530, 20.3398]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7538,  23.7485, -19.2642],\n",
      "        [-22.6349,  24.0492, -19.3635],\n",
      "        [-22.6865,  23.8862, -19.2345],\n",
      "        [-21.9012,  23.4190, -19.2457],\n",
      "        [-22.9261,  24.4527, -20.0515],\n",
      "        [-22.5050,  23.7711, -19.3449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3949,  18.9428,  19.9021, -22.7538,  23.7485, -19.2642],\n",
      "        [ 23.9886,  19.0465,  19.8258, -22.6349,  24.0492, -19.3635],\n",
      "        [ 24.4803,  19.3277,  20.1615, -22.6865,  23.8862, -19.2345],\n",
      "        [ 24.4103,  19.3168,  20.2673, -21.9012,  23.4190, -19.2457],\n",
      "        [ 24.6963,  19.1782,  20.5323, -22.9261,  24.4527, -20.0515],\n",
      "        [ 24.1850,  19.1530,  20.3398, -22.5050,  23.7711, -19.3449]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.642830848693848\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4475, 19.6592, 20.1835],\n",
      "        [23.9342, 19.0189, 20.0864],\n",
      "        [24.0131, 19.2217, 19.7457],\n",
      "        [23.8769, 19.0751, 20.5283],\n",
      "        [24.1882, 19.2952, 20.1466],\n",
      "        [23.9104, 19.2533, 19.7661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.9075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5068,  23.8839, -19.4883],\n",
      "        [-22.5886,  24.0505, -19.0653],\n",
      "        [-22.8747,  24.1863, -19.6612],\n",
      "        [-22.5549,  23.8286, -19.5003],\n",
      "        [-22.5624,  24.2864, -19.5609],\n",
      "        [-22.8141,  24.1568, -19.8027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4475,  19.6592,  20.1835, -22.5068,  23.8839, -19.4883],\n",
      "        [ 23.9342,  19.0189,  20.0864, -22.5886,  24.0505, -19.0653],\n",
      "        [ 24.0131,  19.2217,  19.7457, -22.8747,  24.1863, -19.6612],\n",
      "        [ 23.8769,  19.0751,  20.5283, -22.5549,  23.8286, -19.5003],\n",
      "        [ 24.1882,  19.2952,  20.1466, -22.5624,  24.2864, -19.5609],\n",
      "        [ 23.9104,  19.2533,  19.7661, -22.8141,  24.1568, -19.8027]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.684004783630371\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7422, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0887, 19.2449, 19.7863],\n",
      "        [23.7673, 19.0077, 20.1032],\n",
      "        [23.6575, 18.2537, 19.3635],\n",
      "        [24.3479, 19.8583, 20.2893],\n",
      "        [24.1376, 19.1087, 20.2557],\n",
      "        [24.2227, 18.8067, 20.2615]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6871, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1280,  24.4383, -19.7628],\n",
      "        [-22.4327,  23.5150, -19.5363],\n",
      "        [-22.5445,  24.1293, -19.7416],\n",
      "        [-22.4572,  23.7114, -19.0777],\n",
      "        [-22.2616,  23.7663, -19.4834],\n",
      "        [-22.8616,  24.6139, -19.9293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0887,  19.2449,  19.7863, -23.1280,  24.4383, -19.7628],\n",
      "        [ 23.7673,  19.0077,  20.1032, -22.4327,  23.5150, -19.5363],\n",
      "        [ 23.6575,  18.2537,  19.3635, -22.5445,  24.1293, -19.7416],\n",
      "        [ 24.3479,  19.8583,  20.2893, -22.4572,  23.7114, -19.0777],\n",
      "        [ 24.1376,  19.1087,  20.2557, -22.2616,  23.7663, -19.4834],\n",
      "        [ 24.2227,  18.8067,  20.2615, -22.8616,  24.6139, -19.9293]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.682222366333008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7987, 18.8980, 19.9843],\n",
      "        [24.1989, 19.2489, 20.5314],\n",
      "        [24.0085, 19.0979, 20.2112],\n",
      "        [24.0410, 19.2260, 20.2800],\n",
      "        [24.3187, 19.1830, 20.1231],\n",
      "        [23.6230, 18.6501, 19.3357]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.7082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0732,  24.4260, -19.8173],\n",
      "        [-22.9351,  23.6716, -19.1739],\n",
      "        [-22.8354,  24.2045, -19.4622],\n",
      "        [-22.7173,  24.1160, -19.8265],\n",
      "        [-22.5501,  23.8888, -19.3662],\n",
      "        [-22.3108,  23.6753, -19.4116]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7987,  18.8980,  19.9843, -23.0732,  24.4260, -19.8173],\n",
      "        [ 24.1989,  19.2489,  20.5314, -22.9351,  23.6716, -19.1739],\n",
      "        [ 24.0085,  19.0979,  20.2112, -22.8354,  24.2045, -19.4622],\n",
      "        [ 24.0410,  19.2260,  20.2800, -22.7173,  24.1160, -19.8265],\n",
      "        [ 24.3187,  19.1830,  20.1231, -22.5501,  23.8888, -19.3662],\n",
      "        [ 23.6230,  18.6501,  19.3357, -22.3108,  23.6753, -19.4116]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.665884494781494\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6194, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7313, 18.9715, 20.1693],\n",
      "        [24.4457, 19.5452, 20.1660],\n",
      "        [23.9875, 19.0080, 20.0239],\n",
      "        [23.5638, 18.7678, 19.7408],\n",
      "        [24.0268, 19.0836, 19.9818],\n",
      "        [24.1157, 19.0424, 20.0796]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.8440, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2421,  23.7650, -19.3452],\n",
      "        [-23.2863,  24.5369, -20.1851],\n",
      "        [-23.2590,  24.4482, -19.6206],\n",
      "        [-22.2834,  23.5424, -19.0019],\n",
      "        [-22.8716,  23.7654, -19.2155],\n",
      "        [-22.8576,  24.0292, -19.6102]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7313,  18.9715,  20.1693, -22.2421,  23.7650, -19.3452],\n",
      "        [ 24.4457,  19.5452,  20.1660, -23.2863,  24.5369, -20.1851],\n",
      "        [ 23.9875,  19.0080,  20.0239, -23.2590,  24.4482, -19.6206],\n",
      "        [ 23.5638,  18.7678,  19.7408, -22.2834,  23.5424, -19.0019],\n",
      "        [ 24.0268,  19.0836,  19.9818, -22.8716,  23.7654, -19.2155],\n",
      "        [ 24.1157,  19.0424,  20.0796, -22.8576,  24.0292, -19.6102]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.6147780418396\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8752, 18.9365, 19.3606],\n",
      "        [24.3131, 19.6442, 20.1283],\n",
      "        [23.9273, 19.1675, 20.1368],\n",
      "        [23.4799, 18.8622, 20.1641],\n",
      "        [23.9198, 18.9763, 19.8820],\n",
      "        [24.0741, 19.6632, 20.3292]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.9438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7069,  23.8228, -19.2666],\n",
      "        [-23.2346,  24.3663, -19.7448],\n",
      "        [-23.0843,  23.9563, -19.9224],\n",
      "        [-22.3032,  23.8306, -19.4246],\n",
      "        [-22.9549,  24.3463, -19.6269],\n",
      "        [-22.3306,  23.8827, -19.0317]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8752,  18.9365,  19.3606, -22.7069,  23.8228, -19.2666],\n",
      "        [ 24.3131,  19.6442,  20.1283, -23.2346,  24.3663, -19.7448],\n",
      "        [ 23.9273,  19.1675,  20.1368, -23.0843,  23.9563, -19.9224],\n",
      "        [ 23.4799,  18.8622,  20.1641, -22.3032,  23.8306, -19.4246],\n",
      "        [ 23.9198,  18.9763,  19.8820, -22.9549,  24.3463, -19.6269],\n",
      "        [ 24.0741,  19.6632,  20.3292, -22.3306,  23.8827, -19.0317]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.602941989898682\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6670, 18.8785, 19.9250],\n",
      "        [24.1184, 19.2877, 20.5327],\n",
      "        [24.3160, 18.7866, 20.1867],\n",
      "        [24.5158, 19.2540, 20.3850],\n",
      "        [24.8062, 19.5819, 20.5754],\n",
      "        [24.1726, 19.0046, 20.1713]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.6304, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8729,  24.0669, -19.6882],\n",
      "        [-22.2477,  23.5189, -18.9737],\n",
      "        [-22.6216,  23.7960, -19.6920],\n",
      "        [-22.5621,  23.9244, -19.2234],\n",
      "        [-23.0255,  24.1660, -19.5242],\n",
      "        [-22.8473,  24.4486, -19.8496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6670,  18.8785,  19.9250, -22.8729,  24.0669, -19.6882],\n",
      "        [ 24.1184,  19.2877,  20.5327, -22.2477,  23.5189, -18.9737],\n",
      "        [ 24.3160,  18.7866,  20.1867, -22.6216,  23.7960, -19.6920],\n",
      "        [ 24.5158,  19.2540,  20.3850, -22.5621,  23.9244, -19.2234],\n",
      "        [ 24.8062,  19.5819,  20.5754, -23.0255,  24.1660, -19.5242],\n",
      "        [ 24.1726,  19.0046,  20.1713, -22.8473,  24.4486, -19.8496]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.639838218688965\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8566, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2440, 19.1409, 19.9728],\n",
      "        [24.1903, 18.8263, 19.7734],\n",
      "        [24.3097, 19.0946, 20.0454],\n",
      "        [22.9856, 18.7189, 19.2204],\n",
      "        [23.9897, 18.9200, 19.6212],\n",
      "        [24.3519, 19.2143, 20.0243]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4888,  23.9561, -19.5965],\n",
      "        [-22.8994,  23.9861, -19.6053],\n",
      "        [-22.0037,  23.5193, -19.6435],\n",
      "        [-22.5409,  23.8095, -19.3423],\n",
      "        [-22.4584,  23.6073, -19.2429],\n",
      "        [-22.8843,  23.8338, -19.6469]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2440,  19.1409,  19.9728, -22.4888,  23.9561, -19.5965],\n",
      "        [ 24.1903,  18.8263,  19.7734, -22.8994,  23.9861, -19.6053],\n",
      "        [ 24.3097,  19.0946,  20.0454, -22.0037,  23.5193, -19.6435],\n",
      "        [ 22.9856,  18.7189,  19.2204, -22.5409,  23.8095, -19.3423],\n",
      "        [ 23.9897,  18.9200,  19.6212, -22.4584,  23.6073, -19.2429],\n",
      "        [ 24.3519,  19.2143,  20.0243, -22.8843,  23.8338, -19.6469]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.663260459899902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5353, 19.5142, 20.9482],\n",
      "        [23.8970, 19.2988, 20.0698],\n",
      "        [24.0579, 19.2242, 19.8027],\n",
      "        [24.3920, 19.3942, 19.8719],\n",
      "        [24.6522, 19.9275, 20.1546],\n",
      "        [23.7677, 19.0014, 19.8665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9094,  24.0813, -19.6293],\n",
      "        [-22.8113,  24.3455, -20.0662],\n",
      "        [-22.0679,  23.7809, -19.0255],\n",
      "        [-22.8549,  23.9351, -19.4170],\n",
      "        [-22.6381,  24.0126, -19.6496],\n",
      "        [-22.4672,  23.8498, -19.3199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5353,  19.5142,  20.9482, -22.9094,  24.0813, -19.6293],\n",
      "        [ 23.8970,  19.2988,  20.0698, -22.8113,  24.3455, -20.0662],\n",
      "        [ 24.0579,  19.2242,  19.8027, -22.0679,  23.7809, -19.0255],\n",
      "        [ 24.3920,  19.3942,  19.8719, -22.8549,  23.9351, -19.4170],\n",
      "        [ 24.6522,  19.9275,  20.1546, -22.6381,  24.0126, -19.6496],\n",
      "        [ 23.7677,  19.0014,  19.8665, -22.4672,  23.8498, -19.3199]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.75072717666626\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1657, 18.7992, 19.6480],\n",
      "        [23.9894, 18.8774, 20.1213],\n",
      "        [24.2617, 19.0807, 19.9261],\n",
      "        [24.1956, 18.8770, 20.0247],\n",
      "        [24.5313, 19.3917, 20.1229],\n",
      "        [24.7233, 19.5224, 20.4064]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.5697, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2005,  23.8006, -19.1656],\n",
      "        [-22.3850,  23.8171, -19.7374],\n",
      "        [-22.7950,  23.7507, -19.7714],\n",
      "        [-22.7996,  23.9951, -19.7245],\n",
      "        [-22.5415,  24.2834, -19.4794],\n",
      "        [-22.6195,  23.9969, -19.5999]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1657,  18.7992,  19.6480, -22.2005,  23.8006, -19.1656],\n",
      "        [ 23.9894,  18.8774,  20.1213, -22.3850,  23.8171, -19.7374],\n",
      "        [ 24.2617,  19.0807,  19.9261, -22.7950,  23.7507, -19.7714],\n",
      "        [ 24.1956,  18.8770,  20.0247, -22.7996,  23.9951, -19.7245],\n",
      "        [ 24.5313,  19.3917,  20.1229, -22.5415,  24.2834, -19.4794],\n",
      "        [ 24.7233,  19.5224,  20.4064, -22.6195,  23.9969, -19.5999]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.613236904144287\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2127, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1758, 19.3695, 20.2402],\n",
      "        [24.5831, 19.4008, 20.6865],\n",
      "        [24.0178, 19.2389, 19.8392],\n",
      "        [24.1203, 19.0792, 20.1344],\n",
      "        [23.1998, 18.7683, 19.4540],\n",
      "        [23.7846, 18.9243, 20.1379]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.3052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.0505,  23.4154, -19.1001],\n",
      "        [-22.8568,  24.0118, -19.9638],\n",
      "        [-22.8699,  24.2951, -19.8228],\n",
      "        [-23.0030,  23.9210, -19.6703],\n",
      "        [-22.8101,  23.8703, -19.2277],\n",
      "        [-22.7518,  24.2228, -19.4523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1758,  19.3695,  20.2402, -22.0505,  23.4154, -19.1001],\n",
      "        [ 24.5831,  19.4008,  20.6865, -22.8568,  24.0118, -19.9638],\n",
      "        [ 24.0178,  19.2389,  19.8392, -22.8699,  24.2951, -19.8228],\n",
      "        [ 24.1203,  19.0792,  20.1344, -23.0030,  23.9210, -19.6703],\n",
      "        [ 23.1998,  18.7683,  19.4540, -22.8101,  23.8703, -19.2277],\n",
      "        [ 23.7846,  18.9243,  20.1379, -22.7518,  24.2228, -19.4523]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.639319896697998\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3758, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2637, 19.2960, 20.4066],\n",
      "        [24.5190, 19.6431, 20.2771],\n",
      "        [24.0847, 19.0375, 19.9963],\n",
      "        [24.3421, 19.4267, 20.2310],\n",
      "        [24.2193, 19.3070, 19.8738],\n",
      "        [24.6584, 19.4107, 20.2296]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.7409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0073,  23.7247, -19.8470],\n",
      "        [-22.7229,  24.1702, -19.6511],\n",
      "        [-22.4554,  23.7959, -19.3840],\n",
      "        [-22.4311,  23.7209, -19.2775],\n",
      "        [-22.9021,  23.8957, -19.4422],\n",
      "        [-22.5204,  23.8308, -19.5548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2637,  19.2960,  20.4066, -23.0073,  23.7247, -19.8470],\n",
      "        [ 24.5190,  19.6431,  20.2771, -22.7229,  24.1702, -19.6511],\n",
      "        [ 24.0847,  19.0375,  19.9963, -22.4554,  23.7959, -19.3840],\n",
      "        [ 24.3421,  19.4267,  20.2310, -22.4311,  23.7209, -19.2775],\n",
      "        [ 24.2193,  19.3070,  19.8738, -22.9021,  23.8957, -19.4422],\n",
      "        [ 24.6584,  19.4107,  20.2296, -22.5204,  23.8308, -19.5548]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.708998680114746\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3610, 19.3141, 20.2572],\n",
      "        [24.2823, 19.2543, 20.0508],\n",
      "        [24.4474, 19.3309, 20.1768],\n",
      "        [24.4543, 19.3409, 20.2899],\n",
      "        [24.2455, 19.3298, 20.3504],\n",
      "        [24.2602, 19.2790, 20.2204]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4115, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1263,  24.3387, -19.9008],\n",
      "        [-23.2471,  24.1356, -19.5195],\n",
      "        [-23.3331,  24.9017, -20.3735],\n",
      "        [-22.7354,  24.4484, -19.7169],\n",
      "        [-22.4652,  23.7465, -19.5550],\n",
      "        [-23.1390,  24.3172, -19.9825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3610,  19.3141,  20.2572, -23.1263,  24.3387, -19.9008],\n",
      "        [ 24.2823,  19.2543,  20.0508, -23.2471,  24.1356, -19.5195],\n",
      "        [ 24.4474,  19.3309,  20.1768, -23.3331,  24.9017, -20.3735],\n",
      "        [ 24.4543,  19.3409,  20.2899, -22.7354,  24.4484, -19.7169],\n",
      "        [ 24.2455,  19.3298,  20.3504, -22.4652,  23.7465, -19.5550],\n",
      "        [ 24.2602,  19.2790,  20.2204, -23.1390,  24.3172, -19.9825]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.735398292541504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4615, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.7131, 18.8632, 20.1320],\n",
      "        [24.4475, 19.3751, 20.2252],\n",
      "        [24.3174, 19.2583, 20.7234],\n",
      "        [24.0731, 19.0195, 20.2892],\n",
      "        [23.7228, 18.8760, 19.6264],\n",
      "        [24.5432, 19.2527, 19.8337]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.6114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4156,  24.0119, -19.3958],\n",
      "        [-22.2370,  23.2163, -18.7042],\n",
      "        [-22.0936,  23.6486, -19.2221],\n",
      "        [-22.7404,  24.5954, -20.0869],\n",
      "        [-22.9830,  24.0569, -19.8410],\n",
      "        [-23.1608,  24.5087, -19.9767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.7131,  18.8632,  20.1320, -22.4156,  24.0119, -19.3958],\n",
      "        [ 24.4475,  19.3751,  20.2252, -22.2370,  23.2163, -18.7042],\n",
      "        [ 24.3174,  19.2583,  20.7234, -22.0936,  23.6486, -19.2221],\n",
      "        [ 24.0731,  19.0195,  20.2892, -22.7404,  24.5954, -20.0869],\n",
      "        [ 23.7228,  18.8760,  19.6264, -22.9830,  24.0569, -19.8410],\n",
      "        [ 24.5432,  19.2527,  19.8337, -23.1608,  24.5087, -19.9767]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.638890743255615\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4378, 18.8470, 20.2472],\n",
      "        [24.4068, 19.4510, 20.3060],\n",
      "        [24.5547, 19.4344, 20.4442],\n",
      "        [24.2296, 19.3807, 20.2248],\n",
      "        [24.4737, 19.2825, 20.3793],\n",
      "        [24.2320, 19.2898, 20.3232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.6691, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.2399,  24.2174, -19.5523],\n",
      "        [-22.8808,  23.9599, -19.4550],\n",
      "        [-22.4767,  24.0901, -19.6016],\n",
      "        [-23.1425,  24.4319, -19.8060],\n",
      "        [-22.6312,  24.0161, -19.6010],\n",
      "        [-23.1706,  24.4046, -19.9643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4378,  18.8470,  20.2472, -22.2399,  24.2174, -19.5523],\n",
      "        [ 24.4068,  19.4510,  20.3060, -22.8808,  23.9599, -19.4550],\n",
      "        [ 24.5547,  19.4344,  20.4442, -22.4767,  24.0901, -19.6016],\n",
      "        [ 24.2296,  19.3807,  20.2248, -23.1425,  24.4319, -19.8060],\n",
      "        [ 24.4737,  19.2825,  20.3793, -22.6312,  24.0161, -19.6010],\n",
      "        [ 24.2320,  19.2898,  20.3232, -23.1706,  24.4046, -19.9643]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.687161445617676\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1658, 19.2258, 19.8293],\n",
      "        [24.3016, 18.9247, 20.0272],\n",
      "        [23.8144, 19.1353, 19.5971],\n",
      "        [23.6044, 19.0558, 19.6764],\n",
      "        [24.1383, 19.0224, 19.8983],\n",
      "        [24.4506, 19.1603, 20.0298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.5146, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7056,  24.5923, -19.6732],\n",
      "        [-22.6145,  23.9663, -19.5812],\n",
      "        [-23.0677,  24.2756, -20.0812],\n",
      "        [-23.1488,  24.3974, -19.6225],\n",
      "        [-23.2101,  24.4074, -19.7404],\n",
      "        [-23.1480,  23.6298, -19.6211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1658,  19.2258,  19.8293, -22.7056,  24.5923, -19.6732],\n",
      "        [ 24.3016,  18.9247,  20.0272, -22.6145,  23.9663, -19.5812],\n",
      "        [ 23.8144,  19.1353,  19.5971, -23.0677,  24.2756, -20.0812],\n",
      "        [ 23.6044,  19.0558,  19.6764, -23.1488,  24.3974, -19.6225],\n",
      "        [ 24.1383,  19.0224,  19.8983, -23.2101,  24.4074, -19.7404],\n",
      "        [ 24.4506,  19.1603,  20.0298, -23.1480,  23.6298, -19.6211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.699347972869873\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8069, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4244, 19.3556, 20.3927],\n",
      "        [24.4328, 19.4274, 20.1353],\n",
      "        [24.5991, 19.5037, 20.2713],\n",
      "        [23.8390, 19.2173, 19.7996],\n",
      "        [23.9492, 19.1619, 20.3618],\n",
      "        [24.6142, 19.3918, 20.3987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.1753, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6538,  24.1233, -19.6632],\n",
      "        [-22.9004,  24.3461, -20.1556],\n",
      "        [-22.7490,  23.9335, -19.5623],\n",
      "        [-22.8884,  24.0705, -19.6438],\n",
      "        [-23.0128,  24.1091, -19.8715],\n",
      "        [-23.2497,  24.4747, -19.7995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4244,  19.3556,  20.3927, -22.6538,  24.1233, -19.6632],\n",
      "        [ 24.4328,  19.4274,  20.1353, -22.9004,  24.3461, -20.1556],\n",
      "        [ 24.5991,  19.5037,  20.2713, -22.7490,  23.9335, -19.5623],\n",
      "        [ 23.8390,  19.2173,  19.7996, -22.8884,  24.0705, -19.6438],\n",
      "        [ 23.9492,  19.1619,  20.3618, -23.0128,  24.1091, -19.8715],\n",
      "        [ 24.6142,  19.3918,  20.3987, -23.2497,  24.4747, -19.7995]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.724679946899414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9867, 18.5771, 20.0551],\n",
      "        [24.6633, 19.2053, 20.2369],\n",
      "        [24.2265, 19.0005, 20.0471],\n",
      "        [24.6424, 19.2634, 20.5308],\n",
      "        [24.7241, 19.2968, 20.4909],\n",
      "        [24.6674, 19.4951, 20.5241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2748, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6215,  24.2688, -19.6365],\n",
      "        [-22.7595,  23.6251, -19.5983],\n",
      "        [-23.2171,  24.4332, -20.2286],\n",
      "        [-21.9259,  23.2758, -19.2400],\n",
      "        [-23.3483,  24.3434, -19.9115],\n",
      "        [-22.2571,  24.0908, -19.6264]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9867,  18.5771,  20.0551, -22.6215,  24.2688, -19.6365],\n",
      "        [ 24.6633,  19.2053,  20.2369, -22.7595,  23.6251, -19.5983],\n",
      "        [ 24.2265,  19.0005,  20.0471, -23.2171,  24.4332, -20.2286],\n",
      "        [ 24.6424,  19.2634,  20.5308, -21.9259,  23.2758, -19.2400],\n",
      "        [ 24.7241,  19.2968,  20.4909, -23.3483,  24.3434, -19.9115],\n",
      "        [ 24.6674,  19.4951,  20.5241, -22.2571,  24.0908, -19.6264]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.668331623077393\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4256, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.8933, 19.1341, 20.4355],\n",
      "        [24.6527, 19.4970, 20.5904],\n",
      "        [23.8478, 18.8076, 19.6480],\n",
      "        [24.4496, 19.5751, 20.2334],\n",
      "        [23.9904, 19.2021, 19.6254],\n",
      "        [24.2743, 19.0326, 19.7033]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.2284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.4783,  23.5314, -19.5700],\n",
      "        [-22.3343,  23.0561, -18.5961],\n",
      "        [-23.0623,  23.9664, -19.5295],\n",
      "        [-22.8429,  24.0051, -19.8336],\n",
      "        [-23.2066,  24.6590, -19.8321],\n",
      "        [-22.6822,  23.4497, -19.2014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.8933,  19.1341,  20.4355, -22.4783,  23.5314, -19.5700],\n",
      "        [ 24.6527,  19.4970,  20.5904, -22.3343,  23.0561, -18.5961],\n",
      "        [ 23.8478,  18.8076,  19.6480, -23.0623,  23.9664, -19.5295],\n",
      "        [ 24.4496,  19.5751,  20.2334, -22.8429,  24.0051, -19.8336],\n",
      "        [ 23.9904,  19.2021,  19.6254, -23.2066,  24.6590, -19.8321],\n",
      "        [ 24.2743,  19.0326,  19.7033, -22.6822,  23.4497, -19.2014]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.668281555175781\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3473, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4559, 19.5406, 20.4224],\n",
      "        [23.8503, 19.3085, 20.1409],\n",
      "        [23.9446, 18.8096, 20.1655],\n",
      "        [23.8182, 19.4306, 20.2517],\n",
      "        [24.4136, 19.4330, 20.1318],\n",
      "        [23.9002, 19.2496, 19.8056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(22.6906, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9636,  23.9423, -20.0398],\n",
      "        [-23.0694,  24.7181, -20.0068],\n",
      "        [-22.4698,  23.9029, -19.4838],\n",
      "        [-23.0569,  24.2777, -19.7482],\n",
      "        [-23.0507,  24.2588, -19.5938],\n",
      "        [-23.4498,  24.6881, -20.1202]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4559,  19.5406,  20.4224, -22.9636,  23.9423, -20.0398],\n",
      "        [ 23.8503,  19.3085,  20.1409, -23.0694,  24.7181, -20.0068],\n",
      "        [ 23.9446,  18.8096,  20.1655, -22.4698,  23.9029, -19.4838],\n",
      "        [ 23.8182,  19.4306,  20.2517, -23.0569,  24.2777, -19.7482],\n",
      "        [ 24.4136,  19.4330,  20.1318, -23.0507,  24.2588, -19.5938],\n",
      "        [ 23.9002,  19.2496,  19.8056, -23.4498,  24.6881, -20.1202]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.751698017120361\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6427, 19.7235, 20.6317],\n",
      "        [25.0674, 19.5956, 20.6792],\n",
      "        [24.5326, 19.4614, 20.5309],\n",
      "        [24.1546, 19.4229, 20.5932],\n",
      "        [24.0905, 19.3853, 20.2465],\n",
      "        [23.9844, 19.3184, 20.3444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.9686, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9461,  24.2089, -19.8141],\n",
      "        [-23.2111,  24.6909, -20.3036],\n",
      "        [-22.9665,  24.1245, -19.8538],\n",
      "        [-22.8963,  24.3740, -19.8388],\n",
      "        [-23.3411,  24.6758, -20.1718],\n",
      "        [-22.8164,  23.7727, -19.4853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6427,  19.7235,  20.6317, -22.9461,  24.2089, -19.8141],\n",
      "        [ 25.0674,  19.5956,  20.6792, -23.2111,  24.6909, -20.3036],\n",
      "        [ 24.5326,  19.4614,  20.5309, -22.9665,  24.1245, -19.8538],\n",
      "        [ 24.1546,  19.4229,  20.5932, -22.8963,  24.3740, -19.8388],\n",
      "        [ 24.0905,  19.3853,  20.2465, -23.3411,  24.6758, -20.1718],\n",
      "        [ 23.9844,  19.3184,  20.3444, -22.8164,  23.7727, -19.4853]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.780246257781982\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.6503, 19.0628, 19.8927],\n",
      "        [24.1878, 19.6382, 20.5672],\n",
      "        [24.8123, 19.7944, 20.5564],\n",
      "        [24.0953, 19.0105, 20.1959],\n",
      "        [24.6031, 19.6568, 20.3923],\n",
      "        [24.1672, 19.5208, 20.2523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1678,  24.3414, -19.7604],\n",
      "        [-23.4100,  24.3416, -19.9597],\n",
      "        [-22.8945,  24.3244, -19.7454],\n",
      "        [-23.1214,  24.3107, -19.8635],\n",
      "        [-22.3000,  23.4226, -19.3592],\n",
      "        [-22.5001,  24.1592, -19.6977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.6503,  19.0628,  19.8927, -23.1678,  24.3414, -19.7604],\n",
      "        [ 24.1878,  19.6382,  20.5672, -23.4100,  24.3416, -19.9597],\n",
      "        [ 24.8123,  19.7944,  20.5564, -22.8945,  24.3244, -19.7454],\n",
      "        [ 24.0953,  19.0105,  20.1959, -23.1214,  24.3107, -19.8635],\n",
      "        [ 24.6031,  19.6568,  20.3923, -22.3000,  23.4226, -19.3592],\n",
      "        [ 24.1672,  19.5208,  20.2523, -22.5001,  24.1592, -19.6977]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.6890788078308105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3466, 19.4681, 20.5464],\n",
      "        [24.4040, 19.2413, 20.0396],\n",
      "        [24.4750, 19.2737, 20.2871],\n",
      "        [24.3088, 19.3783, 20.1896],\n",
      "        [24.3468, 19.2526, 20.4602],\n",
      "        [24.3543, 19.2100, 20.3982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3243,  24.0410, -19.3106],\n",
      "        [-22.5808,  23.6508, -19.2446],\n",
      "        [-23.5388,  24.5277, -19.8192],\n",
      "        [-23.0300,  24.2483, -20.0368],\n",
      "        [-22.9734,  24.1995, -19.4177],\n",
      "        [-23.1264,  23.9772, -19.8783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3466,  19.4681,  20.5464, -22.3243,  24.0410, -19.3106],\n",
      "        [ 24.4040,  19.2413,  20.0396, -22.5808,  23.6508, -19.2446],\n",
      "        [ 24.4750,  19.2737,  20.2871, -23.5388,  24.5277, -19.8192],\n",
      "        [ 24.3088,  19.3783,  20.1896, -23.0300,  24.2483, -20.0368],\n",
      "        [ 24.3468,  19.2526,  20.4602, -22.9734,  24.1995, -19.4177],\n",
      "        [ 24.3543,  19.2100,  20.3982, -23.1264,  23.9772, -19.8783]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.719115734100342\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5466, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3614, 19.5669, 20.1144],\n",
      "        [24.5710, 19.7584, 20.2371],\n",
      "        [24.6366, 19.3615, 20.4431],\n",
      "        [23.6581, 18.7056, 19.8921],\n",
      "        [24.5270, 19.2195, 20.2789],\n",
      "        [23.9072, 19.0001, 19.6575]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5889,  24.2212, -19.8104],\n",
      "        [-22.1264,  23.6418, -19.5844],\n",
      "        [-22.5992,  24.1415, -19.7273],\n",
      "        [-23.0452,  24.5124, -20.0056],\n",
      "        [-22.9133,  24.6210, -19.7349],\n",
      "        [-22.8764,  24.5400, -19.8508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3614,  19.5669,  20.1144, -22.5889,  24.2212, -19.8104],\n",
      "        [ 24.5710,  19.7584,  20.2371, -22.1264,  23.6418, -19.5844],\n",
      "        [ 24.6366,  19.3615,  20.4431, -22.5992,  24.1415, -19.7273],\n",
      "        [ 23.6581,  18.7056,  19.8921, -23.0452,  24.5124, -20.0056],\n",
      "        [ 24.5270,  19.2195,  20.2789, -22.9133,  24.6210, -19.7349],\n",
      "        [ 23.9072,  19.0001,  19.6575, -22.8764,  24.5400, -19.8508]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.7333526611328125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2089, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2198, 19.1151, 19.6987],\n",
      "        [24.7066, 19.6572, 20.6339],\n",
      "        [24.0528, 18.9092, 19.9613],\n",
      "        [24.1728, 18.8373, 20.0270],\n",
      "        [24.4515, 19.6215, 20.5704],\n",
      "        [23.7491, 18.5999, 19.5590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.4441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0415,  24.1103, -19.5891],\n",
      "        [-23.2032,  24.6417, -20.1772],\n",
      "        [-23.1422,  24.5860, -20.2483],\n",
      "        [-22.7932,  24.1344, -19.6917],\n",
      "        [-22.8138,  24.1507, -19.8316],\n",
      "        [-23.2543,  24.7934, -20.1579]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2198,  19.1151,  19.6987, -23.0415,  24.1103, -19.5891],\n",
      "        [ 24.7066,  19.6572,  20.6339, -23.2032,  24.6417, -20.1772],\n",
      "        [ 24.0528,  18.9092,  19.9613, -23.1422,  24.5860, -20.2483],\n",
      "        [ 24.1728,  18.8373,  20.0270, -22.7932,  24.1344, -19.6917],\n",
      "        [ 24.4515,  19.6215,  20.5704, -22.8138,  24.1507, -19.8316],\n",
      "        [ 23.7491,  18.5999,  19.5590, -23.2543,  24.7934, -20.1579]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.700701713562012\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7168, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2751, 19.1725, 20.5634],\n",
      "        [24.4019, 18.9919, 20.0452],\n",
      "        [23.9158, 18.9904, 20.1683],\n",
      "        [23.8299, 19.0135, 19.9192],\n",
      "        [24.6198, 19.5931, 20.7469],\n",
      "        [24.0527, 18.9169, 20.2176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1792, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9905,  24.2848, -19.5407],\n",
      "        [-22.4246,  23.9261, -19.6178],\n",
      "        [-23.4760,  24.8043, -20.1580],\n",
      "        [-22.8687,  23.9859, -19.8215],\n",
      "        [-22.7328,  24.1766, -19.4502],\n",
      "        [-22.7428,  24.2179, -19.8934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2751,  19.1725,  20.5634, -22.9905,  24.2848, -19.5407],\n",
      "        [ 24.4019,  18.9919,  20.0452, -22.4246,  23.9261, -19.6178],\n",
      "        [ 23.9158,  18.9904,  20.1683, -23.4760,  24.8043, -20.1580],\n",
      "        [ 23.8299,  19.0135,  19.9192, -22.8687,  23.9859, -19.8215],\n",
      "        [ 24.6198,  19.5931,  20.7469, -22.7328,  24.1766, -19.4502],\n",
      "        [ 24.0527,  18.9169,  20.2176, -22.7428,  24.2179, -19.8934]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.746734142303467\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7391, 19.4609, 20.5682],\n",
      "        [23.6659, 18.4786, 19.4937],\n",
      "        [24.8750, 19.7801, 20.3932],\n",
      "        [24.4975, 19.4675, 20.3562],\n",
      "        [24.3711, 19.0797, 20.2026],\n",
      "        [24.3688, 19.4355, 20.3066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3950, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8770,  23.9768, -19.4247],\n",
      "        [-23.4944,  24.3978, -19.9263],\n",
      "        [-22.4187,  24.0142, -19.7727],\n",
      "        [-22.5706,  24.1776, -19.9285],\n",
      "        [-22.9589,  24.1723, -19.9471],\n",
      "        [-22.8982,  23.7988, -19.5124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7391,  19.4609,  20.5682, -22.8770,  23.9768, -19.4247],\n",
      "        [ 23.6659,  18.4786,  19.4937, -23.4944,  24.3978, -19.9263],\n",
      "        [ 24.8750,  19.7801,  20.3932, -22.4187,  24.0142, -19.7727],\n",
      "        [ 24.4975,  19.4675,  20.3562, -22.5706,  24.1776, -19.9285],\n",
      "        [ 24.3711,  19.0797,  20.2026, -22.9589,  24.1723, -19.9471],\n",
      "        [ 24.3688,  19.4355,  20.3066, -22.8982,  23.7988, -19.5124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.764734745025635\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2945, 19.1534, 20.2653],\n",
      "        [24.4164, 19.1652, 20.5448],\n",
      "        [24.6047, 19.3414, 19.8322],\n",
      "        [24.8593, 20.0992, 20.5555],\n",
      "        [24.2707, 19.2881, 19.9626],\n",
      "        [24.0885, 18.9673, 20.1234]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.9354, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9962,  24.5099, -19.9911],\n",
      "        [-22.5670,  24.4231, -19.8713],\n",
      "        [-23.2730,  24.0104, -19.5869],\n",
      "        [-22.5884,  24.0131, -19.4256],\n",
      "        [-22.8133,  23.8937, -19.3097],\n",
      "        [-22.9839,  24.6354, -19.8277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2945,  19.1534,  20.2653, -22.9962,  24.5099, -19.9911],\n",
      "        [ 24.4164,  19.1652,  20.5448, -22.5670,  24.4231, -19.8713],\n",
      "        [ 24.6047,  19.3414,  19.8322, -23.2730,  24.0104, -19.5869],\n",
      "        [ 24.8593,  20.0992,  20.5555, -22.5884,  24.0131, -19.4256],\n",
      "        [ 24.2707,  19.2881,  19.9626, -22.8133,  23.8937, -19.3097],\n",
      "        [ 24.0885,  18.9673,  20.1234, -22.9839,  24.6354, -19.8277]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.757044315338135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5104, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1890, 19.1044, 20.7384],\n",
      "        [24.4493, 19.3349, 20.3497],\n",
      "        [24.3260, 19.4931, 19.9340],\n",
      "        [23.8439, 19.1534, 20.0291],\n",
      "        [24.1324, 19.3248, 19.8199],\n",
      "        [24.3378, 19.1420, 19.7350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.1139, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2753,  24.4591, -20.2300],\n",
      "        [-22.7939,  24.1950, -19.5250],\n",
      "        [-22.8075,  24.1331, -19.7170],\n",
      "        [-22.6071,  24.4106, -19.8699],\n",
      "        [-22.8060,  24.3290, -20.1543],\n",
      "        [-22.3550,  23.6352, -19.0998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1890,  19.1044,  20.7384, -23.2753,  24.4591, -20.2300],\n",
      "        [ 24.4493,  19.3349,  20.3497, -22.7939,  24.1950, -19.5250],\n",
      "        [ 24.3260,  19.4931,  19.9340, -22.8075,  24.1331, -19.7170],\n",
      "        [ 23.8439,  19.1534,  20.0291, -22.6071,  24.4106, -19.8699],\n",
      "        [ 24.1324,  19.3248,  19.8199, -22.8060,  24.3290, -20.1543],\n",
      "        [ 24.3378,  19.1420,  19.7350, -22.3550,  23.6352, -19.0998]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.7850117683410645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.8320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6114, 19.1061, 20.0480],\n",
      "        [24.2264, 19.2734, 20.4108],\n",
      "        [24.7965, 19.4425, 20.4541],\n",
      "        [24.1143, 19.2568, 20.2081],\n",
      "        [24.9868, 19.8043, 20.8153],\n",
      "        [24.4555, 19.4637, 20.3892]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7014,  23.5236, -19.5467],\n",
      "        [-22.7589,  24.0363, -19.4651],\n",
      "        [-22.1426,  23.5154, -18.9969],\n",
      "        [-23.1807,  24.3013, -19.9114],\n",
      "        [-23.1185,  23.8854, -19.2154],\n",
      "        [-23.0918,  24.5414, -20.2558]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6114,  19.1061,  20.0480, -22.7014,  23.5236, -19.5467],\n",
      "        [ 24.2264,  19.2734,  20.4108, -22.7589,  24.0363, -19.4651],\n",
      "        [ 24.7965,  19.4425,  20.4541, -22.1426,  23.5154, -18.9969],\n",
      "        [ 24.1143,  19.2568,  20.2081, -23.1807,  24.3013, -19.9114],\n",
      "        [ 24.9868,  19.8043,  20.8153, -23.1185,  23.8854, -19.2154],\n",
      "        [ 24.4555,  19.4637,  20.3892, -23.0918,  24.5414, -20.2558]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.712428092956543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4200, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7480, 19.5742, 20.3884],\n",
      "        [24.7594, 19.8025, 20.9843],\n",
      "        [23.9131, 19.7018, 20.0957],\n",
      "        [24.7482, 19.3069, 20.5117],\n",
      "        [24.4197, 19.1779, 20.6901],\n",
      "        [24.2658, 19.1416, 20.1352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.5929,  24.2575, -19.6549],\n",
      "        [-23.1481,  24.4454, -20.0256],\n",
      "        [-22.9836,  24.1004, -19.9420],\n",
      "        [-22.9239,  24.2022, -19.7146],\n",
      "        [-23.7046,  24.7803, -20.2580],\n",
      "        [-22.6060,  24.3637, -19.6907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7480,  19.5742,  20.3884, -22.5929,  24.2575, -19.6549],\n",
      "        [ 24.7594,  19.8025,  20.9843, -23.1481,  24.4454, -20.0256],\n",
      "        [ 23.9131,  19.7018,  20.0957, -22.9836,  24.1004, -19.9420],\n",
      "        [ 24.7482,  19.3069,  20.5117, -22.9239,  24.2022, -19.7146],\n",
      "        [ 24.4197,  19.1779,  20.6901, -23.7046,  24.7803, -20.2580],\n",
      "        [ 24.2658,  19.1416,  20.1352, -22.6060,  24.3637, -19.6907]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.774392127990723\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3071, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7814, 19.8072, 20.5449],\n",
      "        [24.1217, 19.2359, 20.1038],\n",
      "        [24.1463, 19.1942, 19.8756],\n",
      "        [25.0152, 19.8650, 20.8270],\n",
      "        [24.5512, 19.4512, 20.5280],\n",
      "        [24.6689, 19.9278, 20.2176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6443, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9545,  24.0393, -19.9023],\n",
      "        [-23.1231,  24.3130, -19.9431],\n",
      "        [-23.3684,  24.6744, -20.0941],\n",
      "        [-23.0391,  24.5467, -20.0221],\n",
      "        [-22.9357,  24.4525, -20.0621],\n",
      "        [-22.5863,  24.2574, -19.8079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7814,  19.8072,  20.5449, -22.9545,  24.0393, -19.9023],\n",
      "        [ 24.1217,  19.2359,  20.1038, -23.1231,  24.3130, -19.9431],\n",
      "        [ 24.1463,  19.1942,  19.8756, -23.3684,  24.6744, -20.0941],\n",
      "        [ 25.0152,  19.8650,  20.8270, -23.0391,  24.5467, -20.0221],\n",
      "        [ 24.5512,  19.4512,  20.5280, -22.9357,  24.4525, -20.0621],\n",
      "        [ 24.6689,  19.9278,  20.2176, -22.5863,  24.2574, -19.8079]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.802219867706299\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5972, 19.8155, 20.6544],\n",
      "        [24.0092, 18.5237, 20.3916],\n",
      "        [24.1051, 19.5033, 20.3104],\n",
      "        [24.5049, 19.2702, 20.3757],\n",
      "        [24.1835, 19.0959, 19.8048],\n",
      "        [24.4044, 19.9032, 20.3251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9320,  24.5588, -19.9207],\n",
      "        [-23.2612,  24.3605, -20.3266],\n",
      "        [-22.9512,  24.0493, -19.4359],\n",
      "        [-22.7863,  23.9091, -19.8629],\n",
      "        [-22.6770,  23.8842, -19.6190],\n",
      "        [-22.9080,  24.3378, -19.6330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5972,  19.8155,  20.6544, -22.9320,  24.5588, -19.9207],\n",
      "        [ 24.0092,  18.5237,  20.3916, -23.2612,  24.3605, -20.3266],\n",
      "        [ 24.1051,  19.5033,  20.3104, -22.9512,  24.0493, -19.4359],\n",
      "        [ 24.5049,  19.2702,  20.3757, -22.7863,  23.9091, -19.8629],\n",
      "        [ 24.1835,  19.0959,  19.8048, -22.6770,  23.8842, -19.6190],\n",
      "        [ 24.4044,  19.9032,  20.3251, -22.9080,  24.3378, -19.6330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.816617488861084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8669, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0002, 18.6920, 19.9843],\n",
      "        [24.5919, 18.9620, 20.0627],\n",
      "        [23.9105, 19.0049, 19.9587],\n",
      "        [24.4037, 19.4359, 20.2258],\n",
      "        [24.4029, 19.5235, 20.0019],\n",
      "        [24.6510, 19.5768, 20.5166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3517, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7289,  24.4652, -19.7583],\n",
      "        [-23.1853,  24.7893, -20.4412],\n",
      "        [-23.5691,  24.6670, -19.8464],\n",
      "        [-23.0188,  23.9632, -19.7742],\n",
      "        [-23.2726,  24.4640, -19.6560],\n",
      "        [-23.2418,  24.7072, -20.0098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0002,  18.6920,  19.9843, -22.7289,  24.4652, -19.7583],\n",
      "        [ 24.5919,  18.9620,  20.0627, -23.1853,  24.7893, -20.4412],\n",
      "        [ 23.9105,  19.0049,  19.9587, -23.5691,  24.6670, -19.8464],\n",
      "        [ 24.4037,  19.4359,  20.2258, -23.0188,  23.9632, -19.7742],\n",
      "        [ 24.4029,  19.5235,  20.0019, -23.2726,  24.4640, -19.6560],\n",
      "        [ 24.6510,  19.5768,  20.5166, -23.2418,  24.7072, -20.0098]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.709874153137207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3781, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5611, 19.5634, 20.3057],\n",
      "        [23.7730, 18.7663, 19.9921],\n",
      "        [24.9941, 19.6674, 21.3908],\n",
      "        [24.5064, 19.5207, 20.3856],\n",
      "        [24.3000, 19.6401, 20.2543],\n",
      "        [24.0710, 19.3250, 20.3486]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4074, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3757,  24.5670, -20.0715],\n",
      "        [-23.1832,  24.3463, -19.6521],\n",
      "        [-23.0780,  24.4099, -20.1428],\n",
      "        [-23.4969,  24.6564, -20.2423],\n",
      "        [-22.7470,  23.9983, -19.7437],\n",
      "        [-22.6152,  24.1235, -19.8006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5611,  19.5634,  20.3057, -23.3757,  24.5670, -20.0715],\n",
      "        [ 23.7730,  18.7663,  19.9921, -23.1832,  24.3463, -19.6521],\n",
      "        [ 24.9941,  19.6674,  21.3908, -23.0780,  24.4099, -20.1428],\n",
      "        [ 24.5064,  19.5207,  20.3856, -23.4969,  24.6564, -20.2423],\n",
      "        [ 24.3000,  19.6401,  20.2543, -22.7470,  23.9983, -19.7437],\n",
      "        [ 24.0710,  19.3250,  20.3486, -22.6152,  24.1235, -19.8006]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.813429832458496\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3218, 19.4051, 20.4592],\n",
      "        [24.3859, 18.9890, 19.9101],\n",
      "        [24.4513, 19.4779, 20.2914],\n",
      "        [24.3709, 19.2745, 20.0636],\n",
      "        [24.1934, 19.7631, 20.3627],\n",
      "        [24.3327, 19.6245, 20.1588]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.2543, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3794,  24.4755, -19.9701],\n",
      "        [-23.4055,  24.4813, -20.1855],\n",
      "        [-22.8348,  23.4927, -19.4271],\n",
      "        [-22.9083,  24.0841, -19.7466],\n",
      "        [-22.9783,  24.5993, -19.9545],\n",
      "        [-22.7453,  24.1416, -20.0178]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3218,  19.4051,  20.4592, -23.3794,  24.4755, -19.9701],\n",
      "        [ 24.3859,  18.9890,  19.9101, -23.4055,  24.4813, -20.1855],\n",
      "        [ 24.4513,  19.4779,  20.2914, -22.8348,  23.4927, -19.4271],\n",
      "        [ 24.3709,  19.2745,  20.0636, -22.9083,  24.0841, -19.7466],\n",
      "        [ 24.1934,  19.7631,  20.3627, -22.9783,  24.5993, -19.9545],\n",
      "        [ 24.3327,  19.6245,  20.1588, -22.7453,  24.1416, -20.0178]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.798861503601074\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4502, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5480, 19.6011, 20.3424],\n",
      "        [24.3836, 19.3611, 20.0884],\n",
      "        [24.6685, 19.6728, 20.1187],\n",
      "        [23.8845, 18.8935, 19.8311],\n",
      "        [24.7517, 19.4530, 20.7639],\n",
      "        [24.0171, 19.1707, 20.3109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.4633, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1078,  24.4502, -19.9361],\n",
      "        [-22.9769,  24.0513, -19.4521],\n",
      "        [-22.4260,  23.7770, -19.8430],\n",
      "        [-23.5973,  24.5588, -20.0706],\n",
      "        [-22.9725,  24.3878, -20.0806],\n",
      "        [-23.0354,  24.4669, -20.1790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5480,  19.6011,  20.3424, -23.1078,  24.4502, -19.9361],\n",
      "        [ 24.3836,  19.3611,  20.0884, -22.9769,  24.0513, -19.4521],\n",
      "        [ 24.6685,  19.6728,  20.1187, -22.4260,  23.7770, -19.8430],\n",
      "        [ 23.8845,  18.8935,  19.8311, -23.5973,  24.5588, -20.0706],\n",
      "        [ 24.7517,  19.4530,  20.7639, -22.9725,  24.3878, -20.0806],\n",
      "        [ 24.0171,  19.1707,  20.3109, -23.0354,  24.4669, -20.1790]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.80321741104126\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6455, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[23.9677, 19.3931, 19.9912],\n",
      "        [24.3067, 19.1551, 20.1720],\n",
      "        [24.6061, 19.5398, 20.3369],\n",
      "        [24.1177, 19.0000, 20.1093],\n",
      "        [24.5879, 19.5906, 20.4133],\n",
      "        [23.2754, 18.3589, 19.5445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.0838, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5118,  24.5188, -19.8363],\n",
      "        [-23.0591,  24.4474, -20.0688],\n",
      "        [-23.4418,  24.7379, -20.3948],\n",
      "        [-23.0423,  24.2285, -20.1056],\n",
      "        [-23.1891,  23.9664, -19.5132],\n",
      "        [-22.9092,  24.2222, -19.4082]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 23.9677,  19.3931,  19.9912, -23.5118,  24.5188, -19.8363],\n",
      "        [ 24.3067,  19.1551,  20.1720, -23.0591,  24.4474, -20.0688],\n",
      "        [ 24.6061,  19.5398,  20.3369, -23.4418,  24.7379, -20.3948],\n",
      "        [ 24.1177,  19.0000,  20.1093, -23.0423,  24.2285, -20.1056],\n",
      "        [ 24.5879,  19.5906,  20.4133, -23.1891,  23.9664, -19.5132],\n",
      "        [ 23.2754,  18.3589,  19.5445, -22.9092,  24.2222, -19.4082]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.76609468460083\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7858, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9789, 19.5194, 20.7203],\n",
      "        [24.1239, 19.2846, 19.9643],\n",
      "        [24.6543, 19.5266, 20.5099],\n",
      "        [24.4581, 19.4764, 20.0792],\n",
      "        [24.6483, 19.5201, 20.3951],\n",
      "        [24.4742, 19.5400, 20.4843]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.7550, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0183,  24.3183, -20.1905],\n",
      "        [-23.2509,  24.0668, -19.5922],\n",
      "        [-23.2756,  24.4596, -20.1473],\n",
      "        [-22.8935,  23.9004, -19.3533],\n",
      "        [-23.2576,  24.3944, -19.9966],\n",
      "        [-22.8704,  24.2182, -19.8229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9789,  19.5194,  20.7203, -23.0183,  24.3183, -20.1905],\n",
      "        [ 24.1239,  19.2846,  19.9643, -23.2509,  24.0668, -19.5922],\n",
      "        [ 24.6543,  19.5266,  20.5099, -23.2756,  24.4596, -20.1473],\n",
      "        [ 24.4581,  19.4764,  20.0792, -22.8935,  23.9004, -19.3533],\n",
      "        [ 24.6483,  19.5201,  20.3951, -23.2576,  24.3944, -19.9966],\n",
      "        [ 24.4742,  19.5400,  20.4843, -22.8704,  24.2182, -19.8229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.841512680053711\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4289, 19.2044, 20.0348],\n",
      "        [24.3885, 19.7685, 20.3843],\n",
      "        [23.6819, 18.8385, 20.1987],\n",
      "        [24.3800, 19.4781, 20.1373],\n",
      "        [24.6416, 19.9344, 20.6350],\n",
      "        [24.7153, 19.6303, 20.6045]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9125,  23.8390, -19.8245],\n",
      "        [-23.5187,  24.6557, -20.2048],\n",
      "        [-22.6417,  24.0045, -19.6787],\n",
      "        [-23.8280,  25.0399, -20.3162],\n",
      "        [-22.8507,  24.2860, -20.1195],\n",
      "        [-22.8442,  23.8475, -19.4499]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4289,  19.2044,  20.0348, -22.9125,  23.8390, -19.8245],\n",
      "        [ 24.3885,  19.7685,  20.3843, -23.5187,  24.6557, -20.2048],\n",
      "        [ 23.6819,  18.8385,  20.1987, -22.6417,  24.0045, -19.6787],\n",
      "        [ 24.3800,  19.4781,  20.1373, -23.8280,  25.0399, -20.3162],\n",
      "        [ 24.6416,  19.9344,  20.6350, -22.8507,  24.2860, -20.1195],\n",
      "        [ 24.7153,  19.6303,  20.6045, -22.8442,  23.8475, -19.4499]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.7470316886901855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5225, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2521, 19.7378, 20.4553],\n",
      "        [23.9056, 19.0053, 20.1494],\n",
      "        [24.1634, 19.6643, 20.3447],\n",
      "        [24.2838, 19.3444, 20.2810],\n",
      "        [24.8483, 19.8803, 20.8404],\n",
      "        [24.8642, 19.6829, 20.5368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.7599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6292,  24.2739, -19.6989],\n",
      "        [-23.0336,  24.2617, -19.8574],\n",
      "        [-22.7389,  24.0591, -19.7924],\n",
      "        [-22.6238,  24.2751, -19.8753],\n",
      "        [-22.5900,  24.5089, -20.0258],\n",
      "        [-22.6301,  24.2975, -19.7298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2521,  19.7378,  20.4553, -22.6292,  24.2739, -19.6989],\n",
      "        [ 23.9056,  19.0053,  20.1494, -23.0336,  24.2617, -19.8574],\n",
      "        [ 24.1634,  19.6643,  20.3447, -22.7389,  24.0591, -19.7924],\n",
      "        [ 24.2838,  19.3444,  20.2810, -22.6238,  24.2751, -19.8753],\n",
      "        [ 24.8483,  19.8803,  20.8404, -22.5900,  24.5089, -20.0258],\n",
      "        [ 24.8642,  19.6829,  20.5368, -22.6301,  24.2975, -19.7298]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.777137756347656\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2418, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6670, 19.5804, 20.2778],\n",
      "        [24.5852, 19.8980, 20.7094],\n",
      "        [24.4136, 19.5096, 20.4240],\n",
      "        [24.5524, 19.9561, 20.8346],\n",
      "        [24.1805, 19.3551, 20.3299],\n",
      "        [24.5474, 19.3122, 20.1349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6770, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8906,  24.2863, -19.9243],\n",
      "        [-23.2868,  24.3624, -19.9358],\n",
      "        [-22.9484,  23.8343, -19.7889],\n",
      "        [-23.3071,  24.3229, -20.0666],\n",
      "        [-22.9270,  24.5296, -20.2293],\n",
      "        [-22.9770,  24.0389, -19.6308]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6670,  19.5804,  20.2778, -22.8906,  24.2863, -19.9243],\n",
      "        [ 24.5852,  19.8980,  20.7094, -23.2868,  24.3624, -19.9358],\n",
      "        [ 24.4136,  19.5096,  20.4240, -22.9484,  23.8343, -19.7889],\n",
      "        [ 24.5524,  19.9561,  20.8346, -23.3071,  24.3229, -20.0666],\n",
      "        [ 24.1805,  19.3551,  20.3299, -22.9270,  24.5296, -20.2293],\n",
      "        [ 24.5474,  19.3122,  20.1349, -22.9770,  24.0389, -19.6308]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.801941871643066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6167, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2976, 18.9807, 19.6868],\n",
      "        [24.3800, 19.3841, 20.1773],\n",
      "        [24.7253, 20.0621, 20.4612],\n",
      "        [23.9734, 19.2281, 19.9434],\n",
      "        [23.2059, 18.7282, 19.0748],\n",
      "        [25.0440, 19.5103, 21.1411]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7906, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4187,  24.9631, -20.5883],\n",
      "        [-23.5996,  24.8942, -20.5139],\n",
      "        [-22.9378,  24.2067, -20.0266],\n",
      "        [-23.1101,  24.3788, -19.8496],\n",
      "        [-22.7721,  24.1812, -19.8252],\n",
      "        [-23.2861,  24.6712, -20.4405]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2976,  18.9807,  19.6868, -23.4187,  24.9631, -20.5883],\n",
      "        [ 24.3800,  19.3841,  20.1773, -23.5996,  24.8942, -20.5139],\n",
      "        [ 24.7253,  20.0621,  20.4612, -22.9378,  24.2067, -20.0266],\n",
      "        [ 23.9734,  19.2281,  19.9434, -23.1101,  24.3788, -19.8496],\n",
      "        [ 23.2059,  18.7282,  19.0748, -22.7721,  24.1812, -19.8252],\n",
      "        [ 25.0440,  19.5103,  21.1411, -23.2861,  24.6712, -20.4405]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.796739101409912\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3736, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3969, 19.2245, 20.1084],\n",
      "        [24.6950, 19.9649, 20.7129],\n",
      "        [24.6906, 19.6206, 20.4743],\n",
      "        [24.3018, 19.3522, 20.5977],\n",
      "        [24.1658, 19.7009, 20.4580],\n",
      "        [23.8783, 18.9592, 19.7215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4911, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8001,  23.6793, -19.4800],\n",
      "        [-22.7139,  24.1685, -19.8075],\n",
      "        [-22.9593,  24.4155, -19.7800],\n",
      "        [-23.4541,  24.8956, -20.4807],\n",
      "        [-22.9960,  24.5454, -20.1270],\n",
      "        [-23.3324,  24.6455, -19.9174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3969,  19.2245,  20.1084, -22.8001,  23.6793, -19.4800],\n",
      "        [ 24.6950,  19.9649,  20.7129, -22.7139,  24.1685, -19.8075],\n",
      "        [ 24.6906,  19.6206,  20.4743, -22.9593,  24.4155, -19.7800],\n",
      "        [ 24.3018,  19.3522,  20.5977, -23.4541,  24.8956, -20.4807],\n",
      "        [ 24.1658,  19.7009,  20.4580, -22.9960,  24.5454, -20.1270],\n",
      "        [ 23.8783,  18.9592,  19.7215, -23.3324,  24.6455, -19.9174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.738280296325684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8568, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1538, 19.4020, 20.2765],\n",
      "        [24.4332, 19.4857, 20.6163],\n",
      "        [24.5305, 19.2925, 20.6112],\n",
      "        [24.4265, 19.5208, 20.4712],\n",
      "        [24.6475, 19.3212, 20.5741],\n",
      "        [24.2162, 19.5163, 20.5754]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4915, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4657,  25.0275, -20.1717],\n",
      "        [-23.6263,  24.9219, -20.3393],\n",
      "        [-23.1596,  24.6049, -19.8006],\n",
      "        [-22.8338,  24.4636, -19.8551],\n",
      "        [-22.9813,  24.3441, -19.8425],\n",
      "        [-22.4688,  23.8574, -19.6056]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1538,  19.4020,  20.2765, -23.4657,  25.0275, -20.1717],\n",
      "        [ 24.4332,  19.4857,  20.6163, -23.6263,  24.9219, -20.3393],\n",
      "        [ 24.5305,  19.2925,  20.6112, -23.1596,  24.6049, -19.8006],\n",
      "        [ 24.4265,  19.5208,  20.4712, -22.8338,  24.4636, -19.8551],\n",
      "        [ 24.6475,  19.3212,  20.5741, -22.9813,  24.3441, -19.8425],\n",
      "        [ 24.2162,  19.5163,  20.5754, -22.4688,  23.8574, -19.6056]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.824447154998779\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7270, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2089, 19.3355, 19.9033],\n",
      "        [24.9234, 19.5740, 20.5686],\n",
      "        [24.1078, 19.0210, 20.0581],\n",
      "        [24.4980, 19.6327, 20.6329],\n",
      "        [24.0513, 19.1954, 20.1622],\n",
      "        [24.6628, 19.6557, 20.4564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1766, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1029,  24.1033, -19.8920],\n",
      "        [-23.7043,  25.2279, -20.4819],\n",
      "        [-22.8965,  24.0293, -20.2625],\n",
      "        [-23.5041,  24.5711, -20.1629],\n",
      "        [-22.8344,  23.9079, -19.4344],\n",
      "        [-22.9306,  24.0873, -19.5982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2089,  19.3355,  19.9033, -23.1029,  24.1033, -19.8920],\n",
      "        [ 24.9234,  19.5740,  20.5686, -23.7043,  25.2279, -20.4819],\n",
      "        [ 24.1078,  19.0210,  20.0581, -22.8965,  24.0293, -20.2625],\n",
      "        [ 24.4980,  19.6327,  20.6329, -23.5041,  24.5711, -20.1629],\n",
      "        [ 24.0513,  19.1954,  20.1622, -22.8344,  23.9079, -19.4344],\n",
      "        [ 24.6628,  19.6557,  20.4564, -22.9306,  24.0873, -19.5982]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.761230945587158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5578, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7334, 19.7708, 20.5714],\n",
      "        [24.9059, 20.0250, 20.9000],\n",
      "        [24.8862, 19.4091, 20.7295],\n",
      "        [24.9454, 19.8363, 20.6939],\n",
      "        [24.2579, 19.3399, 20.3773],\n",
      "        [25.5047, 20.1198, 21.1786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7606, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1355,  24.4103, -20.1756],\n",
      "        [-23.5130,  24.7521, -19.8913],\n",
      "        [-23.4341,  24.7317, -20.2738],\n",
      "        [-23.3851,  24.8037, -20.2090],\n",
      "        [-23.2226,  24.1588, -19.9328],\n",
      "        [-22.7193,  24.4864, -19.8290]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7334,  19.7708,  20.5714, -23.1355,  24.4103, -20.1756],\n",
      "        [ 24.9059,  20.0250,  20.9000, -23.5130,  24.7521, -19.8913],\n",
      "        [ 24.8862,  19.4091,  20.7295, -23.4341,  24.7317, -20.2738],\n",
      "        [ 24.9454,  19.8363,  20.6939, -23.3851,  24.8037, -20.2090],\n",
      "        [ 24.2579,  19.3399,  20.3773, -23.2226,  24.1588, -19.9328],\n",
      "        [ 25.5047,  20.1198,  21.1786, -22.7193,  24.4864, -19.8290]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.850988388061523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5851, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4801, 19.7941, 20.4897],\n",
      "        [24.7057, 19.3324, 20.4206],\n",
      "        [24.6744, 19.5936, 20.4421],\n",
      "        [23.6889, 19.1151, 19.9424],\n",
      "        [24.4422, 19.4674, 20.3681],\n",
      "        [24.5996, 19.6285, 20.5257]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.8405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9976,  24.1974, -19.6605],\n",
      "        [-23.6077,  24.6652, -20.1009],\n",
      "        [-23.2836,  24.5397, -20.2208],\n",
      "        [-23.2253,  24.2453, -20.2521],\n",
      "        [-22.2658,  23.7421, -19.5796],\n",
      "        [-23.3938,  24.5539, -19.9922]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4801,  19.7941,  20.4897, -22.9976,  24.1974, -19.6605],\n",
      "        [ 24.7057,  19.3324,  20.4206, -23.6077,  24.6652, -20.1009],\n",
      "        [ 24.6744,  19.5936,  20.4421, -23.2836,  24.5397, -20.2208],\n",
      "        [ 23.6889,  19.1151,  19.9424, -23.2253,  24.2453, -20.2521],\n",
      "        [ 24.4422,  19.4674,  20.3681, -22.2658,  23.7421, -19.5796],\n",
      "        [ 24.5996,  19.6285,  20.5257, -23.3938,  24.5539, -19.9922]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.81223201751709\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.0744, 18.6180, 20.1380],\n",
      "        [24.3893, 19.1291, 20.0457],\n",
      "        [24.4233, 19.4996, 20.3375],\n",
      "        [24.7922, 19.8246, 20.8363],\n",
      "        [24.7243, 19.4639, 20.2828],\n",
      "        [24.3313, 19.5101, 20.5578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.4464, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.3767,  23.8500, -19.3860],\n",
      "        [-22.9340,  24.6411, -20.1095],\n",
      "        [-23.1838,  24.0850, -19.8014],\n",
      "        [-23.3253,  24.3724, -20.0175],\n",
      "        [-22.9834,  23.6912, -19.9258],\n",
      "        [-23.4652,  24.7369, -19.8721]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.0744,  18.6180,  20.1380, -22.3767,  23.8500, -19.3860],\n",
      "        [ 24.3893,  19.1291,  20.0457, -22.9340,  24.6411, -20.1095],\n",
      "        [ 24.4233,  19.4996,  20.3375, -23.1838,  24.0850, -19.8014],\n",
      "        [ 24.7922,  19.8246,  20.8363, -23.3253,  24.3724, -20.0175],\n",
      "        [ 24.7243,  19.4639,  20.2828, -22.9834,  23.6912, -19.9258],\n",
      "        [ 24.3313,  19.5101,  20.5578, -23.4652,  24.7369, -19.8721]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.702023506164551\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4540, 19.8135, 20.6024],\n",
      "        [24.4041, 19.5151, 20.6977],\n",
      "        [24.6689, 19.5510, 20.2369],\n",
      "        [24.6992, 19.6507, 20.4628],\n",
      "        [24.4693, 19.5531, 20.1493],\n",
      "        [23.7989, 19.0786, 20.1890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(29.7866, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0892,  24.1157, -19.5806],\n",
      "        [-23.6531,  24.6038, -19.7151],\n",
      "        [-22.9806,  24.2629, -20.0090],\n",
      "        [-22.8598,  23.6187, -19.6866],\n",
      "        [-22.9326,  24.4664, -20.3388],\n",
      "        [-23.4966,  24.9522, -20.2899]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4540,  19.8135,  20.6024, -23.0892,  24.1157, -19.5806],\n",
      "        [ 24.4041,  19.5151,  20.6977, -23.6531,  24.6038, -19.7151],\n",
      "        [ 24.6689,  19.5510,  20.2369, -22.9806,  24.2629, -20.0090],\n",
      "        [ 24.6992,  19.6507,  20.4628, -22.8598,  23.6187, -19.6866],\n",
      "        [ 24.4693,  19.5531,  20.1493, -22.9326,  24.4664, -20.3388],\n",
      "        [ 23.7989,  19.0786,  20.1890, -23.4966,  24.9522, -20.2899]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.817868232727051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2634, 19.1278, 20.4660],\n",
      "        [24.7402, 19.7057, 20.5214],\n",
      "        [24.7491, 19.4815, 20.6029],\n",
      "        [24.1906, 19.1679, 20.1928],\n",
      "        [24.4677, 19.4998, 20.6499],\n",
      "        [24.5168, 19.5581, 20.8348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2627,  24.7462, -20.6102],\n",
      "        [-22.9028,  24.1892, -19.6880],\n",
      "        [-22.9550,  24.5785, -20.1278],\n",
      "        [-23.0562,  24.7033, -19.9025],\n",
      "        [-23.5878,  24.8295, -20.2931],\n",
      "        [-23.2136,  24.5968, -20.3657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2634,  19.1278,  20.4660, -23.2627,  24.7462, -20.6102],\n",
      "        [ 24.7402,  19.7057,  20.5214, -22.9028,  24.1892, -19.6880],\n",
      "        [ 24.7491,  19.4815,  20.6029, -22.9550,  24.5785, -20.1278],\n",
      "        [ 24.1906,  19.1679,  20.1928, -23.0562,  24.7033, -19.9025],\n",
      "        [ 24.4677,  19.4998,  20.6499, -23.5878,  24.8295, -20.2931],\n",
      "        [ 24.5168,  19.5581,  20.8348, -23.2136,  24.5968, -20.3657]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.835186004638672\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5101, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2336, 19.2036, 20.5527],\n",
      "        [24.2480, 19.6165, 20.2302],\n",
      "        [24.3639, 19.5032, 20.2673],\n",
      "        [24.2750, 19.3084, 20.7304],\n",
      "        [24.7120, 20.0453, 20.4492],\n",
      "        [24.6378, 19.9780, 20.4888]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.0259, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3097,  24.3184, -20.0045],\n",
      "        [-23.6948,  24.6847, -20.3301],\n",
      "        [-23.5727,  24.7629, -19.9082],\n",
      "        [-23.0599,  24.4951, -19.9195],\n",
      "        [-23.3050,  24.0155, -19.8661],\n",
      "        [-23.5021,  25.0625, -20.2662]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2336,  19.2036,  20.5527, -23.3097,  24.3184, -20.0045],\n",
      "        [ 24.2480,  19.6165,  20.2302, -23.6948,  24.6847, -20.3301],\n",
      "        [ 24.3639,  19.5032,  20.2673, -23.5727,  24.7629, -19.9082],\n",
      "        [ 24.2750,  19.3084,  20.7304, -23.0599,  24.4951, -19.9195],\n",
      "        [ 24.7120,  20.0453,  20.4492, -23.3050,  24.0155, -19.8661],\n",
      "        [ 24.6378,  19.9780,  20.4888, -23.5021,  25.0625, -20.2662]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.812996864318848\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8657, 19.8485, 20.8723],\n",
      "        [24.6877, 19.7835, 20.5191],\n",
      "        [24.8811, 19.7081, 20.7589],\n",
      "        [24.2963, 19.6697, 20.2889],\n",
      "        [24.4164, 19.5820, 20.4040],\n",
      "        [24.8753, 19.6055, 20.4794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.7578,  24.3060, -19.9824],\n",
      "        [-23.0897,  24.5448, -20.4038],\n",
      "        [-23.2915,  24.9062, -20.0767],\n",
      "        [-23.2933,  24.3002, -19.7466],\n",
      "        [-22.9415,  23.6007, -19.5073],\n",
      "        [-23.3815,  24.3327, -20.5767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8657,  19.8485,  20.8723, -22.7578,  24.3060, -19.9824],\n",
      "        [ 24.6877,  19.7835,  20.5191, -23.0897,  24.5448, -20.4038],\n",
      "        [ 24.8811,  19.7081,  20.7589, -23.2915,  24.9062, -20.0767],\n",
      "        [ 24.2963,  19.6697,  20.2889, -23.2933,  24.3002, -19.7466],\n",
      "        [ 24.4164,  19.5820,  20.4040, -22.9415,  23.6007, -19.5073],\n",
      "        [ 24.8753,  19.6055,  20.4794, -23.3815,  24.3327, -20.5767]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.863165378570557\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6143, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7914, 19.9340, 21.0280],\n",
      "        [24.8427, 19.6897, 20.5264],\n",
      "        [24.8462, 19.6523, 20.4607],\n",
      "        [24.6794, 19.6437, 20.4255],\n",
      "        [24.4375, 19.7212, 20.5732],\n",
      "        [24.4360, 19.8214, 20.5586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5942, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8102,  25.3700, -20.4958],\n",
      "        [-23.5368,  24.6636, -20.2488],\n",
      "        [-23.3530,  24.6587, -20.6327],\n",
      "        [-23.2629,  24.3170, -20.2399],\n",
      "        [-23.0456,  24.4805, -20.1191],\n",
      "        [-22.5316,  23.9277, -19.5152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7914,  19.9340,  21.0280, -23.8102,  25.3700, -20.4958],\n",
      "        [ 24.8427,  19.6897,  20.5264, -23.5368,  24.6636, -20.2488],\n",
      "        [ 24.8462,  19.6523,  20.4607, -23.3530,  24.6587, -20.6327],\n",
      "        [ 24.6794,  19.6437,  20.4255, -23.2629,  24.3170, -20.2399],\n",
      "        [ 24.4375,  19.7212,  20.5732, -23.0456,  24.4805, -20.1191],\n",
      "        [ 24.4360,  19.8214,  20.5586, -22.5316,  23.9277, -19.5152]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.952935695648193\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2315, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7762, 19.5536, 20.4894],\n",
      "        [24.1418, 19.2595, 20.1808],\n",
      "        [24.5206, 19.2554, 20.4110],\n",
      "        [24.7889, 19.8969, 20.7625],\n",
      "        [24.9598, 19.8771, 20.5249],\n",
      "        [24.7799, 19.6575, 20.5124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.9853, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1968,  24.4389, -20.3047],\n",
      "        [-23.2781,  24.6035, -20.2585],\n",
      "        [-23.2347,  24.3908, -20.1334],\n",
      "        [-23.2764,  24.5648, -19.9110],\n",
      "        [-23.4537,  24.7831, -20.1848],\n",
      "        [-23.6536,  24.9188, -19.9814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7762,  19.5536,  20.4894, -23.1968,  24.4389, -20.3047],\n",
      "        [ 24.1418,  19.2595,  20.1808, -23.2781,  24.6035, -20.2585],\n",
      "        [ 24.5206,  19.2554,  20.4110, -23.2347,  24.3908, -20.1334],\n",
      "        [ 24.7889,  19.8969,  20.7625, -23.2764,  24.5648, -19.9110],\n",
      "        [ 24.9598,  19.8771,  20.5249, -23.4537,  24.7831, -20.1848],\n",
      "        [ 24.7799,  19.6575,  20.5124, -23.6536,  24.9188, -19.9814]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.862860202789307\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4590, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6774, 19.4374, 20.4265],\n",
      "        [24.5137, 19.9140, 20.7503],\n",
      "        [24.7688, 19.8731, 20.7568],\n",
      "        [24.3880, 19.2706, 20.0694],\n",
      "        [24.7927, 19.7002, 20.6435],\n",
      "        [24.3339, 19.4569, 20.2397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3098, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0938,  24.6577, -20.1413],\n",
      "        [-23.3728,  24.5170, -19.8983],\n",
      "        [-23.0608,  24.3567, -19.8077],\n",
      "        [-22.7566,  24.2683, -19.8662],\n",
      "        [-23.3214,  24.7134, -20.4361],\n",
      "        [-22.6231,  23.9489, -19.4114]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6774,  19.4374,  20.4265, -23.0938,  24.6577, -20.1413],\n",
      "        [ 24.5137,  19.9140,  20.7503, -23.3728,  24.5170, -19.8983],\n",
      "        [ 24.7688,  19.8731,  20.7568, -23.0608,  24.3567, -19.8077],\n",
      "        [ 24.3880,  19.2706,  20.0694, -22.7566,  24.2683, -19.8662],\n",
      "        [ 24.7927,  19.7002,  20.6435, -23.3214,  24.7134, -20.4361],\n",
      "        [ 24.3339,  19.4569,  20.2397, -22.6231,  23.9489, -19.4114]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.85301399230957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.0800, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2913, 19.5274, 20.0757],\n",
      "        [24.8915, 19.7558, 20.4558],\n",
      "        [24.4185, 19.2457, 20.2831],\n",
      "        [24.8283, 19.7104, 20.6178],\n",
      "        [23.9660, 19.3506, 20.3020],\n",
      "        [24.8078, 19.5457, 20.2482]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1015,  24.2420, -19.9309],\n",
      "        [-23.4138,  24.4705, -20.3760],\n",
      "        [-22.6760,  24.1707, -19.6045],\n",
      "        [-23.5119,  24.8410, -20.2114],\n",
      "        [-22.8866,  24.1880, -19.9379],\n",
      "        [-23.0271,  24.2950, -19.7993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2913,  19.5274,  20.0757, -23.1015,  24.2420, -19.9309],\n",
      "        [ 24.8915,  19.7558,  20.4558, -23.4138,  24.4705, -20.3760],\n",
      "        [ 24.4185,  19.2457,  20.2831, -22.6760,  24.1707, -19.6045],\n",
      "        [ 24.8283,  19.7104,  20.6178, -23.5119,  24.8410, -20.2114],\n",
      "        [ 23.9660,  19.3506,  20.3020, -22.8866,  24.1880, -19.9379],\n",
      "        [ 24.8078,  19.5457,  20.2482, -23.0271,  24.2950, -19.7993]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.803524971008301\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6875, 19.4754, 20.3277],\n",
      "        [25.2860, 20.0108, 21.2262],\n",
      "        [24.8784, 19.4249, 20.6367],\n",
      "        [24.4139, 19.6785, 20.1676],\n",
      "        [24.7587, 19.8734, 20.1425],\n",
      "        [24.1713, 19.0885, 19.9447]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.3270, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4071,  24.7592, -20.0881],\n",
      "        [-23.4625,  24.7281, -20.4296],\n",
      "        [-23.2220,  24.3971, -19.7702],\n",
      "        [-22.8914,  23.8848, -19.2562],\n",
      "        [-23.3169,  24.7115, -20.1640],\n",
      "        [-23.4961,  24.7329, -20.1839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6875,  19.4754,  20.3277, -23.4071,  24.7592, -20.0881],\n",
      "        [ 25.2860,  20.0108,  21.2262, -23.4625,  24.7281, -20.4296],\n",
      "        [ 24.8784,  19.4249,  20.6367, -23.2220,  24.3971, -19.7702],\n",
      "        [ 24.4139,  19.6785,  20.1676, -22.8914,  23.8848, -19.2562],\n",
      "        [ 24.7587,  19.8734,  20.1425, -23.3169,  24.7115, -20.1640],\n",
      "        [ 24.1713,  19.0885,  19.9447, -23.4961,  24.7329, -20.1839]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.865992546081543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1927, 19.3334, 20.2810],\n",
      "        [24.7371, 19.7256, 20.7361],\n",
      "        [24.8953, 19.8764, 20.3557],\n",
      "        [24.1685, 19.3811, 20.1365],\n",
      "        [24.4972, 19.5464, 20.3000],\n",
      "        [24.6311, 19.7366, 20.3833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9387,  24.2831, -20.0122],\n",
      "        [-23.6192,  24.5952, -20.1685],\n",
      "        [-22.9163,  24.0261, -19.6168],\n",
      "        [-23.8414,  24.9216, -20.2901],\n",
      "        [-23.1197,  24.4565, -19.9796],\n",
      "        [-23.4254,  24.5559, -20.3422]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1927,  19.3334,  20.2810, -22.9387,  24.2831, -20.0122],\n",
      "        [ 24.7371,  19.7256,  20.7361, -23.6192,  24.5952, -20.1685],\n",
      "        [ 24.8953,  19.8764,  20.3557, -22.9163,  24.0261, -19.6168],\n",
      "        [ 24.1685,  19.3811,  20.1365, -23.8414,  24.9216, -20.2901],\n",
      "        [ 24.4972,  19.5464,  20.3000, -23.1197,  24.4565, -19.9796],\n",
      "        [ 24.6311,  19.7366,  20.3833, -23.4254,  24.5559, -20.3422]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.802781105041504\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5291, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1770, 20.2532, 20.8370],\n",
      "        [24.0806, 19.5390, 20.2107],\n",
      "        [24.5959, 19.4290, 20.5859],\n",
      "        [24.7950, 19.7988, 20.6632],\n",
      "        [24.4617, 19.3445, 19.9271],\n",
      "        [25.0183, 19.4430, 20.9068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.8856, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8426,  23.9613, -19.8647],\n",
      "        [-23.2742,  24.3162, -19.8666],\n",
      "        [-23.2083,  24.5945, -20.2834],\n",
      "        [-23.2030,  24.4838, -20.0014],\n",
      "        [-22.9032,  24.2295, -19.7637],\n",
      "        [-23.2785,  23.9964, -19.8969]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1770,  20.2532,  20.8370, -22.8426,  23.9613, -19.8647],\n",
      "        [ 24.0806,  19.5390,  20.2107, -23.2742,  24.3162, -19.8666],\n",
      "        [ 24.5959,  19.4290,  20.5859, -23.2083,  24.5945, -20.2834],\n",
      "        [ 24.7950,  19.7988,  20.6632, -23.2030,  24.4838, -20.0014],\n",
      "        [ 24.4617,  19.3445,  19.9271, -22.9032,  24.2295, -19.7637],\n",
      "        [ 25.0183,  19.4430,  20.9068, -23.2785,  23.9964, -19.8969]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.890902996063232\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8554, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4765, 19.5135, 20.4742],\n",
      "        [24.7707, 19.9073, 20.7611],\n",
      "        [24.5292, 19.9743, 20.5841],\n",
      "        [23.9704, 19.0544, 20.2623],\n",
      "        [25.0499, 19.9704, 20.7390],\n",
      "        [24.0634, 19.9316, 20.3020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9353, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2798,  24.4280, -19.8769],\n",
      "        [-22.6142,  24.0973, -19.8632],\n",
      "        [-23.0267,  24.2530, -19.7910],\n",
      "        [-23.7088,  25.1920, -20.7035],\n",
      "        [-23.0815,  24.7690, -20.3273],\n",
      "        [-23.5103,  24.8219, -19.8611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4765,  19.5135,  20.4742, -23.2798,  24.4280, -19.8769],\n",
      "        [ 24.7707,  19.9073,  20.7611, -22.6142,  24.0973, -19.8632],\n",
      "        [ 24.5292,  19.9743,  20.5841, -23.0267,  24.2530, -19.7910],\n",
      "        [ 23.9704,  19.0544,  20.2623, -23.7088,  25.1920, -20.7035],\n",
      "        [ 25.0499,  19.9704,  20.7390, -23.0815,  24.7690, -20.3273],\n",
      "        [ 24.0634,  19.9316,  20.3020, -23.5103,  24.8219, -19.8611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.847146987915039\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7277, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6467, 19.3810, 20.8360],\n",
      "        [24.9174, 19.6396, 20.3686],\n",
      "        [24.7698, 19.7783, 20.6365],\n",
      "        [24.2627, 18.8732, 20.2913],\n",
      "        [24.5871, 19.6403, 21.0584],\n",
      "        [25.1650, 19.6605, 20.8628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3692, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6864,  24.8908, -20.2769],\n",
      "        [-23.7143,  24.9209, -20.5143],\n",
      "        [-22.9352,  23.9391, -19.4278],\n",
      "        [-23.2056,  24.3907, -19.9855],\n",
      "        [-23.4699,  24.2361, -20.2309],\n",
      "        [-23.1520,  24.4737, -19.6551]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6467,  19.3810,  20.8360, -23.6864,  24.8908, -20.2769],\n",
      "        [ 24.9174,  19.6396,  20.3686, -23.7143,  24.9209, -20.5143],\n",
      "        [ 24.7698,  19.7783,  20.6365, -22.9352,  23.9391, -19.4278],\n",
      "        [ 24.2627,  18.8732,  20.2913, -23.2056,  24.3907, -19.9855],\n",
      "        [ 24.5871,  19.6403,  21.0584, -23.4699,  24.2361, -20.2309],\n",
      "        [ 25.1650,  19.6605,  20.8628, -23.1520,  24.4737, -19.6551]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.907818794250488\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7437, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4733, 19.4544, 20.1082],\n",
      "        [25.1925, 20.3985, 21.1284],\n",
      "        [24.8797, 19.9846, 21.0472],\n",
      "        [24.8711, 19.5743, 20.6692],\n",
      "        [23.8809, 19.5652, 20.1076],\n",
      "        [25.3999, 20.1339, 21.0420]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.4253, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5389,  25.0570, -20.5681],\n",
      "        [-23.3100,  24.7170, -20.0601],\n",
      "        [-23.0171,  24.8375, -19.9901],\n",
      "        [-23.3052,  24.4753, -20.2795],\n",
      "        [-23.5120,  24.7393, -20.3851],\n",
      "        [-23.3090,  24.2145, -19.4391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4733,  19.4544,  20.1082, -23.5389,  25.0570, -20.5681],\n",
      "        [ 25.1925,  20.3985,  21.1284, -23.3100,  24.7170, -20.0601],\n",
      "        [ 24.8797,  19.9846,  21.0472, -23.0171,  24.8375, -19.9901],\n",
      "        [ 24.8711,  19.5743,  20.6692, -23.3052,  24.4753, -20.2795],\n",
      "        [ 23.8809,  19.5652,  20.1076, -23.5120,  24.7393, -20.3851],\n",
      "        [ 25.3999,  20.1339,  21.0420, -23.3090,  24.2145, -19.4391]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.880273818969727\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9310, 19.9840, 20.7232],\n",
      "        [24.9675, 20.1735, 20.9843],\n",
      "        [24.2442, 19.9575, 20.3101],\n",
      "        [24.2362, 18.9394, 19.8067],\n",
      "        [24.8810, 19.7585, 20.5009],\n",
      "        [24.7452, 19.8056, 20.0881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.1999, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5550,  24.7876, -20.3030],\n",
      "        [-22.9739,  24.4414, -20.1411],\n",
      "        [-23.0241,  24.4855, -19.9212],\n",
      "        [-23.0439,  23.9617, -19.7358],\n",
      "        [-23.4042,  24.3063, -19.9847],\n",
      "        [-22.7915,  23.9732, -20.1375]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9310,  19.9840,  20.7232, -23.5550,  24.7876, -20.3030],\n",
      "        [ 24.9675,  20.1735,  20.9843, -22.9739,  24.4414, -20.1411],\n",
      "        [ 24.2442,  19.9575,  20.3101, -23.0241,  24.4855, -19.9212],\n",
      "        [ 24.2362,  18.9394,  19.8067, -23.0439,  23.9617, -19.7358],\n",
      "        [ 24.8810,  19.7585,  20.5009, -23.4042,  24.3063, -19.9847],\n",
      "        [ 24.7452,  19.8056,  20.0881, -22.7915,  23.9732, -20.1375]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.933612823486328\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6855, 19.8912, 20.2591],\n",
      "        [24.2755, 19.5673, 20.8761],\n",
      "        [24.3128, 19.3540, 20.2794],\n",
      "        [24.3863, 19.2833, 20.1013],\n",
      "        [25.0250, 19.6024, 20.6451],\n",
      "        [24.6171, 19.7826, 21.0765]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.1849, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5044,  24.6151, -20.4028],\n",
      "        [-23.5104,  24.2950, -20.0905],\n",
      "        [-23.4361,  24.5486, -20.2791],\n",
      "        [-23.6387,  24.9175, -20.4583],\n",
      "        [-23.2358,  24.3437, -19.6249],\n",
      "        [-23.5994,  24.9687, -20.6485]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6855,  19.8912,  20.2591, -23.5044,  24.6151, -20.4028],\n",
      "        [ 24.2755,  19.5673,  20.8761, -23.5104,  24.2950, -20.0905],\n",
      "        [ 24.3128,  19.3540,  20.2794, -23.4361,  24.5486, -20.2791],\n",
      "        [ 24.3863,  19.2833,  20.1013, -23.6387,  24.9175, -20.4583],\n",
      "        [ 25.0250,  19.6024,  20.6451, -23.2358,  24.3437, -19.6249],\n",
      "        [ 24.6171,  19.7826,  21.0765, -23.5994,  24.9687, -20.6485]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.894930839538574\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3226, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0648, 20.0666, 20.8807],\n",
      "        [24.7405, 19.5116, 20.6787],\n",
      "        [24.4982, 19.6715, 20.5656],\n",
      "        [24.9522, 19.5637, 20.8075],\n",
      "        [24.6315, 19.8911, 20.7696],\n",
      "        [25.2414, 19.8729, 20.6374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.0594, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8363,  24.7147, -19.9280],\n",
      "        [-23.2113,  24.9636, -20.3125],\n",
      "        [-23.1586,  24.3883, -19.8667],\n",
      "        [-23.5803,  25.0285, -20.3717],\n",
      "        [-22.8940,  24.2859, -19.8223],\n",
      "        [-23.7171,  24.7334, -20.7516]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0648,  20.0666,  20.8807, -23.8363,  24.7147, -19.9280],\n",
      "        [ 24.7405,  19.5116,  20.6787, -23.2113,  24.9636, -20.3125],\n",
      "        [ 24.4982,  19.6715,  20.5656, -23.1586,  24.3883, -19.8667],\n",
      "        [ 24.9522,  19.5637,  20.8075, -23.5803,  25.0285, -20.3717],\n",
      "        [ 24.6315,  19.8911,  20.7696, -22.8940,  24.2859, -19.8223],\n",
      "        [ 25.2414,  19.8729,  20.6374, -23.7171,  24.7334, -20.7516]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.950222492218018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6348, 19.7656, 20.6605],\n",
      "        [24.9598, 20.0921, 20.9925],\n",
      "        [24.0413, 19.7183, 20.6060],\n",
      "        [24.1594, 19.0086, 20.1143],\n",
      "        [24.5042, 19.6755, 20.6983],\n",
      "        [24.7035, 19.6726, 20.2522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3030,  24.6416, -20.3637],\n",
      "        [-23.5087,  24.9079, -20.2794],\n",
      "        [-23.9671,  25.0207, -20.8482],\n",
      "        [-23.3153,  25.0207, -20.0381],\n",
      "        [-23.7971,  24.7661, -20.4220],\n",
      "        [-23.1218,  24.4564, -19.7437]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6348,  19.7656,  20.6605, -23.3030,  24.6416, -20.3637],\n",
      "        [ 24.9598,  20.0921,  20.9925, -23.5087,  24.9079, -20.2794],\n",
      "        [ 24.0413,  19.7183,  20.6060, -23.9671,  25.0207, -20.8482],\n",
      "        [ 24.1594,  19.0086,  20.1143, -23.3153,  25.0207, -20.0381],\n",
      "        [ 24.5042,  19.6755,  20.6983, -23.7971,  24.7661, -20.4220],\n",
      "        [ 24.7035,  19.6726,  20.2522, -23.1218,  24.4564, -19.7437]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.902487754821777\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4183, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9979, 19.6412, 20.7245],\n",
      "        [24.3512, 19.1415, 19.9482],\n",
      "        [24.6470, 19.7576, 20.6102],\n",
      "        [24.5972, 19.6479, 20.9811],\n",
      "        [24.4391, 19.6994, 21.0229],\n",
      "        [24.5857, 19.3749, 20.2983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.5549, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3129,  25.1012, -20.4456],\n",
      "        [-23.1259,  24.5030, -19.9028],\n",
      "        [-23.4318,  24.7695, -20.2622],\n",
      "        [-23.7029,  24.9189, -20.5468],\n",
      "        [-23.4731,  24.8952, -20.3171],\n",
      "        [-23.3809,  24.3395, -20.3710]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9979,  19.6412,  20.7245, -23.3129,  25.1012, -20.4456],\n",
      "        [ 24.3512,  19.1415,  19.9482, -23.1259,  24.5030, -19.9028],\n",
      "        [ 24.6470,  19.7576,  20.6102, -23.4318,  24.7695, -20.2622],\n",
      "        [ 24.5972,  19.6479,  20.9811, -23.7029,  24.9189, -20.5468],\n",
      "        [ 24.4391,  19.6994,  21.0229, -23.4731,  24.8952, -20.3171],\n",
      "        [ 24.5857,  19.3749,  20.2983, -23.3809,  24.3395, -20.3710]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.9397501945495605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5348, 19.6497, 20.5277],\n",
      "        [25.5219, 20.4911, 21.4975],\n",
      "        [24.7108, 19.7269, 20.5270],\n",
      "        [24.5278, 19.8630, 20.8997],\n",
      "        [25.1793, 19.6942, 20.7328],\n",
      "        [24.9378, 20.1728, 20.8593]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.3532, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1230,  24.1876, -20.1511],\n",
      "        [-23.4110,  25.0741, -20.4693],\n",
      "        [-23.7773,  25.3960, -20.6634],\n",
      "        [-22.6118,  24.0929, -20.0277],\n",
      "        [-23.8265,  24.7007, -20.0287],\n",
      "        [-23.4055,  24.6278, -20.2929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5348,  19.6497,  20.5277, -23.1230,  24.1876, -20.1511],\n",
      "        [ 25.5219,  20.4911,  21.4975, -23.4110,  25.0741, -20.4693],\n",
      "        [ 24.7108,  19.7269,  20.5270, -23.7773,  25.3960, -20.6634],\n",
      "        [ 24.5278,  19.8630,  20.8997, -22.6118,  24.0929, -20.0277],\n",
      "        [ 25.1793,  19.6942,  20.7328, -23.8265,  24.7007, -20.0287],\n",
      "        [ 24.9378,  20.1728,  20.8593, -23.4055,  24.6278, -20.2929]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.8647141456604\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5911, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2585, 19.7872, 20.5853],\n",
      "        [24.3640, 19.6445, 20.3641],\n",
      "        [24.4683, 19.5481, 20.1948],\n",
      "        [24.5148, 19.1960, 20.1021],\n",
      "        [24.6275, 19.6753, 20.9536],\n",
      "        [24.5745, 19.6434, 20.4091]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.1427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.0856,  24.6174, -20.1421],\n",
      "        [-23.7113,  25.3564, -20.8347],\n",
      "        [-23.3107,  24.8385, -20.3502],\n",
      "        [-23.5152,  24.4221, -19.9507],\n",
      "        [-23.7414,  24.7279, -20.7031],\n",
      "        [-23.2013,  24.3284, -20.0624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2585,  19.7872,  20.5853, -23.0856,  24.6174, -20.1421],\n",
      "        [ 24.3640,  19.6445,  20.3641, -23.7113,  25.3564, -20.8347],\n",
      "        [ 24.4683,  19.5481,  20.1948, -23.3107,  24.8385, -20.3502],\n",
      "        [ 24.5148,  19.1960,  20.1021, -23.5152,  24.4221, -19.9507],\n",
      "        [ 24.6275,  19.6753,  20.9536, -23.7414,  24.7279, -20.7031],\n",
      "        [ 24.5745,  19.6434,  20.4091, -23.2013,  24.3284, -20.0624]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.872290134429932\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5550, 19.5006, 20.6553],\n",
      "        [24.8256, 19.6830, 20.1937],\n",
      "        [24.8263, 19.9302, 20.6994],\n",
      "        [24.6524, 19.5256, 20.5987],\n",
      "        [25.3419, 20.3235, 21.0665],\n",
      "        [24.7667, 19.3333, 20.7849]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5637, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6899,  25.0089, -20.4595],\n",
      "        [-23.3256,  24.6693, -20.0858],\n",
      "        [-23.4154,  25.2361, -20.3266],\n",
      "        [-23.2386,  24.5985, -20.1335],\n",
      "        [-22.9019,  24.4061, -19.9358],\n",
      "        [-23.4284,  24.5956, -20.7790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5550,  19.5006,  20.6553, -23.6899,  25.0089, -20.4595],\n",
      "        [ 24.8256,  19.6830,  20.1937, -23.3256,  24.6693, -20.0858],\n",
      "        [ 24.8263,  19.9302,  20.6994, -23.4154,  25.2361, -20.3266],\n",
      "        [ 24.6524,  19.5256,  20.5987, -23.2386,  24.5985, -20.1335],\n",
      "        [ 25.3419,  20.3235,  21.0665, -22.9019,  24.4061, -19.9358],\n",
      "        [ 24.7667,  19.3333,  20.7849, -23.4284,  24.5956, -20.7790]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.923885822296143\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7019, 19.9671, 20.7540],\n",
      "        [25.2266, 20.1298, 21.1788],\n",
      "        [24.6574, 19.4385, 20.4921],\n",
      "        [24.7074, 19.8385, 20.8841],\n",
      "        [24.6706, 19.6642, 20.6707],\n",
      "        [24.7799, 19.8734, 20.4203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.8807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.9633,  24.4487, -20.3010],\n",
      "        [-22.9620,  24.6674, -19.8740],\n",
      "        [-23.1022,  24.7128, -20.0033],\n",
      "        [-23.3968,  24.5782, -19.9587],\n",
      "        [-23.4341,  24.9674, -20.3916],\n",
      "        [-23.2211,  24.2328, -19.8547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7019,  19.9671,  20.7540, -22.9633,  24.4487, -20.3010],\n",
      "        [ 25.2266,  20.1298,  21.1788, -22.9620,  24.6674, -19.8740],\n",
      "        [ 24.6574,  19.4385,  20.4921, -23.1022,  24.7128, -20.0033],\n",
      "        [ 24.7074,  19.8385,  20.8841, -23.3968,  24.5782, -19.9587],\n",
      "        [ 24.6706,  19.6642,  20.6707, -23.4341,  24.9674, -20.3916],\n",
      "        [ 24.7799,  19.8734,  20.4203, -23.2211,  24.2328, -19.8547]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.90626335144043\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0158, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3511, 19.3755, 20.4532],\n",
      "        [24.8623, 19.9780, 20.3237],\n",
      "        [25.1464, 19.9986, 21.1936],\n",
      "        [25.0489, 19.9053, 20.7129],\n",
      "        [25.4842, 20.2525, 21.2942],\n",
      "        [24.8543, 20.0893, 21.2160]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(30.0824, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3310,  24.0656, -19.7306],\n",
      "        [-23.0694,  24.2445, -20.1407],\n",
      "        [-23.5231,  24.8220, -20.3117],\n",
      "        [-23.5001,  24.3067, -19.9437],\n",
      "        [-23.1813,  24.4180, -20.2375],\n",
      "        [-23.1967,  25.1363, -20.3114]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3511,  19.3755,  20.4532, -23.3310,  24.0656, -19.7306],\n",
      "        [ 24.8623,  19.9780,  20.3237, -23.0694,  24.2445, -20.1407],\n",
      "        [ 25.1464,  19.9986,  21.1936, -23.5231,  24.8220, -20.3117],\n",
      "        [ 25.0489,  19.9053,  20.7129, -23.5001,  24.3067, -19.9437],\n",
      "        [ 25.4842,  20.2525,  21.2942, -23.1813,  24.4180, -20.2375],\n",
      "        [ 24.8543,  20.0893,  21.2160, -23.1967,  25.1363, -20.3114]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.84162712097168\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6942, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9703, 19.6467, 20.7736],\n",
      "        [25.1824, 20.3793, 21.1642],\n",
      "        [24.8174, 19.8512, 20.6560],\n",
      "        [25.0670, 19.9449, 20.6192],\n",
      "        [24.4679, 20.1447, 20.7847],\n",
      "        [24.8222, 19.7204, 20.8115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.8356, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2991,  24.8400, -20.5700],\n",
      "        [-23.5506,  24.7780, -20.4556],\n",
      "        [-23.8515,  25.0376, -20.4634],\n",
      "        [-23.6237,  24.9759, -20.6243],\n",
      "        [-23.8902,  25.0751, -20.5690],\n",
      "        [-23.2423,  24.5666, -20.4199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9703,  19.6467,  20.7736, -23.2991,  24.8400, -20.5700],\n",
      "        [ 25.1824,  20.3793,  21.1642, -23.5506,  24.7780, -20.4556],\n",
      "        [ 24.8174,  19.8512,  20.6560, -23.8515,  25.0376, -20.4634],\n",
      "        [ 25.0670,  19.9449,  20.6192, -23.6237,  24.9759, -20.6243],\n",
      "        [ 24.4679,  20.1447,  20.7847, -23.8902,  25.0751, -20.5690],\n",
      "        [ 24.8222,  19.7204,  20.8115, -23.2423,  24.5666, -20.4199]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.945114612579346\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1909, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5418, 19.8123, 20.8799],\n",
      "        [24.8456, 19.5211, 20.7695],\n",
      "        [25.2044, 19.7749, 20.5925],\n",
      "        [24.5886, 20.1645, 20.9953],\n",
      "        [24.1640, 19.4518, 20.1348],\n",
      "        [25.1009, 20.0585, 21.0960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.5063, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5975,  25.2457, -20.5224],\n",
      "        [-23.3739,  24.4928, -20.2241],\n",
      "        [-23.0768,  24.5507, -19.5308],\n",
      "        [-23.2153,  24.8129, -20.5657],\n",
      "        [-23.2276,  24.5709, -20.1017],\n",
      "        [-23.5667,  24.8495, -20.5349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5418,  19.8123,  20.8799, -23.5975,  25.2457, -20.5224],\n",
      "        [ 24.8456,  19.5211,  20.7695, -23.3739,  24.4928, -20.2241],\n",
      "        [ 25.2044,  19.7749,  20.5925, -23.0768,  24.5507, -19.5308],\n",
      "        [ 24.5886,  20.1645,  20.9953, -23.2153,  24.8129, -20.5657],\n",
      "        [ 24.1640,  19.4518,  20.1348, -23.2276,  24.5709, -20.1017],\n",
      "        [ 25.1009,  20.0585,  21.0960, -23.5667,  24.8495, -20.5349]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.956770896911621\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0808, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3197, 19.8874, 20.8843],\n",
      "        [24.5096, 19.7876, 20.5784],\n",
      "        [25.3535, 20.0095, 20.7929],\n",
      "        [24.9887, 20.2291, 20.9748],\n",
      "        [24.3638, 19.7080, 20.4947],\n",
      "        [24.5319, 19.4815, 20.4050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3778,  24.8782, -20.3323],\n",
      "        [-23.4204,  24.8679, -20.4249],\n",
      "        [-23.6156,  24.9854, -20.3230],\n",
      "        [-23.0362,  23.9766, -20.1395],\n",
      "        [-23.3334,  24.5172, -20.5374],\n",
      "        [-23.6138,  24.9891, -20.0259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3197,  19.8874,  20.8843, -23.3778,  24.8782, -20.3323],\n",
      "        [ 24.5096,  19.7876,  20.5784, -23.4204,  24.8679, -20.4249],\n",
      "        [ 25.3535,  20.0095,  20.7929, -23.6156,  24.9854, -20.3230],\n",
      "        [ 24.9887,  20.2291,  20.9748, -23.0362,  23.9766, -20.1395],\n",
      "        [ 24.3638,  19.7080,  20.4947, -23.3334,  24.5172, -20.5374],\n",
      "        [ 24.5319,  19.4815,  20.4050, -23.6138,  24.9891, -20.0259]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.976897716522217\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6964, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5074, 19.0552, 20.4829],\n",
      "        [24.7652, 19.7978, 20.5329],\n",
      "        [24.6394, 20.0195, 20.6171],\n",
      "        [24.7392, 19.5770, 20.5945],\n",
      "        [25.0156, 19.5096, 20.8305],\n",
      "        [24.1345, 19.6066, 20.3638]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.5789, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2782,  24.3843, -20.0039],\n",
      "        [-23.8053,  24.7940, -20.3970],\n",
      "        [-23.6522,  24.6732, -20.2140],\n",
      "        [-23.1434,  24.5924, -20.2683],\n",
      "        [-23.4987,  25.0707, -20.8273],\n",
      "        [-23.1989,  24.8144, -19.7855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5074,  19.0552,  20.4829, -23.2782,  24.3843, -20.0039],\n",
      "        [ 24.7652,  19.7978,  20.5329, -23.8053,  24.7940, -20.3970],\n",
      "        [ 24.6394,  20.0195,  20.6171, -23.6522,  24.6732, -20.2140],\n",
      "        [ 24.7392,  19.5770,  20.5945, -23.1434,  24.5924, -20.2683],\n",
      "        [ 25.0156,  19.5096,  20.8305, -23.4987,  25.0707, -20.8273],\n",
      "        [ 24.1345,  19.6066,  20.3638, -23.1989,  24.8144, -19.7855]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.863790035247803\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5570, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1294, 19.3561, 20.0734],\n",
      "        [24.3625, 19.5500, 20.4503],\n",
      "        [24.7000, 19.7073, 20.4021],\n",
      "        [25.0445, 20.1899, 21.3071],\n",
      "        [25.1322, 20.1511, 20.9604],\n",
      "        [24.3363, 19.0498, 19.9107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.8096, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3312,  25.0405, -20.6266],\n",
      "        [-23.5215,  24.6841, -20.3478],\n",
      "        [-23.1659,  24.5817, -20.1087],\n",
      "        [-23.0839,  23.7777, -19.9895],\n",
      "        [-23.8114,  24.9149, -20.3529],\n",
      "        [-23.5970,  25.1012, -20.7049]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1294,  19.3561,  20.0734, -23.3312,  25.0405, -20.6266],\n",
      "        [ 24.3625,  19.5500,  20.4503, -23.5215,  24.6841, -20.3478],\n",
      "        [ 24.7000,  19.7073,  20.4021, -23.1659,  24.5817, -20.1087],\n",
      "        [ 25.0445,  20.1899,  21.3071, -23.0839,  23.7777, -19.9895],\n",
      "        [ 25.1322,  20.1511,  20.9604, -23.8114,  24.9149, -20.3529],\n",
      "        [ 24.3363,  19.0498,  19.9107, -23.5970,  25.1012, -20.7049]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.878400802612305\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1356, 20.0646, 20.9430],\n",
      "        [24.2954, 19.5172, 20.3760],\n",
      "        [25.0090, 20.4864, 20.7260],\n",
      "        [24.4029, 19.8202, 20.8900],\n",
      "        [24.5301, 19.8682, 20.8065],\n",
      "        [25.0449, 19.8485, 20.7984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.1331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5194,  24.4291, -20.0554],\n",
      "        [-23.8952,  25.3718, -20.5515],\n",
      "        [-23.5714,  24.5411, -20.4977],\n",
      "        [-23.5677,  24.7522, -20.1924],\n",
      "        [-23.7664,  25.0228, -20.7239],\n",
      "        [-23.1974,  24.6994, -20.4646]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1356,  20.0646,  20.9430, -23.5194,  24.4291, -20.0554],\n",
      "        [ 24.2954,  19.5172,  20.3760, -23.8952,  25.3718, -20.5515],\n",
      "        [ 25.0090,  20.4864,  20.7260, -23.5714,  24.5411, -20.4977],\n",
      "        [ 24.4029,  19.8202,  20.8900, -23.5677,  24.7522, -20.1924],\n",
      "        [ 24.5301,  19.8682,  20.8065, -23.7664,  25.0228, -20.7239],\n",
      "        [ 25.0449,  19.8485,  20.7984, -23.1974,  24.6994, -20.4646]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.962946891784668\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7835, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6942, 19.6760, 20.2188],\n",
      "        [24.7209, 20.0027, 20.6631],\n",
      "        [24.9051, 19.9142, 21.0185],\n",
      "        [24.7390, 19.8401, 20.6374],\n",
      "        [25.0365, 19.7548, 20.7735],\n",
      "        [25.2696, 20.2785, 20.6988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4159,  24.9272, -20.6993],\n",
      "        [-23.6845,  25.0377, -20.8088],\n",
      "        [-23.3479,  24.4495, -20.2730],\n",
      "        [-23.9824,  24.7886, -20.5851],\n",
      "        [-23.9803,  25.3031, -20.6548],\n",
      "        [-23.4195,  24.4858, -19.9520]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6942,  19.6760,  20.2188, -23.4159,  24.9272, -20.6993],\n",
      "        [ 24.7209,  20.0027,  20.6631, -23.6845,  25.0377, -20.8088],\n",
      "        [ 24.9051,  19.9142,  21.0185, -23.3479,  24.4495, -20.2730],\n",
      "        [ 24.7390,  19.8401,  20.6374, -23.9824,  24.7886, -20.5851],\n",
      "        [ 25.0365,  19.7548,  20.7735, -23.9803,  25.3031, -20.6548],\n",
      "        [ 25.2696,  20.2785,  20.6988, -23.4195,  24.4858, -19.9520]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.928506374359131\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8992, 19.9770, 20.9031],\n",
      "        [24.7394, 19.7399, 20.7048],\n",
      "        [24.4763, 19.8651, 20.8790],\n",
      "        [24.9259, 19.8375, 21.1845],\n",
      "        [24.6722, 20.0518, 20.6714],\n",
      "        [24.8987, 20.1161, 20.9524]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.5981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.6461,  24.1699, -19.9430],\n",
      "        [-24.0850,  25.0649, -20.7578],\n",
      "        [-23.2701,  24.8133, -20.2225],\n",
      "        [-23.6703,  24.4948, -20.1447],\n",
      "        [-23.1046,  24.3940, -20.1659],\n",
      "        [-23.3705,  24.7069, -20.1591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8992,  19.9770,  20.9031, -22.6461,  24.1699, -19.9430],\n",
      "        [ 24.7394,  19.7399,  20.7048, -24.0850,  25.0649, -20.7578],\n",
      "        [ 24.4763,  19.8651,  20.8790, -23.2701,  24.8133, -20.2225],\n",
      "        [ 24.9259,  19.8375,  21.1845, -23.6703,  24.4948, -20.1447],\n",
      "        [ 24.6722,  20.0518,  20.6714, -23.1046,  24.3940, -20.1659],\n",
      "        [ 24.8987,  20.1161,  20.9524, -23.3705,  24.7069, -20.1591]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.909957408905029\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8625, 19.6759, 20.8924],\n",
      "        [24.8621, 19.6740, 20.6782],\n",
      "        [24.3862, 20.1485, 20.5713],\n",
      "        [24.4352, 19.4910, 20.3378],\n",
      "        [24.7416, 19.9303, 21.0865],\n",
      "        [24.4858, 19.5121, 20.5250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.9539, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8792,  24.9936, -20.4638],\n",
      "        [-23.2507,  24.5951, -20.3089],\n",
      "        [-24.2727,  25.0909, -20.3023],\n",
      "        [-23.6453,  24.5680, -20.1322],\n",
      "        [-23.4487,  24.9678, -20.5467],\n",
      "        [-23.0498,  24.5895, -20.2675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8625,  19.6759,  20.8924, -23.8792,  24.9936, -20.4638],\n",
      "        [ 24.8621,  19.6740,  20.6782, -23.2507,  24.5951, -20.3089],\n",
      "        [ 24.3862,  20.1485,  20.5713, -24.2727,  25.0909, -20.3023],\n",
      "        [ 24.4352,  19.4910,  20.3378, -23.6453,  24.5680, -20.1322],\n",
      "        [ 24.7416,  19.9303,  21.0865, -23.4487,  24.9678, -20.5467],\n",
      "        [ 24.4858,  19.5121,  20.5250, -23.0498,  24.5895, -20.2675]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.98072624206543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5318, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8489, 20.0639, 20.7029],\n",
      "        [24.7728, 20.1162, 20.4400],\n",
      "        [25.0466, 19.8524, 20.6324],\n",
      "        [25.4137, 20.0666, 20.7940],\n",
      "        [24.5925, 19.8813, 21.0726],\n",
      "        [24.5905, 19.8886, 20.7848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7724, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8767,  24.8823, -20.7051],\n",
      "        [-23.7092,  25.0694, -20.4998],\n",
      "        [-23.1252,  24.7620, -20.6015],\n",
      "        [-23.3798,  24.5039, -20.3234],\n",
      "        [-23.7682,  24.7878, -20.5681],\n",
      "        [-23.4753,  25.0599, -20.5162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8489,  20.0639,  20.7029, -23.8767,  24.8823, -20.7051],\n",
      "        [ 24.7728,  20.1162,  20.4400, -23.7092,  25.0694, -20.4998],\n",
      "        [ 25.0466,  19.8524,  20.6324, -23.1252,  24.7620, -20.6015],\n",
      "        [ 25.4137,  20.0666,  20.7940, -23.3798,  24.5039, -20.3234],\n",
      "        [ 24.5925,  19.8813,  21.0726, -23.7682,  24.7878, -20.5681],\n",
      "        [ 24.5905,  19.8886,  20.7848, -23.4753,  25.0599, -20.5162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.9886674880981445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7311, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1405, 19.8874, 20.9921],\n",
      "        [24.5497, 19.2391, 20.7145],\n",
      "        [24.4576, 19.7164, 20.4252],\n",
      "        [24.2166, 20.0859, 20.0430],\n",
      "        [25.3254, 20.1770, 21.2711],\n",
      "        [25.0978, 20.1711, 20.9059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.9924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-22.8929,  24.1665, -20.4293],\n",
      "        [-23.6254,  24.7318, -20.3964],\n",
      "        [-23.7206,  24.6123, -20.4149],\n",
      "        [-23.8205,  25.3182, -20.3794],\n",
      "        [-22.7624,  24.1458, -20.0232],\n",
      "        [-23.7879,  24.7031, -20.5316]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1405,  19.8874,  20.9921, -22.8929,  24.1665, -20.4293],\n",
      "        [ 24.5497,  19.2391,  20.7145, -23.6254,  24.7318, -20.3964],\n",
      "        [ 24.4576,  19.7164,  20.4252, -23.7206,  24.6123, -20.4149],\n",
      "        [ 24.2166,  20.0859,  20.0430, -23.8205,  25.3182, -20.3794],\n",
      "        [ 25.3254,  20.1770,  21.2711, -22.7624,  24.1458, -20.0232],\n",
      "        [ 25.0978,  20.1711,  20.9059, -23.7879,  24.7031, -20.5316]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.94911527633667\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8501, 19.8729, 20.8627],\n",
      "        [24.4766, 19.3785, 20.0780],\n",
      "        [24.9296, 19.8813, 20.7765],\n",
      "        [25.4498, 20.4008, 21.1664],\n",
      "        [24.0090, 19.4483, 19.9777],\n",
      "        [25.0390, 19.6539, 20.4699]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5613,  24.9796, -20.3476],\n",
      "        [-23.1321,  24.3236, -20.0375],\n",
      "        [-23.3451,  24.7071, -20.0068],\n",
      "        [-23.1161,  24.1365, -20.0627],\n",
      "        [-23.6505,  24.9370, -20.2357],\n",
      "        [-23.1567,  24.3584, -20.0900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8501,  19.8729,  20.8627, -23.5613,  24.9796, -20.3476],\n",
      "        [ 24.4766,  19.3785,  20.0780, -23.1321,  24.3236, -20.0375],\n",
      "        [ 24.9296,  19.8813,  20.7765, -23.3451,  24.7071, -20.0068],\n",
      "        [ 25.4498,  20.4008,  21.1664, -23.1161,  24.1365, -20.0627],\n",
      "        [ 24.0090,  19.4483,  19.9777, -23.6505,  24.9370, -20.2357],\n",
      "        [ 25.0390,  19.6539,  20.4699, -23.1567,  24.3584, -20.0900]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.976813793182373\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7066, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.5057, 19.7278, 20.9170],\n",
      "        [24.7184, 19.7568, 20.9259],\n",
      "        [24.2343, 19.1982, 20.3063],\n",
      "        [24.8988, 20.1458, 21.0995],\n",
      "        [25.2501, 20.0693, 20.9672],\n",
      "        [24.7849, 19.9591, 20.7103]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.9588, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4209,  24.6654, -20.4350],\n",
      "        [-23.5653,  24.7708, -20.9625],\n",
      "        [-24.2873,  24.7612, -20.7470],\n",
      "        [-23.0793,  24.2615, -19.9290],\n",
      "        [-23.2816,  24.8614, -20.2727],\n",
      "        [-23.2319,  24.7010, -20.6330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.5057,  19.7278,  20.9170, -23.4209,  24.6654, -20.4350],\n",
      "        [ 24.7184,  19.7568,  20.9259, -23.5653,  24.7708, -20.9625],\n",
      "        [ 24.2343,  19.1982,  20.3063, -24.2873,  24.7612, -20.7470],\n",
      "        [ 24.8988,  20.1458,  21.0995, -23.0793,  24.2615, -19.9290],\n",
      "        [ 25.2501,  20.0693,  20.9672, -23.2816,  24.8614, -20.2727],\n",
      "        [ 24.7849,  19.9591,  20.7103, -23.2319,  24.7010, -20.6330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.945402145385742\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1837, 20.0075, 21.0726],\n",
      "        [24.8075, 20.0806, 20.9715],\n",
      "        [24.8772, 20.0991, 20.8549],\n",
      "        [24.8818, 19.7682, 20.9384],\n",
      "        [25.5014, 20.1396, 20.9976],\n",
      "        [25.2177, 20.1252, 21.0053]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.1167, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0693,  25.6369, -21.0390],\n",
      "        [-23.5759,  24.7349, -20.2875],\n",
      "        [-23.6282,  24.9314, -20.2890],\n",
      "        [-23.2950,  24.5033, -20.0630],\n",
      "        [-23.2145,  24.2556, -19.6493],\n",
      "        [-24.1964,  25.3610, -20.6481]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1837,  20.0075,  21.0726, -24.0693,  25.6369, -21.0390],\n",
      "        [ 24.8075,  20.0806,  20.9715, -23.5759,  24.7349, -20.2875],\n",
      "        [ 24.8772,  20.0991,  20.8549, -23.6282,  24.9314, -20.2890],\n",
      "        [ 24.8818,  19.7682,  20.9384, -23.2950,  24.5033, -20.0630],\n",
      "        [ 25.5014,  20.1396,  20.9976, -23.2145,  24.2556, -19.6493],\n",
      "        [ 25.2177,  20.1252,  21.0053, -24.1964,  25.3610, -20.6481]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.067992210388184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1705, 19.7393, 20.6700],\n",
      "        [24.9591, 19.8761, 21.1456],\n",
      "        [24.4676, 19.6760, 20.4115],\n",
      "        [25.2857, 19.7110, 21.0457],\n",
      "        [24.9308, 19.5702, 20.2525],\n",
      "        [24.7762, 20.2116, 20.8306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.3011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6601,  24.8462, -20.5674],\n",
      "        [-23.2765,  24.7284, -19.8891],\n",
      "        [-23.1075,  24.5578, -20.2027],\n",
      "        [-23.7655,  25.5531, -20.7747],\n",
      "        [-23.2558,  25.0603, -20.1711],\n",
      "        [-23.4701,  25.0168, -20.4588]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1705,  19.7393,  20.6700, -23.6601,  24.8462, -20.5674],\n",
      "        [ 24.9591,  19.8761,  21.1456, -23.2765,  24.7284, -19.8891],\n",
      "        [ 24.4676,  19.6760,  20.4115, -23.1075,  24.5578, -20.2027],\n",
      "        [ 25.2857,  19.7110,  21.0457, -23.7655,  25.5531, -20.7747],\n",
      "        [ 24.9308,  19.5702,  20.2525, -23.2558,  25.0603, -20.1711],\n",
      "        [ 24.7762,  20.2116,  20.8306, -23.4701,  25.0168, -20.4588]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-4.99041223526001\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5540, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1388, 20.2036, 20.8848],\n",
      "        [24.6573, 20.2088, 20.8953],\n",
      "        [25.0796, 19.8595, 20.7927],\n",
      "        [25.2136, 20.1592, 20.7044],\n",
      "        [25.2775, 20.3499, 20.9951],\n",
      "        [24.9273, 20.0911, 21.1385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.2616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2903,  24.6700, -20.1676],\n",
      "        [-23.9495,  24.9341, -20.7824],\n",
      "        [-23.9321,  25.0128, -20.6516],\n",
      "        [-23.5732,  24.7633, -20.5290],\n",
      "        [-23.7773,  24.7028, -20.2448],\n",
      "        [-23.0175,  24.7090, -19.8626]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1388,  20.2036,  20.8848, -23.2903,  24.6700, -20.1676],\n",
      "        [ 24.6573,  20.2088,  20.8953, -23.9495,  24.9341, -20.7824],\n",
      "        [ 25.0796,  19.8595,  20.7927, -23.9321,  25.0128, -20.6516],\n",
      "        [ 25.2136,  20.1592,  20.7044, -23.5732,  24.7633, -20.5290],\n",
      "        [ 25.2775,  20.3499,  20.9951, -23.7773,  24.7028, -20.2448],\n",
      "        [ 24.9273,  20.0911,  21.1385, -23.0175,  24.7090, -19.8626]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.986591815948486\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0109, 20.2011, 20.9108],\n",
      "        [24.9675, 19.7848, 20.8782],\n",
      "        [24.7257, 19.5088, 20.4933],\n",
      "        [24.9837, 19.9452, 20.6848],\n",
      "        [25.3030, 20.4014, 20.9564],\n",
      "        [24.5882, 19.8480, 20.9309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.5746, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2345,  24.4478, -19.7310],\n",
      "        [-23.3079,  24.6216, -19.9924],\n",
      "        [-23.4425,  24.8262, -20.6089],\n",
      "        [-23.4997,  24.8827, -20.4512],\n",
      "        [-23.3288,  24.6657, -20.2270],\n",
      "        [-23.3291,  24.5745, -19.9470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0109,  20.2011,  20.9108, -23.2345,  24.4478, -19.7310],\n",
      "        [ 24.9675,  19.7848,  20.8782, -23.3079,  24.6216, -19.9924],\n",
      "        [ 24.7257,  19.5088,  20.4933, -23.4425,  24.8262, -20.6089],\n",
      "        [ 24.9837,  19.9452,  20.6848, -23.4997,  24.8827, -20.4512],\n",
      "        [ 25.3030,  20.4014,  20.9564, -23.3288,  24.6657, -20.2270],\n",
      "        [ 24.5882,  19.8480,  20.9309, -23.3291,  24.5745, -19.9470]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.961898326873779\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7985, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0366, 19.7328, 20.4446],\n",
      "        [25.0145, 20.0389, 20.8404],\n",
      "        [24.2907, 19.6426, 20.2723],\n",
      "        [24.8797, 19.7211, 21.1045],\n",
      "        [24.5894, 19.6960, 20.2253],\n",
      "        [24.5779, 19.8957, 20.7530]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3664, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1552,  25.2815, -20.9450],\n",
      "        [-23.6644,  24.8215, -20.3509],\n",
      "        [-23.0997,  24.4743, -20.3366],\n",
      "        [-23.0041,  24.8147, -20.4265],\n",
      "        [-23.9154,  25.2413, -20.6659],\n",
      "        [-23.3490,  24.6707, -20.4446]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0366,  19.7328,  20.4446, -24.1552,  25.2815, -20.9450],\n",
      "        [ 25.0145,  20.0389,  20.8404, -23.6644,  24.8215, -20.3509],\n",
      "        [ 24.2907,  19.6426,  20.2723, -23.0997,  24.4743, -20.3366],\n",
      "        [ 24.8797,  19.7211,  21.1045, -23.0041,  24.8147, -20.4265],\n",
      "        [ 24.5894,  19.6960,  20.2253, -23.9154,  25.2413, -20.6659],\n",
      "        [ 24.5779,  19.8957,  20.7530, -23.3490,  24.6707, -20.4446]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.01954460144043\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.1825, 19.8488, 20.3645],\n",
      "        [24.9412, 19.6120, 20.6148],\n",
      "        [24.3937, 19.7929, 20.2086],\n",
      "        [24.7855, 19.9375, 20.8012],\n",
      "        [25.7806, 20.3542, 21.3360],\n",
      "        [24.9039, 19.5325, 20.7597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7212,  25.0021, -20.8401],\n",
      "        [-23.3260,  24.4503, -19.5567],\n",
      "        [-23.2562,  24.7201, -20.4519],\n",
      "        [-23.3492,  25.0248, -20.3397],\n",
      "        [-23.8380,  25.0715, -20.2324],\n",
      "        [-23.6268,  24.7474, -20.5311]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.1825,  19.8488,  20.3645, -23.7212,  25.0021, -20.8401],\n",
      "        [ 24.9412,  19.6120,  20.6148, -23.3260,  24.4503, -19.5567],\n",
      "        [ 24.3937,  19.7929,  20.2086, -23.2562,  24.7201, -20.4519],\n",
      "        [ 24.7855,  19.9375,  20.8012, -23.3492,  25.0248, -20.3397],\n",
      "        [ 25.7806,  20.3542,  21.3360, -23.8380,  25.0715, -20.2324],\n",
      "        [ 24.9039,  19.5325,  20.7597, -23.6268,  24.7474, -20.5311]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.951051712036133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8789, 19.7861, 20.6309],\n",
      "        [24.6462, 19.6907, 20.5767],\n",
      "        [25.0339, 20.3653, 21.0063],\n",
      "        [25.0984, 20.2233, 20.8347],\n",
      "        [25.2049, 19.9581, 21.3042],\n",
      "        [24.9185, 19.4989, 20.5758]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9433, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2367,  24.7906, -20.3209],\n",
      "        [-23.8802,  24.8266, -20.5528],\n",
      "        [-23.5532,  24.8648, -20.5019],\n",
      "        [-23.3718,  24.5808, -19.7933],\n",
      "        [-23.8138,  24.8668, -20.4224],\n",
      "        [-23.7929,  25.4731, -20.8961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8789,  19.7861,  20.6309, -23.2367,  24.7906, -20.3209],\n",
      "        [ 24.6462,  19.6907,  20.5767, -23.8802,  24.8266, -20.5528],\n",
      "        [ 25.0339,  20.3653,  21.0063, -23.5532,  24.8648, -20.5019],\n",
      "        [ 25.0984,  20.2233,  20.8347, -23.3718,  24.5808, -19.7933],\n",
      "        [ 25.2049,  19.9581,  21.3042, -23.8138,  24.8668, -20.4224],\n",
      "        [ 24.9185,  19.4989,  20.5758, -23.7929,  25.4731, -20.8961]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.9619669914245605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8850, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2021, 20.2236, 20.8573],\n",
      "        [24.7956, 19.9379, 20.7116],\n",
      "        [25.1649, 19.8240, 20.8228],\n",
      "        [25.1048, 20.5233, 21.2947],\n",
      "        [25.2904, 20.1189, 21.1450],\n",
      "        [25.0968, 20.0266, 21.0759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.3874, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0055,  25.4334, -21.1499],\n",
      "        [-23.1203,  24.0709, -19.8873],\n",
      "        [-23.7233,  25.4440, -20.8320],\n",
      "        [-22.9025,  24.4709, -20.2844],\n",
      "        [-23.3052,  24.8848, -20.3287],\n",
      "        [-23.5746,  24.9274, -20.3863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2021,  20.2236,  20.8573, -24.0055,  25.4334, -21.1499],\n",
      "        [ 24.7956,  19.9379,  20.7116, -23.1203,  24.0709, -19.8873],\n",
      "        [ 25.1649,  19.8240,  20.8228, -23.7233,  25.4440, -20.8320],\n",
      "        [ 25.1048,  20.5233,  21.2947, -22.9025,  24.4709, -20.2844],\n",
      "        [ 25.2904,  20.1189,  21.1450, -23.3052,  24.8848, -20.3287],\n",
      "        [ 25.0968,  20.0266,  21.0759, -23.5746,  24.9274, -20.3863]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.073183059692383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6620, 19.8531, 20.8791],\n",
      "        [24.6461, 19.8565, 20.7742],\n",
      "        [24.4693, 19.8281, 21.1683],\n",
      "        [25.3588, 20.2462, 20.7157],\n",
      "        [24.3845, 19.4903, 20.5711],\n",
      "        [24.6004, 19.6397, 20.7284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.8845, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1450,  24.2991, -20.0072],\n",
      "        [-22.5522,  23.9322, -19.8302],\n",
      "        [-23.8410,  25.0257, -20.6424],\n",
      "        [-24.2322,  25.3674, -20.5174],\n",
      "        [-23.6224,  25.0918, -20.6053],\n",
      "        [-22.9678,  24.1808, -20.0588]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6620,  19.8531,  20.8791, -23.1450,  24.2991, -20.0072],\n",
      "        [ 24.6461,  19.8565,  20.7742, -22.5522,  23.9322, -19.8302],\n",
      "        [ 24.4693,  19.8281,  21.1683, -23.8410,  25.0257, -20.6424],\n",
      "        [ 25.3588,  20.2462,  20.7157, -24.2322,  25.3674, -20.5174],\n",
      "        [ 24.3845,  19.4903,  20.5711, -23.6224,  25.0918, -20.6053],\n",
      "        [ 24.6004,  19.6397,  20.7284, -22.9678,  24.1808, -20.0588]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.939090251922607\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6594, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6539, 19.9446, 20.4126],\n",
      "        [25.4637, 20.6612, 21.1065],\n",
      "        [25.1210, 19.7684, 20.5353],\n",
      "        [24.9107, 19.8433, 20.5742],\n",
      "        [24.9729, 19.8659, 21.1116],\n",
      "        [24.4949, 19.6765, 20.9101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.8665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3014,  24.4977, -20.3138],\n",
      "        [-23.9067,  25.0703, -20.5300],\n",
      "        [-23.6066,  24.9373, -20.0529],\n",
      "        [-23.4292,  25.0543, -20.7983],\n",
      "        [-23.2711,  24.6447, -19.7493],\n",
      "        [-23.5282,  25.1262, -20.3411]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6539,  19.9446,  20.4126, -23.3014,  24.4977, -20.3138],\n",
      "        [ 25.4637,  20.6612,  21.1065, -23.9067,  25.0703, -20.5300],\n",
      "        [ 25.1210,  19.7684,  20.5353, -23.6066,  24.9373, -20.0529],\n",
      "        [ 24.9107,  19.8433,  20.5742, -23.4292,  25.0543, -20.7983],\n",
      "        [ 24.9729,  19.8659,  21.1116, -23.2711,  24.6447, -19.7493],\n",
      "        [ 24.4949,  19.6765,  20.9101, -23.5282,  25.1262, -20.3411]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.943120002746582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6949, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4651, 19.3271, 20.4519],\n",
      "        [24.7272, 20.1171, 20.6287],\n",
      "        [24.7787, 19.6828, 21.0640],\n",
      "        [24.7334, 20.0474, 20.1937],\n",
      "        [24.9618, 20.4298, 20.9275],\n",
      "        [24.3164, 19.3821, 20.4943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.2119, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4214,  24.7995, -20.3269],\n",
      "        [-23.8455,  24.9633, -20.5444],\n",
      "        [-23.9909,  25.4902, -20.6238],\n",
      "        [-23.9656,  25.0630, -20.6715],\n",
      "        [-24.0825,  25.2034, -20.3027],\n",
      "        [-22.8361,  24.1452, -20.1713]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4651,  19.3271,  20.4519, -23.4214,  24.7995, -20.3269],\n",
      "        [ 24.7272,  20.1171,  20.6287, -23.8455,  24.9633, -20.5444],\n",
      "        [ 24.7787,  19.6828,  21.0640, -23.9909,  25.4902, -20.6238],\n",
      "        [ 24.7334,  20.0474,  20.1937, -23.9656,  25.0630, -20.6715],\n",
      "        [ 24.9618,  20.4298,  20.9275, -24.0825,  25.2034, -20.3027],\n",
      "        [ 24.3164,  19.3821,  20.4943, -22.8361,  24.1452, -20.1713]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.931117534637451\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2746, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3827, 20.2568, 20.9298],\n",
      "        [25.2964, 20.3227, 21.1581],\n",
      "        [24.5321, 19.2993, 20.7459],\n",
      "        [24.7178, 19.4842, 20.8991],\n",
      "        [24.9203, 20.1080, 21.0518],\n",
      "        [25.3218, 20.4557, 21.4133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4857, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0821,  25.2952, -20.6785],\n",
      "        [-23.5322,  24.8693, -20.0728],\n",
      "        [-24.1467,  25.4285, -20.8820],\n",
      "        [-23.4838,  24.7807, -20.7037],\n",
      "        [-23.6423,  25.0135, -20.4533],\n",
      "        [-23.3892,  24.8215, -20.2104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3827,  20.2568,  20.9298, -24.0821,  25.2952, -20.6785],\n",
      "        [ 25.2964,  20.3227,  21.1581, -23.5322,  24.8693, -20.0728],\n",
      "        [ 24.5321,  19.2993,  20.7459, -24.1467,  25.4285, -20.8820],\n",
      "        [ 24.7178,  19.4842,  20.8991, -23.4838,  24.7807, -20.7037],\n",
      "        [ 24.9203,  20.1080,  21.0518, -23.6423,  25.0135, -20.4533],\n",
      "        [ 25.3218,  20.4557,  21.4133, -23.3892,  24.8215, -20.2104]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.0792741775512695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.3828, 19.6834, 20.4844],\n",
      "        [24.8766, 19.9129, 20.3641],\n",
      "        [25.3507, 20.5248, 21.0652],\n",
      "        [24.6814, 19.5468, 20.8122],\n",
      "        [24.9875, 20.3719, 21.0546],\n",
      "        [25.5346, 20.5782, 21.2589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.6653, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6963,  25.2346, -20.8574],\n",
      "        [-23.8057,  25.2338, -20.7816],\n",
      "        [-23.1944,  24.5584, -20.3640],\n",
      "        [-23.5885,  24.6045, -20.6301],\n",
      "        [-23.6150,  25.0048, -20.3031],\n",
      "        [-23.6020,  25.0007, -20.7419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.3828,  19.6834,  20.4844, -23.6963,  25.2346, -20.8574],\n",
      "        [ 24.8766,  19.9129,  20.3641, -23.8057,  25.2338, -20.7816],\n",
      "        [ 25.3507,  20.5248,  21.0652, -23.1944,  24.5584, -20.3640],\n",
      "        [ 24.6814,  19.5468,  20.8122, -23.5885,  24.6045, -20.6301],\n",
      "        [ 24.9875,  20.3719,  21.0546, -23.6150,  25.0048, -20.3031],\n",
      "        [ 25.5346,  20.5782,  21.2589, -23.6020,  25.0007, -20.7419]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.981199741363525\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3878, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7585, 19.8981, 21.1965],\n",
      "        [24.2694, 19.8118, 20.2122],\n",
      "        [24.9979, 19.9071, 21.0590],\n",
      "        [24.8089, 19.5662, 20.5018],\n",
      "        [24.1037, 19.5398, 20.2635],\n",
      "        [25.5380, 20.2771, 21.0674]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.4581, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6192,  25.3198, -20.7138],\n",
      "        [-23.5043,  24.6959, -20.5621],\n",
      "        [-24.1229,  25.2963, -20.7850],\n",
      "        [-23.7649,  24.8602, -20.7194],\n",
      "        [-23.8991,  25.5866, -20.9323],\n",
      "        [-23.7437,  24.6936, -20.4631]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7585,  19.8981,  21.1965, -23.6192,  25.3198, -20.7138],\n",
      "        [ 24.2694,  19.8118,  20.2122, -23.5043,  24.6959, -20.5621],\n",
      "        [ 24.9979,  19.9071,  21.0590, -24.1229,  25.2963, -20.7850],\n",
      "        [ 24.8089,  19.5662,  20.5018, -23.7649,  24.8602, -20.7194],\n",
      "        [ 24.1037,  19.5398,  20.2635, -23.8991,  25.5866, -20.9323],\n",
      "        [ 25.5380,  20.2771,  21.0674, -23.7437,  24.6936, -20.4631]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.037075519561768\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2396, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9663, 20.3720, 21.1874],\n",
      "        [25.1097, 20.0514, 20.6864],\n",
      "        [25.2581, 20.5262, 20.9184],\n",
      "        [24.7972, 20.0700, 20.9513],\n",
      "        [24.7827, 19.8381, 20.8923],\n",
      "        [24.8838, 19.7227, 20.6373]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.6807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6605,  24.9896, -20.4039],\n",
      "        [-23.1095,  24.8226, -20.3702],\n",
      "        [-23.6621,  24.9121, -20.3407],\n",
      "        [-23.8158,  25.2000, -20.6841],\n",
      "        [-23.6069,  24.9350, -20.0331],\n",
      "        [-23.2297,  24.4775, -20.2559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9663,  20.3720,  21.1874, -23.6605,  24.9896, -20.4039],\n",
      "        [ 25.1097,  20.0514,  20.6864, -23.1095,  24.8226, -20.3702],\n",
      "        [ 25.2581,  20.5262,  20.9184, -23.6621,  24.9121, -20.3407],\n",
      "        [ 24.7972,  20.0700,  20.9513, -23.8158,  25.2000, -20.6841],\n",
      "        [ 24.7827,  19.8381,  20.8923, -23.6069,  24.9350, -20.0331],\n",
      "        [ 24.8838,  19.7227,  20.6373, -23.2297,  24.4775, -20.2559]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.046598434448242\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9105, 20.2328, 20.6115],\n",
      "        [25.5685, 20.7568, 21.3496],\n",
      "        [25.3129, 20.3949, 21.0092],\n",
      "        [24.6718, 19.5097, 20.9205],\n",
      "        [24.9197, 19.9955, 21.0612],\n",
      "        [25.0293, 19.8656, 20.7300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.1322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5007,  25.2936, -20.5924],\n",
      "        [-23.9213,  25.5130, -20.9676],\n",
      "        [-23.5240,  24.7541, -20.2054],\n",
      "        [-23.4441,  24.7132, -20.2251],\n",
      "        [-24.0569,  25.3822, -20.7003],\n",
      "        [-24.1427,  25.2183, -21.0521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9105,  20.2328,  20.6115, -23.5007,  25.2936, -20.5924],\n",
      "        [ 25.5685,  20.7568,  21.3496, -23.9213,  25.5130, -20.9676],\n",
      "        [ 25.3129,  20.3949,  21.0092, -23.5240,  24.7541, -20.2054],\n",
      "        [ 24.6718,  19.5097,  20.9205, -23.4441,  24.7132, -20.2251],\n",
      "        [ 24.9197,  19.9955,  21.0612, -24.0569,  25.3822, -20.7003],\n",
      "        [ 25.0293,  19.8656,  20.7300, -24.1427,  25.2183, -21.0521]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.026187419891357\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0119, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7909, 20.0573, 20.9110],\n",
      "        [25.2748, 20.1682, 21.2488],\n",
      "        [24.3974, 19.3762, 20.1806],\n",
      "        [24.7837, 20.4289, 21.0688],\n",
      "        [24.7460, 20.0756, 20.9354],\n",
      "        [25.1511, 20.2807, 21.0036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.9819, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.1743,  24.3676, -19.9309],\n",
      "        [-23.4512,  24.6659, -20.4450],\n",
      "        [-23.3356,  24.7082, -20.1363],\n",
      "        [-23.7062,  24.9938, -20.7517],\n",
      "        [-23.3621,  24.2984, -20.0725],\n",
      "        [-23.5426,  24.7284, -20.4036]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7909,  20.0573,  20.9110, -23.1743,  24.3676, -19.9309],\n",
      "        [ 25.2748,  20.1682,  21.2488, -23.4512,  24.6659, -20.4450],\n",
      "        [ 24.3974,  19.3762,  20.1806, -23.3356,  24.7082, -20.1363],\n",
      "        [ 24.7837,  20.4289,  21.0688, -23.7062,  24.9938, -20.7517],\n",
      "        [ 24.7460,  20.0756,  20.9354, -23.3621,  24.2984, -20.0725],\n",
      "        [ 25.1511,  20.2807,  21.0036, -23.5426,  24.7284, -20.4036]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-4.969113349914551\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5985, 20.3553, 21.5244],\n",
      "        [25.0190, 20.3093, 21.2698],\n",
      "        [24.9387, 20.0413, 20.7145],\n",
      "        [25.2679, 20.4132, 21.3343],\n",
      "        [24.7131, 20.2789, 20.5328],\n",
      "        [25.0853, 20.2182, 21.3907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1680,  25.1959, -21.0818],\n",
      "        [-23.4905,  24.8241, -20.4478],\n",
      "        [-23.8714,  25.0832, -20.5337],\n",
      "        [-23.7346,  24.9427, -20.3675],\n",
      "        [-23.5730,  24.9717, -20.9104],\n",
      "        [-23.7500,  24.9887, -20.8554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5985,  20.3553,  21.5244, -24.1680,  25.1959, -21.0818],\n",
      "        [ 25.0190,  20.3093,  21.2698, -23.4905,  24.8241, -20.4478],\n",
      "        [ 24.9387,  20.0413,  20.7145, -23.8714,  25.0832, -20.5337],\n",
      "        [ 25.2679,  20.4132,  21.3343, -23.7346,  24.9427, -20.3675],\n",
      "        [ 24.7131,  20.2789,  20.5328, -23.5730,  24.9717, -20.9104],\n",
      "        [ 25.0853,  20.2182,  21.3907, -23.7500,  24.9887, -20.8554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.140349388122559\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6110, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8223, 19.8535, 21.1534],\n",
      "        [24.9470, 20.2000, 21.1473],\n",
      "        [24.6472, 19.9265, 20.4053],\n",
      "        [25.0253, 20.1232, 21.0292],\n",
      "        [24.9556, 20.1948, 20.7057],\n",
      "        [25.0882, 20.3409, 20.9507]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.3831, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7561,  24.8413, -20.6967],\n",
      "        [-23.1251,  24.2152, -20.3733],\n",
      "        [-23.4877,  24.9305, -20.6350],\n",
      "        [-23.8657,  24.7299, -20.6918],\n",
      "        [-23.1617,  23.9566, -19.9450],\n",
      "        [-23.5950,  24.5723, -20.1745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8223,  19.8535,  21.1534, -23.7561,  24.8413, -20.6967],\n",
      "        [ 24.9470,  20.2000,  21.1473, -23.1251,  24.2152, -20.3733],\n",
      "        [ 24.6472,  19.9265,  20.4053, -23.4877,  24.9305, -20.6350],\n",
      "        [ 25.0253,  20.1232,  21.0292, -23.8657,  24.7299, -20.6918],\n",
      "        [ 24.9556,  20.1948,  20.7057, -23.1617,  23.9566, -19.9450],\n",
      "        [ 25.0882,  20.3409,  20.9507, -23.5950,  24.5723, -20.1745]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.0334553718566895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3387, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0372, 20.0281, 21.0371],\n",
      "        [24.8822, 20.4122, 20.9178],\n",
      "        [24.7460, 19.8315, 20.5095],\n",
      "        [24.5175, 19.6172, 20.4712],\n",
      "        [25.4191, 20.2169, 21.5379],\n",
      "        [25.0788, 19.7711, 21.1486]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.6805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5297,  24.8585, -20.0232],\n",
      "        [-23.6544,  24.4567, -20.2644],\n",
      "        [-24.1708,  25.4474, -20.7050],\n",
      "        [-23.8304,  25.0936, -21.1303],\n",
      "        [-23.6350,  24.5748, -20.4148],\n",
      "        [-23.9684,  25.2516, -21.1061]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0372,  20.0281,  21.0371, -23.5297,  24.8585, -20.0232],\n",
      "        [ 24.8822,  20.4122,  20.9178, -23.6544,  24.4567, -20.2644],\n",
      "        [ 24.7460,  19.8315,  20.5095, -24.1708,  25.4474, -20.7050],\n",
      "        [ 24.5175,  19.6172,  20.4712, -23.8304,  25.0936, -21.1303],\n",
      "        [ 25.4191,  20.2169,  21.5379, -23.6350,  24.5748, -20.4148],\n",
      "        [ 25.0788,  19.7711,  21.1486, -23.9684,  25.2516, -21.1061]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.022544860839844\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7887, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6066, 19.6105, 20.7277],\n",
      "        [24.9272, 20.3202, 21.1542],\n",
      "        [24.4429, 20.2379, 20.9380],\n",
      "        [24.6609, 20.0982, 20.5945],\n",
      "        [25.0256, 19.8965, 20.7507],\n",
      "        [25.5202, 20.4469, 21.1815]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2823, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0690,  25.5186, -21.0508],\n",
      "        [-23.2454,  24.5222, -20.3573],\n",
      "        [-23.1405,  24.5688, -20.2172],\n",
      "        [-22.8489,  24.5162, -20.3565],\n",
      "        [-23.8205,  25.2009, -20.9379],\n",
      "        [-23.8215,  25.4428, -20.7930]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6066,  19.6105,  20.7277, -24.0690,  25.5186, -21.0508],\n",
      "        [ 24.9272,  20.3202,  21.1542, -23.2454,  24.5222, -20.3573],\n",
      "        [ 24.4429,  20.2379,  20.9380, -23.1405,  24.5688, -20.2172],\n",
      "        [ 24.6609,  20.0982,  20.5945, -22.8489,  24.5162, -20.3565],\n",
      "        [ 25.0256,  19.8965,  20.7507, -23.8205,  25.2009, -20.9379],\n",
      "        [ 25.5202,  20.4469,  21.1815, -23.8215,  25.4428, -20.7930]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.042105197906494\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7492, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3030, 20.3748, 21.2027],\n",
      "        [24.7935, 19.8289, 20.8022],\n",
      "        [24.8101, 20.1452, 20.6252],\n",
      "        [25.3969, 20.3601, 21.0052],\n",
      "        [24.6812, 19.5549, 21.0634],\n",
      "        [25.3713, 20.1502, 21.3787]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.1493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4884,  24.1976, -19.9930],\n",
      "        [-23.6138,  25.1399, -20.7440],\n",
      "        [-23.3948,  24.6965, -20.3196],\n",
      "        [-23.9943,  25.1825, -20.8001],\n",
      "        [-24.3128,  25.7362, -21.6376],\n",
      "        [-23.4446,  24.5643, -20.6471]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3030,  20.3748,  21.2027, -23.4884,  24.1976, -19.9930],\n",
      "        [ 24.7935,  19.8289,  20.8022, -23.6138,  25.1399, -20.7440],\n",
      "        [ 24.8101,  20.1452,  20.6252, -23.3948,  24.6965, -20.3196],\n",
      "        [ 25.3969,  20.3601,  21.0052, -23.9943,  25.1825, -20.8001],\n",
      "        [ 24.6812,  19.5549,  21.0634, -24.3128,  25.7362, -21.6376],\n",
      "        [ 25.3713,  20.1502,  21.3787, -23.4446,  24.5643, -20.6471]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.033605575561523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9825, 20.3357, 20.9159],\n",
      "        [24.7314, 19.6702, 20.9741],\n",
      "        [25.1792, 20.0230, 21.0336],\n",
      "        [24.7964, 19.9393, 20.7663],\n",
      "        [24.6274, 20.1555, 20.9768],\n",
      "        [24.8212, 19.7349, 21.0378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7701,  25.4447, -21.0830],\n",
      "        [-23.7420,  25.0327, -20.7660],\n",
      "        [-24.2463,  25.4660, -20.9049],\n",
      "        [-23.4753,  24.8395, -20.2576],\n",
      "        [-23.9224,  25.0626, -20.8667],\n",
      "        [-23.4375,  24.6221, -20.1704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9825,  20.3357,  20.9159, -23.7701,  25.4447, -21.0830],\n",
      "        [ 24.7314,  19.6702,  20.9741, -23.7420,  25.0327, -20.7660],\n",
      "        [ 25.1792,  20.0230,  21.0336, -24.2463,  25.4660, -20.9049],\n",
      "        [ 24.7964,  19.9393,  20.7663, -23.4753,  24.8395, -20.2576],\n",
      "        [ 24.6274,  20.1555,  20.9768, -23.9224,  25.0626, -20.8667],\n",
      "        [ 24.8212,  19.7349,  21.0378, -23.4375,  24.6221, -20.1704]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.085930347442627\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.2665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4421, 20.5014, 21.3115],\n",
      "        [24.8390, 19.6809, 20.6880],\n",
      "        [25.1518, 20.1691, 21.0161],\n",
      "        [24.6897, 20.0209, 20.8503],\n",
      "        [25.4319, 20.4427, 21.3103],\n",
      "        [25.2361, 19.8459, 20.9209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.6537, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7245,  25.1139, -20.9912],\n",
      "        [-24.0000,  25.4438, -20.7413],\n",
      "        [-23.6845,  24.9126, -20.7096],\n",
      "        [-24.2217,  25.4558, -20.8476],\n",
      "        [-23.6648,  24.7889, -20.3695],\n",
      "        [-23.4986,  25.0908, -20.5944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4421,  20.5014,  21.3115, -23.7245,  25.1139, -20.9912],\n",
      "        [ 24.8390,  19.6809,  20.6880, -24.0000,  25.4438, -20.7413],\n",
      "        [ 25.1518,  20.1691,  21.0161, -23.6845,  24.9126, -20.7096],\n",
      "        [ 24.6897,  20.0209,  20.8503, -24.2217,  25.4558, -20.8476],\n",
      "        [ 25.4319,  20.4427,  21.3103, -23.6648,  24.7889, -20.3695],\n",
      "        [ 25.2361,  19.8459,  20.9209, -23.4986,  25.0908, -20.5944]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.119020462036133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1392, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4853, 20.2384, 21.6544],\n",
      "        [24.8634, 19.9143, 21.2701],\n",
      "        [24.7297, 20.0463, 20.5997],\n",
      "        [25.0267, 20.2537, 21.3091],\n",
      "        [24.9653, 19.8412, 20.2924],\n",
      "        [24.8986, 20.4765, 20.8912]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7718, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6734,  24.6567, -20.4187],\n",
      "        [-23.6426,  25.3275, -20.8209],\n",
      "        [-23.3346,  25.1015, -20.4694],\n",
      "        [-23.6545,  25.3307, -20.9673],\n",
      "        [-22.8575,  24.2798, -20.1866],\n",
      "        [-23.7025,  24.7263, -20.4148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4853,  20.2384,  21.6544, -23.6734,  24.6567, -20.4187],\n",
      "        [ 24.8634,  19.9143,  21.2701, -23.6426,  25.3275, -20.8209],\n",
      "        [ 24.7297,  20.0463,  20.5997, -23.3346,  25.1015, -20.4694],\n",
      "        [ 25.0267,  20.2537,  21.3091, -23.6545,  25.3307, -20.9673],\n",
      "        [ 24.9653,  19.8412,  20.2924, -22.8575,  24.2798, -20.1866],\n",
      "        [ 24.8986,  20.4765,  20.8912, -23.7025,  24.7263, -20.4148]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.096715927124023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3270, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3171, 20.1304, 21.1591],\n",
      "        [25.0579, 20.1375, 21.2436],\n",
      "        [24.7221, 19.5815, 20.7307],\n",
      "        [25.2662, 20.2543, 21.5301],\n",
      "        [24.8376, 20.0564, 20.6549],\n",
      "        [24.6521, 19.8982, 21.1230]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.7359, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5130,  24.9587, -21.0416],\n",
      "        [-23.6704,  25.4001, -20.6335],\n",
      "        [-23.9507,  24.9573, -20.7472],\n",
      "        [-24.0256,  25.0591, -21.1536],\n",
      "        [-23.9600,  25.4759, -21.2798],\n",
      "        [-23.7976,  25.2035, -20.8164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3171,  20.1304,  21.1591, -23.5130,  24.9587, -21.0416],\n",
      "        [ 25.0579,  20.1375,  21.2436, -23.6704,  25.4001, -20.6335],\n",
      "        [ 24.7221,  19.5815,  20.7307, -23.9507,  24.9573, -20.7472],\n",
      "        [ 25.2662,  20.2543,  21.5301, -24.0256,  25.0591, -21.1536],\n",
      "        [ 24.8376,  20.0564,  20.6549, -23.9600,  25.4759, -21.2798],\n",
      "        [ 24.6521,  19.8982,  21.1230, -23.7976,  25.2035, -20.8164]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.08638334274292\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3676, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4905, 20.0784, 21.3897],\n",
      "        [24.9919, 20.1407, 20.8042],\n",
      "        [24.5158, 19.3232, 20.5481],\n",
      "        [25.4986, 20.2051, 21.4058],\n",
      "        [25.0243, 20.4182, 21.2847],\n",
      "        [24.5951, 20.2032, 20.5855]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.5515, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3615,  24.2373, -20.1123],\n",
      "        [-23.3770,  24.6427, -20.4425],\n",
      "        [-23.9461,  25.3826, -20.7329],\n",
      "        [-23.6109,  24.5067, -20.4122],\n",
      "        [-23.7550,  24.8907, -20.8062],\n",
      "        [-24.0443,  25.5736, -21.1423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4905,  20.0784,  21.3897, -23.3615,  24.2373, -20.1123],\n",
      "        [ 24.9919,  20.1407,  20.8042, -23.3770,  24.6427, -20.4425],\n",
      "        [ 24.5158,  19.3232,  20.5481, -23.9461,  25.3826, -20.7329],\n",
      "        [ 25.4986,  20.2051,  21.4058, -23.6109,  24.5067, -20.4122],\n",
      "        [ 25.0243,  20.4182,  21.2847, -23.7550,  24.8907, -20.8062],\n",
      "        [ 24.5951,  20.2032,  20.5855, -24.0443,  25.5736, -21.1423]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.0510382652282715\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2432, 20.1765, 21.0286],\n",
      "        [25.0422, 20.3549, 21.3200],\n",
      "        [25.7571, 20.5338, 21.5421],\n",
      "        [24.9820, 20.0849, 20.8980],\n",
      "        [24.8304, 20.1491, 20.8069],\n",
      "        [25.2632, 20.3731, 20.6277]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.0628, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2812,  25.3715, -21.2227],\n",
      "        [-23.4587,  24.6282, -20.4782],\n",
      "        [-23.5246,  25.0907, -20.6668],\n",
      "        [-23.6231,  24.9003, -20.6484],\n",
      "        [-23.5922,  24.6939, -20.4072],\n",
      "        [-23.7256,  25.0825, -20.7668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2432,  20.1765,  21.0286, -24.2812,  25.3715, -21.2227],\n",
      "        [ 25.0422,  20.3549,  21.3200, -23.4587,  24.6282, -20.4782],\n",
      "        [ 25.7571,  20.5338,  21.5421, -23.5246,  25.0907, -20.6668],\n",
      "        [ 24.9820,  20.0849,  20.8980, -23.6231,  24.9003, -20.6484],\n",
      "        [ 24.8304,  20.1491,  20.8069, -23.5922,  24.6939, -20.4072],\n",
      "        [ 25.2632,  20.3731,  20.6277, -23.7256,  25.0825, -20.7668]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.12591552734375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7272, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7209, 20.2020, 20.5418],\n",
      "        [25.3908, 20.1469, 21.2928],\n",
      "        [24.7080, 20.4804, 21.3602],\n",
      "        [25.2514, 20.4569, 21.2743],\n",
      "        [24.6238, 20.0951, 20.6466],\n",
      "        [25.3338, 20.5421, 21.1454]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.2988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6922,  25.2499, -20.8659],\n",
      "        [-23.4472,  24.5003, -20.4059],\n",
      "        [-23.4789,  24.2111, -20.2389],\n",
      "        [-23.8436,  24.8292, -20.3693],\n",
      "        [-23.7317,  24.7750, -20.4349],\n",
      "        [-23.7121,  25.0796, -20.5020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7209,  20.2020,  20.5418, -23.6922,  25.2499, -20.8659],\n",
      "        [ 25.3908,  20.1469,  21.2928, -23.4472,  24.5003, -20.4059],\n",
      "        [ 24.7080,  20.4804,  21.3602, -23.4789,  24.2111, -20.2389],\n",
      "        [ 25.2514,  20.4569,  21.2743, -23.8436,  24.8292, -20.3693],\n",
      "        [ 24.6238,  20.0951,  20.6466, -23.7317,  24.7750, -20.4349],\n",
      "        [ 25.3338,  20.5421,  21.1454, -23.7121,  25.0796, -20.5020]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.047299861907959\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9680, 19.9911, 21.1379],\n",
      "        [25.4338, 20.5407, 21.3034],\n",
      "        [25.4813, 20.4809, 21.3110],\n",
      "        [25.6535, 20.6627, 21.6142],\n",
      "        [25.3000, 20.3872, 21.1611],\n",
      "        [25.1805, 20.5619, 21.4587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.5865, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6062,  24.6904, -20.4137],\n",
      "        [-23.4300,  24.4492, -20.1618],\n",
      "        [-23.8727,  24.8376, -20.6506],\n",
      "        [-24.0576,  25.2840, -20.9691],\n",
      "        [-24.1030,  24.7116, -20.4507],\n",
      "        [-23.4987,  24.9779, -20.5343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9680,  19.9911,  21.1379, -23.6062,  24.6904, -20.4137],\n",
      "        [ 25.4338,  20.5407,  21.3034, -23.4300,  24.4492, -20.1618],\n",
      "        [ 25.4813,  20.4809,  21.3110, -23.8727,  24.8376, -20.6506],\n",
      "        [ 25.6535,  20.6627,  21.6142, -24.0576,  25.2840, -20.9691],\n",
      "        [ 25.3000,  20.3872,  21.1611, -24.1030,  24.7116, -20.4507],\n",
      "        [ 25.1805,  20.5619,  21.4587, -23.4987,  24.9779, -20.5343]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.0468316078186035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5181, 20.3897, 20.9515],\n",
      "        [25.7104, 20.4878, 21.4595],\n",
      "        [25.0597, 20.3756, 21.2242],\n",
      "        [24.9368, 20.3178, 20.8989],\n",
      "        [25.1719, 20.1684, 21.1735],\n",
      "        [24.9308, 19.8158, 20.8733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.8306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.2697,  24.9034, -20.5637],\n",
      "        [-23.8098,  25.2594, -20.7908],\n",
      "        [-24.3025,  25.5265, -20.9972],\n",
      "        [-23.7827,  25.3477, -20.5818],\n",
      "        [-23.5917,  24.8642, -20.8477],\n",
      "        [-23.7762,  25.2807, -20.8584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5181,  20.3897,  20.9515, -23.2697,  24.9034, -20.5637],\n",
      "        [ 25.7104,  20.4878,  21.4595, -23.8098,  25.2594, -20.7908],\n",
      "        [ 25.0597,  20.3756,  21.2242, -24.3025,  25.5265, -20.9972],\n",
      "        [ 24.9368,  20.3178,  20.8989, -23.7827,  25.3477, -20.5818],\n",
      "        [ 25.1719,  20.1684,  21.1735, -23.5917,  24.8642, -20.8477],\n",
      "        [ 24.9308,  19.8158,  20.8733, -23.7762,  25.2807, -20.8584]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.082788467407227\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.6247, 19.7445, 20.7722],\n",
      "        [25.0218, 19.7216, 20.9820],\n",
      "        [24.6984, 19.7898, 20.3328],\n",
      "        [25.1673, 19.9765, 21.1798],\n",
      "        [25.2819, 20.0754, 20.6792],\n",
      "        [25.4107, 20.2695, 21.1931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1269, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7134,  24.4063, -20.3653],\n",
      "        [-24.1640,  25.2182, -20.8391],\n",
      "        [-24.1792,  25.3553, -20.6988],\n",
      "        [-23.7086,  25.1221, -20.6119],\n",
      "        [-23.6305,  25.1399, -20.1939],\n",
      "        [-24.3314,  25.1884, -20.7568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.6247,  19.7445,  20.7722, -23.7134,  24.4063, -20.3653],\n",
      "        [ 25.0218,  19.7216,  20.9820, -24.1640,  25.2182, -20.8391],\n",
      "        [ 24.6984,  19.7898,  20.3328, -24.1792,  25.3553, -20.6988],\n",
      "        [ 25.1673,  19.9765,  21.1798, -23.7086,  25.1221, -20.6119],\n",
      "        [ 25.2819,  20.0754,  20.6792, -23.6305,  25.1399, -20.1939],\n",
      "        [ 25.4107,  20.2695,  21.1931, -24.3314,  25.1884, -20.7568]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.000710487365723\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2097, 20.2532, 21.1490],\n",
      "        [25.1111, 20.3308, 20.7715],\n",
      "        [25.7170, 20.6990, 21.5827],\n",
      "        [25.2976, 20.2662, 21.0392],\n",
      "        [24.9117, 20.1452, 21.0870],\n",
      "        [25.5998, 20.7021, 21.2537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.5913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2739,  25.6212, -21.3280],\n",
      "        [-23.6945,  25.0530, -20.4710],\n",
      "        [-23.4336,  24.8301, -20.8774],\n",
      "        [-23.5892,  25.0536, -20.7026],\n",
      "        [-23.2955,  24.8610, -20.5274],\n",
      "        [-23.2548,  24.5878, -20.0198]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2097,  20.2532,  21.1490, -24.2739,  25.6212, -21.3280],\n",
      "        [ 25.1111,  20.3308,  20.7715, -23.6945,  25.0530, -20.4710],\n",
      "        [ 25.7170,  20.6990,  21.5827, -23.4336,  24.8301, -20.8774],\n",
      "        [ 25.2976,  20.2662,  21.0392, -23.5892,  25.0536, -20.7026],\n",
      "        [ 24.9117,  20.1452,  21.0870, -23.2955,  24.8610, -20.5274],\n",
      "        [ 25.5998,  20.7021,  21.2537, -23.2548,  24.5878, -20.0198]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.152184009552002\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9992, 20.3114, 21.1313],\n",
      "        [25.2245, 20.1026, 21.2354],\n",
      "        [25.5400, 20.4429, 21.2236],\n",
      "        [25.3207, 20.0225, 20.9377],\n",
      "        [25.3207, 20.8656, 21.1946],\n",
      "        [24.4191, 19.9988, 20.2994]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(23.9419, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9349,  25.2604, -20.6156],\n",
      "        [-23.8632,  25.2193, -20.6775],\n",
      "        [-24.0522,  25.7304, -21.0985],\n",
      "        [-23.6307,  24.9420, -20.9234],\n",
      "        [-23.9788,  25.1390, -20.7445],\n",
      "        [-23.8097,  24.6635, -20.2322]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9992,  20.3114,  21.1313, -23.9349,  25.2604, -20.6156],\n",
      "        [ 25.2245,  20.1026,  21.2354, -23.8632,  25.2193, -20.6775],\n",
      "        [ 25.5400,  20.4429,  21.2236, -24.0522,  25.7304, -21.0985],\n",
      "        [ 25.3207,  20.0225,  20.9377, -23.6307,  24.9420, -20.9234],\n",
      "        [ 25.3207,  20.8656,  21.1946, -23.9788,  25.1390, -20.7445],\n",
      "        [ 24.4191,  19.9988,  20.2994, -23.8097,  24.6635, -20.2322]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.101630210876465\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1527, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9776, 20.1471, 21.1976],\n",
      "        [25.3921, 20.5813, 21.0155],\n",
      "        [25.4132, 20.6107, 21.1459],\n",
      "        [24.6061, 19.8862, 20.9657],\n",
      "        [25.3369, 20.6053, 21.3041],\n",
      "        [24.7364, 20.0389, 21.2051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.3850,  25.3472, -20.9007],\n",
      "        [-24.0364,  25.2645, -21.2497],\n",
      "        [-23.7210,  25.0218, -20.5545],\n",
      "        [-23.5474,  24.8333, -20.4610],\n",
      "        [-24.0076,  25.0419, -20.8796],\n",
      "        [-23.7510,  25.2198, -20.6491]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9776,  20.1471,  21.1976, -23.3850,  25.3472, -20.9007],\n",
      "        [ 25.3921,  20.5813,  21.0155, -24.0364,  25.2645, -21.2497],\n",
      "        [ 25.4132,  20.6107,  21.1459, -23.7210,  25.0218, -20.5545],\n",
      "        [ 24.6061,  19.8862,  20.9657, -23.5474,  24.8333, -20.4610],\n",
      "        [ 25.3369,  20.6053,  21.3041, -24.0076,  25.0419, -20.8796],\n",
      "        [ 24.7364,  20.0389,  21.2051, -23.7510,  25.2198, -20.6491]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.092496395111084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4121, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1884, 20.2743, 21.1136],\n",
      "        [24.8205, 20.3571, 21.0121],\n",
      "        [25.5192, 20.4075, 21.3833],\n",
      "        [25.1230, 20.2673, 20.6634],\n",
      "        [24.9184, 20.4166, 20.6676],\n",
      "        [25.5860, 20.3915, 21.5097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.1933, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0859,  25.0165, -20.7328],\n",
      "        [-24.1625,  24.8042, -20.6790],\n",
      "        [-23.5124,  24.8375, -20.6473],\n",
      "        [-24.5021,  25.8274, -21.1847],\n",
      "        [-23.9803,  25.2879, -20.9794],\n",
      "        [-24.2323,  25.7121, -21.0761]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1884,  20.2743,  21.1136, -24.0859,  25.0165, -20.7328],\n",
      "        [ 24.8205,  20.3571,  21.0121, -24.1625,  24.8042, -20.6790],\n",
      "        [ 25.5192,  20.4075,  21.3833, -23.5124,  24.8375, -20.6473],\n",
      "        [ 25.1230,  20.2673,  20.6634, -24.5021,  25.8274, -21.1847],\n",
      "        [ 24.9184,  20.4166,  20.6676, -23.9803,  25.2879, -20.9794],\n",
      "        [ 25.5860,  20.3915,  21.5097, -24.2323,  25.7121, -21.0761]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.112682819366455\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2085, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2560, 19.9959, 21.1374],\n",
      "        [25.7695, 20.1252, 21.3009],\n",
      "        [25.0924, 20.4618, 21.0654],\n",
      "        [25.1694, 20.3765, 21.1681],\n",
      "        [25.1491, 20.3112, 20.9964],\n",
      "        [25.5935, 20.5396, 21.4338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7769, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0158,  25.1322, -20.5956],\n",
      "        [-23.2335,  24.8629, -20.6756],\n",
      "        [-23.1585,  24.1816, -20.1714],\n",
      "        [-23.5624,  24.7578, -20.5568],\n",
      "        [-23.2637,  25.0507, -20.2804],\n",
      "        [-23.7494,  25.1331, -20.3750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2560,  19.9959,  21.1374, -24.0158,  25.1322, -20.5956],\n",
      "        [ 25.7695,  20.1252,  21.3009, -23.2335,  24.8629, -20.6756],\n",
      "        [ 25.0924,  20.4618,  21.0654, -23.1585,  24.1816, -20.1714],\n",
      "        [ 25.1694,  20.3765,  21.1681, -23.5624,  24.7578, -20.5568],\n",
      "        [ 25.1491,  20.3112,  20.9964, -23.2637,  25.0507, -20.2804],\n",
      "        [ 25.5935,  20.5396,  21.4338, -23.7494,  25.1331, -20.3750]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.107906341552734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6685, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2835, 20.3954, 21.0643],\n",
      "        [25.1422, 20.6689, 21.6055],\n",
      "        [25.0248, 20.1410, 21.1836],\n",
      "        [25.4196, 20.2771, 21.4954],\n",
      "        [25.6329, 20.9212, 21.5495],\n",
      "        [25.3598, 20.6321, 21.4606]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.9116, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6629,  25.0598, -20.8945],\n",
      "        [-23.4115,  24.8890, -20.6596],\n",
      "        [-23.9522,  25.1987, -20.6970],\n",
      "        [-24.0487,  25.0662, -20.4582],\n",
      "        [-23.7273,  25.1850, -20.6925],\n",
      "        [-23.9674,  24.4571, -20.8383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2835,  20.3954,  21.0643, -23.6629,  25.0598, -20.8945],\n",
      "        [ 25.1422,  20.6689,  21.6055, -23.4115,  24.8890, -20.6596],\n",
      "        [ 25.0248,  20.1410,  21.1836, -23.9522,  25.1987, -20.6970],\n",
      "        [ 25.4196,  20.2771,  21.4954, -24.0487,  25.0662, -20.4582],\n",
      "        [ 25.6329,  20.9212,  21.5495, -23.7273,  25.1850, -20.6925],\n",
      "        [ 25.3598,  20.6321,  21.4606, -23.9674,  24.4571, -20.8383]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.1151556968688965\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7979, 20.6907, 21.0155],\n",
      "        [25.2318, 20.2339, 21.3175],\n",
      "        [25.2493, 20.3620, 21.4206],\n",
      "        [25.0279, 20.0852, 21.0989],\n",
      "        [25.5935, 20.5479, 21.3761],\n",
      "        [25.8335, 20.8785, 21.5680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2799, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5486,  25.2951, -20.8756],\n",
      "        [-23.9547,  25.3606, -20.8431],\n",
      "        [-23.8110,  25.1526, -20.3753],\n",
      "        [-24.0594,  24.6466, -20.6022],\n",
      "        [-24.1520,  25.3603, -21.1580],\n",
      "        [-23.7767,  24.8712, -20.3476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7979,  20.6907,  21.0155, -23.5486,  25.2951, -20.8756],\n",
      "        [ 25.2318,  20.2339,  21.3175, -23.9547,  25.3606, -20.8431],\n",
      "        [ 25.2493,  20.3620,  21.4206, -23.8110,  25.1526, -20.3753],\n",
      "        [ 25.0279,  20.0852,  21.0989, -24.0594,  24.6466, -20.6022],\n",
      "        [ 25.5935,  20.5479,  21.3761, -24.1520,  25.3603, -21.1580],\n",
      "        [ 25.8335,  20.8785,  21.5680, -23.7767,  24.8712, -20.3476]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.155425071716309\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1786, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.8029, 20.0830, 20.8372],\n",
      "        [25.4671, 20.1860, 21.4063],\n",
      "        [24.9687, 20.1538, 21.2302],\n",
      "        [25.6213, 20.5857, 21.5749],\n",
      "        [25.3060, 20.3065, 21.0943],\n",
      "        [25.3129, 20.5483, 21.1185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.2834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1828,  25.5901, -20.9483],\n",
      "        [-23.9357,  24.8667, -20.5019],\n",
      "        [-23.9079,  25.2045, -20.6823],\n",
      "        [-23.8759,  25.1152, -20.8039],\n",
      "        [-23.2801,  24.9900, -20.7512],\n",
      "        [-24.0797,  25.2502, -20.8836]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.8029,  20.0830,  20.8372, -24.1828,  25.5901, -20.9483],\n",
      "        [ 25.4671,  20.1860,  21.4063, -23.9357,  24.8667, -20.5019],\n",
      "        [ 24.9687,  20.1538,  21.2302, -23.9079,  25.2045, -20.6823],\n",
      "        [ 25.6213,  20.5857,  21.5749, -23.8759,  25.1152, -20.8039],\n",
      "        [ 25.3060,  20.3065,  21.0943, -23.2801,  24.9900, -20.7512],\n",
      "        [ 25.3129,  20.5483,  21.1185, -24.0797,  25.2502, -20.8836]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.110075950622559\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1376, 20.0699, 21.2573],\n",
      "        [24.5082, 19.9484, 20.5310],\n",
      "        [25.4019, 20.5281, 21.3892],\n",
      "        [24.8110, 20.1568, 20.9796],\n",
      "        [24.9565, 20.1199, 21.3126],\n",
      "        [25.0150, 20.1894, 20.7896]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.2542, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8596,  25.0696, -20.8449],\n",
      "        [-23.2511,  24.9297, -20.3413],\n",
      "        [-23.7613,  24.7074, -20.4716],\n",
      "        [-24.3498,  25.5243, -21.2720],\n",
      "        [-23.9246,  25.1231, -20.5193],\n",
      "        [-23.6990,  25.6600, -20.9454]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1376,  20.0699,  21.2573, -23.8596,  25.0696, -20.8449],\n",
      "        [ 24.5082,  19.9484,  20.5310, -23.2511,  24.9297, -20.3413],\n",
      "        [ 25.4019,  20.5281,  21.3892, -23.7613,  24.7074, -20.4716],\n",
      "        [ 24.8110,  20.1568,  20.9796, -24.3498,  25.5243, -21.2720],\n",
      "        [ 24.9565,  20.1199,  21.3126, -23.9246,  25.1231, -20.5193],\n",
      "        [ 25.0150,  20.1894,  20.7896, -23.6990,  25.6600, -20.9454]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.115963935852051\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1563, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7618, 19.9251, 20.5779],\n",
      "        [25.1290, 20.2294, 21.1594],\n",
      "        [25.4154, 20.4612, 21.2842],\n",
      "        [25.2573, 20.1302, 21.1518],\n",
      "        [25.2339, 20.7510, 21.2481],\n",
      "        [24.6040, 19.5977, 20.4592]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.3719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7878,  25.1068, -20.8185],\n",
      "        [-24.6263,  25.4832, -21.4058],\n",
      "        [-23.6832,  25.2198, -20.2284],\n",
      "        [-24.0248,  25.2687, -20.9383],\n",
      "        [-23.9479,  25.2503, -20.6544],\n",
      "        [-24.3252,  25.5407, -21.1256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7618,  19.9251,  20.5779, -23.7878,  25.1068, -20.8185],\n",
      "        [ 25.1290,  20.2294,  21.1594, -24.6263,  25.4832, -21.4058],\n",
      "        [ 25.4154,  20.4612,  21.2842, -23.6832,  25.2198, -20.2284],\n",
      "        [ 25.2573,  20.1302,  21.1518, -24.0248,  25.2687, -20.9383],\n",
      "        [ 25.2339,  20.7510,  21.2481, -23.9479,  25.2503, -20.6544],\n",
      "        [ 24.6040,  19.5977,  20.4592, -24.3252,  25.5407, -21.1256]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.061795234680176\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4379, 20.1527, 21.5731],\n",
      "        [25.1810, 19.9566, 21.1149],\n",
      "        [25.1375, 20.7847, 21.1442],\n",
      "        [25.1034, 20.0172, 21.2326],\n",
      "        [25.1996, 20.1198, 20.6537],\n",
      "        [25.5137, 20.6849, 21.5890]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.1586, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3376,  25.3275, -20.6614],\n",
      "        [-23.4204,  24.6691, -20.4261],\n",
      "        [-23.7410,  25.2554, -20.6476],\n",
      "        [-23.9297,  25.0895, -20.8616],\n",
      "        [-24.1408,  25.0624, -20.9117],\n",
      "        [-23.9254,  24.9470, -20.8055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4379,  20.1527,  21.5731, -24.3376,  25.3275, -20.6614],\n",
      "        [ 25.1810,  19.9566,  21.1149, -23.4204,  24.6691, -20.4261],\n",
      "        [ 25.1375,  20.7847,  21.1442, -23.7410,  25.2554, -20.6476],\n",
      "        [ 25.1034,  20.0172,  21.2326, -23.9297,  25.0895, -20.8616],\n",
      "        [ 25.1996,  20.1198,  20.6537, -24.1408,  25.0624, -20.9117],\n",
      "        [ 25.5137,  20.6849,  21.5890, -23.9254,  24.9470, -20.8055]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.17145299911499\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4627, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7146, 20.2616, 21.6946],\n",
      "        [25.1817, 20.3727, 21.0202],\n",
      "        [24.9188, 20.1398, 21.1277],\n",
      "        [25.2733, 20.6433, 21.1448],\n",
      "        [24.5807, 20.1794, 20.8063],\n",
      "        [24.6843, 20.0625, 21.2017]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.1913, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9917,  25.0827, -20.7163],\n",
      "        [-23.6791,  24.5152, -20.4078],\n",
      "        [-23.6375,  24.9112, -20.7458],\n",
      "        [-23.9646,  25.3675, -20.8122],\n",
      "        [-23.8590,  25.0611, -20.6939],\n",
      "        [-23.9034,  24.9988, -20.7812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7146,  20.2616,  21.6946, -23.9917,  25.0827, -20.7163],\n",
      "        [ 25.1817,  20.3727,  21.0202, -23.6791,  24.5152, -20.4078],\n",
      "        [ 24.9188,  20.1398,  21.1277, -23.6375,  24.9112, -20.7458],\n",
      "        [ 25.2733,  20.6433,  21.1448, -23.9646,  25.3675, -20.8122],\n",
      "        [ 24.5807,  20.1794,  20.8063, -23.8590,  25.0611, -20.6939],\n",
      "        [ 24.6843,  20.0625,  21.2017, -23.9034,  24.9988, -20.7812]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.178369998931885\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9927, 20.1335, 21.1135],\n",
      "        [25.5123, 20.6585, 21.3272],\n",
      "        [25.0033, 20.1752, 20.7235],\n",
      "        [24.7121, 20.0531, 21.0919],\n",
      "        [25.3737, 20.5343, 21.3455],\n",
      "        [25.7722, 20.9974, 21.6835]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.4240, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.4570,  24.7294, -20.3056],\n",
      "        [-23.7938,  25.0483, -20.7183],\n",
      "        [-24.4861,  25.7004, -21.2655],\n",
      "        [-24.2661,  25.3697, -21.1735],\n",
      "        [-23.7753,  24.9445, -20.9192],\n",
      "        [-23.5592,  25.2853, -20.8422]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9927,  20.1335,  21.1135, -23.4570,  24.7294, -20.3056],\n",
      "        [ 25.5123,  20.6585,  21.3272, -23.7938,  25.0483, -20.7183],\n",
      "        [ 25.0033,  20.1752,  20.7235, -24.4861,  25.7004, -21.2655],\n",
      "        [ 24.7121,  20.0531,  21.0919, -24.2661,  25.3697, -21.1735],\n",
      "        [ 25.3737,  20.5343,  21.3455, -23.7753,  24.9445, -20.9192],\n",
      "        [ 25.7722,  20.9974,  21.6835, -23.5592,  25.2853, -20.8422]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.071904182434082\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5189, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3848, 20.1390, 21.5118],\n",
      "        [25.1645, 20.2020, 21.3896],\n",
      "        [25.2464, 20.4928, 21.1807],\n",
      "        [25.2957, 20.4635, 21.1320],\n",
      "        [25.2662, 20.1688, 21.4108],\n",
      "        [25.2107, 20.0246, 21.0991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.1366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.6666,  25.2767, -20.7330],\n",
      "        [-23.9198,  24.7105, -20.6754],\n",
      "        [-24.6308,  24.9828, -20.9067],\n",
      "        [-23.7358,  25.2146, -20.7041],\n",
      "        [-24.1484,  25.5797, -20.7157],\n",
      "        [-23.4018,  24.8179, -20.9030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3848,  20.1390,  21.5118, -23.6666,  25.2767, -20.7330],\n",
      "        [ 25.1645,  20.2020,  21.3896, -23.9198,  24.7105, -20.6754],\n",
      "        [ 25.2464,  20.4928,  21.1807, -24.6308,  24.9828, -20.9067],\n",
      "        [ 25.2957,  20.4635,  21.1320, -23.7358,  25.2146, -20.7041],\n",
      "        [ 25.2662,  20.1688,  21.4108, -24.1484,  25.5797, -20.7157],\n",
      "        [ 25.2107,  20.0246,  21.0991, -23.4018,  24.8179, -20.9030]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.149197101593018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5251, 20.7543, 21.4257],\n",
      "        [25.6521, 20.5110, 21.1439],\n",
      "        [25.4007, 20.9537, 21.1451],\n",
      "        [25.9479, 20.5876, 21.5608],\n",
      "        [25.5368, 20.8530, 21.4460],\n",
      "        [24.8233, 19.7514, 20.9377]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.5182,  25.1839, -20.6584],\n",
      "        [-23.9525,  25.5638, -20.9158],\n",
      "        [-24.0257,  25.4947, -20.8157],\n",
      "        [-23.8763,  24.8818, -20.6744],\n",
      "        [-23.7239,  24.5298, -20.5409],\n",
      "        [-24.1502,  25.1674, -20.9265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5251,  20.7543,  21.4257, -23.5182,  25.1839, -20.6584],\n",
      "        [ 25.6521,  20.5110,  21.1439, -23.9525,  25.5638, -20.9158],\n",
      "        [ 25.4007,  20.9537,  21.1451, -24.0257,  25.4947, -20.8157],\n",
      "        [ 25.9479,  20.5876,  21.5608, -23.8763,  24.8818, -20.6744],\n",
      "        [ 25.5368,  20.8530,  21.4460, -23.7239,  24.5298, -20.5409],\n",
      "        [ 24.8233,  19.7514,  20.9377, -24.1502,  25.1674, -20.9265]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.164919853210449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4298, 20.4519, 21.1813],\n",
      "        [25.6811, 20.6621, 21.6369],\n",
      "        [25.5195, 20.6419, 21.0436],\n",
      "        [25.4487, 20.2567, 21.0617],\n",
      "        [25.6304, 20.6325, 21.5482],\n",
      "        [25.5396, 20.2898, 21.7487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7960,  25.1611, -20.6598],\n",
      "        [-23.4104,  24.6793, -20.6190],\n",
      "        [-24.2163,  25.0234, -20.7771],\n",
      "        [-23.6509,  25.1425, -20.9840],\n",
      "        [-23.7018,  24.9806, -21.0157],\n",
      "        [-23.8952,  25.1616, -21.0384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4298,  20.4519,  21.1813, -23.7960,  25.1611, -20.6598],\n",
      "        [ 25.6811,  20.6621,  21.6369, -23.4104,  24.6793, -20.6190],\n",
      "        [ 25.5195,  20.6419,  21.0436, -24.2163,  25.0234, -20.7771],\n",
      "        [ 25.4487,  20.2567,  21.0617, -23.6509,  25.1425, -20.9840],\n",
      "        [ 25.6304,  20.6325,  21.5482, -23.7018,  24.9806, -21.0157],\n",
      "        [ 25.5396,  20.2898,  21.7487, -23.8952,  25.1616, -21.0384]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.149277210235596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2220, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3010, 20.2858, 21.0832],\n",
      "        [25.4644, 20.3837, 21.2962],\n",
      "        [24.3757, 19.6996, 20.5121],\n",
      "        [25.2324, 20.6531, 21.6800],\n",
      "        [25.5371, 20.9346, 21.3576],\n",
      "        [25.6580, 20.8379, 21.6829]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.9051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4229,  25.3153, -21.0172],\n",
      "        [-23.5446,  24.9510, -20.5984],\n",
      "        [-23.8998,  25.2976, -20.8105],\n",
      "        [-23.5933,  25.0161, -20.6538],\n",
      "        [-23.6315,  25.0357, -21.0164],\n",
      "        [-23.4656,  25.2573, -20.5392]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3010,  20.2858,  21.0832, -24.4229,  25.3153, -21.0172],\n",
      "        [ 25.4644,  20.3837,  21.2962, -23.5446,  24.9510, -20.5984],\n",
      "        [ 24.3757,  19.6996,  20.5121, -23.8998,  25.2976, -20.8105],\n",
      "        [ 25.2324,  20.6531,  21.6800, -23.5933,  25.0161, -20.6538],\n",
      "        [ 25.5371,  20.9346,  21.3576, -23.6315,  25.0357, -21.0164],\n",
      "        [ 25.6580,  20.8379,  21.6829, -23.4656,  25.2573, -20.5392]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.169958114624023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4343, 20.9296, 21.5306],\n",
      "        [24.8723, 20.5860, 20.9274],\n",
      "        [25.4303, 20.3728, 21.2382],\n",
      "        [25.2677, 20.7905, 21.3459],\n",
      "        [25.0814, 20.1621, 20.9909],\n",
      "        [25.7140, 20.9069, 21.8011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.3303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1696,  24.8268, -20.7716],\n",
      "        [-23.6358,  25.3633, -20.7849],\n",
      "        [-24.2691,  25.5045, -21.0539],\n",
      "        [-23.5247,  24.9679, -20.4213],\n",
      "        [-24.3930,  25.3765, -21.2400],\n",
      "        [-24.3831,  25.6333, -21.0671]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4343,  20.9296,  21.5306, -24.1696,  24.8268, -20.7716],\n",
      "        [ 24.8723,  20.5860,  20.9274, -23.6358,  25.3633, -20.7849],\n",
      "        [ 25.4303,  20.3728,  21.2382, -24.2691,  25.5045, -21.0539],\n",
      "        [ 25.2677,  20.7905,  21.3459, -23.5247,  24.9679, -20.4213],\n",
      "        [ 25.0814,  20.1621,  20.9909, -24.3930,  25.3765, -21.2400],\n",
      "        [ 25.7140,  20.9069,  21.8011, -24.3831,  25.6333, -21.0671]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.187885284423828\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2861, 20.6909, 21.9060],\n",
      "        [24.8657, 20.2475, 21.1539],\n",
      "        [25.7238, 20.8414, 21.6655],\n",
      "        [24.7432, 20.2182, 20.7353],\n",
      "        [25.3557, 20.2477, 21.3745],\n",
      "        [25.2466, 20.1862, 21.0468]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.7912, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0625,  24.8596, -20.6708],\n",
      "        [-23.4325,  24.8079, -20.5179],\n",
      "        [-24.1309,  25.2192, -21.0129],\n",
      "        [-23.9673,  25.5792, -21.0879],\n",
      "        [-23.9077,  25.2636, -21.0319],\n",
      "        [-23.3317,  24.4254, -20.2884]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2861,  20.6909,  21.9060, -24.0625,  24.8596, -20.6708],\n",
      "        [ 24.8657,  20.2475,  21.1539, -23.4325,  24.8079, -20.5179],\n",
      "        [ 25.7238,  20.8414,  21.6655, -24.1309,  25.2192, -21.0129],\n",
      "        [ 24.7432,  20.2182,  20.7353, -23.9673,  25.5792, -21.0879],\n",
      "        [ 25.3557,  20.2477,  21.3745, -23.9077,  25.2636, -21.0319],\n",
      "        [ 25.2466,  20.1862,  21.0468, -23.3317,  24.4254, -20.2884]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.185379981994629\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9418, 20.1260, 20.6903],\n",
      "        [25.1668, 20.1594, 20.5827],\n",
      "        [25.7257, 21.0284, 22.0452],\n",
      "        [25.1057, 20.4350, 21.3201],\n",
      "        [24.6234, 20.0142, 20.9179],\n",
      "        [24.2854, 19.7404, 20.6296]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.3174, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2490,  25.4007, -20.9621],\n",
      "        [-24.3313,  25.4395, -21.1877],\n",
      "        [-24.0256,  25.3723, -20.9400],\n",
      "        [-24.0188,  25.0896, -20.7250],\n",
      "        [-24.1977,  25.3497, -21.1590],\n",
      "        [-23.7941,  25.2168, -20.7889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9418,  20.1260,  20.6903, -24.2490,  25.4007, -20.9621],\n",
      "        [ 25.1668,  20.1594,  20.5827, -24.3313,  25.4395, -21.1877],\n",
      "        [ 25.7257,  21.0284,  22.0452, -24.0256,  25.3723, -20.9400],\n",
      "        [ 25.1057,  20.4350,  21.3201, -24.0188,  25.0896, -20.7250],\n",
      "        [ 24.6234,  20.0142,  20.9179, -24.1977,  25.3497, -21.1590],\n",
      "        [ 24.2854,  19.7404,  20.6296, -23.7941,  25.2168, -20.7889]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.129754543304443\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6431, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3885, 20.2969, 20.7503],\n",
      "        [25.6451, 20.8662, 21.7705],\n",
      "        [24.6424, 20.4052, 21.0984],\n",
      "        [25.4781, 20.6520, 21.4773],\n",
      "        [25.0212, 20.4167, 21.0634],\n",
      "        [25.3447, 20.1898, 21.1640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.3981, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9593,  24.9067, -20.5855],\n",
      "        [-24.3883,  25.4140, -20.8583],\n",
      "        [-24.0388,  25.3784, -20.5188],\n",
      "        [-23.9143,  25.0042, -21.0670],\n",
      "        [-24.1777,  25.2925, -20.7576],\n",
      "        [-23.6156,  25.3795, -20.5376]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3885,  20.2969,  20.7503, -23.9593,  24.9067, -20.5855],\n",
      "        [ 25.6451,  20.8662,  21.7705, -24.3883,  25.4140, -20.8583],\n",
      "        [ 24.6424,  20.4052,  21.0984, -24.0388,  25.3784, -20.5188],\n",
      "        [ 25.4781,  20.6520,  21.4773, -23.9143,  25.0042, -21.0670],\n",
      "        [ 25.0212,  20.4167,  21.0634, -24.1777,  25.2925, -20.7576],\n",
      "        [ 25.3447,  20.1898,  21.1640, -23.6156,  25.3795, -20.5376]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.126462936401367\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.2915, 20.0015, 20.4025],\n",
      "        [25.1046, 20.5627, 21.0947],\n",
      "        [25.7730, 20.7107, 21.2170],\n",
      "        [25.5420, 20.5523, 21.6570],\n",
      "        [25.1252, 20.5278, 21.6440],\n",
      "        [25.3027, 20.2830, 21.2094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.4260, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9453,  25.2672, -21.5079],\n",
      "        [-24.2026,  25.7352, -20.8452],\n",
      "        [-24.0425,  25.5893, -21.3532],\n",
      "        [-23.5706,  24.7345, -20.3054],\n",
      "        [-23.9455,  25.4792, -21.0671],\n",
      "        [-23.8600,  25.0005, -20.8638]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.2915,  20.0015,  20.4025, -23.9453,  25.2672, -21.5079],\n",
      "        [ 25.1046,  20.5627,  21.0947, -24.2026,  25.7352, -20.8452],\n",
      "        [ 25.7730,  20.7107,  21.2170, -24.0425,  25.5893, -21.3532],\n",
      "        [ 25.5420,  20.5523,  21.6570, -23.5706,  24.7345, -20.3054],\n",
      "        [ 25.1252,  20.5278,  21.6440, -23.9455,  25.4792, -21.0671],\n",
      "        [ 25.3027,  20.2830,  21.2094, -23.8600,  25.0005, -20.8638]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.082520961761475\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4124, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1259, 19.8021, 21.0911],\n",
      "        [25.4557, 21.0754, 21.8630],\n",
      "        [24.9314, 20.0409, 21.2936],\n",
      "        [26.1174, 20.6157, 21.3983],\n",
      "        [24.9699, 20.1685, 21.3430],\n",
      "        [25.4249, 20.4914, 21.4209]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.1151, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8695,  24.7318, -20.5546],\n",
      "        [-24.1622,  25.1759, -20.9065],\n",
      "        [-24.2141,  25.4532, -21.3904],\n",
      "        [-24.0786,  25.3986, -20.7956],\n",
      "        [-24.1127,  25.2814, -20.7113],\n",
      "        [-23.8663,  24.9474, -20.8244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1259,  19.8021,  21.0911, -23.8695,  24.7318, -20.5546],\n",
      "        [ 25.4557,  21.0754,  21.8630, -24.1622,  25.1759, -20.9065],\n",
      "        [ 24.9314,  20.0409,  21.2936, -24.2141,  25.4532, -21.3904],\n",
      "        [ 26.1174,  20.6157,  21.3983, -24.0786,  25.3986, -20.7956],\n",
      "        [ 24.9699,  20.1685,  21.3430, -24.1127,  25.2814, -20.7113],\n",
      "        [ 25.4249,  20.4914,  21.4209, -23.8663,  24.9474, -20.8244]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.104833602905273\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5608, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.1596, 20.6598, 21.1666],\n",
      "        [25.6491, 20.4121, 21.2560],\n",
      "        [25.5939, 20.5557, 21.2281],\n",
      "        [25.4158, 20.4856, 21.2893],\n",
      "        [25.5618, 20.7125, 21.5283],\n",
      "        [25.6868, 20.3545, 21.5682]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.1243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7285,  24.8578, -20.4390],\n",
      "        [-23.8873,  24.9687, -20.9380],\n",
      "        [-23.9878,  25.2120, -20.6995],\n",
      "        [-23.4870,  24.7358, -20.6356],\n",
      "        [-24.0711,  25.0987, -20.4721],\n",
      "        [-23.6089,  25.2473, -20.7594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.1596,  20.6598,  21.1666, -23.7285,  24.8578, -20.4390],\n",
      "        [ 25.6491,  20.4121,  21.2560, -23.8873,  24.9687, -20.9380],\n",
      "        [ 25.5939,  20.5557,  21.2281, -23.9878,  25.2120, -20.6995],\n",
      "        [ 25.4158,  20.4856,  21.2893, -23.4870,  24.7358, -20.6356],\n",
      "        [ 25.5618,  20.7125,  21.5283, -24.0711,  25.0987, -20.4721],\n",
      "        [ 25.6868,  20.3545,  21.5682, -23.6089,  25.2473, -20.7594]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.136941909790039\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5455, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0496, 20.3212, 21.1001],\n",
      "        [25.2778, 20.7709, 21.4015],\n",
      "        [25.2696, 20.2058, 21.1606],\n",
      "        [25.6289, 20.9028, 21.8922],\n",
      "        [25.2473, 20.6280, 21.2359],\n",
      "        [25.7038, 20.4628, 21.6584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.8064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1769,  25.1961, -20.8226],\n",
      "        [-23.9481,  25.7108, -21.0835],\n",
      "        [-24.0998,  25.6438, -20.9479],\n",
      "        [-23.7534,  25.4212, -20.8551],\n",
      "        [-23.1383,  24.6817, -20.4767],\n",
      "        [-23.6657,  25.1339, -21.0667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0496,  20.3212,  21.1001, -24.1769,  25.1961, -20.8226],\n",
      "        [ 25.2778,  20.7709,  21.4015, -23.9481,  25.7108, -21.0835],\n",
      "        [ 25.2696,  20.2058,  21.1606, -24.0998,  25.6438, -20.9479],\n",
      "        [ 25.6289,  20.9028,  21.8922, -23.7534,  25.4212, -20.8551],\n",
      "        [ 25.2473,  20.6280,  21.2359, -23.1383,  24.6817, -20.4767],\n",
      "        [ 25.7038,  20.4628,  21.6584, -23.6657,  25.1339, -21.0667]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.1555986404418945\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1148, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7641, 21.1618, 21.9783],\n",
      "        [25.5149, 20.3527, 21.4069],\n",
      "        [25.2069, 20.6184, 21.9120],\n",
      "        [25.1219, 20.1214, 21.3327],\n",
      "        [25.8074, 20.8602, 21.6497],\n",
      "        [25.1737, 20.8400, 21.4282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.6715, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2174,  25.2144, -21.0111],\n",
      "        [-24.0223,  25.3206, -20.9571],\n",
      "        [-23.7966,  24.9201, -21.0327],\n",
      "        [-24.1888,  25.1462, -20.9521],\n",
      "        [-24.1015,  25.1065, -20.8958],\n",
      "        [-24.0682,  25.1327, -21.1832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7641,  21.1618,  21.9783, -24.2174,  25.2144, -21.0111],\n",
      "        [ 25.5149,  20.3527,  21.4069, -24.0223,  25.3206, -20.9571],\n",
      "        [ 25.2069,  20.6184,  21.9120, -23.7966,  24.9201, -21.0327],\n",
      "        [ 25.1219,  20.1214,  21.3327, -24.1888,  25.1462, -20.9521],\n",
      "        [ 25.8074,  20.8602,  21.6497, -24.1015,  25.1065, -20.8958],\n",
      "        [ 25.1737,  20.8400,  21.4282, -24.0682,  25.1327, -21.1832]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.268641471862793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4034, 20.2793, 21.3637],\n",
      "        [25.7134, 20.6424, 21.4147],\n",
      "        [25.1983, 20.4289, 21.4299],\n",
      "        [24.6974, 20.1946, 20.8012],\n",
      "        [25.1397, 20.2085, 20.7484],\n",
      "        [25.4667, 20.5867, 21.3627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.2704, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4812,  25.7502, -20.8320],\n",
      "        [-24.3160,  25.4210, -21.2096],\n",
      "        [-24.2010,  25.3702, -20.8174],\n",
      "        [-23.4051,  24.9935, -20.9113],\n",
      "        [-24.0418,  25.1546, -20.9956],\n",
      "        [-24.2172,  25.3557, -21.1006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4034,  20.2793,  21.3637, -24.4812,  25.7502, -20.8320],\n",
      "        [ 25.7134,  20.6424,  21.4147, -24.3160,  25.4210, -21.2096],\n",
      "        [ 25.1983,  20.4289,  21.4299, -24.2010,  25.3702, -20.8174],\n",
      "        [ 24.6974,  20.1946,  20.8012, -23.4051,  24.9935, -20.9113],\n",
      "        [ 25.1397,  20.2085,  20.7484, -24.0418,  25.1546, -20.9956],\n",
      "        [ 25.4667,  20.5867,  21.3627, -24.2172,  25.3557, -21.1006]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.217552661895752\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4597, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6457, 21.0715, 21.8731],\n",
      "        [24.8605, 20.4529, 20.5422],\n",
      "        [25.1828, 19.8630, 20.8265],\n",
      "        [25.3337, 20.5770, 21.2968],\n",
      "        [25.8329, 20.8428, 21.3953],\n",
      "        [25.0671, 20.3322, 21.0977]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(16.0877, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0934,  25.4942, -20.9219],\n",
      "        [-24.1606,  25.6530, -21.5340],\n",
      "        [-23.9891,  25.7615, -21.2090],\n",
      "        [-23.9383,  25.2529, -21.1365],\n",
      "        [-23.5683,  25.1017, -20.8707],\n",
      "        [-23.9633,  25.6206, -21.1550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6457,  21.0715,  21.8731, -24.0934,  25.4942, -20.9219],\n",
      "        [ 24.8605,  20.4529,  20.5422, -24.1606,  25.6530, -21.5340],\n",
      "        [ 25.1828,  19.8630,  20.8265, -23.9891,  25.7615, -21.2090],\n",
      "        [ 25.3337,  20.5770,  21.2968, -23.9383,  25.2529, -21.1365],\n",
      "        [ 25.8329,  20.8428,  21.3953, -23.5683,  25.1017, -20.8707],\n",
      "        [ 25.0671,  20.3322,  21.0977, -23.9633,  25.6206, -21.1550]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.261714935302734\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3405, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4924, 20.2496, 21.1549],\n",
      "        [25.0096, 19.9535, 20.5539],\n",
      "        [25.3062, 20.3237, 21.1772],\n",
      "        [25.4067, 20.8265, 21.7282],\n",
      "        [25.6003, 20.6519, 21.6414],\n",
      "        [25.7599, 21.0012, 21.5554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.8272, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7833,  25.7719, -21.5667],\n",
      "        [-24.3315,  25.2979, -20.9183],\n",
      "        [-24.0267,  25.1526, -21.2422],\n",
      "        [-24.1974,  25.2356, -20.7170],\n",
      "        [-23.5268,  25.4597, -20.7989],\n",
      "        [-24.1286,  25.2650, -20.9351]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4924,  20.2496,  21.1549, -24.7833,  25.7719, -21.5667],\n",
      "        [ 25.0096,  19.9535,  20.5539, -24.3315,  25.2979, -20.9183],\n",
      "        [ 25.3062,  20.3237,  21.1772, -24.0267,  25.1526, -21.2422],\n",
      "        [ 25.4067,  20.8265,  21.7282, -24.1974,  25.2356, -20.7170],\n",
      "        [ 25.6003,  20.6519,  21.6414, -23.5268,  25.4597, -20.7989],\n",
      "        [ 25.7599,  21.0012,  21.5554, -24.1286,  25.2650, -20.9351]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.246224403381348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7474, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3916, 20.6465, 21.3719],\n",
      "        [25.4211, 20.7663, 21.0968],\n",
      "        [24.5031, 19.9224, 20.7442],\n",
      "        [25.4249, 20.2816, 21.2552],\n",
      "        [25.0373, 20.1610, 21.1192],\n",
      "        [24.9547, 20.0176, 21.1945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.7406, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3371,  25.5976, -20.7507],\n",
      "        [-23.7824,  25.2428, -20.7139],\n",
      "        [-23.9167,  25.1418, -20.9874],\n",
      "        [-24.4627,  25.3450, -21.2814],\n",
      "        [-24.0816,  24.9751, -20.8371],\n",
      "        [-23.9966,  24.9192, -20.7224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3916,  20.6465,  21.3719, -24.3371,  25.5976, -20.7507],\n",
      "        [ 25.4211,  20.7663,  21.0968, -23.7824,  25.2428, -20.7139],\n",
      "        [ 24.5031,  19.9224,  20.7442, -23.9167,  25.1418, -20.9874],\n",
      "        [ 25.4249,  20.2816,  21.2552, -24.4627,  25.3450, -21.2814],\n",
      "        [ 25.0373,  20.1610,  21.1192, -24.0816,  24.9751, -20.8371],\n",
      "        [ 24.9547,  20.0176,  21.1945, -23.9966,  24.9192, -20.7224]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.222722053527832\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.7928, 20.2318, 20.8202],\n",
      "        [24.8183, 20.4203, 21.1322],\n",
      "        [25.4366, 20.4314, 21.6192],\n",
      "        [25.3126, 20.6265, 21.6730],\n",
      "        [25.3315, 20.5957, 21.6152],\n",
      "        [25.4217, 20.5734, 21.4976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.7503, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2528,  25.4212, -21.4272],\n",
      "        [-24.0594,  25.1820, -20.9031],\n",
      "        [-23.4784,  25.3897, -21.0780],\n",
      "        [-23.9494,  25.7498, -21.0485],\n",
      "        [-24.1421,  25.7028, -20.9769],\n",
      "        [-24.5321,  25.5613, -21.0557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.7928,  20.2318,  20.8202, -24.2528,  25.4212, -21.4272],\n",
      "        [ 24.8183,  20.4203,  21.1322, -24.0594,  25.1820, -20.9031],\n",
      "        [ 25.4366,  20.4314,  21.6192, -23.4784,  25.3897, -21.0780],\n",
      "        [ 25.3126,  20.6265,  21.6730, -23.9494,  25.7498, -21.0485],\n",
      "        [ 25.3315,  20.5957,  21.6152, -24.1421,  25.7028, -20.9769],\n",
      "        [ 25.4217,  20.5734,  21.4976, -24.5321,  25.5613, -21.0557]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.164249897003174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5942, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.9899, 20.2582, 21.2066],\n",
      "        [25.8433, 20.9071, 21.7245],\n",
      "        [24.9294, 20.1259, 21.2152],\n",
      "        [25.2416, 20.6542, 21.4951],\n",
      "        [25.5950, 20.6190, 21.5456],\n",
      "        [25.6909, 20.8855, 21.9241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.4807, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2421,  25.1409, -20.9573],\n",
      "        [-24.3136,  25.7573, -21.4064],\n",
      "        [-23.7500,  24.9774, -21.0620],\n",
      "        [-24.0890,  24.8884, -20.7305],\n",
      "        [-24.0000,  25.3888, -21.5728],\n",
      "        [-24.3366,  25.4796, -21.2841]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.9899,  20.2582,  21.2066, -24.2421,  25.1409, -20.9573],\n",
      "        [ 25.8433,  20.9071,  21.7245, -24.3136,  25.7573, -21.4064],\n",
      "        [ 24.9294,  20.1259,  21.2152, -23.7500,  24.9774, -21.0620],\n",
      "        [ 25.2416,  20.6542,  21.4951, -24.0890,  24.8884, -20.7305],\n",
      "        [ 25.5950,  20.6190,  21.5456, -24.0000,  25.3888, -21.5728],\n",
      "        [ 25.6909,  20.8855,  21.9241, -24.3366,  25.4796, -21.2841]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.171431541442871\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7835, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0585, 20.9733, 21.6788],\n",
      "        [25.1816, 20.6181, 20.9513],\n",
      "        [25.5688, 21.0202, 21.3563],\n",
      "        [25.3526, 20.6496, 21.3355],\n",
      "        [25.3494, 20.3657, 21.6951],\n",
      "        [25.2916, 20.4031, 21.2620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.1562, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5637,  25.6480, -21.4863],\n",
      "        [-24.0471,  25.8947, -21.5611],\n",
      "        [-23.6860,  25.4662, -20.5232],\n",
      "        [-23.8808,  25.4769, -21.2248],\n",
      "        [-24.6934,  25.6109, -21.3459],\n",
      "        [-24.2501,  25.4989, -21.0120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0585,  20.9733,  21.6788, -24.5637,  25.6480, -21.4863],\n",
      "        [ 25.1816,  20.6181,  20.9513, -24.0471,  25.8947, -21.5611],\n",
      "        [ 25.5688,  21.0202,  21.3563, -23.6860,  25.4662, -20.5232],\n",
      "        [ 25.3526,  20.6496,  21.3355, -23.8808,  25.4769, -21.2248],\n",
      "        [ 25.3494,  20.3657,  21.6951, -24.6934,  25.6109, -21.3459],\n",
      "        [ 25.2916,  20.4031,  21.2620, -24.2501,  25.4989, -21.0120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.316871166229248\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5989, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7669, 20.6250, 21.4872],\n",
      "        [25.4250, 20.4107, 21.3200],\n",
      "        [25.5726, 20.2952, 21.8299],\n",
      "        [25.5722, 20.2730, 21.4936],\n",
      "        [24.8460, 19.9680, 20.8542],\n",
      "        [25.0196, 19.9179, 20.7421]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.9127, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2942,  25.6586, -20.8522],\n",
      "        [-24.3348,  25.4006, -20.9619],\n",
      "        [-23.6876,  25.0665, -20.6870],\n",
      "        [-24.0767,  25.4028, -20.9050],\n",
      "        [-24.4650,  25.7444, -21.3332],\n",
      "        [-24.0254,  25.6541, -21.1701]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7669,  20.6250,  21.4872, -24.2942,  25.6586, -20.8522],\n",
      "        [ 25.4250,  20.4107,  21.3200, -24.3348,  25.4006, -20.9619],\n",
      "        [ 25.5726,  20.2952,  21.8299, -23.6876,  25.0665, -20.6870],\n",
      "        [ 25.5722,  20.2730,  21.4936, -24.0767,  25.4028, -20.9050],\n",
      "        [ 24.8460,  19.9680,  20.8542, -24.4650,  25.7444, -21.3332],\n",
      "        [ 25.0196,  19.9179,  20.7421, -24.0254,  25.6541, -21.1701]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.257562637329102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4866, 20.5138, 21.2375],\n",
      "        [24.7324, 20.4230, 21.1241],\n",
      "        [24.9731, 20.6342, 21.3942],\n",
      "        [25.6657, 20.6931, 21.3364],\n",
      "        [25.6052, 20.4637, 21.3482],\n",
      "        [25.3734, 20.0538, 21.3935]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.9885, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2871,  25.0967, -21.2536],\n",
      "        [-24.0551,  24.9207, -21.2213],\n",
      "        [-23.9151,  25.1259, -20.5162],\n",
      "        [-24.0334,  25.1959, -21.2023],\n",
      "        [-24.6663,  26.0827, -21.6147],\n",
      "        [-24.3333,  25.2525, -21.1909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4866,  20.5138,  21.2375, -24.2871,  25.0967, -21.2536],\n",
      "        [ 24.7324,  20.4230,  21.1241, -24.0551,  24.9207, -21.2213],\n",
      "        [ 24.9731,  20.6342,  21.3942, -23.9151,  25.1259, -20.5162],\n",
      "        [ 25.6657,  20.6931,  21.3364, -24.0334,  25.1959, -21.2023],\n",
      "        [ 25.6052,  20.4637,  21.3482, -24.6663,  26.0827, -21.6147],\n",
      "        [ 25.3734,  20.0538,  21.3935, -24.3333,  25.2525, -21.1909]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.220866680145264\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2905, 20.8608, 21.6439],\n",
      "        [25.5272, 20.6127, 21.7539],\n",
      "        [25.1155, 19.9651, 21.1519],\n",
      "        [24.9818, 20.1737, 21.0069],\n",
      "        [25.0206, 20.3075, 20.9619],\n",
      "        [25.2670, 20.4277, 21.5346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.3332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7218,  25.0118, -20.6337],\n",
      "        [-24.5963,  26.0934, -21.4478],\n",
      "        [-24.3997,  25.5825, -21.0576],\n",
      "        [-24.2769,  25.3870, -21.1456],\n",
      "        [-23.9285,  25.2144, -20.5783],\n",
      "        [-24.6799,  26.1354, -21.4533]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2905,  20.8608,  21.6439, -23.7218,  25.0118, -20.6337],\n",
      "        [ 25.5272,  20.6127,  21.7539, -24.5963,  26.0934, -21.4478],\n",
      "        [ 25.1155,  19.9651,  21.1519, -24.3997,  25.5825, -21.0576],\n",
      "        [ 24.9818,  20.1737,  21.0069, -24.2769,  25.3870, -21.1456],\n",
      "        [ 25.0206,  20.3075,  20.9619, -23.9285,  25.2144, -20.5783],\n",
      "        [ 25.2670,  20.4277,  21.5346, -24.6799,  26.1354, -21.4533]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.203471660614014\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[24.4820, 19.9397, 21.0921],\n",
      "        [25.1354, 19.9369, 21.5084],\n",
      "        [25.1182, 19.9861, 20.9685],\n",
      "        [25.3010, 20.9063, 21.3781],\n",
      "        [25.6899, 20.1784, 21.1268],\n",
      "        [25.4266, 20.7827, 21.5190]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6376, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4075,  25.2653, -21.2258],\n",
      "        [-24.0986,  25.1401, -21.0831],\n",
      "        [-23.9413,  25.4445, -20.9299],\n",
      "        [-24.4490,  25.7042, -21.2713],\n",
      "        [-24.6682,  25.8781, -21.5561],\n",
      "        [-24.1302,  25.3497, -20.8990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 24.4820,  19.9397,  21.0921, -24.4075,  25.2653, -21.2258],\n",
      "        [ 25.1354,  19.9369,  21.5084, -24.0986,  25.1401, -21.0831],\n",
      "        [ 25.1182,  19.9861,  20.9685, -23.9413,  25.4445, -20.9299],\n",
      "        [ 25.3010,  20.9063,  21.3781, -24.4490,  25.7042, -21.2713],\n",
      "        [ 25.6899,  20.1784,  21.1268, -24.6682,  25.8781, -21.5561],\n",
      "        [ 25.4266,  20.7827,  21.5190, -24.1302,  25.3497, -20.8990]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.15502405166626\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8179, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2754, 20.5050, 21.5940],\n",
      "        [25.5606, 20.4058, 20.9720],\n",
      "        [25.6221, 20.1241, 21.0787],\n",
      "        [25.6200, 20.5658, 21.1506],\n",
      "        [25.0941, 19.9590, 21.2227],\n",
      "        [26.1115, 21.2318, 22.2936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.0649, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9786,  25.2124, -20.7509],\n",
      "        [-23.5608,  24.6317, -20.2801],\n",
      "        [-24.4448,  25.4723, -21.2601],\n",
      "        [-23.5771,  25.1617, -20.2589],\n",
      "        [-24.3026,  25.3085, -20.8651],\n",
      "        [-24.1622,  25.3156, -21.2358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2754,  20.5050,  21.5940, -23.9786,  25.2124, -20.7509],\n",
      "        [ 25.5606,  20.4058,  20.9720, -23.5608,  24.6317, -20.2801],\n",
      "        [ 25.6221,  20.1241,  21.0787, -24.4448,  25.4723, -21.2601],\n",
      "        [ 25.6200,  20.5658,  21.1506, -23.5771,  25.1617, -20.2589],\n",
      "        [ 25.0941,  19.9590,  21.2227, -24.3026,  25.3085, -20.8651],\n",
      "        [ 26.1115,  21.2318,  22.2936, -24.1622,  25.3156, -21.2358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.210822582244873\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6723, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0257, 20.3708, 21.1469],\n",
      "        [25.3763, 20.1313, 21.2275],\n",
      "        [24.5846, 19.9439, 20.9607],\n",
      "        [25.3216, 20.3035, 21.1098],\n",
      "        [25.6552, 20.5587, 21.7880],\n",
      "        [25.6919, 20.6005, 20.8364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.9589, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2057,  25.4535, -21.0403],\n",
      "        [-24.3134,  25.5900, -21.5129],\n",
      "        [-24.7131,  25.9753, -21.5355],\n",
      "        [-24.2316,  25.3456, -20.9895],\n",
      "        [-24.4855,  25.6200, -21.6847],\n",
      "        [-24.2402,  25.5794, -20.9710]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0257,  20.3708,  21.1469, -24.2057,  25.4535, -21.0403],\n",
      "        [ 25.3763,  20.1313,  21.2275, -24.3134,  25.5900, -21.5129],\n",
      "        [ 24.5846,  19.9439,  20.9607, -24.7131,  25.9753, -21.5355],\n",
      "        [ 25.3216,  20.3035,  21.1098, -24.2316,  25.3456, -20.9895],\n",
      "        [ 25.6552,  20.5587,  21.7880, -24.4855,  25.6200, -21.6847],\n",
      "        [ 25.6919,  20.6005,  20.8364, -24.2402,  25.5794, -20.9710]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.199046611785889\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3671, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4924, 20.5707, 21.6425],\n",
      "        [25.4939, 20.5330, 21.3705],\n",
      "        [25.1934, 20.7444, 21.2096],\n",
      "        [25.9060, 20.9989, 21.6898],\n",
      "        [24.9907, 20.1533, 21.3948],\n",
      "        [25.5915, 20.5567, 21.2924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.1342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0846,  25.6153, -21.3725],\n",
      "        [-24.6725,  26.0013, -21.2473],\n",
      "        [-23.8335,  25.4038, -21.0667],\n",
      "        [-24.2695,  25.9940, -21.4584],\n",
      "        [-24.6604,  25.7924, -21.3378],\n",
      "        [-24.4948,  25.9830, -21.7127]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4924,  20.5707,  21.6425, -24.0846,  25.6153, -21.3725],\n",
      "        [ 25.4939,  20.5330,  21.3705, -24.6725,  26.0013, -21.2473],\n",
      "        [ 25.1934,  20.7444,  21.2096, -23.8335,  25.4038, -21.0667],\n",
      "        [ 25.9060,  20.9989,  21.6898, -24.2695,  25.9940, -21.4584],\n",
      "        [ 24.9907,  20.1533,  21.3948, -24.6604,  25.7924, -21.3378],\n",
      "        [ 25.5915,  20.5567,  21.2924, -24.4948,  25.9830, -21.7127]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.264760971069336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6293, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2290, 20.3772, 20.9265],\n",
      "        [25.3317, 20.8172, 21.7942],\n",
      "        [25.5911, 20.9628, 21.8375],\n",
      "        [25.7931, 20.5953, 21.6366],\n",
      "        [25.8151, 20.8550, 21.4299],\n",
      "        [25.4471, 20.6807, 21.3039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5574, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9825,  25.8070, -20.8500],\n",
      "        [-24.0649,  25.4806, -21.3820],\n",
      "        [-24.2842,  25.7465, -21.2209],\n",
      "        [-23.8650,  25.2210, -20.9060],\n",
      "        [-23.9872,  25.8492, -21.4317],\n",
      "        [-23.9465,  25.4503, -21.2957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2290,  20.3772,  20.9265, -23.9825,  25.8070, -20.8500],\n",
      "        [ 25.3317,  20.8172,  21.7942, -24.0649,  25.4806, -21.3820],\n",
      "        [ 25.5911,  20.9628,  21.8375, -24.2842,  25.7465, -21.2209],\n",
      "        [ 25.7931,  20.5953,  21.6366, -23.8650,  25.2210, -20.9060],\n",
      "        [ 25.8151,  20.8550,  21.4299, -23.9872,  25.8492, -21.4317],\n",
      "        [ 25.4471,  20.6807,  21.3039, -23.9465,  25.4503, -21.2957]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.203707695007324\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5195, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4864, 20.4820, 21.1740],\n",
      "        [25.5341, 20.8998, 21.4146],\n",
      "        [25.3885, 20.7617, 21.5586],\n",
      "        [25.1653, 20.2524, 21.2952],\n",
      "        [25.3156, 20.8469, 21.7507],\n",
      "        [24.9095, 19.9456, 21.0053]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.5495, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6866,  25.6218, -21.0879],\n",
      "        [-24.4375,  25.5765, -21.5032],\n",
      "        [-23.4225,  24.9427, -20.9811],\n",
      "        [-23.9986,  25.5391, -20.8894],\n",
      "        [-24.3834,  25.7418, -21.5595],\n",
      "        [-23.7848,  25.1258, -20.6445]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4864,  20.4820,  21.1740, -24.6866,  25.6218, -21.0879],\n",
      "        [ 25.5341,  20.8998,  21.4146, -24.4375,  25.5765, -21.5032],\n",
      "        [ 25.3885,  20.7617,  21.5586, -23.4225,  24.9427, -20.9811],\n",
      "        [ 25.1653,  20.2524,  21.2952, -23.9986,  25.5391, -20.8894],\n",
      "        [ 25.3156,  20.8469,  21.7507, -24.3834,  25.7418, -21.5595],\n",
      "        [ 24.9095,  19.9456,  21.0053, -23.7848,  25.1258, -20.6445]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.256747245788574\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8471, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9995, 20.6362, 21.5996],\n",
      "        [25.1442, 20.1889, 21.0154],\n",
      "        [25.5740, 20.5604, 21.1209],\n",
      "        [25.7398, 20.6198, 21.6050],\n",
      "        [25.7126, 20.4637, 21.6908],\n",
      "        [25.3885, 20.5985, 21.3143]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3170,  25.5357, -21.0910],\n",
      "        [-24.3523,  25.6227, -21.3441],\n",
      "        [-24.1448,  25.4716, -21.1474],\n",
      "        [-24.3995,  25.7362, -21.5085],\n",
      "        [-24.6570,  25.5411, -21.4025],\n",
      "        [-23.9900,  25.2941, -21.0833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9995,  20.6362,  21.5996, -24.3170,  25.5357, -21.0910],\n",
      "        [ 25.1442,  20.1889,  21.0154, -24.3523,  25.6227, -21.3441],\n",
      "        [ 25.5740,  20.5604,  21.1209, -24.1448,  25.4716, -21.1474],\n",
      "        [ 25.7398,  20.6198,  21.6050, -24.3995,  25.7362, -21.5085],\n",
      "        [ 25.7126,  20.4637,  21.6908, -24.6570,  25.5411, -21.4025],\n",
      "        [ 25.3885,  20.5985,  21.3143, -23.9900,  25.2941, -21.0833]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.294472694396973\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3102, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3632, 20.6081, 21.6573],\n",
      "        [25.7839, 20.9660, 21.9134],\n",
      "        [25.4196, 20.8068, 21.8416],\n",
      "        [25.4455, 20.8754, 21.3468],\n",
      "        [25.0607, 20.7486, 21.3130],\n",
      "        [25.8567, 20.9608, 21.7052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.7720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8946,  24.9114, -20.8918],\n",
      "        [-24.7424,  25.8238, -21.2902],\n",
      "        [-24.0141,  25.0338, -21.2304],\n",
      "        [-24.5309,  25.8825, -21.3401],\n",
      "        [-24.1951,  25.3867, -21.1144],\n",
      "        [-24.2513,  25.1929, -20.9520]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3632,  20.6081,  21.6573, -23.8946,  24.9114, -20.8918],\n",
      "        [ 25.7839,  20.9660,  21.9134, -24.7424,  25.8238, -21.2902],\n",
      "        [ 25.4196,  20.8068,  21.8416, -24.0141,  25.0338, -21.2304],\n",
      "        [ 25.4455,  20.8754,  21.3468, -24.5309,  25.8825, -21.3401],\n",
      "        [ 25.0607,  20.7486,  21.3130, -24.1951,  25.3867, -21.1144],\n",
      "        [ 25.8567,  20.9608,  21.7052, -24.2513,  25.1929, -20.9520]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.222993850708008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1070, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0214, 20.3426, 21.2014],\n",
      "        [25.4469, 20.6245, 21.6567],\n",
      "        [25.4651, 20.5075, 21.1886],\n",
      "        [25.2857, 20.7340, 21.3815],\n",
      "        [25.6651, 20.9423, 21.5700],\n",
      "        [25.8130, 20.9141, 21.7037]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.8843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8107,  25.5556, -20.7846],\n",
      "        [-24.2152,  25.7951, -21.3505],\n",
      "        [-24.0762,  26.0945, -21.6157],\n",
      "        [-24.2809,  25.3239, -20.9898],\n",
      "        [-24.1883,  25.7201, -21.4151],\n",
      "        [-24.1489,  25.5579, -21.0013]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0214,  20.3426,  21.2014, -23.8107,  25.5556, -20.7846],\n",
      "        [ 25.4469,  20.6245,  21.6567, -24.2152,  25.7951, -21.3505],\n",
      "        [ 25.4651,  20.5075,  21.1886, -24.0762,  26.0945, -21.6157],\n",
      "        [ 25.2857,  20.7340,  21.3815, -24.2809,  25.3239, -20.9898],\n",
      "        [ 25.6651,  20.9423,  21.5700, -24.1883,  25.7201, -21.4151],\n",
      "        [ 25.8130,  20.9141,  21.7037, -24.1489,  25.5579, -21.0013]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.194617748260498\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4330, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1463, 21.0212, 21.9125],\n",
      "        [25.4331, 20.6436, 21.7365],\n",
      "        [25.7267, 20.4611, 21.6750],\n",
      "        [25.5113, 20.7197, 21.3372],\n",
      "        [25.3400, 20.4280, 21.0384],\n",
      "        [25.2977, 20.8976, 21.8023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.6519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4602,  25.7784, -21.5163],\n",
      "        [-24.7706,  25.8847, -21.3224],\n",
      "        [-23.8302,  24.8797, -20.3629],\n",
      "        [-24.0380,  25.3880, -20.9808],\n",
      "        [-24.1234,  25.5262, -21.3041],\n",
      "        [-24.3490,  25.3667, -21.1970]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1463,  21.0212,  21.9125, -24.4602,  25.7784, -21.5163],\n",
      "        [ 25.4331,  20.6436,  21.7365, -24.7706,  25.8847, -21.3224],\n",
      "        [ 25.7267,  20.4611,  21.6750, -23.8302,  24.8797, -20.3629],\n",
      "        [ 25.5113,  20.7197,  21.3372, -24.0380,  25.3880, -20.9808],\n",
      "        [ 25.3400,  20.4280,  21.0384, -24.1234,  25.5262, -21.3041],\n",
      "        [ 25.2977,  20.8976,  21.8023, -24.3490,  25.3667, -21.1970]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.359360218048096\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7207, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4175, 20.6423, 21.4630],\n",
      "        [25.9997, 20.8804, 21.6457],\n",
      "        [25.9856, 20.9084, 21.3752],\n",
      "        [25.6489, 19.9609, 21.3046],\n",
      "        [25.7040, 21.1636, 21.6852],\n",
      "        [26.0716, 21.1406, 21.8205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.3595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2336,  25.1027, -21.0340],\n",
      "        [-23.9359,  24.7865, -21.3946],\n",
      "        [-24.1586,  25.7732, -21.5326],\n",
      "        [-24.0992,  25.3966, -21.2090],\n",
      "        [-24.0529,  25.7494, -21.3650],\n",
      "        [-24.2280,  25.4963, -20.7891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4175,  20.6423,  21.4630, -24.2336,  25.1027, -21.0340],\n",
      "        [ 25.9997,  20.8804,  21.6457, -23.9359,  24.7865, -21.3946],\n",
      "        [ 25.9856,  20.9084,  21.3752, -24.1586,  25.7732, -21.5326],\n",
      "        [ 25.6489,  19.9609,  21.3046, -24.0992,  25.3966, -21.2090],\n",
      "        [ 25.7040,  21.1636,  21.6852, -24.0529,  25.7494, -21.3650],\n",
      "        [ 26.0716,  21.1406,  21.8205, -24.2280,  25.4963, -20.7891]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.245628833770752\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6623, 20.5288, 21.8259],\n",
      "        [25.9769, 21.2303, 21.6192],\n",
      "        [25.2064, 20.4272, 21.2831],\n",
      "        [25.0713, 20.4338, 21.3906],\n",
      "        [25.8719, 21.2032, 21.7736],\n",
      "        [25.2785, 20.1012, 21.0945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.6393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6064,  25.8697, -21.5659],\n",
      "        [-24.2166,  25.3253, -21.2567],\n",
      "        [-24.5705,  25.4233, -20.7614],\n",
      "        [-24.7054,  25.6791, -21.3003],\n",
      "        [-24.6101,  25.7458, -21.3932],\n",
      "        [-24.4647,  25.2962, -21.2127]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6623,  20.5288,  21.8259, -24.6064,  25.8697, -21.5659],\n",
      "        [ 25.9769,  21.2303,  21.6192, -24.2166,  25.3253, -21.2567],\n",
      "        [ 25.2064,  20.4272,  21.2831, -24.5705,  25.4233, -20.7614],\n",
      "        [ 25.0713,  20.4338,  21.3906, -24.7054,  25.6791, -21.3003],\n",
      "        [ 25.8719,  21.2032,  21.7736, -24.6101,  25.7458, -21.3932],\n",
      "        [ 25.2785,  20.1012,  21.0945, -24.4647,  25.2962, -21.2127]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.326473712921143\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1275, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8980, 20.6955, 21.5888],\n",
      "        [25.2300, 20.4041, 21.4358],\n",
      "        [25.6656, 20.7468, 21.9278],\n",
      "        [25.9625, 20.9580, 21.8218],\n",
      "        [25.8910, 20.7661, 21.8958],\n",
      "        [25.3005, 20.6100, 21.4570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.1351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.8175,  25.0747, -20.9731],\n",
      "        [-24.3354,  25.8544, -21.5750],\n",
      "        [-24.7782,  26.2145, -21.8772],\n",
      "        [-24.7015,  26.0725, -22.0967],\n",
      "        [-24.0843,  25.3001, -20.9733],\n",
      "        [-23.8642,  24.8720, -20.9512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8980,  20.6955,  21.5888, -23.8175,  25.0747, -20.9731],\n",
      "        [ 25.2300,  20.4041,  21.4358, -24.3354,  25.8544, -21.5750],\n",
      "        [ 25.6656,  20.7468,  21.9278, -24.7782,  26.2145, -21.8772],\n",
      "        [ 25.9625,  20.9580,  21.8218, -24.7015,  26.0725, -22.0967],\n",
      "        [ 25.8910,  20.7661,  21.8958, -24.0843,  25.3001, -20.9733],\n",
      "        [ 25.3005,  20.6100,  21.4570, -23.8642,  24.8720, -20.9512]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.26556921005249\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6729, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0997, 21.0287, 21.6205],\n",
      "        [24.9231, 20.4822, 21.1400],\n",
      "        [25.1181, 20.3984, 21.0237],\n",
      "        [24.7476, 20.3533, 20.9154],\n",
      "        [25.5154, 20.5322, 21.2989],\n",
      "        [25.5653, 20.6625, 21.1809]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.9302, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5066,  25.4988, -21.3497],\n",
      "        [-24.6341,  25.7282, -21.5807],\n",
      "        [-24.4689,  25.5818, -21.3964],\n",
      "        [-24.5214,  25.6949, -21.5989],\n",
      "        [-24.1500,  25.5834, -21.1750],\n",
      "        [-24.3868,  25.4736, -21.2426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0997,  21.0287,  21.6205, -24.5066,  25.4988, -21.3497],\n",
      "        [ 24.9231,  20.4822,  21.1400, -24.6341,  25.7282, -21.5807],\n",
      "        [ 25.1181,  20.3984,  21.0237, -24.4689,  25.5818, -21.3964],\n",
      "        [ 24.7476,  20.3533,  20.9154, -24.5214,  25.6949, -21.5989],\n",
      "        [ 25.5154,  20.5322,  21.2989, -24.1500,  25.5834, -21.1750],\n",
      "        [ 25.5653,  20.6625,  21.1809, -24.3868,  25.4736, -21.2426]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.338723182678223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8415, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9042, 21.3348, 21.8030],\n",
      "        [25.7213, 21.0087, 21.9012],\n",
      "        [25.4295, 20.4702, 21.6119],\n",
      "        [26.0621, 21.1771, 21.7518],\n",
      "        [25.7175, 20.6435, 22.0446],\n",
      "        [25.8857, 21.2031, 21.7931]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.7221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.0624,  25.4460, -20.7288],\n",
      "        [-24.2265,  25.7747, -21.1703],\n",
      "        [-24.2974,  25.0412, -20.9783],\n",
      "        [-24.5867,  26.2190, -21.6396],\n",
      "        [-24.2758,  25.7400, -21.2280],\n",
      "        [-24.0392,  25.2947, -21.0686]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9042,  21.3348,  21.8030, -24.0624,  25.4460, -20.7288],\n",
      "        [ 25.7213,  21.0087,  21.9012, -24.2265,  25.7747, -21.1703],\n",
      "        [ 25.4295,  20.4702,  21.6119, -24.2974,  25.0412, -20.9783],\n",
      "        [ 26.0621,  21.1771,  21.7518, -24.5867,  26.2190, -21.6396],\n",
      "        [ 25.7175,  20.6435,  22.0446, -24.2758,  25.7400, -21.2280],\n",
      "        [ 25.8857,  21.2031,  21.7931, -24.0392,  25.2947, -21.0686]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.315062999725342\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5943, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3314, 20.8974, 21.1982],\n",
      "        [25.5111, 20.3491, 21.5479],\n",
      "        [25.5534, 21.0081, 21.6400],\n",
      "        [25.6287, 20.3694, 21.5132],\n",
      "        [25.4372, 20.4556, 20.9818],\n",
      "        [25.2137, 20.3683, 21.3548]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.2456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0320,  25.9544, -21.7303],\n",
      "        [-23.9391,  25.7313, -21.0934],\n",
      "        [-23.3864,  25.1631, -20.6692],\n",
      "        [-23.5057,  24.7455, -20.9372],\n",
      "        [-24.4069,  25.5704, -21.1875],\n",
      "        [-24.8900,  26.4506, -21.9759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3314,  20.8974,  21.1982, -25.0320,  25.9544, -21.7303],\n",
      "        [ 25.5111,  20.3491,  21.5479, -23.9391,  25.7313, -21.0934],\n",
      "        [ 25.5534,  21.0081,  21.6400, -23.3864,  25.1631, -20.6692],\n",
      "        [ 25.6287,  20.3694,  21.5132, -23.5057,  24.7455, -20.9372],\n",
      "        [ 25.4372,  20.4556,  20.9818, -24.4069,  25.5704, -21.1875],\n",
      "        [ 25.2137,  20.3683,  21.3548, -24.8900,  26.4506, -21.9759]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.322521209716797\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8100, 20.8212, 21.4635],\n",
      "        [24.9902, 20.2686, 21.5773],\n",
      "        [25.2451, 20.4454, 21.6064],\n",
      "        [25.9619, 20.8145, 21.2920],\n",
      "        [25.7769, 20.9132, 21.7001],\n",
      "        [25.5231, 20.5207, 21.6909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.8787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5722,  25.9224, -21.7383],\n",
      "        [-24.5864,  25.7545, -21.1414],\n",
      "        [-24.1170,  25.8266, -21.1677],\n",
      "        [-24.3907,  25.7310, -21.2267],\n",
      "        [-24.2111,  25.6044, -20.9428],\n",
      "        [-23.6941,  25.0230, -21.0189]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8100,  20.8212,  21.4635, -24.5722,  25.9224, -21.7383],\n",
      "        [ 24.9902,  20.2686,  21.5773, -24.5864,  25.7545, -21.1414],\n",
      "        [ 25.2451,  20.4454,  21.6064, -24.1170,  25.8266, -21.1677],\n",
      "        [ 25.9619,  20.8145,  21.2920, -24.3907,  25.7310, -21.2267],\n",
      "        [ 25.7769,  20.9132,  21.7001, -24.2111,  25.6044, -20.9428],\n",
      "        [ 25.5231,  20.5207,  21.6909, -23.6941,  25.0230, -21.0189]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.342710494995117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5489, 20.6096, 21.7860],\n",
      "        [26.3399, 21.1278, 22.0410],\n",
      "        [25.6938, 20.8111, 21.5342],\n",
      "        [25.2484, 20.5642, 21.4949],\n",
      "        [25.9205, 20.9984, 21.3596],\n",
      "        [25.3687, 20.8359, 21.3650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.7824, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3825,  25.7404, -21.6280],\n",
      "        [-24.0782,  25.4682, -21.1955],\n",
      "        [-24.6300,  25.6658, -21.3690],\n",
      "        [-24.3261,  25.2605, -21.2043],\n",
      "        [-23.7578,  25.3085, -21.0183],\n",
      "        [-23.6944,  25.5871, -20.6119]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5489,  20.6096,  21.7860, -24.3825,  25.7404, -21.6280],\n",
      "        [ 26.3399,  21.1278,  22.0410, -24.0782,  25.4682, -21.1955],\n",
      "        [ 25.6938,  20.8111,  21.5342, -24.6300,  25.6658, -21.3690],\n",
      "        [ 25.2484,  20.5642,  21.4949, -24.3261,  25.2605, -21.2043],\n",
      "        [ 25.9205,  20.9984,  21.3596, -23.7578,  25.3085, -21.0183],\n",
      "        [ 25.3687,  20.8359,  21.3650, -23.6944,  25.5871, -20.6119]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.3221611976623535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5496, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4183, 20.8255, 21.4475],\n",
      "        [25.4938, 20.8407, 21.2759],\n",
      "        [24.3241, 19.8114, 20.8583],\n",
      "        [25.6856, 20.6454, 21.6162],\n",
      "        [25.2847, 20.6661, 21.7150],\n",
      "        [25.1958, 20.4403, 21.1179]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.9605, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7879,  26.0338, -21.6088],\n",
      "        [-24.1698,  25.3788, -21.4321],\n",
      "        [-23.9437,  25.3371, -20.9260],\n",
      "        [-24.5597,  25.8613, -21.3381],\n",
      "        [-24.5149,  25.5831, -21.2346],\n",
      "        [-24.4660,  25.5279, -20.9198]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4183,  20.8255,  21.4475, -24.7879,  26.0338, -21.6088],\n",
      "        [ 25.4938,  20.8407,  21.2759, -24.1698,  25.3788, -21.4321],\n",
      "        [ 24.3241,  19.8114,  20.8583, -23.9437,  25.3371, -20.9260],\n",
      "        [ 25.6856,  20.6454,  21.6162, -24.5597,  25.8613, -21.3381],\n",
      "        [ 25.2847,  20.6661,  21.7150, -24.5149,  25.5831, -21.2346],\n",
      "        [ 25.1958,  20.4403,  21.1179, -24.4660,  25.5279, -20.9198]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.332644462585449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9674, 20.8809, 22.0424],\n",
      "        [26.0019, 20.7485, 21.8703],\n",
      "        [25.5763, 21.0655, 21.8682],\n",
      "        [26.0916, 21.2673, 22.0312],\n",
      "        [25.2849, 20.7859, 21.5114],\n",
      "        [25.4990, 20.6772, 21.4874]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.6361, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5040,  25.6128, -21.6326],\n",
      "        [-23.9339,  25.5448, -21.1220],\n",
      "        [-24.1678,  25.5449, -21.3747],\n",
      "        [-23.8680,  25.1627, -20.6555],\n",
      "        [-24.0654,  25.6472, -21.3617],\n",
      "        [-24.2084,  25.5564, -21.0908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9674,  20.8809,  22.0424, -24.5040,  25.6128, -21.6326],\n",
      "        [ 26.0019,  20.7485,  21.8703, -23.9339,  25.5448, -21.1220],\n",
      "        [ 25.5763,  21.0655,  21.8682, -24.1678,  25.5449, -21.3747],\n",
      "        [ 26.0916,  21.2673,  22.0312, -23.8680,  25.1627, -20.6555],\n",
      "        [ 25.2849,  20.7859,  21.5114, -24.0654,  25.6472, -21.3617],\n",
      "        [ 25.4990,  20.6772,  21.4874, -24.2084,  25.5564, -21.0908]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.368174076080322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8435, 21.2019, 21.6062],\n",
      "        [25.4744, 20.7288, 21.6521],\n",
      "        [25.0634, 20.3208, 21.3078],\n",
      "        [26.3400, 21.2698, 22.3173],\n",
      "        [25.0741, 20.1737, 20.8120],\n",
      "        [25.1838, 20.0959, 21.6126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.2301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6650,  26.1580, -21.4662],\n",
      "        [-24.4850,  25.4211, -21.0845],\n",
      "        [-24.3147,  25.5216, -21.5167],\n",
      "        [-24.2746,  25.3136, -21.3542],\n",
      "        [-24.2630,  25.7872, -21.4840],\n",
      "        [-23.8923,  25.0766, -21.4554]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8435,  21.2019,  21.6062, -24.6650,  26.1580, -21.4662],\n",
      "        [ 25.4744,  20.7288,  21.6521, -24.4850,  25.4211, -21.0845],\n",
      "        [ 25.0634,  20.3208,  21.3078, -24.3147,  25.5216, -21.5167],\n",
      "        [ 26.3400,  21.2698,  22.3173, -24.2746,  25.3136, -21.3542],\n",
      "        [ 25.0741,  20.1737,  20.8120, -24.2630,  25.7872, -21.4840],\n",
      "        [ 25.1838,  20.0959,  21.6126, -23.8923,  25.0766, -21.4554]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.374989032745361\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8122, 20.8790, 21.7587],\n",
      "        [25.0916, 20.8777, 21.8265],\n",
      "        [25.5426, 20.6281, 21.8632],\n",
      "        [25.9553, 20.8558, 21.5337],\n",
      "        [25.7900, 20.8394, 21.7485],\n",
      "        [25.3641, 20.5464, 21.0848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3588,  25.9643, -21.3972],\n",
      "        [-23.8814,  25.5690, -20.9627],\n",
      "        [-24.1749,  25.5314, -21.4007],\n",
      "        [-23.7471,  24.9319, -20.8792],\n",
      "        [-24.7137,  25.7995, -21.9266],\n",
      "        [-24.3642,  25.6336, -21.0553]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8122,  20.8790,  21.7587, -24.3588,  25.9643, -21.3972],\n",
      "        [ 25.0916,  20.8777,  21.8265, -23.8814,  25.5690, -20.9627],\n",
      "        [ 25.5426,  20.6281,  21.8632, -24.1749,  25.5314, -21.4007],\n",
      "        [ 25.9553,  20.8558,  21.5337, -23.7471,  24.9319, -20.8792],\n",
      "        [ 25.7900,  20.8394,  21.7485, -24.7137,  25.7995, -21.9266],\n",
      "        [ 25.3641,  20.5464,  21.0848, -24.3642,  25.6336, -21.0553]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.352130889892578\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7168, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9726, 20.6757, 21.8294],\n",
      "        [25.4511, 20.7846, 21.3385],\n",
      "        [25.3670, 20.8311, 21.7154],\n",
      "        [25.3608, 20.7502, 21.1164],\n",
      "        [24.9960, 20.2401, 21.1044],\n",
      "        [25.6587, 20.9002, 21.4051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.7587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6378,  26.0251, -21.5232],\n",
      "        [-24.8938,  25.9283, -21.4724],\n",
      "        [-24.2656,  25.4757, -21.5545],\n",
      "        [-24.5869,  26.0855, -21.3852],\n",
      "        [-24.4787,  25.7810, -21.3570],\n",
      "        [-24.0436,  24.9389, -21.0330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9726,  20.6757,  21.8294, -24.6378,  26.0251, -21.5232],\n",
      "        [ 25.4511,  20.7846,  21.3385, -24.8938,  25.9283, -21.4724],\n",
      "        [ 25.3670,  20.8311,  21.7154, -24.2656,  25.4757, -21.5545],\n",
      "        [ 25.3608,  20.7502,  21.1164, -24.5869,  26.0855, -21.3852],\n",
      "        [ 24.9960,  20.2401,  21.1044, -24.4787,  25.7810, -21.3570],\n",
      "        [ 25.6587,  20.9002,  21.4051, -24.0436,  24.9389, -21.0330]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.373623847961426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0037, 20.9198, 21.8333],\n",
      "        [25.9869, 21.2001, 21.9277],\n",
      "        [25.9648, 20.9300, 21.4478],\n",
      "        [25.1989, 20.2531, 21.2243],\n",
      "        [25.6771, 20.5787, 21.3213],\n",
      "        [26.2083, 21.5785, 22.0149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2953,  25.4705, -21.1423],\n",
      "        [-24.4902,  25.9142, -21.4189],\n",
      "        [-24.4076,  25.5356, -21.1346],\n",
      "        [-24.7754,  25.5255, -21.5305],\n",
      "        [-24.5514,  26.0080, -21.3695],\n",
      "        [-24.2038,  25.9810, -21.2327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0037,  20.9198,  21.8333, -24.2953,  25.4705, -21.1423],\n",
      "        [ 25.9869,  21.2001,  21.9277, -24.4902,  25.9142, -21.4189],\n",
      "        [ 25.9648,  20.9300,  21.4478, -24.4076,  25.5356, -21.1346],\n",
      "        [ 25.1989,  20.2531,  21.2243, -24.7754,  25.5255, -21.5305],\n",
      "        [ 25.6771,  20.5787,  21.3213, -24.5514,  26.0080, -21.3695],\n",
      "        [ 26.2083,  21.5785,  22.0149, -24.2038,  25.9810, -21.2327]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.344089508056641\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2446, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2886, 20.0359, 21.1588],\n",
      "        [25.1136, 20.2472, 21.0369],\n",
      "        [25.9095, 20.8404, 22.1321],\n",
      "        [25.0647, 20.4748, 21.2409],\n",
      "        [25.7187, 20.2967, 21.4344],\n",
      "        [25.9320, 21.1836, 21.8550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.1935, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2468,  26.0235, -21.6075],\n",
      "        [-24.2673,  25.7263, -21.4581],\n",
      "        [-23.5845,  24.7844, -20.7556],\n",
      "        [-24.5668,  25.8870, -21.7190],\n",
      "        [-24.9048,  25.8861, -21.9349],\n",
      "        [-24.4765,  26.2267, -21.5108]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2886,  20.0359,  21.1588, -24.2468,  26.0235, -21.6075],\n",
      "        [ 25.1136,  20.2472,  21.0369, -24.2673,  25.7263, -21.4581],\n",
      "        [ 25.9095,  20.8404,  22.1321, -23.5845,  24.7844, -20.7556],\n",
      "        [ 25.0647,  20.4748,  21.2409, -24.5668,  25.8870, -21.7190],\n",
      "        [ 25.7187,  20.2967,  21.4344, -24.9048,  25.8861, -21.9349],\n",
      "        [ 25.9320,  21.1836,  21.8550, -24.4765,  26.2267, -21.5108]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.278897285461426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4583, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8534, 21.1750, 21.9401],\n",
      "        [26.2777, 21.0169, 21.6329],\n",
      "        [25.6588, 20.5092, 22.0401],\n",
      "        [25.7453, 20.9054, 21.8016],\n",
      "        [26.4398, 21.2983, 22.0418],\n",
      "        [25.4631, 20.6664, 21.5397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.6166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4808,  25.6147, -21.1521],\n",
      "        [-24.1366,  25.6569, -21.4055],\n",
      "        [-24.8139,  26.0020, -21.4347],\n",
      "        [-24.2346,  25.3065, -21.1299],\n",
      "        [-24.3550,  25.7014, -21.5021],\n",
      "        [-24.5478,  25.4037, -21.1156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8534,  21.1750,  21.9401, -24.4808,  25.6147, -21.1521],\n",
      "        [ 26.2777,  21.0169,  21.6329, -24.1366,  25.6569, -21.4055],\n",
      "        [ 25.6588,  20.5092,  22.0401, -24.8139,  26.0020, -21.4347],\n",
      "        [ 25.7453,  20.9054,  21.8016, -24.2346,  25.3065, -21.1299],\n",
      "        [ 26.4398,  21.2983,  22.0418, -24.3550,  25.7014, -21.5021],\n",
      "        [ 25.4631,  20.6664,  21.5397, -24.5478,  25.4037, -21.1156]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.364723205566406\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5619, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0242, 20.8045, 22.0172],\n",
      "        [25.3969, 20.7392, 21.4269],\n",
      "        [25.7130, 20.9305, 21.7675],\n",
      "        [25.9248, 21.0114, 21.5876],\n",
      "        [26.0134, 20.9786, 21.9022],\n",
      "        [26.1091, 21.4917, 21.9186]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.7089, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1675,  25.5477, -21.0798],\n",
      "        [-24.2212,  25.3599, -21.0840],\n",
      "        [-24.2375,  25.8003, -21.1750],\n",
      "        [-25.0982,  26.0458, -21.8551],\n",
      "        [-24.3394,  25.4357, -20.8961],\n",
      "        [-24.0616,  25.1700, -20.8608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0242,  20.8045,  22.0172, -24.1675,  25.5477, -21.0798],\n",
      "        [ 25.3969,  20.7392,  21.4269, -24.2212,  25.3599, -21.0840],\n",
      "        [ 25.7130,  20.9305,  21.7675, -24.2375,  25.8003, -21.1750],\n",
      "        [ 25.9248,  21.0114,  21.5876, -25.0982,  26.0458, -21.8551],\n",
      "        [ 26.0134,  20.9786,  21.9022, -24.3394,  25.4357, -20.8961],\n",
      "        [ 26.1091,  21.4917,  21.9186, -24.0616,  25.1700, -20.8608]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.351711273193359\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4976, 21.0443, 21.6963],\n",
      "        [25.5649, 20.7767, 21.5813],\n",
      "        [25.1730, 20.6863, 21.3523],\n",
      "        [25.7086, 20.4687, 21.1164],\n",
      "        [25.7835, 20.8275, 21.7061],\n",
      "        [25.3762, 20.5164, 21.7612]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.2079, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1418,  25.3426, -21.1437],\n",
      "        [-24.8153,  26.3920, -22.0016],\n",
      "        [-24.8682,  26.5387, -21.8358],\n",
      "        [-24.2358,  25.7318, -21.2719],\n",
      "        [-24.0818,  25.7027, -21.0816],\n",
      "        [-24.3944,  25.4094, -21.2910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4976,  21.0443,  21.6963, -24.1418,  25.3426, -21.1437],\n",
      "        [ 25.5649,  20.7767,  21.5813, -24.8153,  26.3920, -22.0016],\n",
      "        [ 25.1730,  20.6863,  21.3523, -24.8682,  26.5387, -21.8358],\n",
      "        [ 25.7086,  20.4687,  21.1164, -24.2358,  25.7318, -21.2719],\n",
      "        [ 25.7835,  20.8275,  21.7061, -24.0818,  25.7027, -21.0816],\n",
      "        [ 25.3762,  20.5164,  21.7612, -24.3944,  25.4094, -21.2910]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.3131279945373535\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4245, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3223, 20.6268, 21.8709],\n",
      "        [26.3500, 20.8931, 22.0977],\n",
      "        [25.4876, 20.6483, 21.6210],\n",
      "        [25.6733, 21.1648, 21.6779],\n",
      "        [25.3950, 20.5278, 21.3022],\n",
      "        [25.8910, 20.7381, 21.5275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.2295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2362,  25.6659, -21.1608],\n",
      "        [-24.9472,  26.0207, -21.4954],\n",
      "        [-24.2430,  25.6667, -21.2238],\n",
      "        [-23.9520,  25.6757, -20.8322],\n",
      "        [-24.5756,  25.6564, -21.3822],\n",
      "        [-24.7662,  25.9714, -21.9530]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3223,  20.6268,  21.8709, -24.2362,  25.6659, -21.1608],\n",
      "        [ 26.3500,  20.8931,  22.0977, -24.9472,  26.0207, -21.4954],\n",
      "        [ 25.4876,  20.6483,  21.6210, -24.2430,  25.6667, -21.2238],\n",
      "        [ 25.6733,  21.1648,  21.6779, -23.9520,  25.6757, -20.8322],\n",
      "        [ 25.3950,  20.5278,  21.3022, -24.5756,  25.6564, -21.3822],\n",
      "        [ 25.8910,  20.7381,  21.5275, -24.7662,  25.9714, -21.9530]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.314333915710449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1976, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7454, 20.7872, 21.4366],\n",
      "        [25.4277, 20.8836, 21.5589],\n",
      "        [24.9502, 20.6837, 21.3281],\n",
      "        [25.5031, 20.6780, 21.8488],\n",
      "        [25.2450, 20.5863, 21.4201],\n",
      "        [25.9613, 20.7504, 22.1568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.2242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7655,  25.8238, -21.4609],\n",
      "        [-24.1688,  25.7082, -21.3001],\n",
      "        [-24.5553,  25.4154, -21.0425],\n",
      "        [-24.1681,  25.6999, -21.3972],\n",
      "        [-24.5291,  25.5985, -21.1312],\n",
      "        [-24.4763,  25.8051, -21.5374]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7454,  20.7872,  21.4366, -24.7655,  25.8238, -21.4609],\n",
      "        [ 25.4277,  20.8836,  21.5589, -24.1688,  25.7082, -21.3001],\n",
      "        [ 24.9502,  20.6837,  21.3281, -24.5553,  25.4154, -21.0425],\n",
      "        [ 25.5031,  20.6780,  21.8488, -24.1681,  25.6999, -21.3972],\n",
      "        [ 25.2450,  20.5863,  21.4201, -24.5291,  25.5985, -21.1312],\n",
      "        [ 25.9613,  20.7504,  22.1568, -24.4763,  25.8051, -21.5374]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.356222152709961\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8573, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7031, 20.8083, 21.7983],\n",
      "        [25.9117, 21.0202, 21.7852],\n",
      "        [25.0556, 20.5672, 21.1643],\n",
      "        [25.8097, 20.7347, 21.9918],\n",
      "        [26.2566, 21.2655, 22.1985],\n",
      "        [25.7070, 20.4666, 21.4398]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.1435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5865,  25.9872, -21.5452],\n",
      "        [-25.3588,  26.7299, -22.0284],\n",
      "        [-24.3443,  25.4757, -21.3267],\n",
      "        [-24.6801,  25.7064, -21.4151],\n",
      "        [-24.7738,  26.0380, -21.5126],\n",
      "        [-24.4688,  25.5233, -21.1500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7031,  20.8083,  21.7983, -24.5865,  25.9872, -21.5452],\n",
      "        [ 25.9117,  21.0202,  21.7852, -25.3588,  26.7299, -22.0284],\n",
      "        [ 25.0556,  20.5672,  21.1643, -24.3443,  25.4757, -21.3267],\n",
      "        [ 25.8097,  20.7347,  21.9918, -24.6801,  25.7064, -21.4151],\n",
      "        [ 26.2566,  21.2655,  22.1985, -24.7738,  26.0380, -21.5126],\n",
      "        [ 25.7070,  20.4666,  21.4398, -24.4688,  25.5233, -21.1500]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.37477970123291\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4828, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1281, 21.5842, 21.6238],\n",
      "        [26.0422, 21.1129, 21.8354],\n",
      "        [26.1592, 21.3288, 21.9623],\n",
      "        [25.1777, 20.5395, 21.1014],\n",
      "        [25.8466, 21.3748, 21.7452],\n",
      "        [25.1280, 20.3934, 21.5824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.0033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5624,  25.7508, -21.5345],\n",
      "        [-24.2250,  25.1154, -21.1954],\n",
      "        [-24.1248,  25.6762, -21.5794],\n",
      "        [-24.3313,  25.6229, -21.1434],\n",
      "        [-24.3546,  25.7479, -21.3008],\n",
      "        [-24.4230,  25.4527, -21.7810]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1281,  21.5842,  21.6238, -24.5624,  25.7508, -21.5345],\n",
      "        [ 26.0422,  21.1129,  21.8354, -24.2250,  25.1154, -21.1954],\n",
      "        [ 26.1592,  21.3288,  21.9623, -24.1248,  25.6762, -21.5794],\n",
      "        [ 25.1777,  20.5395,  21.1014, -24.3313,  25.6229, -21.1434],\n",
      "        [ 25.8466,  21.3748,  21.7452, -24.3546,  25.7479, -21.3008],\n",
      "        [ 25.1280,  20.3934,  21.5824, -24.4230,  25.4527, -21.7810]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.408257007598877\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6388, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6822, 21.0363, 21.6169],\n",
      "        [25.8191, 21.2700, 21.8276],\n",
      "        [24.9195, 20.3591, 21.1921],\n",
      "        [25.4996, 20.7504, 21.6884],\n",
      "        [25.5708, 20.8151, 21.3139],\n",
      "        [26.1846, 21.2640, 21.9342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.5280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6978,  25.8625, -21.7573],\n",
      "        [-24.3016,  25.4903, -21.0062],\n",
      "        [-23.9872,  25.5584, -20.8079],\n",
      "        [-24.3138,  25.5645, -21.5303],\n",
      "        [-24.8756,  26.6094, -21.9994],\n",
      "        [-24.6670,  25.9947, -21.4669]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6822,  21.0363,  21.6169, -24.6978,  25.8625, -21.7573],\n",
      "        [ 25.8191,  21.2700,  21.8276, -24.3016,  25.4903, -21.0062],\n",
      "        [ 24.9195,  20.3591,  21.1921, -23.9872,  25.5584, -20.8079],\n",
      "        [ 25.4996,  20.7504,  21.6884, -24.3138,  25.5645, -21.5303],\n",
      "        [ 25.5708,  20.8151,  21.3139, -24.8756,  26.6094, -21.9994],\n",
      "        [ 26.1846,  21.2640,  21.9342, -24.6670,  25.9947, -21.4669]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.382157325744629\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5825, 20.6974, 21.1313],\n",
      "        [25.4113, 20.6755, 21.5918],\n",
      "        [25.4960, 20.7199, 21.7685],\n",
      "        [26.2093, 21.7191, 22.0327],\n",
      "        [26.3583, 21.3380, 21.9757],\n",
      "        [26.0407, 21.0673, 21.7550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.3693, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3749,  25.5305, -21.3439],\n",
      "        [-24.6662,  25.8706, -21.4600],\n",
      "        [-24.5012,  25.6135, -21.3527],\n",
      "        [-24.8058,  26.3445, -21.9878],\n",
      "        [-24.1727,  25.3212, -21.2850],\n",
      "        [-24.3021,  25.5419, -21.4722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5825,  20.6974,  21.1313, -24.3749,  25.5305, -21.3439],\n",
      "        [ 25.4113,  20.6755,  21.5918, -24.6662,  25.8706, -21.4600],\n",
      "        [ 25.4960,  20.7199,  21.7685, -24.5012,  25.6135, -21.3527],\n",
      "        [ 26.2093,  21.7191,  22.0327, -24.8058,  26.3445, -21.9878],\n",
      "        [ 26.3583,  21.3380,  21.9757, -24.1727,  25.3212, -21.2850],\n",
      "        [ 26.0407,  21.0673,  21.7550, -24.3021,  25.5419, -21.4722]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.31158971786499\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1236, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9424, 21.1921, 21.2747],\n",
      "        [25.6384, 20.5118, 21.4199],\n",
      "        [26.1893, 21.2519, 21.8330],\n",
      "        [26.0258, 20.9540, 21.9593],\n",
      "        [25.7140, 20.5459, 21.9264],\n",
      "        [25.2735, 20.5459, 21.3307]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8475, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1747,  26.3972, -22.0616],\n",
      "        [-24.2956,  25.8604, -21.2414],\n",
      "        [-24.6780,  25.6928, -21.2327],\n",
      "        [-23.9171,  25.6505, -21.3005],\n",
      "        [-24.8769,  25.9467, -21.7507],\n",
      "        [-24.1261,  25.2357, -21.7223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9424,  21.1921,  21.2747, -25.1747,  26.3972, -22.0616],\n",
      "        [ 25.6384,  20.5118,  21.4199, -24.2956,  25.8604, -21.2414],\n",
      "        [ 26.1893,  21.2519,  21.8330, -24.6780,  25.6928, -21.2327],\n",
      "        [ 26.0258,  20.9540,  21.9593, -23.9171,  25.6505, -21.3005],\n",
      "        [ 25.7140,  20.5459,  21.9264, -24.8769,  25.9467, -21.7507],\n",
      "        [ 25.2735,  20.5459,  21.3307, -24.1261,  25.2357, -21.7223]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.43302583694458\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8184, 20.7892, 21.4313],\n",
      "        [26.2305, 21.2083, 22.1815],\n",
      "        [25.3954, 20.8875, 21.8289],\n",
      "        [25.7654, 20.9858, 22.0159],\n",
      "        [25.8920, 21.2769, 21.8454],\n",
      "        [25.2939, 21.0315, 20.7947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.3356, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7283,  25.8341, -21.5654],\n",
      "        [-24.5108,  25.5917, -21.4396],\n",
      "        [-24.2383,  25.5985, -21.1560],\n",
      "        [-25.2345,  26.3337, -21.7388],\n",
      "        [-24.8003,  25.6989, -21.5994],\n",
      "        [-24.2616,  25.4278, -21.2508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8184,  20.7892,  21.4313, -24.7283,  25.8341, -21.5654],\n",
      "        [ 26.2305,  21.2083,  22.1815, -24.5108,  25.5917, -21.4396],\n",
      "        [ 25.3954,  20.8875,  21.8289, -24.2383,  25.5985, -21.1560],\n",
      "        [ 25.7654,  20.9858,  22.0159, -25.2345,  26.3337, -21.7388],\n",
      "        [ 25.8920,  21.2769,  21.8454, -24.8003,  25.6989, -21.5994],\n",
      "        [ 25.2939,  21.0315,  20.7947, -24.2616,  25.4278, -21.2508]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.3729729652404785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4437, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6374, 20.7355, 21.5430],\n",
      "        [25.8303, 21.2678, 22.0803],\n",
      "        [25.1886, 20.7188, 21.5971],\n",
      "        [25.8071, 20.9437, 21.4495],\n",
      "        [26.0585, 20.9421, 22.0145],\n",
      "        [25.5948, 20.8441, 21.3342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.4880, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9059,  25.3175, -21.2097],\n",
      "        [-24.6665,  25.6084, -21.4437],\n",
      "        [-24.0924,  25.4194, -21.1148],\n",
      "        [-24.5365,  25.8720, -21.1231],\n",
      "        [-24.8893,  25.9390, -21.6491],\n",
      "        [-23.9574,  25.4197, -21.3360]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6374,  20.7355,  21.5430, -23.9059,  25.3175, -21.2097],\n",
      "        [ 25.8303,  21.2678,  22.0803, -24.6665,  25.6084, -21.4437],\n",
      "        [ 25.1886,  20.7188,  21.5971, -24.0924,  25.4194, -21.1148],\n",
      "        [ 25.8071,  20.9437,  21.4495, -24.5365,  25.8720, -21.1231],\n",
      "        [ 26.0585,  20.9421,  22.0145, -24.8893,  25.9390, -21.6491],\n",
      "        [ 25.5948,  20.8441,  21.3342, -23.9574,  25.4197, -21.3360]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.312675476074219\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0834, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3360, 20.4011, 21.2069],\n",
      "        [25.6842, 20.7541, 21.7157],\n",
      "        [25.7027, 20.9684, 21.4541],\n",
      "        [25.7630, 21.1550, 21.6846],\n",
      "        [25.9228, 21.4809, 22.0594],\n",
      "        [25.3064, 20.9226, 21.4806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.6364, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4308,  25.5252, -21.1617],\n",
      "        [-24.7357,  25.5582, -21.2570],\n",
      "        [-24.4913,  25.5999, -21.4139],\n",
      "        [-24.0001,  25.2319, -20.8482],\n",
      "        [-24.4937,  25.8581, -21.3548],\n",
      "        [-24.7524,  26.2189, -21.7711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3360,  20.4011,  21.2069, -24.4308,  25.5252, -21.1617],\n",
      "        [ 25.6842,  20.7541,  21.7157, -24.7357,  25.5582, -21.2570],\n",
      "        [ 25.7027,  20.9684,  21.4541, -24.4913,  25.5999, -21.4139],\n",
      "        [ 25.7630,  21.1550,  21.6846, -24.0001,  25.2319, -20.8482],\n",
      "        [ 25.9228,  21.4809,  22.0594, -24.4937,  25.8581, -21.3548],\n",
      "        [ 25.3064,  20.9226,  21.4806, -24.7524,  26.2189, -21.7711]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.295706272125244\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6525, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5184, 20.7985, 21.4518],\n",
      "        [25.7989, 20.8803, 22.0582],\n",
      "        [26.0329, 21.0262, 22.2109],\n",
      "        [25.2725, 21.0936, 21.5646],\n",
      "        [25.4312, 20.7138, 21.5111],\n",
      "        [25.9884, 21.1817, 21.7438]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.0957, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6413,  25.8229, -21.4472],\n",
      "        [-24.2433,  25.7112, -21.0522],\n",
      "        [-24.2331,  25.2914, -21.1821],\n",
      "        [-24.7227,  25.8847, -21.6590],\n",
      "        [-24.4199,  25.7618, -21.6234],\n",
      "        [-24.1185,  25.5251, -21.2915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5184,  20.7985,  21.4518, -24.6413,  25.8229, -21.4472],\n",
      "        [ 25.7989,  20.8803,  22.0582, -24.2433,  25.7112, -21.0522],\n",
      "        [ 26.0329,  21.0262,  22.2109, -24.2331,  25.2914, -21.1821],\n",
      "        [ 25.2725,  21.0936,  21.5646, -24.7227,  25.8847, -21.6590],\n",
      "        [ 25.4312,  20.7138,  21.5111, -24.4199,  25.7618, -21.6234],\n",
      "        [ 25.9884,  21.1817,  21.7438, -24.1185,  25.5251, -21.2915]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.357186794281006\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7939, 21.0610, 21.5409],\n",
      "        [25.5582, 20.8597, 21.6340],\n",
      "        [25.1402, 20.8839, 21.4219],\n",
      "        [25.8456, 21.1399, 22.1825],\n",
      "        [26.1605, 21.2636, 21.5639],\n",
      "        [25.1322, 20.6293, 21.5400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.4893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1137,  25.4514, -21.3368],\n",
      "        [-24.3017,  25.5187, -21.3821],\n",
      "        [-24.8438,  25.7590, -21.7299],\n",
      "        [-24.7704,  25.7811, -21.5763],\n",
      "        [-24.6197,  25.4121, -21.4071],\n",
      "        [-24.8741,  26.4562, -21.7215]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7939,  21.0610,  21.5409, -24.1137,  25.4514, -21.3368],\n",
      "        [ 25.5582,  20.8597,  21.6340, -24.3017,  25.5187, -21.3821],\n",
      "        [ 25.1402,  20.8839,  21.4219, -24.8438,  25.7590, -21.7299],\n",
      "        [ 25.8456,  21.1399,  22.1825, -24.7704,  25.7811, -21.5763],\n",
      "        [ 26.1605,  21.2636,  21.5639, -24.6197,  25.4121, -21.4071],\n",
      "        [ 25.1322,  20.6293,  21.5400, -24.8741,  26.4562, -21.7215]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.35265588760376\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3516, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4910, 21.1205, 21.4011],\n",
      "        [25.2670, 20.9241, 21.4247],\n",
      "        [26.1507, 21.2953, 22.1933],\n",
      "        [25.6306, 20.7088, 22.0491],\n",
      "        [25.8891, 21.3578, 21.9642],\n",
      "        [25.7130, 20.9581, 21.9412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4898,  25.8303, -21.4690],\n",
      "        [-24.7634,  25.9594, -21.4821],\n",
      "        [-24.7490,  26.0112, -21.6336],\n",
      "        [-24.0851,  25.6822, -21.1425],\n",
      "        [-24.1613,  25.0848, -21.2253],\n",
      "        [-24.1743,  24.9697, -21.0017]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4910,  21.1205,  21.4011, -24.4898,  25.8303, -21.4690],\n",
      "        [ 25.2670,  20.9241,  21.4247, -24.7634,  25.9594, -21.4821],\n",
      "        [ 26.1507,  21.2953,  22.1933, -24.7490,  26.0112, -21.6336],\n",
      "        [ 25.6306,  20.7088,  22.0491, -24.0851,  25.6822, -21.1425],\n",
      "        [ 25.8891,  21.3578,  21.9642, -24.1613,  25.0848, -21.2253],\n",
      "        [ 25.7130,  20.9581,  21.9412, -24.1743,  24.9697, -21.0017]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.363880634307861\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4751, 21.0744, 22.0247],\n",
      "        [26.2131, 21.1741, 22.1691],\n",
      "        [26.4044, 21.3147, 22.3854],\n",
      "        [25.4551, 20.3729, 21.0401],\n",
      "        [25.7800, 20.8115, 21.9621],\n",
      "        [25.4153, 20.5910, 21.2604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9330, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.7902,  25.0868, -20.5788],\n",
      "        [-23.9131,  25.3550, -21.2484],\n",
      "        [-24.7853,  25.5746, -21.8911],\n",
      "        [-25.3005,  26.1483, -21.6815],\n",
      "        [-24.4591,  26.0144, -21.5228],\n",
      "        [-24.5988,  25.6489, -21.5294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4751,  21.0744,  22.0247, -23.7902,  25.0868, -20.5788],\n",
      "        [ 26.2131,  21.1741,  22.1691, -23.9131,  25.3550, -21.2484],\n",
      "        [ 26.4044,  21.3147,  22.3854, -24.7853,  25.5746, -21.8911],\n",
      "        [ 25.4551,  20.3729,  21.0401, -25.3005,  26.1483, -21.6815],\n",
      "        [ 25.7800,  20.8115,  21.9621, -24.4591,  26.0144, -21.5228],\n",
      "        [ 25.4153,  20.5910,  21.2604, -24.5988,  25.6489, -21.5294]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.369766712188721\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1777, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9554, 21.4977, 22.2025],\n",
      "        [25.5459, 20.9748, 21.8422],\n",
      "        [26.0619, 21.1969, 21.8056],\n",
      "        [25.8795, 20.9396, 22.0164],\n",
      "        [25.3389, 20.7558, 21.6494],\n",
      "        [25.7058, 20.7451, 21.4783]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.8896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-23.9607,  25.5588, -20.9488],\n",
      "        [-24.2384,  25.7386, -21.3724],\n",
      "        [-24.2248,  25.0857, -21.1276],\n",
      "        [-24.3402,  25.7585, -21.3787],\n",
      "        [-24.4239,  25.6265, -21.1295],\n",
      "        [-24.4749,  25.9834, -21.2190]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9554,  21.4977,  22.2025, -23.9607,  25.5588, -20.9488],\n",
      "        [ 25.5459,  20.9748,  21.8422, -24.2384,  25.7386, -21.3724],\n",
      "        [ 26.0619,  21.1969,  21.8056, -24.2248,  25.0857, -21.1276],\n",
      "        [ 25.8795,  20.9396,  22.0164, -24.3402,  25.7585, -21.3787],\n",
      "        [ 25.3389,  20.7558,  21.6494, -24.4239,  25.6265, -21.1295],\n",
      "        [ 25.7058,  20.7451,  21.4783, -24.4749,  25.9834, -21.2190]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.399081230163574\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4645, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.0702, 20.7449, 21.4257],\n",
      "        [25.7677, 20.8225, 22.1393],\n",
      "        [25.8718, 21.0501, 22.0060],\n",
      "        [25.4522, 21.2650, 21.9052],\n",
      "        [25.9500, 20.9983, 21.8647],\n",
      "        [25.4760, 20.6803, 21.3353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.1033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6974,  25.8574, -21.5975],\n",
      "        [-24.7553,  25.9326, -21.2216],\n",
      "        [-24.8672,  26.3680, -22.0801],\n",
      "        [-24.9666,  25.7759, -21.3146],\n",
      "        [-24.8443,  25.6753, -21.5664],\n",
      "        [-23.3927,  24.6727, -20.6742]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.0702,  20.7449,  21.4257, -24.6974,  25.8574, -21.5975],\n",
      "        [ 25.7677,  20.8225,  22.1393, -24.7553,  25.9326, -21.2216],\n",
      "        [ 25.8718,  21.0501,  22.0060, -24.8672,  26.3680, -22.0801],\n",
      "        [ 25.4522,  21.2650,  21.9052, -24.9666,  25.7759, -21.3146],\n",
      "        [ 25.9500,  20.9983,  21.8647, -24.8443,  25.6753, -21.5664],\n",
      "        [ 25.4760,  20.6803,  21.3353, -23.3927,  24.6727, -20.6742]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.346743583679199\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3834, 20.9525, 21.7137],\n",
      "        [26.0298, 21.0128, 22.1766],\n",
      "        [25.2840, 20.6796, 21.4427],\n",
      "        [25.7935, 20.5592, 21.8111],\n",
      "        [25.9744, 20.8376, 21.7312],\n",
      "        [26.2343, 20.5882, 22.0199]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.0995, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.2295,  25.7531, -21.2350],\n",
      "        [-24.2485,  25.7957, -21.1280],\n",
      "        [-24.8275,  25.7406, -21.5606],\n",
      "        [-24.9935,  26.0690, -21.5717],\n",
      "        [-24.4248,  26.1584, -21.5780],\n",
      "        [-24.8997,  26.2932, -21.8088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3834,  20.9525,  21.7137, -24.2295,  25.7531, -21.2350],\n",
      "        [ 26.0298,  21.0128,  22.1766, -24.2485,  25.7957, -21.1280],\n",
      "        [ 25.2840,  20.6796,  21.4427, -24.8275,  25.7406, -21.5606],\n",
      "        [ 25.7935,  20.5592,  21.8111, -24.9935,  26.0690, -21.5717],\n",
      "        [ 25.9744,  20.8376,  21.7312, -24.4248,  26.1584, -21.5780],\n",
      "        [ 26.2343,  20.5882,  22.0199, -24.8997,  26.2932, -21.8088]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.355722904205322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7805, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2881, 20.4159, 21.1631],\n",
      "        [25.8185, 21.2991, 21.9596],\n",
      "        [26.0627, 21.0080, 21.6320],\n",
      "        [25.6702, 21.0757, 21.7887],\n",
      "        [25.8049, 20.9229, 21.8808],\n",
      "        [25.2844, 20.4974, 21.6233]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4821, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4243,  26.0316, -21.5438],\n",
      "        [-24.1211,  26.2163, -21.6658],\n",
      "        [-24.3281,  25.8306, -21.1722],\n",
      "        [-24.8227,  25.8199, -21.7029],\n",
      "        [-24.3438,  25.5965, -21.2740],\n",
      "        [-24.2993,  26.2095, -21.6248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2881,  20.4159,  21.1631, -24.4243,  26.0316, -21.5438],\n",
      "        [ 25.8185,  21.2991,  21.9596, -24.1211,  26.2163, -21.6658],\n",
      "        [ 26.0627,  21.0080,  21.6320, -24.3281,  25.8306, -21.1722],\n",
      "        [ 25.6702,  21.0757,  21.7887, -24.8227,  25.8199, -21.7029],\n",
      "        [ 25.8049,  20.9229,  21.8808, -24.3438,  25.5965, -21.2740],\n",
      "        [ 25.2844,  20.4974,  21.6233, -24.2993,  26.2095, -21.6248]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.3345818519592285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0436, 20.9719, 21.8669],\n",
      "        [25.6220, 20.6070, 21.6324],\n",
      "        [25.8882, 21.3461, 22.0785],\n",
      "        [25.7407, 20.8897, 21.8215],\n",
      "        [26.1034, 21.4654, 22.5681],\n",
      "        [26.1382, 21.1999, 21.9725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(15.9456, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9064,  26.1782, -21.7552],\n",
      "        [-24.6106,  25.8352, -21.6771],\n",
      "        [-24.2157,  25.3220, -20.8490],\n",
      "        [-23.9223,  25.5804, -21.2728],\n",
      "        [-24.9517,  26.0340, -21.9428],\n",
      "        [-24.4299,  25.8089, -21.4283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0436,  20.9719,  21.8669, -24.9064,  26.1782, -21.7552],\n",
      "        [ 25.6220,  20.6070,  21.6324, -24.6106,  25.8352, -21.6771],\n",
      "        [ 25.8882,  21.3461,  22.0785, -24.2157,  25.3220, -20.8490],\n",
      "        [ 25.7407,  20.8897,  21.8215, -23.9223,  25.5804, -21.2728],\n",
      "        [ 26.1034,  21.4654,  22.5681, -24.9517,  26.0340, -21.9428],\n",
      "        [ 26.1382,  21.1999,  21.9725, -24.4299,  25.8089, -21.4283]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.454356670379639\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3686, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6953, 21.7722, 22.5079],\n",
      "        [25.8358, 21.0786, 21.6646],\n",
      "        [25.6638, 20.6762, 21.3748],\n",
      "        [26.2113, 21.3295, 22.0718],\n",
      "        [26.1883, 21.2250, 21.7756],\n",
      "        [25.3583, 20.9839, 22.0578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(31.8550, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1928,  26.5671, -21.9891],\n",
      "        [-24.8806,  26.0042, -21.8775],\n",
      "        [-24.5470,  26.0283, -21.7859],\n",
      "        [-24.0467,  25.4162, -21.0667],\n",
      "        [-24.1355,  25.5954, -21.2828],\n",
      "        [-24.7238,  25.4860, -21.4192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6953,  21.7722,  22.5079, -25.1928,  26.5671, -21.9891],\n",
      "        [ 25.8358,  21.0786,  21.6646, -24.8806,  26.0042, -21.8775],\n",
      "        [ 25.6638,  20.6762,  21.3748, -24.5470,  26.0283, -21.7859],\n",
      "        [ 26.2113,  21.3295,  22.0718, -24.0467,  25.4162, -21.0667],\n",
      "        [ 26.1883,  21.2250,  21.7756, -24.1355,  25.5954, -21.2828],\n",
      "        [ 25.3583,  20.9839,  22.0578, -24.7238,  25.4860, -21.4192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.576909065246582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2820, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0785, 21.7161, 22.1356],\n",
      "        [24.8780, 20.7654, 20.9598],\n",
      "        [25.8997, 21.3220, 21.9823],\n",
      "        [25.5618, 20.5031, 21.5744],\n",
      "        [26.1776, 21.6093, 22.1603],\n",
      "        [25.5221, 20.8213, 21.6359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4578,  25.6637, -21.2093],\n",
      "        [-24.9124,  26.1274, -21.8360],\n",
      "        [-24.3431,  25.8101, -21.6022],\n",
      "        [-24.1528,  25.2249, -20.9821],\n",
      "        [-25.2185,  26.1720, -22.1924],\n",
      "        [-24.9731,  26.3074, -21.9145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0785,  21.7161,  22.1356, -24.4578,  25.6637, -21.2093],\n",
      "        [ 24.8780,  20.7654,  20.9598, -24.9124,  26.1274, -21.8360],\n",
      "        [ 25.8997,  21.3220,  21.9823, -24.3431,  25.8101, -21.6022],\n",
      "        [ 25.5618,  20.5031,  21.5744, -24.1528,  25.2249, -20.9821],\n",
      "        [ 26.1776,  21.6093,  22.1603, -25.2185,  26.1720, -22.1924],\n",
      "        [ 25.5221,  20.8213,  21.6359, -24.9731,  26.3074, -21.9145]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.448761940002441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7004, 20.7677, 21.3666],\n",
      "        [25.9968, 21.0672, 21.8855],\n",
      "        [25.8005, 21.2874, 21.6427],\n",
      "        [25.8089, 21.0981, 21.5211],\n",
      "        [26.0826, 21.2880, 22.0920],\n",
      "        [26.2806, 21.6512, 22.1029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.9197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6487,  25.7955, -21.4241],\n",
      "        [-24.5512,  25.4611, -21.1066],\n",
      "        [-24.6377,  25.6132, -21.3969],\n",
      "        [-24.9860,  26.2567, -22.0670],\n",
      "        [-23.9889,  24.9902, -21.0261],\n",
      "        [-24.5310,  25.7063, -21.6409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7004,  20.7677,  21.3666, -24.6487,  25.7955, -21.4241],\n",
      "        [ 25.9968,  21.0672,  21.8855, -24.5512,  25.4611, -21.1066],\n",
      "        [ 25.8005,  21.2874,  21.6427, -24.6377,  25.6132, -21.3969],\n",
      "        [ 25.8089,  21.0981,  21.5211, -24.9860,  26.2567, -22.0670],\n",
      "        [ 26.0826,  21.2880,  22.0920, -23.9889,  24.9902, -21.0261],\n",
      "        [ 26.2806,  21.6512,  22.1029, -24.5310,  25.7063, -21.6409]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.380716800689697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4860, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8640, 20.8651, 21.7920],\n",
      "        [26.0416, 20.8951, 21.8023],\n",
      "        [25.3365, 20.3796, 21.7271],\n",
      "        [26.2902, 21.3445, 21.7692],\n",
      "        [25.4950, 20.9852, 21.6595],\n",
      "        [25.6665, 20.7406, 21.8434]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.9513, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6110,  25.7517, -21.6411],\n",
      "        [-24.5095,  25.8545, -21.1209],\n",
      "        [-24.4356,  25.7006, -21.2149],\n",
      "        [-25.0546,  25.7917, -21.6861],\n",
      "        [-24.9963,  26.0596, -21.9070],\n",
      "        [-24.0802,  26.0189, -21.4571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8640,  20.8651,  21.7920, -24.6110,  25.7517, -21.6411],\n",
      "        [ 26.0416,  20.8951,  21.8023, -24.5095,  25.8545, -21.1209],\n",
      "        [ 25.3365,  20.3796,  21.7271, -24.4356,  25.7006, -21.2149],\n",
      "        [ 26.2902,  21.3445,  21.7692, -25.0546,  25.7917, -21.6861],\n",
      "        [ 25.4950,  20.9852,  21.6595, -24.9963,  26.0596, -21.9070],\n",
      "        [ 25.6665,  20.7406,  21.8434, -24.0802,  26.0189, -21.4571]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.416862487792969\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2791, 21.6765, 22.2913],\n",
      "        [25.8181, 20.6765, 22.0992],\n",
      "        [25.9433, 20.8670, 21.9094],\n",
      "        [26.1079, 21.4622, 21.8319],\n",
      "        [25.5213, 21.0672, 22.0271],\n",
      "        [26.1128, 20.9341, 21.8358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.8278, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0289,  25.9820, -21.8477],\n",
      "        [-24.6133,  25.6457, -21.6039],\n",
      "        [-24.4544,  25.7075, -21.2169],\n",
      "        [-24.4749,  25.9821, -21.8040],\n",
      "        [-24.7458,  25.8186, -21.4510],\n",
      "        [-23.9465,  25.7483, -21.3911]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2791,  21.6765,  22.2913, -25.0289,  25.9820, -21.8477],\n",
      "        [ 25.8181,  20.6765,  22.0992, -24.6133,  25.6457, -21.6039],\n",
      "        [ 25.9433,  20.8670,  21.9094, -24.4544,  25.7075, -21.2169],\n",
      "        [ 26.1079,  21.4622,  21.8319, -24.4749,  25.9821, -21.8040],\n",
      "        [ 25.5213,  21.0672,  22.0271, -24.7458,  25.8186, -21.4510],\n",
      "        [ 26.1128,  20.9341,  21.8358, -23.9465,  25.7483, -21.3911]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.5189738273620605\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1719, 21.2235, 21.6605],\n",
      "        [25.3438, 20.2270, 21.4493],\n",
      "        [25.9468, 21.1462, 21.6873],\n",
      "        [25.7653, 20.8118, 21.9061],\n",
      "        [25.8087, 20.9366, 22.0867],\n",
      "        [25.4938, 20.5175, 21.4803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.4045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9439,  26.1005, -21.2819],\n",
      "        [-24.7245,  26.5753, -21.5914],\n",
      "        [-24.5710,  25.9469, -21.3406],\n",
      "        [-24.3796,  25.6347, -21.6153],\n",
      "        [-24.4828,  25.7079, -21.2085],\n",
      "        [-25.0202,  25.9165, -22.0798]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1719,  21.2235,  21.6605, -24.9439,  26.1005, -21.2819],\n",
      "        [ 25.3438,  20.2270,  21.4493, -24.7245,  26.5753, -21.5914],\n",
      "        [ 25.9468,  21.1462,  21.6873, -24.5710,  25.9469, -21.3406],\n",
      "        [ 25.7653,  20.8118,  21.9061, -24.3796,  25.6347, -21.6153],\n",
      "        [ 25.8087,  20.9366,  22.0867, -24.4828,  25.7079, -21.2085],\n",
      "        [ 25.4938,  20.5175,  21.4803, -25.0202,  25.9165, -22.0798]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.456971168518066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1135, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.2296, 20.5862, 21.2076],\n",
      "        [26.8005, 21.8745, 22.4893],\n",
      "        [25.8891, 21.4448, 22.1919],\n",
      "        [26.0844, 21.2185, 21.7282],\n",
      "        [26.1505, 21.5271, 22.1699],\n",
      "        [25.5889, 21.0602, 21.7162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.0348, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8913,  26.5135, -21.8027],\n",
      "        [-24.5403,  25.9832, -21.5419],\n",
      "        [-24.0236,  25.3722, -21.2265],\n",
      "        [-24.9575,  26.0403, -21.9273],\n",
      "        [-24.6962,  25.9942, -21.5087],\n",
      "        [-24.2894,  25.4307, -21.3174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.2296,  20.5862,  21.2076, -24.8913,  26.5135, -21.8027],\n",
      "        [ 26.8005,  21.8745,  22.4893, -24.5403,  25.9832, -21.5419],\n",
      "        [ 25.8891,  21.4448,  22.1919, -24.0236,  25.3722, -21.2265],\n",
      "        [ 26.0844,  21.2185,  21.7282, -24.9575,  26.0403, -21.9273],\n",
      "        [ 26.1505,  21.5271,  22.1699, -24.6962,  25.9942, -21.5087],\n",
      "        [ 25.5889,  21.0602,  21.7162, -24.2894,  25.4307, -21.3174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.393967151641846\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8388, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1585, 21.1556, 22.2626],\n",
      "        [26.4302, 21.5010, 22.5075],\n",
      "        [26.0022, 21.2582, 21.9424],\n",
      "        [25.9896, 21.1081, 21.8853],\n",
      "        [25.8960, 21.1230, 21.4175],\n",
      "        [26.3099, 21.5010, 22.4512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.1679, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1478,  24.8142, -20.7919],\n",
      "        [-24.5772,  26.2524, -21.7618],\n",
      "        [-24.8615,  25.8906, -21.4134],\n",
      "        [-24.3762,  25.5275, -21.6595],\n",
      "        [-24.8958,  26.2371, -21.5736],\n",
      "        [-24.2176,  25.2099, -21.2072]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1585,  21.1556,  22.2626, -24.1478,  24.8142, -20.7919],\n",
      "        [ 26.4302,  21.5010,  22.5075, -24.5772,  26.2524, -21.7618],\n",
      "        [ 26.0022,  21.2582,  21.9424, -24.8615,  25.8906, -21.4134],\n",
      "        [ 25.9896,  21.1081,  21.8853, -24.3762,  25.5275, -21.6595],\n",
      "        [ 25.8960,  21.1230,  21.4175, -24.8958,  26.2371, -21.5736],\n",
      "        [ 26.3099,  21.5010,  22.4512, -24.2176,  25.2099, -21.2072]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.39816951751709\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5232, 21.3925, 22.1561],\n",
      "        [25.6662, 21.0041, 21.7622],\n",
      "        [25.9660, 20.9451, 21.8696],\n",
      "        [25.1200, 20.6023, 21.2043],\n",
      "        [26.6505, 21.6770, 22.4210],\n",
      "        [25.6866, 21.1464, 21.8867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.7915, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4744,  25.2886, -21.4822],\n",
      "        [-24.0704,  25.3961, -21.4320],\n",
      "        [-24.2244,  25.4697, -21.3939],\n",
      "        [-24.5745,  25.4918, -21.1707],\n",
      "        [-24.3808,  25.4542, -21.5315],\n",
      "        [-24.0331,  25.7530, -21.0207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5232,  21.3925,  22.1561, -24.4744,  25.2886, -21.4822],\n",
      "        [ 25.6662,  21.0041,  21.7622, -24.0704,  25.3961, -21.4320],\n",
      "        [ 25.9660,  20.9451,  21.8696, -24.2244,  25.4697, -21.3939],\n",
      "        [ 25.1200,  20.6023,  21.2043, -24.5745,  25.4918, -21.1707],\n",
      "        [ 26.6505,  21.6770,  22.4210, -24.3808,  25.4542, -21.5315],\n",
      "        [ 25.6866,  21.1464,  21.8867, -24.0331,  25.7530, -21.0207]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.4700398445129395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2081, 21.2877, 21.8885],\n",
      "        [25.7488, 21.2436, 21.7412],\n",
      "        [25.7505, 20.9168, 21.7468],\n",
      "        [26.5358, 21.5262, 22.0203],\n",
      "        [26.4329, 21.5026, 22.0657],\n",
      "        [26.2598, 20.9369, 22.0995]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.0600, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3933,  25.3761, -21.6054],\n",
      "        [-24.3624,  25.7133, -21.3417],\n",
      "        [-24.4816,  25.3684, -21.4281],\n",
      "        [-24.6452,  26.1921, -21.3176],\n",
      "        [-25.0293,  26.3680, -21.8422],\n",
      "        [-24.6180,  25.8881, -21.8863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2081,  21.2877,  21.8885, -24.3933,  25.3761, -21.6054],\n",
      "        [ 25.7488,  21.2436,  21.7412, -24.3624,  25.7133, -21.3417],\n",
      "        [ 25.7505,  20.9168,  21.7468, -24.4816,  25.3684, -21.4281],\n",
      "        [ 26.5358,  21.5262,  22.0203, -24.6452,  26.1921, -21.3176],\n",
      "        [ 26.4329,  21.5026,  22.0657, -25.0293,  26.3680, -21.8422],\n",
      "        [ 26.2598,  20.9369,  22.0995, -24.6180,  25.8881, -21.8863]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.4433112144470215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3410, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8946, 21.0401, 22.0850],\n",
      "        [25.8159, 21.3704, 21.8581],\n",
      "        [26.4518, 21.2229, 22.2495],\n",
      "        [25.6502, 20.9491, 21.8398],\n",
      "        [26.3760, 21.3265, 22.6139],\n",
      "        [26.1652, 20.9821, 22.0909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(40.8251, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1876,  25.5045, -21.1816],\n",
      "        [-25.0442,  26.1152, -22.1525],\n",
      "        [-24.5550,  25.6177, -21.4934],\n",
      "        [-24.5776,  26.0094, -21.4984],\n",
      "        [-23.9695,  25.5305, -21.2840],\n",
      "        [-25.0498,  26.0342, -21.6859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8946,  21.0401,  22.0850, -24.1876,  25.5045, -21.1816],\n",
      "        [ 25.8159,  21.3704,  21.8581, -25.0442,  26.1152, -22.1525],\n",
      "        [ 26.4518,  21.2229,  22.2495, -24.5550,  25.6177, -21.4934],\n",
      "        [ 25.6502,  20.9491,  21.8398, -24.5776,  26.0094, -21.4984],\n",
      "        [ 26.3760,  21.3265,  22.6139, -23.9695,  25.5305, -21.2840],\n",
      "        [ 26.1652,  20.9821,  22.0909, -25.0498,  26.0342, -21.6859]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.4145588874816895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7273, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8105, 20.9581, 21.6419],\n",
      "        [25.9056, 21.3054, 22.0518],\n",
      "        [26.1472, 21.2604, 22.0745],\n",
      "        [25.7353, 21.0944, 21.6967],\n",
      "        [26.1620, 21.3802, 21.9510],\n",
      "        [26.5134, 21.5559, 22.4955]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3267, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3274,  26.2822, -22.4686],\n",
      "        [-24.9232,  25.8873, -21.3879],\n",
      "        [-24.1913,  25.8135, -21.5960],\n",
      "        [-24.1437,  25.5915, -21.1458],\n",
      "        [-24.7488,  25.5219, -21.6537],\n",
      "        [-24.5894,  25.7883, -21.7469]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8105,  20.9581,  21.6419, -25.3274,  26.2822, -22.4686],\n",
      "        [ 25.9056,  21.3054,  22.0518, -24.9232,  25.8873, -21.3879],\n",
      "        [ 26.1472,  21.2604,  22.0745, -24.1913,  25.8135, -21.5960],\n",
      "        [ 25.7353,  21.0944,  21.6967, -24.1437,  25.5915, -21.1458],\n",
      "        [ 26.1620,  21.3802,  21.9510, -24.7488,  25.5219, -21.6537],\n",
      "        [ 26.5134,  21.5559,  22.4955, -24.5894,  25.7883, -21.7469]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.491441249847412\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0001, 20.9417, 21.8704],\n",
      "        [26.2266, 21.4908, 22.0638],\n",
      "        [26.0948, 21.6554, 22.7520],\n",
      "        [25.8904, 20.7471, 21.5708],\n",
      "        [25.2894, 20.6353, 21.4714],\n",
      "        [25.2824, 20.3017, 21.3245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.9033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9619,  25.9000, -21.7658],\n",
      "        [-24.2407,  25.7958, -20.9863],\n",
      "        [-25.0597,  26.4445, -21.4908],\n",
      "        [-25.1490,  26.5594, -22.1860],\n",
      "        [-24.6651,  25.5502, -21.6314],\n",
      "        [-24.5177,  25.7543, -21.7457]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0001,  20.9417,  21.8704, -24.9619,  25.9000, -21.7658],\n",
      "        [ 26.2266,  21.4908,  22.0638, -24.2407,  25.7958, -20.9863],\n",
      "        [ 26.0948,  21.6554,  22.7520, -25.0597,  26.4445, -21.4908],\n",
      "        [ 25.8904,  20.7471,  21.5708, -25.1490,  26.5594, -22.1860],\n",
      "        [ 25.2894,  20.6353,  21.4714, -24.6651,  25.5502, -21.6314],\n",
      "        [ 25.2824,  20.3017,  21.3245, -24.5177,  25.7543, -21.7457]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.467453956604004\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6958, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8709, 20.7085, 21.5925],\n",
      "        [26.3487, 21.5117, 22.3037],\n",
      "        [26.2252, 21.0366, 21.9598],\n",
      "        [26.0748, 21.3193, 22.2101],\n",
      "        [26.1658, 21.2253, 21.9429],\n",
      "        [25.9679, 21.2450, 22.3299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.3285, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8950,  25.9151, -21.8411],\n",
      "        [-24.3412,  25.6821, -21.3004],\n",
      "        [-24.8019,  26.3519, -21.7581],\n",
      "        [-25.1556,  26.0846, -22.0237],\n",
      "        [-24.8349,  26.0633, -21.6545],\n",
      "        [-24.8782,  26.0994, -21.5537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8709,  20.7085,  21.5925, -24.8950,  25.9151, -21.8411],\n",
      "        [ 26.3487,  21.5117,  22.3037, -24.3412,  25.6821, -21.3004],\n",
      "        [ 26.2252,  21.0366,  21.9598, -24.8019,  26.3519, -21.7581],\n",
      "        [ 26.0748,  21.3193,  22.2101, -25.1556,  26.0846, -22.0237],\n",
      "        [ 26.1658,  21.2253,  21.9429, -24.8349,  26.0633, -21.6545],\n",
      "        [ 25.9679,  21.2450,  22.3299, -24.8782,  26.0994, -21.5537]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.442300796508789\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4665, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0760, 20.9677, 21.9107],\n",
      "        [25.4834, 21.1735, 21.7437],\n",
      "        [25.7467, 21.1360, 21.5257],\n",
      "        [25.3209, 20.4968, 21.2443],\n",
      "        [25.8366, 21.1185, 21.5488],\n",
      "        [26.2324, 21.1910, 21.8755]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.5265, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8492,  26.1207, -21.7782],\n",
      "        [-24.5608,  25.4530, -21.9203],\n",
      "        [-24.6429,  25.9376, -21.6465],\n",
      "        [-24.0614,  25.4298, -20.8398],\n",
      "        [-24.4012,  26.2354, -21.7276],\n",
      "        [-24.8163,  25.8526, -21.9233]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0760,  20.9677,  21.9107, -24.8492,  26.1207, -21.7782],\n",
      "        [ 25.4834,  21.1735,  21.7437, -24.5608,  25.4530, -21.9203],\n",
      "        [ 25.7467,  21.1360,  21.5257, -24.6429,  25.9376, -21.6465],\n",
      "        [ 25.3209,  20.4968,  21.2443, -24.0614,  25.4298, -20.8398],\n",
      "        [ 25.8366,  21.1185,  21.5488, -24.4012,  26.2354, -21.7276],\n",
      "        [ 26.2324,  21.1910,  21.8755, -24.8163,  25.8526, -21.9233]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.482364654541016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7304, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1089, 21.0642, 22.1982],\n",
      "        [25.9100, 21.3189, 21.7385],\n",
      "        [26.2360, 21.8233, 21.8436],\n",
      "        [26.3441, 22.0241, 22.0879],\n",
      "        [25.6238, 21.1464, 22.0191],\n",
      "        [25.9007, 21.1067, 21.6812]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4203, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0012,  25.8074, -21.5588],\n",
      "        [-24.9650,  26.1268, -21.7844],\n",
      "        [-24.8523,  25.8862, -21.7133],\n",
      "        [-24.9084,  26.0689, -21.7052],\n",
      "        [-25.3224,  26.5812, -22.4501],\n",
      "        [-24.9488,  26.2520, -22.0423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1089,  21.0642,  22.1982, -25.0012,  25.8074, -21.5588],\n",
      "        [ 25.9100,  21.3189,  21.7385, -24.9650,  26.1268, -21.7844],\n",
      "        [ 26.2360,  21.8233,  21.8436, -24.8523,  25.8862, -21.7133],\n",
      "        [ 26.3441,  22.0241,  22.0879, -24.9084,  26.0689, -21.7052],\n",
      "        [ 25.6238,  21.1464,  22.0191, -25.3224,  26.5812, -22.4501],\n",
      "        [ 25.9007,  21.1067,  21.6812, -24.9488,  26.2520, -22.0423]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.489953994750977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3347, 21.0940, 21.9802],\n",
      "        [26.1356, 20.9422, 21.9209],\n",
      "        [25.3257, 20.9260, 22.2495],\n",
      "        [25.6987, 21.2127, 21.8298],\n",
      "        [26.1710, 20.9792, 21.7807],\n",
      "        [25.7258, 21.1310, 21.9506]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.4571, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4935,  26.0723, -21.7459],\n",
      "        [-24.8037,  26.4144, -22.0549],\n",
      "        [-24.7295,  26.5094, -22.4125],\n",
      "        [-24.3918,  25.7950, -21.8415],\n",
      "        [-24.7655,  25.9745, -21.8656],\n",
      "        [-25.2342,  26.2988, -22.1628]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3347,  21.0940,  21.9802, -24.4935,  26.0723, -21.7459],\n",
      "        [ 26.1356,  20.9422,  21.9209, -24.8037,  26.4144, -22.0549],\n",
      "        [ 25.3257,  20.9260,  22.2495, -24.7295,  26.5094, -22.4125],\n",
      "        [ 25.6987,  21.2127,  21.8298, -24.3918,  25.7950, -21.8415],\n",
      "        [ 26.1710,  20.9792,  21.7807, -24.7655,  25.9745, -21.8656],\n",
      "        [ 25.7258,  21.1310,  21.9506, -25.2342,  26.2988, -22.1628]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.492717266082764\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5160, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5744, 20.4329, 21.6467],\n",
      "        [25.9802, 21.0212, 21.5713],\n",
      "        [25.5714, 21.2724, 22.0828],\n",
      "        [25.8080, 20.9583, 22.0550],\n",
      "        [25.6193, 20.8524, 21.8334],\n",
      "        [25.7694, 20.7734, 21.6918]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.1005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.5068,  25.9908, -21.5956],\n",
      "        [-25.2976,  26.1073, -21.8634],\n",
      "        [-24.7105,  26.0756, -21.8121],\n",
      "        [-24.0552,  25.4660, -21.4872],\n",
      "        [-24.2366,  25.4600, -21.4310],\n",
      "        [-24.1587,  25.3742, -21.5436]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5744,  20.4329,  21.6467, -24.5068,  25.9908, -21.5956],\n",
      "        [ 25.9802,  21.0212,  21.5713, -25.2976,  26.1073, -21.8634],\n",
      "        [ 25.5714,  21.2724,  22.0828, -24.7105,  26.0756, -21.8121],\n",
      "        [ 25.8080,  20.9583,  22.0550, -24.0552,  25.4660, -21.4872],\n",
      "        [ 25.6193,  20.8524,  21.8334, -24.2366,  25.4600, -21.4310],\n",
      "        [ 25.7694,  20.7734,  21.6918, -24.1587,  25.3742, -21.5436]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.4094929695129395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9369, 21.3998, 22.0247],\n",
      "        [25.9207, 21.2463, 22.3138],\n",
      "        [25.7197, 20.9672, 21.8569],\n",
      "        [26.3272, 21.6355, 22.1023],\n",
      "        [25.2445, 20.6770, 21.7544],\n",
      "        [26.5836, 21.5166, 22.2579]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.7141, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.3556,  24.7940, -21.1670],\n",
      "        [-24.5500,  26.0508, -21.6029],\n",
      "        [-24.8401,  25.6198, -21.5731],\n",
      "        [-25.2177,  26.6707, -22.2640],\n",
      "        [-24.6293,  26.1348, -21.8745],\n",
      "        [-25.0923,  26.3293, -22.1213]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9369,  21.3998,  22.0247, -24.3556,  24.7940, -21.1670],\n",
      "        [ 25.9207,  21.2463,  22.3138, -24.5500,  26.0508, -21.6029],\n",
      "        [ 25.7197,  20.9672,  21.8569, -24.8401,  25.6198, -21.5731],\n",
      "        [ 26.3272,  21.6355,  22.1023, -25.2177,  26.6707, -22.2640],\n",
      "        [ 25.2445,  20.6770,  21.7544, -24.6293,  26.1348, -21.8745],\n",
      "        [ 26.5836,  21.5166,  22.2579, -25.0923,  26.3293, -22.1213]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.420872211456299\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7502, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1023, 21.2486, 21.7767],\n",
      "        [25.6018, 21.2431, 21.7064],\n",
      "        [25.7997, 20.5661, 21.9028],\n",
      "        [26.2884, 21.5313, 21.9491],\n",
      "        [25.7015, 21.0144, 22.0793],\n",
      "        [26.1132, 21.1760, 22.1962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4972,  25.6962, -21.9958],\n",
      "        [-24.3740,  25.5736, -21.4037],\n",
      "        [-24.4756,  26.0543, -21.9987],\n",
      "        [-25.2786,  26.5264, -22.3039],\n",
      "        [-25.0773,  26.2698, -21.9970],\n",
      "        [-24.9204,  25.8041, -21.8182]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1023,  21.2486,  21.7767, -24.4972,  25.6962, -21.9958],\n",
      "        [ 25.6018,  21.2431,  21.7064, -24.3740,  25.5736, -21.4037],\n",
      "        [ 25.7997,  20.5661,  21.9028, -24.4756,  26.0543, -21.9987],\n",
      "        [ 26.2884,  21.5313,  21.9491, -25.2786,  26.5264, -22.3039],\n",
      "        [ 25.7015,  21.0144,  22.0793, -25.0773,  26.2698, -21.9970],\n",
      "        [ 26.1132,  21.1760,  22.1962, -24.9204,  25.8041, -21.8182]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.4756317138671875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3051, 21.5290, 22.3358],\n",
      "        [25.9760, 21.7562, 22.2487],\n",
      "        [26.0974, 20.7634, 21.5679],\n",
      "        [26.2296, 21.4820, 22.3618],\n",
      "        [26.1999, 20.9944, 21.7516],\n",
      "        [25.9403, 21.5937, 21.9750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.6033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0455,  26.5490, -21.9657],\n",
      "        [-24.8409,  26.0356, -21.6940],\n",
      "        [-24.6236,  25.8480, -21.3404],\n",
      "        [-24.9664,  26.1877, -21.9688],\n",
      "        [-24.6608,  25.8647, -21.6359],\n",
      "        [-25.1394,  26.8829, -22.1155]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3051,  21.5290,  22.3358, -25.0455,  26.5490, -21.9657],\n",
      "        [ 25.9760,  21.7562,  22.2487, -24.8409,  26.0356, -21.6940],\n",
      "        [ 26.0974,  20.7634,  21.5679, -24.6236,  25.8480, -21.3404],\n",
      "        [ 26.2296,  21.4820,  22.3618, -24.9664,  26.1877, -21.9688],\n",
      "        [ 26.1999,  20.9944,  21.7516, -24.6608,  25.8647, -21.6359],\n",
      "        [ 25.9403,  21.5937,  21.9750, -25.1394,  26.8829, -22.1155]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.57146692276001\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0866, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.5320, 20.5143, 21.6388],\n",
      "        [26.4139, 21.5543, 22.3169],\n",
      "        [26.2887, 21.8542, 22.0605],\n",
      "        [26.1705, 20.8286, 21.8323],\n",
      "        [25.4908, 20.9037, 21.9067],\n",
      "        [25.8333, 21.1481, 22.0397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.1439,  25.3638, -21.2815],\n",
      "        [-24.4084,  25.5862, -21.6565],\n",
      "        [-24.2331,  25.9728, -21.7328],\n",
      "        [-24.6800,  26.1576, -21.5453],\n",
      "        [-24.8449,  26.2207, -22.0828],\n",
      "        [-25.1348,  26.5631, -21.9935]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.5320,  20.5143,  21.6388, -24.1439,  25.3638, -21.2815],\n",
      "        [ 26.4139,  21.5543,  22.3169, -24.4084,  25.5862, -21.6565],\n",
      "        [ 26.2887,  21.8542,  22.0605, -24.2331,  25.9728, -21.7328],\n",
      "        [ 26.1705,  20.8286,  21.8323, -24.6800,  26.1576, -21.5453],\n",
      "        [ 25.4908,  20.9037,  21.9067, -24.8449,  26.2207, -22.0828],\n",
      "        [ 25.8333,  21.1481,  22.0397, -25.1348,  26.5631, -21.9935]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.373328685760498\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3530, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.4396, 21.1307, 21.8483],\n",
      "        [25.8778, 21.1330, 22.0914],\n",
      "        [25.9731, 21.4678, 22.0960],\n",
      "        [26.7109, 21.5801, 22.1717],\n",
      "        [26.1668, 21.4381, 21.8078],\n",
      "        [26.2149, 21.3090, 22.1380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0105, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6194,  25.7944, -21.2845],\n",
      "        [-24.5929,  25.5472, -21.4735],\n",
      "        [-24.7675,  25.7403, -21.9643],\n",
      "        [-24.6746,  25.8019, -21.4044],\n",
      "        [-24.7777,  26.0422, -21.9609],\n",
      "        [-25.3414,  26.9175, -22.5031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.4396,  21.1307,  21.8483, -24.6194,  25.7944, -21.2845],\n",
      "        [ 25.8778,  21.1330,  22.0914, -24.5929,  25.5472, -21.4735],\n",
      "        [ 25.9731,  21.4678,  22.0960, -24.7675,  25.7403, -21.9643],\n",
      "        [ 26.7109,  21.5801,  22.1717, -24.6746,  25.8019, -21.4044],\n",
      "        [ 26.1668,  21.4381,  21.8078, -24.7777,  26.0422, -21.9609],\n",
      "        [ 26.2149,  21.3090,  22.1380, -25.3414,  26.9175, -22.5031]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.432501792907715\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7429, 20.7484, 21.4868],\n",
      "        [26.6742, 21.4552, 22.5413],\n",
      "        [26.4062, 21.5897, 22.3591],\n",
      "        [25.2574, 20.9290, 21.4358],\n",
      "        [25.6220, 21.0232, 21.7134],\n",
      "        [25.7483, 21.2693, 22.1621]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.1890, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1450,  26.4214, -22.1627],\n",
      "        [-25.1597,  26.5037, -21.8587],\n",
      "        [-24.9752,  26.1649, -21.6995],\n",
      "        [-24.5060,  25.6411, -21.6180],\n",
      "        [-25.4426,  26.5035, -22.3485],\n",
      "        [-25.0490,  26.0854, -21.9208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7429,  20.7484,  21.4868, -25.1450,  26.4214, -22.1627],\n",
      "        [ 26.6742,  21.4552,  22.5413, -25.1597,  26.5037, -21.8587],\n",
      "        [ 26.4062,  21.5897,  22.3591, -24.9752,  26.1649, -21.6995],\n",
      "        [ 25.2574,  20.9290,  21.4358, -24.5060,  25.6411, -21.6180],\n",
      "        [ 25.6220,  21.0232,  21.7134, -25.4426,  26.5035, -22.3485],\n",
      "        [ 25.7483,  21.2693,  22.1621, -25.0490,  26.0854, -21.9208]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.486160755157471\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.3839, 20.6611, 21.5932],\n",
      "        [26.0257, 21.2208, 22.1684],\n",
      "        [26.1054, 21.0581, 22.3837],\n",
      "        [26.5151, 21.6091, 22.2096],\n",
      "        [26.0271, 21.1503, 21.8802],\n",
      "        [26.0809, 21.2727, 22.3221]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.1284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7895,  25.8353, -21.8174],\n",
      "        [-24.6444,  25.3518, -20.9959],\n",
      "        [-24.5291,  26.1810, -21.5121],\n",
      "        [-24.5493,  25.6718, -21.6221],\n",
      "        [-24.8887,  26.3295, -22.2264],\n",
      "        [-24.8784,  26.1913, -21.7229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.3839,  20.6611,  21.5932, -24.7895,  25.8353, -21.8174],\n",
      "        [ 26.0257,  21.2208,  22.1684, -24.6444,  25.3518, -20.9959],\n",
      "        [ 26.1054,  21.0581,  22.3837, -24.5291,  26.1810, -21.5121],\n",
      "        [ 26.5151,  21.6091,  22.2096, -24.5493,  25.6718, -21.6221],\n",
      "        [ 26.0271,  21.1503,  21.8802, -24.8887,  26.3295, -22.2264],\n",
      "        [ 26.0809,  21.2727,  22.3221, -24.8784,  26.1913, -21.7229]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.427718162536621\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0318, 21.7364, 22.0858],\n",
      "        [25.4954, 20.7774, 21.7424],\n",
      "        [26.4928, 21.2779, 22.5453],\n",
      "        [26.4092, 21.4572, 22.2755],\n",
      "        [25.9260, 21.2154, 22.2631],\n",
      "        [25.8043, 20.8987, 22.0703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.5420, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2900,  26.5042, -22.2311],\n",
      "        [-24.9083,  25.8232, -21.9865],\n",
      "        [-24.2736,  26.3824, -22.0042],\n",
      "        [-25.0885,  26.3657, -21.9378],\n",
      "        [-25.0463,  25.9103, -21.8636],\n",
      "        [-24.5463,  25.7691, -21.6152]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0318,  21.7364,  22.0858, -25.2900,  26.5042, -22.2311],\n",
      "        [ 25.4954,  20.7774,  21.7424, -24.9083,  25.8232, -21.9865],\n",
      "        [ 26.4928,  21.2779,  22.5453, -24.2736,  26.3824, -22.0042],\n",
      "        [ 26.4092,  21.4572,  22.2755, -25.0885,  26.3657, -21.9378],\n",
      "        [ 25.9260,  21.2154,  22.2631, -25.0463,  25.9103, -21.8636],\n",
      "        [ 25.8043,  20.8987,  22.0703, -24.5463,  25.7691, -21.6152]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.57621431350708\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0502, 21.0153, 21.9258],\n",
      "        [26.2032, 21.6359, 22.0162],\n",
      "        [25.9805, 21.2932, 22.2047],\n",
      "        [25.6132, 20.8216, 21.8126],\n",
      "        [25.6545, 21.0201, 21.7866],\n",
      "        [26.2968, 21.7210, 22.5399]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.0905, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4873,  25.9082, -21.9191],\n",
      "        [-24.5748,  26.0607, -21.4942],\n",
      "        [-25.6578,  26.6959, -22.5941],\n",
      "        [-25.1755,  26.2389, -22.0795],\n",
      "        [-24.9038,  25.9203, -21.4119],\n",
      "        [-24.5710,  25.8171, -21.7138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0502,  21.0153,  21.9258, -24.4873,  25.9082, -21.9191],\n",
      "        [ 26.2032,  21.6359,  22.0162, -24.5748,  26.0607, -21.4942],\n",
      "        [ 25.9805,  21.2932,  22.2047, -25.6578,  26.6959, -22.5941],\n",
      "        [ 25.6132,  20.8216,  21.8126, -25.1755,  26.2389, -22.0795],\n",
      "        [ 25.6545,  21.0201,  21.7866, -24.9038,  25.9203, -21.4119],\n",
      "        [ 26.2968,  21.7210,  22.5399, -24.5710,  25.8171, -21.7138]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.489541053771973\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6094, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3447, 21.2664, 22.4758],\n",
      "        [26.6322, 21.8264, 22.5430],\n",
      "        [26.2387, 21.0994, 22.3050],\n",
      "        [26.1641, 21.1107, 21.7373],\n",
      "        [26.1915, 21.4313, 22.1483],\n",
      "        [26.2983, 21.3389, 21.8339]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9316,  26.3696, -22.1128],\n",
      "        [-25.4525,  26.5101, -22.1056],\n",
      "        [-24.5230,  25.7472, -21.5393],\n",
      "        [-24.7216,  26.1653, -21.7767],\n",
      "        [-24.9102,  26.0938, -21.5672],\n",
      "        [-24.6069,  26.2033, -22.1051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3447,  21.2664,  22.4758, -24.9316,  26.3696, -22.1128],\n",
      "        [ 26.6322,  21.8264,  22.5430, -25.4525,  26.5101, -22.1056],\n",
      "        [ 26.2387,  21.0994,  22.3050, -24.5230,  25.7472, -21.5393],\n",
      "        [ 26.1641,  21.1107,  21.7373, -24.7216,  26.1653, -21.7767],\n",
      "        [ 26.1915,  21.4313,  22.1483, -24.9102,  26.0938, -21.5672],\n",
      "        [ 26.2983,  21.3389,  21.8339, -24.6069,  26.2033, -22.1051]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.577768802642822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8920, 20.9423, 21.9085],\n",
      "        [26.0040, 21.0145, 21.9822],\n",
      "        [25.9019, 20.9212, 22.1207],\n",
      "        [26.0514, 21.3132, 22.3375],\n",
      "        [26.1785, 21.6517, 21.9028],\n",
      "        [25.6953, 20.9697, 21.8196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.9266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8855,  26.4149, -21.8118],\n",
      "        [-25.3649,  25.9958, -21.8810],\n",
      "        [-25.4544,  26.4406, -22.4733],\n",
      "        [-24.7507,  26.3943, -22.1306],\n",
      "        [-24.9310,  26.1283, -21.7263],\n",
      "        [-25.3974,  26.4753, -22.2763]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8920,  20.9423,  21.9085, -24.8855,  26.4149, -21.8118],\n",
      "        [ 26.0040,  21.0145,  21.9822, -25.3649,  25.9958, -21.8810],\n",
      "        [ 25.9019,  20.9212,  22.1207, -25.4544,  26.4406, -22.4733],\n",
      "        [ 26.0514,  21.3132,  22.3375, -24.7507,  26.3943, -22.1306],\n",
      "        [ 26.1785,  21.6517,  21.9028, -24.9310,  26.1283, -21.7263],\n",
      "        [ 25.6953,  20.9697,  21.8196, -25.3974,  26.4753, -22.2763]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.5101728439331055\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2672, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7536, 21.1438, 22.0725],\n",
      "        [26.4706, 21.4746, 22.0457],\n",
      "        [25.6002, 20.7251, 21.7496],\n",
      "        [26.1543, 21.3135, 22.0923],\n",
      "        [26.6577, 21.7720, 22.4766],\n",
      "        [25.9770, 21.1095, 22.0654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.1101, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8526,  26.2893, -22.2607],\n",
      "        [-25.2114,  25.9458, -21.8396],\n",
      "        [-24.9243,  26.8133, -22.0156],\n",
      "        [-24.9704,  26.3115, -21.9531],\n",
      "        [-24.7629,  25.7363, -21.8920],\n",
      "        [-25.1416,  26.1115, -22.1043]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7536,  21.1438,  22.0725, -24.8526,  26.2893, -22.2607],\n",
      "        [ 26.4706,  21.4746,  22.0457, -25.2114,  25.9458, -21.8396],\n",
      "        [ 25.6002,  20.7251,  21.7496, -24.9243,  26.8133, -22.0156],\n",
      "        [ 26.1543,  21.3135,  22.0923, -24.9704,  26.3115, -21.9531],\n",
      "        [ 26.6577,  21.7720,  22.4766, -24.7629,  25.7363, -21.8920],\n",
      "        [ 25.9770,  21.1095,  22.0654, -25.1416,  26.1115, -22.1043]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.525979042053223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5076, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3953, 21.7505, 22.0016],\n",
      "        [26.4127, 21.3888, 22.3195],\n",
      "        [26.1565, 21.5468, 22.1077],\n",
      "        [26.2929, 21.3969, 22.1325],\n",
      "        [25.5736, 21.3409, 22.1069],\n",
      "        [25.7688, 21.2912, 21.7511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.8415, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9239,  26.1805, -21.7043],\n",
      "        [-24.9356,  26.3452, -21.7756],\n",
      "        [-25.6442,  26.8078, -22.4754],\n",
      "        [-24.5539,  26.1219, -21.9773],\n",
      "        [-24.6197,  25.3682, -21.4511],\n",
      "        [-24.6539,  26.0602, -21.7967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3953,  21.7505,  22.0016, -24.9239,  26.1805, -21.7043],\n",
      "        [ 26.4127,  21.3888,  22.3195, -24.9356,  26.3452, -21.7756],\n",
      "        [ 26.1565,  21.5468,  22.1077, -25.6442,  26.8078, -22.4754],\n",
      "        [ 26.2929,  21.3969,  22.1325, -24.5539,  26.1219, -21.9773],\n",
      "        [ 25.5736,  21.3409,  22.1069, -24.6197,  25.3682, -21.4511],\n",
      "        [ 25.7688,  21.2912,  21.7511, -24.6539,  26.0602, -21.7967]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.562824249267578\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4985, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6374, 21.4917, 22.4730],\n",
      "        [26.0553, 21.3090, 22.0189],\n",
      "        [25.6671, 21.1701, 21.6242],\n",
      "        [25.5820, 20.4681, 21.2327],\n",
      "        [26.2987, 21.5284, 22.3137],\n",
      "        [26.0509, 21.3715, 22.1141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(49.7523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6968,  25.6666, -21.5995],\n",
      "        [-24.8269,  25.9121, -21.8930],\n",
      "        [-24.9094,  26.0671, -22.1908],\n",
      "        [-24.3105,  25.9606, -21.6949],\n",
      "        [-25.0571,  26.2524, -21.7664],\n",
      "        [-24.6150,  25.7888, -21.5315]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6374,  21.4917,  22.4730, -24.6968,  25.6666, -21.5995],\n",
      "        [ 26.0553,  21.3090,  22.0189, -24.8269,  25.9121, -21.8930],\n",
      "        [ 25.6671,  21.1701,  21.6242, -24.9094,  26.0671, -22.1908],\n",
      "        [ 25.5820,  20.4681,  21.2327, -24.3105,  25.9606, -21.6949],\n",
      "        [ 26.2987,  21.5284,  22.3137, -25.0571,  26.2524, -21.7664],\n",
      "        [ 26.0509,  21.3715,  22.1141, -24.6150,  25.7888, -21.5315]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.507148742675781\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0211, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0307, 21.5194, 22.2521],\n",
      "        [26.0868, 21.3769, 22.2011],\n",
      "        [26.0364, 21.5121, 22.4626],\n",
      "        [26.1693, 21.0602, 22.2134],\n",
      "        [25.7367, 20.8807, 22.1395],\n",
      "        [26.1040, 21.5635, 22.3413]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.8491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0794,  26.4274, -22.0879],\n",
      "        [-25.6723,  26.6417, -22.4133],\n",
      "        [-25.0791,  26.0437, -22.0560],\n",
      "        [-25.2306,  26.5526, -22.1839],\n",
      "        [-25.0569,  26.0857, -22.0059],\n",
      "        [-24.6326,  25.7694, -21.9498]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0307,  21.5194,  22.2521, -25.0794,  26.4274, -22.0879],\n",
      "        [ 26.0868,  21.3769,  22.2011, -25.6723,  26.6417, -22.4133],\n",
      "        [ 26.0364,  21.5121,  22.4626, -25.0791,  26.0437, -22.0560],\n",
      "        [ 26.1693,  21.0602,  22.2134, -25.2306,  26.5526, -22.1839],\n",
      "        [ 25.7367,  20.8807,  22.1395, -25.0569,  26.0857, -22.0059],\n",
      "        [ 26.1040,  21.5635,  22.3413, -24.6326,  25.7694, -21.9498]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.575327396392822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3616, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0326, 21.0988, 21.8785],\n",
      "        [25.5740, 20.8567, 22.1713],\n",
      "        [25.5939, 21.0155, 21.6820],\n",
      "        [25.9231, 21.4294, 22.2751],\n",
      "        [25.4708, 20.8060, 21.9081],\n",
      "        [26.4754, 21.8301, 22.0278]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.9149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9300,  26.3007, -21.7725],\n",
      "        [-24.9052,  25.8077, -21.8890],\n",
      "        [-24.7688,  26.2289, -21.9481],\n",
      "        [-24.6195,  25.6021, -21.6544],\n",
      "        [-24.7535,  26.3940, -22.1473],\n",
      "        [-24.8343,  26.3403, -21.6991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0326,  21.0988,  21.8785, -24.9300,  26.3007, -21.7725],\n",
      "        [ 25.5740,  20.8567,  22.1713, -24.9052,  25.8077, -21.8890],\n",
      "        [ 25.5939,  21.0155,  21.6820, -24.7688,  26.2289, -21.9481],\n",
      "        [ 25.9231,  21.4294,  22.2751, -24.6195,  25.6021, -21.6544],\n",
      "        [ 25.4708,  20.8060,  21.9081, -24.7535,  26.3940, -22.1473],\n",
      "        [ 26.4754,  21.8301,  22.0278, -24.8343,  26.3403, -21.6991]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.5273213386535645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7364, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9608, 21.2461, 21.9448],\n",
      "        [26.4394, 21.3377, 22.2174],\n",
      "        [25.9578, 21.3364, 22.0232],\n",
      "        [26.1071, 21.7843, 21.9577],\n",
      "        [25.8580, 21.4605, 21.7067],\n",
      "        [25.9319, 21.1588, 22.0703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.5358, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7245,  26.0458, -21.8624],\n",
      "        [-24.8619,  26.0675, -22.0226],\n",
      "        [-24.5231,  25.3600, -21.1531],\n",
      "        [-25.1988,  26.5003, -22.2690],\n",
      "        [-25.0823,  26.4464, -22.0081],\n",
      "        [-24.9298,  26.3139, -21.6015]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9608,  21.2461,  21.9448, -24.7245,  26.0458, -21.8624],\n",
      "        [ 26.4394,  21.3377,  22.2174, -24.8619,  26.0675, -22.0226],\n",
      "        [ 25.9578,  21.3364,  22.0232, -24.5231,  25.3600, -21.1531],\n",
      "        [ 26.1071,  21.7843,  21.9577, -25.1988,  26.5003, -22.2690],\n",
      "        [ 25.8580,  21.4605,  21.7067, -25.0823,  26.4464, -22.0081],\n",
      "        [ 25.9319,  21.1588,  22.0703, -24.9298,  26.3139, -21.6015]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.519763469696045\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8601, 21.2257, 21.8403],\n",
      "        [26.5726, 21.5472, 22.1705],\n",
      "        [26.1725, 21.5800, 22.2815],\n",
      "        [25.9714, 21.1716, 22.4106],\n",
      "        [26.1217, 21.5747, 22.2839],\n",
      "        [26.3715, 21.4042, 22.4311]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(32.9393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2753,  26.5454, -22.0992],\n",
      "        [-25.0241,  26.6458, -22.0502],\n",
      "        [-25.3137,  26.5517, -21.9267],\n",
      "        [-24.7621,  26.3028, -21.7100],\n",
      "        [-25.1881,  26.0424, -22.3625],\n",
      "        [-24.3011,  25.6130, -21.5603]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8601,  21.2257,  21.8403, -25.2753,  26.5454, -22.0992],\n",
      "        [ 26.5726,  21.5472,  22.1705, -25.0241,  26.6458, -22.0502],\n",
      "        [ 26.1725,  21.5800,  22.2815, -25.3137,  26.5517, -21.9267],\n",
      "        [ 25.9714,  21.1716,  22.4106, -24.7621,  26.3028, -21.7100],\n",
      "        [ 26.1217,  21.5747,  22.2839, -25.1881,  26.0424, -22.3625],\n",
      "        [ 26.3715,  21.4042,  22.4311, -24.3011,  25.6130, -21.5603]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.55424690246582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3567, 21.1396, 22.2336],\n",
      "        [26.5282, 21.8440, 22.4842],\n",
      "        [26.0198, 21.0807, 21.8781],\n",
      "        [26.2649, 21.7817, 21.9737],\n",
      "        [26.8084, 21.7569, 22.6573],\n",
      "        [26.2701, 21.3781, 22.0383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9739, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7414,  26.3521, -22.0965],\n",
      "        [-24.8915,  25.9831, -21.7800],\n",
      "        [-25.2168,  26.4713, -22.1742],\n",
      "        [-24.8465,  26.0456, -21.6711],\n",
      "        [-24.3693,  26.0715, -21.7585],\n",
      "        [-24.7980,  26.0242, -22.0283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3567,  21.1396,  22.2336, -24.7414,  26.3521, -22.0965],\n",
      "        [ 26.5282,  21.8440,  22.4842, -24.8915,  25.9831, -21.7800],\n",
      "        [ 26.0198,  21.0807,  21.8781, -25.2168,  26.4713, -22.1742],\n",
      "        [ 26.2649,  21.7817,  21.9737, -24.8465,  26.0456, -21.6711],\n",
      "        [ 26.8084,  21.7569,  22.6573, -24.3693,  26.0715, -21.7585],\n",
      "        [ 26.2701,  21.3781,  22.0383, -24.7980,  26.0242, -22.0283]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.572372913360596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0575, 21.5404, 22.2240],\n",
      "        [26.0557, 21.2737, 22.3228],\n",
      "        [26.6332, 21.6935, 21.8718],\n",
      "        [25.6174, 21.0876, 21.9170],\n",
      "        [26.3343, 21.4638, 21.7344],\n",
      "        [26.2803, 21.8458, 22.2949]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.5069, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0461,  26.4443, -22.0573],\n",
      "        [-24.8536,  26.2056, -21.8447],\n",
      "        [-24.4643,  25.9118, -21.3850],\n",
      "        [-25.1177,  26.6270, -22.1968],\n",
      "        [-24.7870,  26.3738, -22.0996],\n",
      "        [-24.6072,  26.3480, -22.0428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0575,  21.5404,  22.2240, -25.0461,  26.4443, -22.0573],\n",
      "        [ 26.0557,  21.2737,  22.3228, -24.8536,  26.2056, -21.8447],\n",
      "        [ 26.6332,  21.6935,  21.8718, -24.4643,  25.9118, -21.3850],\n",
      "        [ 25.6174,  21.0876,  21.9170, -25.1177,  26.6270, -22.1968],\n",
      "        [ 26.3343,  21.4638,  21.7344, -24.7870,  26.3738, -22.0996],\n",
      "        [ 26.2803,  21.8458,  22.2949, -24.6072,  26.3480, -22.0428]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.584198951721191\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2821, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7798, 21.1394, 21.9911],\n",
      "        [26.0998, 21.1810, 22.5318],\n",
      "        [26.1788, 21.3566, 22.3657],\n",
      "        [26.1241, 21.2673, 22.1722],\n",
      "        [26.8338, 21.8690, 22.6617],\n",
      "        [26.2033, 21.6337, 22.1609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.8043, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9774,  26.1344, -22.2085],\n",
      "        [-25.3841,  26.7664, -22.3219],\n",
      "        [-24.7578,  26.2661, -21.9881],\n",
      "        [-24.9779,  26.3829, -22.1897],\n",
      "        [-24.8610,  25.9444, -21.6010],\n",
      "        [-24.9398,  26.1391, -21.9667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7798,  21.1394,  21.9911, -24.9774,  26.1344, -22.2085],\n",
      "        [ 26.0998,  21.1810,  22.5318, -25.3841,  26.7664, -22.3219],\n",
      "        [ 26.1788,  21.3566,  22.3657, -24.7578,  26.2661, -21.9881],\n",
      "        [ 26.1241,  21.2673,  22.1722, -24.9779,  26.3829, -22.1897],\n",
      "        [ 26.8338,  21.8690,  22.6617, -24.8610,  25.9444, -21.6010],\n",
      "        [ 26.2033,  21.6337,  22.1609, -24.9398,  26.1391, -21.9667]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.537455081939697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0969, 20.8343, 22.4156],\n",
      "        [25.7843, 21.3253, 22.1170],\n",
      "        [25.8782, 21.2399, 21.9146],\n",
      "        [25.9391, 21.1391, 22.1038],\n",
      "        [26.0836, 21.5048, 22.5499],\n",
      "        [26.2368, 21.2694, 22.5725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.6988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7312,  25.9870, -21.3210],\n",
      "        [-24.8881,  25.5366, -21.4476],\n",
      "        [-25.3687,  26.5765, -22.3236],\n",
      "        [-24.7201,  26.2016, -21.6570],\n",
      "        [-24.9134,  25.8092, -21.7679],\n",
      "        [-24.4964,  26.0551, -21.9622]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0969,  20.8343,  22.4156, -24.7312,  25.9870, -21.3210],\n",
      "        [ 25.7843,  21.3253,  22.1170, -24.8881,  25.5366, -21.4476],\n",
      "        [ 25.8782,  21.2399,  21.9146, -25.3687,  26.5765, -22.3236],\n",
      "        [ 25.9391,  21.1391,  22.1038, -24.7201,  26.2016, -21.6570],\n",
      "        [ 26.0836,  21.5048,  22.5499, -24.9134,  25.8092, -21.7679],\n",
      "        [ 26.2368,  21.2694,  22.5725, -24.4964,  26.0551, -21.9622]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.52610445022583\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7611, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7624, 21.2109, 22.0153],\n",
      "        [25.8783, 21.4617, 21.5016],\n",
      "        [26.4869, 21.5030, 22.3699],\n",
      "        [26.0968, 21.7442, 22.0426],\n",
      "        [27.1080, 21.9381, 22.7457],\n",
      "        [26.7322, 21.7793, 22.4806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6216, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6204,  26.2177, -22.1043],\n",
      "        [-24.7036,  26.1762, -21.7639],\n",
      "        [-25.0378,  26.1124, -22.0345],\n",
      "        [-25.2043,  26.4660, -22.2254],\n",
      "        [-24.7479,  26.4436, -22.0315],\n",
      "        [-24.7323,  25.6503, -21.8265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7624,  21.2109,  22.0153, -24.6204,  26.2177, -22.1043],\n",
      "        [ 25.8783,  21.4617,  21.5016, -24.7036,  26.1762, -21.7639],\n",
      "        [ 26.4869,  21.5030,  22.3699, -25.0378,  26.1124, -22.0345],\n",
      "        [ 26.0968,  21.7442,  22.0426, -25.2043,  26.4660, -22.2254],\n",
      "        [ 27.1080,  21.9381,  22.7457, -24.7479,  26.4436, -22.0315],\n",
      "        [ 26.7322,  21.7793,  22.4806, -24.7323,  25.6503, -21.8265]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.531702041625977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5485, 21.3708, 22.1292],\n",
      "        [26.1491, 21.0846, 21.9379],\n",
      "        [26.1394, 21.3625, 21.7776],\n",
      "        [26.3657, 21.3796, 21.8691],\n",
      "        [26.5959, 21.4204, 22.3932],\n",
      "        [26.1656, 21.1269, 22.0883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.1417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8914,  26.6798, -22.2370],\n",
      "        [-25.3384,  26.8293, -22.4539],\n",
      "        [-25.3855,  26.8081, -22.3122],\n",
      "        [-24.9981,  26.4453, -22.0670],\n",
      "        [-25.7756,  26.6841, -22.7672],\n",
      "        [-24.6259,  25.4621, -20.9721]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5485,  21.3708,  22.1292, -24.8914,  26.6798, -22.2370],\n",
      "        [ 26.1491,  21.0846,  21.9379, -25.3384,  26.8293, -22.4539],\n",
      "        [ 26.1394,  21.3625,  21.7776, -25.3855,  26.8081, -22.3122],\n",
      "        [ 26.3657,  21.3796,  21.8691, -24.9981,  26.4453, -22.0670],\n",
      "        [ 26.5959,  21.4204,  22.3932, -25.7756,  26.6841, -22.7672],\n",
      "        [ 26.1656,  21.1269,  22.0883, -24.6259,  25.4621, -20.9721]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.616271018981934\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.9647, 21.5625, 22.6429],\n",
      "        [26.2839, 21.5740, 22.2754],\n",
      "        [26.2663, 21.3267, 22.1853],\n",
      "        [26.7759, 21.8166, 22.2622],\n",
      "        [26.0040, 21.4887, 21.9850],\n",
      "        [26.4391, 21.4094, 22.3165]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0481, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7253,  26.3067, -22.0110],\n",
      "        [-25.0575,  26.2359, -22.0337],\n",
      "        [-24.7563,  26.1939, -22.0499],\n",
      "        [-24.3470,  25.8402, -21.7709],\n",
      "        [-24.7841,  25.9879, -21.8120],\n",
      "        [-24.6968,  26.4944, -21.8791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.9647,  21.5625,  22.6429, -24.7253,  26.3067, -22.0110],\n",
      "        [ 26.2839,  21.5740,  22.2754, -25.0575,  26.2359, -22.0337],\n",
      "        [ 26.2663,  21.3267,  22.1853, -24.7563,  26.1939, -22.0499],\n",
      "        [ 26.7759,  21.8166,  22.2622, -24.3470,  25.8402, -21.7709],\n",
      "        [ 26.0040,  21.4887,  21.9850, -24.7841,  25.9879, -21.8120],\n",
      "        [ 26.4391,  21.4094,  22.3165, -24.6968,  26.4944, -21.8791]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.591063499450684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1222, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1783, 21.2778, 22.1622],\n",
      "        [26.0306, 20.7932, 21.9328],\n",
      "        [26.0382, 21.4232, 22.1255],\n",
      "        [26.0421, 20.9853, 21.5817],\n",
      "        [26.4254, 21.4467, 22.2051],\n",
      "        [26.7624, 22.1061, 22.8158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.0396, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9994,  26.0377, -22.0045],\n",
      "        [-24.9699,  26.2634, -22.1388],\n",
      "        [-24.9710,  25.6978, -21.9565],\n",
      "        [-24.7189,  25.8997, -21.9723],\n",
      "        [-24.8153,  26.3926, -22.1028],\n",
      "        [-24.8401,  26.2873, -21.9303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1783,  21.2778,  22.1622, -24.9994,  26.0377, -22.0045],\n",
      "        [ 26.0306,  20.7932,  21.9328, -24.9699,  26.2634, -22.1388],\n",
      "        [ 26.0382,  21.4232,  22.1255, -24.9710,  25.6978, -21.9565],\n",
      "        [ 26.0421,  20.9853,  21.5817, -24.7189,  25.8997, -21.9723],\n",
      "        [ 26.4254,  21.4467,  22.2051, -24.8153,  26.3926, -22.1028],\n",
      "        [ 26.7624,  22.1061,  22.8158, -24.8401,  26.2873, -21.9303]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.572196006774902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9476, 21.8382, 22.5152],\n",
      "        [25.7358, 21.0659, 21.6076],\n",
      "        [26.1611, 21.4688, 22.3154],\n",
      "        [25.6039, 21.0861, 22.3238],\n",
      "        [26.1288, 21.5371, 21.9778],\n",
      "        [26.2613, 21.3723, 22.2632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3521, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8881,  26.2620, -21.8151],\n",
      "        [-24.8614,  26.1800, -22.0165],\n",
      "        [-25.3686,  26.7412, -22.7219],\n",
      "        [-24.1187,  25.3816, -21.2096],\n",
      "        [-24.8299,  26.0495, -22.0410],\n",
      "        [-24.8299,  25.7517, -21.7547]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9476,  21.8382,  22.5152, -24.8881,  26.2620, -21.8151],\n",
      "        [ 25.7358,  21.0659,  21.6076, -24.8614,  26.1800, -22.0165],\n",
      "        [ 26.1611,  21.4688,  22.3154, -25.3686,  26.7412, -22.7219],\n",
      "        [ 25.6039,  21.0861,  22.3238, -24.1187,  25.3816, -21.2096],\n",
      "        [ 26.1288,  21.5371,  21.9778, -24.8299,  26.0495, -22.0410],\n",
      "        [ 26.2613,  21.3723,  22.2632, -24.8299,  25.7517, -21.7547]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.649867057800293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2497, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4683, 21.6060, 22.4147],\n",
      "        [25.9633, 21.1337, 21.9821],\n",
      "        [26.1416, 21.5152, 22.2303],\n",
      "        [26.4595, 21.8038, 22.4439],\n",
      "        [26.3814, 21.6013, 22.3352],\n",
      "        [26.6847, 21.6902, 22.2174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.4855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3276,  26.9487, -22.8453],\n",
      "        [-25.0121,  26.5013, -22.2839],\n",
      "        [-25.1279,  26.0002, -21.9274],\n",
      "        [-25.2416,  25.8530, -21.9180],\n",
      "        [-24.8864,  26.0574, -22.2035],\n",
      "        [-25.5256,  26.4310, -22.3442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4683,  21.6060,  22.4147, -25.3276,  26.9487, -22.8453],\n",
      "        [ 25.9633,  21.1337,  21.9821, -25.0121,  26.5013, -22.2839],\n",
      "        [ 26.1416,  21.5152,  22.2303, -25.1279,  26.0002, -21.9274],\n",
      "        [ 26.4595,  21.8038,  22.4439, -25.2416,  25.8530, -21.9180],\n",
      "        [ 26.3814,  21.6013,  22.3352, -24.8864,  26.0574, -22.2035],\n",
      "        [ 26.6847,  21.6902,  22.2174, -25.5256,  26.4310, -22.3442]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.682504653930664\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6547, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.8461, 21.1930, 22.2703],\n",
      "        [26.2216, 21.1295, 22.1272],\n",
      "        [26.3494, 21.5784, 22.0763],\n",
      "        [26.1722, 21.5013, 22.6344],\n",
      "        [26.5414, 21.6349, 22.5822],\n",
      "        [26.6911, 21.7519, 22.3385]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.6559, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8105,  25.6007, -21.8477],\n",
      "        [-24.9104,  26.2923, -21.9956],\n",
      "        [-24.9356,  26.3120, -22.0251],\n",
      "        [-25.2273,  26.0613, -21.8225],\n",
      "        [-24.7256,  26.0499, -21.3924],\n",
      "        [-25.5327,  26.7026, -22.5726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.8461,  21.1930,  22.2703, -24.8105,  25.6007, -21.8477],\n",
      "        [ 26.2216,  21.1295,  22.1272, -24.9104,  26.2923, -21.9956],\n",
      "        [ 26.3494,  21.5784,  22.0763, -24.9356,  26.3120, -22.0251],\n",
      "        [ 26.1722,  21.5013,  22.6344, -25.2273,  26.0613, -21.8225],\n",
      "        [ 26.5414,  21.6349,  22.5822, -24.7256,  26.0499, -21.3924],\n",
      "        [ 26.6911,  21.7519,  22.3385, -25.5327,  26.7026, -22.5726]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.535098552703857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6645, 21.2914, 22.1017],\n",
      "        [26.1028, 21.3386, 21.5632],\n",
      "        [26.4992, 21.6088, 22.4143],\n",
      "        [26.0585, 21.4819, 21.9558],\n",
      "        [26.7177, 21.7477, 22.3207],\n",
      "        [26.2935, 20.7500, 22.2241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.4926, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4578,  26.9008, -22.5223],\n",
      "        [-24.1559,  25.8065, -21.2823],\n",
      "        [-24.3207,  26.0051, -21.8899],\n",
      "        [-25.9767,  27.2721, -22.7357],\n",
      "        [-24.8387,  25.7905, -22.0262],\n",
      "        [-25.5313,  26.8994, -22.5597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6645,  21.2914,  22.1017, -25.4578,  26.9008, -22.5223],\n",
      "        [ 26.1028,  21.3386,  21.5632, -24.1559,  25.8065, -21.2823],\n",
      "        [ 26.4992,  21.6088,  22.4143, -24.3207,  26.0051, -21.8899],\n",
      "        [ 26.0585,  21.4819,  21.9558, -25.9767,  27.2721, -22.7357],\n",
      "        [ 26.7177,  21.7477,  22.3207, -24.8387,  25.7905, -22.0262],\n",
      "        [ 26.2935,  20.7500,  22.2241, -25.5313,  26.8994, -22.5597]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.611397743225098\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7681, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3916, 21.5980, 22.6329],\n",
      "        [26.3577, 21.4714, 22.1784],\n",
      "        [26.6874, 21.7602, 22.5244],\n",
      "        [26.8543, 21.8811, 22.3846],\n",
      "        [26.3457, 21.2636, 22.2978],\n",
      "        [26.2451, 21.3480, 21.9671]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.3917, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9947,  26.4781, -22.0916],\n",
      "        [-24.4810,  26.1245, -21.8208],\n",
      "        [-24.5914,  26.2930, -21.5214],\n",
      "        [-24.8900,  26.2811, -21.8943],\n",
      "        [-24.4525,  26.3064, -21.5022],\n",
      "        [-24.7435,  25.6256, -21.6672]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3916,  21.5980,  22.6329, -24.9947,  26.4781, -22.0916],\n",
      "        [ 26.3577,  21.4714,  22.1784, -24.4810,  26.1245, -21.8208],\n",
      "        [ 26.6874,  21.7602,  22.5244, -24.5914,  26.2930, -21.5214],\n",
      "        [ 26.8543,  21.8811,  22.3846, -24.8900,  26.2811, -21.8943],\n",
      "        [ 26.3457,  21.2636,  22.2978, -24.4525,  26.3064, -21.5022],\n",
      "        [ 26.2451,  21.3480,  21.9671, -24.7435,  25.6256, -21.6672]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.643794059753418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9047, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4822, 21.5720, 22.1755],\n",
      "        [26.4741, 21.3178, 22.3020],\n",
      "        [26.0578, 21.3566, 21.8957],\n",
      "        [25.6494, 20.8081, 21.8845],\n",
      "        [26.1380, 21.8680, 22.5272],\n",
      "        [26.4209, 21.4762, 22.3329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.2607, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1905,  26.0392, -21.9916],\n",
      "        [-25.1711,  26.3644, -22.1364],\n",
      "        [-25.3699,  26.0576, -22.2934],\n",
      "        [-25.2944,  26.7141, -22.1541],\n",
      "        [-24.9886,  26.6312, -22.4399],\n",
      "        [-24.3289,  26.1106, -21.2626]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4822,  21.5720,  22.1755, -25.1905,  26.0392, -21.9916],\n",
      "        [ 26.4741,  21.3178,  22.3020, -25.1711,  26.3644, -22.1364],\n",
      "        [ 26.0578,  21.3566,  21.8957, -25.3699,  26.0576, -22.2934],\n",
      "        [ 25.6494,  20.8081,  21.8845, -25.2944,  26.7141, -22.1541],\n",
      "        [ 26.1380,  21.8680,  22.5272, -24.9886,  26.6312, -22.4399],\n",
      "        [ 26.4209,  21.4762,  22.3329, -24.3289,  26.1106, -21.2626]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.616819381713867\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1646, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3095, 21.3848, 22.1169],\n",
      "        [25.9322, 21.7327, 22.0248],\n",
      "        [26.0409, 21.4469, 22.0293],\n",
      "        [25.8495, 21.0400, 22.2796],\n",
      "        [26.2608, 21.4345, 22.2560],\n",
      "        [26.6235, 22.0016, 22.2519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.6547, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1669,  26.0302, -21.5371],\n",
      "        [-25.0238,  26.2145, -21.9454],\n",
      "        [-25.0995,  26.4773, -22.1298],\n",
      "        [-24.4425,  26.0242, -21.4875],\n",
      "        [-25.5221,  26.5825, -22.1880],\n",
      "        [-25.4768,  26.7107, -22.2146]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3095,  21.3848,  22.1169, -25.1669,  26.0302, -21.5371],\n",
      "        [ 25.9322,  21.7327,  22.0248, -25.0238,  26.2145, -21.9454],\n",
      "        [ 26.0409,  21.4469,  22.0293, -25.0995,  26.4773, -22.1298],\n",
      "        [ 25.8495,  21.0400,  22.2796, -24.4425,  26.0242, -21.4875],\n",
      "        [ 26.2608,  21.4345,  22.2560, -25.5221,  26.5825, -22.1880],\n",
      "        [ 26.6235,  22.0016,  22.2519, -25.4768,  26.7107, -22.2146]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.586117267608643\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7945, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.7407, 21.7447, 22.5063],\n",
      "        [26.3793, 21.7571, 22.5163],\n",
      "        [26.1897, 21.1063, 22.3579],\n",
      "        [26.0992, 21.1364, 21.9493],\n",
      "        [26.1838, 21.2100, 21.9662],\n",
      "        [26.3300, 21.7148, 22.3759]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.4788, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9189,  26.1188, -21.9639],\n",
      "        [-25.6920,  26.6186, -22.2681],\n",
      "        [-25.6278,  26.7789, -22.4056],\n",
      "        [-24.8007,  26.1082, -21.8198],\n",
      "        [-25.2489,  26.4728, -22.0858],\n",
      "        [-24.5151,  26.0842, -21.8988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.7407,  21.7447,  22.5063, -24.9189,  26.1188, -21.9639],\n",
      "        [ 26.3793,  21.7571,  22.5163, -25.6920,  26.6186, -22.2681],\n",
      "        [ 26.1897,  21.1063,  22.3579, -25.6278,  26.7789, -22.4056],\n",
      "        [ 26.0992,  21.1364,  21.9493, -24.8007,  26.1082, -21.8198],\n",
      "        [ 26.1838,  21.2100,  21.9662, -25.2489,  26.4728, -22.0858],\n",
      "        [ 26.3300,  21.7148,  22.3759, -24.5151,  26.0842, -21.8988]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.648352146148682\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9941, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6653, 22.0237, 22.8004],\n",
      "        [26.3551, 21.6193, 21.8799],\n",
      "        [26.3926, 21.6931, 22.6824],\n",
      "        [26.3568, 21.2505, 21.9013],\n",
      "        [26.5507, 21.3773, 22.1932],\n",
      "        [26.7099, 21.7584, 22.9581]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.7875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3277,  26.7056, -21.8458],\n",
      "        [-25.0741,  26.5816, -22.3175],\n",
      "        [-25.1223,  26.1338, -22.0958],\n",
      "        [-24.7585,  26.2047, -21.7277],\n",
      "        [-25.6316,  26.0071, -22.3423],\n",
      "        [-25.4067,  26.7392, -22.3940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6653,  22.0237,  22.8004, -25.3277,  26.7056, -21.8458],\n",
      "        [ 26.3551,  21.6193,  21.8799, -25.0741,  26.5816, -22.3175],\n",
      "        [ 26.3926,  21.6931,  22.6824, -25.1223,  26.1338, -22.0958],\n",
      "        [ 26.3568,  21.2505,  21.9013, -24.7585,  26.2047, -21.7277],\n",
      "        [ 26.5507,  21.3773,  22.1932, -25.6316,  26.0071, -22.3423],\n",
      "        [ 26.7099,  21.7584,  22.9581, -25.4067,  26.7392, -22.3940]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.701183319091797\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.6483, 21.3914, 21.5421],\n",
      "        [26.4710, 21.6937, 22.3193],\n",
      "        [26.3762, 21.0333, 22.0388],\n",
      "        [26.1231, 21.4614, 22.1159],\n",
      "        [26.7921, 21.8236, 22.2481],\n",
      "        [26.4629, 21.6740, 22.5691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1939,  25.8105, -21.8236],\n",
      "        [-25.2698,  26.2490, -21.9178],\n",
      "        [-25.5485,  26.8160, -22.1634],\n",
      "        [-24.4473,  26.2611, -22.0365],\n",
      "        [-25.0403,  26.2099, -21.9295],\n",
      "        [-24.6638,  26.1711, -21.8134]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.6483,  21.3914,  21.5421, -25.1939,  25.8105, -21.8236],\n",
      "        [ 26.4710,  21.6937,  22.3193, -25.2698,  26.2490, -21.9178],\n",
      "        [ 26.3762,  21.0333,  22.0388, -25.5485,  26.8160, -22.1634],\n",
      "        [ 26.1231,  21.4614,  22.1159, -24.4473,  26.2611, -22.0365],\n",
      "        [ 26.7921,  21.8236,  22.2481, -25.0403,  26.2099, -21.9295],\n",
      "        [ 26.4629,  21.6740,  22.5691, -24.6638,  26.1711, -21.8134]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.531278133392334\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8346, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2118, 21.3064, 22.4955],\n",
      "        [25.9610, 21.6138, 22.2059],\n",
      "        [26.4099, 21.7583, 22.5018],\n",
      "        [26.4157, 21.2270, 22.2595],\n",
      "        [26.4723, 21.3430, 22.0321],\n",
      "        [26.0900, 20.9344, 21.9219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.7869, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3778,  26.5736, -22.0640],\n",
      "        [-24.8411,  26.3426, -21.5126],\n",
      "        [-24.9852,  26.3586, -21.8509],\n",
      "        [-25.6219,  27.1626, -22.8016],\n",
      "        [-25.3570,  26.5469, -22.3434],\n",
      "        [-25.6231,  27.0660, -22.8197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2118,  21.3064,  22.4955, -25.3778,  26.5736, -22.0640],\n",
      "        [ 25.9610,  21.6138,  22.2059, -24.8411,  26.3426, -21.5126],\n",
      "        [ 26.4099,  21.7583,  22.5018, -24.9852,  26.3586, -21.8509],\n",
      "        [ 26.4157,  21.2270,  22.2595, -25.6219,  27.1626, -22.8016],\n",
      "        [ 26.4723,  21.3430,  22.0321, -25.3570,  26.5469, -22.3434],\n",
      "        [ 26.0900,  20.9344,  21.9219, -25.6231,  27.0660, -22.8197]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.6447954177856445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1529, 21.5614, 22.5909],\n",
      "        [26.0784, 21.1788, 22.4066],\n",
      "        [26.3117, 21.4187, 22.4195],\n",
      "        [26.2592, 21.6779, 22.5289],\n",
      "        [26.4898, 21.1383, 22.1655],\n",
      "        [26.7129, 21.6470, 22.3468]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.5427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6767,  26.1015, -21.5567],\n",
      "        [-24.8890,  25.8828, -21.9106],\n",
      "        [-25.3472,  26.5933, -22.2887],\n",
      "        [-25.4169,  26.9991, -22.4482],\n",
      "        [-24.9485,  26.1826, -21.7030],\n",
      "        [-24.8414,  26.1395, -21.6261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1529,  21.5614,  22.5909, -24.6767,  26.1015, -21.5567],\n",
      "        [ 26.0784,  21.1788,  22.4066, -24.8890,  25.8828, -21.9106],\n",
      "        [ 26.3117,  21.4187,  22.4195, -25.3472,  26.5933, -22.2887],\n",
      "        [ 26.2592,  21.6779,  22.5289, -25.4169,  26.9991, -22.4482],\n",
      "        [ 26.4898,  21.1383,  22.1655, -24.9485,  26.1826, -21.7030],\n",
      "        [ 26.7129,  21.6470,  22.3468, -24.8414,  26.1395, -21.6261]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.601046562194824\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2754, 21.6055, 22.6339],\n",
      "        [25.9685, 21.3653, 22.1762],\n",
      "        [26.5538, 21.7593, 22.2191],\n",
      "        [26.3785, 22.1133, 22.3835],\n",
      "        [26.6840, 21.9275, 22.0207],\n",
      "        [26.2737, 21.4118, 21.9599]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.7717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3764,  27.2716, -22.6461],\n",
      "        [-24.4637,  25.8873, -21.6059],\n",
      "        [-25.3247,  26.8001, -22.3337],\n",
      "        [-25.1897,  26.4587, -22.4011],\n",
      "        [-25.0643,  25.7819, -21.8623],\n",
      "        [-25.0318,  26.0956, -21.9975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2754,  21.6055,  22.6339, -25.3764,  27.2716, -22.6461],\n",
      "        [ 25.9685,  21.3653,  22.1762, -24.4637,  25.8873, -21.6059],\n",
      "        [ 26.5538,  21.7593,  22.2191, -25.3247,  26.8001, -22.3337],\n",
      "        [ 26.3785,  22.1133,  22.3835, -25.1897,  26.4587, -22.4011],\n",
      "        [ 26.6840,  21.9275,  22.0207, -25.0643,  25.7819, -21.8623],\n",
      "        [ 26.2737,  21.4118,  21.9599, -25.0318,  26.0956, -21.9975]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.710703372955322\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2912, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4420, 21.8883, 22.2464],\n",
      "        [26.0813, 21.3591, 21.9791],\n",
      "        [26.7906, 21.5311, 22.4555],\n",
      "        [26.3039, 21.0364, 22.1639],\n",
      "        [26.5778, 21.6988, 22.6562],\n",
      "        [25.7270, 20.9267, 22.0511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5542,  26.6512, -22.7667],\n",
      "        [-24.9779,  25.9550, -21.8710],\n",
      "        [-25.1457,  26.4113, -21.9838],\n",
      "        [-25.0615,  26.2360, -21.8015],\n",
      "        [-25.2255,  26.3799, -22.0109],\n",
      "        [-25.8310,  27.1617, -22.6940]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4420,  21.8883,  22.2464, -25.5542,  26.6512, -22.7667],\n",
      "        [ 26.0813,  21.3591,  21.9791, -24.9779,  25.9550, -21.8710],\n",
      "        [ 26.7906,  21.5311,  22.4555, -25.1457,  26.4113, -21.9838],\n",
      "        [ 26.3039,  21.0364,  22.1639, -25.0615,  26.2360, -21.8015],\n",
      "        [ 26.5778,  21.6988,  22.6562, -25.2255,  26.3799, -22.0109],\n",
      "        [ 25.7270,  20.9267,  22.0511, -25.8310,  27.1617, -22.6940]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.700826644897461\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9081, 21.9814, 22.5604],\n",
      "        [25.8649, 21.2709, 21.9805],\n",
      "        [26.3853, 21.4774, 22.3723],\n",
      "        [26.8797, 22.3713, 22.9495],\n",
      "        [26.9346, 21.9521, 22.7077],\n",
      "        [26.1375, 21.2284, 21.8571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.4824, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4777,  26.5312, -22.4752],\n",
      "        [-25.4815,  26.6345, -22.6556],\n",
      "        [-25.1806,  26.4283, -22.0682],\n",
      "        [-24.7856,  26.3501, -21.7341],\n",
      "        [-25.2216,  26.6527, -22.2351],\n",
      "        [-25.2538,  26.5816, -22.3455]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9081,  21.9814,  22.5604, -25.4777,  26.5312, -22.4752],\n",
      "        [ 25.8649,  21.2709,  21.9805, -25.4815,  26.6345, -22.6556],\n",
      "        [ 26.3853,  21.4774,  22.3723, -25.1806,  26.4283, -22.0682],\n",
      "        [ 26.8797,  22.3713,  22.9495, -24.7856,  26.3501, -21.7341],\n",
      "        [ 26.9346,  21.9521,  22.7077, -25.2216,  26.6527, -22.2351],\n",
      "        [ 26.1375,  21.2284,  21.8571, -25.2538,  26.5816, -22.3455]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.730104446411133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5666, 21.8129, 22.3347],\n",
      "        [25.7447, 20.9716, 22.2275],\n",
      "        [26.6830, 21.9011, 22.2558],\n",
      "        [26.5970, 21.8939, 22.7341],\n",
      "        [26.4588, 21.5397, 22.3283],\n",
      "        [26.2725, 21.5774, 22.7757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.0763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3982,  26.2889, -21.9708],\n",
      "        [-24.7524,  26.5669, -21.8752],\n",
      "        [-25.0838,  26.4031, -21.8284],\n",
      "        [-24.6932,  26.0133, -21.5231],\n",
      "        [-24.5857,  25.9280, -21.5069],\n",
      "        [-24.5035,  26.2190, -21.9522]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5666,  21.8129,  22.3347, -25.3982,  26.2889, -21.9708],\n",
      "        [ 25.7447,  20.9716,  22.2275, -24.7524,  26.5669, -21.8752],\n",
      "        [ 26.6830,  21.9011,  22.2558, -25.0838,  26.4031, -21.8284],\n",
      "        [ 26.5970,  21.8939,  22.7341, -24.6932,  26.0133, -21.5231],\n",
      "        [ 26.4588,  21.5397,  22.3283, -24.5857,  25.9280, -21.5069],\n",
      "        [ 26.2725,  21.5774,  22.7757, -24.5035,  26.2190, -21.9522]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.671421051025391\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5910, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1152, 22.0723, 22.6328],\n",
      "        [26.5880, 21.7370, 22.3967],\n",
      "        [25.8449, 21.3892, 22.2584],\n",
      "        [26.3347, 21.6240, 21.8671],\n",
      "        [25.8891, 21.2730, 21.7712],\n",
      "        [26.2433, 21.7053, 22.4096]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(24.9696, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2391,  26.5514, -22.4321],\n",
      "        [-25.0802,  26.2323, -22.0901],\n",
      "        [-25.3143,  26.1415, -22.1853],\n",
      "        [-24.8480,  25.8895, -21.4539],\n",
      "        [-24.9329,  25.8204, -21.7630],\n",
      "        [-24.9758,  26.5783, -22.5007]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1152,  22.0723,  22.6328, -25.2391,  26.5514, -22.4321],\n",
      "        [ 26.5880,  21.7370,  22.3967, -25.0802,  26.2323, -22.0901],\n",
      "        [ 25.8449,  21.3892,  22.2584, -25.3143,  26.1415, -22.1853],\n",
      "        [ 26.3347,  21.6240,  21.8671, -24.8480,  25.8895, -21.4539],\n",
      "        [ 25.8891,  21.2730,  21.7712, -24.9329,  25.8204, -21.7630],\n",
      "        [ 26.2433,  21.7053,  22.4096, -24.9758,  26.5783, -22.5007]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.742901802062988\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0697, 21.3456, 22.3606],\n",
      "        [26.0183, 21.4336, 22.1934],\n",
      "        [27.0151, 22.0413, 22.9515],\n",
      "        [26.6297, 21.7022, 22.2698],\n",
      "        [26.2281, 21.7836, 22.7301],\n",
      "        [26.3565, 21.6069, 22.6895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.8449, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2603,  26.8111, -22.4095],\n",
      "        [-25.0846,  26.6234, -21.7515],\n",
      "        [-25.0891,  26.9183, -22.3859],\n",
      "        [-25.4305,  26.7167, -22.2816],\n",
      "        [-25.5028,  26.7814, -22.6918],\n",
      "        [-25.2040,  26.9967, -22.5970]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0697,  21.3456,  22.3606, -25.2603,  26.8111, -22.4095],\n",
      "        [ 26.0183,  21.4336,  22.1934, -25.0846,  26.6234, -21.7515],\n",
      "        [ 27.0151,  22.0413,  22.9515, -25.0891,  26.9183, -22.3859],\n",
      "        [ 26.6297,  21.7022,  22.2698, -25.4305,  26.7167, -22.2816],\n",
      "        [ 26.2281,  21.7836,  22.7301, -25.5028,  26.7814, -22.6918],\n",
      "        [ 26.3565,  21.6069,  22.6895, -25.2040,  26.9967, -22.5970]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.660046577453613\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0210, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1537, 21.3058, 22.0018],\n",
      "        [26.6933, 21.7210, 22.5530],\n",
      "        [26.6379, 22.2631, 22.3913],\n",
      "        [27.1796, 22.0715, 22.9049],\n",
      "        [26.1602, 21.4318, 22.1230],\n",
      "        [26.6711, 21.7454, 22.0250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.9554, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0765,  26.4325, -22.3074],\n",
      "        [-25.0271,  26.1898, -22.2766],\n",
      "        [-24.7572,  26.0507, -21.5375],\n",
      "        [-25.0928,  26.6342, -22.1340],\n",
      "        [-25.0433,  26.1927, -22.1368],\n",
      "        [-25.4021,  26.7400, -22.5685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1537,  21.3058,  22.0018, -25.0765,  26.4325, -22.3074],\n",
      "        [ 26.6933,  21.7210,  22.5530, -25.0271,  26.1898, -22.2766],\n",
      "        [ 26.6379,  22.2631,  22.3913, -24.7572,  26.0507, -21.5375],\n",
      "        [ 27.1796,  22.0715,  22.9049, -25.0928,  26.6342, -22.1340],\n",
      "        [ 26.1602,  21.4318,  22.1230, -25.0433,  26.1927, -22.1368],\n",
      "        [ 26.6711,  21.7454,  22.0250, -25.4021,  26.7400, -22.5685]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.625711917877197\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8316, 21.8826, 22.4090],\n",
      "        [26.3738, 21.5942, 22.1729],\n",
      "        [26.0612, 21.5891, 22.1673],\n",
      "        [26.8422, 21.8421, 22.6581],\n",
      "        [26.9052, 21.9149, 22.9558],\n",
      "        [26.1984, 21.8494, 22.4505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9985, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5162,  27.1086, -22.9397],\n",
      "        [-25.6466,  26.8417, -22.3000],\n",
      "        [-24.9299,  26.0258, -21.9891],\n",
      "        [-25.6401,  26.8364, -22.2093],\n",
      "        [-25.6169,  27.1190, -22.9641],\n",
      "        [-24.5457,  25.9532, -21.8121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8316,  21.8826,  22.4090, -25.5162,  27.1086, -22.9397],\n",
      "        [ 26.3738,  21.5942,  22.1729, -25.6466,  26.8417, -22.3000],\n",
      "        [ 26.0612,  21.5891,  22.1673, -24.9299,  26.0258, -21.9891],\n",
      "        [ 26.8422,  21.8421,  22.6581, -25.6401,  26.8364, -22.2093],\n",
      "        [ 26.9052,  21.9149,  22.9558, -25.6169,  27.1190, -22.9641],\n",
      "        [ 26.1984,  21.8494,  22.4505, -24.5457,  25.9532, -21.8121]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.760880470275879\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7698, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0198, 22.0209, 22.9594],\n",
      "        [27.0138, 22.3568, 22.8609],\n",
      "        [26.9387, 22.1708, 22.7754],\n",
      "        [25.9117, 21.3462, 22.5539],\n",
      "        [27.0274, 22.2705, 22.9448],\n",
      "        [26.6491, 22.2460, 23.0112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(41.9109, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4315,  26.9255, -22.9120],\n",
      "        [-25.1492,  26.3551, -22.4570],\n",
      "        [-25.3991,  26.4568, -22.0252],\n",
      "        [-24.9290,  26.2679, -21.6599],\n",
      "        [-25.1422,  26.1880, -22.0828],\n",
      "        [-25.0097,  26.4474, -22.1900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0198,  22.0209,  22.9594, -25.4315,  26.9255, -22.9120],\n",
      "        [ 27.0138,  22.3568,  22.8609, -25.1492,  26.3551, -22.4570],\n",
      "        [ 26.9387,  22.1708,  22.7754, -25.3991,  26.4568, -22.0252],\n",
      "        [ 25.9117,  21.3462,  22.5539, -24.9290,  26.2679, -21.6599],\n",
      "        [ 27.0274,  22.2705,  22.9448, -25.1422,  26.1880, -22.0828],\n",
      "        [ 26.6491,  22.2460,  23.0112, -25.0097,  26.4474, -22.1900]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.792521953582764\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8556, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5867, 21.4858, 22.3612],\n",
      "        [26.7876, 22.0220, 22.5648],\n",
      "        [26.2390, 21.2513, 22.3932],\n",
      "        [26.3890, 21.7963, 22.3135],\n",
      "        [26.1429, 21.0152, 22.3289],\n",
      "        [26.7550, 21.7748, 22.4764]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2020, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6680,  26.8767, -22.4160],\n",
      "        [-25.1195,  26.4423, -22.1615],\n",
      "        [-25.5681,  27.1299, -22.5330],\n",
      "        [-25.2113,  26.2537, -21.9927],\n",
      "        [-25.2377,  26.7998, -22.6874],\n",
      "        [-25.0664,  26.7106, -22.0557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5867,  21.4858,  22.3612, -25.6680,  26.8767, -22.4160],\n",
      "        [ 26.7876,  22.0220,  22.5648, -25.1195,  26.4423, -22.1615],\n",
      "        [ 26.2390,  21.2513,  22.3932, -25.5681,  27.1299, -22.5330],\n",
      "        [ 26.3890,  21.7963,  22.3135, -25.2113,  26.2537, -21.9927],\n",
      "        [ 26.1429,  21.0152,  22.3289, -25.2377,  26.7998, -22.6874],\n",
      "        [ 26.7550,  21.7748,  22.4764, -25.0664,  26.7106, -22.0557]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.717130184173584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7668, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2782, 21.6378, 22.5414],\n",
      "        [26.6441, 21.7719, 22.8101],\n",
      "        [25.8520, 21.1456, 21.8869],\n",
      "        [26.7540, 21.8049, 22.8500],\n",
      "        [25.7146, 21.2948, 22.0629],\n",
      "        [26.4768, 22.1761, 22.2391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.8199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5579,  26.8510, -22.6199],\n",
      "        [-25.2566,  26.7302, -22.4648],\n",
      "        [-24.9103,  25.9485, -21.7497],\n",
      "        [-24.5773,  26.2265, -21.8023],\n",
      "        [-24.8001,  26.0009, -21.9090],\n",
      "        [-25.3180,  26.3337, -22.1338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2782,  21.6378,  22.5414, -25.5579,  26.8510, -22.6199],\n",
      "        [ 26.6441,  21.7719,  22.8101, -25.2566,  26.7302, -22.4648],\n",
      "        [ 25.8520,  21.1456,  21.8869, -24.9103,  25.9485, -21.7497],\n",
      "        [ 26.7540,  21.8049,  22.8500, -24.5773,  26.2265, -21.8023],\n",
      "        [ 25.7146,  21.2948,  22.0629, -24.8001,  26.0009, -21.9090],\n",
      "        [ 26.4768,  22.1761,  22.2391, -25.3180,  26.3337, -22.1338]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.71702241897583\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5775, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1448, 21.7061, 21.9683],\n",
      "        [26.6462, 22.0912, 22.2555],\n",
      "        [26.4583, 21.4754, 22.5513],\n",
      "        [26.8080, 22.0665, 22.3946],\n",
      "        [26.5685, 21.6624, 22.3727],\n",
      "        [26.0502, 21.3612, 22.0219]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.7322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4114,  26.8397, -22.2122],\n",
      "        [-24.5464,  26.1013, -21.8446],\n",
      "        [-24.9076,  25.9598, -22.0535],\n",
      "        [-24.6045,  25.8140, -21.5688],\n",
      "        [-25.2313,  26.4923, -22.1438],\n",
      "        [-25.5979,  26.7908, -22.4961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1448,  21.7061,  21.9683, -25.4114,  26.8397, -22.2122],\n",
      "        [ 26.6462,  22.0912,  22.2555, -24.5464,  26.1013, -21.8446],\n",
      "        [ 26.4583,  21.4754,  22.5513, -24.9076,  25.9598, -22.0535],\n",
      "        [ 26.8080,  22.0665,  22.3946, -24.6045,  25.8140, -21.5688],\n",
      "        [ 26.5685,  21.6624,  22.3727, -25.2313,  26.4923, -22.1438],\n",
      "        [ 26.0502,  21.3612,  22.0219, -25.5979,  26.7908, -22.4961]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.670795917510986\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6421, 22.1158, 22.4006],\n",
      "        [25.7035, 20.8507, 21.7688],\n",
      "        [26.4431, 21.7013, 22.5411],\n",
      "        [26.1401, 21.4668, 22.4219],\n",
      "        [26.9355, 22.1449, 22.7055],\n",
      "        [26.2235, 21.7142, 21.7561]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.0700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5220,  26.5998, -22.4521],\n",
      "        [-25.4108,  26.5401, -22.6931],\n",
      "        [-25.3447,  26.8441, -22.9372],\n",
      "        [-25.1374,  26.3939, -22.3293],\n",
      "        [-25.3782,  26.8721, -22.1847],\n",
      "        [-25.3821,  26.9058, -22.4689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6421,  22.1158,  22.4006, -25.5220,  26.5998, -22.4521],\n",
      "        [ 25.7035,  20.8507,  21.7688, -25.4108,  26.5401, -22.6931],\n",
      "        [ 26.4431,  21.7013,  22.5411, -25.3447,  26.8441, -22.9372],\n",
      "        [ 26.1401,  21.4668,  22.4219, -25.1374,  26.3939, -22.3293],\n",
      "        [ 26.9355,  22.1449,  22.7055, -25.3782,  26.8721, -22.1847],\n",
      "        [ 26.2235,  21.7142,  21.7561, -25.3821,  26.9058, -22.4689]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.735637664794922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8374, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4578, 21.7388, 22.7526],\n",
      "        [26.5805, 21.6283, 22.2417],\n",
      "        [27.1442, 22.3102, 23.4298],\n",
      "        [27.0558, 22.1393, 22.7937],\n",
      "        [27.1015, 22.1579, 23.0103],\n",
      "        [26.5457, 21.8308, 22.4962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.5599, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0291,  26.6166, -22.2870],\n",
      "        [-25.8773,  27.1288, -22.8545],\n",
      "        [-24.0588,  25.3871, -20.9427],\n",
      "        [-25.3220,  26.5006, -22.3381],\n",
      "        [-25.1567,  26.4057, -22.4472],\n",
      "        [-24.7580,  26.1269, -21.5515]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4578,  21.7388,  22.7526, -25.0291,  26.6166, -22.2870],\n",
      "        [ 26.5805,  21.6283,  22.2417, -25.8773,  27.1288, -22.8545],\n",
      "        [ 27.1442,  22.3102,  23.4298, -24.0588,  25.3871, -20.9427],\n",
      "        [ 27.0558,  22.1393,  22.7937, -25.3220,  26.5006, -22.3381],\n",
      "        [ 27.1015,  22.1579,  23.0103, -25.1567,  26.4057, -22.4472],\n",
      "        [ 26.5457,  21.8308,  22.4962, -24.7580,  26.1269, -21.5515]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.7093000411987305\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4645, 21.5261, 22.1929],\n",
      "        [26.0719, 21.3912, 22.5384],\n",
      "        [26.2719, 21.9212, 22.1456],\n",
      "        [26.3725, 21.4321, 22.0418],\n",
      "        [26.5267, 21.5584, 22.1165],\n",
      "        [26.7009, 21.6016, 22.5271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.7528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6810,  26.9803, -22.4800],\n",
      "        [-24.4474,  26.2269, -21.7110],\n",
      "        [-25.5502,  26.3529, -22.0953],\n",
      "        [-25.2475,  26.4714, -22.4880],\n",
      "        [-24.5813,  26.0817, -21.6738],\n",
      "        [-25.0751,  26.3672, -22.3926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4645,  21.5261,  22.1929, -25.6810,  26.9803, -22.4800],\n",
      "        [ 26.0719,  21.3912,  22.5384, -24.4474,  26.2269, -21.7110],\n",
      "        [ 26.2719,  21.9212,  22.1456, -25.5502,  26.3529, -22.0953],\n",
      "        [ 26.3725,  21.4321,  22.0418, -25.2475,  26.4714, -22.4880],\n",
      "        [ 26.5267,  21.5584,  22.1165, -24.5813,  26.0817, -21.6738],\n",
      "        [ 26.7009,  21.6016,  22.5271, -25.0751,  26.3672, -22.3926]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.71986198425293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.2383, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3230, 21.6741, 22.0345],\n",
      "        [26.9011, 21.9582, 22.3739],\n",
      "        [26.8172, 21.9553, 22.3802],\n",
      "        [26.4207, 21.2688, 22.3826],\n",
      "        [26.7539, 21.9926, 22.2651],\n",
      "        [26.8032, 21.8540, 22.7860]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.3443, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8169,  26.7147, -22.6238],\n",
      "        [-25.1919,  26.3537, -22.0601],\n",
      "        [-25.5865,  26.7946, -22.1433],\n",
      "        [-25.5439,  26.3954, -22.0271],\n",
      "        [-25.1570,  26.5108, -22.2693],\n",
      "        [-25.4203,  26.1894, -22.3308]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3230,  21.6741,  22.0345, -25.8169,  26.7147, -22.6238],\n",
      "        [ 26.9011,  21.9582,  22.3739, -25.1919,  26.3537, -22.0601],\n",
      "        [ 26.8172,  21.9553,  22.3802, -25.5865,  26.7946, -22.1433],\n",
      "        [ 26.4207,  21.2688,  22.3826, -25.5439,  26.3954, -22.0271],\n",
      "        [ 26.7539,  21.9926,  22.2651, -25.1570,  26.5108, -22.2693],\n",
      "        [ 26.8032,  21.8540,  22.7860, -25.4203,  26.1894, -22.3308]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.711184978485107\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8558, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8124, 21.8040, 22.5610],\n",
      "        [26.2247, 21.6491, 22.1463],\n",
      "        [27.0245, 22.0600, 23.0379],\n",
      "        [26.1385, 20.8895, 22.3175],\n",
      "        [26.7266, 21.7412, 22.4593],\n",
      "        [26.2212, 21.3393, 22.4141]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3937, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3015,  26.5404, -22.0730],\n",
      "        [-25.6427,  26.8944, -22.6979],\n",
      "        [-24.8465,  26.5254, -22.2379],\n",
      "        [-25.2923,  26.8327, -22.3955],\n",
      "        [-25.4574,  26.6619, -22.5153],\n",
      "        [-25.4024,  26.9264, -22.4281]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8124,  21.8040,  22.5610, -25.3015,  26.5404, -22.0730],\n",
      "        [ 26.2247,  21.6491,  22.1463, -25.6427,  26.8944, -22.6979],\n",
      "        [ 27.0245,  22.0600,  23.0379, -24.8465,  26.5254, -22.2379],\n",
      "        [ 26.1385,  20.8895,  22.3175, -25.2923,  26.8327, -22.3955],\n",
      "        [ 26.7266,  21.7412,  22.4593, -25.4574,  26.6619, -22.5153],\n",
      "        [ 26.2212,  21.3393,  22.4141, -25.4024,  26.9264, -22.4281]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.728199005126953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3782, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9127, 22.0173, 22.7281],\n",
      "        [26.2702, 21.2594, 21.9266],\n",
      "        [26.6775, 21.9010, 22.5453],\n",
      "        [26.4197, 21.6973, 22.3499],\n",
      "        [26.9100, 21.9362, 22.8997],\n",
      "        [25.7694, 21.2626, 21.7225]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.2690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4861,  26.7687, -22.7796],\n",
      "        [-25.4218,  26.6696, -22.0592],\n",
      "        [-24.8411,  26.4034, -21.9896],\n",
      "        [-25.2482,  26.5687, -22.3477],\n",
      "        [-25.3948,  26.4024, -22.2905],\n",
      "        [-25.5803,  26.7272, -22.7990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9127,  22.0173,  22.7281, -25.4861,  26.7687, -22.7796],\n",
      "        [ 26.2702,  21.2594,  21.9266, -25.4218,  26.6696, -22.0592],\n",
      "        [ 26.6775,  21.9010,  22.5453, -24.8411,  26.4034, -21.9896],\n",
      "        [ 26.4197,  21.6973,  22.3499, -25.2482,  26.5687, -22.3477],\n",
      "        [ 26.9100,  21.9362,  22.8997, -25.3948,  26.4024, -22.2905],\n",
      "        [ 25.7694,  21.2626,  21.7225, -25.5803,  26.7272, -22.7990]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.785750389099121\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7793, 21.4440, 22.2306],\n",
      "        [25.5511, 21.5756, 21.8598],\n",
      "        [26.5452, 21.5677, 22.7158],\n",
      "        [26.4315, 21.7028, 22.4188],\n",
      "        [26.1717, 21.5109, 22.4757],\n",
      "        [26.0605, 21.4762, 22.3950]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1349, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3790,  26.8911, -22.4326],\n",
      "        [-25.8148,  26.8412, -22.5500],\n",
      "        [-26.0063,  27.4683, -23.1153],\n",
      "        [-26.0066,  27.3637, -22.9627],\n",
      "        [-25.7752,  27.0670, -22.5645],\n",
      "        [-25.4678,  26.9984, -22.2364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7793,  21.4440,  22.2306, -25.3790,  26.8911, -22.4326],\n",
      "        [ 25.5511,  21.5756,  21.8598, -25.8148,  26.8412, -22.5500],\n",
      "        [ 26.5452,  21.5677,  22.7158, -26.0063,  27.4683, -23.1153],\n",
      "        [ 26.4315,  21.7028,  22.4188, -26.0066,  27.3637, -22.9627],\n",
      "        [ 26.1717,  21.5109,  22.4757, -25.7752,  27.0670, -22.5645],\n",
      "        [ 26.0605,  21.4762,  22.3950, -25.4678,  26.9984, -22.2364]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.674134254455566\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5089, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1233, 21.8071, 22.1892],\n",
      "        [26.4685, 21.6255, 22.6370],\n",
      "        [25.7438, 21.2645, 22.0194],\n",
      "        [26.6923, 21.9302, 22.7938],\n",
      "        [26.8540, 22.0263, 22.9164],\n",
      "        [26.3082, 21.7230, 22.1950]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.5383, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6792,  26.5445, -22.5488],\n",
      "        [-25.4069,  26.9155, -22.3877],\n",
      "        [-25.4480,  26.8421, -22.4708],\n",
      "        [-25.5225,  26.9417, -22.7637],\n",
      "        [-24.7974,  26.3321, -22.1611],\n",
      "        [-25.2742,  26.2844, -21.9372]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1233,  21.8071,  22.1892, -25.6792,  26.5445, -22.5488],\n",
      "        [ 26.4685,  21.6255,  22.6370, -25.4069,  26.9155, -22.3877],\n",
      "        [ 25.7438,  21.2645,  22.0194, -25.4480,  26.8421, -22.4708],\n",
      "        [ 26.6923,  21.9302,  22.7938, -25.5225,  26.9417, -22.7637],\n",
      "        [ 26.8540,  22.0263,  22.9164, -24.7974,  26.3321, -22.1611],\n",
      "        [ 26.3082,  21.7230,  22.1950, -25.2742,  26.2844, -21.9372]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.706573486328125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7674, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.2062, 21.1983, 22.4802],\n",
      "        [26.1380, 21.5904, 22.4667],\n",
      "        [26.9299, 21.9609, 22.9952],\n",
      "        [25.8554, 21.1063, 22.0553],\n",
      "        [26.8152, 21.9821, 22.3757],\n",
      "        [25.9436, 21.0201, 21.8235]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.5496, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6497,  26.8654, -22.7210],\n",
      "        [-25.2138,  26.6991, -22.1201],\n",
      "        [-24.7179,  25.8385, -22.0177],\n",
      "        [-25.4849,  26.7051, -22.1873],\n",
      "        [-25.4800,  26.5909, -22.2036],\n",
      "        [-25.2912,  27.1149, -22.1989]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.2062,  21.1983,  22.4802, -25.6497,  26.8654, -22.7210],\n",
      "        [ 26.1380,  21.5904,  22.4667, -25.2138,  26.6991, -22.1201],\n",
      "        [ 26.9299,  21.9609,  22.9952, -24.7179,  25.8385, -22.0177],\n",
      "        [ 25.8554,  21.1063,  22.0553, -25.4849,  26.7051, -22.1873],\n",
      "        [ 26.8152,  21.9821,  22.3757, -25.4800,  26.5909, -22.2036],\n",
      "        [ 25.9436,  21.0201,  21.8235, -25.2912,  27.1149, -22.1989]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.72056770324707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4710, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8749, 22.1577, 22.6026],\n",
      "        [26.8597, 22.1372, 22.5110],\n",
      "        [26.8934, 21.9578, 22.6372],\n",
      "        [26.3789, 21.7221, 22.1700],\n",
      "        [26.5171, 21.2894, 22.5446],\n",
      "        [26.3162, 21.7242, 21.9999]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.5152, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0117,  26.9378, -22.5398],\n",
      "        [-25.4380,  26.7956, -22.4361],\n",
      "        [-25.3319,  26.4809, -22.6562],\n",
      "        [-25.6459,  27.2028, -22.4155],\n",
      "        [-25.7325,  27.1094, -22.5487],\n",
      "        [-25.4388,  26.9117, -22.2647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8749,  22.1577,  22.6026, -25.0117,  26.9378, -22.5398],\n",
      "        [ 26.8597,  22.1372,  22.5110, -25.4380,  26.7956, -22.4361],\n",
      "        [ 26.8934,  21.9578,  22.6372, -25.3319,  26.4809, -22.6562],\n",
      "        [ 26.3789,  21.7221,  22.1700, -25.6459,  27.2028, -22.4155],\n",
      "        [ 26.5171,  21.2894,  22.5446, -25.7325,  27.1094, -22.5487],\n",
      "        [ 26.3162,  21.7242,  21.9999, -25.4388,  26.9117, -22.2647]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.773473739624023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5919, 21.9208, 22.9948],\n",
      "        [26.9357, 22.1271, 22.6401],\n",
      "        [26.2781, 21.8869, 22.5751],\n",
      "        [25.9321, 21.2282, 22.0362],\n",
      "        [26.5264, 22.0482, 22.0730],\n",
      "        [26.1078, 21.4485, 22.3627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2098, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8871,  25.9241, -22.0381],\n",
      "        [-25.2180,  26.4487, -22.4050],\n",
      "        [-25.3639,  26.5784, -22.3399],\n",
      "        [-25.8791,  26.9968, -22.6046],\n",
      "        [-24.8341,  26.4722, -22.4104],\n",
      "        [-25.8871,  26.7969, -22.8009]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5919,  21.9208,  22.9948, -24.8871,  25.9241, -22.0381],\n",
      "        [ 26.9357,  22.1271,  22.6401, -25.2180,  26.4487, -22.4050],\n",
      "        [ 26.2781,  21.8869,  22.5751, -25.3639,  26.5784, -22.3399],\n",
      "        [ 25.9321,  21.2282,  22.0362, -25.8791,  26.9968, -22.6046],\n",
      "        [ 26.5264,  22.0482,  22.0730, -24.8341,  26.4722, -22.4104],\n",
      "        [ 26.1078,  21.4485,  22.3627, -25.8871,  26.7969, -22.8009]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.713675498962402\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8075, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1667, 21.4798, 22.0233],\n",
      "        [26.3153, 21.7256, 22.6741],\n",
      "        [26.6747, 22.2984, 22.8451],\n",
      "        [26.9580, 21.7452, 22.8600],\n",
      "        [26.4111, 21.4202, 22.1187],\n",
      "        [26.3736, 21.7280, 22.0024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.9938, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6360,  25.8875, -22.4328],\n",
      "        [-25.3063,  26.7599, -22.3110],\n",
      "        [-25.3284,  26.9627, -22.4022],\n",
      "        [-25.3983,  26.5718, -22.3646],\n",
      "        [-25.6915,  27.1410, -22.5711],\n",
      "        [-25.3153,  26.4135, -22.5224]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1667,  21.4798,  22.0233, -24.6360,  25.8875, -22.4328],\n",
      "        [ 26.3153,  21.7256,  22.6741, -25.3063,  26.7599, -22.3110],\n",
      "        [ 26.6747,  22.2984,  22.8451, -25.3284,  26.9627, -22.4022],\n",
      "        [ 26.9580,  21.7452,  22.8600, -25.3983,  26.5718, -22.3646],\n",
      "        [ 26.4111,  21.4202,  22.1187, -25.6915,  27.1410, -22.5711],\n",
      "        [ 26.3736,  21.7280,  22.0024, -25.3153,  26.4135, -22.5224]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.633885383605957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4831, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1902, 21.6301, 22.0822],\n",
      "        [26.6795, 22.0558, 22.9140],\n",
      "        [26.8116, 22.0045, 22.9181],\n",
      "        [27.0996, 22.6275, 23.1064],\n",
      "        [26.4330, 21.7767, 22.2796],\n",
      "        [26.3585, 21.3466, 22.4021]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.9838, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.8920,  26.7877, -22.2853],\n",
      "        [-24.9610,  26.6139, -22.3553],\n",
      "        [-24.9449,  25.9062, -21.9868],\n",
      "        [-25.5620,  26.6958, -22.6139],\n",
      "        [-25.1718,  26.3341, -22.2346],\n",
      "        [-25.0694,  26.6437, -21.8909]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1902,  21.6301,  22.0822, -24.8920,  26.7877, -22.2853],\n",
      "        [ 26.6795,  22.0558,  22.9140, -24.9610,  26.6139, -22.3553],\n",
      "        [ 26.8116,  22.0045,  22.9181, -24.9449,  25.9062, -21.9868],\n",
      "        [ 27.0996,  22.6275,  23.1064, -25.5620,  26.6958, -22.6139],\n",
      "        [ 26.4330,  21.7767,  22.2796, -25.1718,  26.3341, -22.2346],\n",
      "        [ 26.3585,  21.3466,  22.4021, -25.0694,  26.6437, -21.8909]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.6826276779174805\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9520, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4311, 21.4845, 22.1765],\n",
      "        [27.1104, 22.3462, 22.7154],\n",
      "        [26.8761, 22.3206, 23.1015],\n",
      "        [26.5783, 22.0605, 23.0790],\n",
      "        [26.6598, 22.0808, 22.7200],\n",
      "        [26.4247, 21.1008, 22.4604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.7804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7545,  26.0883, -21.6184],\n",
      "        [-25.2719,  26.4496, -22.4663],\n",
      "        [-24.7863,  25.9022, -22.0843],\n",
      "        [-25.3933,  26.3536, -22.2978],\n",
      "        [-25.1212,  26.4638, -22.3065],\n",
      "        [-25.5204,  26.7264, -22.3739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4311,  21.4845,  22.1765, -24.7545,  26.0883, -21.6184],\n",
      "        [ 27.1104,  22.3462,  22.7154, -25.2719,  26.4496, -22.4663],\n",
      "        [ 26.8761,  22.3206,  23.1015, -24.7863,  25.9022, -22.0843],\n",
      "        [ 26.5783,  22.0605,  23.0790, -25.3933,  26.3536, -22.2978],\n",
      "        [ 26.6598,  22.0808,  22.7200, -25.1212,  26.4638, -22.3065],\n",
      "        [ 26.4247,  21.1008,  22.4604, -25.5204,  26.7264, -22.3739]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.647061824798584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6916, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1733, 21.2716, 22.2136],\n",
      "        [26.6570, 22.0384, 22.7043],\n",
      "        [26.5293, 21.7602, 22.3962],\n",
      "        [26.4028, 21.8559, 22.7972],\n",
      "        [26.3370, 21.9062, 22.6030],\n",
      "        [26.3538, 22.4344, 22.4245]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0467, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1658,  26.4056, -22.3206],\n",
      "        [-25.3680,  26.7401, -22.2615],\n",
      "        [-25.4177,  26.4674, -22.0723],\n",
      "        [-25.4765,  26.4041, -22.1664],\n",
      "        [-24.8812,  26.3861, -22.0668],\n",
      "        [-25.2396,  26.4360, -22.3608]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1733,  21.2716,  22.2136, -25.1658,  26.4056, -22.3206],\n",
      "        [ 26.6570,  22.0384,  22.7043, -25.3680,  26.7401, -22.2615],\n",
      "        [ 26.5293,  21.7602,  22.3962, -25.4177,  26.4674, -22.0723],\n",
      "        [ 26.4028,  21.8559,  22.7972, -25.4765,  26.4041, -22.1664],\n",
      "        [ 26.3370,  21.9062,  22.6030, -24.8812,  26.3861, -22.0668],\n",
      "        [ 26.3538,  22.4344,  22.4245, -25.2396,  26.4360, -22.3608]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.675319671630859\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0979, 22.2572, 23.1244],\n",
      "        [26.3015, 21.6650, 22.3676],\n",
      "        [25.8854, 21.1768, 22.5124],\n",
      "        [26.4519, 21.5128, 22.3519],\n",
      "        [26.3943, 21.9988, 22.4528],\n",
      "        [25.8559, 21.2074, 22.2637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(50.4994, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4121,  27.0306, -22.4025],\n",
      "        [-25.4104,  26.5214, -22.2958],\n",
      "        [-25.4802,  26.3193, -22.0084],\n",
      "        [-24.9316,  26.4334, -22.1965],\n",
      "        [-25.9447,  27.0778, -22.8174],\n",
      "        [-25.5358,  26.5078, -22.7098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0979,  22.2572,  23.1244, -25.4121,  27.0306, -22.4025],\n",
      "        [ 26.3015,  21.6650,  22.3676, -25.4104,  26.5214, -22.2958],\n",
      "        [ 25.8854,  21.1768,  22.5124, -25.4802,  26.3193, -22.0084],\n",
      "        [ 26.4519,  21.5128,  22.3519, -24.9316,  26.4334, -22.1965],\n",
      "        [ 26.3943,  21.9988,  22.4528, -25.9447,  27.0778, -22.8174],\n",
      "        [ 25.8559,  21.2074,  22.2637, -25.5358,  26.5078, -22.7098]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.8377532958984375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8356, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.1402, 21.6362, 22.2397],\n",
      "        [26.4835, 21.6571, 22.3872],\n",
      "        [26.4716, 22.0425, 22.7727],\n",
      "        [26.8606, 21.7629, 22.6480],\n",
      "        [27.1097, 21.8785, 23.1747],\n",
      "        [27.1245, 22.2729, 23.1169]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.2925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5227,  26.3190, -22.1938],\n",
      "        [-24.5830,  26.2051, -21.8149],\n",
      "        [-25.6072,  26.6639, -22.4922],\n",
      "        [-26.0096,  27.2086, -22.9012],\n",
      "        [-25.4774,  26.7682, -22.6955],\n",
      "        [-25.0041,  26.2490, -21.9933]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.1402,  21.6362,  22.2397, -25.5227,  26.3190, -22.1938],\n",
      "        [ 26.4835,  21.6571,  22.3872, -24.5830,  26.2051, -21.8149],\n",
      "        [ 26.4716,  22.0425,  22.7727, -25.6072,  26.6639, -22.4922],\n",
      "        [ 26.8606,  21.7629,  22.6480, -26.0096,  27.2086, -22.9012],\n",
      "        [ 27.1097,  21.8785,  23.1747, -25.4774,  26.7682, -22.6955],\n",
      "        [ 27.1245,  22.2729,  23.1169, -25.0041,  26.2490, -21.9933]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.696831703186035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6537, 21.8098, 22.4707],\n",
      "        [26.5567, 21.6960, 22.2441],\n",
      "        [27.0636, 22.4099, 22.9970],\n",
      "        [26.5407, 21.6798, 22.3303],\n",
      "        [27.1667, 22.1394, 23.0052],\n",
      "        [26.2961, 21.8569, 23.0188]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.7065, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1929,  26.0322, -21.9624],\n",
      "        [-25.7392,  27.1891, -22.6336],\n",
      "        [-25.3025,  26.0979, -22.4911],\n",
      "        [-25.5819,  26.7669, -22.8385],\n",
      "        [-24.7077,  25.9573, -21.6423],\n",
      "        [-24.9734,  25.7787, -21.6693]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6537,  21.8098,  22.4707, -25.1929,  26.0322, -21.9624],\n",
      "        [ 26.5567,  21.6960,  22.2441, -25.7392,  27.1891, -22.6336],\n",
      "        [ 27.0636,  22.4099,  22.9970, -25.3025,  26.0979, -22.4911],\n",
      "        [ 26.5407,  21.6798,  22.3303, -25.5819,  26.7669, -22.8385],\n",
      "        [ 27.1667,  22.1394,  23.0052, -24.7077,  25.9573, -21.6423],\n",
      "        [ 26.2961,  21.8569,  23.0188, -24.9734,  25.7787, -21.6693]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.714648723602295\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4072, 21.5421, 22.7342],\n",
      "        [26.4827, 21.7482, 22.7110],\n",
      "        [26.2470, 21.8121, 22.6358],\n",
      "        [26.4233, 21.7880, 22.2053],\n",
      "        [26.6152, 21.8024, 22.6618],\n",
      "        [26.4953, 21.2506, 21.9073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4046, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.9828,  26.7603, -22.5441],\n",
      "        [-25.6897,  27.0204, -22.4201],\n",
      "        [-25.5493,  27.0297, -22.5888],\n",
      "        [-25.3882,  26.2157, -22.4990],\n",
      "        [-25.7221,  26.8900, -22.8839],\n",
      "        [-25.8222,  26.7655, -22.7279]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4072,  21.5421,  22.7342, -24.9828,  26.7603, -22.5441],\n",
      "        [ 26.4827,  21.7482,  22.7110, -25.6897,  27.0204, -22.4201],\n",
      "        [ 26.2470,  21.8121,  22.6358, -25.5493,  27.0297, -22.5888],\n",
      "        [ 26.4233,  21.7880,  22.2053, -25.3882,  26.2157, -22.4990],\n",
      "        [ 26.6152,  21.8024,  22.6618, -25.7221,  26.8900, -22.8839],\n",
      "        [ 26.4953,  21.2506,  21.9073, -25.8222,  26.7655, -22.7279]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.742109298706055\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4730, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3447, 21.4142, 22.4478],\n",
      "        [26.9870, 22.0576, 22.7467],\n",
      "        [26.2381, 21.8964, 22.6108],\n",
      "        [25.7794, 21.3493, 21.6915],\n",
      "        [26.4677, 22.0892, 22.4996],\n",
      "        [26.6592, 21.5317, 22.4731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.0227, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3598,  26.4996, -22.7732],\n",
      "        [-25.2422,  26.6948, -22.3029],\n",
      "        [-25.0831,  26.5793, -22.4669],\n",
      "        [-25.5503,  27.0186, -22.6605],\n",
      "        [-25.3190,  26.4825, -22.2305],\n",
      "        [-25.0602,  26.4498, -22.7848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3447,  21.4142,  22.4478, -25.3598,  26.4996, -22.7732],\n",
      "        [ 26.9870,  22.0576,  22.7467, -25.2422,  26.6948, -22.3029],\n",
      "        [ 26.2381,  21.8964,  22.6108, -25.0831,  26.5793, -22.4669],\n",
      "        [ 25.7794,  21.3493,  21.6915, -25.5503,  27.0186, -22.6605],\n",
      "        [ 26.4677,  22.0892,  22.4996, -25.3190,  26.4825, -22.2305],\n",
      "        [ 26.6592,  21.5317,  22.4731, -25.0602,  26.4498, -22.7848]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.733081817626953\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4377, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0110, 22.3568, 23.2845],\n",
      "        [26.5745, 21.9320, 22.4461],\n",
      "        [26.5346, 21.9228, 22.3536],\n",
      "        [25.7289, 21.6096, 21.9302],\n",
      "        [26.4110, 21.3431, 22.4391],\n",
      "        [26.5992, 21.6194, 22.7067]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0964, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3728,  26.5565, -22.3716],\n",
      "        [-25.4536,  26.7241, -22.6912],\n",
      "        [-25.2297,  26.5543, -22.7330],\n",
      "        [-24.9422,  25.8338, -21.9015],\n",
      "        [-25.6721,  27.1101, -22.5283],\n",
      "        [-25.0551,  26.2517, -22.4260]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0110,  22.3568,  23.2845, -25.3728,  26.5565, -22.3716],\n",
      "        [ 26.5745,  21.9320,  22.4461, -25.4536,  26.7241, -22.6912],\n",
      "        [ 26.5346,  21.9228,  22.3536, -25.2297,  26.5543, -22.7330],\n",
      "        [ 25.7289,  21.6096,  21.9302, -24.9422,  25.8338, -21.9015],\n",
      "        [ 26.4110,  21.3431,  22.4391, -25.6721,  27.1101, -22.5283],\n",
      "        [ 26.5992,  21.6194,  22.7067, -25.0551,  26.2517, -22.4260]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.833787441253662\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8074, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5032, 21.8138, 22.1690],\n",
      "        [26.7922, 21.6163, 23.0479],\n",
      "        [26.3202, 21.9496, 22.2992],\n",
      "        [26.2247, 21.6984, 22.1733],\n",
      "        [26.7752, 21.7078, 22.5577],\n",
      "        [26.5821, 21.7783, 22.5484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.9444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8886,  26.8209, -22.9314],\n",
      "        [-25.6846,  26.8807, -22.5734],\n",
      "        [-25.8673,  26.7701, -22.8131],\n",
      "        [-24.9081,  26.2348, -22.2220],\n",
      "        [-25.6866,  27.2157, -22.9496],\n",
      "        [-25.3249,  26.2964, -21.8371]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5032,  21.8138,  22.1690, -25.8886,  26.8209, -22.9314],\n",
      "        [ 26.7922,  21.6163,  23.0479, -25.6846,  26.8807, -22.5734],\n",
      "        [ 26.3202,  21.9496,  22.2992, -25.8673,  26.7701, -22.8131],\n",
      "        [ 26.2247,  21.6984,  22.1733, -24.9081,  26.2348, -22.2220],\n",
      "        [ 26.7752,  21.7078,  22.5577, -25.6866,  27.2157, -22.9496],\n",
      "        [ 26.5821,  21.7783,  22.5484, -25.3249,  26.2964, -21.8371]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.781571865081787\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5716, 21.4408, 22.5205],\n",
      "        [25.9588, 21.3744, 22.0706],\n",
      "        [25.9794, 21.6026, 22.1388],\n",
      "        [26.5483, 21.8211, 22.2498],\n",
      "        [26.8359, 21.7777, 22.7393],\n",
      "        [26.6900, 21.8810, 22.8129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.6907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8527,  26.6950, -22.6307],\n",
      "        [-25.6483,  26.7391, -22.5115],\n",
      "        [-25.3717,  26.8375, -22.8365],\n",
      "        [-25.1658,  26.4214, -22.2199],\n",
      "        [-25.4202,  26.4710, -22.3717],\n",
      "        [-25.9229,  26.8206, -22.5256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5716,  21.4408,  22.5205, -25.8527,  26.6950, -22.6307],\n",
      "        [ 25.9588,  21.3744,  22.0706, -25.6483,  26.7391, -22.5115],\n",
      "        [ 25.9794,  21.6026,  22.1388, -25.3717,  26.8375, -22.8365],\n",
      "        [ 26.5483,  21.8211,  22.2498, -25.1658,  26.4214, -22.2199],\n",
      "        [ 26.8359,  21.7777,  22.7393, -25.4202,  26.4710, -22.3717],\n",
      "        [ 26.6900,  21.8810,  22.8129, -25.9229,  26.8206, -22.5256]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.77553129196167\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4522, 21.5079, 22.0982],\n",
      "        [26.9841, 22.4335, 23.1242],\n",
      "        [27.0760, 22.0454, 23.0410],\n",
      "        [26.8451, 22.0195, 22.6693],\n",
      "        [26.5838, 21.8994, 22.4176],\n",
      "        [26.3088, 21.6997, 22.2476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.7699, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5438,  26.9732, -22.6193],\n",
      "        [-25.6959,  26.7168, -22.6100],\n",
      "        [-25.5049,  26.1603, -22.5459],\n",
      "        [-25.7790,  26.7076, -22.6098],\n",
      "        [-25.2346,  26.4562, -21.9391],\n",
      "        [-25.1227,  26.4327, -21.8713]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4522,  21.5079,  22.0982, -25.5438,  26.9732, -22.6193],\n",
      "        [ 26.9841,  22.4335,  23.1242, -25.6959,  26.7168, -22.6100],\n",
      "        [ 27.0760,  22.0454,  23.0410, -25.5049,  26.1603, -22.5459],\n",
      "        [ 26.8451,  22.0195,  22.6693, -25.7790,  26.7076, -22.6098],\n",
      "        [ 26.5838,  21.8994,  22.4176, -25.2346,  26.4562, -21.9391],\n",
      "        [ 26.3088,  21.6997,  22.2476, -25.1227,  26.4327, -21.8713]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.753096103668213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0804, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[25.7433, 21.3882, 22.1939],\n",
      "        [26.5664, 21.4953, 22.6750],\n",
      "        [26.0725, 21.0319, 22.5170],\n",
      "        [26.7924, 22.0004, 22.7414],\n",
      "        [26.9205, 22.7204, 23.1561],\n",
      "        [27.1103, 22.2654, 23.1452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.2413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1133,  26.3534, -22.3024],\n",
      "        [-25.8315,  26.9645, -22.8055],\n",
      "        [-25.4647,  26.7863, -22.3726],\n",
      "        [-25.1181,  26.3333, -22.1334],\n",
      "        [-25.0118,  26.4570, -22.0105],\n",
      "        [-25.5879,  26.7036, -22.4017]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 25.7433,  21.3882,  22.1939, -25.1133,  26.3534, -22.3024],\n",
      "        [ 26.5664,  21.4953,  22.6750, -25.8315,  26.9645, -22.8055],\n",
      "        [ 26.0725,  21.0319,  22.5170, -25.4647,  26.7863, -22.3726],\n",
      "        [ 26.7924,  22.0004,  22.7414, -25.1181,  26.3333, -22.1334],\n",
      "        [ 26.9205,  22.7204,  23.1561, -25.0118,  26.4570, -22.0105],\n",
      "        [ 27.1103,  22.2654,  23.1452, -25.5879,  26.7036, -22.4017]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.669556617736816\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3868, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4263, 21.6322, 22.6456],\n",
      "        [26.5091, 22.1136, 22.8568],\n",
      "        [26.4406, 21.8611, 22.5143],\n",
      "        [26.2552, 21.4763, 22.4048],\n",
      "        [26.1128, 21.6722, 22.4428],\n",
      "        [26.8116, 21.9142, 22.7869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0576, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.6712,  26.5046, -21.8908],\n",
      "        [-24.7315,  25.5378, -21.2922],\n",
      "        [-25.8483,  27.0023, -22.4084],\n",
      "        [-25.1034,  26.8573, -22.3004],\n",
      "        [-25.0177,  26.8199, -22.1547],\n",
      "        [-25.3850,  26.7041, -22.1473]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4263,  21.6322,  22.6456, -24.6712,  26.5046, -21.8908],\n",
      "        [ 26.5091,  22.1136,  22.8568, -24.7315,  25.5378, -21.2922],\n",
      "        [ 26.4406,  21.8611,  22.5143, -25.8483,  27.0023, -22.4084],\n",
      "        [ 26.2552,  21.4763,  22.4048, -25.1034,  26.8573, -22.3004],\n",
      "        [ 26.1128,  21.6722,  22.4428, -25.0177,  26.8199, -22.1547],\n",
      "        [ 26.8116,  21.9142,  22.7869, -25.3850,  26.7041, -22.1473]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.716217994689941\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6458, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8565, 22.2757, 22.9515],\n",
      "        [26.7931, 22.2331, 22.4648],\n",
      "        [26.9998, 21.6385, 22.9605],\n",
      "        [27.2156, 21.9351, 22.6905],\n",
      "        [26.6928, 22.1318, 22.9797],\n",
      "        [26.3178, 21.5483, 22.7640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.4780, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.4420,  25.9430, -21.7290],\n",
      "        [-25.6295,  26.8236, -22.5650],\n",
      "        [-25.0129,  26.4698, -22.0962],\n",
      "        [-25.5497,  26.7528, -22.4802],\n",
      "        [-25.9669,  26.9402, -22.8195],\n",
      "        [-25.6436,  26.7585, -22.5470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8565,  22.2757,  22.9515, -24.4420,  25.9430, -21.7290],\n",
      "        [ 26.7931,  22.2331,  22.4648, -25.6295,  26.8236, -22.5650],\n",
      "        [ 26.9998,  21.6385,  22.9605, -25.0129,  26.4698, -22.0962],\n",
      "        [ 27.2156,  21.9351,  22.6905, -25.5497,  26.7528, -22.4802],\n",
      "        [ 26.6928,  22.1318,  22.9797, -25.9669,  26.9402, -22.8195],\n",
      "        [ 26.3178,  21.5483,  22.7640, -25.6436,  26.7585, -22.5470]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.744986534118652\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6987, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4123, 22.7000, 22.8860],\n",
      "        [26.7031, 22.2156, 23.1971],\n",
      "        [26.5939, 21.8468, 22.6956],\n",
      "        [26.7627, 21.9642, 23.0460],\n",
      "        [27.0542, 22.1602, 22.8709],\n",
      "        [26.8860, 22.4749, 22.8668]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.0064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8237,  26.4566, -22.2180],\n",
      "        [-25.4781,  26.5575, -22.2457],\n",
      "        [-25.1264,  26.6563, -22.2582],\n",
      "        [-25.1767,  26.7888, -22.5268],\n",
      "        [-25.7944,  26.8860, -22.5806],\n",
      "        [-25.4398,  27.0335, -22.6924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4123,  22.7000,  22.8860, -25.8237,  26.4566, -22.2180],\n",
      "        [ 26.7031,  22.2156,  23.1971, -25.4781,  26.5575, -22.2457],\n",
      "        [ 26.5939,  21.8468,  22.6956, -25.1264,  26.6563, -22.2582],\n",
      "        [ 26.7627,  21.9642,  23.0460, -25.1767,  26.7888, -22.5268],\n",
      "        [ 27.0542,  22.1602,  22.8709, -25.7944,  26.8860, -22.5806],\n",
      "        [ 26.8860,  22.4749,  22.8668, -25.4398,  27.0335, -22.6924]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.870389938354492\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4304, 21.5659, 22.4610],\n",
      "        [26.9226, 22.0764, 23.0219],\n",
      "        [26.7230, 22.2688, 22.8344],\n",
      "        [26.3786, 22.2215, 22.5395],\n",
      "        [26.5678, 21.7930, 22.4927],\n",
      "        [26.3472, 21.9322, 22.6550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.3600, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7970,  27.0273, -22.9008],\n",
      "        [-25.4193,  26.7011, -22.8323],\n",
      "        [-26.2007,  27.5224, -23.2223],\n",
      "        [-25.3041,  26.7164, -22.2933],\n",
      "        [-25.1200,  26.3663, -22.1215],\n",
      "        [-25.0133,  26.5376, -21.9907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4304,  21.5659,  22.4610, -25.7970,  27.0273, -22.9008],\n",
      "        [ 26.9226,  22.0764,  23.0219, -25.4193,  26.7011, -22.8323],\n",
      "        [ 26.7230,  22.2688,  22.8344, -26.2007,  27.5224, -23.2223],\n",
      "        [ 26.3786,  22.2215,  22.5395, -25.3041,  26.7164, -22.2933],\n",
      "        [ 26.5678,  21.7930,  22.4927, -25.1200,  26.3663, -22.1215],\n",
      "        [ 26.3472,  21.9322,  22.6550, -25.0133,  26.5376, -21.9907]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.799091815948486\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1351, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6240, 21.9418, 22.5109],\n",
      "        [26.9591, 22.2581, 23.1049],\n",
      "        [26.8153, 21.9365, 22.7067],\n",
      "        [26.1996, 21.8451, 22.4624],\n",
      "        [27.0863, 22.3384, 23.0776],\n",
      "        [27.0317, 22.1948, 23.2015]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.6383, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6416,  26.6986, -22.6107],\n",
      "        [-25.3912,  26.6343, -22.4065],\n",
      "        [-25.9274,  27.5361, -22.9541],\n",
      "        [-25.6504,  26.7568, -22.2604],\n",
      "        [-25.3428,  26.7258, -22.3697],\n",
      "        [-25.2997,  26.2504, -22.1867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6240,  21.9418,  22.5109, -25.6416,  26.6986, -22.6107],\n",
      "        [ 26.9591,  22.2581,  23.1049, -25.3912,  26.6343, -22.4065],\n",
      "        [ 26.8153,  21.9365,  22.7067, -25.9274,  27.5361, -22.9541],\n",
      "        [ 26.1996,  21.8451,  22.4624, -25.6504,  26.7568, -22.2604],\n",
      "        [ 27.0863,  22.3384,  23.0776, -25.3428,  26.7258, -22.3697],\n",
      "        [ 27.0317,  22.1948,  23.2015, -25.2997,  26.2504, -22.1867]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.801176071166992\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0985, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5971, 21.8654, 22.7399],\n",
      "        [26.1602, 21.3842, 22.3285],\n",
      "        [26.6462, 21.7774, 22.4184],\n",
      "        [27.0740, 22.2303, 23.1119],\n",
      "        [26.6799, 21.7878, 22.2427],\n",
      "        [26.9684, 22.1877, 23.0454]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6154, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.0658,  26.6044, -22.2140],\n",
      "        [-25.2339,  26.5074, -22.3143],\n",
      "        [-25.0703,  26.2139, -22.2693],\n",
      "        [-25.3913,  26.5944, -22.3289],\n",
      "        [-25.5208,  26.5384, -21.9848],\n",
      "        [-25.4443,  26.2400, -22.2005]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5971,  21.8654,  22.7399, -25.0658,  26.6044, -22.2140],\n",
      "        [ 26.1602,  21.3842,  22.3285, -25.2339,  26.5074, -22.3143],\n",
      "        [ 26.6462,  21.7774,  22.4184, -25.0703,  26.2139, -22.2693],\n",
      "        [ 27.0740,  22.2303,  23.1119, -25.3913,  26.5944, -22.3289],\n",
      "        [ 26.6799,  21.7878,  22.2427, -25.5208,  26.5384, -21.9848],\n",
      "        [ 26.9684,  22.1877,  23.0454, -25.4443,  26.2400, -22.2005]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.774330139160156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5080, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8752, 21.8870, 22.8197],\n",
      "        [26.3576, 21.9250, 22.5109],\n",
      "        [26.7197, 21.5979, 22.7826],\n",
      "        [26.8357, 21.9492, 22.9811],\n",
      "        [26.7641, 21.8880, 22.7921],\n",
      "        [26.9266, 22.1285, 22.9974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.2372, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2737,  26.6650, -22.7065],\n",
      "        [-25.6475,  26.4865, -22.5651],\n",
      "        [-25.4612,  26.8636, -22.6533],\n",
      "        [-24.8854,  26.3503, -22.3004],\n",
      "        [-24.7300,  26.2016, -21.7943],\n",
      "        [-25.2323,  26.7083, -22.7250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8752,  21.8870,  22.8197, -25.2737,  26.6650, -22.7065],\n",
      "        [ 26.3576,  21.9250,  22.5109, -25.6475,  26.4865, -22.5651],\n",
      "        [ 26.7197,  21.5979,  22.7826, -25.4612,  26.8636, -22.6533],\n",
      "        [ 26.8357,  21.9492,  22.9811, -24.8854,  26.3503, -22.3004],\n",
      "        [ 26.7641,  21.8880,  22.7921, -24.7300,  26.2016, -21.7943],\n",
      "        [ 26.9266,  22.1285,  22.9974, -25.2323,  26.7083, -22.7250]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.819667339324951\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9003, 22.1960, 23.0983],\n",
      "        [26.8127, 21.7520, 22.4770],\n",
      "        [27.1455, 22.4089, 23.0452],\n",
      "        [26.5691, 22.0593, 22.3736],\n",
      "        [27.2266, 22.2904, 23.1981],\n",
      "        [26.4518, 21.3202, 22.5907]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.1784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5101,  26.4013, -22.1291],\n",
      "        [-25.9278,  27.2885, -23.0090],\n",
      "        [-25.2594,  26.6165, -22.2060],\n",
      "        [-25.4495,  26.9391, -22.5708],\n",
      "        [-25.5678,  26.7583, -22.8974],\n",
      "        [-25.7452,  26.9509, -23.2003]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9003,  22.1960,  23.0983, -25.5101,  26.4013, -22.1291],\n",
      "        [ 26.8127,  21.7520,  22.4770, -25.9278,  27.2885, -23.0090],\n",
      "        [ 27.1455,  22.4089,  23.0452, -25.2594,  26.6165, -22.2060],\n",
      "        [ 26.5691,  22.0593,  22.3736, -25.4495,  26.9391, -22.5708],\n",
      "        [ 27.2266,  22.2904,  23.1981, -25.5678,  26.7583, -22.8974],\n",
      "        [ 26.4518,  21.3202,  22.5907, -25.7452,  26.9509, -23.2003]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.828378677368164\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5195, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8078, 22.1164, 22.6294],\n",
      "        [26.9582, 22.1544, 23.0756],\n",
      "        [26.9147, 22.1225, 22.9410],\n",
      "        [26.8815, 21.7246, 22.6739],\n",
      "        [26.3032, 21.5828, 22.2017],\n",
      "        [26.4474, 21.7458, 22.0703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9258, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2761,  26.9657, -22.6796],\n",
      "        [-25.2324,  26.7728, -22.6982],\n",
      "        [-25.6170,  26.9359, -22.3688],\n",
      "        [-25.3695,  26.5422, -22.1154],\n",
      "        [-25.6435,  26.5593, -22.5391],\n",
      "        [-25.8129,  26.7891, -22.3645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8078,  22.1164,  22.6294, -25.2761,  26.9657, -22.6796],\n",
      "        [ 26.9582,  22.1544,  23.0756, -25.2324,  26.7728, -22.6982],\n",
      "        [ 26.9147,  22.1225,  22.9410, -25.6170,  26.9359, -22.3688],\n",
      "        [ 26.8815,  21.7246,  22.6739, -25.3695,  26.5422, -22.1154],\n",
      "        [ 26.3032,  21.5828,  22.2017, -25.6435,  26.5593, -22.5391],\n",
      "        [ 26.4474,  21.7458,  22.0703, -25.8129,  26.7891, -22.3645]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.829587936401367\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.9084, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3231, 22.4796, 23.2844],\n",
      "        [27.0198, 21.9650, 22.8488],\n",
      "        [26.5754, 21.7635, 22.6871],\n",
      "        [26.6434, 22.3274, 22.9585],\n",
      "        [26.2204, 21.4277, 22.1410],\n",
      "        [26.8182, 21.9091, 22.9426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.5716, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.2030,  26.6113, -22.7623],\n",
      "        [-26.1811,  27.4634, -23.2099],\n",
      "        [-25.5126,  26.5605, -22.5082],\n",
      "        [-25.0042,  26.6701, -22.5362],\n",
      "        [-25.1410,  25.8857, -21.9720],\n",
      "        [-25.6782,  26.9774, -22.5341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3231,  22.4796,  23.2844, -25.2030,  26.6113, -22.7623],\n",
      "        [ 27.0198,  21.9650,  22.8488, -26.1811,  27.4634, -23.2099],\n",
      "        [ 26.5754,  21.7635,  22.6871, -25.5126,  26.5605, -22.5082],\n",
      "        [ 26.6434,  22.3274,  22.9585, -25.0042,  26.6701, -22.5362],\n",
      "        [ 26.2204,  21.4277,  22.1410, -25.1410,  25.8857, -21.9720],\n",
      "        [ 26.8182,  21.9091,  22.9426, -25.6782,  26.9774, -22.5341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.88944673538208\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0016, 22.4434, 23.2018],\n",
      "        [26.4356, 21.7765, 22.4387],\n",
      "        [27.4673, 22.3116, 22.9510],\n",
      "        [26.6747, 21.3200, 22.4413],\n",
      "        [26.9849, 21.7823, 22.9428],\n",
      "        [27.0207, 21.7642, 22.6895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9558, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5778,  26.9344, -22.8379],\n",
      "        [-25.2998,  26.6491, -22.5207],\n",
      "        [-25.1095,  26.9543, -22.2765],\n",
      "        [-25.6717,  27.0074, -23.0627],\n",
      "        [-26.0534,  27.1564, -22.8499],\n",
      "        [-25.4253,  26.7207, -22.4709]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0016,  22.4434,  23.2018, -25.5778,  26.9344, -22.8379],\n",
      "        [ 26.4356,  21.7765,  22.4387, -25.2998,  26.6491, -22.5207],\n",
      "        [ 27.4673,  22.3116,  22.9510, -25.1095,  26.9543, -22.2765],\n",
      "        [ 26.6747,  21.3200,  22.4413, -25.6717,  27.0074, -23.0627],\n",
      "        [ 26.9849,  21.7823,  22.9428, -26.0534,  27.1564, -22.8499],\n",
      "        [ 27.0207,  21.7642,  22.6895, -25.4253,  26.7207, -22.4709]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.895965576171875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3048, 21.8667, 22.4740],\n",
      "        [26.7001, 21.9691, 22.6164],\n",
      "        [27.1275, 22.1996, 23.1423],\n",
      "        [26.7689, 22.1630, 22.6200],\n",
      "        [26.5625, 21.9636, 22.8054],\n",
      "        [26.8622, 22.5633, 22.8533]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.4110, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8019,  26.7197, -22.5144],\n",
      "        [-25.8700,  26.9329, -22.6847],\n",
      "        [-25.2541,  26.5697, -22.8847],\n",
      "        [-26.1056,  27.2640, -23.0921],\n",
      "        [-25.4703,  26.8471, -22.2379],\n",
      "        [-25.4335,  26.3690, -22.1238]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3048,  21.8667,  22.4740, -25.8019,  26.7197, -22.5144],\n",
      "        [ 26.7001,  21.9691,  22.6164, -25.8700,  26.9329, -22.6847],\n",
      "        [ 27.1275,  22.1996,  23.1423, -25.2541,  26.5697, -22.8847],\n",
      "        [ 26.7689,  22.1630,  22.6200, -26.1056,  27.2640, -23.0921],\n",
      "        [ 26.5625,  21.9636,  22.8054, -25.4703,  26.8471, -22.2379],\n",
      "        [ 26.8622,  22.5633,  22.8533, -25.4335,  26.3690, -22.1238]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.796241760253906\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1809, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8310, 22.4797, 22.6484],\n",
      "        [26.7255, 21.8719, 22.6033],\n",
      "        [26.6625, 21.7386, 22.6286],\n",
      "        [27.3445, 22.6396, 23.2546],\n",
      "        [26.9602, 22.1810, 22.8959],\n",
      "        [26.6782, 21.7561, 22.5496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.1397, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7734,  27.5518, -23.0655],\n",
      "        [-25.4417,  26.8987, -22.2827],\n",
      "        [-26.2557,  27.5930, -23.2463],\n",
      "        [-25.1305,  26.7743, -22.3017],\n",
      "        [-25.4844,  26.6363, -22.4470],\n",
      "        [-25.5351,  26.7729, -22.9617]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8310,  22.4797,  22.6484, -25.7734,  27.5518, -23.0655],\n",
      "        [ 26.7255,  21.8719,  22.6033, -25.4417,  26.8987, -22.2827],\n",
      "        [ 26.6625,  21.7386,  22.6286, -26.2557,  27.5930, -23.2463],\n",
      "        [ 27.3445,  22.6396,  23.2546, -25.1305,  26.7743, -22.3017],\n",
      "        [ 26.9602,  22.1810,  22.8959, -25.4844,  26.6363, -22.4470],\n",
      "        [ 26.6782,  21.7561,  22.5496, -25.5351,  26.7729, -22.9617]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.902624130249023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2917, 22.2885, 23.2148],\n",
      "        [26.6571, 22.3466, 22.6426],\n",
      "        [27.1597, 22.1985, 22.8080],\n",
      "        [26.8385, 22.5425, 23.1193],\n",
      "        [26.1914, 21.3025, 21.8219],\n",
      "        [26.6124, 21.9260, 22.5775]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4245, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9068,  26.7627, -22.5928],\n",
      "        [-25.7441,  27.0587, -22.5504],\n",
      "        [-25.6810,  26.8909, -22.6131],\n",
      "        [-25.2934,  26.4572, -22.4062],\n",
      "        [-25.5865,  26.9311, -22.6588],\n",
      "        [-25.3750,  26.8365, -22.5342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2917,  22.2885,  23.2148, -25.9068,  26.7627, -22.5928],\n",
      "        [ 26.6571,  22.3466,  22.6426, -25.7441,  27.0587, -22.5504],\n",
      "        [ 27.1597,  22.1985,  22.8080, -25.6810,  26.8909, -22.6131],\n",
      "        [ 26.8385,  22.5425,  23.1193, -25.2934,  26.4572, -22.4062],\n",
      "        [ 26.1914,  21.3025,  21.8219, -25.5865,  26.9311, -22.6588],\n",
      "        [ 26.6124,  21.9260,  22.5775, -25.3750,  26.8365, -22.5342]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.910655498504639\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1322, 22.2478, 23.2041],\n",
      "        [26.2615, 21.8336, 22.3292],\n",
      "        [26.5708, 21.8956, 22.8669],\n",
      "        [25.9604, 21.4234, 22.5123],\n",
      "        [26.6292, 22.1039, 22.8029],\n",
      "        [26.3969, 21.6158, 22.1497]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.1786, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0722,  26.7509, -22.3616],\n",
      "        [-25.3118,  26.5038, -22.7067],\n",
      "        [-25.4970,  26.7047, -22.5565],\n",
      "        [-26.2173,  27.0905, -22.8497],\n",
      "        [-25.4910,  26.8001, -22.6161],\n",
      "        [-25.4016,  26.9044, -22.6391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1322,  22.2478,  23.2041, -26.0722,  26.7509, -22.3616],\n",
      "        [ 26.2615,  21.8336,  22.3292, -25.3118,  26.5038, -22.7067],\n",
      "        [ 26.5708,  21.8956,  22.8669, -25.4970,  26.7047, -22.5565],\n",
      "        [ 25.9604,  21.4234,  22.5123, -26.2173,  27.0905, -22.8497],\n",
      "        [ 26.6292,  22.1039,  22.8029, -25.4910,  26.8001, -22.6161],\n",
      "        [ 26.3969,  21.6158,  22.1497, -25.4016,  26.9044, -22.6391]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.900497913360596\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4814, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5253, 21.5865, 22.7615],\n",
      "        [26.6352, 21.7434, 22.5672],\n",
      "        [26.2315, 21.2926, 22.3663],\n",
      "        [26.7865, 22.2478, 23.0066],\n",
      "        [26.6047, 21.7880, 22.5829],\n",
      "        [26.1794, 21.5025, 22.2654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.3397, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9443,  26.9407, -23.0192],\n",
      "        [-25.9059,  27.1587, -22.9121],\n",
      "        [-25.9349,  27.0654, -22.6910],\n",
      "        [-25.6100,  27.0798, -22.9580],\n",
      "        [-25.7525,  26.5000, -22.4904],\n",
      "        [-25.5403,  26.9322, -22.6298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5253,  21.5865,  22.7615, -25.9443,  26.9407, -23.0192],\n",
      "        [ 26.6352,  21.7434,  22.5672, -25.9059,  27.1587, -22.9121],\n",
      "        [ 26.2315,  21.2926,  22.3663, -25.9349,  27.0654, -22.6910],\n",
      "        [ 26.7865,  22.2478,  23.0066, -25.6100,  27.0798, -22.9580],\n",
      "        [ 26.6047,  21.7880,  22.5829, -25.7525,  26.5000, -22.4904],\n",
      "        [ 26.1794,  21.5025,  22.2654, -25.5403,  26.9322, -22.6298]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.847139835357666\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4490, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4454, 22.1244, 22.4168],\n",
      "        [26.5581, 21.5189, 22.9895],\n",
      "        [27.1188, 22.4360, 23.2488],\n",
      "        [26.4708, 22.1289, 23.1044],\n",
      "        [27.1423, 22.7015, 23.3694],\n",
      "        [26.9481, 22.0212, 22.8334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3135, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.1500,  26.5984, -22.5942],\n",
      "        [-25.4999,  26.7505, -22.7180],\n",
      "        [-25.1390,  26.6453, -22.5583],\n",
      "        [-26.0253,  27.1389, -23.1031],\n",
      "        [-25.9937,  27.2246, -22.9838],\n",
      "        [-25.0786,  26.5945, -22.0618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4454,  22.1244,  22.4168, -25.1500,  26.5984, -22.5942],\n",
      "        [ 26.5581,  21.5189,  22.9895, -25.4999,  26.7505, -22.7180],\n",
      "        [ 27.1188,  22.4360,  23.2488, -25.1390,  26.6453, -22.5583],\n",
      "        [ 26.4708,  22.1289,  23.1044, -26.0253,  27.1389, -23.1031],\n",
      "        [ 27.1423,  22.7015,  23.3694, -25.9937,  27.2246, -22.9838],\n",
      "        [ 26.9481,  22.0212,  22.8334, -25.0786,  26.5945, -22.0618]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.795019626617432\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4815, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.3427, 21.6203, 22.2242],\n",
      "        [27.3453, 22.2371, 23.5285],\n",
      "        [26.3475, 21.8540, 22.2698],\n",
      "        [26.9746, 22.7055, 23.1063],\n",
      "        [27.1488, 22.4805, 23.1569],\n",
      "        [26.7201, 22.3088, 22.8603]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.5695, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5071,  27.1092, -22.9591],\n",
      "        [-25.8873,  26.8156, -22.8561],\n",
      "        [-25.1942,  25.6695, -22.0470],\n",
      "        [-25.2148,  26.4611, -22.4578],\n",
      "        [-25.5498,  26.7410, -22.3049],\n",
      "        [-25.3420,  26.2178, -22.1403]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.3427,  21.6203,  22.2242, -25.5071,  27.1092, -22.9591],\n",
      "        [ 27.3453,  22.2371,  23.5285, -25.8873,  26.8156, -22.8561],\n",
      "        [ 26.3475,  21.8540,  22.2698, -25.1942,  25.6695, -22.0470],\n",
      "        [ 26.9746,  22.7055,  23.1063, -25.2148,  26.4611, -22.4578],\n",
      "        [ 27.1488,  22.4805,  23.1569, -25.5498,  26.7410, -22.3049],\n",
      "        [ 26.7201,  22.3088,  22.8603, -25.3420,  26.2178, -22.1403]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.806577682495117\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3504, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9864, 21.9957, 22.9584],\n",
      "        [26.8707, 22.3173, 22.7591],\n",
      "        [26.8784, 21.8874, 23.1503],\n",
      "        [27.2756, 22.7257, 23.3168],\n",
      "        [26.6019, 21.2355, 22.6884],\n",
      "        [26.9730, 22.1659, 22.7806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.8090, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5622,  26.7973, -22.5364],\n",
      "        [-24.9346,  26.6603, -22.2588],\n",
      "        [-25.7564,  26.6079, -22.3018],\n",
      "        [-25.9170,  27.2396, -23.1173],\n",
      "        [-25.2925,  26.6516, -22.8610],\n",
      "        [-25.6708,  26.4393, -22.7610]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9864,  21.9957,  22.9584, -25.5622,  26.7973, -22.5364],\n",
      "        [ 26.8707,  22.3173,  22.7591, -24.9346,  26.6603, -22.2588],\n",
      "        [ 26.8784,  21.8874,  23.1503, -25.7564,  26.6079, -22.3018],\n",
      "        [ 27.2756,  22.7257,  23.3168, -25.9170,  27.2396, -23.1173],\n",
      "        [ 26.6019,  21.2355,  22.6884, -25.2925,  26.6516, -22.8610],\n",
      "        [ 26.9730,  22.1659,  22.7806, -25.6708,  26.4393, -22.7610]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.86892032623291\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3178, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5258, 21.5727, 22.6280],\n",
      "        [27.5386, 22.6799, 23.8024],\n",
      "        [26.7044, 22.2499, 22.8006],\n",
      "        [26.9989, 22.6565, 23.0776],\n",
      "        [26.9493, 21.9635, 22.8221],\n",
      "        [26.8986, 22.1374, 23.0879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.9008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3106,  26.7979, -22.5815],\n",
      "        [-25.7864,  27.0858, -22.8877],\n",
      "        [-26.1604,  27.1704, -22.9102],\n",
      "        [-25.5915,  26.5497, -21.9786],\n",
      "        [-25.4626,  26.7465, -22.7219],\n",
      "        [-26.3866,  27.2083, -23.0928]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5258,  21.5727,  22.6280, -25.3106,  26.7979, -22.5815],\n",
      "        [ 27.5386,  22.6799,  23.8024, -25.7864,  27.0858, -22.8877],\n",
      "        [ 26.7044,  22.2499,  22.8006, -26.1604,  27.1704, -22.9102],\n",
      "        [ 26.9989,  22.6565,  23.0776, -25.5915,  26.5497, -21.9786],\n",
      "        [ 26.9493,  21.9635,  22.8221, -25.4626,  26.7465, -22.7219],\n",
      "        [ 26.8986,  22.1374,  23.0879, -26.3866,  27.2083, -23.0928]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.807831764221191\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2584, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5026, 22.0041, 22.3159],\n",
      "        [26.8113, 21.8715, 22.6375],\n",
      "        [27.4226, 22.5225, 23.2460],\n",
      "        [26.8695, 22.9011, 23.5071],\n",
      "        [26.3652, 21.7386, 22.5397],\n",
      "        [26.9275, 22.3571, 22.7414]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9790, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7959,  27.3158, -23.1225],\n",
      "        [-25.9433,  26.5443, -22.4841],\n",
      "        [-25.7151,  26.7040, -22.8279],\n",
      "        [-25.9058,  26.6462, -22.8113],\n",
      "        [-25.5879,  26.7945, -22.5948],\n",
      "        [-25.1456,  26.3756, -22.2363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5026,  22.0041,  22.3159, -25.7959,  27.3158, -23.1225],\n",
      "        [ 26.8113,  21.8715,  22.6375, -25.9433,  26.5443, -22.4841],\n",
      "        [ 27.4226,  22.5225,  23.2460, -25.7151,  26.7040, -22.8279],\n",
      "        [ 26.8695,  22.9011,  23.5071, -25.9058,  26.6462, -22.8113],\n",
      "        [ 26.3652,  21.7386,  22.5397, -25.5879,  26.7945, -22.5948],\n",
      "        [ 26.9275,  22.3571,  22.7414, -25.1456,  26.3756, -22.2363]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.861532211303711\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9711, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0580, 22.4692, 22.8113],\n",
      "        [26.4066, 21.9782, 22.6092],\n",
      "        [26.8020, 22.2948, 22.8764],\n",
      "        [26.2847, 21.8998, 22.2742],\n",
      "        [26.7941, 22.4537, 23.0187],\n",
      "        [26.7757, 21.7861, 22.1793]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.5036, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4728,  27.0516, -22.6045],\n",
      "        [-25.4073,  26.5156, -22.4762],\n",
      "        [-25.8429,  26.7109, -22.5512],\n",
      "        [-25.6680,  27.0924, -22.6430],\n",
      "        [-25.7666,  26.8229, -22.4733],\n",
      "        [-25.7446,  27.0863, -22.9000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0580,  22.4692,  22.8113, -25.4728,  27.0516, -22.6045],\n",
      "        [ 26.4066,  21.9782,  22.6092, -25.4073,  26.5156, -22.4762],\n",
      "        [ 26.8020,  22.2948,  22.8764, -25.8429,  26.7109, -22.5512],\n",
      "        [ 26.2847,  21.8998,  22.2742, -25.6680,  27.0924, -22.6430],\n",
      "        [ 26.7941,  22.4537,  23.0187, -25.7666,  26.8229, -22.4733],\n",
      "        [ 26.7757,  21.7861,  22.1793, -25.7446,  27.0863, -22.9000]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.896975517272949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4408, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.7767, 22.2641, 22.7350],\n",
      "        [26.1276, 21.5513, 22.1852],\n",
      "        [27.1913, 22.2924, 23.1871],\n",
      "        [26.8889, 22.5738, 23.2725],\n",
      "        [26.5501, 21.7351, 22.6956],\n",
      "        [26.6309, 21.7850, 22.9159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8378,  27.0502, -22.8177],\n",
      "        [-26.1208,  27.2482, -23.1359],\n",
      "        [-25.4536,  26.6678, -22.8648],\n",
      "        [-25.8234,  26.7681, -22.8136],\n",
      "        [-24.6479,  26.5850, -22.1194],\n",
      "        [-25.4957,  27.0273, -22.5282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.7767,  22.2641,  22.7350, -25.8378,  27.0502, -22.8177],\n",
      "        [ 26.1276,  21.5513,  22.1852, -26.1208,  27.2482, -23.1359],\n",
      "        [ 27.1913,  22.2924,  23.1871, -25.4536,  26.6678, -22.8648],\n",
      "        [ 26.8889,  22.5738,  23.2725, -25.8234,  26.7681, -22.8136],\n",
      "        [ 26.5501,  21.7351,  22.6956, -24.6479,  26.5850, -22.1194],\n",
      "        [ 26.6309,  21.7850,  22.9159, -25.4957,  27.0273, -22.5282]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.89166259765625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1376, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2045, 21.9749, 23.1809],\n",
      "        [26.4734, 21.8862, 22.3550],\n",
      "        [26.7933, 21.7238, 22.2947],\n",
      "        [26.8260, 22.1280, 22.6727],\n",
      "        [26.7364, 22.3156, 22.6989],\n",
      "        [26.8159, 22.2792, 22.8834]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9731, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0438,  26.9363, -22.8602],\n",
      "        [-25.5285,  26.7929, -22.3088],\n",
      "        [-25.1525,  26.5727, -22.1548],\n",
      "        [-25.8127,  27.5384, -22.8666],\n",
      "        [-26.1958,  27.3565, -22.7962],\n",
      "        [-24.7228,  26.4871, -22.6247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2045,  21.9749,  23.1809, -26.0438,  26.9363, -22.8602],\n",
      "        [ 26.4734,  21.8862,  22.3550, -25.5285,  26.7929, -22.3088],\n",
      "        [ 26.7933,  21.7238,  22.2947, -25.1525,  26.5727, -22.1548],\n",
      "        [ 26.8260,  22.1280,  22.6727, -25.8127,  27.5384, -22.8666],\n",
      "        [ 26.7364,  22.3156,  22.6989, -26.1958,  27.3565, -22.7962],\n",
      "        [ 26.8159,  22.2792,  22.8834, -24.7228,  26.4871, -22.6247]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.9315338134765625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9996, 22.2834, 23.0086],\n",
      "        [26.9248, 22.3151, 22.8882],\n",
      "        [27.1192, 22.5886, 23.4797],\n",
      "        [26.8966, 22.3954, 23.3056],\n",
      "        [26.9095, 21.6957, 23.1823],\n",
      "        [26.7339, 22.1621, 23.0300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.9120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2534,  27.5594, -23.2320],\n",
      "        [-25.8716,  26.9580, -22.6525],\n",
      "        [-25.8473,  27.2805, -22.9168],\n",
      "        [-26.0480,  27.2526, -23.3911],\n",
      "        [-25.7486,  26.8612, -22.6807],\n",
      "        [-26.1724,  27.2499, -22.8934]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9996,  22.2834,  23.0086, -26.2534,  27.5594, -23.2320],\n",
      "        [ 26.9248,  22.3151,  22.8882, -25.8716,  26.9580, -22.6525],\n",
      "        [ 27.1192,  22.5886,  23.4797, -25.8473,  27.2805, -22.9168],\n",
      "        [ 26.8966,  22.3954,  23.3056, -26.0480,  27.2526, -23.3911],\n",
      "        [ 26.9095,  21.6957,  23.1823, -25.7486,  26.8612, -22.6807],\n",
      "        [ 26.7339,  22.1621,  23.0300, -26.1724,  27.2499, -22.8934]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.966740131378174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5858, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8275, 22.2453, 23.3685],\n",
      "        [27.1100, 22.1005, 23.1782],\n",
      "        [26.5652, 21.5416, 22.4983],\n",
      "        [27.1140, 22.3492, 23.1132],\n",
      "        [26.9778, 22.0054, 22.8642],\n",
      "        [26.6389, 22.0194, 22.6431]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(33.9611, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9519,  27.2552, -23.1267],\n",
      "        [-26.3185,  27.3256, -23.0225],\n",
      "        [-25.8776,  26.9335, -22.8005],\n",
      "        [-25.0509,  26.6208, -22.3075],\n",
      "        [-25.6854,  26.9399, -22.7336],\n",
      "        [-25.4782,  26.6584, -22.4957]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8275,  22.2453,  23.3685, -25.9519,  27.2552, -23.1267],\n",
      "        [ 27.1100,  22.1005,  23.1782, -26.3185,  27.3256, -23.0225],\n",
      "        [ 26.5652,  21.5416,  22.4983, -25.8776,  26.9335, -22.8005],\n",
      "        [ 27.1140,  22.3492,  23.1132, -25.0509,  26.6208, -22.3075],\n",
      "        [ 26.9778,  22.0054,  22.8642, -25.6854,  26.9399, -22.7336],\n",
      "        [ 26.6389,  22.0194,  22.6431, -25.4782,  26.6584, -22.4957]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.9495849609375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2653, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2867, 22.3239, 23.2309],\n",
      "        [27.3859, 22.1976, 23.4649],\n",
      "        [26.7574, 22.1937, 22.2827],\n",
      "        [26.8420, 22.1600, 22.7207],\n",
      "        [26.8344, 22.0668, 22.6848],\n",
      "        [26.7643, 21.9482, 22.6859]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.1041, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7329,  26.9840, -23.0345],\n",
      "        [-25.8436,  27.2401, -22.7637],\n",
      "        [-25.9425,  26.8933, -22.7576],\n",
      "        [-25.0546,  26.3508, -22.4243],\n",
      "        [-25.8176,  26.7456, -22.7263],\n",
      "        [-26.3698,  27.5340, -23.1484]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2867,  22.3239,  23.2309, -25.7329,  26.9840, -23.0345],\n",
      "        [ 27.3859,  22.1976,  23.4649, -25.8436,  27.2401, -22.7637],\n",
      "        [ 26.7574,  22.1937,  22.2827, -25.9425,  26.8933, -22.7576],\n",
      "        [ 26.8420,  22.1600,  22.7207, -25.0546,  26.3508, -22.4243],\n",
      "        [ 26.8344,  22.0668,  22.6848, -25.8176,  26.7456, -22.7263],\n",
      "        [ 26.7643,  21.9482,  22.6859, -26.3698,  27.5340, -23.1484]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.9526286125183105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0835, 21.7431, 23.1822],\n",
      "        [26.4770, 21.6899, 22.6731],\n",
      "        [27.3088, 21.9661, 22.9404],\n",
      "        [26.5029, 22.1428, 22.5835],\n",
      "        [26.4590, 21.5699, 22.2213],\n",
      "        [26.7488, 21.9401, 23.1556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.2199, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5559,  26.9419, -22.8402],\n",
      "        [-25.5786,  27.1732, -22.8331],\n",
      "        [-25.9515,  27.3158, -22.9267],\n",
      "        [-26.1327,  27.2383, -23.0438],\n",
      "        [-25.9075,  26.6083, -22.8302],\n",
      "        [-25.5768,  27.1219, -22.6092]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0835,  21.7431,  23.1822, -25.5559,  26.9419, -22.8402],\n",
      "        [ 26.4770,  21.6899,  22.6731, -25.5786,  27.1732, -22.8331],\n",
      "        [ 27.3088,  21.9661,  22.9404, -25.9515,  27.3158, -22.9267],\n",
      "        [ 26.5029,  22.1428,  22.5835, -26.1327,  27.2383, -23.0438],\n",
      "        [ 26.4590,  21.5699,  22.2213, -25.9075,  26.6083, -22.8302],\n",
      "        [ 26.7488,  21.9401,  23.1556, -25.5768,  27.1219, -22.6092]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.906905174255371\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8549, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5765, 22.0217, 22.6474],\n",
      "        [27.1926, 22.1490, 23.0657],\n",
      "        [26.7527, 22.4469, 22.9803],\n",
      "        [26.9122, 21.9805, 22.5856],\n",
      "        [26.8373, 21.8534, 22.4156],\n",
      "        [26.7727, 21.7849, 22.3714]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.3716, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0510,  27.2528, -22.7212],\n",
      "        [-25.6274,  26.8426, -23.0970],\n",
      "        [-26.0836,  27.2734, -23.2317],\n",
      "        [-25.3254,  26.3977, -22.6833],\n",
      "        [-25.4561,  26.9261, -22.4935],\n",
      "        [-25.6585,  27.1693, -23.0987]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5765,  22.0217,  22.6474, -26.0510,  27.2528, -22.7212],\n",
      "        [ 27.1926,  22.1490,  23.0657, -25.6274,  26.8426, -23.0970],\n",
      "        [ 26.7527,  22.4469,  22.9803, -26.0836,  27.2734, -23.2317],\n",
      "        [ 26.9122,  21.9805,  22.5856, -25.3254,  26.3977, -22.6833],\n",
      "        [ 26.8373,  21.8534,  22.4156, -25.4561,  26.9261, -22.4935],\n",
      "        [ 26.7727,  21.7849,  22.3714, -25.6585,  27.1693, -23.0987]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.89169979095459\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6208, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0866, 22.2650, 23.0232],\n",
      "        [26.5841, 21.8637, 22.6115],\n",
      "        [26.3652, 21.7375, 22.6464],\n",
      "        [26.9953, 22.4692, 23.0912],\n",
      "        [27.0273, 21.9198, 23.1088],\n",
      "        [26.5196, 21.7856, 22.5647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2861,  27.6535, -23.1717],\n",
      "        [-25.5067,  26.5943, -22.3977],\n",
      "        [-26.2966,  27.6588, -23.5066],\n",
      "        [-25.6949,  27.1035, -22.7725],\n",
      "        [-25.3735,  26.6697, -22.6789],\n",
      "        [-25.3207,  26.6564, -22.7634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0866,  22.2650,  23.0232, -26.2861,  27.6535, -23.1717],\n",
      "        [ 26.5841,  21.8637,  22.6115, -25.5067,  26.5943, -22.3977],\n",
      "        [ 26.3652,  21.7375,  22.6464, -26.2966,  27.6588, -23.5066],\n",
      "        [ 26.9953,  22.4692,  23.0912, -25.6949,  27.1035, -22.7725],\n",
      "        [ 27.0273,  21.9198,  23.1088, -25.3735,  26.6697, -22.6789],\n",
      "        [ 26.5196,  21.7856,  22.5647, -25.3207,  26.6564, -22.7634]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.984158515930176\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2367, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3123, 22.6477, 23.3095],\n",
      "        [27.0606, 22.5203, 22.9737],\n",
      "        [26.4218, 21.5368, 22.6240],\n",
      "        [26.8940, 22.1254, 23.0999],\n",
      "        [26.1674, 21.5505, 22.7130],\n",
      "        [26.9614, 22.7947, 23.1586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9705, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2365,  27.1106, -23.1151],\n",
      "        [-25.9197,  27.2238, -22.8790],\n",
      "        [-25.4478,  27.1885, -22.8195],\n",
      "        [-25.3373,  26.5953, -22.6785],\n",
      "        [-24.9121,  26.5566, -22.5140],\n",
      "        [-25.5642,  26.5461, -22.7980]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3123,  22.6477,  23.3095, -26.2365,  27.1106, -23.1151],\n",
      "        [ 27.0606,  22.5203,  22.9737, -25.9197,  27.2238, -22.8790],\n",
      "        [ 26.4218,  21.5368,  22.6240, -25.4478,  27.1885, -22.8195],\n",
      "        [ 26.8940,  22.1254,  23.0999, -25.3373,  26.5953, -22.6785],\n",
      "        [ 26.1674,  21.5505,  22.7130, -24.9121,  26.5566, -22.5140],\n",
      "        [ 26.9614,  22.7947,  23.1586, -25.5642,  26.5461, -22.7980]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.001826286315918\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9619, 22.1589, 22.6413],\n",
      "        [26.4753, 22.1560, 22.6098],\n",
      "        [26.9945, 22.3425, 22.7623],\n",
      "        [27.0591, 22.0816, 22.5935],\n",
      "        [26.8563, 22.1657, 22.8673],\n",
      "        [26.5774, 22.7744, 22.8325]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3437, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9363,  27.3584, -22.9686],\n",
      "        [-25.8488,  26.8447, -22.8927],\n",
      "        [-25.3138,  26.7735, -22.4009],\n",
      "        [-25.8217,  26.6522, -22.7937],\n",
      "        [-26.2801,  27.1471, -23.1560],\n",
      "        [-26.2143,  27.7721, -23.1815]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9619,  22.1589,  22.6413, -25.9363,  27.3584, -22.9686],\n",
      "        [ 26.4753,  22.1560,  22.6098, -25.8488,  26.8447, -22.8927],\n",
      "        [ 26.9945,  22.3425,  22.7623, -25.3138,  26.7735, -22.4009],\n",
      "        [ 27.0591,  22.0816,  22.5935, -25.8217,  26.6522, -22.7937],\n",
      "        [ 26.8563,  22.1657,  22.8673, -26.2801,  27.1471, -23.1560],\n",
      "        [ 26.5774,  22.7744,  22.8325, -26.2143,  27.7721, -23.1815]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.930446624755859\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8855, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.7504, 22.1504, 23.0121],\n",
      "        [26.4460, 22.0703, 22.6375],\n",
      "        [27.5315, 22.7953, 23.4388],\n",
      "        [26.7025, 21.7696, 22.3680],\n",
      "        [26.6226, 21.9020, 22.5055],\n",
      "        [26.4913, 21.7377, 22.6789]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.5843, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3386,  26.3720, -22.1664],\n",
      "        [-25.8769,  27.1831, -22.7734],\n",
      "        [-26.2350,  27.3710, -23.0560],\n",
      "        [-25.6241,  26.5038, -22.4656],\n",
      "        [-25.3956,  26.7644, -22.9808],\n",
      "        [-25.7108,  26.7041, -23.1692]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.7504,  22.1504,  23.0121, -25.3386,  26.3720, -22.1664],\n",
      "        [ 26.4460,  22.0703,  22.6375, -25.8769,  27.1831, -22.7734],\n",
      "        [ 27.5315,  22.7953,  23.4388, -26.2350,  27.3710, -23.0560],\n",
      "        [ 26.7025,  21.7696,  22.3680, -25.6241,  26.5038, -22.4656],\n",
      "        [ 26.6226,  21.9020,  22.5055, -25.3956,  26.7644, -22.9808],\n",
      "        [ 26.4913,  21.7377,  22.6789, -25.7108,  26.7041, -23.1692]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.856204032897949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5798, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5973, 21.7726, 22.4277],\n",
      "        [27.0552, 22.1420, 23.1047],\n",
      "        [26.3728, 21.8273, 22.9002],\n",
      "        [26.8715, 22.2228, 23.0078],\n",
      "        [26.7692, 22.3810, 22.8394],\n",
      "        [26.8897, 21.7656, 22.9735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.0684, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-24.7986,  26.1173, -22.1284],\n",
      "        [-25.9668,  26.8399, -22.4935],\n",
      "        [-25.9419,  27.0177, -22.9145],\n",
      "        [-26.0871,  27.5004, -23.1432],\n",
      "        [-25.6422,  27.1649, -22.9969],\n",
      "        [-26.0448,  26.9874, -23.1099]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5973,  21.7726,  22.4277, -24.7986,  26.1173, -22.1284],\n",
      "        [ 27.0552,  22.1420,  23.1047, -25.9668,  26.8399, -22.4935],\n",
      "        [ 26.3728,  21.8273,  22.9002, -25.9419,  27.0177, -22.9145],\n",
      "        [ 26.8715,  22.2228,  23.0078, -26.0871,  27.5004, -23.1432],\n",
      "        [ 26.7692,  22.3810,  22.8394, -25.6422,  27.1649, -22.9969],\n",
      "        [ 26.8897,  21.7656,  22.9735, -26.0448,  26.9874, -23.1099]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.779446125030518\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.7045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5977, 21.9221, 22.8333],\n",
      "        [26.0596, 21.5636, 22.6791],\n",
      "        [26.7817, 22.2835, 22.9773],\n",
      "        [26.3009, 22.1336, 22.8575],\n",
      "        [27.4848, 22.1933, 23.3702],\n",
      "        [27.3496, 22.6215, 23.5702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9544,  27.0106, -22.9667],\n",
      "        [-25.9558,  27.0662, -23.0799],\n",
      "        [-25.0464,  26.6639, -22.3693],\n",
      "        [-25.3368,  26.6545, -22.7167],\n",
      "        [-25.2481,  26.5936, -22.5789],\n",
      "        [-25.5739,  27.3463, -22.7138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5977,  21.9221,  22.8333, -25.9544,  27.0106, -22.9667],\n",
      "        [ 26.0596,  21.5636,  22.6791, -25.9558,  27.0662, -23.0799],\n",
      "        [ 26.7817,  22.2835,  22.9773, -25.0464,  26.6639, -22.3693],\n",
      "        [ 26.3009,  22.1336,  22.8575, -25.3368,  26.6545, -22.7167],\n",
      "        [ 27.4848,  22.1933,  23.3702, -25.2481,  26.5936, -22.5789],\n",
      "        [ 27.3496,  22.6215,  23.5702, -25.5739,  27.3463, -22.7138]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.904291152954102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3632, 22.6275, 23.3491],\n",
      "        [26.6071, 21.9894, 23.1259],\n",
      "        [26.9606, 22.3063, 22.8146],\n",
      "        [27.0123, 22.6234, 23.4572],\n",
      "        [26.8608, 22.2922, 23.1756],\n",
      "        [26.5133, 21.5711, 22.7833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1862, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7055,  27.0659, -22.6500],\n",
      "        [-25.9798,  26.8943, -22.9284],\n",
      "        [-25.3596,  26.9413, -22.6975],\n",
      "        [-25.3315,  26.4186, -22.1258],\n",
      "        [-26.2784,  27.4430, -22.8744],\n",
      "        [-26.1325,  27.5433, -23.2193]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3632,  22.6275,  23.3491, -25.7055,  27.0659, -22.6500],\n",
      "        [ 26.6071,  21.9894,  23.1259, -25.9798,  26.8943, -22.9284],\n",
      "        [ 26.9606,  22.3063,  22.8146, -25.3596,  26.9413, -22.6975],\n",
      "        [ 27.0123,  22.6234,  23.4572, -25.3315,  26.4186, -22.1258],\n",
      "        [ 26.8608,  22.2922,  23.1756, -26.2784,  27.4430, -22.8744],\n",
      "        [ 26.5133,  21.5711,  22.7833, -26.1325,  27.5433, -23.2193]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.981388568878174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3238, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5283, 22.8757, 23.2634],\n",
      "        [27.1987, 22.7626, 23.4006],\n",
      "        [27.4915, 22.5671, 23.3843],\n",
      "        [26.6407, 22.2107, 22.7241],\n",
      "        [26.8112, 22.3045, 22.9631],\n",
      "        [26.8089, 22.1472, 23.1343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.2341, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6926,  26.7170, -22.6687],\n",
      "        [-25.3289,  26.2519, -22.3948],\n",
      "        [-26.0860,  27.1593, -22.8973],\n",
      "        [-25.7331,  26.6618, -22.5568],\n",
      "        [-25.9617,  27.1385, -23.2004],\n",
      "        [-25.7501,  26.9302, -22.8353]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5283,  22.8757,  23.2634, -25.6926,  26.7170, -22.6687],\n",
      "        [ 27.1987,  22.7626,  23.4006, -25.3289,  26.2519, -22.3948],\n",
      "        [ 27.4915,  22.5671,  23.3843, -26.0860,  27.1593, -22.8973],\n",
      "        [ 26.6407,  22.2107,  22.7241, -25.7331,  26.6618, -22.5568],\n",
      "        [ 26.8112,  22.3045,  22.9631, -25.9617,  27.1385, -23.2004],\n",
      "        [ 26.8089,  22.1472,  23.1343, -25.7501,  26.9302, -22.8353]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.984402179718018\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1787, 22.2169, 23.0657],\n",
      "        [26.8741, 22.1019, 23.2278],\n",
      "        [27.7215, 22.6679, 23.0334],\n",
      "        [27.4244, 22.4134, 23.1666],\n",
      "        [26.9288, 22.3001, 23.2599],\n",
      "        [27.1460, 22.5551, 22.8833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9406,  27.2213, -23.0770],\n",
      "        [-25.3810,  26.4977, -22.2370],\n",
      "        [-24.6509,  25.5448, -22.0111],\n",
      "        [-25.9285,  26.9277, -22.7707],\n",
      "        [-25.5765,  26.6979, -22.7812],\n",
      "        [-25.7998,  26.6110, -22.7946]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1787,  22.2169,  23.0657, -25.9406,  27.2213, -23.0770],\n",
      "        [ 26.8741,  22.1019,  23.2278, -25.3810,  26.4977, -22.2370],\n",
      "        [ 27.7215,  22.6679,  23.0334, -24.6509,  25.5448, -22.0111],\n",
      "        [ 27.4244,  22.4134,  23.1666, -25.9285,  26.9277, -22.7707],\n",
      "        [ 26.9288,  22.3001,  23.2599, -25.5765,  26.6979, -22.7812],\n",
      "        [ 27.1460,  22.5551,  22.8833, -25.7998,  26.6110, -22.7946]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.973964691162109\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8535, 22.0973, 22.8273],\n",
      "        [26.9911, 22.3626, 23.0648],\n",
      "        [26.7449, 22.4786, 23.0051],\n",
      "        [26.9224, 22.3076, 23.0347],\n",
      "        [26.3829, 21.8431, 22.6649],\n",
      "        [26.4679, 22.1220, 22.9202]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.2466, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8428,  27.0580, -22.8193],\n",
      "        [-25.9345,  27.2532, -23.1560],\n",
      "        [-25.1439,  26.4326, -21.9301],\n",
      "        [-25.6892,  27.0264, -22.9600],\n",
      "        [-25.7482,  27.1800, -22.8758],\n",
      "        [-25.5435,  26.6862, -22.4653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8535,  22.0973,  22.8273, -25.8428,  27.0580, -22.8193],\n",
      "        [ 26.9911,  22.3626,  23.0648, -25.9345,  27.2532, -23.1560],\n",
      "        [ 26.7449,  22.4786,  23.0051, -25.1439,  26.4326, -21.9301],\n",
      "        [ 26.9224,  22.3076,  23.0347, -25.6892,  27.0264, -22.9600],\n",
      "        [ 26.3829,  21.8431,  22.6649, -25.7482,  27.1800, -22.8758],\n",
      "        [ 26.4679,  22.1220,  22.9202, -25.5435,  26.6862, -22.4653]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.925498008728027\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7989, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0185, 22.1621, 23.1649],\n",
      "        [26.6654, 22.0770, 22.7474],\n",
      "        [27.5652, 22.4202, 23.5383],\n",
      "        [26.7620, 22.0838, 23.0463],\n",
      "        [27.4593, 22.5520, 23.4202],\n",
      "        [26.8618, 22.2371, 22.9591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.6444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5465,  27.1735, -22.6513],\n",
      "        [-26.2440,  27.1984, -22.8225],\n",
      "        [-25.9129,  26.9243, -22.9777],\n",
      "        [-25.8885,  26.7982, -23.0492],\n",
      "        [-26.5037,  27.4652, -23.2416],\n",
      "        [-25.8791,  27.2671, -23.0570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0185,  22.1621,  23.1649, -25.5465,  27.1735, -22.6513],\n",
      "        [ 26.6654,  22.0770,  22.7474, -26.2440,  27.1984, -22.8225],\n",
      "        [ 27.5652,  22.4202,  23.5383, -25.9129,  26.9243, -22.9777],\n",
      "        [ 26.7620,  22.0838,  23.0463, -25.8885,  26.7982, -23.0492],\n",
      "        [ 27.4593,  22.5520,  23.4202, -26.5037,  27.4652, -23.2416],\n",
      "        [ 26.8618,  22.2371,  22.9591, -25.8791,  27.2671, -23.0570]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.943390846252441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6100, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8781, 22.1015, 22.7051],\n",
      "        [27.1017, 22.4243, 22.8632],\n",
      "        [27.0828, 22.5943, 23.4583],\n",
      "        [27.3036, 22.4155, 23.2180],\n",
      "        [26.8574, 22.1684, 22.6683],\n",
      "        [26.0161, 21.5989, 22.5302]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.2118, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4303,  26.7464, -22.5799],\n",
      "        [-25.8415,  26.9288, -23.1304],\n",
      "        [-26.0049,  27.0294, -22.8565],\n",
      "        [-25.4228,  26.8426, -22.7536],\n",
      "        [-25.3128,  26.8377, -22.3156],\n",
      "        [-25.1510,  26.6102, -22.4192]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8781,  22.1015,  22.7051, -25.4303,  26.7464, -22.5799],\n",
      "        [ 27.1017,  22.4243,  22.8632, -25.8415,  26.9288, -23.1304],\n",
      "        [ 27.0828,  22.5943,  23.4583, -26.0049,  27.0294, -22.8565],\n",
      "        [ 27.3036,  22.4155,  23.2180, -25.4228,  26.8426, -22.7536],\n",
      "        [ 26.8574,  22.1684,  22.6683, -25.3128,  26.8377, -22.3156],\n",
      "        [ 26.0161,  21.5989,  22.5302, -25.1510,  26.6102, -22.4192]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.891880989074707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6752, 21.8437, 22.8141],\n",
      "        [27.6620, 23.0731, 23.8587],\n",
      "        [26.6779, 22.0658, 22.9904],\n",
      "        [27.0079, 22.2909, 22.7004],\n",
      "        [26.4581, 22.0597, 23.1071],\n",
      "        [26.9295, 22.6319, 22.4735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.0360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5953,  26.8042, -22.7282],\n",
      "        [-26.3516,  27.3069, -23.2664],\n",
      "        [-25.8962,  26.9261, -22.5902],\n",
      "        [-25.8966,  27.1085, -22.4827],\n",
      "        [-25.2392,  26.5063, -22.6842],\n",
      "        [-25.8327,  27.2330, -22.7451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6752,  21.8437,  22.8141, -25.5953,  26.8042, -22.7282],\n",
      "        [ 27.6620,  23.0731,  23.8587, -26.3516,  27.3069, -23.2664],\n",
      "        [ 26.6779,  22.0658,  22.9904, -25.8962,  26.9261, -22.5902],\n",
      "        [ 27.0079,  22.2909,  22.7004, -25.8966,  27.1085, -22.4827],\n",
      "        [ 26.4581,  22.0597,  23.1071, -25.2392,  26.5063, -22.6842],\n",
      "        [ 26.9295,  22.6319,  22.4735, -25.8327,  27.2330, -22.7451]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.890814781188965\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8265, 22.4485, 22.8830],\n",
      "        [26.8316, 22.1387, 22.9095],\n",
      "        [26.8741, 22.1571, 23.0708],\n",
      "        [26.8375, 22.3579, 23.0130],\n",
      "        [27.3946, 22.6058, 23.2233],\n",
      "        [27.2584, 22.3431, 23.0986]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.3525, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9185,  27.2530, -22.8673],\n",
      "        [-26.2956,  27.3080, -23.0992],\n",
      "        [-26.2808,  27.2486, -22.9236],\n",
      "        [-25.6471,  26.6022, -22.9549],\n",
      "        [-26.0616,  26.6917, -22.7954],\n",
      "        [-26.4583,  27.1524, -23.3188]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8265,  22.4485,  22.8830, -25.9185,  27.2530, -22.8673],\n",
      "        [ 26.8316,  22.1387,  22.9095, -26.2956,  27.3080, -23.0992],\n",
      "        [ 26.8741,  22.1571,  23.0708, -26.2808,  27.2486, -22.9236],\n",
      "        [ 26.8375,  22.3579,  23.0130, -25.6471,  26.6022, -22.9549],\n",
      "        [ 27.3946,  22.6058,  23.2233, -26.0616,  26.6917, -22.7954],\n",
      "        [ 27.2584,  22.3431,  23.0986, -26.4583,  27.1524, -23.3188]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.958303928375244\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2019, 22.3328, 23.1152],\n",
      "        [27.6930, 22.8997, 23.6241],\n",
      "        [28.0082, 23.1845, 23.9830],\n",
      "        [27.0887, 22.5803, 23.3320],\n",
      "        [26.7183, 21.8854, 23.1168],\n",
      "        [27.0718, 22.1546, 23.1370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.6680, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3210,  27.2075, -23.1401],\n",
      "        [-25.6336,  26.6318, -22.8757],\n",
      "        [-25.7986,  27.0561, -22.9956],\n",
      "        [-25.6999,  26.9873, -23.1606],\n",
      "        [-26.3649,  27.4834, -23.2630],\n",
      "        [-25.9906,  26.8154, -22.6346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2019,  22.3328,  23.1152, -26.3210,  27.2075, -23.1401],\n",
      "        [ 27.6930,  22.8997,  23.6241, -25.6336,  26.6318, -22.8757],\n",
      "        [ 28.0082,  23.1845,  23.9830, -25.7986,  27.0561, -22.9956],\n",
      "        [ 27.0887,  22.5803,  23.3320, -25.6999,  26.9873, -23.1606],\n",
      "        [ 26.7183,  21.8854,  23.1168, -26.3649,  27.4834, -23.2630],\n",
      "        [ 27.0718,  22.1546,  23.1370, -25.9906,  26.8154, -22.6346]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.008123397827148\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4553, 22.3913, 23.3743],\n",
      "        [26.8321, 22.8133, 22.7078],\n",
      "        [26.5565, 22.1639, 22.4150],\n",
      "        [27.2156, 22.6664, 22.7643],\n",
      "        [26.3862, 21.7146, 22.3658],\n",
      "        [26.4799, 21.3295, 22.0944]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(42.3673, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0413,  27.2798, -23.0559],\n",
      "        [-25.6439,  27.0584, -22.8612],\n",
      "        [-25.7971,  26.8692, -22.9874],\n",
      "        [-26.1473,  27.0851, -22.8656],\n",
      "        [-25.2139,  26.4813, -22.2594],\n",
      "        [-25.5141,  26.4551, -22.5350]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4553,  22.3913,  23.3743, -26.0413,  27.2798, -23.0559],\n",
      "        [ 26.8321,  22.8133,  22.7078, -25.6439,  27.0584, -22.8612],\n",
      "        [ 26.5565,  22.1639,  22.4150, -25.7971,  26.8692, -22.9874],\n",
      "        [ 27.2156,  22.6664,  22.7643, -26.1473,  27.0851, -22.8656],\n",
      "        [ 26.3862,  21.7146,  22.3658, -25.2139,  26.4813, -22.2594],\n",
      "        [ 26.4799,  21.3295,  22.0944, -25.5141,  26.4551, -22.5350]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.028481483459473\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8606, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8492, 22.4549, 23.3264],\n",
      "        [26.9981, 22.3663, 23.1431],\n",
      "        [27.6266, 22.7694, 23.2790],\n",
      "        [26.5082, 22.1227, 22.5240],\n",
      "        [28.1591, 22.9697, 23.6249],\n",
      "        [27.2057, 22.4512, 23.3327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.2000, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6196,  27.4347, -23.1153],\n",
      "        [-25.5010,  26.9899, -22.8956],\n",
      "        [-26.7293,  27.8922, -23.0694],\n",
      "        [-25.9074,  26.9846, -22.7038],\n",
      "        [-25.7863,  26.5886, -22.8217],\n",
      "        [-26.0072,  27.1597, -23.0165]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8492,  22.4549,  23.3264, -25.6196,  27.4347, -23.1153],\n",
      "        [ 26.9981,  22.3663,  23.1431, -25.5010,  26.9899, -22.8956],\n",
      "        [ 27.6266,  22.7694,  23.2790, -26.7293,  27.8922, -23.0694],\n",
      "        [ 26.5082,  22.1227,  22.5240, -25.9074,  26.9846, -22.7038],\n",
      "        [ 28.1591,  22.9697,  23.6249, -25.7863,  26.5886, -22.8217],\n",
      "        [ 27.2057,  22.4512,  23.3327, -26.0072,  27.1597, -23.0165]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.989816188812256\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9801, 22.2068, 22.9631],\n",
      "        [26.8752, 22.2538, 23.1366],\n",
      "        [27.1362, 22.6328, 23.0382],\n",
      "        [27.2031, 22.3556, 23.3532],\n",
      "        [26.8848, 22.0122, 22.8080],\n",
      "        [26.9729, 22.3779, 23.2509]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.1305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2943,  27.5681, -23.1030],\n",
      "        [-25.7513,  27.0542, -23.3034],\n",
      "        [-25.6923,  27.1944, -22.5772],\n",
      "        [-26.2484,  26.9775, -23.0290],\n",
      "        [-25.8447,  27.0796, -22.6510],\n",
      "        [-25.7850,  26.9347, -22.8618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9801,  22.2068,  22.9631, -26.2943,  27.5681, -23.1030],\n",
      "        [ 26.8752,  22.2538,  23.1366, -25.7513,  27.0542, -23.3034],\n",
      "        [ 27.1362,  22.6328,  23.0382, -25.6923,  27.1944, -22.5772],\n",
      "        [ 27.2031,  22.3556,  23.3532, -26.2484,  26.9775, -23.0290],\n",
      "        [ 26.8848,  22.0122,  22.8080, -25.8447,  27.0796, -22.6510],\n",
      "        [ 26.9729,  22.3779,  23.2509, -25.7850,  26.9347, -22.8618]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.001577377319336\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7494, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4695, 22.3566, 22.9610],\n",
      "        [26.8839, 22.0774, 22.5500],\n",
      "        [26.6765, 22.3394, 22.7581],\n",
      "        [27.1019, 22.4204, 23.0969],\n",
      "        [27.3809, 22.6497, 23.0871],\n",
      "        [27.2747, 22.6545, 23.4993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(25.5086, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0291,  27.0500, -22.8068],\n",
      "        [-25.9065,  27.3925, -22.9290],\n",
      "        [-25.8437,  26.8506, -22.8038],\n",
      "        [-26.3374,  27.6231, -23.4253],\n",
      "        [-25.7458,  26.9473, -22.8799],\n",
      "        [-26.4939,  27.3407, -23.1609]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4695,  22.3566,  22.9610, -26.0291,  27.0500, -22.8068],\n",
      "        [ 26.8839,  22.0774,  22.5500, -25.9065,  27.3925, -22.9290],\n",
      "        [ 26.6765,  22.3394,  22.7581, -25.8437,  26.8506, -22.8038],\n",
      "        [ 27.1019,  22.4204,  23.0969, -26.3374,  27.6231, -23.4253],\n",
      "        [ 27.3809,  22.6497,  23.0871, -25.7458,  26.9473, -22.8799],\n",
      "        [ 27.2747,  22.6545,  23.4993, -26.4939,  27.3407, -23.1609]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.998167037963867\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6436, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1858, 22.3829, 22.9646],\n",
      "        [27.1160, 22.7064, 23.2743],\n",
      "        [27.1337, 22.6220, 23.2377],\n",
      "        [27.4538, 22.1637, 23.5376],\n",
      "        [27.4221, 22.6373, 23.3500],\n",
      "        [27.1873, 22.3221, 23.1857]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.4706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7383,  26.6405, -22.6904],\n",
      "        [-25.7816,  26.9560, -23.1673],\n",
      "        [-25.8045,  27.0177, -23.0944],\n",
      "        [-25.6014,  26.8559, -23.0536],\n",
      "        [-26.4218,  27.6036, -23.5593],\n",
      "        [-26.2377,  27.4861, -22.9159]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1858,  22.3829,  22.9646, -25.7383,  26.6405, -22.6904],\n",
      "        [ 27.1160,  22.7064,  23.2743, -25.7816,  26.9560, -23.1673],\n",
      "        [ 27.1337,  22.6220,  23.2377, -25.8045,  27.0177, -23.0944],\n",
      "        [ 27.4538,  22.1637,  23.5376, -25.6014,  26.8559, -23.0536],\n",
      "        [ 27.4221,  22.6373,  23.3500, -26.4218,  27.6036, -23.5593],\n",
      "        [ 27.1873,  22.3221,  23.1857, -26.2377,  27.4861, -22.9159]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.956521987915039\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7303, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0363, 22.3970, 22.6922],\n",
      "        [27.2384, 22.7085, 23.2336],\n",
      "        [26.6555, 22.0910, 23.0186],\n",
      "        [26.5426, 22.0047, 22.9160],\n",
      "        [27.0581, 22.1746, 22.7779],\n",
      "        [26.7551, 22.5773, 23.6733]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.5307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6914,  27.6694, -23.5047],\n",
      "        [-25.9870,  27.4809, -23.2025],\n",
      "        [-25.3047,  26.7264, -22.6926],\n",
      "        [-26.2162,  27.2354, -23.5099],\n",
      "        [-26.0433,  27.3618, -23.4037],\n",
      "        [-26.2987,  27.4671, -23.3976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0363,  22.3970,  22.6922, -26.6914,  27.6694, -23.5047],\n",
      "        [ 27.2384,  22.7085,  23.2336, -25.9870,  27.4809, -23.2025],\n",
      "        [ 26.6555,  22.0910,  23.0186, -25.3047,  26.7264, -22.6926],\n",
      "        [ 26.5426,  22.0047,  22.9160, -26.2162,  27.2354, -23.5099],\n",
      "        [ 27.0581,  22.1746,  22.7779, -26.0433,  27.3618, -23.4037],\n",
      "        [ 26.7551,  22.5773,  23.6733, -26.2987,  27.4671, -23.3976]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.034553527832031\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3690, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1488, 22.4322, 23.0317],\n",
      "        [27.2130, 22.2297, 22.9208],\n",
      "        [27.6046, 22.5642, 23.1979],\n",
      "        [26.7700, 22.2297, 22.9352],\n",
      "        [27.2987, 22.2461, 23.1269],\n",
      "        [26.8366, 22.2145, 22.7904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.5429, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6980,  26.7217, -22.8795],\n",
      "        [-26.1347,  26.9363, -23.0264],\n",
      "        [-25.5060,  26.5140, -22.9775],\n",
      "        [-26.1208,  27.4082, -23.1525],\n",
      "        [-25.9655,  27.1908, -23.0268],\n",
      "        [-25.7458,  26.8071, -22.8269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1488,  22.4322,  23.0317, -25.6980,  26.7217, -22.8795],\n",
      "        [ 27.2130,  22.2297,  22.9208, -26.1347,  26.9363, -23.0264],\n",
      "        [ 27.6046,  22.5642,  23.1979, -25.5060,  26.5140, -22.9775],\n",
      "        [ 26.7700,  22.2297,  22.9352, -26.1208,  27.4082, -23.1525],\n",
      "        [ 27.2987,  22.2461,  23.1269, -25.9655,  27.1908, -23.0268],\n",
      "        [ 26.8366,  22.2145,  22.7904, -25.7458,  26.8071, -22.8269]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.970481872558594\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2522, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5493, 22.2876, 22.8182],\n",
      "        [26.8696, 22.2670, 23.0849],\n",
      "        [26.9480, 21.9382, 22.8115],\n",
      "        [27.1446, 22.4179, 23.0039],\n",
      "        [27.0435, 22.4037, 22.9924],\n",
      "        [27.1899, 22.3900, 22.9023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.9657, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8897,  27.4551, -22.7946],\n",
      "        [-26.0014,  27.1302, -23.1892],\n",
      "        [-25.8930,  26.8400, -22.8727],\n",
      "        [-26.2742,  27.2366, -23.2277],\n",
      "        [-25.9833,  27.3585, -23.4832],\n",
      "        [-26.2315,  27.6528, -23.3895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5493,  22.2876,  22.8182, -25.8897,  27.4551, -22.7946],\n",
      "        [ 26.8696,  22.2670,  23.0849, -26.0014,  27.1302, -23.1892],\n",
      "        [ 26.9480,  21.9382,  22.8115, -25.8930,  26.8400, -22.8727],\n",
      "        [ 27.1446,  22.4179,  23.0039, -26.2742,  27.2366, -23.2277],\n",
      "        [ 27.0435,  22.4037,  22.9924, -25.9833,  27.3585, -23.4832],\n",
      "        [ 27.1899,  22.3900,  22.9023, -26.2315,  27.6528, -23.3895]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.955976963043213\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7360, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1173, 22.1202, 22.8602],\n",
      "        [27.0034, 22.1088, 22.9624],\n",
      "        [27.5096, 22.6960, 23.0120],\n",
      "        [26.8037, 21.9716, 22.8679],\n",
      "        [27.1741, 22.1933, 22.8967],\n",
      "        [26.9799, 22.2472, 22.9442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.6926, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8900,  26.9736, -22.9544],\n",
      "        [-25.9567,  27.0578, -22.4300],\n",
      "        [-26.1457,  27.0051, -22.9098],\n",
      "        [-26.0725,  27.7613, -23.3185],\n",
      "        [-25.6568,  27.1111, -22.8391],\n",
      "        [-26.2782,  27.0499, -23.2285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1173,  22.1202,  22.8602, -25.8900,  26.9736, -22.9544],\n",
      "        [ 27.0034,  22.1088,  22.9624, -25.9567,  27.0578, -22.4300],\n",
      "        [ 27.5096,  22.6960,  23.0120, -26.1457,  27.0051, -22.9098],\n",
      "        [ 26.8037,  21.9716,  22.8679, -26.0725,  27.7613, -23.3185],\n",
      "        [ 27.1741,  22.1933,  22.8967, -25.6568,  27.1111, -22.8391],\n",
      "        [ 26.9799,  22.2472,  22.9442, -26.2782,  27.0499, -23.2285]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.971819877624512\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2183, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0541, 22.4842, 22.9479],\n",
      "        [26.8944, 22.7153, 23.2554],\n",
      "        [26.8130, 22.3353, 23.1320],\n",
      "        [27.3407, 22.6193, 23.1386],\n",
      "        [26.7388, 22.0362, 23.0661],\n",
      "        [27.3435, 22.6024, 23.2259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1915, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0170,  27.2188, -23.1957],\n",
      "        [-25.8063,  27.0332, -23.2796],\n",
      "        [-25.9294,  26.9392, -23.0965],\n",
      "        [-25.8962,  27.3852, -22.8256],\n",
      "        [-25.4516,  26.6115, -22.4829],\n",
      "        [-25.6421,  27.2938, -23.0747]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0541,  22.4842,  22.9479, -26.0170,  27.2188, -23.1957],\n",
      "        [ 26.8944,  22.7153,  23.2554, -25.8063,  27.0332, -23.2796],\n",
      "        [ 26.8130,  22.3353,  23.1320, -25.9294,  26.9392, -23.0965],\n",
      "        [ 27.3407,  22.6193,  23.1386, -25.8962,  27.3852, -22.8256],\n",
      "        [ 26.7388,  22.0362,  23.0661, -25.4516,  26.6115, -22.4829],\n",
      "        [ 27.3435,  22.6024,  23.2259, -25.6421,  27.2938, -23.0747]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.008389949798584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6317, 22.6779, 23.4866],\n",
      "        [27.2591, 22.3057, 22.9746],\n",
      "        [26.7695, 21.6364, 22.6716],\n",
      "        [26.8386, 22.0036, 22.7510],\n",
      "        [26.5950, 22.4256, 23.1444],\n",
      "        [27.4356, 22.5594, 23.4694]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6036, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1726,  27.1771, -22.8120],\n",
      "        [-25.9363,  26.8964, -22.8617],\n",
      "        [-26.3970,  27.4612, -23.7953],\n",
      "        [-25.9175,  27.0650, -22.9973],\n",
      "        [-25.8062,  27.6250, -23.4865],\n",
      "        [-26.7765,  27.5570, -23.4285]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6317,  22.6779,  23.4866, -26.1726,  27.1771, -22.8120],\n",
      "        [ 27.2591,  22.3057,  22.9746, -25.9363,  26.8964, -22.8617],\n",
      "        [ 26.7695,  21.6364,  22.6716, -26.3970,  27.4612, -23.7953],\n",
      "        [ 26.8386,  22.0036,  22.7510, -25.9175,  27.0650, -22.9973],\n",
      "        [ 26.5950,  22.4256,  23.1444, -25.8062,  27.6250, -23.4865],\n",
      "        [ 27.4356,  22.5594,  23.4694, -26.7765,  27.5570, -23.4285]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.066802024841309\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3541, 22.7346, 23.5259],\n",
      "        [27.2286, 22.4161, 23.3476],\n",
      "        [26.2764, 22.1375, 22.7845],\n",
      "        [27.5040, 22.5688, 23.2468],\n",
      "        [26.5666, 21.8225, 22.6394],\n",
      "        [26.9567, 22.2520, 22.9251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8021, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5376,  27.5885, -23.6084],\n",
      "        [-25.5552,  26.5091, -23.1741],\n",
      "        [-26.0407,  27.4063, -23.1254],\n",
      "        [-25.9758,  26.9896, -23.0515],\n",
      "        [-25.9987,  27.4324, -23.2397],\n",
      "        [-25.5045,  26.6649, -22.9917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3541,  22.7346,  23.5259, -26.5376,  27.5885, -23.6084],\n",
      "        [ 27.2286,  22.4161,  23.3476, -25.5552,  26.5091, -23.1741],\n",
      "        [ 26.2764,  22.1375,  22.7845, -26.0407,  27.4063, -23.1254],\n",
      "        [ 27.5040,  22.5688,  23.2468, -25.9758,  26.9896, -23.0515],\n",
      "        [ 26.5666,  21.8225,  22.6394, -25.9987,  27.4324, -23.2397],\n",
      "        [ 26.9567,  22.2520,  22.9251, -25.5045,  26.6649, -22.9917]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.109506607055664\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9490, 22.1298, 23.2048],\n",
      "        [27.0562, 22.6444, 22.6425],\n",
      "        [27.6949, 22.4928, 23.0996],\n",
      "        [27.1524, 21.9664, 22.8908],\n",
      "        [26.7006, 22.6172, 22.6837],\n",
      "        [26.7491, 22.0531, 23.1256]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.0398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8099,  27.0157, -22.9982],\n",
      "        [-25.7552,  26.9831, -23.1290],\n",
      "        [-25.4960,  26.9731, -22.5271],\n",
      "        [-25.9624,  26.9249, -23.4819],\n",
      "        [-26.4237,  27.4665, -23.2859],\n",
      "        [-25.9621,  27.0756, -23.1963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9490,  22.1298,  23.2048, -25.8099,  27.0157, -22.9982],\n",
      "        [ 27.0562,  22.6444,  22.6425, -25.7552,  26.9831, -23.1290],\n",
      "        [ 27.6949,  22.4928,  23.0996, -25.4960,  26.9731, -22.5271],\n",
      "        [ 27.1524,  21.9664,  22.8908, -25.9624,  26.9249, -23.4819],\n",
      "        [ 26.7006,  22.6172,  22.6837, -26.4237,  27.4665, -23.2859],\n",
      "        [ 26.7491,  22.0531,  23.1256, -25.9621,  27.0756, -23.1963]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.986721515655518\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3702, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5887, 22.2316, 22.8771],\n",
      "        [27.4263, 22.7081, 23.3686],\n",
      "        [27.3332, 22.6263, 23.5051],\n",
      "        [27.7814, 22.9226, 23.5739],\n",
      "        [27.3063, 22.4953, 23.4139],\n",
      "        [26.8468, 22.3838, 23.3985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.9157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8404,  27.4576, -23.1028],\n",
      "        [-26.3279,  27.2408, -23.0033],\n",
      "        [-26.0747,  27.5512, -23.2498],\n",
      "        [-25.9020,  27.5078, -23.2754],\n",
      "        [-25.2358,  26.5458, -22.2942],\n",
      "        [-26.5098,  27.6942, -23.5978]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5887,  22.2316,  22.8771, -25.8404,  27.4576, -23.1028],\n",
      "        [ 27.4263,  22.7081,  23.3686, -26.3279,  27.2408, -23.0033],\n",
      "        [ 27.3332,  22.6263,  23.5051, -26.0747,  27.5512, -23.2498],\n",
      "        [ 27.7814,  22.9226,  23.5739, -25.9020,  27.5078, -23.2754],\n",
      "        [ 27.3063,  22.4953,  23.4139, -25.2358,  26.5458, -22.2942],\n",
      "        [ 26.8468,  22.3838,  23.3985, -26.5098,  27.6942, -23.5978]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-5.977970600128174\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3007, 22.4974, 23.1833],\n",
      "        [27.1114, 22.5019, 23.6089],\n",
      "        [27.1791, 22.2340, 23.0737],\n",
      "        [26.8294, 22.4098, 22.9085],\n",
      "        [27.5536, 22.4882, 23.1034],\n",
      "        [27.2212, 22.5904, 23.3991]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.4565, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8398,  27.3126, -23.1776],\n",
      "        [-25.6393,  26.3916, -22.7164],\n",
      "        [-25.9404,  27.3445, -23.0802],\n",
      "        [-26.1168,  27.6141, -23.4450],\n",
      "        [-25.5650,  26.5928, -22.5342],\n",
      "        [-25.8935,  27.3485, -23.2719]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3007,  22.4974,  23.1833, -25.8398,  27.3126, -23.1776],\n",
      "        [ 27.1114,  22.5019,  23.6089, -25.6393,  26.3916, -22.7164],\n",
      "        [ 27.1791,  22.2340,  23.0737, -25.9404,  27.3445, -23.0802],\n",
      "        [ 26.8294,  22.4098,  22.9085, -26.1168,  27.6141, -23.4450],\n",
      "        [ 27.5536,  22.4882,  23.1034, -25.5650,  26.5928, -22.5342],\n",
      "        [ 27.2212,  22.5904,  23.3991, -25.8935,  27.3485, -23.2719]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.039865493774414\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2705, 22.7234, 23.2363],\n",
      "        [26.6306, 22.2833, 22.3247],\n",
      "        [27.4007, 22.7643, 23.3855],\n",
      "        [27.1363, 22.5299, 23.1216],\n",
      "        [26.7975, 22.3647, 23.4713],\n",
      "        [27.2976, 22.3182, 23.1340]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5059,  27.7582, -23.6217],\n",
      "        [-26.4015,  27.6869, -23.4928],\n",
      "        [-25.6813,  27.0702, -23.0524],\n",
      "        [-25.8289,  26.8755, -22.7555],\n",
      "        [-26.0517,  27.2509, -23.0718],\n",
      "        [-26.2553,  27.0933, -22.8723]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2705,  22.7234,  23.2363, -26.5059,  27.7582, -23.6217],\n",
      "        [ 26.6306,  22.2833,  22.3247, -26.4015,  27.6869, -23.4928],\n",
      "        [ 27.4007,  22.7643,  23.3855, -25.6813,  27.0702, -23.0524],\n",
      "        [ 27.1363,  22.5299,  23.1216, -25.8289,  26.8755, -22.7555],\n",
      "        [ 26.7975,  22.3647,  23.4713, -26.0517,  27.2509, -23.0718],\n",
      "        [ 27.2976,  22.3182,  23.1340, -26.2553,  27.0933, -22.8723]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.104495048522949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2673, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6427, 22.8413, 23.6445],\n",
      "        [26.7296, 22.4289, 23.0732],\n",
      "        [26.7484, 22.3200, 23.3278],\n",
      "        [27.1078, 22.5003, 23.3273],\n",
      "        [27.2495, 22.0899, 22.8748],\n",
      "        [27.3782, 22.8771, 23.2021]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.5946, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8447,  26.9631, -22.6294],\n",
      "        [-26.5352,  27.6056, -23.3732],\n",
      "        [-26.2675,  27.3613, -23.7679],\n",
      "        [-26.0791,  27.0649, -22.9119],\n",
      "        [-26.1565,  27.6922, -23.3282],\n",
      "        [-25.8360,  27.4745, -23.0223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6427,  22.8413,  23.6445, -25.8447,  26.9631, -22.6294],\n",
      "        [ 26.7296,  22.4289,  23.0732, -26.5352,  27.6056, -23.3732],\n",
      "        [ 26.7484,  22.3200,  23.3278, -26.2675,  27.3613, -23.7679],\n",
      "        [ 27.1078,  22.5003,  23.3273, -26.0791,  27.0649, -22.9119],\n",
      "        [ 27.2495,  22.0899,  22.8748, -26.1565,  27.6922, -23.3282],\n",
      "        [ 27.3782,  22.8771,  23.2021, -25.8360,  27.4745, -23.0223]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.067262649536133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5273, 22.4109, 23.4780],\n",
      "        [26.9198, 22.3892, 23.2064],\n",
      "        [27.3548, 22.8432, 23.5041],\n",
      "        [26.4491, 22.0445, 22.8230],\n",
      "        [27.1611, 22.5741, 23.0393],\n",
      "        [27.3020, 22.9807, 23.2984]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.3120, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.6646,  26.9895, -22.8810],\n",
      "        [-25.5717,  27.0236, -23.1915],\n",
      "        [-26.1558,  27.5773, -23.4876],\n",
      "        [-25.9556,  26.9657, -22.7407],\n",
      "        [-26.5257,  27.8378, -23.3798],\n",
      "        [-25.8775,  27.1398, -23.2161]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5273,  22.4109,  23.4780, -25.6646,  26.9895, -22.8810],\n",
      "        [ 26.9198,  22.3892,  23.2064, -25.5717,  27.0236, -23.1915],\n",
      "        [ 27.3548,  22.8432,  23.5041, -26.1558,  27.5773, -23.4876],\n",
      "        [ 26.4491,  22.0445,  22.8230, -25.9556,  26.9657, -22.7407],\n",
      "        [ 27.1611,  22.5741,  23.0393, -26.5257,  27.8378, -23.3798],\n",
      "        [ 27.3020,  22.9807,  23.2984, -25.8775,  27.1398, -23.2161]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.041593551635742\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5547, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3066, 22.3910, 23.6287],\n",
      "        [27.3807, 22.7978, 23.6753],\n",
      "        [26.7575, 22.4330, 23.0691],\n",
      "        [27.3013, 22.3223, 22.9594],\n",
      "        [26.9596, 22.4079, 23.2858],\n",
      "        [26.9658, 22.4732, 23.2513]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.5594, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.5070,  26.5832, -22.8806],\n",
      "        [-26.1326,  27.5761, -23.0507],\n",
      "        [-26.1416,  27.7984, -23.3505],\n",
      "        [-26.2336,  27.7665, -23.2819],\n",
      "        [-25.9465,  27.3718, -23.1093],\n",
      "        [-26.1157,  27.4417, -23.2439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3066,  22.3910,  23.6287, -25.5070,  26.5832, -22.8806],\n",
      "        [ 27.3807,  22.7978,  23.6753, -26.1326,  27.5761, -23.0507],\n",
      "        [ 26.7575,  22.4330,  23.0691, -26.1416,  27.7984, -23.3505],\n",
      "        [ 27.3013,  22.3223,  22.9594, -26.2336,  27.7665, -23.2819],\n",
      "        [ 26.9596,  22.4079,  23.2858, -25.9465,  27.3718, -23.1093],\n",
      "        [ 26.9658,  22.4732,  23.2513, -26.1157,  27.4417, -23.2439]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.016760349273682\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7161, 23.2228, 23.7554],\n",
      "        [26.6695, 22.3852, 23.1352],\n",
      "        [27.1258, 22.5217, 23.3040],\n",
      "        [27.3264, 22.8189, 22.8488],\n",
      "        [26.6585, 22.0629, 22.8267],\n",
      "        [27.3904, 22.2705, 23.4748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.9870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0606,  27.2712, -23.3485],\n",
      "        [-26.2070,  27.1687, -23.4045],\n",
      "        [-26.3638,  27.8791, -23.5402],\n",
      "        [-26.2095,  27.4893, -23.2756],\n",
      "        [-25.5369,  26.7530, -22.6641],\n",
      "        [-26.5162,  27.3396, -23.3879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7161,  23.2228,  23.7554, -26.0606,  27.2712, -23.3485],\n",
      "        [ 26.6695,  22.3852,  23.1352, -26.2070,  27.1687, -23.4045],\n",
      "        [ 27.1258,  22.5217,  23.3040, -26.3638,  27.8791, -23.5402],\n",
      "        [ 27.3264,  22.8189,  22.8488, -26.2095,  27.4893, -23.2756],\n",
      "        [ 26.6585,  22.0629,  22.8267, -25.5369,  26.7530, -22.6641],\n",
      "        [ 27.3904,  22.2705,  23.4748, -26.5162,  27.3396, -23.3879]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.137003421783447\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7887, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2212, 22.6176, 23.3516],\n",
      "        [27.4089, 22.3826, 23.2144],\n",
      "        [27.1675, 22.4545, 23.3276],\n",
      "        [27.4020, 22.2882, 23.4797],\n",
      "        [27.9072, 22.7425, 23.5223],\n",
      "        [27.5082, 22.9004, 23.3763]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.6925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1780,  27.3185, -23.3045],\n",
      "        [-26.2279,  27.3319, -22.8857],\n",
      "        [-25.5787,  26.5376, -22.7806],\n",
      "        [-26.0284,  27.4959, -23.2012],\n",
      "        [-26.1611,  27.5755, -23.4026],\n",
      "        [-25.7793,  26.7213, -22.5599]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2212,  22.6176,  23.3516, -26.1780,  27.3185, -23.3045],\n",
      "        [ 27.4089,  22.3826,  23.2144, -26.2279,  27.3319, -22.8857],\n",
      "        [ 27.1675,  22.4545,  23.3276, -25.5787,  26.5376, -22.7806],\n",
      "        [ 27.4020,  22.2882,  23.4797, -26.0284,  27.4959, -23.2012],\n",
      "        [ 27.9072,  22.7425,  23.5223, -26.1611,  27.5755, -23.4026],\n",
      "        [ 27.5082,  22.9004,  23.3763, -25.7793,  26.7213, -22.5599]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.075437545776367\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5242, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3369, 22.5430, 23.0545],\n",
      "        [27.4034, 22.3356, 23.3181],\n",
      "        [27.2700, 22.5467, 23.3373],\n",
      "        [27.5034, 22.9512, 23.5953],\n",
      "        [26.6709, 22.0176, 22.7563],\n",
      "        [26.5954, 22.0971, 22.6951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8500,  27.1128, -23.3209],\n",
      "        [-25.9561,  27.0309, -23.2197],\n",
      "        [-25.7340,  27.1392, -22.8415],\n",
      "        [-26.0170,  27.0849, -23.3563],\n",
      "        [-25.6293,  26.9362, -22.4876],\n",
      "        [-26.4386,  27.9277, -23.7258]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3369,  22.5430,  23.0545, -25.8500,  27.1128, -23.3209],\n",
      "        [ 27.4034,  22.3356,  23.3181, -25.9561,  27.0309, -23.2197],\n",
      "        [ 27.2700,  22.5467,  23.3373, -25.7340,  27.1392, -22.8415],\n",
      "        [ 27.5034,  22.9512,  23.5953, -26.0170,  27.0849, -23.3563],\n",
      "        [ 26.6709,  22.0176,  22.7563, -25.6293,  26.9362, -22.4876],\n",
      "        [ 26.5954,  22.0971,  22.6951, -26.4386,  27.9277, -23.7258]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.048244476318359\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7629, 22.5860, 23.6132],\n",
      "        [27.1365, 22.8262, 23.0594],\n",
      "        [27.3309, 22.4647, 23.3561],\n",
      "        [27.1300, 22.4557, 23.3623],\n",
      "        [27.8742, 23.1412, 23.7119],\n",
      "        [26.8620, 22.5980, 23.4559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6084, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4961,  27.5876, -23.3666],\n",
      "        [-26.2127,  27.3365, -22.9968],\n",
      "        [-25.8627,  27.5753, -23.2754],\n",
      "        [-25.2581,  27.0051, -22.6801],\n",
      "        [-26.0074,  27.1120, -23.0542],\n",
      "        [-25.8351,  27.0631, -23.0932]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7629,  22.5860,  23.6132, -26.4961,  27.5876, -23.3666],\n",
      "        [ 27.1365,  22.8262,  23.0594, -26.2127,  27.3365, -22.9968],\n",
      "        [ 27.3309,  22.4647,  23.3561, -25.8627,  27.5753, -23.2754],\n",
      "        [ 27.1300,  22.4557,  23.3623, -25.2581,  27.0051, -22.6801],\n",
      "        [ 27.8742,  23.1412,  23.7119, -26.0074,  27.1120, -23.0542],\n",
      "        [ 26.8620,  22.5980,  23.4559, -25.8351,  27.0631, -23.0932]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1437225341796875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5796, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2013, 22.7184, 23.4610],\n",
      "        [27.2212, 22.4290, 23.2278],\n",
      "        [27.3837, 22.6611, 23.4622],\n",
      "        [26.7635, 22.1466, 22.6092],\n",
      "        [27.7561, 22.2662, 23.1568],\n",
      "        [27.4139, 22.6894, 23.4300]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.1813, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8504,  27.2820, -22.9174],\n",
      "        [-26.2754,  27.3639, -23.2722],\n",
      "        [-25.6679,  26.9105, -22.6700],\n",
      "        [-25.7439,  26.6916, -22.7422],\n",
      "        [-25.9484,  27.5020, -23.5946],\n",
      "        [-26.1918,  27.6598, -23.3419]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2013,  22.7184,  23.4610, -25.8504,  27.2820, -22.9174],\n",
      "        [ 27.2212,  22.4290,  23.2278, -26.2754,  27.3639, -23.2722],\n",
      "        [ 27.3837,  22.6611,  23.4622, -25.6679,  26.9105, -22.6700],\n",
      "        [ 26.7635,  22.1466,  22.6092, -25.7439,  26.6916, -22.7422],\n",
      "        [ 27.7561,  22.2662,  23.1568, -25.9484,  27.5020, -23.5946],\n",
      "        [ 27.4139,  22.6894,  23.4300, -26.1918,  27.6598, -23.3419]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.064328193664551\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6832, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.5125, 22.4854, 22.8193],\n",
      "        [27.4016, 22.9710, 23.6225],\n",
      "        [26.8365, 22.4603, 23.1338],\n",
      "        [27.2039, 22.7887, 23.2839],\n",
      "        [27.1346, 22.7839, 23.5815],\n",
      "        [27.3726, 23.0943, 23.4919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.6606, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2792,  27.1050, -23.4913],\n",
      "        [-26.0888,  26.9215, -23.0066],\n",
      "        [-26.2588,  27.4898, -23.2238],\n",
      "        [-26.3944,  27.5571, -23.2953],\n",
      "        [-26.1871,  26.9830, -22.5281],\n",
      "        [-26.5607,  27.6867, -23.2816]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.5125,  22.4854,  22.8193, -26.2792,  27.1050, -23.4913],\n",
      "        [ 27.4016,  22.9710,  23.6225, -26.0888,  26.9215, -23.0066],\n",
      "        [ 26.8365,  22.4603,  23.1338, -26.2588,  27.4898, -23.2238],\n",
      "        [ 27.2039,  22.7887,  23.2839, -26.3944,  27.5571, -23.2953],\n",
      "        [ 27.1346,  22.7839,  23.5815, -26.1871,  26.9830, -22.5281],\n",
      "        [ 27.3726,  23.0943,  23.4919, -26.5607,  27.6867, -23.2816]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.015510559082031\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8057, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6815, 23.0580, 23.8839],\n",
      "        [27.1356, 22.7877, 23.5242],\n",
      "        [27.1160, 22.4718, 22.9476],\n",
      "        [26.9733, 22.4537, 23.2598],\n",
      "        [26.8732, 22.2245, 22.8665],\n",
      "        [27.5012, 23.1089, 23.3388]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3773,  27.4395, -23.2250],\n",
      "        [-25.6828,  26.9909, -22.8437],\n",
      "        [-25.9585,  27.2811, -23.0273],\n",
      "        [-25.9385,  27.3092, -23.3182],\n",
      "        [-26.0514,  27.1474, -23.2694],\n",
      "        [-26.1277,  27.5738, -23.2169]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6815,  23.0580,  23.8839, -26.3773,  27.4395, -23.2250],\n",
      "        [ 27.1356,  22.7877,  23.5242, -25.6828,  26.9909, -22.8437],\n",
      "        [ 27.1160,  22.4718,  22.9476, -25.9585,  27.2811, -23.0273],\n",
      "        [ 26.9733,  22.4537,  23.2598, -25.9385,  27.3092, -23.3182],\n",
      "        [ 26.8732,  22.2245,  22.8665, -26.0514,  27.1474, -23.2694],\n",
      "        [ 27.5012,  23.1089,  23.3388, -26.1277,  27.5738, -23.2169]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.160897254943848\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7467, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6833, 22.5791, 23.4564],\n",
      "        [26.8082, 22.3966, 22.7580],\n",
      "        [27.9635, 23.0534, 23.8348],\n",
      "        [27.4175, 22.9815, 23.7461],\n",
      "        [26.6738, 22.2437, 22.9066],\n",
      "        [27.2739, 22.9747, 23.5604]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.8339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.7602,  27.4132, -23.0832],\n",
      "        [-26.5626,  27.7185, -23.5690],\n",
      "        [-26.7734,  27.8150, -23.7456],\n",
      "        [-26.5661,  27.8265, -23.4809],\n",
      "        [-25.9504,  27.3694, -22.9902],\n",
      "        [-26.0781,  27.2829, -23.3168]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6833,  22.5791,  23.4564, -25.7602,  27.4132, -23.0832],\n",
      "        [ 26.8082,  22.3966,  22.7580, -26.5626,  27.7185, -23.5690],\n",
      "        [ 27.9635,  23.0534,  23.8348, -26.7734,  27.8150, -23.7456],\n",
      "        [ 27.4175,  22.9815,  23.7461, -26.5661,  27.8265, -23.4809],\n",
      "        [ 26.6738,  22.2437,  22.9066, -25.9504,  27.3694, -22.9902],\n",
      "        [ 27.2739,  22.9747,  23.5604, -26.0781,  27.2829, -23.3168]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.098271369934082\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.6918, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4817, 22.8057, 23.2879],\n",
      "        [26.8455, 22.5179, 22.7663],\n",
      "        [26.7975, 22.3927, 22.9917],\n",
      "        [27.2450, 22.4542, 23.1549],\n",
      "        [27.0949, 22.8533, 23.0894],\n",
      "        [27.0695, 22.3756, 23.4616]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.3452, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2960,  27.7139, -23.3409],\n",
      "        [-25.6340,  27.1869, -22.5373],\n",
      "        [-26.5371,  27.6066, -23.5833],\n",
      "        [-26.0978,  27.2563, -23.1566],\n",
      "        [-26.4184,  27.4057, -23.0426],\n",
      "        [-26.5060,  27.6947, -23.7216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4817,  22.8057,  23.2879, -26.2960,  27.7139, -23.3409],\n",
      "        [ 26.8455,  22.5179,  22.7663, -25.6340,  27.1869, -22.5373],\n",
      "        [ 26.7975,  22.3927,  22.9917, -26.5371,  27.6066, -23.5833],\n",
      "        [ 27.2450,  22.4542,  23.1549, -26.0978,  27.2563, -23.1566],\n",
      "        [ 27.0949,  22.8533,  23.0894, -26.4184,  27.4057, -23.0426],\n",
      "        [ 27.0695,  22.3756,  23.4616, -26.5060,  27.6947, -23.7216]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1276350021362305\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2412, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7388, 23.1295, 23.5075],\n",
      "        [27.0176, 22.4292, 23.3868],\n",
      "        [27.2432, 22.4121, 23.1875],\n",
      "        [26.9793, 22.6713, 23.2866],\n",
      "        [27.3841, 22.7786, 23.2085],\n",
      "        [27.4227, 22.3980, 23.6378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.5924, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0988,  27.6022, -23.1529],\n",
      "        [-25.8522,  27.2035, -23.0232],\n",
      "        [-26.5901,  27.4815, -23.2881],\n",
      "        [-26.4696,  27.5148, -23.3766],\n",
      "        [-26.4317,  27.4011, -23.4768],\n",
      "        [-25.5455,  27.1352, -22.9386]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7388,  23.1295,  23.5075, -26.0988,  27.6022, -23.1529],\n",
      "        [ 27.0176,  22.4292,  23.3868, -25.8522,  27.2035, -23.0232],\n",
      "        [ 27.2432,  22.4121,  23.1875, -26.5901,  27.4815, -23.2881],\n",
      "        [ 26.9793,  22.6713,  23.2866, -26.4696,  27.5148, -23.3766],\n",
      "        [ 27.3841,  22.7786,  23.2085, -26.4317,  27.4011, -23.4768],\n",
      "        [ 27.4227,  22.3980,  23.6378, -25.5455,  27.1352, -22.9386]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.148987770080566\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.7948, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.0746, 21.4854, 22.0258],\n",
      "        [27.0967, 22.2808, 22.7772],\n",
      "        [27.0631, 22.4285, 22.7542],\n",
      "        [27.1010, 22.8252, 23.1007],\n",
      "        [27.8969, 22.7304, 23.3196],\n",
      "        [27.5592, 22.9755, 23.7841]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.6463, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8290,  26.7779, -23.0655],\n",
      "        [-26.2163,  27.4524, -23.1040],\n",
      "        [-25.7542,  27.0584, -22.6692],\n",
      "        [-25.9216,  26.9502, -23.0327],\n",
      "        [-25.8208,  26.8815, -23.0562],\n",
      "        [-25.8957,  27.0114, -23.0253]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.0746,  21.4854,  22.0258, -25.8290,  26.7779, -23.0655],\n",
      "        [ 27.0967,  22.2808,  22.7772, -26.2163,  27.4524, -23.1040],\n",
      "        [ 27.0631,  22.4285,  22.7542, -25.7542,  27.0584, -22.6692],\n",
      "        [ 27.1010,  22.8252,  23.1007, -25.9216,  26.9502, -23.0327],\n",
      "        [ 27.8969,  22.7304,  23.3196, -25.8208,  26.8815, -23.0562],\n",
      "        [ 27.5592,  22.9755,  23.7841, -25.8957,  27.0114, -23.0253]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.88611364364624\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0767, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6710, 22.7483, 23.6041],\n",
      "        [27.1229, 22.2461, 22.9387],\n",
      "        [27.4517, 22.7482, 22.8941],\n",
      "        [27.5771, 22.8407, 23.8848],\n",
      "        [26.5376, 21.8367, 23.1672],\n",
      "        [26.5303, 22.0282, 22.8727]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.0317, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3216,  27.6012, -23.5375],\n",
      "        [-25.7207,  26.6322, -23.2202],\n",
      "        [-26.1509,  27.5988, -23.2866],\n",
      "        [-25.9341,  27.4955, -22.8990],\n",
      "        [-26.0185,  27.6052, -23.5212],\n",
      "        [-26.3357,  27.5603, -23.1598]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6710,  22.7483,  23.6041, -26.3216,  27.6012, -23.5375],\n",
      "        [ 27.1229,  22.2461,  22.9387, -25.7207,  26.6322, -23.2202],\n",
      "        [ 27.4517,  22.7482,  22.8941, -26.1509,  27.5988, -23.2866],\n",
      "        [ 27.5771,  22.8407,  23.8848, -25.9341,  27.4955, -22.8990],\n",
      "        [ 26.5376,  21.8367,  23.1672, -26.0185,  27.6052, -23.5212],\n",
      "        [ 26.5303,  22.0282,  22.8727, -26.3357,  27.5603, -23.1598]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.159330368041992\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5889, 23.1858, 23.5538],\n",
      "        [27.8523, 23.2765, 23.8902],\n",
      "        [27.6347, 22.8185, 23.6889],\n",
      "        [27.1360, 22.6634, 23.1216],\n",
      "        [26.7860, 22.3297, 22.8411],\n",
      "        [26.6140, 22.0046, 22.9697]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.9716, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1384,  27.2797, -23.1205],\n",
      "        [-26.4783,  28.0304, -23.5783],\n",
      "        [-26.2328,  27.4064, -23.7736],\n",
      "        [-25.9526,  26.8566, -22.9950],\n",
      "        [-26.0513,  26.9198, -22.7152],\n",
      "        [-26.8485,  27.8031, -23.9105]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5889,  23.1858,  23.5538, -26.1384,  27.2797, -23.1205],\n",
      "        [ 27.8523,  23.2765,  23.8902, -26.4783,  28.0304, -23.5783],\n",
      "        [ 27.6347,  22.8185,  23.6889, -26.2328,  27.4064, -23.7736],\n",
      "        [ 27.1360,  22.6634,  23.1216, -25.9526,  26.8566, -22.9950],\n",
      "        [ 26.7860,  22.3297,  22.8411, -26.0513,  26.9198, -22.7152],\n",
      "        [ 26.6140,  22.0046,  22.9697, -26.8485,  27.8031, -23.9105]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.139070987701416\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.6288, 21.7726, 22.7912],\n",
      "        [27.4519, 22.7678, 23.2428],\n",
      "        [27.3960, 22.7825, 23.2894],\n",
      "        [27.1854, 22.4988, 23.2121],\n",
      "        [27.2471, 23.0605, 23.6644],\n",
      "        [27.4310, 22.8086, 23.5162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.4695, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0732,  27.1949, -22.8186],\n",
      "        [-25.2299,  26.6941, -22.8382],\n",
      "        [-26.1781,  27.8100, -23.3935],\n",
      "        [-26.3765,  27.4314, -23.4696],\n",
      "        [-26.8955,  28.1123, -23.7912],\n",
      "        [-25.1677,  26.6059, -22.6953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.6288,  21.7726,  22.7912, -26.0732,  27.1949, -22.8186],\n",
      "        [ 27.4519,  22.7678,  23.2428, -25.2299,  26.6941, -22.8382],\n",
      "        [ 27.3960,  22.7825,  23.2894, -26.1781,  27.8100, -23.3935],\n",
      "        [ 27.1854,  22.4988,  23.2121, -26.3765,  27.4314, -23.4696],\n",
      "        [ 27.2471,  23.0605,  23.6644, -26.8955,  28.1123, -23.7912],\n",
      "        [ 27.4310,  22.8086,  23.5162, -25.1677,  26.6059, -22.6953]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-5.985936164855957\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4883, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3433, 22.8418, 23.3906],\n",
      "        [27.3184, 23.0704, 23.1059],\n",
      "        [27.6156, 23.1394, 23.7547],\n",
      "        [27.2117, 22.4435, 23.0629],\n",
      "        [27.1179, 22.5680, 23.4744],\n",
      "        [27.8378, 22.4792, 23.4408]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6262,  27.7310, -23.4171],\n",
      "        [-26.1650,  27.6678, -23.4861],\n",
      "        [-26.3503,  27.5886, -23.1493],\n",
      "        [-25.8158,  27.3374, -23.3597],\n",
      "        [-25.9147,  27.6703, -23.2194],\n",
      "        [-26.5176,  27.6038, -23.2872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3433,  22.8418,  23.3906, -26.6262,  27.7310, -23.4171],\n",
      "        [ 27.3184,  23.0704,  23.1059, -26.1650,  27.6678, -23.4861],\n",
      "        [ 27.6156,  23.1394,  23.7547, -26.3503,  27.5886, -23.1493],\n",
      "        [ 27.2117,  22.4435,  23.0629, -25.8158,  27.3374, -23.3597],\n",
      "        [ 27.1179,  22.5680,  23.4744, -25.9147,  27.6703, -23.2194],\n",
      "        [ 27.8378,  22.4792,  23.4408, -26.5176,  27.6038, -23.2872]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.152647018432617\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.4616, 21.9936, 22.3707],\n",
      "        [27.1852, 22.8743, 23.3899],\n",
      "        [27.4819, 22.0393, 23.5487],\n",
      "        [27.1526, 22.6426, 23.1625],\n",
      "        [27.4359, 22.6092, 22.9961],\n",
      "        [27.5518, 22.9489, 23.6370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.5747, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1450,  27.8588, -23.4265],\n",
      "        [-26.2480,  27.6433, -23.2711],\n",
      "        [-26.2217,  27.3502, -23.3060],\n",
      "        [-25.9700,  27.1259, -23.3043],\n",
      "        [-26.5675,  27.6086, -23.4616],\n",
      "        [-26.0464,  26.8386, -23.0836]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.4616,  21.9936,  22.3707, -26.1450,  27.8588, -23.4265],\n",
      "        [ 27.1852,  22.8743,  23.3899, -26.2480,  27.6433, -23.2711],\n",
      "        [ 27.4819,  22.0393,  23.5487, -26.2217,  27.3502, -23.3060],\n",
      "        [ 27.1526,  22.6426,  23.1625, -25.9700,  27.1259, -23.3043],\n",
      "        [ 27.4359,  22.6092,  22.9961, -26.5675,  27.6086, -23.4616],\n",
      "        [ 27.5518,  22.9489,  23.6370, -26.0464,  26.8386, -23.0836]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.014832496643066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7882, 23.6233, 23.8939],\n",
      "        [26.6875, 21.9148, 22.7686],\n",
      "        [27.3591, 22.8166, 23.6807],\n",
      "        [27.2358, 22.7805, 23.0279],\n",
      "        [27.1714, 22.7124, 23.3465],\n",
      "        [27.5678, 22.5968, 23.2874]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(51.6417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9962,  27.1563, -23.0014],\n",
      "        [-26.5010,  28.1963, -23.8091],\n",
      "        [-26.6058,  27.6257, -23.6657],\n",
      "        [-26.5852,  27.5161, -23.7246],\n",
      "        [-25.8165,  26.9764, -22.6660],\n",
      "        [-25.8884,  26.8139, -22.6080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7882,  23.6233,  23.8939, -25.9962,  27.1563, -23.0014],\n",
      "        [ 26.6875,  21.9148,  22.7686, -26.5010,  28.1963, -23.8091],\n",
      "        [ 27.3591,  22.8166,  23.6807, -26.6058,  27.6257, -23.6657],\n",
      "        [ 27.2358,  22.7805,  23.0279, -26.5852,  27.5161, -23.7246],\n",
      "        [ 27.1714,  22.7124,  23.3465, -25.8165,  26.9764, -22.6660],\n",
      "        [ 27.5678,  22.5968,  23.2874, -25.8884,  26.8139, -22.6080]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.176547050476074\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7624, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5725, 23.1952, 23.2377],\n",
      "        [27.2358, 22.0873, 23.2919],\n",
      "        [27.3716, 22.6503, 23.5418],\n",
      "        [27.0911, 22.5724, 23.6983],\n",
      "        [27.0092, 22.6286, 23.1321],\n",
      "        [26.4927, 22.1910, 22.7790]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.4231, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2683,  27.6596, -23.1718],\n",
      "        [-26.4045,  27.4022, -23.3198],\n",
      "        [-25.7672,  27.4368, -23.0566],\n",
      "        [-25.9876,  27.1437, -23.1695],\n",
      "        [-26.7107,  27.5836, -23.5730],\n",
      "        [-26.4727,  27.5458, -23.4832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5725,  23.1952,  23.2377, -26.2683,  27.6596, -23.1718],\n",
      "        [ 27.2358,  22.0873,  23.2919, -26.4045,  27.4022, -23.3198],\n",
      "        [ 27.3716,  22.6503,  23.5418, -25.7672,  27.4368, -23.0566],\n",
      "        [ 27.0911,  22.5724,  23.6983, -25.9876,  27.1437, -23.1695],\n",
      "        [ 27.0092,  22.6286,  23.1321, -26.7107,  27.5836, -23.5730],\n",
      "        [ 26.4927,  22.1910,  22.7790, -26.4727,  27.5458, -23.4832]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.15403938293457\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4202, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5185, 22.8253, 23.3154],\n",
      "        [27.7693, 23.1231, 23.4872],\n",
      "        [26.4590, 22.1313, 23.0607],\n",
      "        [27.0184, 21.9831, 23.3576],\n",
      "        [27.4517, 22.8101, 23.4626],\n",
      "        [27.8564, 23.1608, 23.7952]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1658, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9973,  27.3449, -23.0442],\n",
      "        [-25.7486,  27.0385, -22.7530],\n",
      "        [-26.3728,  27.7938, -23.7669],\n",
      "        [-26.4002,  27.6138, -23.6989],\n",
      "        [-25.4837,  26.9717, -23.3394],\n",
      "        [-26.3755,  27.5091, -23.1757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5185,  22.8253,  23.3154, -25.9973,  27.3449, -23.0442],\n",
      "        [ 27.7693,  23.1231,  23.4872, -25.7486,  27.0385, -22.7530],\n",
      "        [ 26.4590,  22.1313,  23.0607, -26.3728,  27.7938, -23.7669],\n",
      "        [ 27.0184,  21.9831,  23.3576, -26.4002,  27.6138, -23.6989],\n",
      "        [ 27.4517,  22.8101,  23.4626, -25.4837,  26.9717, -23.3394],\n",
      "        [ 27.8564,  23.1608,  23.7952, -26.3755,  27.5091, -23.1757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.1176886558532715\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1104, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8569, 22.8852, 23.6256],\n",
      "        [27.4095, 22.7197, 23.5244],\n",
      "        [27.3186, 22.7403, 23.0547],\n",
      "        [27.2905, 22.9260, 23.7234],\n",
      "        [27.4122, 23.0713, 23.4060],\n",
      "        [27.0778, 22.6856, 23.3657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.1699, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3537,  27.6124, -23.4313],\n",
      "        [-26.3613,  27.9795, -23.4318],\n",
      "        [-26.6876,  27.9808, -23.9181],\n",
      "        [-26.1586,  27.6559, -23.3932],\n",
      "        [-26.4279,  27.6116, -23.3715],\n",
      "        [-26.6013,  27.5551, -23.4399]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8569,  22.8852,  23.6256, -26.3537,  27.6124, -23.4313],\n",
      "        [ 27.4095,  22.7197,  23.5244, -26.3613,  27.9795, -23.4318],\n",
      "        [ 27.3186,  22.7403,  23.0547, -26.6876,  27.9808, -23.9181],\n",
      "        [ 27.2905,  22.9260,  23.7234, -26.1586,  27.6559, -23.3932],\n",
      "        [ 27.4122,  23.0713,  23.4060, -26.4279,  27.6116, -23.3715],\n",
      "        [ 27.0778,  22.6856,  23.3657, -26.6013,  27.5551, -23.4399]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.189779758453369\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1450, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2275, 22.7376, 23.8947],\n",
      "        [28.0222, 23.4131, 24.2780],\n",
      "        [27.1185, 22.7153, 23.3282],\n",
      "        [26.9564, 22.7666, 23.4000],\n",
      "        [27.3326, 22.6839, 23.4189],\n",
      "        [27.1331, 22.7813, 23.8050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1262, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7373,  28.0356, -24.0281],\n",
      "        [-25.6899,  27.1975, -23.0770],\n",
      "        [-26.0063,  27.3240, -23.3207],\n",
      "        [-25.8156,  27.0402, -23.3074],\n",
      "        [-26.2075,  27.8473, -23.4102],\n",
      "        [-26.5429,  27.8818, -23.7475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2275,  22.7376,  23.8947, -26.7373,  28.0356, -24.0281],\n",
      "        [ 28.0222,  23.4131,  24.2780, -25.6899,  27.1975, -23.0770],\n",
      "        [ 27.1185,  22.7153,  23.3282, -26.0063,  27.3240, -23.3207],\n",
      "        [ 26.9564,  22.7666,  23.4000, -25.8156,  27.0402, -23.3074],\n",
      "        [ 27.3326,  22.6839,  23.4189, -26.2075,  27.8473, -23.4102],\n",
      "        [ 27.1331,  22.7813,  23.8050, -26.5429,  27.8818, -23.7475]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.211939811706543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9636, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0502, 22.6388, 23.0419],\n",
      "        [26.9367, 22.3435, 23.1870],\n",
      "        [26.8142, 22.0534, 22.9655],\n",
      "        [27.9175, 23.1729, 24.0198],\n",
      "        [27.8707, 22.6824, 23.7715],\n",
      "        [27.1053, 22.4632, 23.3415]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.9282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.9589,  27.4135, -23.4900],\n",
      "        [-26.6346,  27.4591, -23.3436],\n",
      "        [-26.1769,  27.4238, -23.4173],\n",
      "        [-26.5981,  28.0661, -23.6482],\n",
      "        [-26.6285,  27.7484, -23.4240],\n",
      "        [-26.1908,  27.7903, -23.3387]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0502,  22.6388,  23.0419, -25.9589,  27.4135, -23.4900],\n",
      "        [ 26.9367,  22.3435,  23.1870, -26.6346,  27.4591, -23.3436],\n",
      "        [ 26.8142,  22.0534,  22.9655, -26.1769,  27.4238, -23.4173],\n",
      "        [ 27.9175,  23.1729,  24.0198, -26.5981,  28.0661, -23.6482],\n",
      "        [ 27.8707,  22.6824,  23.7715, -26.6285,  27.7484, -23.4240],\n",
      "        [ 27.1053,  22.4632,  23.3415, -26.1908,  27.7903, -23.3387]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.092594146728516\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6501, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4171, 23.2701, 23.7487],\n",
      "        [27.5104, 22.8521, 23.3554],\n",
      "        [26.8110, 22.8752, 23.1451],\n",
      "        [27.9294, 22.8830, 23.7112],\n",
      "        [27.1408, 22.5815, 23.5337],\n",
      "        [27.1147, 22.6318, 23.0893]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.2197, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3250,  27.6975, -23.5252],\n",
      "        [-26.3653,  27.9479, -23.6609],\n",
      "        [-26.6648,  27.4763, -23.3382],\n",
      "        [-26.5471,  27.9430, -23.5955],\n",
      "        [-26.3389,  27.5047, -23.5711],\n",
      "        [-26.6087,  28.1994, -24.0239]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4171,  23.2701,  23.7487, -26.3250,  27.6975, -23.5252],\n",
      "        [ 27.5104,  22.8521,  23.3554, -26.3653,  27.9479, -23.6609],\n",
      "        [ 26.8110,  22.8752,  23.1451, -26.6648,  27.4763, -23.3382],\n",
      "        [ 27.9294,  22.8830,  23.7112, -26.5471,  27.9430, -23.5955],\n",
      "        [ 27.1408,  22.5815,  23.5337, -26.3389,  27.5047, -23.5711],\n",
      "        [ 27.1147,  22.6318,  23.0893, -26.6087,  28.1994, -24.0239]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.196203231811523\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5116, 22.6734, 23.1723],\n",
      "        [26.7587, 22.4472, 23.3508],\n",
      "        [27.3162, 22.7384, 23.5643],\n",
      "        [27.5019, 23.0437, 23.8092],\n",
      "        [27.4517, 23.0750, 23.6244],\n",
      "        [28.1809, 23.4399, 23.7466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.0579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3263,  27.1254, -23.1464],\n",
      "        [-26.7272,  27.6175, -23.4770],\n",
      "        [-26.2204,  27.4211, -23.3774],\n",
      "        [-26.4258,  28.0435, -23.7511],\n",
      "        [-26.7001,  27.7779, -23.5554],\n",
      "        [-26.4596,  27.5398, -23.1951]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5116,  22.6734,  23.1723, -26.3263,  27.1254, -23.1464],\n",
      "        [ 26.7587,  22.4472,  23.3508, -26.7272,  27.6175, -23.4770],\n",
      "        [ 27.3162,  22.7384,  23.5643, -26.2204,  27.4211, -23.3774],\n",
      "        [ 27.5019,  23.0437,  23.8092, -26.4258,  28.0435, -23.7511],\n",
      "        [ 27.4517,  23.0750,  23.6244, -26.7001,  27.7779, -23.5554],\n",
      "        [ 28.1809,  23.4399,  23.7466, -26.4596,  27.5398, -23.1951]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1213483810424805\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6336, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9176, 22.9919, 23.3565],\n",
      "        [28.1203, 22.7788, 23.8149],\n",
      "        [27.2766, 22.8112, 23.6018],\n",
      "        [27.2912, 22.9522, 23.0021],\n",
      "        [27.2502, 22.5827, 23.6235],\n",
      "        [27.3897, 23.0853, 23.6971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1511, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1574,  27.8134, -23.4284],\n",
      "        [-26.1319,  27.5618, -23.4811],\n",
      "        [-26.0877,  27.2444, -23.3159],\n",
      "        [-26.3340,  27.4333, -23.4436],\n",
      "        [-25.9266,  27.5633, -23.1752],\n",
      "        [-25.8687,  27.3230, -23.4886]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9176,  22.9919,  23.3565, -26.1574,  27.8134, -23.4284],\n",
      "        [ 28.1203,  22.7788,  23.8149, -26.1319,  27.5618, -23.4811],\n",
      "        [ 27.2766,  22.8112,  23.6018, -26.0877,  27.2444, -23.3159],\n",
      "        [ 27.2912,  22.9522,  23.0021, -26.3340,  27.4333, -23.4436],\n",
      "        [ 27.2502,  22.5827,  23.6235, -25.9266,  27.5633, -23.1752],\n",
      "        [ 27.3897,  23.0853,  23.6971, -25.8687,  27.3230, -23.4886]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.194766044616699\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3126, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6356, 22.3978, 23.6778],\n",
      "        [27.9983, 23.1302, 23.5076],\n",
      "        [27.4272, 22.6662, 23.1100],\n",
      "        [27.4112, 22.6844, 23.1870],\n",
      "        [28.1685, 23.0941, 23.6827],\n",
      "        [27.1155, 22.6402, 23.3068]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.3598, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3630,  27.4774, -23.5106],\n",
      "        [-26.0251,  27.1577, -23.1435],\n",
      "        [-25.8222,  27.2988, -23.4302],\n",
      "        [-26.0114,  27.5778, -23.4194],\n",
      "        [-25.6115,  26.6392, -22.1571],\n",
      "        [-26.1538,  27.5639, -23.2101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6356,  22.3978,  23.6778, -26.3630,  27.4774, -23.5106],\n",
      "        [ 27.9983,  23.1302,  23.5076, -26.0251,  27.1577, -23.1435],\n",
      "        [ 27.4272,  22.6662,  23.1100, -25.8222,  27.2988, -23.4302],\n",
      "        [ 27.4112,  22.6844,  23.1870, -26.0114,  27.5778, -23.4194],\n",
      "        [ 28.1685,  23.0941,  23.6827, -25.6115,  26.6392, -22.1571],\n",
      "        [ 27.1155,  22.6402,  23.3068, -26.1538,  27.5639, -23.2101]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.17158842086792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1638, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3456, 22.8211, 23.5235],\n",
      "        [27.6142, 22.9838, 23.4739],\n",
      "        [27.8822, 23.0019, 23.6817],\n",
      "        [27.1688, 22.6876, 23.6833],\n",
      "        [27.8539, 22.9566, 23.6684],\n",
      "        [27.3699, 22.9273, 23.5250]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6055, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4348,  27.5573, -23.4710],\n",
      "        [-25.1784,  26.4372, -21.9111],\n",
      "        [-26.2395,  27.6983, -23.3221],\n",
      "        [-26.5611,  27.5184, -23.4399],\n",
      "        [-26.2611,  27.1005, -23.2299],\n",
      "        [-26.1402,  27.6564, -23.6030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3456,  22.8211,  23.5235, -26.4348,  27.5573, -23.4710],\n",
      "        [ 27.6142,  22.9838,  23.4739, -25.1784,  26.4372, -21.9111],\n",
      "        [ 27.8822,  23.0019,  23.6817, -26.2395,  27.6983, -23.3221],\n",
      "        [ 27.1688,  22.6876,  23.6833, -26.5611,  27.5184, -23.4399],\n",
      "        [ 27.8539,  22.9566,  23.6684, -26.2611,  27.1005, -23.2299],\n",
      "        [ 27.3699,  22.9273,  23.5250, -26.1402,  27.6564, -23.6030]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.17008113861084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4589, 22.8930, 23.6443],\n",
      "        [28.1330, 23.4809, 24.2571],\n",
      "        [27.3644, 23.0646, 23.6650],\n",
      "        [27.3763, 22.9026, 23.3642],\n",
      "        [27.2540, 23.2568, 23.3200],\n",
      "        [27.0201, 22.8230, 23.3147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.2538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4267,  27.5257, -23.5662],\n",
      "        [-25.8157,  26.8598, -22.8333],\n",
      "        [-26.4424,  27.4637, -23.1618],\n",
      "        [-25.8285,  27.0186, -22.9304],\n",
      "        [-26.3445,  27.9049, -23.5719],\n",
      "        [-26.5279,  27.7888, -23.6429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4589,  22.8930,  23.6443, -26.4267,  27.5257, -23.5662],\n",
      "        [ 28.1330,  23.4809,  24.2571, -25.8157,  26.8598, -22.8333],\n",
      "        [ 27.3644,  23.0646,  23.6650, -26.4424,  27.4637, -23.1618],\n",
      "        [ 27.3763,  22.9026,  23.3642, -25.8285,  27.0186, -22.9304],\n",
      "        [ 27.2540,  23.2568,  23.3200, -26.3445,  27.9049, -23.5719],\n",
      "        [ 27.0201,  22.8230,  23.3147, -26.5279,  27.7888, -23.6429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1880669593811035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5373, 22.7277, 23.4909],\n",
      "        [27.1748, 22.6171, 23.6543],\n",
      "        [27.8421, 22.9336, 23.3783],\n",
      "        [27.5170, 22.8515, 23.5464],\n",
      "        [26.7753, 22.2440, 23.1834],\n",
      "        [27.4936, 22.2947, 23.3203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.2221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3390,  27.6698, -23.6624],\n",
      "        [-26.6675,  27.2589, -23.5028],\n",
      "        [-25.9270,  27.4650, -23.4612],\n",
      "        [-26.5523,  27.7319, -23.5828],\n",
      "        [-26.8642,  27.9347, -23.9246],\n",
      "        [-27.1755,  27.7554, -23.7719]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5373,  22.7277,  23.4909, -26.3390,  27.6698, -23.6624],\n",
      "        [ 27.1748,  22.6171,  23.6543, -26.6675,  27.2589, -23.5028],\n",
      "        [ 27.8421,  22.9336,  23.3783, -25.9270,  27.4650, -23.4612],\n",
      "        [ 27.5170,  22.8515,  23.5464, -26.5523,  27.7319, -23.5828],\n",
      "        [ 26.7753,  22.2440,  23.1834, -26.8642,  27.9347, -23.9246],\n",
      "        [ 27.4936,  22.2947,  23.3203, -27.1755,  27.7554, -23.7719]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1863579750061035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.1919, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8529, 22.5957, 23.8933],\n",
      "        [27.4499, 23.0102, 23.5572],\n",
      "        [27.5442, 22.8918, 23.3835],\n",
      "        [27.2617, 22.2662, 22.9164],\n",
      "        [27.2254, 22.4571, 23.2726],\n",
      "        [27.4525, 22.8690, 23.4112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.1594, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3436,  26.7232, -22.7131],\n",
      "        [-26.2019,  27.4759, -23.3414],\n",
      "        [-26.3219,  27.7520, -23.6065],\n",
      "        [-26.2115,  27.4113, -23.4243],\n",
      "        [-25.8184,  26.7810, -22.9070],\n",
      "        [-26.2642,  27.5056, -23.4080]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8529,  22.5957,  23.8933, -25.3436,  26.7232, -22.7131],\n",
      "        [ 27.4499,  23.0102,  23.5572, -26.2019,  27.4759, -23.3414],\n",
      "        [ 27.5442,  22.8918,  23.3835, -26.3219,  27.7520, -23.6065],\n",
      "        [ 27.2617,  22.2662,  22.9164, -26.2115,  27.4113, -23.4243],\n",
      "        [ 27.2254,  22.4571,  23.2726, -25.8184,  26.7810, -22.9070],\n",
      "        [ 27.4525,  22.8690,  23.4112, -26.2642,  27.5056, -23.4080]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1194305419921875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6984, 22.4461, 23.2225],\n",
      "        [27.4317, 23.0520, 23.6568],\n",
      "        [27.7124, 23.3416, 23.3787],\n",
      "        [27.0550, 22.2953, 22.9214],\n",
      "        [27.3555, 23.1072, 23.5241],\n",
      "        [27.2916, 22.3605, 23.4024]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.5953, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3704,  27.5612, -23.4130],\n",
      "        [-26.4376,  27.9256, -23.5132],\n",
      "        [-26.7190,  28.1627, -23.8078],\n",
      "        [-26.6517,  27.7818, -23.7960],\n",
      "        [-26.3839,  27.7177, -24.0810],\n",
      "        [-26.5763,  27.1632, -23.1303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6984,  22.4461,  23.2225, -26.3704,  27.5612, -23.4130],\n",
      "        [ 27.4317,  23.0520,  23.6568, -26.4376,  27.9256, -23.5132],\n",
      "        [ 27.7124,  23.3416,  23.3787, -26.7190,  28.1627, -23.8078],\n",
      "        [ 27.0550,  22.2953,  22.9214, -26.6517,  27.7818, -23.7960],\n",
      "        [ 27.3555,  23.1072,  23.5241, -26.3839,  27.7177, -24.0810],\n",
      "        [ 27.2916,  22.3605,  23.4024, -26.5763,  27.1632, -23.1303]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.165699481964111\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2350, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0576, 22.4629, 23.1129],\n",
      "        [27.6817, 22.8219, 23.2925],\n",
      "        [27.1766, 22.1570, 23.4333],\n",
      "        [27.5064, 22.6434, 23.5274],\n",
      "        [27.3430, 22.6924, 23.1359],\n",
      "        [27.7011, 23.0167, 23.5109]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.7352, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8670,  27.6970, -23.2366],\n",
      "        [-26.3772,  27.4803, -23.3044],\n",
      "        [-26.2057,  27.3553, -23.0991],\n",
      "        [-26.5107,  27.7430, -23.6002],\n",
      "        [-26.2169,  27.6252, -23.3377],\n",
      "        [-25.8108,  27.5221, -23.3429]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0576,  22.4629,  23.1129, -25.8670,  27.6970, -23.2366],\n",
      "        [ 27.6817,  22.8219,  23.2925, -26.3772,  27.4803, -23.3044],\n",
      "        [ 27.1766,  22.1570,  23.4333, -26.2057,  27.3553, -23.0991],\n",
      "        [ 27.5064,  22.6434,  23.5274, -26.5107,  27.7430, -23.6002],\n",
      "        [ 27.3430,  22.6924,  23.1359, -26.2169,  27.6252, -23.3377],\n",
      "        [ 27.7011,  23.0167,  23.5109, -25.8108,  27.5221, -23.3429]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.109167098999023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8185, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4598, 22.6816, 23.3397],\n",
      "        [27.4627, 22.6199, 23.5476],\n",
      "        [27.4247, 22.5030, 23.0742],\n",
      "        [27.1385, 22.7546, 23.1145],\n",
      "        [27.0445, 22.7275, 23.1029],\n",
      "        [27.2749, 22.9456, 23.2453]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(17.3840, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2884,  27.4815, -23.4627],\n",
      "        [-26.4743,  27.7407, -23.4420],\n",
      "        [-26.6030,  27.7468, -23.9622],\n",
      "        [-26.0584,  27.3490, -23.1849],\n",
      "        [-25.8439,  27.5604, -23.3235],\n",
      "        [-26.5668,  27.6268, -23.8348]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4598,  22.6816,  23.3397, -26.2884,  27.4815, -23.4627],\n",
      "        [ 27.4627,  22.6199,  23.5476, -26.4743,  27.7407, -23.4420],\n",
      "        [ 27.4247,  22.5030,  23.0742, -26.6030,  27.7468, -23.9622],\n",
      "        [ 27.1385,  22.7546,  23.1145, -26.0584,  27.3490, -23.1849],\n",
      "        [ 27.0445,  22.7275,  23.1029, -25.8439,  27.5604, -23.3235],\n",
      "        [ 27.2749,  22.9456,  23.2453, -26.5668,  27.6268, -23.8348]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.166041851043701\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7552, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2426, 23.6927, 23.7922],\n",
      "        [27.4205, 22.9926, 23.4027],\n",
      "        [26.5738, 21.9467, 22.5927],\n",
      "        [27.4416, 22.6987, 23.9417],\n",
      "        [26.9029, 22.0140, 22.9220],\n",
      "        [27.9788, 23.3621, 23.9973]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6435, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4313,  27.5459, -23.3674],\n",
      "        [-26.8146,  27.9617, -24.0855],\n",
      "        [-26.0694,  27.7605, -23.4994],\n",
      "        [-26.3692,  27.3675, -22.9825],\n",
      "        [-26.3501,  27.6568, -23.5073],\n",
      "        [-26.5605,  27.4266, -23.8175]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2426,  23.6927,  23.7922, -26.4313,  27.5459, -23.3674],\n",
      "        [ 27.4205,  22.9926,  23.4027, -26.8146,  27.9617, -24.0855],\n",
      "        [ 26.5738,  21.9467,  22.5927, -26.0694,  27.7605, -23.4994],\n",
      "        [ 27.4416,  22.6987,  23.9417, -26.3692,  27.3675, -22.9825],\n",
      "        [ 26.9029,  22.0140,  22.9220, -26.3501,  27.6568, -23.5073],\n",
      "        [ 27.9788,  23.3621,  23.9973, -26.5605,  27.4266, -23.8175]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.27471923828125\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5259, 23.0643, 23.4572],\n",
      "        [26.8235, 22.0972, 22.7383],\n",
      "        [27.9474, 23.1572, 23.6855],\n",
      "        [27.4565, 22.9190, 23.3847],\n",
      "        [27.9060, 23.6316, 23.8154],\n",
      "        [27.3843, 22.6175, 23.2563]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9426, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3863,  28.0895, -23.7880],\n",
      "        [-26.8210,  27.4644, -23.5758],\n",
      "        [-26.3305,  27.5518, -23.5047],\n",
      "        [-25.8734,  27.1390, -23.4056],\n",
      "        [-27.0258,  28.1918, -23.8425],\n",
      "        [-26.6553,  27.3314, -23.5298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5259,  23.0643,  23.4572, -26.3863,  28.0895, -23.7880],\n",
      "        [ 26.8235,  22.0972,  22.7383, -26.8210,  27.4644, -23.5758],\n",
      "        [ 27.9474,  23.1572,  23.6855, -26.3305,  27.5518, -23.5047],\n",
      "        [ 27.4565,  22.9190,  23.3847, -25.8734,  27.1390, -23.4056],\n",
      "        [ 27.9060,  23.6316,  23.8154, -27.0258,  28.1918, -23.8425],\n",
      "        [ 27.3843,  22.6175,  23.2563, -26.6553,  27.3314, -23.5298]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.2298054695129395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0235, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1621, 22.2055, 23.2461],\n",
      "        [27.8227, 22.6352, 23.3840],\n",
      "        [26.8297, 22.5576, 22.9767],\n",
      "        [26.8277, 22.3567, 23.6175],\n",
      "        [27.5360, 23.5227, 24.0711],\n",
      "        [27.9850, 23.0291, 23.6532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.4114, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7433,  27.6457, -23.9902],\n",
      "        [-26.7838,  27.9895, -23.5735],\n",
      "        [-26.1375,  27.5747, -23.4653],\n",
      "        [-26.8820,  28.0840, -23.9263],\n",
      "        [-27.2099,  28.1766, -24.0236],\n",
      "        [-26.2309,  27.5657, -23.5645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1621,  22.2055,  23.2461, -26.7433,  27.6457, -23.9902],\n",
      "        [ 27.8227,  22.6352,  23.3840, -26.7838,  27.9895, -23.5735],\n",
      "        [ 26.8297,  22.5576,  22.9767, -26.1375,  27.5747, -23.4653],\n",
      "        [ 26.8277,  22.3567,  23.6175, -26.8820,  28.0840, -23.9263],\n",
      "        [ 27.5360,  23.5227,  24.0711, -27.2099,  28.1766, -24.0236],\n",
      "        [ 27.9850,  23.0291,  23.6532, -26.2309,  27.5657, -23.5645]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.172138690948486\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4268, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0185, 23.4479, 23.9293],\n",
      "        [27.1760, 22.6931, 23.6069],\n",
      "        [27.3878, 22.7105, 23.2634],\n",
      "        [27.2622, 22.7019, 23.6407],\n",
      "        [27.5312, 22.8473, 23.7290],\n",
      "        [27.7845, 23.3806, 24.2406]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.3246, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3406,  27.5746, -23.8032],\n",
      "        [-25.8696,  27.3640, -23.4712],\n",
      "        [-26.8311,  27.7135, -23.5403],\n",
      "        [-26.0404,  27.6546, -23.5613],\n",
      "        [-25.7963,  27.1495, -22.8215],\n",
      "        [-26.0212,  27.4104, -23.1489]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0185,  23.4479,  23.9293, -26.3406,  27.5746, -23.8032],\n",
      "        [ 27.1760,  22.6931,  23.6069, -25.8696,  27.3640, -23.4712],\n",
      "        [ 27.3878,  22.7105,  23.2634, -26.8311,  27.7135, -23.5403],\n",
      "        [ 27.2622,  22.7019,  23.6407, -26.0404,  27.6546, -23.5613],\n",
      "        [ 27.5312,  22.8473,  23.7290, -25.7963,  27.1495, -22.8215],\n",
      "        [ 27.7845,  23.3806,  24.2406, -26.0212,  27.4104, -23.1489]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.27678918838501\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3519, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9866, 22.9679, 24.2114],\n",
      "        [26.8639, 22.5546, 23.0234],\n",
      "        [27.6726, 22.9712, 23.5104],\n",
      "        [27.2913, 22.7419, 23.2410],\n",
      "        [27.2009, 22.7613, 22.9837],\n",
      "        [27.5481, 22.8430, 23.0568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.9145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1199,  27.1100, -23.6551],\n",
      "        [-25.9378,  27.3025, -23.0866],\n",
      "        [-26.4051,  27.5418, -23.6690],\n",
      "        [-26.6998,  28.2411, -23.5978],\n",
      "        [-26.5902,  27.6803, -23.7582],\n",
      "        [-26.2426,  27.1515, -23.3881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9866,  22.9679,  24.2114, -26.1199,  27.1100, -23.6551],\n",
      "        [ 26.8639,  22.5546,  23.0234, -25.9378,  27.3025, -23.0866],\n",
      "        [ 27.6726,  22.9712,  23.5104, -26.4051,  27.5418, -23.6690],\n",
      "        [ 27.2913,  22.7419,  23.2410, -26.6998,  28.2411, -23.5978],\n",
      "        [ 27.2009,  22.7613,  22.9837, -26.5902,  27.6803, -23.7582],\n",
      "        [ 27.5481,  22.8430,  23.0568, -26.2426,  27.1515, -23.3881]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.242525577545166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2572, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.0175, 22.6292, 23.0827],\n",
      "        [27.1501, 22.9088, 23.0929],\n",
      "        [27.5918, 22.7234, 23.5685],\n",
      "        [27.8792, 22.8733, 23.9485],\n",
      "        [27.3335, 22.6056, 23.7013],\n",
      "        [27.5658, 22.5422, 23.5905]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(43.8252, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4187,  27.6287, -23.7253],\n",
      "        [-25.0373,  26.6793, -22.5674],\n",
      "        [-26.8587,  27.8104, -23.7794],\n",
      "        [-26.0080,  27.7561, -23.5179],\n",
      "        [-26.5139,  27.7894, -23.7610],\n",
      "        [-26.7198,  28.0488, -23.8964]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.0175,  22.6292,  23.0827, -26.4187,  27.6287, -23.7253],\n",
      "        [ 27.1501,  22.9088,  23.0929, -25.0373,  26.6793, -22.5674],\n",
      "        [ 27.5918,  22.7234,  23.5685, -26.8587,  27.8104, -23.7794],\n",
      "        [ 27.8792,  22.8733,  23.9485, -26.0080,  27.7561, -23.5179],\n",
      "        [ 27.3335,  22.6056,  23.7013, -26.5139,  27.7894, -23.7610],\n",
      "        [ 27.5658,  22.5422,  23.5905, -26.7198,  28.0488, -23.8964]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.157407283782959\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2265, 22.8406, 23.6473],\n",
      "        [26.9140, 22.2874, 23.1571],\n",
      "        [27.7425, 23.3942, 23.4628],\n",
      "        [27.6479, 22.9386, 23.5646],\n",
      "        [27.9085, 23.0998, 23.5200],\n",
      "        [27.6550, 22.8147, 23.6412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.1050, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6517,  27.5931, -23.6434],\n",
      "        [-27.0686,  28.1347, -24.0831],\n",
      "        [-26.5228,  27.5495, -23.6009],\n",
      "        [-26.4775,  27.4812, -23.7053],\n",
      "        [-25.9876,  27.1636, -23.1991],\n",
      "        [-26.2962,  27.0944, -23.3389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2265,  22.8406,  23.6473, -26.6517,  27.5931, -23.6434],\n",
      "        [ 26.9140,  22.2874,  23.1571, -27.0686,  28.1347, -24.0831],\n",
      "        [ 27.7425,  23.3942,  23.4628, -26.5228,  27.5495, -23.6009],\n",
      "        [ 27.6479,  22.9386,  23.5646, -26.4775,  27.4812, -23.7053],\n",
      "        [ 27.9085,  23.0998,  23.5200, -25.9876,  27.1636, -23.1991],\n",
      "        [ 27.6550,  22.8147,  23.6412, -26.2962,  27.0944, -23.3389]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.210026264190674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2512, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6923, 22.4967, 23.5407],\n",
      "        [28.1254, 23.4198, 23.8052],\n",
      "        [27.6331, 23.3063, 23.7137],\n",
      "        [27.4608, 22.7379, 23.4864],\n",
      "        [27.7966, 22.9738, 23.6521],\n",
      "        [27.8513, 23.3157, 24.0314]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.9167, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5241,  27.6655, -23.6777],\n",
      "        [-26.0694,  27.3887, -23.2835],\n",
      "        [-26.3774,  27.5254, -23.6431],\n",
      "        [-26.6691,  27.9046, -23.6273],\n",
      "        [-26.2120,  27.2597, -23.6801],\n",
      "        [-26.3463,  27.0299, -23.3919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6923,  22.4967,  23.5407, -26.5241,  27.6655, -23.6777],\n",
      "        [ 28.1254,  23.4198,  23.8052, -26.0694,  27.3887, -23.2835],\n",
      "        [ 27.6331,  23.3063,  23.7137, -26.3774,  27.5254, -23.6431],\n",
      "        [ 27.4608,  22.7379,  23.4864, -26.6691,  27.9046, -23.6273],\n",
      "        [ 27.7966,  22.9738,  23.6521, -26.2120,  27.2597, -23.6801],\n",
      "        [ 27.8513,  23.3157,  24.0314, -26.3463,  27.0299, -23.3919]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.219468593597412\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4312, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6729, 23.0040, 23.4080],\n",
      "        [28.0149, 23.1307, 23.9993],\n",
      "        [27.1458, 22.8284, 23.1929],\n",
      "        [27.4059, 23.1420, 23.9571],\n",
      "        [27.1993, 22.6874, 22.9966],\n",
      "        [27.8681, 23.0713, 23.4679]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.0812, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1994,  27.7609, -23.4968],\n",
      "        [-26.4016,  27.3742, -23.4510],\n",
      "        [-26.4215,  27.9312, -23.5806],\n",
      "        [-26.4617,  27.6669, -23.5145],\n",
      "        [-26.5763,  27.4818, -23.5908],\n",
      "        [-27.0037,  27.8603, -24.0724]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6729,  23.0040,  23.4080, -26.1994,  27.7609, -23.4968],\n",
      "        [ 28.0149,  23.1307,  23.9993, -26.4016,  27.3742, -23.4510],\n",
      "        [ 27.1458,  22.8284,  23.1929, -26.4215,  27.9312, -23.5806],\n",
      "        [ 27.4059,  23.1420,  23.9571, -26.4617,  27.6669, -23.5145],\n",
      "        [ 27.1993,  22.6874,  22.9966, -26.5763,  27.4818, -23.5908],\n",
      "        [ 27.8681,  23.0713,  23.4679, -27.0037,  27.8603, -24.0724]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.21915340423584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2447, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8279, 22.1337, 23.3881],\n",
      "        [27.8615, 22.8855, 23.7664],\n",
      "        [27.4803, 23.3233, 24.0934],\n",
      "        [27.5355, 22.5841, 23.6173],\n",
      "        [26.9658, 22.3414, 22.7523],\n",
      "        [28.1115, 23.2274, 24.0196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.2597, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8672,  28.1109, -23.5834],\n",
      "        [-26.0872,  26.7421, -22.7102],\n",
      "        [-26.1454,  27.5633, -23.3324],\n",
      "        [-25.9895,  27.6659, -23.4552],\n",
      "        [-26.1728,  27.7551, -23.3617],\n",
      "        [-26.1717,  27.3726, -23.5442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8279,  22.1337,  23.3881, -26.8672,  28.1109, -23.5834],\n",
      "        [ 27.8615,  22.8855,  23.7664, -26.0872,  26.7421, -22.7102],\n",
      "        [ 27.4803,  23.3233,  24.0934, -26.1454,  27.5633, -23.3324],\n",
      "        [ 27.5355,  22.5841,  23.6173, -25.9895,  27.6659, -23.4552],\n",
      "        [ 26.9658,  22.3414,  22.7523, -26.1728,  27.7551, -23.3617],\n",
      "        [ 28.1115,  23.2274,  24.0196, -26.1717,  27.3726, -23.5442]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.181157112121582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0275, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2009, 23.5237, 23.9993],\n",
      "        [27.2376, 22.8187, 23.0168],\n",
      "        [28.0028, 23.3801, 23.7404],\n",
      "        [27.6002, 22.9206, 23.8901],\n",
      "        [26.9191, 22.4510, 23.7071],\n",
      "        [27.7268, 23.2437, 23.8806]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8492, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0616,  27.4559, -23.2092],\n",
      "        [-26.4098,  27.8207, -23.7245],\n",
      "        [-26.0471,  27.5044, -23.6424],\n",
      "        [-26.5867,  27.5912, -23.8562],\n",
      "        [-26.1155,  27.2829, -23.3496],\n",
      "        [-26.2226,  27.7449, -23.7227]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2009,  23.5237,  23.9993, -26.0616,  27.4559, -23.2092],\n",
      "        [ 27.2376,  22.8187,  23.0168, -26.4098,  27.8207, -23.7245],\n",
      "        [ 28.0028,  23.3801,  23.7404, -26.0471,  27.5044, -23.6424],\n",
      "        [ 27.6002,  22.9206,  23.8901, -26.5867,  27.5912, -23.8562],\n",
      "        [ 26.9191,  22.4510,  23.7071, -26.1155,  27.2829, -23.3496],\n",
      "        [ 27.7268,  23.2437,  23.8806, -26.2226,  27.7449, -23.7227]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.274257659912109\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4999, 22.4083, 23.7499],\n",
      "        [27.6995, 22.5512, 23.8531],\n",
      "        [27.3784, 22.5891, 23.3648],\n",
      "        [27.3838, 22.7046, 23.2154],\n",
      "        [27.2985, 22.7255, 23.4180],\n",
      "        [27.2134, 22.8520, 23.4942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.7238, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.0221,  27.2468, -23.3113],\n",
      "        [-26.9274,  27.9513, -23.6261],\n",
      "        [-26.3481,  27.6938, -23.6944],\n",
      "        [-25.8016,  27.5371, -23.1411],\n",
      "        [-26.5851,  27.7774, -24.0017],\n",
      "        [-26.8216,  28.4316, -24.0716]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4999,  22.4083,  23.7499, -26.0221,  27.2468, -23.3113],\n",
      "        [ 27.6995,  22.5512,  23.8531, -26.9274,  27.9513, -23.6261],\n",
      "        [ 27.3784,  22.5891,  23.3648, -26.3481,  27.6938, -23.6944],\n",
      "        [ 27.3838,  22.7046,  23.2154, -25.8016,  27.5371, -23.1411],\n",
      "        [ 27.2985,  22.7255,  23.4180, -26.5851,  27.7774, -24.0017],\n",
      "        [ 27.2134,  22.8520,  23.4942, -26.8216,  28.4316, -24.0716]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.17793607711792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8215, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7258, 23.1683, 23.6654],\n",
      "        [27.3932, 22.6591, 23.5888],\n",
      "        [27.3490, 23.0681, 23.6187],\n",
      "        [27.2707, 22.6644, 23.9520],\n",
      "        [28.0140, 23.3209, 23.8809],\n",
      "        [27.6462, 23.0945, 23.7207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.5338, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2411,  27.3592, -22.9122],\n",
      "        [-26.0948,  27.5126, -23.1590],\n",
      "        [-26.7793,  28.1658, -23.7288],\n",
      "        [-26.4298,  28.0247, -23.3904],\n",
      "        [-26.7895,  27.3754, -23.6779],\n",
      "        [-26.3320,  27.3141, -23.5094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7258,  23.1683,  23.6654, -26.2411,  27.3592, -22.9122],\n",
      "        [ 27.3932,  22.6591,  23.5888, -26.0948,  27.5126, -23.1590],\n",
      "        [ 27.3490,  23.0681,  23.6187, -26.7793,  28.1658, -23.7288],\n",
      "        [ 27.2707,  22.6644,  23.9520, -26.4298,  28.0247, -23.3904],\n",
      "        [ 28.0140,  23.3209,  23.8809, -26.7895,  27.3754, -23.6779],\n",
      "        [ 27.6462,  23.0945,  23.7207, -26.3320,  27.3141, -23.5094]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.216513633728027\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5475, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5720, 23.2172, 24.1034],\n",
      "        [27.9923, 23.1942, 23.7594],\n",
      "        [27.7641, 23.2005, 23.9189],\n",
      "        [27.3548, 22.4033, 23.0289],\n",
      "        [27.8096, 23.0558, 23.7942],\n",
      "        [27.4906, 22.3424, 23.0634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.1579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8647,  27.7081, -23.9889],\n",
      "        [-26.1586,  27.4023, -23.6020],\n",
      "        [-26.3593,  27.5623, -23.1173],\n",
      "        [-26.0583,  27.3387, -23.3267],\n",
      "        [-27.0624,  28.3425, -24.3422],\n",
      "        [-26.8656,  28.1444, -23.8011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5720,  23.2172,  24.1034, -26.8647,  27.7081, -23.9889],\n",
      "        [ 27.9923,  23.1942,  23.7594, -26.1586,  27.4023, -23.6020],\n",
      "        [ 27.7641,  23.2005,  23.9189, -26.3593,  27.5623, -23.1173],\n",
      "        [ 27.3548,  22.4033,  23.0289, -26.0583,  27.3387, -23.3267],\n",
      "        [ 27.8096,  23.0558,  23.7942, -27.0624,  28.3425, -24.3422],\n",
      "        [ 27.4906,  22.3424,  23.0634, -26.8656,  28.1444, -23.8011]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.301268100738525\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0691, 23.0576, 23.9966],\n",
      "        [27.3224, 22.9875, 23.9131],\n",
      "        [27.3661, 22.4695, 23.3212],\n",
      "        [27.9074, 23.0655, 23.7325],\n",
      "        [27.9604, 23.3913, 24.0860],\n",
      "        [27.7184, 23.4235, 24.0378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9774, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2931,  27.7524, -23.4180],\n",
      "        [-26.5137,  27.6263, -23.5261],\n",
      "        [-26.8604,  27.4683, -23.3742],\n",
      "        [-26.0549,  27.4353, -23.2744],\n",
      "        [-26.5166,  28.0933, -23.5279],\n",
      "        [-26.3655,  27.4045, -23.5177]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0691,  23.0576,  23.9966, -26.2931,  27.7524, -23.4180],\n",
      "        [ 27.3224,  22.9875,  23.9131, -26.5137,  27.6263, -23.5261],\n",
      "        [ 27.3661,  22.4695,  23.3212, -26.8604,  27.4683, -23.3742],\n",
      "        [ 27.9074,  23.0655,  23.7325, -26.0549,  27.4353, -23.2744],\n",
      "        [ 27.9604,  23.3913,  24.0860, -26.5166,  28.0933, -23.5279],\n",
      "        [ 27.7184,  23.4235,  24.0378, -26.3655,  27.4045, -23.5177]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.283609390258789\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4046, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2608, 23.1846, 24.1285],\n",
      "        [27.7358, 22.8413, 24.0284],\n",
      "        [27.5956, 23.0385, 23.7570],\n",
      "        [27.7256, 23.4501, 23.8270],\n",
      "        [27.9489, 23.3200, 23.5938],\n",
      "        [27.4681, 22.9665, 23.4866]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.4111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2212,  27.4442, -23.1950],\n",
      "        [-26.2508,  27.4924, -23.4872],\n",
      "        [-26.3944,  27.8334, -23.6039],\n",
      "        [-26.7635,  28.0451, -23.9484],\n",
      "        [-26.5528,  27.9519, -23.7285],\n",
      "        [-26.8710,  28.1182, -24.0408]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2608,  23.1846,  24.1285, -26.2212,  27.4442, -23.1950],\n",
      "        [ 27.7358,  22.8413,  24.0284, -26.2508,  27.4924, -23.4872],\n",
      "        [ 27.5956,  23.0385,  23.7570, -26.3944,  27.8334, -23.6039],\n",
      "        [ 27.7256,  23.4501,  23.8270, -26.7635,  28.0451, -23.9484],\n",
      "        [ 27.9489,  23.3200,  23.5938, -26.5528,  27.9519, -23.7285],\n",
      "        [ 27.4681,  22.9665,  23.4866, -26.8710,  28.1182, -24.0408]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.286011695861816\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8601, 23.1791, 23.3179],\n",
      "        [27.5948, 22.9829, 23.5426],\n",
      "        [27.2436, 22.6807, 23.2102],\n",
      "        [28.4412, 23.1058, 24.4873],\n",
      "        [27.8812, 23.3441, 23.9136],\n",
      "        [26.9809, 22.5534, 23.4707]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.2061, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2335,  27.6081, -23.2450],\n",
      "        [-26.6217,  27.8664, -23.5349],\n",
      "        [-26.1770,  27.1161, -23.1890],\n",
      "        [-26.9235,  27.8865, -24.1393],\n",
      "        [-26.5423,  27.3962, -23.5124],\n",
      "        [-26.3176,  27.3199, -23.3430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8601,  23.1791,  23.3179, -26.2335,  27.6081, -23.2450],\n",
      "        [ 27.5948,  22.9829,  23.5426, -26.6217,  27.8664, -23.5349],\n",
      "        [ 27.2436,  22.6807,  23.2102, -26.1770,  27.1161, -23.1890],\n",
      "        [ 28.4412,  23.1058,  24.4873, -26.9235,  27.8865, -24.1393],\n",
      "        [ 27.8812,  23.3441,  23.9136, -26.5423,  27.3962, -23.5124],\n",
      "        [ 26.9809,  22.5534,  23.4707, -26.3176,  27.3199, -23.3430]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.235228061676025\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6383, 22.8743, 23.5067],\n",
      "        [27.6610, 22.9252, 23.6490],\n",
      "        [27.9748, 23.5204, 23.7865],\n",
      "        [27.4141, 23.0158, 23.9525],\n",
      "        [27.1845, 22.8251, 23.4760],\n",
      "        [27.2274, 22.5206, 23.4031]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.5078, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6094,  27.7477, -23.7187],\n",
      "        [-25.9072,  27.2854, -23.1464],\n",
      "        [-26.7237,  27.6608, -23.4161],\n",
      "        [-26.3554,  27.9625, -23.8862],\n",
      "        [-26.7646,  28.0776, -23.9046],\n",
      "        [-26.5089,  27.9656, -23.9260]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6383,  22.8743,  23.5067, -26.6094,  27.7477, -23.7187],\n",
      "        [ 27.6610,  22.9252,  23.6490, -25.9072,  27.2854, -23.1464],\n",
      "        [ 27.9748,  23.5204,  23.7865, -26.7237,  27.6608, -23.4161],\n",
      "        [ 27.4141,  23.0158,  23.9525, -26.3554,  27.9625, -23.8862],\n",
      "        [ 27.1845,  22.8251,  23.4760, -26.7646,  28.0776, -23.9046],\n",
      "        [ 27.2274,  22.5206,  23.4031, -26.5089,  27.9656, -23.9260]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.255974769592285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7752, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9744, 23.1957, 24.0536],\n",
      "        [26.9861, 22.5477, 23.8302],\n",
      "        [27.6787, 23.1241, 23.7777],\n",
      "        [27.0863, 22.4413, 23.4994],\n",
      "        [26.8559, 22.5304, 23.2633],\n",
      "        [28.1587, 23.4069, 24.0664]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.7572, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6285,  27.8094, -23.9285],\n",
      "        [-26.5496,  27.7541, -23.4333],\n",
      "        [-26.6943,  28.0691, -23.9767],\n",
      "        [-26.9987,  27.9188, -23.9479],\n",
      "        [-26.8054,  27.9254, -23.4988],\n",
      "        [-27.2053,  28.4881, -24.1504]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9744,  23.1957,  24.0536, -26.6285,  27.8094, -23.9285],\n",
      "        [ 26.9861,  22.5477,  23.8302, -26.5496,  27.7541, -23.4333],\n",
      "        [ 27.6787,  23.1241,  23.7777, -26.6943,  28.0691, -23.9767],\n",
      "        [ 27.0863,  22.4413,  23.4994, -26.9987,  27.9188, -23.9479],\n",
      "        [ 26.8559,  22.5304,  23.2633, -26.8054,  27.9254, -23.4988],\n",
      "        [ 28.1587,  23.4069,  24.0664, -27.2053,  28.4881, -24.1504]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.324031829833984\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1331, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2964, 22.7547, 23.4195],\n",
      "        [28.4035, 23.1277, 23.9482],\n",
      "        [27.4075, 23.2125, 23.9217],\n",
      "        [27.8671, 23.0602, 23.8266],\n",
      "        [27.7536, 23.4633, 23.8627],\n",
      "        [28.3064, 23.4870, 23.9729]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6961, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5053,  27.4876, -23.9608],\n",
      "        [-26.9543,  28.0018, -24.0803],\n",
      "        [-26.9603,  27.7839, -23.7778],\n",
      "        [-27.1175,  28.4953, -24.1367],\n",
      "        [-26.4566,  27.5960, -23.2593],\n",
      "        [-26.4908,  27.2248, -22.6768]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2964,  22.7547,  23.4195, -26.5053,  27.4876, -23.9608],\n",
      "        [ 28.4035,  23.1277,  23.9482, -26.9543,  28.0018, -24.0803],\n",
      "        [ 27.4075,  23.2125,  23.9217, -26.9603,  27.7839, -23.7778],\n",
      "        [ 27.8671,  23.0602,  23.8266, -27.1175,  28.4953, -24.1367],\n",
      "        [ 27.7536,  23.4633,  23.8627, -26.4566,  27.5960, -23.2593],\n",
      "        [ 28.3064,  23.4870,  23.9729, -26.4908,  27.2248, -22.6768]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.225955486297607\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3379, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7846, 23.2354, 23.4885],\n",
      "        [27.6575, 22.9898, 23.3129],\n",
      "        [27.4609, 22.6432, 23.6042],\n",
      "        [27.4602, 22.9330, 23.6853],\n",
      "        [27.6366, 23.0033, 23.1996],\n",
      "        [27.3670, 22.5487, 23.8008]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(34.8305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9428,  27.9737, -24.0495],\n",
      "        [-26.3326,  27.5681, -23.3322],\n",
      "        [-26.8188,  28.2862, -23.9750],\n",
      "        [-26.6784,  28.3743, -24.0326],\n",
      "        [-26.0026,  27.5882, -23.6295],\n",
      "        [-26.5005,  27.6629, -23.9408]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7846,  23.2354,  23.4885, -26.9428,  27.9737, -24.0495],\n",
      "        [ 27.6575,  22.9898,  23.3129, -26.3326,  27.5681, -23.3322],\n",
      "        [ 27.4609,  22.6432,  23.6042, -26.8188,  28.2862, -23.9750],\n",
      "        [ 27.4602,  22.9330,  23.6853, -26.6784,  28.3743, -24.0326],\n",
      "        [ 27.6366,  23.0033,  23.1996, -26.0026,  27.5882, -23.6295],\n",
      "        [ 27.3670,  22.5487,  23.8008, -26.5005,  27.6629, -23.9408]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.313458442687988\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6020, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9738, 23.4603, 24.2840],\n",
      "        [27.6119, 23.0242, 23.8342],\n",
      "        [27.1515, 22.7294, 23.6321],\n",
      "        [26.8337, 22.5841, 22.5400],\n",
      "        [27.5991, 22.7529, 23.3961],\n",
      "        [27.7692, 23.1820, 23.1126]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.7248, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2787,  27.2230, -23.2128],\n",
      "        [-27.1366,  28.3448, -24.1838],\n",
      "        [-26.7386,  27.9922, -23.7123],\n",
      "        [-26.0369,  27.0559, -23.5571],\n",
      "        [-26.5681,  28.2012, -23.7770],\n",
      "        [-25.7951,  27.7281, -23.4665]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9738,  23.4603,  24.2840, -26.2787,  27.2230, -23.2128],\n",
      "        [ 27.6119,  23.0242,  23.8342, -27.1366,  28.3448, -24.1838],\n",
      "        [ 27.1515,  22.7294,  23.6321, -26.7386,  27.9922, -23.7123],\n",
      "        [ 26.8337,  22.5841,  22.5400, -26.0369,  27.0559, -23.5571],\n",
      "        [ 27.5991,  22.7529,  23.3961, -26.5681,  28.2012, -23.7770],\n",
      "        [ 27.7692,  23.1820,  23.1126, -25.7951,  27.7281, -23.4665]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.293581008911133\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3561, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3697, 22.9071, 23.3814],\n",
      "        [27.3086, 22.3815, 23.3001],\n",
      "        [28.0370, 23.4511, 23.9263],\n",
      "        [27.6757, 23.1359, 23.4633],\n",
      "        [27.3128, 22.9131, 23.4579],\n",
      "        [27.1190, 22.0099, 23.2412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.4650,  26.6816, -22.8317],\n",
      "        [-25.7794,  27.3215, -23.0117],\n",
      "        [-26.2348,  27.5352, -23.4545],\n",
      "        [-26.4714,  27.6919, -23.5688],\n",
      "        [-26.2115,  27.7500, -23.4936],\n",
      "        [-27.0635,  28.3361, -24.6462]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3697,  22.9071,  23.3814, -25.4650,  26.6816, -22.8317],\n",
      "        [ 27.3086,  22.3815,  23.3001, -25.7794,  27.3215, -23.0117],\n",
      "        [ 28.0370,  23.4511,  23.9263, -26.2348,  27.5352, -23.4545],\n",
      "        [ 27.6757,  23.1359,  23.4633, -26.4714,  27.6919, -23.5688],\n",
      "        [ 27.3128,  22.9131,  23.4579, -26.2115,  27.7500, -23.4936],\n",
      "        [ 27.1190,  22.0099,  23.2412, -27.0635,  28.3361, -24.6462]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.1364593505859375\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7287, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7947, 22.9146, 23.9572],\n",
      "        [27.8408, 23.3153, 24.3324],\n",
      "        [27.1771, 22.9992, 23.6273],\n",
      "        [27.7663, 23.2208, 23.6619],\n",
      "        [27.4615, 22.6628, 23.2733],\n",
      "        [28.0876, 23.3728, 23.7748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.5904, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7945,  28.1247, -23.7487],\n",
      "        [-26.5127,  27.4836, -23.1069],\n",
      "        [-26.9108,  27.6732, -23.5512],\n",
      "        [-26.1205,  27.2263, -23.4698],\n",
      "        [-26.8649,  27.7142, -23.7485],\n",
      "        [-26.3790,  27.8870, -23.5923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7947,  22.9146,  23.9572, -26.7945,  28.1247, -23.7487],\n",
      "        [ 27.8408,  23.3153,  24.3324, -26.5127,  27.4836, -23.1069],\n",
      "        [ 27.1771,  22.9992,  23.6273, -26.9108,  27.6732, -23.5512],\n",
      "        [ 27.7663,  23.2208,  23.6619, -26.1205,  27.2263, -23.4698],\n",
      "        [ 27.4615,  22.6628,  23.2733, -26.8649,  27.7142, -23.7485],\n",
      "        [ 28.0876,  23.3728,  23.7748, -26.3790,  27.8870, -23.5923]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.321569442749023\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9237, 23.2546, 23.6541],\n",
      "        [28.0669, 23.4558, 24.2567],\n",
      "        [27.5004, 22.6734, 23.7207],\n",
      "        [27.5577, 22.6176, 23.6241],\n",
      "        [26.9092, 22.8765, 23.5605],\n",
      "        [27.5295, 23.0559, 23.7058]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.7528, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.8090,  26.8361, -22.9943],\n",
      "        [-26.7830,  27.6163, -23.7816],\n",
      "        [-26.5365,  27.5784, -23.5786],\n",
      "        [-26.8209,  28.0154, -23.9077],\n",
      "        [-27.0828,  28.3966, -24.0366],\n",
      "        [-26.5766,  27.2094, -23.3664]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9237,  23.2546,  23.6541, -25.8090,  26.8361, -22.9943],\n",
      "        [ 28.0669,  23.4558,  24.2567, -26.7830,  27.6163, -23.7816],\n",
      "        [ 27.5004,  22.6734,  23.7207, -26.5365,  27.5784, -23.5786],\n",
      "        [ 27.5577,  22.6176,  23.6241, -26.8209,  28.0154, -23.9077],\n",
      "        [ 26.9092,  22.8765,  23.5605, -27.0828,  28.3966, -24.0366],\n",
      "        [ 27.5295,  23.0559,  23.7058, -26.5766,  27.2094, -23.3664]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.220545768737793\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1576, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4208, 22.7756, 22.9934],\n",
      "        [27.2795, 22.6643, 23.5463],\n",
      "        [27.4886, 22.9721, 23.2956],\n",
      "        [27.4921, 22.9581, 23.8167],\n",
      "        [27.2346, 22.9950, 23.2743],\n",
      "        [27.6079, 23.1205, 23.5571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.5024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-25.3022,  26.9257, -22.9087],\n",
      "        [-27.0812,  28.2887, -23.8721],\n",
      "        [-26.4815,  27.7225, -23.6097],\n",
      "        [-27.1318,  28.4523, -24.2019],\n",
      "        [-26.8193,  27.9011, -23.7677],\n",
      "        [-26.7016,  28.2066, -24.0363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4208,  22.7756,  22.9934, -25.3022,  26.9257, -22.9087],\n",
      "        [ 27.2795,  22.6643,  23.5463, -27.0812,  28.2887, -23.8721],\n",
      "        [ 27.4886,  22.9721,  23.2956, -26.4815,  27.7225, -23.6097],\n",
      "        [ 27.4921,  22.9581,  23.8167, -27.1318,  28.4523, -24.2019],\n",
      "        [ 27.2346,  22.9950,  23.2743, -26.8193,  27.9011, -23.7677],\n",
      "        [ 27.6079,  23.1205,  23.5571, -26.7016,  28.2066, -24.0363]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.127612113952637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5582, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5381, 22.9571, 24.1686],\n",
      "        [27.4317, 22.6576, 23.7668],\n",
      "        [27.6357, 23.0783, 23.4741],\n",
      "        [27.7695, 23.6364, 23.9045],\n",
      "        [27.9488, 23.3666, 24.2401],\n",
      "        [27.8336, 23.7358, 23.9930]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.0593, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2774,  27.5564, -23.8238],\n",
      "        [-26.5050,  28.0593, -24.0691],\n",
      "        [-26.3809,  27.1581, -23.2770],\n",
      "        [-26.5268,  27.5866, -23.5261],\n",
      "        [-26.9622,  28.5700, -24.1582],\n",
      "        [-26.7494,  27.9457, -24.0329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5381,  22.9571,  24.1686, -26.2774,  27.5564, -23.8238],\n",
      "        [ 27.4317,  22.6576,  23.7668, -26.5050,  28.0593, -24.0691],\n",
      "        [ 27.6357,  23.0783,  23.4741, -26.3809,  27.1581, -23.2770],\n",
      "        [ 27.7695,  23.6364,  23.9045, -26.5268,  27.5866, -23.5261],\n",
      "        [ 27.9488,  23.3666,  24.2401, -26.9622,  28.5700, -24.1582],\n",
      "        [ 27.8336,  23.7358,  23.9930, -26.7494,  27.9457, -24.0329]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.286501884460449\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2760, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0458, 23.4734, 24.3198],\n",
      "        [27.8095, 23.2739, 23.9088],\n",
      "        [27.3886, 22.7592, 23.6559],\n",
      "        [27.8296, 23.2932, 24.1051],\n",
      "        [26.8902, 22.1697, 23.4159],\n",
      "        [27.8053, 23.6652, 23.8483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.8833, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4276,  27.9161, -23.3850],\n",
      "        [-26.7123,  28.0253, -24.1787],\n",
      "        [-26.7762,  28.0553, -23.9487],\n",
      "        [-26.6581,  28.0394, -23.6265],\n",
      "        [-26.5714,  27.3093, -23.8800],\n",
      "        [-26.6083,  27.9806, -24.0293]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0458,  23.4734,  24.3198, -26.4276,  27.9161, -23.3850],\n",
      "        [ 27.8095,  23.2739,  23.9088, -26.7123,  28.0253, -24.1787],\n",
      "        [ 27.3886,  22.7592,  23.6559, -26.7762,  28.0553, -23.9487],\n",
      "        [ 27.8296,  23.2932,  24.1051, -26.6581,  28.0394, -23.6265],\n",
      "        [ 26.8902,  22.1697,  23.4159, -26.5714,  27.3093, -23.8800],\n",
      "        [ 27.8053,  23.6652,  23.8483, -26.6083,  27.9806, -24.0293]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.348987579345703\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0004, 23.5169, 23.8785],\n",
      "        [27.6622, 23.1564, 23.7944],\n",
      "        [27.8986, 23.1338, 24.1102],\n",
      "        [27.7041, 23.2448, 24.2775],\n",
      "        [27.3482, 22.7084, 23.7505],\n",
      "        [28.1206, 23.6601, 24.1310]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.8147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3922,  27.5013, -23.6397],\n",
      "        [-26.8369,  28.1178, -24.0854],\n",
      "        [-26.6339,  27.7720, -23.5421],\n",
      "        [-27.0048,  28.3250, -24.2349],\n",
      "        [-26.0900,  27.0384, -22.9352],\n",
      "        [-26.4937,  27.7332, -23.5661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0004,  23.5169,  23.8785, -26.3922,  27.5013, -23.6397],\n",
      "        [ 27.6622,  23.1564,  23.7944, -26.8369,  28.1178, -24.0854],\n",
      "        [ 27.8986,  23.1338,  24.1102, -26.6339,  27.7720, -23.5421],\n",
      "        [ 27.7041,  23.2448,  24.2775, -27.0048,  28.3250, -24.2349],\n",
      "        [ 27.3482,  22.7084,  23.7505, -26.0900,  27.0384, -22.9352],\n",
      "        [ 28.1206,  23.6601,  24.1310, -26.4937,  27.7332, -23.5661]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.31966495513916\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8669, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2215, 23.4440, 23.6406],\n",
      "        [28.3795, 23.3152, 24.0391],\n",
      "        [27.7664, 23.2178, 23.7625],\n",
      "        [27.8377, 23.0814, 23.5524],\n",
      "        [28.2488, 23.3556, 24.2492],\n",
      "        [27.5207, 22.8124, 23.3046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7363,  27.8927, -23.9787],\n",
      "        [-26.3494,  27.6407, -23.5669],\n",
      "        [-26.0946,  27.5022, -23.7274],\n",
      "        [-26.2775,  27.6558, -23.6906],\n",
      "        [-27.0737,  27.7959, -23.9310],\n",
      "        [-26.3508,  27.8011, -23.4898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2215,  23.4440,  23.6406, -26.7363,  27.8927, -23.9787],\n",
      "        [ 28.3795,  23.3152,  24.0391, -26.3494,  27.6407, -23.5669],\n",
      "        [ 27.7664,  23.2178,  23.7625, -26.0946,  27.5022, -23.7274],\n",
      "        [ 27.8377,  23.0814,  23.5524, -26.2775,  27.6558, -23.6906],\n",
      "        [ 28.2488,  23.3556,  24.2492, -27.0737,  27.7959, -23.9310],\n",
      "        [ 27.5207,  22.8124,  23.3046, -26.3508,  27.8011, -23.4898]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.357998847961426\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2020, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7816, 23.4756, 23.9482],\n",
      "        [27.0846, 22.8739, 23.5815],\n",
      "        [27.7702, 22.9218, 23.2050],\n",
      "        [27.8679, 23.5486, 23.6505],\n",
      "        [27.5764, 22.9923, 24.0323],\n",
      "        [27.5631, 23.4102, 23.7685]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.9817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7662,  27.8237, -23.7507],\n",
      "        [-26.8255,  27.8009, -23.8444],\n",
      "        [-26.4827,  27.7054, -24.0005],\n",
      "        [-26.5125,  27.8533, -23.5824],\n",
      "        [-26.9331,  28.1512, -23.8371],\n",
      "        [-26.4974,  27.5799, -23.4129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7816,  23.4756,  23.9482, -26.7662,  27.8237, -23.7507],\n",
      "        [ 27.0846,  22.8739,  23.5815, -26.8255,  27.8009, -23.8444],\n",
      "        [ 27.7702,  22.9218,  23.2050, -26.4827,  27.7054, -24.0005],\n",
      "        [ 27.8679,  23.5486,  23.6505, -26.5125,  27.8533, -23.5824],\n",
      "        [ 27.5764,  22.9923,  24.0323, -26.9331,  28.1512, -23.8371],\n",
      "        [ 27.5631,  23.4102,  23.7685, -26.4974,  27.5799, -23.4129]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.3425774574279785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7793, 23.3178, 24.1788],\n",
      "        [27.3060, 22.7365, 23.6927],\n",
      "        [28.6899, 23.9034, 24.0160],\n",
      "        [27.3764, 22.6119, 23.5287],\n",
      "        [28.1687, 23.4019, 24.3182],\n",
      "        [27.0110, 22.9779, 23.5969]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.7330, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4828,  27.5354, -23.7873],\n",
      "        [-26.3651,  28.1148, -23.7449],\n",
      "        [-26.5464,  27.3878, -23.7459],\n",
      "        [-27.0980,  28.1790, -24.2982],\n",
      "        [-26.4731,  28.0509, -23.6735],\n",
      "        [-27.4441,  28.6830, -24.4769]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7793,  23.3178,  24.1788, -26.4828,  27.5354, -23.7873],\n",
      "        [ 27.3060,  22.7365,  23.6927, -26.3651,  28.1148, -23.7449],\n",
      "        [ 28.6899,  23.9034,  24.0160, -26.5464,  27.3878, -23.7459],\n",
      "        [ 27.3764,  22.6119,  23.5287, -27.0980,  28.1790, -24.2982],\n",
      "        [ 28.1687,  23.4019,  24.3182, -26.4731,  28.0509, -23.6735],\n",
      "        [ 27.0110,  22.9779,  23.5969, -27.4441,  28.6830, -24.4769]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.329283714294434\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5757, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9964, 23.3392, 24.2490],\n",
      "        [28.0881, 23.7414, 24.0283],\n",
      "        [28.3280, 23.3075, 23.9980],\n",
      "        [28.4283, 23.4054, 24.1047],\n",
      "        [28.4425, 23.4661, 24.2640],\n",
      "        [28.0670, 23.2154, 23.9635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0821, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6668,  28.0153, -24.1771],\n",
      "        [-26.9337,  28.3452, -24.1693],\n",
      "        [-26.5277,  28.0860, -23.5970],\n",
      "        [-26.9045,  28.2033, -24.0735],\n",
      "        [-26.7529,  28.0957, -24.0495],\n",
      "        [-26.5352,  27.7855, -23.4512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9964,  23.3392,  24.2490, -26.6668,  28.0153, -24.1771],\n",
      "        [ 28.0881,  23.7414,  24.0283, -26.9337,  28.3452, -24.1693],\n",
      "        [ 28.3280,  23.3075,  23.9980, -26.5277,  28.0860, -23.5970],\n",
      "        [ 28.4283,  23.4054,  24.1047, -26.9045,  28.2033, -24.0735],\n",
      "        [ 28.4425,  23.4661,  24.2640, -26.7529,  28.0957, -24.0495],\n",
      "        [ 28.0670,  23.2154,  23.9635, -26.5352,  27.7855, -23.4512]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.384765148162842\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0598, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8274, 23.0007, 23.8304],\n",
      "        [27.4580, 23.3039, 23.6575],\n",
      "        [28.3049, 23.6108, 24.2098],\n",
      "        [27.8746, 23.3763, 23.6779],\n",
      "        [27.6914, 23.0848, 23.6126],\n",
      "        [27.7049, 23.0925, 23.6055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.6159, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6167,  27.9014, -23.6816],\n",
      "        [-26.8967,  28.0077, -23.6086],\n",
      "        [-26.7858,  27.8863, -23.7221],\n",
      "        [-26.6016,  28.0157, -23.9744],\n",
      "        [-26.0711,  27.2358, -22.7408],\n",
      "        [-25.9556,  27.1958, -23.3641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8274,  23.0007,  23.8304, -26.6167,  27.9014, -23.6816],\n",
      "        [ 27.4580,  23.3039,  23.6575, -26.8967,  28.0077, -23.6086],\n",
      "        [ 28.3049,  23.6108,  24.2098, -26.7858,  27.8863, -23.7221],\n",
      "        [ 27.8746,  23.3763,  23.6779, -26.6016,  28.0157, -23.9744],\n",
      "        [ 27.6914,  23.0848,  23.6126, -26.0711,  27.2358, -22.7408],\n",
      "        [ 27.7049,  23.0925,  23.6055, -25.9556,  27.1958, -23.3641]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.32328462600708\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7337, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2728, 22.4385, 23.0376],\n",
      "        [26.3427, 21.5494, 22.9072],\n",
      "        [27.4013, 22.5859, 23.5259],\n",
      "        [27.8461, 23.3724, 24.2008],\n",
      "        [27.9330, 22.8937, 23.7041],\n",
      "        [27.9622, 23.1664, 23.4328]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.7785, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7825,  28.3101, -23.9639],\n",
      "        [-26.8652,  28.1538, -23.8846],\n",
      "        [-26.6818,  28.2167, -23.6835],\n",
      "        [-26.6491,  27.9371, -23.4433],\n",
      "        [-26.7756,  28.2993, -23.8299],\n",
      "        [-26.8085,  27.6509, -23.5624]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2728,  22.4385,  23.0376, -26.7825,  28.3101, -23.9639],\n",
      "        [ 26.3427,  21.5494,  22.9072, -26.8652,  28.1538, -23.8846],\n",
      "        [ 27.4013,  22.5859,  23.5259, -26.6818,  28.2167, -23.6835],\n",
      "        [ 27.8461,  23.3724,  24.2008, -26.6491,  27.9371, -23.4433],\n",
      "        [ 27.9330,  22.8937,  23.7041, -26.7756,  28.2993, -23.8299],\n",
      "        [ 27.9622,  23.1664,  23.4328, -26.8085,  27.6509, -23.5624]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.265994548797607\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7246, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2596, 22.8638, 23.6651],\n",
      "        [27.3612, 23.2167, 23.2577],\n",
      "        [28.2354, 24.0750, 24.3353],\n",
      "        [27.6210, 22.9591, 23.4781],\n",
      "        [27.4838, 22.6764, 23.5998],\n",
      "        [27.2624, 23.0079, 23.7793]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.5282, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.3338,  27.3807, -23.2725],\n",
      "        [-25.8860,  27.1259, -23.2144],\n",
      "        [-26.8358,  28.1915, -24.0105],\n",
      "        [-26.9412,  28.2043, -23.8909],\n",
      "        [-26.0579,  27.6005, -23.4322],\n",
      "        [-26.0929,  27.1905, -23.4162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2596,  22.8638,  23.6651, -26.3338,  27.3807, -23.2725],\n",
      "        [ 27.3612,  23.2167,  23.2577, -25.8860,  27.1259, -23.2144],\n",
      "        [ 28.2354,  24.0750,  24.3353, -26.8358,  28.1915, -24.0105],\n",
      "        [ 27.6210,  22.9591,  23.4781, -26.9412,  28.2043, -23.8909],\n",
      "        [ 27.4838,  22.6764,  23.5998, -26.0579,  27.6005, -23.4322],\n",
      "        [ 27.2624,  23.0079,  23.7793, -26.0929,  27.1905, -23.4162]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.239440441131592\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3288, 23.2946, 24.0658],\n",
      "        [27.6478, 22.7581, 23.5192],\n",
      "        [27.6835, 23.2951, 23.7869],\n",
      "        [26.9537, 22.0669, 23.2475],\n",
      "        [26.6875, 22.6058, 23.3774],\n",
      "        [28.3793, 23.8297, 24.4826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.6382, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4199,  27.4292, -23.5770],\n",
      "        [-26.3790,  27.9420, -24.0396],\n",
      "        [-26.2813,  27.7009, -23.5842],\n",
      "        [-26.3173,  27.5059, -23.6969],\n",
      "        [-26.8243,  27.5885, -23.4782],\n",
      "        [-26.8564,  27.9309, -24.0587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3288,  23.2946,  24.0658, -26.4199,  27.4292, -23.5770],\n",
      "        [ 27.6478,  22.7581,  23.5192, -26.3790,  27.9420, -24.0396],\n",
      "        [ 27.6835,  23.2951,  23.7869, -26.2813,  27.7009, -23.5842],\n",
      "        [ 26.9537,  22.0669,  23.2475, -26.3173,  27.5059, -23.6969],\n",
      "        [ 26.6875,  22.6058,  23.3774, -26.8243,  27.5885, -23.4782],\n",
      "        [ 28.3793,  23.8297,  24.4826, -26.8564,  27.9309, -24.0587]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.350905895233154\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5891, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8144, 23.4928, 23.5423],\n",
      "        [27.6988, 23.3918, 23.7515],\n",
      "        [28.5784, 23.6409, 24.4952],\n",
      "        [27.7560, 23.1143, 23.7185],\n",
      "        [27.5339, 22.8180, 23.4531],\n",
      "        [27.7079, 23.2722, 24.2329]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.4166, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5282,  27.3223, -23.3904],\n",
      "        [-26.8829,  27.8069, -23.8422],\n",
      "        [-27.2212,  28.5400, -24.6054],\n",
      "        [-27.2242,  28.3129, -23.9893],\n",
      "        [-26.8960,  28.3807, -24.0495],\n",
      "        [-26.2843,  27.5505, -23.6552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8144,  23.4928,  23.5423, -26.5282,  27.3223, -23.3904],\n",
      "        [ 27.6988,  23.3918,  23.7515, -26.8829,  27.8069, -23.8422],\n",
      "        [ 28.5784,  23.6409,  24.4952, -27.2212,  28.5400, -24.6054],\n",
      "        [ 27.7560,  23.1143,  23.7185, -27.2242,  28.3129, -23.9893],\n",
      "        [ 27.5339,  22.8180,  23.4531, -26.8960,  28.3807, -24.0495],\n",
      "        [ 27.7079,  23.2722,  24.2329, -26.2843,  27.5505, -23.6552]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.300496578216553\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1597, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1272, 23.1391, 23.7599],\n",
      "        [27.6011, 23.1182, 23.6267],\n",
      "        [27.4470, 22.5437, 23.4642],\n",
      "        [28.2565, 23.7481, 24.3753],\n",
      "        [27.3654, 22.3489, 23.5315],\n",
      "        [27.2180, 22.5723, 23.2383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9725, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9702,  27.9767, -23.9265],\n",
      "        [-26.4064,  28.1721, -23.8825],\n",
      "        [-26.8165,  28.2704, -24.0208],\n",
      "        [-27.9440,  28.9825, -24.7643],\n",
      "        [-26.6495,  28.0439, -23.9060],\n",
      "        [-26.4784,  28.1331, -23.6702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1272,  23.1391,  23.7599, -26.9702,  27.9767, -23.9265],\n",
      "        [ 27.6011,  23.1182,  23.6267, -26.4064,  28.1721, -23.8825],\n",
      "        [ 27.4470,  22.5437,  23.4642, -26.8165,  28.2704, -24.0208],\n",
      "        [ 28.2565,  23.7481,  24.3753, -27.9440,  28.9825, -24.7643],\n",
      "        [ 27.3654,  22.3489,  23.5315, -26.6495,  28.0439, -23.9060],\n",
      "        [ 27.2180,  22.5723,  23.2383, -26.4784,  28.1331, -23.6702]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.375172138214111\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.4403, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1748, 23.4511, 24.0024],\n",
      "        [27.1317, 23.0802, 23.0943],\n",
      "        [27.7276, 23.2586, 24.1154],\n",
      "        [27.6754, 22.8946, 23.7213],\n",
      "        [27.3023, 23.1078, 23.7130],\n",
      "        [27.3414, 22.3896, 23.0330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.3762, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8718,  28.1229, -23.8469],\n",
      "        [-27.0668,  28.5055, -24.1985],\n",
      "        [-26.0923,  27.5977, -23.1728],\n",
      "        [-26.5849,  27.6838, -23.4755],\n",
      "        [-26.8093,  27.8702, -23.8588],\n",
      "        [-26.0162,  27.7091, -23.5500]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1748,  23.4511,  24.0024, -26.8718,  28.1229, -23.8469],\n",
      "        [ 27.1317,  23.0802,  23.0943, -27.0668,  28.5055, -24.1985],\n",
      "        [ 27.7276,  23.2586,  24.1154, -26.0923,  27.5977, -23.1728],\n",
      "        [ 27.6754,  22.8946,  23.7213, -26.5849,  27.6838, -23.4755],\n",
      "        [ 27.3023,  23.1078,  23.7130, -26.8093,  27.8702, -23.8588],\n",
      "        [ 27.3414,  22.3896,  23.0330, -26.0162,  27.7091, -23.5500]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.402603626251221\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0679, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9903, 23.3575, 24.0491],\n",
      "        [28.3902, 23.6003, 23.9021],\n",
      "        [27.9881, 23.1915, 23.5826],\n",
      "        [27.9414, 23.3430, 23.7760],\n",
      "        [28.4203, 23.3783, 24.3785],\n",
      "        [27.5836, 22.8391, 23.6974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.6817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9743,  27.8313, -23.9728],\n",
      "        [-26.5538,  27.4392, -23.1802],\n",
      "        [-26.6276,  27.9236, -23.8249],\n",
      "        [-26.7384,  28.2156, -24.1872],\n",
      "        [-26.7722,  27.7739, -23.9225],\n",
      "        [-26.8775,  28.3628, -23.9929]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9903,  23.3575,  24.0491, -26.9743,  27.8313, -23.9728],\n",
      "        [ 28.3902,  23.6003,  23.9021, -26.5538,  27.4392, -23.1802],\n",
      "        [ 27.9881,  23.1915,  23.5826, -26.6276,  27.9236, -23.8249],\n",
      "        [ 27.9414,  23.3430,  23.7760, -26.7384,  28.2156, -24.1872],\n",
      "        [ 28.4203,  23.3783,  24.3785, -26.7722,  27.7739, -23.9225],\n",
      "        [ 27.5836,  22.8391,  23.6974, -26.8775,  28.3628, -23.9929]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.389380931854248\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5365, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1418, 23.6965, 23.8418],\n",
      "        [27.8688, 23.2816, 23.7866],\n",
      "        [26.9913, 22.5331, 23.6747],\n",
      "        [27.7569, 22.7815, 23.7934],\n",
      "        [28.0907, 23.5024, 24.3576],\n",
      "        [27.7705, 23.3954, 23.6284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.1045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6292,  28.0897, -24.0157],\n",
      "        [-26.3853,  27.5591, -23.0344],\n",
      "        [-26.9733,  28.1991, -23.8977],\n",
      "        [-27.1127,  28.3893, -24.1053],\n",
      "        [-27.0311,  28.6156, -24.1800],\n",
      "        [-27.0077,  28.3242, -23.9827]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1418,  23.6965,  23.8418, -26.6292,  28.0897, -24.0157],\n",
      "        [ 27.8688,  23.2816,  23.7866, -26.3853,  27.5591, -23.0344],\n",
      "        [ 26.9913,  22.5331,  23.6747, -26.9733,  28.1991, -23.8977],\n",
      "        [ 27.7569,  22.7815,  23.7934, -27.1127,  28.3893, -24.1053],\n",
      "        [ 28.0907,  23.5024,  24.3576, -27.0311,  28.6156, -24.1800],\n",
      "        [ 27.7705,  23.3954,  23.6284, -27.0077,  28.3242, -23.9827]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.401317596435547\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6180, 23.3275, 24.0137],\n",
      "        [28.1160, 23.1880, 24.3705],\n",
      "        [27.7291, 23.1370, 23.8862],\n",
      "        [27.6522, 23.1524, 23.9749],\n",
      "        [28.1890, 23.4645, 24.3260],\n",
      "        [28.0822, 23.4156, 23.6645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.9810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6401,  28.1217, -23.6100],\n",
      "        [-26.4360,  27.9280, -23.5258],\n",
      "        [-27.0690,  28.0406, -24.0482],\n",
      "        [-26.5111,  27.1958, -23.4543],\n",
      "        [-27.0745,  27.7882, -23.4646],\n",
      "        [-26.5918,  27.5195, -23.8101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6180,  23.3275,  24.0137, -26.6401,  28.1217, -23.6100],\n",
      "        [ 28.1160,  23.1880,  24.3705, -26.4360,  27.9280, -23.5258],\n",
      "        [ 27.7291,  23.1370,  23.8862, -27.0690,  28.0406, -24.0482],\n",
      "        [ 27.6522,  23.1524,  23.9749, -26.5111,  27.1958, -23.4543],\n",
      "        [ 28.1890,  23.4645,  24.3260, -27.0745,  27.7882, -23.4646],\n",
      "        [ 28.0822,  23.4156,  23.6645, -26.5918,  27.5195, -23.8101]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.357420921325684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1404, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0461, 23.1758, 24.0204],\n",
      "        [28.3924, 23.5478, 24.1258],\n",
      "        [27.8799, 23.0254, 23.6597],\n",
      "        [27.5640, 23.0744, 23.8652],\n",
      "        [27.1248, 22.3252, 23.7842],\n",
      "        [28.1536, 23.1104, 23.8767]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.1672, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0435,  28.1966, -24.3575],\n",
      "        [-26.5087,  27.7980, -23.4138],\n",
      "        [-26.5855,  27.6219, -23.5035],\n",
      "        [-27.0854,  28.2855, -24.1754],\n",
      "        [-26.8045,  28.1480, -24.0368],\n",
      "        [-27.1218,  28.3601, -24.4881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0461,  23.1758,  24.0204, -27.0435,  28.1966, -24.3575],\n",
      "        [ 28.3924,  23.5478,  24.1258, -26.5087,  27.7980, -23.4138],\n",
      "        [ 27.8799,  23.0254,  23.6597, -26.5855,  27.6219, -23.5035],\n",
      "        [ 27.5640,  23.0744,  23.8652, -27.0854,  28.2855, -24.1754],\n",
      "        [ 27.1248,  22.3252,  23.7842, -26.8045,  28.1480, -24.0368],\n",
      "        [ 28.1536,  23.1104,  23.8767, -27.1218,  28.3601, -24.4881]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.418933391571045\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7694, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.8681, 22.4016, 22.8172],\n",
      "        [27.8930, 23.2489, 23.7520],\n",
      "        [28.4064, 23.8401, 24.2135],\n",
      "        [27.9382, 23.2249, 23.9077],\n",
      "        [27.7705, 22.9792, 23.6816],\n",
      "        [28.4145, 23.3134, 24.1413]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.0165, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0927,  27.9701, -24.1778],\n",
      "        [-27.1687,  28.2784, -24.1803],\n",
      "        [-26.8436,  28.1977, -23.8956],\n",
      "        [-26.4160,  27.0600, -22.8408],\n",
      "        [-26.3022,  27.4254, -23.6695],\n",
      "        [-26.3508,  27.7096, -23.5587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.8681,  22.4016,  22.8172, -27.0927,  27.9701, -24.1778],\n",
      "        [ 27.8930,  23.2489,  23.7520, -27.1687,  28.2784, -24.1803],\n",
      "        [ 28.4064,  23.8401,  24.2135, -26.8436,  28.1977, -23.8956],\n",
      "        [ 27.9382,  23.2249,  23.9077, -26.4160,  27.0600, -22.8408],\n",
      "        [ 27.7705,  22.9792,  23.6816, -26.3022,  27.4254, -23.6695],\n",
      "        [ 28.4145,  23.3134,  24.1413, -26.3508,  27.7096, -23.5587]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.2558674812316895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7027, 23.2194, 23.7891],\n",
      "        [27.3075, 22.8498, 23.1909],\n",
      "        [27.5573, 23.1977, 23.4601],\n",
      "        [28.0572, 23.5225, 24.3420],\n",
      "        [27.2419, 22.9373, 23.2889],\n",
      "        [28.1711, 23.5751, 24.4579]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.2125, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4252,  27.8110, -23.9708],\n",
      "        [-27.1617,  27.9746, -23.6210],\n",
      "        [-26.5269,  27.8942, -23.9319],\n",
      "        [-27.4968,  28.5348, -24.5450],\n",
      "        [-27.0643,  27.8900, -23.7499],\n",
      "        [-27.5623,  28.9332, -24.5223]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7027,  23.2194,  23.7891, -26.4252,  27.8110, -23.9708],\n",
      "        [ 27.3075,  22.8498,  23.1909, -27.1617,  27.9746, -23.6210],\n",
      "        [ 27.5573,  23.1977,  23.4601, -26.5269,  27.8942, -23.9319],\n",
      "        [ 28.0572,  23.5225,  24.3420, -27.4968,  28.5348, -24.5450],\n",
      "        [ 27.2419,  22.9373,  23.2889, -27.0643,  27.8900, -23.7499],\n",
      "        [ 28.1711,  23.5751,  24.4579, -27.5623,  28.9332, -24.5223]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.3447184562683105\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9123, 23.1067, 23.7076],\n",
      "        [27.4634, 23.4858, 24.0785],\n",
      "        [27.8909, 23.5112, 24.1092],\n",
      "        [27.7278, 23.1966, 23.8438],\n",
      "        [27.9416, 23.2925, 23.6350],\n",
      "        [28.0559, 23.6310, 23.9871]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0427,  28.3102, -24.3204],\n",
      "        [-27.1780,  28.0638, -23.8636],\n",
      "        [-26.9857,  28.0672, -23.8509],\n",
      "        [-27.3153,  28.3130, -24.2526],\n",
      "        [-26.4810,  27.8779, -23.5648],\n",
      "        [-27.0232,  28.4347, -24.3284]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9123,  23.1067,  23.7076, -27.0427,  28.3102, -24.3204],\n",
      "        [ 27.4634,  23.4858,  24.0785, -27.1780,  28.0638, -23.8636],\n",
      "        [ 27.8909,  23.5112,  24.1092, -26.9857,  28.0672, -23.8509],\n",
      "        [ 27.7278,  23.1966,  23.8438, -27.3153,  28.3130, -24.2526],\n",
      "        [ 27.9416,  23.2925,  23.6350, -26.4810,  27.8779, -23.5648],\n",
      "        [ 28.0559,  23.6310,  23.9871, -27.0232,  28.4347, -24.3284]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.403111457824707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0771, 23.3691, 24.0246],\n",
      "        [28.1255, 23.9199, 24.6325],\n",
      "        [27.5930, 22.9353, 23.8144],\n",
      "        [27.9830, 23.4170, 23.7355],\n",
      "        [27.9402, 23.2983, 24.1247],\n",
      "        [27.9183, 23.1124, 24.2680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.9497, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8045,  27.7660, -23.2563],\n",
      "        [-26.3306,  27.7408, -23.8930],\n",
      "        [-26.0740,  27.7174, -23.6052],\n",
      "        [-26.1852,  27.6505, -23.6621],\n",
      "        [-26.3250,  27.2613, -23.1542],\n",
      "        [-26.4772,  27.8276, -23.7014]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0771,  23.3691,  24.0246, -26.8045,  27.7660, -23.2563],\n",
      "        [ 28.1255,  23.9199,  24.6325, -26.3306,  27.7408, -23.8930],\n",
      "        [ 27.5930,  22.9353,  23.8144, -26.0740,  27.7174, -23.6052],\n",
      "        [ 27.9830,  23.4170,  23.7355, -26.1852,  27.6505, -23.6621],\n",
      "        [ 27.9402,  23.2983,  24.1247, -26.3250,  27.2613, -23.1542],\n",
      "        [ 27.9183,  23.1124,  24.2680, -26.4772,  27.8276, -23.7014]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.37654447555542\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9417, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3915, 24.1401, 24.6300],\n",
      "        [27.8618, 23.3793, 24.1833],\n",
      "        [27.9837, 23.5803, 23.9065],\n",
      "        [27.5703, 22.7985, 23.3796],\n",
      "        [27.9757, 23.3837, 24.3717],\n",
      "        [26.9820, 22.6693, 23.3794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.3955, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1599,  28.2548, -23.9686],\n",
      "        [-26.5147,  27.7616, -23.7169],\n",
      "        [-26.9670,  28.1928, -24.1018],\n",
      "        [-26.5736,  28.2404, -23.9121],\n",
      "        [-26.5493,  27.5735, -23.3256],\n",
      "        [-26.7669,  27.9912, -23.6043]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3915,  24.1401,  24.6300, -27.1599,  28.2548, -23.9686],\n",
      "        [ 27.8618,  23.3793,  24.1833, -26.5147,  27.7616, -23.7169],\n",
      "        [ 27.9837,  23.5803,  23.9065, -26.9670,  28.1928, -24.1018],\n",
      "        [ 27.5703,  22.7985,  23.3796, -26.5736,  28.2404, -23.9121],\n",
      "        [ 27.9757,  23.3837,  24.3717, -26.5493,  27.5735, -23.3256],\n",
      "        [ 26.9820,  22.6693,  23.3794, -26.7669,  27.9912, -23.6043]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.508004188537598\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0488, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.4915, 23.4531, 23.9891],\n",
      "        [27.8094, 23.2069, 23.8705],\n",
      "        [28.4665, 23.4513, 24.1003],\n",
      "        [27.5273, 22.8581, 23.7304],\n",
      "        [28.0797, 23.4534, 23.9314],\n",
      "        [28.1140, 23.6067, 24.5689]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.7409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7156,  28.1210, -24.1997],\n",
      "        [-27.2291,  28.1704, -23.8720],\n",
      "        [-26.8026,  27.7876, -23.6903],\n",
      "        [-26.7692,  28.0664, -24.3554],\n",
      "        [-26.3969,  27.4560, -23.5150],\n",
      "        [-27.1125,  28.0425, -24.0979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.4915,  23.4531,  23.9891, -26.7156,  28.1210, -24.1997],\n",
      "        [ 27.8094,  23.2069,  23.8705, -27.2291,  28.1704, -23.8720],\n",
      "        [ 28.4665,  23.4513,  24.1003, -26.8026,  27.7876, -23.6903],\n",
      "        [ 27.5273,  22.8581,  23.7304, -26.7692,  28.0664, -24.3554],\n",
      "        [ 28.0797,  23.4534,  23.9314, -26.3969,  27.4560, -23.5150],\n",
      "        [ 28.1140,  23.6067,  24.5689, -27.1125,  28.0425, -24.0979]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.388810634613037\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0801, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6573, 22.7757, 24.0125],\n",
      "        [28.1157, 23.1458, 23.9162],\n",
      "        [28.3597, 23.5105, 23.9202],\n",
      "        [27.6947, 22.9977, 23.5054],\n",
      "        [27.6190, 22.8727, 23.2807],\n",
      "        [27.5508, 23.0582, 23.7979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.2081, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8378,  28.0647, -24.0104],\n",
      "        [-26.6729,  27.7839, -23.5762],\n",
      "        [-26.8458,  28.4009, -24.4530],\n",
      "        [-26.4442,  27.5815, -23.4869],\n",
      "        [-26.7002,  27.7880, -23.9217],\n",
      "        [-26.8660,  28.2935, -23.9960]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6573,  22.7757,  24.0125, -26.8378,  28.0647, -24.0104],\n",
      "        [ 28.1157,  23.1458,  23.9162, -26.6729,  27.7839, -23.5762],\n",
      "        [ 28.3597,  23.5105,  23.9202, -26.8458,  28.4009, -24.4530],\n",
      "        [ 27.6947,  22.9977,  23.5054, -26.4442,  27.5815, -23.4869],\n",
      "        [ 27.6190,  22.8727,  23.2807, -26.7002,  27.7880, -23.9217],\n",
      "        [ 27.5508,  23.0582,  23.7979, -26.8660,  28.2935, -23.9960]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.372356414794922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4468, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0501, 23.4676, 24.1744],\n",
      "        [27.9426, 23.8846, 24.2083],\n",
      "        [27.6771, 23.2607, 23.5989],\n",
      "        [27.2363, 23.3828, 24.0143],\n",
      "        [27.9806, 22.8082, 23.5849],\n",
      "        [28.0363, 23.5405, 24.0822]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(52.4641, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6353,  27.4552, -23.3664],\n",
      "        [-26.7163,  27.4562, -23.4535],\n",
      "        [-26.9528,  28.5445, -24.2092],\n",
      "        [-26.7436,  28.1474, -23.9069],\n",
      "        [-26.3687,  27.7353, -23.7137],\n",
      "        [-26.2477,  27.7117, -23.5825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0501,  23.4676,  24.1744, -26.6353,  27.4552, -23.3664],\n",
      "        [ 27.9426,  23.8846,  24.2083, -26.7163,  27.4562, -23.4535],\n",
      "        [ 27.6771,  23.2607,  23.5989, -26.9528,  28.5445, -24.2092],\n",
      "        [ 27.2363,  23.3828,  24.0143, -26.7436,  28.1474, -23.9069],\n",
      "        [ 27.9806,  22.8082,  23.5849, -26.3687,  27.7353, -23.7137],\n",
      "        [ 28.0363,  23.5405,  24.0822, -26.2477,  27.7117, -23.5825]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.379024028778076\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0877, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6259, 23.0627, 23.8806],\n",
      "        [27.3922, 22.9061, 23.7562],\n",
      "        [27.4547, 23.1297, 23.8775],\n",
      "        [28.2143, 23.3180, 24.3609],\n",
      "        [27.7897, 22.9097, 23.6585],\n",
      "        [28.3242, 23.9418, 24.0568]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5617, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2098,  28.4084, -24.0773],\n",
      "        [-27.0783,  27.6874, -24.2465],\n",
      "        [-26.3768,  27.8119, -23.3510],\n",
      "        [-26.7777,  28.0197, -23.8860],\n",
      "        [-26.7251,  28.0505, -23.5335],\n",
      "        [-26.4595,  27.5146, -23.6139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6259,  23.0627,  23.8806, -27.2098,  28.4084, -24.0773],\n",
      "        [ 27.3922,  22.9061,  23.7562, -27.0783,  27.6874, -24.2465],\n",
      "        [ 27.4547,  23.1297,  23.8775, -26.3768,  27.8119, -23.3510],\n",
      "        [ 28.2143,  23.3180,  24.3609, -26.7777,  28.0197, -23.8860],\n",
      "        [ 27.7897,  22.9097,  23.6585, -26.7251,  28.0505, -23.5335],\n",
      "        [ 28.3242,  23.9418,  24.0568, -26.4595,  27.5146, -23.6139]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.408015251159668\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(4.1339, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0122, 23.3984, 24.1812],\n",
      "        [27.9531, 23.4067, 23.9919],\n",
      "        [28.3423, 23.9947, 24.1310],\n",
      "        [28.2064, 23.9450, 24.1674],\n",
      "        [27.6692, 23.2428, 24.1426],\n",
      "        [28.4580, 24.0186, 24.7880]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6528,  27.8824, -23.8076],\n",
      "        [-26.6893,  27.6820, -23.2974],\n",
      "        [-26.7393,  28.4300, -24.4215],\n",
      "        [-26.7965,  28.0905, -23.9604],\n",
      "        [-27.1718,  27.8736, -23.7887],\n",
      "        [-27.0509,  28.2188, -24.0361]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0122,  23.3984,  24.1812, -26.6528,  27.8824, -23.8076],\n",
      "        [ 27.9531,  23.4067,  23.9919, -26.6893,  27.6820, -23.2974],\n",
      "        [ 28.3423,  23.9947,  24.1310, -26.7393,  28.4300, -24.4215],\n",
      "        [ 28.2064,  23.9450,  24.1674, -26.7965,  28.0905, -23.9604],\n",
      "        [ 27.6692,  23.2428,  24.1426, -27.1718,  27.8736, -23.7887],\n",
      "        [ 28.4580,  24.0186,  24.7880, -27.0509,  28.2188, -24.0361]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.409522533416748\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7986, 23.3319, 24.5595],\n",
      "        [28.0987, 23.3799, 24.1170],\n",
      "        [27.5010, 22.7268, 23.7682],\n",
      "        [27.3913, 23.0401, 23.4580],\n",
      "        [27.8875, 22.9599, 23.6688],\n",
      "        [27.1423, 22.9629, 23.5965]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.7038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1250,  28.1153, -23.9354],\n",
      "        [-26.7402,  28.1235, -23.7658],\n",
      "        [-27.0824,  28.2384, -24.3182],\n",
      "        [-26.9364,  27.5909, -23.5644],\n",
      "        [-27.2674,  28.2531, -24.2711],\n",
      "        [-27.4835,  28.2935, -24.1649]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7986,  23.3319,  24.5595, -27.1250,  28.1153, -23.9354],\n",
      "        [ 28.0987,  23.3799,  24.1170, -26.7402,  28.1235, -23.7658],\n",
      "        [ 27.5010,  22.7268,  23.7682, -27.0824,  28.2384, -24.3182],\n",
      "        [ 27.3913,  23.0401,  23.4580, -26.9364,  27.5909, -23.5644],\n",
      "        [ 27.8875,  22.9599,  23.6688, -27.2674,  28.2531, -24.2711],\n",
      "        [ 27.1423,  22.9629,  23.5965, -27.4835,  28.2935, -24.1649]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.4454545974731445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6797, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2575, 22.3536, 23.3802],\n",
      "        [27.8198, 23.2714, 24.2589],\n",
      "        [28.2825, 23.4751, 24.3826],\n",
      "        [27.7971, 22.8736, 23.5965],\n",
      "        [27.6147, 23.1005, 24.0269],\n",
      "        [27.9844, 23.3542, 23.7776]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.6438, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.1209,  27.4686, -23.6601],\n",
      "        [-27.5615,  28.9198, -24.6509],\n",
      "        [-26.7306,  27.9490, -23.7850],\n",
      "        [-27.3965,  28.4763, -23.9960],\n",
      "        [-26.9971,  27.9134, -24.1448],\n",
      "        [-27.3378,  28.6163, -24.3301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2575,  22.3536,  23.3802, -26.1209,  27.4686, -23.6601],\n",
      "        [ 27.8198,  23.2714,  24.2589, -27.5615,  28.9198, -24.6509],\n",
      "        [ 28.2825,  23.4751,  24.3826, -26.7306,  27.9490, -23.7850],\n",
      "        [ 27.7971,  22.8736,  23.5965, -27.3965,  28.4763, -23.9960],\n",
      "        [ 27.6147,  23.1005,  24.0269, -26.9971,  27.9134, -24.1448],\n",
      "        [ 27.9844,  23.3542,  23.7776, -27.3378,  28.6163, -24.3301]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.253349304199219\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.2489, 22.9036, 23.4017],\n",
      "        [28.3262, 23.4941, 24.1029],\n",
      "        [28.1311, 23.8184, 24.1822],\n",
      "        [28.2433, 23.6742, 24.2441],\n",
      "        [28.3252, 23.4883, 24.2250],\n",
      "        [27.5211, 23.2070, 23.7320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.6310, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5180,  27.7605, -23.8171],\n",
      "        [-26.3979,  27.6179, -23.6334],\n",
      "        [-27.0227,  28.4316, -24.4702],\n",
      "        [-27.1116,  28.4844, -24.4401],\n",
      "        [-27.4906,  28.9835, -24.8295],\n",
      "        [-26.5063,  27.3514, -23.3098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.2489,  22.9036,  23.4017, -26.5180,  27.7605, -23.8171],\n",
      "        [ 28.3262,  23.4941,  24.1029, -26.3979,  27.6179, -23.6334],\n",
      "        [ 28.1311,  23.8184,  24.1822, -27.0227,  28.4316, -24.4702],\n",
      "        [ 28.2433,  23.6742,  24.2441, -27.1116,  28.4844, -24.4401],\n",
      "        [ 28.3252,  23.4883,  24.2250, -27.4906,  28.9835, -24.8295],\n",
      "        [ 27.5211,  23.2070,  23.7320, -26.5063,  27.3514, -23.3098]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.307223796844482\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4529, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0347, 23.8927, 24.1441],\n",
      "        [27.7979, 23.3137, 23.9575],\n",
      "        [27.5693, 23.1749, 23.4259],\n",
      "        [28.2063, 23.5542, 24.3332],\n",
      "        [28.0224, 23.3201, 23.8214],\n",
      "        [27.5488, 22.6836, 23.5283]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.5412, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1670,  28.2427, -24.4367],\n",
      "        [-26.8588,  28.1314, -23.7337],\n",
      "        [-27.0871,  28.2128, -23.7328],\n",
      "        [-26.8674,  28.2635, -23.9425],\n",
      "        [-26.6628,  27.3935, -23.6443],\n",
      "        [-26.7883,  28.3020, -24.1299]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0347,  23.8927,  24.1441, -27.1670,  28.2427, -24.4367],\n",
      "        [ 27.7979,  23.3137,  23.9575, -26.8588,  28.1314, -23.7337],\n",
      "        [ 27.5693,  23.1749,  23.4259, -27.0871,  28.2128, -23.7328],\n",
      "        [ 28.2063,  23.5542,  24.3332, -26.8674,  28.2635, -23.9425],\n",
      "        [ 28.0224,  23.3201,  23.8214, -26.6628,  27.3935, -23.6443],\n",
      "        [ 27.5488,  22.6836,  23.5283, -26.7883,  28.3020, -24.1299]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.487983703613281\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3498, 23.1720, 23.8949],\n",
      "        [27.1852, 23.0887, 23.9264],\n",
      "        [28.1742, 23.8242, 24.0296],\n",
      "        [27.6052, 23.3555, 23.8087],\n",
      "        [27.8946, 23.6528, 23.9660],\n",
      "        [26.9128, 22.9274, 22.9936]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.8877, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.6140,  28.0007, -24.0521],\n",
      "        [-26.5311,  27.6093, -23.5204],\n",
      "        [-27.0633,  28.4877, -24.3538],\n",
      "        [-26.5508,  28.3194, -24.0074],\n",
      "        [-27.4079,  28.9168, -24.5834],\n",
      "        [-26.8063,  27.8892, -24.0380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3498,  23.1720,  23.8949, -26.6140,  28.0007, -24.0521],\n",
      "        [ 27.1852,  23.0887,  23.9264, -26.5311,  27.6093, -23.5204],\n",
      "        [ 28.1742,  23.8242,  24.0296, -27.0633,  28.4877, -24.3538],\n",
      "        [ 27.6052,  23.3555,  23.8087, -26.5508,  28.3194, -24.0074],\n",
      "        [ 27.8946,  23.6528,  23.9660, -27.4079,  28.9168, -24.5834],\n",
      "        [ 26.9128,  22.9274,  22.9936, -26.8063,  27.8892, -24.0380]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.370726585388184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3884, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7445, 23.2986, 23.8993],\n",
      "        [27.7887, 23.2121, 23.5656],\n",
      "        [27.9241, 23.2202, 24.0063],\n",
      "        [28.3748, 23.7506, 24.0975],\n",
      "        [28.3239, 23.9608, 24.4488],\n",
      "        [27.6219, 23.2847, 23.8725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5210,  28.2177, -24.5158],\n",
      "        [-27.4579,  28.5146, -24.3172],\n",
      "        [-27.3906,  28.8658, -24.9118],\n",
      "        [-26.5765,  28.0163, -24.0056],\n",
      "        [-26.8904,  27.7299, -23.8706],\n",
      "        [-26.7311,  27.7278, -23.7018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7445,  23.2986,  23.8993, -27.5210,  28.2177, -24.5158],\n",
      "        [ 27.7887,  23.2121,  23.5656, -27.4579,  28.5146, -24.3172],\n",
      "        [ 27.9241,  23.2202,  24.0063, -27.3906,  28.8658, -24.9118],\n",
      "        [ 28.3748,  23.7506,  24.0975, -26.5765,  28.0163, -24.0056],\n",
      "        [ 28.3239,  23.9608,  24.4488, -26.8904,  27.7299, -23.8706],\n",
      "        [ 27.6219,  23.2847,  23.8725, -26.7311,  27.7278, -23.7018]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.456143856048584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2773, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2411, 23.3835, 24.0122],\n",
      "        [28.1503, 23.6130, 24.3072],\n",
      "        [27.9360, 23.3500, 24.1249],\n",
      "        [27.8720, 23.5335, 24.3018],\n",
      "        [27.8147, 23.1335, 23.8032],\n",
      "        [27.5909, 23.5814, 24.1430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0165,  28.2789, -24.2314],\n",
      "        [-27.0697,  28.3258, -24.4852],\n",
      "        [-27.2697,  28.2776, -24.3769],\n",
      "        [-27.1018,  28.5617, -24.3734],\n",
      "        [-27.1429,  28.5519, -24.3692],\n",
      "        [-27.0256,  28.5474, -24.2474]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2411,  23.3835,  24.0122, -27.0165,  28.2789, -24.2314],\n",
      "        [ 28.1503,  23.6130,  24.3072, -27.0697,  28.3258, -24.4852],\n",
      "        [ 27.9360,  23.3500,  24.1249, -27.2697,  28.2776, -24.3769],\n",
      "        [ 27.8720,  23.5335,  24.3018, -27.1018,  28.5617, -24.3734],\n",
      "        [ 27.8147,  23.1335,  23.8032, -27.1429,  28.5519, -24.3692],\n",
      "        [ 27.5909,  23.5814,  24.1430, -27.0256,  28.5474, -24.2474]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.469705581665039\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4366, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[26.9933, 22.9709, 23.3744],\n",
      "        [28.0158, 23.6301, 24.0083],\n",
      "        [28.6593, 23.8468, 24.5811],\n",
      "        [28.3366, 23.7801, 24.6928],\n",
      "        [27.4459, 23.1692, 24.1386],\n",
      "        [27.5533, 22.9979, 23.4898]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5376, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8135,  28.0179, -24.0615],\n",
      "        [-26.8154,  27.7723, -24.0312],\n",
      "        [-26.8749,  28.2297, -23.9822],\n",
      "        [-27.0019,  28.5233, -23.9890],\n",
      "        [-26.0213,  27.9865, -23.8558],\n",
      "        [-26.8806,  27.8930, -23.8526]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 26.9933,  22.9709,  23.3744, -26.8135,  28.0179, -24.0615],\n",
      "        [ 28.0158,  23.6301,  24.0083, -26.8154,  27.7723, -24.0312],\n",
      "        [ 28.6593,  23.8468,  24.5811, -26.8749,  28.2297, -23.9822],\n",
      "        [ 28.3366,  23.7801,  24.6928, -27.0019,  28.5233, -23.9890],\n",
      "        [ 27.4459,  23.1692,  24.1386, -26.0213,  27.9865, -23.8558],\n",
      "        [ 27.5533,  22.9979,  23.4898, -26.8806,  27.8930, -23.8526]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.33233118057251\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5289, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3383, 23.8644, 24.1284],\n",
      "        [27.7990, 22.8103, 23.6654],\n",
      "        [28.0467, 23.4836, 24.3430],\n",
      "        [27.9246, 22.8989, 23.8880],\n",
      "        [27.9752, 23.4906, 24.2404],\n",
      "        [28.0736, 23.1878, 24.0930]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.4779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9661,  27.9603, -24.2537],\n",
      "        [-27.6010,  28.8786, -24.7552],\n",
      "        [-26.8404,  28.2338, -24.1185],\n",
      "        [-26.9891,  28.0033, -24.4108],\n",
      "        [-27.4658,  28.5439, -24.6736],\n",
      "        [-27.8529,  28.6063, -24.3850]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3383,  23.8644,  24.1284, -26.9661,  27.9603, -24.2537],\n",
      "        [ 27.7990,  22.8103,  23.6654, -27.6010,  28.8786, -24.7552],\n",
      "        [ 28.0467,  23.4836,  24.3430, -26.8404,  28.2338, -24.1185],\n",
      "        [ 27.9246,  22.8989,  23.8880, -26.9891,  28.0033, -24.4108],\n",
      "        [ 27.9752,  23.4906,  24.2404, -27.4658,  28.5439, -24.6736],\n",
      "        [ 28.0736,  23.1878,  24.0930, -27.8529,  28.6063, -24.3850]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.489297866821289\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7886, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1056, 22.3705, 23.6342],\n",
      "        [28.3775, 23.8464, 24.5761],\n",
      "        [27.8823, 23.2618, 23.8958],\n",
      "        [28.0637, 23.4658, 24.1340],\n",
      "        [27.4823, 22.9774, 23.5581],\n",
      "        [27.2840, 23.3564, 23.7502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9555,  28.3193, -24.1331],\n",
      "        [-27.7161,  28.8368, -24.4610],\n",
      "        [-27.0774,  28.3810, -24.3852],\n",
      "        [-27.0109,  28.1564, -24.0308],\n",
      "        [-26.8408,  28.1483, -23.9175],\n",
      "        [-27.3509,  28.2672, -24.3710]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1056,  22.3705,  23.6342, -26.9555,  28.3193, -24.1331],\n",
      "        [ 28.3775,  23.8464,  24.5761, -27.7161,  28.8368, -24.4610],\n",
      "        [ 27.8823,  23.2618,  23.8958, -27.0774,  28.3810, -24.3852],\n",
      "        [ 28.0637,  23.4658,  24.1340, -27.0109,  28.1564, -24.0308],\n",
      "        [ 27.4823,  22.9774,  23.5581, -26.8408,  28.1483, -23.9175],\n",
      "        [ 27.2840,  23.3564,  23.7502, -27.3509,  28.2672, -24.3710]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.351722717285156\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0225, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3688, 23.3084, 24.1416],\n",
      "        [28.1601, 23.6080, 24.2680],\n",
      "        [28.2183, 23.8971, 24.7502],\n",
      "        [27.3001, 22.7542, 23.5103],\n",
      "        [28.2680, 23.3881, 24.3378],\n",
      "        [28.2574, 23.8082, 24.4468]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.0221, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9515,  28.0245, -24.4173],\n",
      "        [-26.8958,  28.1175, -23.7809],\n",
      "        [-26.7885,  28.1627, -23.7992],\n",
      "        [-26.9404,  27.7169, -24.2039],\n",
      "        [-26.9119,  28.0922, -24.0430],\n",
      "        [-26.4503,  27.6321, -23.6842]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3688,  23.3084,  24.1416, -26.9515,  28.0245, -24.4173],\n",
      "        [ 28.1601,  23.6080,  24.2680, -26.8958,  28.1175, -23.7809],\n",
      "        [ 28.2183,  23.8971,  24.7502, -26.7885,  28.1627, -23.7992],\n",
      "        [ 27.3001,  22.7542,  23.5103, -26.9404,  27.7169, -24.2039],\n",
      "        [ 28.2680,  23.3881,  24.3378, -26.9119,  28.0922, -24.0430],\n",
      "        [ 28.2574,  23.8082,  24.4468, -26.4503,  27.6321, -23.6842]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.481874465942383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4740, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8249, 23.3407, 23.8060],\n",
      "        [28.1457, 23.8176, 24.0233],\n",
      "        [27.9830, 23.0474, 24.0560],\n",
      "        [28.4920, 23.7509, 24.7565],\n",
      "        [28.0831, 23.3394, 24.2460],\n",
      "        [27.7667, 23.2761, 23.6133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2461, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5900,  28.5504, -24.4200],\n",
      "        [-26.7160,  27.7883, -23.9714],\n",
      "        [-27.4419,  28.6784, -24.5356],\n",
      "        [-27.2737,  28.2871, -24.1424],\n",
      "        [-27.2841,  28.4088, -24.4619],\n",
      "        [-26.7281,  28.2732, -24.2655]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8249,  23.3407,  23.8060, -27.5900,  28.5504, -24.4200],\n",
      "        [ 28.1457,  23.8176,  24.0233, -26.7160,  27.7883, -23.9714],\n",
      "        [ 27.9830,  23.0474,  24.0560, -27.4419,  28.6784, -24.5356],\n",
      "        [ 28.4920,  23.7509,  24.7565, -27.2737,  28.2871, -24.1424],\n",
      "        [ 28.0831,  23.3394,  24.2460, -27.2841,  28.4088, -24.4619],\n",
      "        [ 27.7667,  23.2761,  23.6133, -26.7281,  28.2732, -24.2655]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.482313632965088\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2406, 23.7289, 24.5234],\n",
      "        [27.6262, 23.5357, 24.3057],\n",
      "        [28.0378, 23.5271, 24.0760],\n",
      "        [28.0576, 23.6297, 23.7853],\n",
      "        [28.3461, 23.4543, 23.8027],\n",
      "        [28.3785, 23.8061, 24.0946]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.3720, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9348,  27.8858, -24.1812],\n",
      "        [-27.8117,  29.0300, -24.7162],\n",
      "        [-26.8221,  27.9272, -24.0193],\n",
      "        [-26.6707,  27.8802, -23.6381],\n",
      "        [-26.6183,  27.3766, -23.5928],\n",
      "        [-26.7501,  28.3778, -23.7801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2406,  23.7289,  24.5234, -26.9348,  27.8858, -24.1812],\n",
      "        [ 27.6262,  23.5357,  24.3057, -27.8117,  29.0300, -24.7162],\n",
      "        [ 28.0378,  23.5271,  24.0760, -26.8221,  27.9272, -24.0193],\n",
      "        [ 28.0576,  23.6297,  23.7853, -26.6707,  27.8802, -23.6381],\n",
      "        [ 28.3461,  23.4543,  23.8027, -26.6183,  27.3766, -23.5928],\n",
      "        [ 28.3785,  23.8061,  24.0946, -26.7501,  28.3778, -23.7801]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.499405384063721\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9614, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9291, 23.3884, 23.9697],\n",
      "        [28.4284, 23.5668, 24.3705],\n",
      "        [27.7459, 23.3738, 24.0520],\n",
      "        [27.7922, 23.0205, 23.9588],\n",
      "        [28.4748, 23.6710, 24.6388],\n",
      "        [28.1631, 23.7420, 24.3511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9283,  28.3448, -24.5267],\n",
      "        [-26.3111,  27.8401, -23.5588],\n",
      "        [-27.1995,  28.3246, -24.0065],\n",
      "        [-26.3025,  28.0388, -23.6754],\n",
      "        [-26.9876,  28.4954, -24.7789],\n",
      "        [-26.8124,  28.2826, -23.9321]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9291,  23.3884,  23.9697, -26.9283,  28.3448, -24.5267],\n",
      "        [ 28.4284,  23.5668,  24.3705, -26.3111,  27.8401, -23.5588],\n",
      "        [ 27.7459,  23.3738,  24.0520, -27.1995,  28.3246, -24.0065],\n",
      "        [ 27.7922,  23.0205,  23.9588, -26.3025,  28.0388, -23.6754],\n",
      "        [ 28.4748,  23.6710,  24.6388, -26.9876,  28.4954, -24.7789],\n",
      "        [ 28.1631,  23.7420,  24.3511, -26.8124,  28.2826, -23.9321]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.472841739654541\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.5877, 23.5218, 23.8672],\n",
      "        [28.2698, 23.6615, 24.2595],\n",
      "        [27.7520, 23.3895, 24.1205],\n",
      "        [27.8381, 23.4905, 24.3219],\n",
      "        [27.9237, 23.2460, 23.6675],\n",
      "        [28.3699, 23.5620, 24.3740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(53.6184, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2352,  28.4372, -24.5683],\n",
      "        [-26.8472,  27.9560, -23.9633],\n",
      "        [-26.9307,  28.2423, -24.2227],\n",
      "        [-27.2415,  27.8783, -23.8731],\n",
      "        [-27.3389,  28.2833, -24.3359],\n",
      "        [-26.5656,  27.7385, -23.9526]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.5877,  23.5218,  23.8672, -27.2352,  28.4372, -24.5683],\n",
      "        [ 28.2698,  23.6615,  24.2595, -26.8472,  27.9560, -23.9633],\n",
      "        [ 27.7520,  23.3895,  24.1205, -26.9307,  28.2423, -24.2227],\n",
      "        [ 27.8381,  23.4905,  24.3219, -27.2415,  27.8783, -23.8731],\n",
      "        [ 27.9237,  23.2460,  23.6675, -27.3389,  28.2833, -24.3359],\n",
      "        [ 28.3699,  23.5620,  24.3740, -26.5656,  27.7385, -23.9526]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.471864700317383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7694, 24.0257, 25.0904],\n",
      "        [28.0440, 23.0939, 23.7527],\n",
      "        [27.6389, 23.3509, 23.8736],\n",
      "        [27.8198, 23.4930, 23.7896],\n",
      "        [27.8083, 23.1788, 23.9380],\n",
      "        [28.5318, 24.0476, 24.5654]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9087, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9227,  28.2299, -24.0249],\n",
      "        [-26.9013,  28.2153, -24.0279],\n",
      "        [-27.0678,  27.9310, -23.8082],\n",
      "        [-27.1077,  28.4946, -24.5822],\n",
      "        [-26.9904,  28.3014, -24.1892],\n",
      "        [-27.2543,  28.0692, -24.5273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7694,  24.0257,  25.0904, -26.9227,  28.2299, -24.0249],\n",
      "        [ 28.0440,  23.0939,  23.7527, -26.9013,  28.2153, -24.0279],\n",
      "        [ 27.6389,  23.3509,  23.8736, -27.0678,  27.9310, -23.8082],\n",
      "        [ 27.8198,  23.4930,  23.7896, -27.1077,  28.4946, -24.5822],\n",
      "        [ 27.8083,  23.1788,  23.9380, -26.9904,  28.3014, -24.1892],\n",
      "        [ 28.5318,  24.0476,  24.5654, -27.2543,  28.0692, -24.5273]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.581818580627441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1620, 22.9303, 24.3376],\n",
      "        [28.1812, 23.8117, 24.4561],\n",
      "        [27.9049, 23.6807, 24.2307],\n",
      "        [27.3817, 23.2632, 23.9387],\n",
      "        [28.8794, 24.1037, 24.7240],\n",
      "        [28.2786, 23.3762, 24.2480]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2898,  28.7682, -24.2856],\n",
      "        [-27.4307,  28.9014, -24.4512],\n",
      "        [-26.2264,  27.7248, -23.9330],\n",
      "        [-27.1354,  28.1896, -24.4147],\n",
      "        [-26.9900,  28.2972, -24.1669],\n",
      "        [-27.5559,  28.6527, -24.6774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1620,  22.9303,  24.3376, -27.2898,  28.7682, -24.2856],\n",
      "        [ 28.1812,  23.8117,  24.4561, -27.4307,  28.9014, -24.4512],\n",
      "        [ 27.9049,  23.6807,  24.2307, -26.2264,  27.7248, -23.9330],\n",
      "        [ 27.3817,  23.2632,  23.9387, -27.1354,  28.1896, -24.4147],\n",
      "        [ 28.8794,  24.1037,  24.7240, -26.9900,  28.2972, -24.1669],\n",
      "        [ 28.2786,  23.3762,  24.2480, -27.5559,  28.6527, -24.6774]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.514770030975342\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1085, 23.4523, 23.7494],\n",
      "        [28.0145, 23.5540, 24.0178],\n",
      "        [28.1832, 23.5713, 23.9583],\n",
      "        [27.9089, 23.2900, 24.0132],\n",
      "        [27.6163, 22.9115, 23.6358],\n",
      "        [27.5932, 23.5124, 23.4908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.9284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1441,  28.6735, -24.5023],\n",
      "        [-26.5080,  27.8694, -24.0565],\n",
      "        [-27.0700,  27.9573, -23.3685],\n",
      "        [-26.7999,  27.7479, -23.9343],\n",
      "        [-26.4936,  27.8719, -24.0077],\n",
      "        [-27.0246,  28.4100, -24.6039]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1085,  23.4523,  23.7494, -27.1441,  28.6735, -24.5023],\n",
      "        [ 28.0145,  23.5540,  24.0178, -26.5080,  27.8694, -24.0565],\n",
      "        [ 28.1832,  23.5713,  23.9583, -27.0700,  27.9573, -23.3685],\n",
      "        [ 27.9089,  23.2900,  24.0132, -26.7999,  27.7479, -23.9343],\n",
      "        [ 27.6163,  22.9115,  23.6358, -26.4936,  27.8719, -24.0077],\n",
      "        [ 27.5932,  23.5124,  23.4908, -27.0246,  28.4100, -24.6039]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.502835273742676\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5332, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4580, 24.0000, 24.1604],\n",
      "        [28.3673, 23.8936, 24.3636],\n",
      "        [27.9522, 23.4101, 23.7655],\n",
      "        [28.3327, 23.6079, 24.1277],\n",
      "        [28.3410, 23.2985, 23.9293],\n",
      "        [27.6882, 23.1376, 23.8475]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2518, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0150,  28.1579, -23.7507],\n",
      "        [-27.5573,  28.1928, -24.4650],\n",
      "        [-27.1776,  28.4436, -23.9952],\n",
      "        [-27.1896,  28.4964, -24.4261],\n",
      "        [-26.6385,  27.4724, -23.5167],\n",
      "        [-26.9405,  28.1448, -24.3817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4580,  24.0000,  24.1604, -27.0150,  28.1579, -23.7507],\n",
      "        [ 28.3673,  23.8936,  24.3636, -27.5573,  28.1928, -24.4650],\n",
      "        [ 27.9522,  23.4101,  23.7655, -27.1776,  28.4436, -23.9952],\n",
      "        [ 28.3327,  23.6079,  24.1277, -27.1896,  28.4964, -24.4261],\n",
      "        [ 28.3410,  23.2985,  23.9293, -26.6385,  27.4724, -23.5167],\n",
      "        [ 27.6882,  23.1376,  23.8475, -26.9405,  28.1448, -24.3817]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.516575813293457\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3766, 23.4144, 24.5006],\n",
      "        [27.6862, 23.0933, 24.1678],\n",
      "        [28.6205, 23.7606, 24.3548],\n",
      "        [27.5665, 23.1469, 23.7561],\n",
      "        [28.1613, 23.7340, 24.3739],\n",
      "        [28.0242, 23.4660, 24.3428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3870, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0604,  28.0928, -23.7470],\n",
      "        [-26.6800,  28.1453, -24.5554],\n",
      "        [-26.9469,  28.2105, -23.7127],\n",
      "        [-27.2828,  28.4783, -24.6163],\n",
      "        [-27.5573,  28.8222, -24.7744],\n",
      "        [-27.1975,  28.6732, -23.8048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3766,  23.4144,  24.5006, -27.0604,  28.0928, -23.7470],\n",
      "        [ 27.6862,  23.0933,  24.1678, -26.6800,  28.1453, -24.5554],\n",
      "        [ 28.6205,  23.7606,  24.3548, -26.9469,  28.2105, -23.7127],\n",
      "        [ 27.5665,  23.1469,  23.7561, -27.2828,  28.4783, -24.6163],\n",
      "        [ 28.1613,  23.7340,  24.3739, -27.5573,  28.8222, -24.7744],\n",
      "        [ 28.0242,  23.4660,  24.3428, -27.1975,  28.6732, -23.8048]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.507335662841797\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8224, 22.8665, 23.5566],\n",
      "        [27.8017, 23.5278, 24.0007],\n",
      "        [28.1770, 23.3417, 24.1120],\n",
      "        [27.7548, 23.4236, 24.0461],\n",
      "        [28.0801, 23.5604, 24.1279],\n",
      "        [28.6811, 23.9420, 24.3968]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9465, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6042,  28.8050, -24.6518],\n",
      "        [-26.5698,  27.6052, -23.8713],\n",
      "        [-27.1202,  28.3159, -24.4944],\n",
      "        [-27.2634,  28.3954, -24.2737],\n",
      "        [-26.7930,  27.9652, -23.9229],\n",
      "        [-27.2746,  28.4482, -24.0542]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8224,  22.8665,  23.5566, -27.6042,  28.8050, -24.6518],\n",
      "        [ 27.8017,  23.5278,  24.0007, -26.5698,  27.6052, -23.8713],\n",
      "        [ 28.1770,  23.3417,  24.1120, -27.1202,  28.3159, -24.4944],\n",
      "        [ 27.7548,  23.4236,  24.0461, -27.2634,  28.3954, -24.2737],\n",
      "        [ 28.0801,  23.5604,  24.1279, -26.7930,  27.9652, -23.9229],\n",
      "        [ 28.6811,  23.9420,  24.3968, -27.2746,  28.4482, -24.0542]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.488170623779297\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8762, 23.3336, 24.1261],\n",
      "        [28.2593, 23.5564, 24.5767],\n",
      "        [28.3194, 23.2796, 24.0945],\n",
      "        [28.0448, 23.0274, 24.1303],\n",
      "        [27.8164, 23.1170, 24.2358],\n",
      "        [27.7062, 23.0908, 23.7046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.7340, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.9550,  28.7709, -24.4879],\n",
      "        [-27.8395,  28.7639, -24.3886],\n",
      "        [-27.0716,  28.5068, -24.4170],\n",
      "        [-26.9214,  27.9455, -23.6547],\n",
      "        [-26.7939,  27.7366, -23.5789],\n",
      "        [-26.4821,  27.5926, -23.5850]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8762,  23.3336,  24.1261, -26.9550,  28.7709, -24.4879],\n",
      "        [ 28.2593,  23.5564,  24.5767, -27.8395,  28.7639, -24.3886],\n",
      "        [ 28.3194,  23.2796,  24.0945, -27.0716,  28.5068, -24.4170],\n",
      "        [ 28.0448,  23.0274,  24.1303, -26.9214,  27.9455, -23.6547],\n",
      "        [ 27.8164,  23.1170,  24.2358, -26.7939,  27.7366, -23.5789],\n",
      "        [ 27.7062,  23.0908,  23.7046, -26.4821,  27.5926, -23.5850]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.507805824279785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9188, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3757, 23.5895, 24.4471],\n",
      "        [28.2397, 23.6116, 24.2057],\n",
      "        [28.0223, 23.4993, 23.9575],\n",
      "        [28.8804, 23.9359, 24.7463],\n",
      "        [27.7241, 23.4711, 23.9117],\n",
      "        [27.9689, 23.5835, 24.4313]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.9515, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9264,  29.0066, -24.4576],\n",
      "        [-27.3620,  28.1944, -24.1450],\n",
      "        [-27.6631,  28.9557, -24.4215],\n",
      "        [-27.1786,  28.6639, -24.7141],\n",
      "        [-26.1298,  27.4535, -23.7151],\n",
      "        [-26.8216,  28.0703, -23.8309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3757,  23.5895,  24.4471, -27.9264,  29.0066, -24.4576],\n",
      "        [ 28.2397,  23.6116,  24.2057, -27.3620,  28.1944, -24.1450],\n",
      "        [ 28.0223,  23.4993,  23.9575, -27.6631,  28.9557, -24.4215],\n",
      "        [ 28.8804,  23.9359,  24.7463, -27.1786,  28.6639, -24.7141],\n",
      "        [ 27.7241,  23.4711,  23.9117, -26.1298,  27.4535, -23.7151],\n",
      "        [ 27.9689,  23.5835,  24.4313, -26.8216,  28.0703, -23.8309]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.607371807098389\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6066, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7923, 24.4461, 25.3398],\n",
      "        [28.3144, 23.6892, 24.1352],\n",
      "        [28.6313, 23.7152, 24.5307],\n",
      "        [28.3038, 23.8300, 24.8155],\n",
      "        [28.5564, 23.4631, 24.2298],\n",
      "        [27.3849, 23.3282, 23.9383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.7851, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1024,  28.6242, -24.2885],\n",
      "        [-27.0335,  28.4955, -24.2655],\n",
      "        [-27.1592,  28.0236, -24.5966],\n",
      "        [-27.0263,  28.4777, -24.3344],\n",
      "        [-27.4274,  28.6030, -24.1653],\n",
      "        [-26.8362,  27.7840, -24.0045]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7923,  24.4461,  25.3398, -27.1024,  28.6242, -24.2885],\n",
      "        [ 28.3144,  23.6892,  24.1352, -27.0335,  28.4955, -24.2655],\n",
      "        [ 28.6313,  23.7152,  24.5307, -27.1592,  28.0236, -24.5966],\n",
      "        [ 28.3038,  23.8300,  24.8155, -27.0263,  28.4777, -24.3344],\n",
      "        [ 28.5564,  23.4631,  24.2298, -27.4274,  28.6030, -24.1653],\n",
      "        [ 27.3849,  23.3282,  23.9383, -26.8362,  27.7840, -24.0045]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.65763521194458\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1316, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3992, 23.6939, 24.4724],\n",
      "        [27.9799, 23.4752, 24.5343],\n",
      "        [28.0645, 23.5211, 23.9883],\n",
      "        [28.3204, 23.7220, 24.2999],\n",
      "        [27.8096, 23.5994, 24.1260],\n",
      "        [28.0700, 23.5717, 24.1191]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8389, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2758,  28.8896, -24.6869],\n",
      "        [-26.6862,  27.9155, -23.2808],\n",
      "        [-27.6088,  29.1295, -25.1862],\n",
      "        [-26.8192,  28.5403, -24.2330],\n",
      "        [-27.8489,  29.0998, -24.4948],\n",
      "        [-26.6556,  27.5667, -23.7446]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3992,  23.6939,  24.4724, -27.2758,  28.8896, -24.6869],\n",
      "        [ 27.9799,  23.4752,  24.5343, -26.6862,  27.9155, -23.2808],\n",
      "        [ 28.0645,  23.5211,  23.9883, -27.6088,  29.1295, -25.1862],\n",
      "        [ 28.3204,  23.7220,  24.2999, -26.8192,  28.5403, -24.2330],\n",
      "        [ 27.8096,  23.5994,  24.1260, -27.8489,  29.0998, -24.4948],\n",
      "        [ 28.0700,  23.5717,  24.1191, -26.6556,  27.5667, -23.7446]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.596540927886963\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0870, 23.1549, 24.0778],\n",
      "        [28.2113, 23.2222, 24.3249],\n",
      "        [27.5953, 23.1782, 23.9081],\n",
      "        [28.4509, 23.7202, 24.4985],\n",
      "        [28.5620, 23.9428, 24.6305],\n",
      "        [28.1054, 23.6716, 23.8860]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4863, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2621,  28.2271, -24.3712],\n",
      "        [-27.0550,  28.2075, -24.1772],\n",
      "        [-27.2863,  28.1122, -24.1151],\n",
      "        [-27.0860,  28.3424, -24.1833],\n",
      "        [-27.1919,  28.2186, -24.2095],\n",
      "        [-27.1148,  28.5207, -24.3766]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0870,  23.1549,  24.0778, -27.2621,  28.2271, -24.3712],\n",
      "        [ 28.2113,  23.2222,  24.3249, -27.0550,  28.2075, -24.1772],\n",
      "        [ 27.5953,  23.1782,  23.9081, -27.2863,  28.1122, -24.1151],\n",
      "        [ 28.4509,  23.7202,  24.4985, -27.0860,  28.3424, -24.1833],\n",
      "        [ 28.5620,  23.9428,  24.6305, -27.1919,  28.2186, -24.2095],\n",
      "        [ 28.1054,  23.6716,  23.8860, -27.1148,  28.5207, -24.3766]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.5052056312561035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4686, 23.6921, 24.3056],\n",
      "        [27.8717, 23.0601, 23.9926],\n",
      "        [29.3455, 24.5636, 25.2738],\n",
      "        [28.2361, 23.8066, 24.1833],\n",
      "        [28.5963, 23.4476, 24.2485],\n",
      "        [28.3594, 23.4925, 24.3359]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.6306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2602,  28.1260, -24.2525],\n",
      "        [-26.6325,  28.5658, -24.3775],\n",
      "        [-27.7154,  28.6752, -24.8456],\n",
      "        [-27.1038,  28.1214, -23.8723],\n",
      "        [-27.7731,  28.6127, -24.5243],\n",
      "        [-26.5601,  28.4535, -24.0527]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4686,  23.6921,  24.3056, -27.2602,  28.1260, -24.2525],\n",
      "        [ 27.8717,  23.0601,  23.9926, -26.6325,  28.5658, -24.3775],\n",
      "        [ 29.3455,  24.5636,  25.2738, -27.7154,  28.6752, -24.8456],\n",
      "        [ 28.2361,  23.8066,  24.1833, -27.1038,  28.1214, -23.8723],\n",
      "        [ 28.5963,  23.4476,  24.2485, -27.7731,  28.6127, -24.5243],\n",
      "        [ 28.3594,  23.4925,  24.3359, -26.5601,  28.4535, -24.0527]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.552359580993652\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7835, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9794, 23.5306, 24.1697],\n",
      "        [27.9611, 23.0208, 23.9375],\n",
      "        [28.2682, 23.6930, 24.6286],\n",
      "        [28.4392, 24.0681, 24.4404],\n",
      "        [28.0231, 23.5326, 23.8709],\n",
      "        [27.9052, 23.3843, 23.9166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.4142, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2016,  27.9423, -24.1715],\n",
      "        [-27.2490,  28.5223, -24.2977],\n",
      "        [-27.2453,  28.5355, -24.4465],\n",
      "        [-27.2793,  28.9912, -24.7401],\n",
      "        [-27.0546,  28.6141, -24.1399],\n",
      "        [-27.7118,  28.6775, -24.6301]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9794,  23.5306,  24.1697, -27.2016,  27.9423, -24.1715],\n",
      "        [ 27.9611,  23.0208,  23.9375, -27.2490,  28.5223, -24.2977],\n",
      "        [ 28.2682,  23.6930,  24.6286, -27.2453,  28.5355, -24.4465],\n",
      "        [ 28.4392,  24.0681,  24.4404, -27.2793,  28.9912, -24.7401],\n",
      "        [ 28.0231,  23.5326,  23.8709, -27.0546,  28.6141, -24.1399],\n",
      "        [ 27.9052,  23.3843,  23.9166, -27.7118,  28.6775, -24.6301]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.502106189727783\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.2460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1853, 23.2538, 23.7732],\n",
      "        [28.6810, 24.1090, 24.2772],\n",
      "        [28.3249, 23.7604, 24.4607],\n",
      "        [28.0911, 23.2742, 23.8293],\n",
      "        [28.4636, 23.9204, 24.4303],\n",
      "        [27.7466, 23.8153, 24.1203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.0201, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8176,  28.3456, -24.1491],\n",
      "        [-27.3191,  28.4880, -24.2774],\n",
      "        [-26.1473,  27.5297, -23.6288],\n",
      "        [-26.9036,  28.5434, -24.6431],\n",
      "        [-27.3629,  28.3785, -24.3833],\n",
      "        [-26.6298,  27.6764, -23.9945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1853,  23.2538,  23.7732, -26.8176,  28.3456, -24.1491],\n",
      "        [ 28.6810,  24.1090,  24.2772, -27.3191,  28.4880, -24.2774],\n",
      "        [ 28.3249,  23.7604,  24.4607, -26.1473,  27.5297, -23.6288],\n",
      "        [ 28.0911,  23.2742,  23.8293, -26.9036,  28.5434, -24.6431],\n",
      "        [ 28.4636,  23.9204,  24.4303, -27.3629,  28.3785, -24.3833],\n",
      "        [ 27.7466,  23.8153,  24.1203, -26.6298,  27.6764, -23.9945]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.43035888671875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1129, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4411, 23.9837, 24.1964],\n",
      "        [27.9881, 23.5564, 24.0918],\n",
      "        [28.0562, 23.6306, 24.0258],\n",
      "        [28.6586, 23.7015, 24.4428],\n",
      "        [28.0031, 23.2086, 24.0518],\n",
      "        [28.2659, 24.1568, 24.2195]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(44.7806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1017,  28.7860, -24.5026],\n",
      "        [-27.2843,  28.7959, -24.3689],\n",
      "        [-27.3912,  28.7919, -24.5896],\n",
      "        [-26.6135,  27.1416, -24.0737],\n",
      "        [-26.9932,  28.1317, -24.2050],\n",
      "        [-27.5487,  28.4815, -24.7757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4411,  23.9837,  24.1964, -27.1017,  28.7860, -24.5026],\n",
      "        [ 27.9881,  23.5564,  24.0918, -27.2843,  28.7959, -24.3689],\n",
      "        [ 28.0562,  23.6306,  24.0258, -27.3912,  28.7919, -24.5896],\n",
      "        [ 28.6586,  23.7015,  24.4428, -26.6135,  27.1416, -24.0737],\n",
      "        [ 28.0031,  23.2086,  24.0518, -26.9932,  28.1317, -24.2050],\n",
      "        [ 28.2659,  24.1568,  24.2195, -27.5487,  28.4815, -24.7757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.590467929840088\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2749, 23.7899, 24.7843],\n",
      "        [28.1076, 23.4834, 24.2238],\n",
      "        [28.5485, 24.0256, 24.7625],\n",
      "        [28.4370, 24.1272, 24.7427],\n",
      "        [28.8321, 23.9545, 24.5735],\n",
      "        [28.2508, 23.6973, 24.0305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.5077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8359,  28.4911, -24.4112],\n",
      "        [-27.4514,  28.7587, -24.8274],\n",
      "        [-26.6839,  27.8350, -23.5604],\n",
      "        [-26.9339,  28.0913, -24.0430],\n",
      "        [-27.2220,  28.4519, -24.4781],\n",
      "        [-27.8753,  28.9892, -24.9592]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2749,  23.7899,  24.7843, -26.8359,  28.4911, -24.4112],\n",
      "        [ 28.1076,  23.4834,  24.2238, -27.4514,  28.7587, -24.8274],\n",
      "        [ 28.5485,  24.0256,  24.7625, -26.6839,  27.8350, -23.5604],\n",
      "        [ 28.4370,  24.1272,  24.7427, -26.9339,  28.0913, -24.0430],\n",
      "        [ 28.8321,  23.9545,  24.5735, -27.2220,  28.4519, -24.4781],\n",
      "        [ 28.2508,  23.6973,  24.0305, -27.8753,  28.9892, -24.9592]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.579873085021973\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5925, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.6831, 23.0770, 23.7341],\n",
      "        [28.4019, 23.5454, 24.3928],\n",
      "        [28.0125, 23.7850, 23.9274],\n",
      "        [27.8571, 23.5046, 24.1658],\n",
      "        [27.9005, 23.2237, 23.5700],\n",
      "        [28.3736, 24.0475, 24.3900]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.4523, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3090,  28.7183, -24.2932],\n",
      "        [-27.3463,  28.6962, -24.6117],\n",
      "        [-27.6999,  28.9946, -24.9074],\n",
      "        [-27.2471,  28.5371, -24.0799],\n",
      "        [-26.7278,  28.0201, -23.9877],\n",
      "        [-27.5330,  28.9004, -24.4364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.6831,  23.0770,  23.7341, -27.3090,  28.7183, -24.2932],\n",
      "        [ 28.4019,  23.5454,  24.3928, -27.3463,  28.6962, -24.6117],\n",
      "        [ 28.0125,  23.7850,  23.9274, -27.6999,  28.9946, -24.9074],\n",
      "        [ 27.8571,  23.5046,  24.1658, -27.2471,  28.5371, -24.0799],\n",
      "        [ 27.9005,  23.2237,  23.5700, -26.7278,  28.0201, -23.9877],\n",
      "        [ 28.3736,  24.0475,  24.3900, -27.5330,  28.9004, -24.4364]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.493351936340332\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4147, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3276, 23.9031, 24.1800],\n",
      "        [28.6267, 23.8914, 24.4618],\n",
      "        [28.2848, 23.7555, 24.4427],\n",
      "        [28.2681, 23.7199, 24.4414],\n",
      "        [28.6156, 24.3088, 24.7455],\n",
      "        [28.6757, 23.7485, 24.5066]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.3155, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.5682,  27.6083, -23.6178],\n",
      "        [-27.4387,  28.2679, -24.2783],\n",
      "        [-26.9956,  28.3435, -24.4365],\n",
      "        [-27.0887,  28.3615, -24.0623],\n",
      "        [-26.5317,  27.7343, -23.6893],\n",
      "        [-27.3300,  28.1924, -24.8434]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3276,  23.9031,  24.1800, -26.5682,  27.6083, -23.6178],\n",
      "        [ 28.6267,  23.8914,  24.4618, -27.4387,  28.2679, -24.2783],\n",
      "        [ 28.2848,  23.7555,  24.4427, -26.9956,  28.3435, -24.4365],\n",
      "        [ 28.2681,  23.7199,  24.4414, -27.0887,  28.3615, -24.0623],\n",
      "        [ 28.6156,  24.3088,  24.7455, -26.5317,  27.7343, -23.6893],\n",
      "        [ 28.6757,  23.7485,  24.5066, -27.3300,  28.1924, -24.8434]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.492456436157227\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7811, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3067, 23.7393, 24.0757],\n",
      "        [27.9825, 23.4687, 24.0569],\n",
      "        [28.1305, 23.5715, 24.3817],\n",
      "        [28.6620, 23.9930, 24.4230],\n",
      "        [28.1773, 23.5000, 24.2483],\n",
      "        [28.3493, 23.9570, 24.4732]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.1393, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4065,  28.2213, -24.0627],\n",
      "        [-27.1529,  28.4345, -24.3482],\n",
      "        [-27.3103,  28.3641, -24.2185],\n",
      "        [-26.9672,  27.9510, -23.8129],\n",
      "        [-27.3909,  28.6110, -24.0375],\n",
      "        [-26.5978,  27.9517, -24.1682]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3067,  23.7393,  24.0757, -27.4065,  28.2213, -24.0627],\n",
      "        [ 27.9825,  23.4687,  24.0569, -27.1529,  28.4345, -24.3482],\n",
      "        [ 28.1305,  23.5715,  24.3817, -27.3103,  28.3641, -24.2185],\n",
      "        [ 28.6620,  23.9930,  24.4230, -26.9672,  27.9510, -23.8129],\n",
      "        [ 28.1773,  23.5000,  24.2483, -27.3909,  28.6110, -24.0375],\n",
      "        [ 28.3493,  23.9570,  24.4732, -26.5978,  27.9517, -24.1682]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.5511980056762695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4123, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.9763, 23.5186, 24.5238],\n",
      "        [28.5519, 24.0857, 24.2710],\n",
      "        [28.0331, 23.9382, 24.2312],\n",
      "        [28.5632, 23.7208, 24.7223],\n",
      "        [28.2711, 23.8735, 24.5478],\n",
      "        [28.3065, 23.7751, 24.6349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.4656, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4196,  28.6148, -24.3014],\n",
      "        [-27.0032,  27.6406, -23.7654],\n",
      "        [-26.9708,  27.7881, -23.8854],\n",
      "        [-26.7284,  27.9432, -24.3008],\n",
      "        [-27.4368,  28.6924, -24.4249],\n",
      "        [-27.5942,  28.7323, -24.7811]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.9763,  23.5186,  24.5238, -27.4196,  28.6148, -24.3014],\n",
      "        [ 28.5519,  24.0857,  24.2710, -27.0032,  27.6406, -23.7654],\n",
      "        [ 28.0331,  23.9382,  24.2312, -26.9708,  27.7881, -23.8854],\n",
      "        [ 28.5632,  23.7208,  24.7223, -26.7284,  27.9432, -24.3008],\n",
      "        [ 28.2711,  23.8735,  24.5478, -27.4368,  28.6924, -24.4249],\n",
      "        [ 28.3065,  23.7751,  24.6349, -27.5942,  28.7323, -24.7811]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.571228981018066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2921, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1536, 23.8506, 24.3885],\n",
      "        [28.3494, 23.6196, 23.9627],\n",
      "        [28.7297, 23.7715, 24.5612],\n",
      "        [28.1879, 23.3197, 24.2013],\n",
      "        [28.6446, 23.8205, 24.7243],\n",
      "        [28.6033, 24.0317, 24.6200]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.1092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7231,  28.6996, -24.5965],\n",
      "        [-26.7154,  28.0056, -24.1345],\n",
      "        [-27.0757,  28.2524, -24.3719],\n",
      "        [-26.9984,  28.0853, -23.9678],\n",
      "        [-27.6700,  28.9657, -24.6655],\n",
      "        [-27.1061,  28.3625, -23.9505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1536,  23.8506,  24.3885, -27.7231,  28.6996, -24.5965],\n",
      "        [ 28.3494,  23.6196,  23.9627, -26.7154,  28.0056, -24.1345],\n",
      "        [ 28.7297,  23.7715,  24.5612, -27.0757,  28.2524, -24.3719],\n",
      "        [ 28.1879,  23.3197,  24.2013, -26.9984,  28.0853, -23.9678],\n",
      "        [ 28.6446,  23.8205,  24.7243, -27.6700,  28.9657, -24.6655],\n",
      "        [ 28.6033,  24.0317,  24.6200, -27.1061,  28.3625, -23.9505]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.613278865814209\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4694, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.3490, 23.0429, 23.8526],\n",
      "        [28.2996, 23.6672, 24.5766],\n",
      "        [27.8343, 23.5142, 24.2478],\n",
      "        [28.2705, 23.7685, 24.3402],\n",
      "        [27.8460, 23.1912, 23.8671],\n",
      "        [28.8436, 24.1194, 25.0375]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.2815, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5804,  29.0881, -24.7789],\n",
      "        [-27.2500,  28.2999, -24.3355],\n",
      "        [-27.0642,  28.6185, -24.1102],\n",
      "        [-27.8993,  29.2226, -24.9299],\n",
      "        [-27.7099,  29.0174, -24.8003],\n",
      "        [-26.5607,  28.5211, -24.3323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.3490,  23.0429,  23.8526, -27.5804,  29.0881, -24.7789],\n",
      "        [ 28.2996,  23.6672,  24.5766, -27.2500,  28.2999, -24.3355],\n",
      "        [ 27.8343,  23.5142,  24.2478, -27.0642,  28.6185, -24.1102],\n",
      "        [ 28.2705,  23.7685,  24.3402, -27.8993,  29.2226, -24.9299],\n",
      "        [ 27.8460,  23.1912,  23.8671, -27.7099,  29.0174, -24.8003],\n",
      "        [ 28.8436,  24.1194,  25.0375, -26.5607,  28.5211, -24.3323]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.528801918029785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3496, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1255, 23.8354, 24.4960],\n",
      "        [27.8395, 23.6708, 23.9008],\n",
      "        [28.1160, 23.5745, 24.2668],\n",
      "        [28.1395, 23.8722, 24.4455],\n",
      "        [28.2085, 23.9289, 23.9477],\n",
      "        [28.1894, 23.7759, 24.1732]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.3810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0141,  28.5552, -24.5838],\n",
      "        [-27.2662,  28.5315, -24.2784],\n",
      "        [-27.3345,  29.1062, -24.5424],\n",
      "        [-26.7002,  27.7088, -23.8931],\n",
      "        [-27.3331,  28.4496, -24.1856],\n",
      "        [-26.6031,  27.5376, -23.5559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1255,  23.8354,  24.4960, -27.0141,  28.5552, -24.5838],\n",
      "        [ 27.8395,  23.6708,  23.9008, -27.2662,  28.5315, -24.2784],\n",
      "        [ 28.1160,  23.5745,  24.2668, -27.3345,  29.1062, -24.5424],\n",
      "        [ 28.1395,  23.8722,  24.4455, -26.7002,  27.7088, -23.8931],\n",
      "        [ 28.2085,  23.9289,  23.9477, -27.3331,  28.4496, -24.1856],\n",
      "        [ 28.1894,  23.7759,  24.1732, -26.6031,  27.5376, -23.5559]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.587972640991211\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3795, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.7668, 23.0013, 24.2080],\n",
      "        [28.2524, 23.7409, 24.2166],\n",
      "        [28.5979, 24.0231, 24.5289],\n",
      "        [27.4509, 23.5737, 24.1276],\n",
      "        [28.4447, 23.6386, 24.4727],\n",
      "        [28.4635, 24.0334, 24.6465]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.6719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4610,  28.4930, -24.5975],\n",
      "        [-27.0285,  28.0865, -24.0258],\n",
      "        [-27.2398,  27.9890, -24.1043],\n",
      "        [-26.8570,  28.1995, -23.9864],\n",
      "        [-27.8058,  28.7914, -24.7924],\n",
      "        [-27.1986,  28.7411, -24.4658]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.7668,  23.0013,  24.2080, -27.4610,  28.4930, -24.5975],\n",
      "        [ 28.2524,  23.7409,  24.2166, -27.0285,  28.0865, -24.0258],\n",
      "        [ 28.5979,  24.0231,  24.5289, -27.2398,  27.9890, -24.1043],\n",
      "        [ 27.4509,  23.5737,  24.1276, -26.8570,  28.1995, -23.9864],\n",
      "        [ 28.4447,  23.6386,  24.4727, -27.8058,  28.7914, -24.7924],\n",
      "        [ 28.4635,  24.0334,  24.6465, -27.1986,  28.7411, -24.4658]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.538675308227539\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.1175, 23.0538, 23.8372],\n",
      "        [28.3859, 24.3033, 24.3630],\n",
      "        [29.0140, 24.1356, 24.9780],\n",
      "        [28.5977, 24.1270, 24.6240],\n",
      "        [28.0961, 23.4898, 24.6041],\n",
      "        [28.6467, 23.7574, 24.5848]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8287, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2112,  28.2654, -24.8226],\n",
      "        [-26.7379,  28.0501, -24.3002],\n",
      "        [-27.7130,  28.6378, -24.4139],\n",
      "        [-26.8278,  28.2292, -24.0854],\n",
      "        [-27.1867,  28.3473, -24.0355],\n",
      "        [-27.4146,  28.1923, -24.4459]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.1175,  23.0538,  23.8372, -27.2112,  28.2654, -24.8226],\n",
      "        [ 28.3859,  24.3033,  24.3630, -26.7379,  28.0501, -24.3002],\n",
      "        [ 29.0140,  24.1356,  24.9780, -27.7130,  28.6378, -24.4139],\n",
      "        [ 28.5977,  24.1270,  24.6240, -26.8278,  28.2292, -24.0854],\n",
      "        [ 28.0961,  23.4898,  24.6041, -27.1867,  28.3473, -24.0355],\n",
      "        [ 28.6467,  23.7574,  24.5848, -27.4146,  28.1923, -24.4459]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.476741790771484\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1280, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3813, 23.6939, 24.4627],\n",
      "        [28.1375, 24.2853, 24.1994],\n",
      "        [28.0196, 23.5973, 23.9895],\n",
      "        [28.4952, 24.3098, 24.5401],\n",
      "        [28.2646, 23.1160, 24.3623],\n",
      "        [28.9404, 24.2487, 24.8652]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.7538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0752,  28.4947, -24.7030],\n",
      "        [-27.0527,  28.0674, -24.0985],\n",
      "        [-27.5967,  28.7053, -24.4510],\n",
      "        [-27.4272,  28.4668, -24.7307],\n",
      "        [-27.8716,  29.1914, -25.0177],\n",
      "        [-27.4754,  28.6855, -24.5974]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3813,  23.6939,  24.4627, -27.0752,  28.4947, -24.7030],\n",
      "        [ 28.1375,  24.2853,  24.1994, -27.0527,  28.0674, -24.0985],\n",
      "        [ 28.0196,  23.5973,  23.9895, -27.5967,  28.7053, -24.4510],\n",
      "        [ 28.4952,  24.3098,  24.5401, -27.4272,  28.4668, -24.7307],\n",
      "        [ 28.2646,  23.1160,  24.3623, -27.8716,  29.1914, -25.0177],\n",
      "        [ 28.9404,  24.2487,  24.8652, -27.4754,  28.6855, -24.5974]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.605281352996826\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5601, 24.2957, 24.8959],\n",
      "        [28.2218, 23.3967, 24.2319],\n",
      "        [28.4212, 23.5006, 24.5371],\n",
      "        [27.7986, 23.4193, 24.0969],\n",
      "        [28.7291, 24.4560, 24.6351],\n",
      "        [28.7762, 24.2315, 25.1341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.0353, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2596,  28.4569, -24.6831],\n",
      "        [-27.0742,  27.9601, -24.1368],\n",
      "        [-26.8389,  28.4093, -24.1118],\n",
      "        [-27.3678,  28.8917, -24.4959],\n",
      "        [-27.1004,  28.5871, -24.4096],\n",
      "        [-27.7891,  29.1304, -25.0773]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5601,  24.2957,  24.8959, -27.2596,  28.4569, -24.6831],\n",
      "        [ 28.2218,  23.3967,  24.2319, -27.0742,  27.9601, -24.1368],\n",
      "        [ 28.4212,  23.5006,  24.5371, -26.8389,  28.4093, -24.1118],\n",
      "        [ 27.7986,  23.4193,  24.0969, -27.3678,  28.8917, -24.4959],\n",
      "        [ 28.7291,  24.4560,  24.6351, -27.1004,  28.5871, -24.4096],\n",
      "        [ 28.7762,  24.2315,  25.1341, -27.7891,  29.1304, -25.0773]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.666057586669922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6462, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2053, 23.8960, 24.4546],\n",
      "        [28.0648, 23.4551, 24.3525],\n",
      "        [28.2769, 23.5874, 23.9973],\n",
      "        [28.6830, 24.3519, 24.7278],\n",
      "        [28.6904, 23.6742, 24.2588],\n",
      "        [28.5344, 24.1196, 24.4667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.5149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5711,  29.3440, -24.9770],\n",
      "        [-27.4557,  29.0843, -24.7084],\n",
      "        [-27.6779,  28.7953, -24.5844],\n",
      "        [-27.6097,  29.0080, -24.7219],\n",
      "        [-27.5450,  28.6398, -24.6375],\n",
      "        [-27.2927,  28.2235, -24.3937]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2053,  23.8960,  24.4546, -27.5711,  29.3440, -24.9770],\n",
      "        [ 28.0648,  23.4551,  24.3525, -27.4557,  29.0843, -24.7084],\n",
      "        [ 28.2769,  23.5874,  23.9973, -27.6779,  28.7953, -24.5844],\n",
      "        [ 28.6830,  24.3519,  24.7278, -27.6097,  29.0080, -24.7219],\n",
      "        [ 28.6904,  23.6742,  24.2588, -27.5450,  28.6398, -24.6375],\n",
      "        [ 28.5344,  24.1196,  24.4667, -27.2927,  28.2235, -24.3937]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.667142391204834\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3986, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5339, 23.9391, 24.8279],\n",
      "        [28.0657, 23.6825, 24.0915],\n",
      "        [28.5875, 23.8862, 24.9807],\n",
      "        [28.5670, 24.0186, 24.5548],\n",
      "        [28.1053, 23.6865, 24.3302],\n",
      "        [28.7506, 24.1954, 24.6420]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.8719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8396,  28.3336, -24.8404],\n",
      "        [-27.1842,  28.6672, -24.6528],\n",
      "        [-27.0614,  28.2757, -24.1211],\n",
      "        [-27.5895,  28.5783, -24.6266],\n",
      "        [-27.4960,  28.6739, -24.5360],\n",
      "        [-27.6404,  28.8917, -24.7023]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5339,  23.9391,  24.8279, -26.8396,  28.3336, -24.8404],\n",
      "        [ 28.0657,  23.6825,  24.0915, -27.1842,  28.6672, -24.6528],\n",
      "        [ 28.5875,  23.8862,  24.9807, -27.0614,  28.2757, -24.1211],\n",
      "        [ 28.5670,  24.0186,  24.5548, -27.5895,  28.5783, -24.6266],\n",
      "        [ 28.1053,  23.6865,  24.3302, -27.4960,  28.6739, -24.5360],\n",
      "        [ 28.7506,  24.1954,  24.6420, -27.6404,  28.8917, -24.7023]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.636329650878906\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.8590, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2036, 23.9341, 24.1817],\n",
      "        [28.5128, 23.8327, 24.3330],\n",
      "        [28.5854, 24.1394, 24.6860],\n",
      "        [28.5489, 24.2414, 24.6855],\n",
      "        [28.4608, 23.9275, 24.4492],\n",
      "        [28.4731, 23.2827, 24.4666]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.6264, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3744,  28.6625, -24.2125],\n",
      "        [-26.8652,  28.0307, -23.9467],\n",
      "        [-27.3797,  28.8337, -24.5166],\n",
      "        [-27.2618,  28.1904, -24.3819],\n",
      "        [-27.3207,  27.8681, -24.0183],\n",
      "        [-27.4491,  28.5226, -24.4416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2036,  23.9341,  24.1817, -27.3744,  28.6625, -24.2125],\n",
      "        [ 28.5128,  23.8327,  24.3330, -26.8652,  28.0307, -23.9467],\n",
      "        [ 28.5854,  24.1394,  24.6860, -27.3797,  28.8337, -24.5166],\n",
      "        [ 28.5489,  24.2414,  24.6855, -27.2618,  28.1904, -24.3819],\n",
      "        [ 28.4608,  23.9275,  24.4492, -27.3207,  27.8681, -24.0183],\n",
      "        [ 28.4731,  23.2827,  24.4666, -27.4491,  28.5226, -24.4416]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.6009840965271\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7215, 23.6919, 24.7436],\n",
      "        [27.8147, 23.6968, 24.3688],\n",
      "        [28.4210, 24.1688, 24.2482],\n",
      "        [28.3719, 24.3368, 24.6299],\n",
      "        [27.8103, 23.3274, 24.3084],\n",
      "        [28.7078, 24.0329, 24.5311]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.5149, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0709,  28.5237, -24.7432],\n",
      "        [-27.5952,  28.6380, -24.6055],\n",
      "        [-27.1961,  28.9239, -24.8868],\n",
      "        [-27.7337,  28.9868, -24.6254],\n",
      "        [-26.4304,  27.7874, -23.7836],\n",
      "        [-26.9110,  27.9730, -24.4057]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7215,  23.6919,  24.7436, -27.0709,  28.5237, -24.7432],\n",
      "        [ 27.8147,  23.6968,  24.3688, -27.5952,  28.6380, -24.6055],\n",
      "        [ 28.4210,  24.1688,  24.2482, -27.1961,  28.9239, -24.8868],\n",
      "        [ 28.3719,  24.3368,  24.6299, -27.7337,  28.9868, -24.6254],\n",
      "        [ 27.8103,  23.3274,  24.3084, -26.4304,  27.7874, -23.7836],\n",
      "        [ 28.7078,  24.0329,  24.5311, -26.9110,  27.9730, -24.4057]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.650601863861084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5230, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4439, 23.5578, 24.4115],\n",
      "        [28.2647, 23.7715, 24.1011],\n",
      "        [27.9493, 23.7193, 24.0912],\n",
      "        [28.2695, 23.7757, 24.7487],\n",
      "        [28.8292, 24.5091, 24.7291],\n",
      "        [28.0951, 23.4633, 24.2428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.3441, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.2918,  27.6174, -23.5303],\n",
      "        [-27.9688,  28.8845, -24.8519],\n",
      "        [-26.9327,  28.3814, -24.1270],\n",
      "        [-27.2322,  28.5394, -24.5369],\n",
      "        [-27.0673,  28.5699, -24.3070],\n",
      "        [-26.4630,  28.1166, -23.8147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4439,  23.5578,  24.4115, -26.2918,  27.6174, -23.5303],\n",
      "        [ 28.2647,  23.7715,  24.1011, -27.9688,  28.8845, -24.8519],\n",
      "        [ 27.9493,  23.7193,  24.0912, -26.9327,  28.3814, -24.1270],\n",
      "        [ 28.2695,  23.7757,  24.7487, -27.2322,  28.5394, -24.5369],\n",
      "        [ 28.8292,  24.5091,  24.7291, -27.0673,  28.5699, -24.3070],\n",
      "        [ 28.0951,  23.4633,  24.2428, -26.4630,  28.1166, -23.8147]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.512415409088135\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8398, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2079, 23.6038, 24.1819],\n",
      "        [27.9864, 23.6194, 24.0627],\n",
      "        [28.5871, 24.1865, 24.3114],\n",
      "        [28.3127, 24.2073, 24.7459],\n",
      "        [28.0192, 23.6000, 24.0375],\n",
      "        [28.4416, 23.9410, 24.5400]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.3507, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3215,  28.4554, -24.0500],\n",
      "        [-27.5755,  28.4483, -24.5021],\n",
      "        [-27.0808,  28.3684, -24.2668],\n",
      "        [-27.4705,  28.6128, -24.6968],\n",
      "        [-27.7852,  29.0093, -25.2142],\n",
      "        [-27.2996,  28.1125, -24.3241]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2079,  23.6038,  24.1819, -27.3215,  28.4554, -24.0500],\n",
      "        [ 27.9864,  23.6194,  24.0627, -27.5755,  28.4483, -24.5021],\n",
      "        [ 28.5871,  24.1865,  24.3114, -27.0808,  28.3684, -24.2668],\n",
      "        [ 28.3127,  24.2073,  24.7459, -27.4705,  28.6128, -24.6968],\n",
      "        [ 28.0192,  23.6000,  24.0375, -27.7852,  29.0093, -25.2142],\n",
      "        [ 28.4416,  23.9410,  24.5400, -27.2996,  28.1125, -24.3241]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.579479217529297\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9460, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4329, 23.9700, 24.6374],\n",
      "        [28.5069, 23.6996, 24.4855],\n",
      "        [28.1429, 23.2806, 24.3043],\n",
      "        [28.2706, 23.9014, 24.1338],\n",
      "        [28.3942, 23.7474, 24.4416],\n",
      "        [28.6866, 23.9940, 24.6924]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.2761, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3735,  28.7333, -24.8644],\n",
      "        [-27.2101,  28.4591, -24.2580],\n",
      "        [-27.9503,  28.7112, -24.9886],\n",
      "        [-26.9867,  28.2030, -24.3187],\n",
      "        [-27.3279,  28.8239, -24.6827],\n",
      "        [-27.3896,  28.3483, -24.4660]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4329,  23.9700,  24.6374, -27.3735,  28.7333, -24.8644],\n",
      "        [ 28.5069,  23.6996,  24.4855, -27.2101,  28.4591, -24.2580],\n",
      "        [ 28.1429,  23.2806,  24.3043, -27.9503,  28.7112, -24.9886],\n",
      "        [ 28.2706,  23.9014,  24.1338, -26.9867,  28.2030, -24.3187],\n",
      "        [ 28.3942,  23.7474,  24.4416, -27.3279,  28.8239, -24.6827],\n",
      "        [ 28.6866,  23.9940,  24.6924, -27.3896,  28.3483, -24.4660]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.669119834899902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5532, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7552, 23.9096, 24.5591],\n",
      "        [28.5511, 23.7923, 24.5533],\n",
      "        [27.6613, 23.3684, 24.2222],\n",
      "        [28.6248, 23.7676, 24.3583],\n",
      "        [28.3456, 23.4260, 24.5059],\n",
      "        [28.1427, 24.1953, 24.4016]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.6305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5135,  28.2869, -24.3312],\n",
      "        [-27.4217,  28.3760, -25.1463],\n",
      "        [-27.6293,  29.0451, -24.8532],\n",
      "        [-27.2318,  28.5288, -24.1454],\n",
      "        [-28.1873,  29.3401, -25.4611],\n",
      "        [-27.2144,  28.6897, -25.1383]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7552,  23.9096,  24.5591, -27.5135,  28.2869, -24.3312],\n",
      "        [ 28.5511,  23.7923,  24.5533, -27.4217,  28.3760, -25.1463],\n",
      "        [ 27.6613,  23.3684,  24.2222, -27.6293,  29.0451, -24.8532],\n",
      "        [ 28.6248,  23.7676,  24.3583, -27.2318,  28.5288, -24.1454],\n",
      "        [ 28.3456,  23.4260,  24.5059, -28.1873,  29.3401, -25.4611],\n",
      "        [ 28.1427,  24.1953,  24.4016, -27.2144,  28.6897, -25.1383]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.654102325439453\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2657, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5784, 23.7505, 24.7274],\n",
      "        [28.2336, 23.6433, 24.4198],\n",
      "        [28.8671, 24.4148, 24.9115],\n",
      "        [28.3127, 23.9966, 24.6819],\n",
      "        [28.3943, 24.1282, 24.5901],\n",
      "        [28.9301, 24.0066, 24.9451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8224, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4151,  28.2811, -24.1499],\n",
      "        [-26.8440,  27.9667, -24.2310],\n",
      "        [-26.8678,  27.9849, -23.6826],\n",
      "        [-27.0957,  28.4068, -24.7303],\n",
      "        [-27.3399,  28.5328, -24.3921],\n",
      "        [-26.9519,  27.9733, -24.2595]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5784,  23.7505,  24.7274, -27.4151,  28.2811, -24.1499],\n",
      "        [ 28.2336,  23.6433,  24.4198, -26.8440,  27.9667, -24.2310],\n",
      "        [ 28.8671,  24.4148,  24.9115, -26.8678,  27.9849, -23.6826],\n",
      "        [ 28.3127,  23.9966,  24.6819, -27.0957,  28.4068, -24.7303],\n",
      "        [ 28.3943,  24.1282,  24.5901, -27.3399,  28.5328, -24.3921],\n",
      "        [ 28.9301,  24.0066,  24.9451, -26.9519,  27.9733, -24.2595]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.638518333435059\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4175, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4686, 24.0966, 24.5536],\n",
      "        [27.8391, 23.2745, 24.3480],\n",
      "        [28.4112, 23.7875, 24.6010],\n",
      "        [28.2403, 23.7420, 24.3608],\n",
      "        [28.8233, 23.8560, 24.8196],\n",
      "        [28.2587, 24.0715, 24.4557]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.0427, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4509,  28.4376, -24.4393],\n",
      "        [-27.8120,  29.4207, -25.2188],\n",
      "        [-27.2822,  28.9476, -24.8990],\n",
      "        [-26.9112,  28.2844, -24.3190],\n",
      "        [-27.2500,  28.3854, -24.6817],\n",
      "        [-27.3350,  28.4168, -24.6536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4686,  24.0966,  24.5536, -27.4509,  28.4376, -24.4393],\n",
      "        [ 27.8391,  23.2745,  24.3480, -27.8120,  29.4207, -25.2188],\n",
      "        [ 28.4112,  23.7875,  24.6010, -27.2822,  28.9476, -24.8990],\n",
      "        [ 28.2403,  23.7420,  24.3608, -26.9112,  28.2844, -24.3190],\n",
      "        [ 28.8233,  23.8560,  24.8196, -27.2500,  28.3854, -24.6817],\n",
      "        [ 28.2587,  24.0715,  24.4557, -27.3350,  28.4168, -24.6536]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.655755996704102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8696, 24.0670, 24.8168],\n",
      "        [28.6293, 24.0289, 24.5517],\n",
      "        [28.7814, 24.3439, 24.4303],\n",
      "        [28.2663, 23.9237, 24.3790],\n",
      "        [28.1984, 23.9556, 24.1079],\n",
      "        [28.5558, 23.6531, 24.4203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.6219, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2707,  28.5727, -24.7572],\n",
      "        [-26.7386,  28.1646, -24.2948],\n",
      "        [-27.6334,  28.7272, -24.7589],\n",
      "        [-27.5021,  28.6824, -24.8329],\n",
      "        [-27.1299,  28.1756, -24.3179],\n",
      "        [-27.1607,  28.1139, -24.2840]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8696,  24.0670,  24.8168, -27.2707,  28.5727, -24.7572],\n",
      "        [ 28.6293,  24.0289,  24.5517, -26.7386,  28.1646, -24.2948],\n",
      "        [ 28.7814,  24.3439,  24.4303, -27.6334,  28.7272, -24.7589],\n",
      "        [ 28.2663,  23.9237,  24.3790, -27.5021,  28.6824, -24.8329],\n",
      "        [ 28.1984,  23.9556,  24.1079, -27.1299,  28.1756, -24.3179],\n",
      "        [ 28.5558,  23.6531,  24.4203, -27.1607,  28.1139, -24.2840]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.701010704040527\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0296, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7789, 24.2023, 24.9640],\n",
      "        [28.1616, 23.7235, 24.1174],\n",
      "        [28.2887, 24.1531, 24.4588],\n",
      "        [28.6148, 23.5168, 24.2863],\n",
      "        [27.5330, 22.7824, 23.7676],\n",
      "        [28.1008, 23.3879, 24.2448]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.9437, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7910,  28.8792, -24.8388],\n",
      "        [-27.6725,  28.6533, -24.7334],\n",
      "        [-27.5930,  28.6584, -24.7857],\n",
      "        [-27.5375,  28.5304, -24.1965],\n",
      "        [-27.1411,  28.0050, -24.3505],\n",
      "        [-27.0505,  28.2985, -23.7630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7789,  24.2023,  24.9640, -27.7910,  28.8792, -24.8388],\n",
      "        [ 28.1616,  23.7235,  24.1174, -27.6725,  28.6533, -24.7334],\n",
      "        [ 28.2887,  24.1531,  24.4588, -27.5930,  28.6584, -24.7857],\n",
      "        [ 28.6148,  23.5168,  24.2863, -27.5375,  28.5304, -24.1965],\n",
      "        [ 27.5330,  22.7824,  23.7676, -27.1411,  28.0050, -24.3505],\n",
      "        [ 28.1008,  23.3879,  24.2448, -27.0505,  28.2985, -23.7630]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.744340896606445\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3591, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5580, 23.9559, 24.3712],\n",
      "        [27.8353, 23.3279, 24.0542],\n",
      "        [28.3023, 23.7601, 24.3884],\n",
      "        [28.6136, 23.7078, 24.4771],\n",
      "        [27.9597, 23.6599, 24.1178],\n",
      "        [28.7786, 24.2740, 24.8468]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(35.9486, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5636,  28.7234, -24.6614],\n",
      "        [-27.2760,  28.1419, -24.6933],\n",
      "        [-27.8232,  28.8246, -24.7030],\n",
      "        [-26.8074,  28.1728, -23.8375],\n",
      "        [-27.1194,  28.1723, -24.4855],\n",
      "        [-26.9557,  28.4527, -24.1832]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5580,  23.9559,  24.3712, -27.5636,  28.7234, -24.6614],\n",
      "        [ 27.8353,  23.3279,  24.0542, -27.2760,  28.1419, -24.6933],\n",
      "        [ 28.3023,  23.7601,  24.3884, -27.8232,  28.8246, -24.7030],\n",
      "        [ 28.6136,  23.7078,  24.4771, -26.8074,  28.1728, -23.8375],\n",
      "        [ 27.9597,  23.6599,  24.1178, -27.1194,  28.1723, -24.4855],\n",
      "        [ 28.7786,  24.2740,  24.8468, -26.9557,  28.4527, -24.1832]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.675296306610107\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[27.8056, 23.2978, 24.1643],\n",
      "        [28.4620, 24.0069, 24.2633],\n",
      "        [29.0233, 23.8656, 24.6783],\n",
      "        [28.5554, 23.8798, 24.6880],\n",
      "        [28.2459, 23.6795, 24.1904],\n",
      "        [28.1270, 23.7334, 24.4880]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.9306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0445,  28.7720, -25.1957],\n",
      "        [-27.7391,  28.9378, -24.6628],\n",
      "        [-27.5823,  28.6379, -24.7662],\n",
      "        [-27.8201,  28.8169, -24.8230],\n",
      "        [-27.7954,  29.0211, -24.8279],\n",
      "        [-26.7719,  28.1051, -24.2185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 27.8056,  23.2978,  24.1643, -28.0445,  28.7720, -25.1957],\n",
      "        [ 28.4620,  24.0069,  24.2633, -27.7391,  28.9378, -24.6628],\n",
      "        [ 29.0233,  23.8656,  24.6783, -27.5823,  28.6379, -24.7662],\n",
      "        [ 28.5554,  23.8798,  24.6880, -27.8201,  28.8169, -24.8230],\n",
      "        [ 28.2459,  23.6795,  24.1904, -27.7954,  29.0211, -24.8279],\n",
      "        [ 28.1270,  23.7334,  24.4880, -26.7719,  28.1051, -24.2185]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.636231899261475\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4142, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6572, 23.7429, 24.8749],\n",
      "        [28.1241, 23.7422, 24.2087],\n",
      "        [29.1133, 24.2417, 25.0206],\n",
      "        [27.9234, 23.3865, 24.0337],\n",
      "        [28.6853, 24.0834, 24.2896],\n",
      "        [28.1625, 23.8088, 23.9903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.6198, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9027,  28.7248, -24.6924],\n",
      "        [-27.3577,  29.0201, -24.6689],\n",
      "        [-27.2590,  28.8149, -24.4645],\n",
      "        [-27.4168,  28.8575, -24.9069],\n",
      "        [-27.1471,  28.6132, -24.9030],\n",
      "        [-27.4077,  28.8878, -24.6214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6572,  23.7429,  24.8749, -27.9027,  28.7248, -24.6924],\n",
      "        [ 28.1241,  23.7422,  24.2087, -27.3577,  29.0201, -24.6689],\n",
      "        [ 29.1133,  24.2417,  25.0206, -27.2590,  28.8149, -24.4645],\n",
      "        [ 27.9234,  23.3865,  24.0337, -27.4168,  28.8575, -24.9069],\n",
      "        [ 28.6853,  24.0834,  24.2896, -27.1471,  28.6132, -24.9030],\n",
      "        [ 28.1625,  23.8088,  23.9903, -27.4077,  28.8878, -24.6214]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.715153217315674\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1875, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8894, 23.8398, 24.7277],\n",
      "        [27.7893, 23.4814, 23.7936],\n",
      "        [28.5521, 24.0183, 24.3175],\n",
      "        [28.2346, 23.6407, 23.7960],\n",
      "        [28.5182, 24.0160, 24.6585],\n",
      "        [28.4968, 23.9189, 24.3453]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2481, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2203,  28.3913, -24.7091],\n",
      "        [-27.7569,  28.6005, -24.8267],\n",
      "        [-28.0147,  29.2284, -25.2374],\n",
      "        [-27.7009,  29.5055, -25.1191],\n",
      "        [-27.3762,  28.7185, -24.4797],\n",
      "        [-27.8956,  28.6182, -24.4380]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8894,  23.8398,  24.7277, -27.2203,  28.3913, -24.7091],\n",
      "        [ 27.7893,  23.4814,  23.7936, -27.7569,  28.6005, -24.8267],\n",
      "        [ 28.5521,  24.0183,  24.3175, -28.0147,  29.2284, -25.2374],\n",
      "        [ 28.2346,  23.6407,  23.7960, -27.7009,  29.5055, -25.1191],\n",
      "        [ 28.5182,  24.0160,  24.6585, -27.3762,  28.7185, -24.4797],\n",
      "        [ 28.4968,  23.9189,  24.3453, -27.8956,  28.6182, -24.4380]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.6888227462768555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2640, 23.5783, 24.3064],\n",
      "        [28.0944, 23.7433, 24.4146],\n",
      "        [29.1663, 24.3714, 24.8518],\n",
      "        [27.8425, 23.4932, 23.8420],\n",
      "        [27.6997, 23.0045, 23.3013],\n",
      "        [28.6064, 23.6305, 24.4945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.8293,  28.4517, -24.1137],\n",
      "        [-27.8477,  29.0337, -24.8870],\n",
      "        [-27.2057,  28.1795, -24.3835],\n",
      "        [-27.6111,  28.9744, -24.5940],\n",
      "        [-27.1221,  28.3546, -24.2924],\n",
      "        [-28.0108,  29.0552, -24.8303]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2640,  23.5783,  24.3064, -26.8293,  28.4517, -24.1137],\n",
      "        [ 28.0944,  23.7433,  24.4146, -27.8477,  29.0337, -24.8870],\n",
      "        [ 29.1663,  24.3714,  24.8518, -27.2057,  28.1795, -24.3835],\n",
      "        [ 27.8425,  23.4932,  23.8420, -27.6111,  28.9744, -24.5940],\n",
      "        [ 27.6997,  23.0045,  23.3013, -27.1221,  28.3546, -24.2924],\n",
      "        [ 28.6064,  23.6305,  24.4945, -28.0108,  29.0552, -24.8303]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.593448638916016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5098, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3699, 23.6864, 24.3781],\n",
      "        [28.3690, 23.6515, 24.4650],\n",
      "        [28.6660, 24.2326, 24.4468],\n",
      "        [28.4440, 23.9989, 24.4069],\n",
      "        [28.3444, 24.1012, 24.5384],\n",
      "        [28.4129, 24.0243, 24.5450]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7092,  29.0670, -24.9946],\n",
      "        [-27.7604,  28.6426, -24.5385],\n",
      "        [-27.5839,  29.0656, -24.9249],\n",
      "        [-28.0622,  29.3769, -25.0204],\n",
      "        [-27.3867,  27.7715, -24.4891],\n",
      "        [-26.9141,  28.3183, -24.6289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3699,  23.6864,  24.3781, -27.7092,  29.0670, -24.9946],\n",
      "        [ 28.3690,  23.6515,  24.4650, -27.7604,  28.6426, -24.5385],\n",
      "        [ 28.6660,  24.2326,  24.4468, -27.5839,  29.0656, -24.9249],\n",
      "        [ 28.4440,  23.9989,  24.4069, -28.0622,  29.3769, -25.0204],\n",
      "        [ 28.3444,  24.1012,  24.5384, -27.3867,  27.7715, -24.4891],\n",
      "        [ 28.4129,  24.0243,  24.5450, -26.9141,  28.3183, -24.6289]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.694517612457275\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0509, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1483, 24.3378, 25.1175],\n",
      "        [28.0964, 23.5679, 24.1896],\n",
      "        [28.6412, 23.6945, 24.3835],\n",
      "        [28.9415, 24.1636, 24.7256],\n",
      "        [28.9467, 24.2754, 24.7631],\n",
      "        [29.1618, 24.5468, 25.1511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.1787, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.5948,  29.2120, -25.1598],\n",
      "        [-26.8158,  28.2892, -24.3445],\n",
      "        [-26.7557,  27.9073, -24.1903],\n",
      "        [-27.6594,  28.5981, -24.5545],\n",
      "        [-26.3882,  27.6987, -24.0311],\n",
      "        [-27.9718,  28.9883, -25.3214]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1483,  24.3378,  25.1175, -28.5948,  29.2120, -25.1598],\n",
      "        [ 28.0964,  23.5679,  24.1896, -26.8158,  28.2892, -24.3445],\n",
      "        [ 28.6412,  23.6945,  24.3835, -26.7557,  27.9073, -24.1903],\n",
      "        [ 28.9415,  24.1636,  24.7256, -27.6594,  28.5981, -24.5545],\n",
      "        [ 28.9467,  24.2754,  24.7631, -26.3882,  27.6987, -24.0311],\n",
      "        [ 29.1618,  24.5468,  25.1511, -27.9718,  28.9883, -25.3214]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.846077919006348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.4626, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7647, 23.8895, 24.2362],\n",
      "        [28.3958, 24.0553, 24.9584],\n",
      "        [27.5116, 22.6705, 23.5213],\n",
      "        [28.3992, 23.8128, 24.4975],\n",
      "        [28.6798, 24.6463, 24.8571],\n",
      "        [28.7973, 24.9310, 25.0537]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.0361, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7184,  28.4200, -24.5741],\n",
      "        [-28.0673,  29.3410, -25.1787],\n",
      "        [-27.9329,  28.8504, -24.9278],\n",
      "        [-27.3873,  28.1966, -24.1405],\n",
      "        [-27.8604,  28.8436, -24.6336],\n",
      "        [-27.7008,  28.6017, -24.5399]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7647,  23.8895,  24.2362, -27.7184,  28.4200, -24.5741],\n",
      "        [ 28.3958,  24.0553,  24.9584, -28.0673,  29.3410, -25.1787],\n",
      "        [ 27.5116,  22.6705,  23.5213, -27.9329,  28.8504, -24.9278],\n",
      "        [ 28.3992,  23.8128,  24.4975, -27.3873,  28.1966, -24.1405],\n",
      "        [ 28.6798,  24.6463,  24.8571, -27.8604,  28.8436, -24.6336],\n",
      "        [ 28.7973,  24.9310,  25.0537, -27.7008,  28.6017, -24.5399]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.683344841003418\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9706, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7346, 24.1179, 24.5224],\n",
      "        [27.8908, 23.7299, 24.2977],\n",
      "        [29.0042, 24.3133, 24.5721],\n",
      "        [28.0116, 23.4924, 24.5460],\n",
      "        [28.9926, 24.1992, 24.8135],\n",
      "        [28.9540, 24.1850, 24.9583]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.9005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1820,  28.5983, -24.3945],\n",
      "        [-27.7521,  28.5763, -24.2778],\n",
      "        [-27.1761,  28.3785, -24.5695],\n",
      "        [-27.5049,  28.6844, -24.6795],\n",
      "        [-27.5883,  28.8965, -24.9829],\n",
      "        [-27.3860,  28.6822, -24.3205]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7346,  24.1179,  24.5224, -27.1820,  28.5983, -24.3945],\n",
      "        [ 27.8908,  23.7299,  24.2977, -27.7521,  28.5763, -24.2778],\n",
      "        [ 29.0042,  24.3133,  24.5721, -27.1761,  28.3785, -24.5695],\n",
      "        [ 28.0116,  23.4924,  24.5460, -27.5049,  28.6844, -24.6795],\n",
      "        [ 28.9926,  24.1992,  24.8135, -27.5883,  28.8965, -24.9829],\n",
      "        [ 28.9540,  24.1850,  24.9583, -27.3860,  28.6822, -24.3205]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.687543869018555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3254, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5347, 24.2580, 24.9598],\n",
      "        [28.5356, 23.6743, 24.8166],\n",
      "        [28.3050, 23.7686, 24.8400],\n",
      "        [27.9441, 23.7489, 24.1182],\n",
      "        [28.0971, 23.8004, 24.1691],\n",
      "        [28.3538, 23.7114, 24.3720]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.1844, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8273,  29.2602, -25.3371],\n",
      "        [-27.4848,  28.3996, -24.5726],\n",
      "        [-26.8861,  28.4668, -24.2055],\n",
      "        [-27.4955,  29.0967, -24.8411],\n",
      "        [-27.5113,  28.2903, -24.7044],\n",
      "        [-27.8145,  28.3766, -24.6917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5347,  24.2580,  24.9598, -27.8273,  29.2602, -25.3371],\n",
      "        [ 28.5356,  23.6743,  24.8166, -27.4848,  28.3996, -24.5726],\n",
      "        [ 28.3050,  23.7686,  24.8400, -26.8861,  28.4668, -24.2055],\n",
      "        [ 27.9441,  23.7489,  24.1182, -27.4955,  29.0967, -24.8411],\n",
      "        [ 28.0971,  23.8004,  24.1691, -27.5113,  28.2903, -24.7044],\n",
      "        [ 28.3538,  23.7114,  24.3720, -27.8145,  28.3766, -24.6917]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.785391807556152\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1799, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8271, 24.3105, 24.4385],\n",
      "        [28.4070, 23.6787, 24.6087],\n",
      "        [28.3797, 23.9212, 24.2169],\n",
      "        [28.6330, 24.0337, 24.4043],\n",
      "        [28.1874, 24.0243, 24.1596],\n",
      "        [28.1354, 23.5787, 24.3660]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.8501, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.4164,  27.8631, -24.1158],\n",
      "        [-27.0219,  28.0603, -23.8675],\n",
      "        [-27.7463,  28.6944, -24.5601],\n",
      "        [-28.1150,  29.6461, -25.4389],\n",
      "        [-27.5443,  28.9852, -24.4180],\n",
      "        [-27.0499,  28.5178, -24.3853]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8271,  24.3105,  24.4385, -26.4164,  27.8631, -24.1158],\n",
      "        [ 28.4070,  23.6787,  24.6087, -27.0219,  28.0603, -23.8675],\n",
      "        [ 28.3797,  23.9212,  24.2169, -27.7463,  28.6944, -24.5601],\n",
      "        [ 28.6330,  24.0337,  24.4043, -28.1150,  29.6461, -25.4389],\n",
      "        [ 28.1874,  24.0243,  24.1596, -27.5443,  28.9852, -24.4180],\n",
      "        [ 28.1354,  23.5787,  24.3660, -27.0499,  28.5178, -24.3853]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.633471965789795\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3323, 23.6991, 24.3776],\n",
      "        [28.6607, 23.8727, 24.8054],\n",
      "        [28.8400, 24.2099, 24.8752],\n",
      "        [27.7753, 23.4677, 24.4290],\n",
      "        [28.5971, 24.4486, 24.6538],\n",
      "        [28.9013, 24.5720, 25.2578]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.6748, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7449,  29.2379, -24.5932],\n",
      "        [-27.3575,  28.5356, -24.7463],\n",
      "        [-26.7056,  28.6973, -24.4409],\n",
      "        [-27.2582,  28.5810, -24.5453],\n",
      "        [-27.3263,  28.3296, -24.6950],\n",
      "        [-27.4140,  28.7162, -24.8059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3323,  23.6991,  24.3776, -27.7449,  29.2379, -24.5932],\n",
      "        [ 28.6607,  23.8727,  24.8054, -27.3575,  28.5356, -24.7463],\n",
      "        [ 28.8400,  24.2099,  24.8752, -26.7056,  28.6973, -24.4409],\n",
      "        [ 27.7753,  23.4677,  24.4290, -27.2582,  28.5810, -24.5453],\n",
      "        [ 28.5971,  24.4486,  24.6538, -27.3263,  28.3296, -24.6950],\n",
      "        [ 28.9013,  24.5720,  25.2578, -27.4140,  28.7162, -24.8059]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.700406074523926\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2736, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4906, 23.9938, 24.5756],\n",
      "        [28.3706, 23.9797, 24.7555],\n",
      "        [28.4790, 24.1474, 24.6232],\n",
      "        [28.4468, 24.0724, 24.3375],\n",
      "        [28.3328, 23.7545, 24.6404],\n",
      "        [28.3202, 23.8875, 24.0878]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.0288, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3627,  28.7023, -24.5931],\n",
      "        [-27.8384,  28.6642, -24.9447],\n",
      "        [-27.0631,  28.3680, -24.0008],\n",
      "        [-27.6361,  29.4751, -25.2209],\n",
      "        [-27.8529,  28.4462, -24.5993],\n",
      "        [-26.7456,  28.1918, -23.9847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4906,  23.9938,  24.5756, -27.3627,  28.7023, -24.5931],\n",
      "        [ 28.3706,  23.9797,  24.7555, -27.8384,  28.6642, -24.9447],\n",
      "        [ 28.4790,  24.1474,  24.6232, -27.0631,  28.3680, -24.0008],\n",
      "        [ 28.4468,  24.0724,  24.3375, -27.6361,  29.4751, -25.2209],\n",
      "        [ 28.3328,  23.7545,  24.6404, -27.8529,  28.4462, -24.5993],\n",
      "        [ 28.3202,  23.8875,  24.0878, -26.7456,  28.1918, -23.9847]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.696895599365234\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3896, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0144, 23.9804, 24.4131],\n",
      "        [29.0681, 24.7006, 24.9255],\n",
      "        [27.9919, 23.2679, 23.8032],\n",
      "        [28.2549, 23.5889, 24.1363],\n",
      "        [28.1940, 23.8711, 24.8250],\n",
      "        [29.1303, 24.0724, 24.8928]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.1893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3949,  28.5315, -24.8379],\n",
      "        [-28.3396,  29.5201, -25.3248],\n",
      "        [-27.3472,  28.2447, -24.2374],\n",
      "        [-27.6449,  28.6316, -24.6683],\n",
      "        [-26.2696,  27.8378, -23.9438],\n",
      "        [-26.7932,  27.7428, -23.9120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0144,  23.9804,  24.4131, -27.3949,  28.5315, -24.8379],\n",
      "        [ 29.0681,  24.7006,  24.9255, -28.3396,  29.5201, -25.3248],\n",
      "        [ 27.9919,  23.2679,  23.8032, -27.3472,  28.2447, -24.2374],\n",
      "        [ 28.2549,  23.5889,  24.1363, -27.6449,  28.6316, -24.6683],\n",
      "        [ 28.1940,  23.8711,  24.8250, -26.2696,  27.8378, -23.9438],\n",
      "        [ 29.1303,  24.0724,  24.8928, -26.7932,  27.7428, -23.9120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.66556978225708\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7735, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8853, 24.1752, 25.0982],\n",
      "        [28.6597, 23.9575, 24.6359],\n",
      "        [28.9680, 24.2382, 25.1100],\n",
      "        [28.8504, 24.3865, 25.0980],\n",
      "        [28.5665, 23.6824, 24.4645],\n",
      "        [28.5105, 23.9760, 24.6749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(26.8243, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2758,  28.1831, -24.1453],\n",
      "        [-27.7148,  28.2326, -24.6301],\n",
      "        [-27.3193,  28.5948, -24.4125],\n",
      "        [-26.8090,  28.1412, -23.8424],\n",
      "        [-27.0267,  28.6623, -24.3857],\n",
      "        [-28.0128,  29.4670, -25.3732]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8853,  24.1752,  25.0982, -27.2758,  28.1831, -24.1453],\n",
      "        [ 28.6597,  23.9575,  24.6359, -27.7148,  28.2326, -24.6301],\n",
      "        [ 28.9680,  24.2382,  25.1100, -27.3193,  28.5948, -24.4125],\n",
      "        [ 28.8504,  24.3865,  25.0980, -26.8090,  28.1412, -23.8424],\n",
      "        [ 28.5665,  23.6824,  24.4645, -27.0267,  28.6623, -24.3857],\n",
      "        [ 28.5105,  23.9760,  24.6749, -28.0128,  29.4670, -25.3732]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.717804431915283\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2711, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1333, 23.6218, 24.4472],\n",
      "        [28.2434, 23.8965, 24.5409],\n",
      "        [27.7560, 23.5360, 24.0571],\n",
      "        [29.0907, 24.7063, 25.2115],\n",
      "        [28.7075, 23.8022, 24.1157],\n",
      "        [27.9216, 23.9555, 23.7421]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.5564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2242,  28.9233, -24.9138],\n",
      "        [-26.9541,  28.2751, -24.7799],\n",
      "        [-26.8652,  28.2788, -24.3163],\n",
      "        [-27.8795,  28.9850, -24.7910],\n",
      "        [-27.2943,  28.5948, -24.4217],\n",
      "        [-27.2655,  28.6877, -25.0061]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1333,  23.6218,  24.4472, -27.2242,  28.9233, -24.9138],\n",
      "        [ 28.2434,  23.8965,  24.5409, -26.9541,  28.2751, -24.7799],\n",
      "        [ 27.7560,  23.5360,  24.0571, -26.8652,  28.2788, -24.3163],\n",
      "        [ 29.0907,  24.7063,  25.2115, -27.8795,  28.9850, -24.7910],\n",
      "        [ 28.7075,  23.8022,  24.1157, -27.2943,  28.5948, -24.4217],\n",
      "        [ 27.9216,  23.9555,  23.7421, -27.2655,  28.6877, -25.0061]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.675902366638184\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1015, 23.2287, 24.4297],\n",
      "        [28.0692, 23.6141, 24.4823],\n",
      "        [28.6204, 24.0309, 24.5903],\n",
      "        [28.8733, 24.3036, 24.7167],\n",
      "        [28.7791, 24.5503, 24.8523],\n",
      "        [29.1054, 24.1795, 24.9287]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.0083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-26.7851,  28.4199, -24.3745],\n",
      "        [-27.3650,  28.5397, -24.3513],\n",
      "        [-27.4679,  28.8174, -24.4566],\n",
      "        [-27.0509,  28.4978, -24.7143],\n",
      "        [-27.0290,  28.2287, -24.7451],\n",
      "        [-27.9896,  28.9505, -25.2594]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1015,  23.2287,  24.4297, -26.7851,  28.4199, -24.3745],\n",
      "        [ 28.0692,  23.6141,  24.4823, -27.3650,  28.5397, -24.3513],\n",
      "        [ 28.6204,  24.0309,  24.5903, -27.4679,  28.8174, -24.4566],\n",
      "        [ 28.8733,  24.3036,  24.7167, -27.0509,  28.4978, -24.7143],\n",
      "        [ 28.7791,  24.5503,  24.8523, -27.0290,  28.2287, -24.7451],\n",
      "        [ 29.1054,  24.1795,  24.9287, -27.9896,  28.9505, -25.2594]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.6064229011535645\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1860, 23.7563, 24.5936],\n",
      "        [28.6804, 23.6448, 24.1688],\n",
      "        [29.0371, 24.3330, 24.7230],\n",
      "        [28.5815, 23.8964, 24.5337],\n",
      "        [28.1245, 23.6358, 24.7553],\n",
      "        [28.3816, 23.7393, 24.7194]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.6742, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2501,  28.6067, -24.4907],\n",
      "        [-27.9903,  28.9081, -25.2782],\n",
      "        [-27.8014,  28.9940, -24.8792],\n",
      "        [-27.6313,  28.7866, -24.8584],\n",
      "        [-28.3934,  29.2652, -25.2427],\n",
      "        [-26.9483,  28.4771, -24.5021]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1860,  23.7563,  24.5936, -27.2501,  28.6067, -24.4907],\n",
      "        [ 28.6804,  23.6448,  24.1688, -27.9903,  28.9081, -25.2782],\n",
      "        [ 29.0371,  24.3330,  24.7230, -27.8014,  28.9940, -24.8792],\n",
      "        [ 28.5815,  23.8964,  24.5337, -27.6313,  28.7866, -24.8584],\n",
      "        [ 28.1245,  23.6358,  24.7553, -28.3934,  29.2652, -25.2427],\n",
      "        [ 28.3816,  23.7393,  24.7194, -26.9483,  28.4771, -24.5021]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.670131683349609\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7763, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.1585, 23.7230, 24.4694],\n",
      "        [29.0746, 24.5400, 25.2591],\n",
      "        [28.4518, 23.8943, 25.1078],\n",
      "        [28.1856, 23.6018, 24.1981],\n",
      "        [28.3625, 23.8062, 24.4193],\n",
      "        [28.0986, 23.9049, 24.8207]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(18.8859, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8845,  28.5716, -24.9827],\n",
      "        [-28.0582,  28.8791, -25.1461],\n",
      "        [-27.7518,  29.2990, -25.0993],\n",
      "        [-27.2785,  28.7707, -24.5569],\n",
      "        [-26.9202,  28.2312, -24.3683],\n",
      "        [-27.6401,  28.7381, -24.8751]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.1585,  23.7230,  24.4694, -27.8845,  28.5716, -24.9827],\n",
      "        [ 29.0746,  24.5400,  25.2591, -28.0582,  28.8791, -25.1461],\n",
      "        [ 28.4518,  23.8943,  25.1078, -27.7518,  29.2990, -25.0993],\n",
      "        [ 28.1856,  23.6018,  24.1981, -27.2785,  28.7707, -24.5569],\n",
      "        [ 28.3625,  23.8062,  24.4193, -26.9202,  28.2312, -24.3683],\n",
      "        [ 28.0986,  23.9049,  24.8207, -27.6401,  28.7381, -24.8751]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.701516151428223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1329, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9044, 23.9134, 24.8245],\n",
      "        [28.3717, 23.8254, 24.6549],\n",
      "        [28.3908, 23.5477, 24.5936],\n",
      "        [28.1704, 24.1910, 24.5151],\n",
      "        [28.6260, 24.3015, 24.6391],\n",
      "        [28.7548, 24.1508, 24.6720]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.1111, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7365,  28.5964, -24.7134],\n",
      "        [-27.6898,  29.0989, -25.2822],\n",
      "        [-26.7238,  28.2560, -24.1863],\n",
      "        [-27.9905,  28.9486, -24.7879],\n",
      "        [-27.5998,  28.9102, -25.0172],\n",
      "        [-27.6308,  28.4649, -24.5487]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9044,  23.9134,  24.8245, -27.7365,  28.5964, -24.7134],\n",
      "        [ 28.3717,  23.8254,  24.6549, -27.6898,  29.0989, -25.2822],\n",
      "        [ 28.3908,  23.5477,  24.5936, -26.7238,  28.2560, -24.1863],\n",
      "        [ 28.1704,  24.1910,  24.5151, -27.9905,  28.9486, -24.7879],\n",
      "        [ 28.6260,  24.3015,  24.6391, -27.5998,  28.9102, -25.0172],\n",
      "        [ 28.7548,  24.1508,  24.6720, -27.6308,  28.4649, -24.5487]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.757662296295166\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2517, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4270, 23.9854, 24.7445],\n",
      "        [28.7324, 24.1057, 24.7276],\n",
      "        [28.9663, 24.6709, 25.0141],\n",
      "        [28.7764, 24.0624, 24.7088],\n",
      "        [28.3853, 24.4420, 24.9675],\n",
      "        [29.1173, 24.3988, 24.8712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7263, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2904,  28.5233, -24.4445],\n",
      "        [-27.5399,  28.8461, -24.8425],\n",
      "        [-27.3140,  28.5295, -24.3417],\n",
      "        [-27.8973,  28.7161, -25.3971],\n",
      "        [-27.4290,  28.2720, -24.5470],\n",
      "        [-27.3632,  28.9415, -24.7358]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4270,  23.9854,  24.7445, -27.2904,  28.5233, -24.4445],\n",
      "        [ 28.7324,  24.1057,  24.7276, -27.5399,  28.8461, -24.8425],\n",
      "        [ 28.9663,  24.6709,  25.0141, -27.3140,  28.5295, -24.3417],\n",
      "        [ 28.7764,  24.0624,  24.7088, -27.8973,  28.7161, -25.3971],\n",
      "        [ 28.3853,  24.4420,  24.9675, -27.4290,  28.2720, -24.5470],\n",
      "        [ 29.1173,  24.3988,  24.8712, -27.3632,  28.9415, -24.7358]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.702902793884277\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.0204, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6775, 23.9791, 24.7839],\n",
      "        [28.6268, 24.0378, 24.4265],\n",
      "        [28.1058, 23.9028, 24.3625],\n",
      "        [28.7766, 24.4195, 25.0000],\n",
      "        [27.8441, 23.4116, 24.0648],\n",
      "        [29.3759, 24.5431, 25.4264]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.6491, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.1150,  27.9808, -24.3905],\n",
      "        [-27.5618,  28.9087, -24.4905],\n",
      "        [-27.4619,  28.7580, -24.4342],\n",
      "        [-27.8038,  29.0671, -24.7695],\n",
      "        [-27.8590,  28.8604, -25.1192],\n",
      "        [-27.1193,  28.4267, -24.5583]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6775,  23.9791,  24.7839, -27.1150,  27.9808, -24.3905],\n",
      "        [ 28.6268,  24.0378,  24.4265, -27.5618,  28.9087, -24.4905],\n",
      "        [ 28.1058,  23.9028,  24.3625, -27.4619,  28.7580, -24.4342],\n",
      "        [ 28.7766,  24.4195,  25.0000, -27.8038,  29.0671, -24.7695],\n",
      "        [ 27.8441,  23.4116,  24.0648, -27.8590,  28.8604, -25.1192],\n",
      "        [ 29.3759,  24.5431,  25.4264, -27.1193,  28.4267, -24.5583]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.691075325012207\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8839, 24.3037, 25.3449],\n",
      "        [28.3076, 23.6273, 24.5396],\n",
      "        [28.1630, 24.2077, 24.8460],\n",
      "        [28.5015, 24.0266, 24.1898],\n",
      "        [28.1341, 23.5223, 24.3674],\n",
      "        [28.5889, 24.1870, 24.5740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2191, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7642,  28.9590, -24.9529],\n",
      "        [-27.4923,  28.7664, -25.0596],\n",
      "        [-27.9285,  28.9824, -25.0186],\n",
      "        [-27.5434,  28.7880, -24.9284],\n",
      "        [-28.3320,  29.6595, -25.3857],\n",
      "        [-27.3797,  28.5714, -24.6932]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8839,  24.3037,  25.3449, -27.7642,  28.9590, -24.9529],\n",
      "        [ 28.3076,  23.6273,  24.5396, -27.4923,  28.7664, -25.0596],\n",
      "        [ 28.1630,  24.2077,  24.8460, -27.9285,  28.9824, -25.0186],\n",
      "        [ 28.5015,  24.0266,  24.1898, -27.5434,  28.7880, -24.9284],\n",
      "        [ 28.1341,  23.5223,  24.3674, -28.3320,  29.6595, -25.3857],\n",
      "        [ 28.5889,  24.1870,  24.5740, -27.3797,  28.5714, -24.6932]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.826225280761719\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0717, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0914, 24.0105, 23.8642],\n",
      "        [29.1533, 24.7635, 25.1132],\n",
      "        [29.2733, 24.5135, 25.2740],\n",
      "        [28.2428, 24.1877, 24.8714],\n",
      "        [28.4327, 23.9865, 24.3500],\n",
      "        [28.1230, 23.8267, 24.3675]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.4779, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8239,  28.9817, -24.6765],\n",
      "        [-28.2019,  29.1719, -25.1479],\n",
      "        [-27.5683,  28.6305, -24.6867],\n",
      "        [-27.8648,  29.0216, -25.2914],\n",
      "        [-27.1063,  28.1857, -24.3820],\n",
      "        [-28.1759,  28.9826, -25.0532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0914,  24.0105,  23.8642, -27.8239,  28.9817, -24.6765],\n",
      "        [ 29.1533,  24.7635,  25.1132, -28.2019,  29.1719, -25.1479],\n",
      "        [ 29.2733,  24.5135,  25.2740, -27.5683,  28.6305, -24.6867],\n",
      "        [ 28.2428,  24.1877,  24.8714, -27.8648,  29.0216, -25.2914],\n",
      "        [ 28.4327,  23.9865,  24.3500, -27.1063,  28.1857, -24.3820],\n",
      "        [ 28.1230,  23.8267,  24.3675, -28.1759,  28.9826, -25.0532]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.693459510803223\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3162, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5245, 23.9996, 24.7611],\n",
      "        [29.0585, 24.4799, 25.0289],\n",
      "        [28.4278, 23.9778, 24.7509],\n",
      "        [28.4996, 23.8117, 24.2466],\n",
      "        [28.0627, 23.6401, 24.5368],\n",
      "        [28.8172, 24.0504, 24.6305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.2145, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9177,  28.8920, -24.4850],\n",
      "        [-27.7148,  28.9929, -24.4799],\n",
      "        [-27.3565,  28.0347, -24.4457],\n",
      "        [-27.8382,  28.5040, -24.8202],\n",
      "        [-28.0627,  29.3934, -24.9926],\n",
      "        [-27.7307,  28.2405, -24.5873]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5245,  23.9996,  24.7611, -27.9177,  28.8920, -24.4850],\n",
      "        [ 29.0585,  24.4799,  25.0289, -27.7148,  28.9929, -24.4799],\n",
      "        [ 28.4278,  23.9778,  24.7509, -27.3565,  28.0347, -24.4457],\n",
      "        [ 28.4996,  23.8117,  24.2466, -27.8382,  28.5040, -24.8202],\n",
      "        [ 28.0627,  23.6401,  24.5368, -28.0627,  29.3934, -24.9926],\n",
      "        [ 28.8172,  24.0504,  24.6305, -27.7307,  28.2405, -24.5873]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.757571220397949\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4849, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3315, 23.9494, 24.6737],\n",
      "        [28.5536, 24.2606, 24.7959],\n",
      "        [28.5259, 24.1458, 24.4809],\n",
      "        [28.7613, 24.4157, 24.8682],\n",
      "        [29.0393, 24.6012, 24.7808],\n",
      "        [28.9823, 24.2332, 24.6532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(36.8934, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1653,  29.2286, -25.1064],\n",
      "        [-26.7927,  28.4993, -24.5932],\n",
      "        [-27.1208,  27.8454, -23.7868],\n",
      "        [-27.2439,  28.5051, -24.2266],\n",
      "        [-27.9238,  29.0729, -24.9398],\n",
      "        [-28.0156,  28.9204, -24.9800]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3315,  23.9494,  24.6737, -28.1653,  29.2286, -25.1064],\n",
      "        [ 28.5536,  24.2606,  24.7959, -26.7927,  28.4993, -24.5932],\n",
      "        [ 28.5259,  24.1458,  24.4809, -27.1208,  27.8454, -23.7868],\n",
      "        [ 28.7613,  24.4157,  24.8682, -27.2439,  28.5051, -24.2266],\n",
      "        [ 29.0393,  24.6012,  24.7808, -27.9238,  29.0729, -24.9398],\n",
      "        [ 28.9823,  24.2332,  24.6532, -28.0156,  28.9204, -24.9800]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.785091876983643\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0639, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.2524, 23.8790, 24.6617],\n",
      "        [28.3466, 23.7217, 24.0955],\n",
      "        [28.0287, 23.5078, 24.1391],\n",
      "        [28.8097, 24.0137, 24.5535],\n",
      "        [29.1726, 24.2656, 25.1464],\n",
      "        [28.7161, 24.3460, 24.6962]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.5722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9855,  29.2558, -24.9991],\n",
      "        [-27.4944,  28.7819, -24.5737],\n",
      "        [-27.7646,  28.9995, -25.1944],\n",
      "        [-27.3082,  29.1411, -24.9858],\n",
      "        [-27.7263,  28.9803, -24.8379],\n",
      "        [-27.0403,  28.2281, -24.0895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.2524,  23.8790,  24.6617, -27.9855,  29.2558, -24.9991],\n",
      "        [ 28.3466,  23.7217,  24.0955, -27.4944,  28.7819, -24.5737],\n",
      "        [ 28.0287,  23.5078,  24.1391, -27.7646,  28.9995, -25.1944],\n",
      "        [ 28.8097,  24.0137,  24.5535, -27.3082,  29.1411, -24.9858],\n",
      "        [ 29.1726,  24.2656,  25.1464, -27.7263,  28.9803, -24.8379],\n",
      "        [ 28.7161,  24.3460,  24.6962, -27.0403,  28.2281, -24.0895]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.770162582397461\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8045, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7213, 24.1699, 24.8747],\n",
      "        [28.3454, 23.8937, 24.2855],\n",
      "        [28.7500, 24.1403, 24.6908],\n",
      "        [28.9399, 24.5265, 25.2747],\n",
      "        [28.9469, 23.8248, 24.5063],\n",
      "        [28.8874, 24.3604, 25.1490]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.7734, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3431,  28.5088, -24.5647],\n",
      "        [-27.1337,  28.6815, -24.3376],\n",
      "        [-27.6599,  28.6575, -25.0298],\n",
      "        [-27.7470,  29.0626, -25.1350],\n",
      "        [-27.6013,  28.8349, -24.8396],\n",
      "        [-27.4497,  28.8158, -24.5942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7213,  24.1699,  24.8747, -27.3431,  28.5088, -24.5647],\n",
      "        [ 28.3454,  23.8937,  24.2855, -27.1337,  28.6815, -24.3376],\n",
      "        [ 28.7500,  24.1403,  24.6908, -27.6599,  28.6575, -25.0298],\n",
      "        [ 28.9399,  24.5265,  25.2747, -27.7470,  29.0626, -25.1350],\n",
      "        [ 28.9469,  23.8248,  24.5063, -27.6013,  28.8349, -24.8396],\n",
      "        [ 28.8874,  24.3604,  25.1490, -27.4497,  28.8158, -24.5942]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.752771854400635\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1853, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5865, 24.2456, 24.5310],\n",
      "        [28.2522, 23.8983, 24.3044],\n",
      "        [28.3275, 23.9938, 24.6413],\n",
      "        [28.5516, 24.0830, 24.7340],\n",
      "        [29.1059, 24.3203, 25.0499],\n",
      "        [29.0955, 24.6467, 24.9010]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(27.5522, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5143,  29.0609, -24.6810],\n",
      "        [-27.5478,  28.9052, -25.0728],\n",
      "        [-28.1943,  29.9302, -25.1822],\n",
      "        [-27.3676,  28.8837, -24.9377],\n",
      "        [-27.9299,  29.1174, -25.0516],\n",
      "        [-27.8520,  29.0288, -24.9208]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5865,  24.2456,  24.5310, -27.5143,  29.0609, -24.6810],\n",
      "        [ 28.2522,  23.8983,  24.3044, -27.5478,  28.9052, -25.0728],\n",
      "        [ 28.3275,  23.9938,  24.6413, -28.1943,  29.9302, -25.1822],\n",
      "        [ 28.5516,  24.0830,  24.7340, -27.3676,  28.8837, -24.9377],\n",
      "        [ 29.1059,  24.3203,  25.0499, -27.9299,  29.1174, -25.0516],\n",
      "        [ 29.0955,  24.6467,  24.9010, -27.8520,  29.0288, -24.9208]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.765344619750977\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2555, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.5484, 25.0260, 25.2618],\n",
      "        [28.0615, 23.4897, 24.4086],\n",
      "        [28.9070, 24.4664, 25.0319],\n",
      "        [29.4473, 24.4786, 25.1207],\n",
      "        [28.9988, 23.9511, 25.0642],\n",
      "        [28.5843, 24.0734, 24.6060]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.3070, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5975,  28.8410, -24.8385],\n",
      "        [-27.2630,  28.7122, -24.7491],\n",
      "        [-27.7433,  28.8220, -24.4901],\n",
      "        [-27.1093,  28.2715, -24.9033],\n",
      "        [-27.3724,  28.6754, -24.7617],\n",
      "        [-27.0496,  28.0557, -24.1263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.5484,  25.0260,  25.2618, -27.5975,  28.8410, -24.8385],\n",
      "        [ 28.0615,  23.4897,  24.4086, -27.2630,  28.7122, -24.7491],\n",
      "        [ 28.9070,  24.4664,  25.0319, -27.7433,  28.8220, -24.4901],\n",
      "        [ 29.4473,  24.4786,  25.1207, -27.1093,  28.2715, -24.9033],\n",
      "        [ 28.9988,  23.9511,  25.0642, -27.3724,  28.6754, -24.7617],\n",
      "        [ 28.5843,  24.0734,  24.6060, -27.0496,  28.0557, -24.1263]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.887904167175293\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4160, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9259, 24.7197, 25.1454],\n",
      "        [29.1457, 24.5646, 25.0827],\n",
      "        [28.2350, 23.8186, 24.1502],\n",
      "        [28.9831, 24.1447, 24.8986],\n",
      "        [28.3355, 23.9332, 24.8450],\n",
      "        [28.2988, 24.3042, 24.7430]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3719, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0502,  29.2154, -25.3315],\n",
      "        [-27.8433,  28.5533, -24.8127],\n",
      "        [-27.8750,  28.9581, -25.0107],\n",
      "        [-28.1145,  28.9298, -24.8484],\n",
      "        [-27.9415,  29.1990, -25.0424],\n",
      "        [-27.5980,  28.7222, -24.9591]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9259,  24.7197,  25.1454, -28.0502,  29.2154, -25.3315],\n",
      "        [ 29.1457,  24.5646,  25.0827, -27.8433,  28.5533, -24.8127],\n",
      "        [ 28.2350,  23.8186,  24.1502, -27.8750,  28.9581, -25.0107],\n",
      "        [ 28.9831,  24.1447,  24.8986, -28.1145,  28.9298, -24.8484],\n",
      "        [ 28.3355,  23.9332,  24.8450, -27.9415,  29.1990, -25.0424],\n",
      "        [ 28.2988,  24.3042,  24.7430, -27.5980,  28.7222, -24.9591]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.884692192077637\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0797, 24.3268, 24.6233],\n",
      "        [27.9549, 23.5239, 24.6007],\n",
      "        [28.1697, 23.8531, 24.4951],\n",
      "        [29.1163, 24.4476, 25.4580],\n",
      "        [28.5092, 24.2418, 24.8348],\n",
      "        [27.9977, 24.1210, 24.6638]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.4659, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8758,  28.8104, -24.8715],\n",
      "        [-27.6366,  28.4859, -24.5682],\n",
      "        [-27.3678,  28.3185, -24.4431],\n",
      "        [-26.3779,  28.0609, -23.6441],\n",
      "        [-27.0689,  28.3212, -24.1154],\n",
      "        [-28.0270,  28.7893, -24.9869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0797,  24.3268,  24.6233, -27.8758,  28.8104, -24.8715],\n",
      "        [ 27.9549,  23.5239,  24.6007, -27.6366,  28.4859, -24.5682],\n",
      "        [ 28.1697,  23.8531,  24.4951, -27.3678,  28.3185, -24.4431],\n",
      "        [ 29.1163,  24.4476,  25.4580, -26.3779,  28.0609, -23.6441],\n",
      "        [ 28.5092,  24.2418,  24.8348, -27.0689,  28.3212, -24.1154],\n",
      "        [ 27.9977,  24.1210,  24.6638, -28.0270,  28.7893, -24.9869]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.817285537719727\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3311, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4581, 23.9398, 24.4372],\n",
      "        [28.3531, 23.9082, 24.6461],\n",
      "        [28.8960, 23.8188, 24.4441],\n",
      "        [29.2951, 24.6514, 25.0876],\n",
      "        [28.6752, 24.0088, 24.5454],\n",
      "        [29.1975, 24.1486, 24.7862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.8048, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7222,  28.6785, -24.6349],\n",
      "        [-28.0493,  29.2463, -25.4680],\n",
      "        [-28.0254,  29.0561, -25.0504],\n",
      "        [-27.5457,  29.3005, -24.8766],\n",
      "        [-27.0740,  28.5571, -24.6477],\n",
      "        [-27.4495,  28.5530, -24.7850]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4581,  23.9398,  24.4372, -27.7222,  28.6785, -24.6349],\n",
      "        [ 28.3531,  23.9082,  24.6461, -28.0493,  29.2463, -25.4680],\n",
      "        [ 28.8960,  23.8188,  24.4441, -28.0254,  29.0561, -25.0504],\n",
      "        [ 29.2951,  24.6514,  25.0876, -27.5457,  29.3005, -24.8766],\n",
      "        [ 28.6752,  24.0088,  24.5454, -27.0740,  28.5571, -24.6477],\n",
      "        [ 29.1975,  24.1486,  24.7862, -27.4495,  28.5530, -24.7850]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.740933895111084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4556, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8193, 24.0744, 25.0418],\n",
      "        [28.8705, 23.9543, 25.0134],\n",
      "        [28.2725, 23.7160, 24.2794],\n",
      "        [28.5784, 24.0378, 24.7701],\n",
      "        [28.8228, 24.3859, 24.9238],\n",
      "        [29.1975, 24.5288, 25.2864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.7881, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7015,  28.9187, -24.8850],\n",
      "        [-28.6536,  29.5997, -25.6393],\n",
      "        [-27.8600,  29.0420, -25.1610],\n",
      "        [-28.5135,  29.1275, -25.2087],\n",
      "        [-27.6012,  28.7142, -24.9296],\n",
      "        [-27.6999,  29.1913, -25.1645]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8193,  24.0744,  25.0418, -27.7015,  28.9187, -24.8850],\n",
      "        [ 28.8705,  23.9543,  25.0134, -28.6536,  29.5997, -25.6393],\n",
      "        [ 28.2725,  23.7160,  24.2794, -27.8600,  29.0420, -25.1610],\n",
      "        [ 28.5784,  24.0378,  24.7701, -28.5135,  29.1275, -25.2087],\n",
      "        [ 28.8228,  24.3859,  24.9238, -27.6012,  28.7142, -24.9296],\n",
      "        [ 29.1975,  24.5288,  25.2864, -27.6999,  29.1913, -25.1645]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.815430164337158\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8391, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6650, 24.1684, 24.3300],\n",
      "        [28.4316, 24.5688, 24.7321],\n",
      "        [29.1875, 24.5914, 25.1072],\n",
      "        [28.2450, 24.0360, 24.3060],\n",
      "        [28.4780, 24.4242, 24.8527],\n",
      "        [29.0690, 24.3893, 25.2428]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.8255, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7623,  28.4834, -24.6136],\n",
      "        [-27.2475,  28.5587, -24.4991],\n",
      "        [-28.1480,  28.9712, -25.1760],\n",
      "        [-27.5783,  28.2401, -24.3377],\n",
      "        [-27.7496,  28.9912, -25.1348],\n",
      "        [-28.1356,  29.4402, -25.6006]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6650,  24.1684,  24.3300, -27.7623,  28.4834, -24.6136],\n",
      "        [ 28.4316,  24.5688,  24.7321, -27.2475,  28.5587, -24.4991],\n",
      "        [ 29.1875,  24.5914,  25.1072, -28.1480,  28.9712, -25.1760],\n",
      "        [ 28.2450,  24.0360,  24.3060, -27.5783,  28.2401, -24.3377],\n",
      "        [ 28.4780,  24.4242,  24.8527, -27.7496,  28.9912, -25.1348],\n",
      "        [ 29.0690,  24.3893,  25.2428, -28.1356,  29.4402, -25.6006]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.75351095199585\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5310, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3357, 24.5079, 24.6439],\n",
      "        [29.0670, 24.4605, 24.7607],\n",
      "        [28.9519, 24.2465, 24.5818],\n",
      "        [28.8162, 24.2566, 24.7408],\n",
      "        [28.6707, 24.1107, 24.6288],\n",
      "        [28.8664, 24.6772, 24.6232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4420, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0736,  29.3490, -25.0386],\n",
      "        [-27.2733,  28.5967, -24.8657],\n",
      "        [-27.7665,  29.1594, -25.1250],\n",
      "        [-27.5207,  28.7830, -24.3575],\n",
      "        [-27.6851,  28.4470, -24.9407],\n",
      "        [-28.0562,  29.0882, -25.1667]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3357,  24.5079,  24.6439, -28.0736,  29.3490, -25.0386],\n",
      "        [ 29.0670,  24.4605,  24.7607, -27.2733,  28.5967, -24.8657],\n",
      "        [ 28.9519,  24.2465,  24.5818, -27.7665,  29.1594, -25.1250],\n",
      "        [ 28.8162,  24.2566,  24.7408, -27.5207,  28.7830, -24.3575],\n",
      "        [ 28.6707,  24.1107,  24.6288, -27.6851,  28.4470, -24.9407],\n",
      "        [ 28.8664,  24.6772,  24.6232, -28.0562,  29.0882, -25.1667]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.825202941894531\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1817, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3093, 23.8390, 24.5027],\n",
      "        [28.8225, 24.4248, 25.0486],\n",
      "        [28.7359, 24.1948, 24.8292],\n",
      "        [28.4094, 24.3715, 24.8445],\n",
      "        [28.5881, 23.9455, 24.7989],\n",
      "        [28.4478, 24.2283, 24.2104]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0735,  29.3675, -25.2412],\n",
      "        [-27.5906,  28.8286, -24.6278],\n",
      "        [-28.3095,  29.4412, -25.0520],\n",
      "        [-27.3401,  28.8298, -24.8077],\n",
      "        [-28.4120,  29.3840, -25.5477],\n",
      "        [-27.5312,  28.0790, -24.7176]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3093,  23.8390,  24.5027, -28.0735,  29.3675, -25.2412],\n",
      "        [ 28.8225,  24.4248,  25.0486, -27.5906,  28.8286, -24.6278],\n",
      "        [ 28.7359,  24.1948,  24.8292, -28.3095,  29.4412, -25.0520],\n",
      "        [ 28.4094,  24.3715,  24.8445, -27.3401,  28.8298, -24.8077],\n",
      "        [ 28.5881,  23.9455,  24.7989, -28.4120,  29.3840, -25.5477],\n",
      "        [ 28.4478,  24.2283,  24.2104, -27.5312,  28.0790, -24.7176]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.800287246704102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4776, 24.1002, 24.2847],\n",
      "        [28.7867, 24.1310, 25.1073],\n",
      "        [29.1188, 24.3369, 25.0761],\n",
      "        [28.3178, 23.9919, 24.3864],\n",
      "        [28.4294, 24.0786, 24.7513],\n",
      "        [28.5614, 24.2850, 24.8162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.2864, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2288,  29.3185, -24.7569],\n",
      "        [-27.8005,  28.6306, -24.9498],\n",
      "        [-27.9968,  28.7943, -25.1501],\n",
      "        [-27.7558,  29.3490, -24.8205],\n",
      "        [-28.0904,  28.8505, -25.0303],\n",
      "        [-27.4318,  28.7306, -24.5889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4776,  24.1002,  24.2847, -28.2288,  29.3185, -24.7569],\n",
      "        [ 28.7867,  24.1310,  25.1073, -27.8005,  28.6306, -24.9498],\n",
      "        [ 29.1188,  24.3369,  25.0761, -27.9968,  28.7943, -25.1501],\n",
      "        [ 28.3178,  23.9919,  24.3864, -27.7558,  29.3490, -24.8205],\n",
      "        [ 28.4294,  24.0786,  24.7513, -28.0904,  28.8505, -25.0303],\n",
      "        [ 28.5614,  24.2850,  24.8162, -27.4318,  28.7306, -24.5889]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.799654960632324\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2358, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4984, 24.7389, 25.4550],\n",
      "        [29.2208, 24.4737, 25.3022],\n",
      "        [27.9458, 23.7739, 24.5986],\n",
      "        [28.6883, 24.3936, 25.0756],\n",
      "        [29.3245, 25.1299, 25.1957],\n",
      "        [28.8003, 24.3559, 24.6755]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7205, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3679,  28.6514, -24.7242],\n",
      "        [-27.5665,  28.5764, -24.7087],\n",
      "        [-27.7468,  28.6613, -24.8035],\n",
      "        [-27.9182,  29.4029, -25.1066],\n",
      "        [-28.0325,  29.2099, -25.2218],\n",
      "        [-28.0597,  29.4519, -25.3810]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4984,  24.7389,  25.4550, -27.3679,  28.6514, -24.7242],\n",
      "        [ 29.2208,  24.4737,  25.3022, -27.5665,  28.5764, -24.7087],\n",
      "        [ 27.9458,  23.7739,  24.5986, -27.7468,  28.6613, -24.8035],\n",
      "        [ 28.6883,  24.3936,  25.0756, -27.9182,  29.4029, -25.1066],\n",
      "        [ 29.3245,  25.1299,  25.1957, -28.0325,  29.2099, -25.2218],\n",
      "        [ 28.8003,  24.3559,  24.6755, -28.0597,  29.4519, -25.3810]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.882233619689941\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7627, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9236, 24.5392, 25.2871],\n",
      "        [29.2852, 24.7681, 25.6623],\n",
      "        [28.7122, 23.9594, 24.1120],\n",
      "        [29.0572, 24.8986, 25.4516],\n",
      "        [28.5568, 24.2054, 24.6687],\n",
      "        [28.9520, 23.9438, 24.8998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.1743, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.2074,  28.4698, -24.2677],\n",
      "        [-27.3830,  28.9736, -24.9746],\n",
      "        [-28.2301,  28.9611, -25.3898],\n",
      "        [-27.6752,  28.8265, -24.7978],\n",
      "        [-27.4903,  28.6863, -24.8609],\n",
      "        [-28.0851,  29.2338, -25.3876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9236,  24.5392,  25.2871, -27.2074,  28.4698, -24.2677],\n",
      "        [ 29.2852,  24.7681,  25.6623, -27.3830,  28.9736, -24.9746],\n",
      "        [ 28.7122,  23.9594,  24.1120, -28.2301,  28.9611, -25.3898],\n",
      "        [ 29.0572,  24.8986,  25.4516, -27.6752,  28.8265, -24.7978],\n",
      "        [ 28.5568,  24.2054,  24.6687, -27.4903,  28.6863, -24.8609],\n",
      "        [ 28.9520,  23.9438,  24.8998, -28.0851,  29.2338, -25.3876]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.807179927825928\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9304, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9925, 24.5458, 24.7520],\n",
      "        [28.4244, 24.1870, 24.4412],\n",
      "        [28.2790, 23.7193, 24.2257],\n",
      "        [28.4006, 24.2767, 24.2364],\n",
      "        [28.9550, 24.2221, 25.3378],\n",
      "        [29.2741, 24.7495, 25.5055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.2483, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1773,  29.3259, -24.7257],\n",
      "        [-27.9065,  28.8691, -24.9671],\n",
      "        [-28.1287,  29.2524, -25.4432],\n",
      "        [-26.8342,  28.4897, -24.5274],\n",
      "        [-27.6348,  29.0519, -24.9795],\n",
      "        [-28.2050,  29.1336, -25.1059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9925,  24.5458,  24.7520, -28.1773,  29.3259, -24.7257],\n",
      "        [ 28.4244,  24.1870,  24.4412, -27.9065,  28.8691, -24.9671],\n",
      "        [ 28.2790,  23.7193,  24.2257, -28.1287,  29.2524, -25.4432],\n",
      "        [ 28.4006,  24.2767,  24.2364, -26.8342,  28.4897, -24.5274],\n",
      "        [ 28.9550,  24.2221,  25.3378, -27.6348,  29.0519, -24.9795],\n",
      "        [ 29.2741,  24.7495,  25.5055, -28.2050,  29.1336, -25.1059]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.872957229614258\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0106, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6795, 24.5502, 24.8690],\n",
      "        [28.1840, 23.7943, 24.6960],\n",
      "        [29.0469, 24.2075, 24.8088],\n",
      "        [28.4329, 24.0798, 24.5259],\n",
      "        [28.9108, 24.1810, 25.0786],\n",
      "        [28.1803, 23.7727, 24.2369]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.2444, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6836,  28.4752, -24.6053],\n",
      "        [-27.9085,  28.8655, -25.2659],\n",
      "        [-27.8088,  28.8504, -25.0840],\n",
      "        [-28.2491,  29.0486, -25.1660],\n",
      "        [-27.3498,  28.9475, -24.8414],\n",
      "        [-27.4525,  29.2130, -24.8863]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6795,  24.5502,  24.8690, -27.6836,  28.4752, -24.6053],\n",
      "        [ 28.1840,  23.7943,  24.6960, -27.9085,  28.8655, -25.2659],\n",
      "        [ 29.0469,  24.2075,  24.8088, -27.8088,  28.8504, -25.0840],\n",
      "        [ 28.4329,  24.0798,  24.5259, -28.2491,  29.0486, -25.1660],\n",
      "        [ 28.9108,  24.1810,  25.0786, -27.3498,  28.9475, -24.8414],\n",
      "        [ 28.1803,  23.7727,  24.2369, -27.4525,  29.2130, -24.8863]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.8063483238220215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4815, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5425, 24.0464, 24.6339],\n",
      "        [28.3437, 23.7340, 24.5240],\n",
      "        [28.9384, 24.4497, 25.1144],\n",
      "        [29.6850, 24.8010, 25.4431],\n",
      "        [28.3010, 23.6100, 24.4729],\n",
      "        [28.6806, 24.3559, 24.6147]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.9409, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9009,  28.8346, -25.0734],\n",
      "        [-27.9178,  28.9803, -24.9486],\n",
      "        [-27.5994,  28.3016, -24.7727],\n",
      "        [-27.4466,  29.1903, -24.8647],\n",
      "        [-28.1074,  29.2906, -25.3155],\n",
      "        [-28.3016,  29.3255, -25.2061]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5425,  24.0464,  24.6339, -27.9009,  28.8346, -25.0734],\n",
      "        [ 28.3437,  23.7340,  24.5240, -27.9178,  28.9803, -24.9486],\n",
      "        [ 28.9384,  24.4497,  25.1144, -27.5994,  28.3016, -24.7727],\n",
      "        [ 29.6850,  24.8010,  25.4431, -27.4466,  29.1903, -24.8647],\n",
      "        [ 28.3010,  23.6100,  24.4729, -28.1074,  29.2906, -25.3155],\n",
      "        [ 28.6806,  24.3559,  24.6147, -28.3016,  29.3255, -25.2061]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.807260036468506\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6760, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7037, 24.5202, 24.9032],\n",
      "        [29.0355, 24.2699, 25.1930],\n",
      "        [28.9407, 24.4143, 25.1300],\n",
      "        [28.6742, 23.9383, 24.8266],\n",
      "        [28.7833, 24.4299, 25.3299],\n",
      "        [28.4053, 24.0061, 24.7003]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.5327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8292,  29.0718, -25.2822],\n",
      "        [-27.6041,  28.9097, -24.8979],\n",
      "        [-27.9802,  29.4971, -25.3658],\n",
      "        [-27.6346,  29.1644, -25.0861],\n",
      "        [-27.7001,  28.6457, -24.9390],\n",
      "        [-27.7418,  29.0553, -24.9983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7037,  24.5202,  24.9032, -27.8292,  29.0718, -25.2822],\n",
      "        [ 29.0355,  24.2699,  25.1930, -27.6041,  28.9097, -24.8979],\n",
      "        [ 28.9407,  24.4143,  25.1300, -27.9802,  29.4971, -25.3658],\n",
      "        [ 28.6742,  23.9383,  24.8266, -27.6346,  29.1644, -25.0861],\n",
      "        [ 28.7833,  24.4299,  25.3299, -27.7001,  28.6457, -24.9390],\n",
      "        [ 28.4053,  24.0061,  24.7003, -27.7418,  29.0553, -24.9983]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.863710403442383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4162, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8502, 24.3757, 24.4868],\n",
      "        [29.0805, 24.1615, 25.1067],\n",
      "        [28.4102, 24.0443, 24.8210],\n",
      "        [29.0641, 24.5101, 25.1813],\n",
      "        [28.2630, 23.8645, 24.4966],\n",
      "        [28.6782, 23.9517, 24.6704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(45.9974, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7413,  28.3603, -24.5412],\n",
      "        [-27.4588,  28.3888, -24.6533],\n",
      "        [-27.7084,  28.7462, -24.9848],\n",
      "        [-27.4488,  29.1422, -24.7389],\n",
      "        [-26.9844,  28.8341, -24.5587],\n",
      "        [-27.9365,  28.8515, -24.7124]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8502,  24.3757,  24.4868, -27.7413,  28.3603, -24.5412],\n",
      "        [ 29.0805,  24.1615,  25.1067, -27.4588,  28.3888, -24.6533],\n",
      "        [ 28.4102,  24.0443,  24.8210, -27.7084,  28.7462, -24.9848],\n",
      "        [ 29.0641,  24.5101,  25.1813, -27.4488,  29.1422, -24.7389],\n",
      "        [ 28.2630,  23.8645,  24.4966, -26.9844,  28.8341, -24.5587],\n",
      "        [ 28.6782,  23.9517,  24.6704, -27.9365,  28.8515, -24.7124]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.792290687561035\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4869, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3027, 24.8290, 25.5644],\n",
      "        [29.0601, 24.4191, 24.9312],\n",
      "        [28.6138, 23.8779, 24.7996],\n",
      "        [28.6339, 23.8446, 24.5046],\n",
      "        [28.9850, 24.2276, 24.6321],\n",
      "        [29.4189, 24.7898, 25.4262]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.1784, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6290,  29.0775, -24.7767],\n",
      "        [-28.0376,  29.1274, -25.2819],\n",
      "        [-27.4924,  28.7513, -24.8432],\n",
      "        [-28.3501,  29.4220, -25.1513],\n",
      "        [-28.4047,  29.4846, -25.5361],\n",
      "        [-27.4200,  29.1318, -25.0342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3027,  24.8290,  25.5644, -27.6290,  29.0775, -24.7767],\n",
      "        [ 29.0601,  24.4191,  24.9312, -28.0376,  29.1274, -25.2819],\n",
      "        [ 28.6138,  23.8779,  24.7996, -27.4924,  28.7513, -24.8432],\n",
      "        [ 28.6339,  23.8446,  24.5046, -28.3501,  29.4220, -25.1513],\n",
      "        [ 28.9850,  24.2276,  24.6321, -28.4047,  29.4846, -25.5361],\n",
      "        [ 29.4189,  24.7898,  25.4262, -27.4200,  29.1318, -25.0342]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.923034191131592\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8800, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8861, 24.3791, 24.8511],\n",
      "        [28.8050, 24.6467, 24.9980],\n",
      "        [28.9251, 24.3780, 24.8620],\n",
      "        [28.8514, 24.6390, 25.1881],\n",
      "        [28.9224, 24.2303, 24.8858],\n",
      "        [28.6832, 24.4808, 25.0735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.4622, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8584,  29.2936, -24.9166],\n",
      "        [-27.7019,  29.0697, -25.0456],\n",
      "        [-28.5579,  29.2828, -25.6126],\n",
      "        [-27.3119,  28.6099, -24.8273],\n",
      "        [-27.6042,  28.8561, -24.6981],\n",
      "        [-28.0272,  28.9834, -25.1734]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8861,  24.3791,  24.8511, -27.8584,  29.2936, -24.9166],\n",
      "        [ 28.8050,  24.6467,  24.9980, -27.7019,  29.0697, -25.0456],\n",
      "        [ 28.9251,  24.3780,  24.8620, -28.5579,  29.2828, -25.6126],\n",
      "        [ 28.8514,  24.6390,  25.1881, -27.3119,  28.6099, -24.8273],\n",
      "        [ 28.9224,  24.2303,  24.8858, -27.6042,  28.8561, -24.6981],\n",
      "        [ 28.6832,  24.4808,  25.0735, -28.0272,  28.9834, -25.1734]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.87050724029541\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7186, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3052, 24.6584, 25.0088],\n",
      "        [28.7150, 24.3278, 25.2043],\n",
      "        [28.4461, 23.9453, 24.6917],\n",
      "        [28.0494, 23.9347, 24.3432],\n",
      "        [29.2732, 24.8314, 24.9782],\n",
      "        [28.9093, 24.4801, 25.0979]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(54.9044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6987,  28.6818, -24.7336],\n",
      "        [-27.4095,  28.5517, -24.5681],\n",
      "        [-27.6291,  28.9908, -24.9780],\n",
      "        [-27.3850,  28.4832, -24.4820],\n",
      "        [-27.9705,  29.1079, -25.3525],\n",
      "        [-27.5469,  28.3338, -24.6318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3052,  24.6584,  25.0088, -27.6987,  28.6818, -24.7336],\n",
      "        [ 28.7150,  24.3278,  25.2043, -27.4095,  28.5517, -24.5681],\n",
      "        [ 28.4461,  23.9453,  24.6917, -27.6291,  28.9908, -24.9780],\n",
      "        [ 28.0494,  23.9347,  24.3432, -27.3850,  28.4832, -24.4820],\n",
      "        [ 29.2732,  24.8314,  24.9782, -27.9705,  29.1079, -25.3525],\n",
      "        [ 28.9093,  24.4801,  25.0979, -27.5469,  28.3338, -24.6318]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.878791332244873\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9593, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0627, 24.3023, 24.9455],\n",
      "        [28.9531, 24.0987, 24.4536],\n",
      "        [28.1742, 23.6136, 24.7397],\n",
      "        [28.4180, 23.9759, 24.5527],\n",
      "        [29.2667, 24.1916, 24.9796],\n",
      "        [28.5558, 24.2203, 24.6097]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7312, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.0776,  28.3652, -24.5391],\n",
      "        [-27.3928,  28.5255, -24.2521],\n",
      "        [-27.6823,  29.0624, -25.0629],\n",
      "        [-28.3688,  29.3814, -25.3401],\n",
      "        [-27.8677,  28.9469, -24.9466],\n",
      "        [-28.0326,  28.9669, -24.7341]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0627,  24.3023,  24.9455, -27.0776,  28.3652, -24.5391],\n",
      "        [ 28.9531,  24.0987,  24.4536, -27.3928,  28.5255, -24.2521],\n",
      "        [ 28.1742,  23.6136,  24.7397, -27.6823,  29.0624, -25.0629],\n",
      "        [ 28.4180,  23.9759,  24.5527, -28.3688,  29.3814, -25.3401],\n",
      "        [ 29.2667,  24.1916,  24.9796, -27.8677,  28.9469, -24.9466],\n",
      "        [ 28.5558,  24.2203,  24.6097, -28.0326,  28.9669, -24.7341]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.807366371154785\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7656, 24.4212, 24.7263],\n",
      "        [29.1991, 24.1414, 24.6718],\n",
      "        [28.7702, 23.8500, 24.6164],\n",
      "        [28.5374, 24.0878, 24.6189],\n",
      "        [29.3060, 24.8629, 25.2928],\n",
      "        [28.9853, 24.6856, 25.2542]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2042,  29.2170, -25.1781],\n",
      "        [-27.4381,  28.8007, -24.4372],\n",
      "        [-28.8817,  30.0207, -25.8318],\n",
      "        [-27.9820,  29.2349, -25.1904],\n",
      "        [-27.9474,  29.1497, -24.8711],\n",
      "        [-27.9667,  28.7041, -25.2228]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7656,  24.4212,  24.7263, -28.2042,  29.2170, -25.1781],\n",
      "        [ 29.1991,  24.1414,  24.6718, -27.4381,  28.8007, -24.4372],\n",
      "        [ 28.7702,  23.8500,  24.6164, -28.8817,  30.0207, -25.8318],\n",
      "        [ 28.5374,  24.0878,  24.6189, -27.9820,  29.2349, -25.1904],\n",
      "        [ 29.3060,  24.8629,  25.2928, -27.9474,  29.1497, -24.8711],\n",
      "        [ 28.9853,  24.6856,  25.2542, -27.9667,  28.7041, -25.2228]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.883854866027832\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8388, 24.4779, 24.8841],\n",
      "        [27.5082, 23.6713, 24.4577],\n",
      "        [28.3787, 23.8080, 24.5575],\n",
      "        [29.2237, 24.6421, 25.1469],\n",
      "        [28.7629, 24.5364, 24.9489],\n",
      "        [29.1213, 24.3133, 24.8309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.3532, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8538,  28.8255, -25.2016],\n",
      "        [-28.3150,  29.4077, -25.3639],\n",
      "        [-28.1814,  29.3885, -25.1910],\n",
      "        [-28.0307,  29.3555, -25.2563],\n",
      "        [-28.4029,  29.3746, -25.5664],\n",
      "        [-27.9681,  29.4265, -25.4395]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8388,  24.4779,  24.8841, -27.8538,  28.8255, -25.2016],\n",
      "        [ 27.5082,  23.6713,  24.4577, -28.3150,  29.4077, -25.3639],\n",
      "        [ 28.3787,  23.8080,  24.5575, -28.1814,  29.3885, -25.1910],\n",
      "        [ 29.2237,  24.6421,  25.1469, -28.0307,  29.3555, -25.2563],\n",
      "        [ 28.7629,  24.5364,  24.9489, -28.4029,  29.3746, -25.5664],\n",
      "        [ 29.1213,  24.3133,  24.8309, -27.9681,  29.4265, -25.4395]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.871870040893555\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7688, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7241, 24.3094, 25.0633],\n",
      "        [28.0839, 23.3980, 24.2339],\n",
      "        [28.3586, 24.1987, 24.6640],\n",
      "        [29.2971, 24.8673, 25.4279],\n",
      "        [29.4434, 24.7634, 25.4417],\n",
      "        [28.7096, 24.1661, 24.8786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.1650, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6589,  29.2173, -24.9212],\n",
      "        [-27.2804,  28.5793, -24.8924],\n",
      "        [-27.6767,  28.4923, -24.9166],\n",
      "        [-28.0863,  29.0685, -24.9313],\n",
      "        [-27.7982,  29.1675, -25.4980],\n",
      "        [-28.4959,  29.3903, -25.7518]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7241,  24.3094,  25.0633, -27.6589,  29.2173, -24.9212],\n",
      "        [ 28.0839,  23.3980,  24.2339, -27.2804,  28.5793, -24.8924],\n",
      "        [ 28.3586,  24.1987,  24.6640, -27.6767,  28.4923, -24.9166],\n",
      "        [ 29.2971,  24.8673,  25.4279, -28.0863,  29.0685, -24.9313],\n",
      "        [ 29.4434,  24.7634,  25.4417, -27.7982,  29.1675, -25.4980],\n",
      "        [ 28.7096,  24.1661,  24.8786, -28.4959,  29.3903, -25.7518]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.86877965927124\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7395, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3831, 25.0751, 25.2127],\n",
      "        [28.6363, 24.2158, 24.9012],\n",
      "        [28.9629, 24.7570, 24.7122],\n",
      "        [28.6749, 24.4232, 24.5988],\n",
      "        [29.2426, 24.9384, 25.1695],\n",
      "        [28.6234, 24.3261, 24.6631]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.5848, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9041,  28.8455, -24.7690],\n",
      "        [-27.8230,  29.1663, -24.7260],\n",
      "        [-27.8891,  29.0391, -25.4450],\n",
      "        [-28.9000,  30.1225, -26.0588],\n",
      "        [-27.3158,  27.9562, -24.1438],\n",
      "        [-27.8446,  29.1470, -25.1756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3831,  25.0751,  25.2127, -27.9041,  28.8455, -24.7690],\n",
      "        [ 28.6363,  24.2158,  24.9012, -27.8230,  29.1663, -24.7260],\n",
      "        [ 28.9629,  24.7570,  24.7122, -27.8891,  29.0391, -25.4450],\n",
      "        [ 28.6749,  24.4232,  24.5988, -28.9000,  30.1225, -26.0588],\n",
      "        [ 29.2426,  24.9384,  25.1695, -27.3158,  27.9562, -24.1438],\n",
      "        [ 28.6234,  24.3261,  24.6631, -27.8446,  29.1470, -25.1756]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.935396194458008\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7494, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7790, 24.5355, 25.0355],\n",
      "        [28.5498, 24.1012, 24.5747],\n",
      "        [28.6736, 24.2843, 24.2987],\n",
      "        [28.7538, 24.1987, 24.9456],\n",
      "        [28.8877, 24.5828, 25.0409],\n",
      "        [28.6870, 24.3175, 24.8298]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8712,  29.1946, -25.1007],\n",
      "        [-28.2353,  29.5167, -25.5603],\n",
      "        [-28.3713,  29.5585, -25.4116],\n",
      "        [-27.7302,  28.7577, -25.2357],\n",
      "        [-27.9907,  29.3081, -25.1080],\n",
      "        [-27.7554,  29.3718, -25.1274]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7790,  24.5355,  25.0355, -27.8712,  29.1946, -25.1007],\n",
      "        [ 28.5498,  24.1012,  24.5747, -28.2353,  29.5167, -25.5603],\n",
      "        [ 28.6736,  24.2843,  24.2987, -28.3713,  29.5585, -25.4116],\n",
      "        [ 28.7538,  24.1987,  24.9456, -27.7302,  28.7577, -25.2357],\n",
      "        [ 28.8877,  24.5828,  25.0409, -27.9907,  29.3081, -25.1080],\n",
      "        [ 28.6870,  24.3175,  24.8298, -27.7554,  29.3718, -25.1274]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.896515846252441\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4447, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8145, 24.6069, 25.2952],\n",
      "        [28.8447, 24.6411, 24.9139],\n",
      "        [28.9029, 24.3357, 25.1940],\n",
      "        [29.0515, 24.2910, 24.9145],\n",
      "        [29.0620, 24.4422, 24.9455],\n",
      "        [28.4688, 24.0948, 24.7838]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.1745, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.7668,  29.6754, -25.6591],\n",
      "        [-27.7621,  29.1167, -24.9758],\n",
      "        [-27.5960,  28.8534, -24.8375],\n",
      "        [-28.5397,  29.3823, -25.0581],\n",
      "        [-27.9251,  29.0437, -24.9716],\n",
      "        [-27.4753,  28.6374, -24.8244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8145,  24.6069,  25.2952, -28.7668,  29.6754, -25.6591],\n",
      "        [ 28.8447,  24.6411,  24.9139, -27.7621,  29.1167, -24.9758],\n",
      "        [ 28.9029,  24.3357,  25.1940, -27.5960,  28.8534, -24.8375],\n",
      "        [ 29.0515,  24.2910,  24.9145, -28.5397,  29.3823, -25.0581],\n",
      "        [ 29.0620,  24.4422,  24.9455, -27.9251,  29.0437, -24.9716],\n",
      "        [ 28.4688,  24.0948,  24.7838, -27.4753,  28.6374, -24.8244]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.987817287445068\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4534, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0068, 24.4960, 24.9345],\n",
      "        [28.6730, 23.9190, 24.6820],\n",
      "        [28.7509, 23.8647, 25.0246],\n",
      "        [29.0754, 24.4995, 25.2944],\n",
      "        [29.0487, 24.4255, 25.3718],\n",
      "        [28.2761, 23.9062, 24.4975]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.7138, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3969,  29.6167, -25.3687],\n",
      "        [-28.1940,  29.3112, -25.2862],\n",
      "        [-28.5212,  29.5720, -25.4495],\n",
      "        [-27.4611,  28.5409, -24.6849],\n",
      "        [-28.3690,  29.3852, -25.3797],\n",
      "        [-27.8472,  28.8867, -24.6656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0068,  24.4960,  24.9345, -28.3969,  29.6167, -25.3687],\n",
      "        [ 28.6730,  23.9190,  24.6820, -28.1940,  29.3112, -25.2862],\n",
      "        [ 28.7509,  23.8647,  25.0246, -28.5212,  29.5720, -25.4495],\n",
      "        [ 29.0754,  24.4995,  25.2944, -27.4611,  28.5409, -24.6849],\n",
      "        [ 29.0487,  24.4255,  25.3718, -28.3690,  29.3852, -25.3797],\n",
      "        [ 28.2761,  23.9062,  24.4975, -27.8472,  28.8867, -24.6656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.95298957824707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.5982, 24.5526, 25.3029],\n",
      "        [29.3104, 24.6422, 25.3999],\n",
      "        [28.9358, 24.1771, 24.4519],\n",
      "        [29.0085, 24.3235, 25.0398],\n",
      "        [28.4670, 24.0842, 24.6833],\n",
      "        [28.8629, 24.4707, 25.2331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.4833, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8869,  28.8813, -24.8697],\n",
      "        [-27.1682,  28.7755, -24.6938],\n",
      "        [-27.8333,  29.4842, -25.3196],\n",
      "        [-27.3710,  28.4942, -24.9961],\n",
      "        [-27.1876,  28.7135, -24.6779],\n",
      "        [-28.2147,  28.9750, -25.0985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.5982,  24.5526,  25.3029, -27.8869,  28.8813, -24.8697],\n",
      "        [ 29.3104,  24.6422,  25.3999, -27.1682,  28.7755, -24.6938],\n",
      "        [ 28.9358,  24.1771,  24.4519, -27.8333,  29.4842, -25.3196],\n",
      "        [ 29.0085,  24.3235,  25.0398, -27.3710,  28.4942, -24.9961],\n",
      "        [ 28.4670,  24.0842,  24.6833, -27.1876,  28.7135, -24.6779],\n",
      "        [ 28.8629,  24.4707,  25.2331, -28.2147,  28.9750, -25.0985]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.944350719451904\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5553, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.4228, 24.1750, 24.7695],\n",
      "        [28.7285, 24.4191, 24.6275],\n",
      "        [28.8293, 24.3218, 24.6043],\n",
      "        [28.4487, 24.3881, 24.8134],\n",
      "        [28.3396, 23.7114, 24.3635],\n",
      "        [28.4453, 24.3797, 24.2121]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.3548, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8937,  28.9052, -25.1075],\n",
      "        [-28.3164,  29.7981, -25.8643],\n",
      "        [-27.2508,  28.9181, -24.6808],\n",
      "        [-27.3121,  28.7729, -24.4992],\n",
      "        [-27.4845,  28.7519, -24.7945],\n",
      "        [-27.9442,  29.1549, -25.0590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.4228,  24.1750,  24.7695, -27.8937,  28.9052, -25.1075],\n",
      "        [ 28.7285,  24.4191,  24.6275, -28.3164,  29.7981, -25.8643],\n",
      "        [ 28.8293,  24.3218,  24.6043, -27.2508,  28.9181, -24.6808],\n",
      "        [ 28.4487,  24.3881,  24.8134, -27.3121,  28.7729, -24.4992],\n",
      "        [ 28.3396,  23.7114,  24.3635, -27.4845,  28.7519, -24.7945],\n",
      "        [ 28.4453,  24.3797,  24.2121, -27.9442,  29.1549, -25.0590]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.846578598022461\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1800, 25.2423, 25.2967],\n",
      "        [29.2167, 24.3188, 25.2898],\n",
      "        [29.1330, 24.2646, 25.2959],\n",
      "        [28.9499, 24.6145, 25.1880],\n",
      "        [29.2484, 24.6192, 25.2757],\n",
      "        [28.9741, 24.1560, 24.6508]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.2592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3090,  29.3434, -25.3302],\n",
      "        [-27.7414,  29.3478, -25.1230],\n",
      "        [-28.4543,  29.8049, -25.7133],\n",
      "        [-27.8726,  28.9709, -24.9947],\n",
      "        [-27.9369,  28.9306, -25.0131],\n",
      "        [-27.6997,  29.0465, -24.8307]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1800,  25.2423,  25.2967, -28.3090,  29.3434, -25.3302],\n",
      "        [ 29.2167,  24.3188,  25.2898, -27.7414,  29.3478, -25.1230],\n",
      "        [ 29.1330,  24.2646,  25.2959, -28.4543,  29.8049, -25.7133],\n",
      "        [ 28.9499,  24.6145,  25.1880, -27.8726,  28.9709, -24.9947],\n",
      "        [ 29.2484,  24.6192,  25.2757, -27.9369,  28.9306, -25.0131],\n",
      "        [ 28.9741,  24.1560,  24.6508, -27.6997,  29.0465, -24.8307]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.000606060028076\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7049, 24.0684, 24.9506],\n",
      "        [29.5921, 24.7312, 25.5304],\n",
      "        [28.9412, 24.5093, 25.0312],\n",
      "        [29.0730, 24.5403, 25.0198],\n",
      "        [28.7314, 24.2383, 25.0456],\n",
      "        [29.3806, 25.0534, 25.2130]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.2612, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2423,  29.4594, -25.2728],\n",
      "        [-27.5992,  28.8313, -25.1890],\n",
      "        [-27.8530,  29.4791, -25.3010],\n",
      "        [-28.1097,  29.3330, -25.3475],\n",
      "        [-27.8134,  29.3386, -25.1212],\n",
      "        [-27.8462,  29.3662, -25.2999]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7049,  24.0684,  24.9506, -28.2423,  29.4594, -25.2728],\n",
      "        [ 29.5921,  24.7312,  25.5304, -27.5992,  28.8313, -25.1890],\n",
      "        [ 28.9412,  24.5093,  25.0312, -27.8530,  29.4791, -25.3010],\n",
      "        [ 29.0730,  24.5403,  25.0198, -28.1097,  29.3330, -25.3475],\n",
      "        [ 28.7314,  24.2383,  25.0456, -27.8134,  29.3386, -25.1212],\n",
      "        [ 29.3806,  25.0534,  25.2130, -27.8462,  29.3662, -25.2999]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.912757396697998\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2882, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9176, 24.4150, 24.9209],\n",
      "        [27.9966, 23.9887, 24.3715],\n",
      "        [29.5713, 24.5201, 25.1986],\n",
      "        [28.5746, 24.0916, 24.7627],\n",
      "        [28.6180, 24.3468, 24.9527],\n",
      "        [28.9166, 24.5701, 25.1148]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.4440, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3367,  28.7141, -24.5722],\n",
      "        [-27.7056,  29.0068, -25.0157],\n",
      "        [-28.4403,  29.2827, -25.6996],\n",
      "        [-27.8784,  29.4702, -24.9872],\n",
      "        [-27.9132,  29.0611, -24.9382],\n",
      "        [-28.8197,  29.9769, -25.7518]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9176,  24.4150,  24.9209, -27.3367,  28.7141, -24.5722],\n",
      "        [ 27.9966,  23.9887,  24.3715, -27.7056,  29.0068, -25.0157],\n",
      "        [ 29.5713,  24.5201,  25.1986, -28.4403,  29.2827, -25.6996],\n",
      "        [ 28.5746,  24.0916,  24.7627, -27.8784,  29.4702, -24.9872],\n",
      "        [ 28.6180,  24.3468,  24.9527, -27.9132,  29.0611, -24.9382],\n",
      "        [ 28.9166,  24.5701,  25.1148, -28.8197,  29.9769, -25.7518]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.851737022399902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.6164, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4674, 25.0232, 25.3476],\n",
      "        [28.2701, 24.1710, 24.6364],\n",
      "        [28.6271, 23.8758, 24.9532],\n",
      "        [28.9202, 24.3306, 24.7038],\n",
      "        [29.5043, 24.6536, 25.1130],\n",
      "        [28.2102, 23.7893, 24.2518]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7072, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1273,  28.9106, -25.0971],\n",
      "        [-28.3501,  29.5789, -25.3257],\n",
      "        [-28.4304,  29.2859, -25.4976],\n",
      "        [-27.5979,  28.7468, -25.2126],\n",
      "        [-27.3874,  28.3654, -24.3199],\n",
      "        [-27.6797,  29.0002, -25.2453]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4674,  25.0232,  25.3476, -28.1273,  28.9106, -25.0971],\n",
      "        [ 28.2701,  24.1710,  24.6364, -28.3501,  29.5789, -25.3257],\n",
      "        [ 28.6271,  23.8758,  24.9532, -28.4304,  29.2859, -25.4976],\n",
      "        [ 28.9202,  24.3306,  24.7038, -27.5979,  28.7468, -25.2126],\n",
      "        [ 29.5043,  24.6536,  25.1130, -27.3874,  28.3654, -24.3199],\n",
      "        [ 28.2102,  23.7893,  24.2518, -27.6797,  29.0002, -25.2453]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.985556125640869\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9217, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2223, 24.5079, 25.2574],\n",
      "        [28.3531, 23.9634, 25.0659],\n",
      "        [28.4188, 24.4151, 24.8840],\n",
      "        [28.2636, 24.2610, 24.6592],\n",
      "        [28.7996, 23.9483, 24.9728],\n",
      "        [29.0525, 24.7555, 25.4744]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.2920, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1521,  29.9877, -25.7099],\n",
      "        [-27.9583,  29.2882, -25.2916],\n",
      "        [-28.3418,  29.6110, -25.7011],\n",
      "        [-27.3267,  28.6959, -24.8104],\n",
      "        [-27.9600,  28.9636, -24.8717],\n",
      "        [-28.1111,  29.3554, -25.3629]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2223,  24.5079,  25.2574, -28.1521,  29.9877, -25.7099],\n",
      "        [ 28.3531,  23.9634,  25.0659, -27.9583,  29.2882, -25.2916],\n",
      "        [ 28.4188,  24.4151,  24.8840, -28.3418,  29.6110, -25.7011],\n",
      "        [ 28.2636,  24.2610,  24.6592, -27.3267,  28.6959, -24.8104],\n",
      "        [ 28.7996,  23.9483,  24.9728, -27.9600,  28.9636, -24.8717],\n",
      "        [ 29.0525,  24.7555,  25.4744, -28.1111,  29.3554, -25.3629]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.013274669647217\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3451, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8810, 24.3953, 24.9424],\n",
      "        [29.0184, 24.6903, 24.8902],\n",
      "        [28.8972, 24.6769, 25.2593],\n",
      "        [28.6215, 24.2904, 24.8096],\n",
      "        [29.1079, 25.0552, 25.5067],\n",
      "        [29.3424, 24.7879, 25.3378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.8968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5718,  28.8182, -24.6114],\n",
      "        [-27.4480,  28.8105, -24.9310],\n",
      "        [-28.7256,  30.1376, -25.9785],\n",
      "        [-28.2241,  29.7650, -25.2089],\n",
      "        [-28.3652,  29.8942, -25.5217],\n",
      "        [-28.1022,  29.6076, -25.4343]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8810,  24.3953,  24.9424, -27.5718,  28.8182, -24.6114],\n",
      "        [ 29.0184,  24.6903,  24.8902, -27.4480,  28.8105, -24.9310],\n",
      "        [ 28.8972,  24.6769,  25.2593, -28.7256,  30.1376, -25.9785],\n",
      "        [ 28.6215,  24.2904,  24.8096, -28.2241,  29.7650, -25.2089],\n",
      "        [ 29.1079,  25.0552,  25.5067, -28.3652,  29.8942, -25.5217],\n",
      "        [ 29.3424,  24.7879,  25.3378, -28.1022,  29.6076, -25.4343]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.870548248291016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0255, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3292, 24.7398, 25.4794],\n",
      "        [28.7180, 24.3312, 24.9829],\n",
      "        [29.2516, 24.7468, 25.4320],\n",
      "        [28.8123, 24.3788, 25.0581],\n",
      "        [29.0440, 24.4293, 24.8046],\n",
      "        [28.9111, 24.5024, 25.0158]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.5117, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2878,  29.2797, -25.0440],\n",
      "        [-27.8265,  28.7296, -24.8668],\n",
      "        [-28.2054,  29.4638, -25.1382],\n",
      "        [-27.3318,  28.8370, -24.5542],\n",
      "        [-27.7612,  29.0486, -25.0519],\n",
      "        [-27.5904,  29.2644, -25.3757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3292,  24.7398,  25.4794, -28.2878,  29.2797, -25.0440],\n",
      "        [ 28.7180,  24.3312,  24.9829, -27.8265,  28.7296, -24.8668],\n",
      "        [ 29.2516,  24.7468,  25.4320, -28.2054,  29.4638, -25.1382],\n",
      "        [ 28.8123,  24.3788,  25.0581, -27.3318,  28.8370, -24.5542],\n",
      "        [ 29.0440,  24.4293,  24.8046, -27.7612,  29.0486, -25.0519],\n",
      "        [ 28.9111,  24.5024,  25.0158, -27.5904,  29.2644, -25.3757]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.99858283996582\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3217, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1688, 24.3111, 25.0023],\n",
      "        [28.5931, 24.7136, 25.1035],\n",
      "        [29.1297, 24.8134, 25.2966],\n",
      "        [28.9996, 25.0561, 25.2628],\n",
      "        [29.2366, 24.7572, 25.3223],\n",
      "        [28.6653, 24.5583, 24.8139]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.7365, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2241,  29.3165, -25.4483],\n",
      "        [-27.7351,  28.7169, -24.9471],\n",
      "        [-28.0855,  29.5868, -25.2277],\n",
      "        [-28.0363,  29.2539, -25.1577],\n",
      "        [-27.8425,  29.1315, -24.9512],\n",
      "        [-28.2561,  29.1573, -25.5335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1688,  24.3111,  25.0023, -28.2241,  29.3165, -25.4483],\n",
      "        [ 28.5931,  24.7136,  25.1035, -27.7351,  28.7169, -24.9471],\n",
      "        [ 29.1297,  24.8134,  25.2966, -28.0855,  29.5868, -25.2277],\n",
      "        [ 28.9996,  25.0561,  25.2628, -28.0363,  29.2539, -25.1577],\n",
      "        [ 29.2366,  24.7572,  25.3223, -27.8425,  29.1315, -24.9512],\n",
      "        [ 28.6653,  24.5583,  24.8139, -28.2561,  29.1573, -25.5335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.963379859924316\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1756, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6647, 24.3934, 24.6527],\n",
      "        [29.2537, 24.9099, 25.2057],\n",
      "        [29.0832, 24.0628, 24.7731],\n",
      "        [29.0897, 24.8630, 25.0881],\n",
      "        [28.7412, 23.9904, 24.8887],\n",
      "        [28.6800, 23.9708, 24.8169]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9483, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0699,  29.2281, -25.3577],\n",
      "        [-28.0421,  29.3993, -25.3961],\n",
      "        [-28.4863,  29.3801, -25.5272],\n",
      "        [-28.3578,  29.4684, -25.5053],\n",
      "        [-28.2103,  28.9571, -25.3093],\n",
      "        [-28.3242,  29.6327, -25.4656]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6647,  24.3934,  24.6527, -28.0699,  29.2281, -25.3577],\n",
      "        [ 29.2537,  24.9099,  25.2057, -28.0421,  29.3993, -25.3961],\n",
      "        [ 29.0832,  24.0628,  24.7731, -28.4863,  29.3801, -25.5272],\n",
      "        [ 29.0897,  24.8630,  25.0881, -28.3578,  29.4684, -25.5053],\n",
      "        [ 28.7412,  23.9904,  24.8887, -28.2103,  28.9571, -25.3093],\n",
      "        [ 28.6800,  23.9708,  24.8169, -28.3242,  29.6327, -25.4656]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.909816741943359\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8868, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3431, 24.6883, 25.4300],\n",
      "        [28.0583, 23.9899, 24.2004],\n",
      "        [29.0761, 24.6691, 25.3813],\n",
      "        [29.0608, 24.9660, 25.2458],\n",
      "        [28.9019, 24.6254, 25.2351],\n",
      "        [29.0431, 24.2895, 25.0999]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.4701, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9842,  28.9168, -25.0470],\n",
      "        [-27.8995,  29.1221, -25.0667],\n",
      "        [-27.5873,  28.9605, -24.8332],\n",
      "        [-27.9620,  28.6612, -24.9533],\n",
      "        [-28.2229,  29.4829, -25.5407],\n",
      "        [-28.0371,  28.9926, -25.5637]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3431,  24.6883,  25.4300, -27.9842,  28.9168, -25.0470],\n",
      "        [ 28.0583,  23.9899,  24.2004, -27.8995,  29.1221, -25.0667],\n",
      "        [ 29.0761,  24.6691,  25.3813, -27.5873,  28.9605, -24.8332],\n",
      "        [ 29.0608,  24.9660,  25.2458, -27.9620,  28.6612, -24.9533],\n",
      "        [ 28.9019,  24.6254,  25.2351, -28.2229,  29.4829, -25.5407],\n",
      "        [ 29.0431,  24.2895,  25.0999, -28.0371,  28.9926, -25.5637]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.975104331970215\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8489, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3582, 24.1794, 24.5179],\n",
      "        [29.4703, 24.9703, 25.5012],\n",
      "        [29.0962, 24.3365, 25.4669],\n",
      "        [28.1301, 24.1606, 24.4384],\n",
      "        [29.4089, 24.9212, 25.6410],\n",
      "        [29.2130, 24.3668, 24.7420]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.4878, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1917,  29.0021, -24.8327],\n",
      "        [-27.9227,  29.2349, -25.1388],\n",
      "        [-28.3740,  29.9445, -25.7572],\n",
      "        [-27.9215,  29.2985, -24.9176],\n",
      "        [-27.2368,  28.6103, -24.6405],\n",
      "        [-27.4880,  29.0609, -24.7538]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3582,  24.1794,  24.5179, -28.1917,  29.0021, -24.8327],\n",
      "        [ 29.4703,  24.9703,  25.5012, -27.9227,  29.2349, -25.1388],\n",
      "        [ 29.0962,  24.3365,  25.4669, -28.3740,  29.9445, -25.7572],\n",
      "        [ 28.1301,  24.1606,  24.4384, -27.9215,  29.2985, -24.9176],\n",
      "        [ 29.4089,  24.9212,  25.6410, -27.2368,  28.6103, -24.6405],\n",
      "        [ 29.2130,  24.3668,  24.7420, -27.4880,  29.0609, -24.7538]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.8595476150512695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7642, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.8809, 25.1310, 25.5307],\n",
      "        [29.0108, 24.2485, 24.9322],\n",
      "        [28.1875, 23.8831, 24.7663],\n",
      "        [28.4475, 24.0816, 24.7380],\n",
      "        [28.3278, 23.8396, 24.7194],\n",
      "        [29.0798, 24.4521, 25.4076]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.4647, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3661,  28.9165, -25.3388],\n",
      "        [-28.0569,  29.3217, -25.0917],\n",
      "        [-27.4405,  28.4828, -24.7520],\n",
      "        [-28.3967,  29.3293, -25.2895],\n",
      "        [-28.2523,  29.3187, -25.4039],\n",
      "        [-28.0770,  28.9616, -25.0232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.8809,  25.1310,  25.5307, -28.3661,  28.9165, -25.3388],\n",
      "        [ 29.0108,  24.2485,  24.9322, -28.0569,  29.3217, -25.0917],\n",
      "        [ 28.1875,  23.8831,  24.7663, -27.4405,  28.4828, -24.7520],\n",
      "        [ 28.4475,  24.0816,  24.7380, -28.3967,  29.3293, -25.2895],\n",
      "        [ 28.3278,  23.8396,  24.7194, -28.2523,  29.3187, -25.4039],\n",
      "        [ 29.0798,  24.4521,  25.4076, -28.0770,  28.9616, -25.0232]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.05684232711792\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8306, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0347, 24.6432, 25.4828],\n",
      "        [29.0213, 24.2458, 25.0930],\n",
      "        [29.0153, 24.7043, 25.4779],\n",
      "        [29.3101, 24.6077, 25.3815],\n",
      "        [28.8916, 24.4406, 24.7018],\n",
      "        [28.5494, 24.6259, 24.8570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8800, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7003,  28.6791, -24.6093],\n",
      "        [-27.8253,  29.1704, -24.8020],\n",
      "        [-28.4186,  29.2557, -25.1960],\n",
      "        [-28.3142,  29.2242, -24.9720],\n",
      "        [-28.1427,  28.9470, -25.3869],\n",
      "        [-28.7243,  29.5953, -25.7349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0347,  24.6432,  25.4828, -27.7003,  28.6791, -24.6093],\n",
      "        [ 29.0213,  24.2458,  25.0930, -27.8253,  29.1704, -24.8020],\n",
      "        [ 29.0153,  24.7043,  25.4779, -28.4186,  29.2557, -25.1960],\n",
      "        [ 29.3101,  24.6077,  25.3815, -28.3142,  29.2242, -24.9720],\n",
      "        [ 28.8916,  24.4406,  24.7018, -28.1427,  28.9470, -25.3869],\n",
      "        [ 28.5494,  24.6259,  24.8570, -28.7243,  29.5953, -25.7349]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.929547309875488\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7425, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1298, 24.8543, 25.2749],\n",
      "        [29.3060, 24.7077, 25.2692],\n",
      "        [28.6471, 24.2774, 24.6437],\n",
      "        [27.9531, 23.4137, 24.2328],\n",
      "        [29.3586, 24.7776, 24.8876],\n",
      "        [28.8360, 24.3605, 24.9451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(55.9810, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9496,  29.2460, -24.9706],\n",
      "        [-28.4630,  29.7046, -25.7223],\n",
      "        [-28.0223,  29.4298, -25.2979],\n",
      "        [-28.0825,  29.3349, -24.6939],\n",
      "        [-27.9691,  29.2230, -25.2205],\n",
      "        [-27.8023,  28.9876, -24.9389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1298,  24.8543,  25.2749, -27.9496,  29.2460, -24.9706],\n",
      "        [ 29.3060,  24.7077,  25.2692, -28.4630,  29.7046, -25.7223],\n",
      "        [ 28.6471,  24.2774,  24.6437, -28.0223,  29.4298, -25.2979],\n",
      "        [ 27.9531,  23.4137,  24.2328, -28.0825,  29.3349, -24.6939],\n",
      "        [ 29.3586,  24.7776,  24.8876, -27.9691,  29.2230, -25.2205],\n",
      "        [ 28.8360,  24.3605,  24.9451, -27.8023,  28.9876, -24.9389]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.9793572425842285\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.6353, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8228, 24.9818, 25.3007],\n",
      "        [29.0919, 24.4775, 24.6909],\n",
      "        [28.8463, 24.3622, 25.0182],\n",
      "        [29.0768, 24.3647, 25.0727],\n",
      "        [28.9292, 24.0179, 25.1615],\n",
      "        [29.3457, 24.9171, 25.2018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.4638, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1870,  29.8642, -25.4759],\n",
      "        [-28.6327,  29.8645, -25.8299],\n",
      "        [-28.2504,  29.2283, -25.1800],\n",
      "        [-28.6895,  29.7442, -26.1616],\n",
      "        [-27.2607,  28.5677, -24.5852],\n",
      "        [-27.7763,  28.7169, -24.8642]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8228,  24.9818,  25.3007, -28.1870,  29.8642, -25.4759],\n",
      "        [ 29.0919,  24.4775,  24.6909, -28.6327,  29.8645, -25.8299],\n",
      "        [ 28.8463,  24.3622,  25.0182, -28.2504,  29.2283, -25.1800],\n",
      "        [ 29.0768,  24.3647,  25.0727, -28.6895,  29.7442, -26.1616],\n",
      "        [ 28.9292,  24.0179,  25.1615, -27.2607,  28.5677, -24.5852],\n",
      "        [ 29.3457,  24.9171,  25.2018, -27.7763,  28.7169, -24.8642]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.020571708679199\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1722, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.7733, 24.6828, 25.5203],\n",
      "        [29.2918, 24.8392, 24.9225],\n",
      "        [28.5616, 24.1136, 25.6399],\n",
      "        [28.9279, 24.4462, 25.1976],\n",
      "        [29.2655, 24.5640, 25.3829],\n",
      "        [28.9400, 24.4101, 24.9581]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.8587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2705,  29.8218, -25.6649],\n",
      "        [-28.3471,  29.3630, -25.2329],\n",
      "        [-27.9623,  29.4978, -25.6053],\n",
      "        [-28.1699,  29.4420, -25.2267],\n",
      "        [-28.2541,  29.6699, -25.3094],\n",
      "        [-28.8066,  29.9502, -25.8852]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.7733,  24.6828,  25.5203, -28.2705,  29.8218, -25.6649],\n",
      "        [ 29.2918,  24.8392,  24.9225, -28.3471,  29.3630, -25.2329],\n",
      "        [ 28.5616,  24.1136,  25.6399, -27.9623,  29.4978, -25.6053],\n",
      "        [ 28.9279,  24.4462,  25.1976, -28.1699,  29.4420, -25.2267],\n",
      "        [ 29.2655,  24.5640,  25.3829, -28.2541,  29.6699, -25.3094],\n",
      "        [ 28.9400,  24.4101,  24.9581, -28.8066,  29.9502, -25.8852]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.084598541259766\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4218, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6737, 24.5707, 24.7897],\n",
      "        [28.9830, 24.5877, 25.1728],\n",
      "        [28.2864, 24.1225, 24.5862],\n",
      "        [29.7149, 25.0830, 25.5232],\n",
      "        [29.2049, 24.8373, 25.4596],\n",
      "        [28.9537, 24.5127, 24.8862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.2321, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3449,  29.4584, -25.3487],\n",
      "        [-27.5914,  29.1620, -24.9212],\n",
      "        [-27.9342,  28.9680, -25.2305],\n",
      "        [-28.1818,  29.3496, -25.4218],\n",
      "        [-28.1009,  29.1010, -25.1680],\n",
      "        [-28.0761,  28.9295, -24.9748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6737,  24.5707,  24.7897, -28.3449,  29.4584, -25.3487],\n",
      "        [ 28.9830,  24.5877,  25.1728, -27.5914,  29.1620, -24.9212],\n",
      "        [ 28.2864,  24.1225,  24.5862, -27.9342,  28.9680, -25.2305],\n",
      "        [ 29.7149,  25.0830,  25.5232, -28.1818,  29.3496, -25.4218],\n",
      "        [ 29.2049,  24.8373,  25.4596, -28.1009,  29.1010, -25.1680],\n",
      "        [ 28.9537,  24.5127,  24.8862, -28.0761,  28.9295, -24.9748]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.960218906402588\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0830, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9352, 24.8865, 25.1555],\n",
      "        [28.6939, 24.4191, 24.9749],\n",
      "        [29.8054, 25.0952, 25.9943],\n",
      "        [28.7194, 24.5020, 24.6351],\n",
      "        [28.9922, 24.3558, 24.7106],\n",
      "        [29.3321, 24.8871, 25.4993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.3499, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0405,  29.0289, -25.0218],\n",
      "        [-28.3978,  29.5029, -25.8107],\n",
      "        [-28.4456,  29.4332, -25.3379],\n",
      "        [-27.6969,  29.5989, -25.5840],\n",
      "        [-28.0213,  29.1435, -25.1219],\n",
      "        [-27.8144,  28.9674, -25.1177]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9352,  24.8865,  25.1555, -28.0405,  29.0289, -25.0218],\n",
      "        [ 28.6939,  24.4191,  24.9749, -28.3978,  29.5029, -25.8107],\n",
      "        [ 29.8054,  25.0952,  25.9943, -28.4456,  29.4332, -25.3379],\n",
      "        [ 28.7194,  24.5020,  24.6351, -27.6969,  29.5989, -25.5840],\n",
      "        [ 28.9922,  24.3558,  24.7106, -28.0213,  29.1435, -25.1219],\n",
      "        [ 29.3321,  24.8871,  25.4993, -27.8144,  28.9674, -25.1177]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.9681854248046875\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0083, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9881, 24.6298, 25.4579],\n",
      "        [29.0461, 24.5625, 24.9674],\n",
      "        [28.7841, 24.3145, 24.9134],\n",
      "        [29.3871, 24.6144, 25.0351],\n",
      "        [27.6581, 23.4234, 23.9294],\n",
      "        [28.5672, 24.7329, 24.7217]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.1928, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.3294,  28.5418, -24.7794],\n",
      "        [-27.9271,  29.4018, -24.7753],\n",
      "        [-27.7606,  29.0684, -25.1720],\n",
      "        [-28.0112,  29.5637, -25.4110],\n",
      "        [-27.9015,  29.0200, -24.7948],\n",
      "        [-27.4190,  28.0412, -24.9170]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9881,  24.6298,  25.4579, -27.3294,  28.5418, -24.7794],\n",
      "        [ 29.0461,  24.5625,  24.9674, -27.9271,  29.4018, -24.7753],\n",
      "        [ 28.7841,  24.3145,  24.9134, -27.7606,  29.0684, -25.1720],\n",
      "        [ 29.3871,  24.6144,  25.0351, -28.0112,  29.5637, -25.4110],\n",
      "        [ 27.6581,  23.4234,  23.9294, -27.9015,  29.0200, -24.7948],\n",
      "        [ 28.5672,  24.7329,  24.7217, -27.4190,  28.0412, -24.9170]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.923346996307373\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4322, 24.9936, 25.0914],\n",
      "        [28.9977, 24.5853, 25.0096],\n",
      "        [28.9973, 24.3041, 24.9339],\n",
      "        [29.4993, 25.0182, 25.3368],\n",
      "        [28.4193, 24.3185, 24.6705],\n",
      "        [28.4364, 24.6966, 24.9368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.0897, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4985,  29.7641, -25.8729],\n",
      "        [-27.8063,  29.1079, -25.4402],\n",
      "        [-28.1879,  29.4587, -25.6057],\n",
      "        [-28.3074,  29.1095, -25.5798],\n",
      "        [-28.5377,  29.9507, -25.8925],\n",
      "        [-28.1298,  29.1699, -25.4502]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4322,  24.9936,  25.0914, -28.4985,  29.7641, -25.8729],\n",
      "        [ 28.9977,  24.5853,  25.0096, -27.8063,  29.1079, -25.4402],\n",
      "        [ 28.9973,  24.3041,  24.9339, -28.1879,  29.4587, -25.6057],\n",
      "        [ 29.4993,  25.0182,  25.3368, -28.3074,  29.1095, -25.5798],\n",
      "        [ 28.4193,  24.3185,  24.6705, -28.5377,  29.9507, -25.8925],\n",
      "        [ 28.4364,  24.6966,  24.9368, -28.1298,  29.1699, -25.4502]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.0774617195129395\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4951, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.6693, 25.0482, 25.6748],\n",
      "        [29.2297, 24.6495, 25.4656],\n",
      "        [29.3171, 24.5249, 25.3106],\n",
      "        [28.9663, 24.6219, 25.2737],\n",
      "        [28.6491, 24.1883, 24.5821],\n",
      "        [29.5396, 24.8472, 25.7717]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9707, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4972,  29.4036, -25.3262],\n",
      "        [-28.1919,  29.5680, -25.4417],\n",
      "        [-28.7214,  29.6309, -25.7378],\n",
      "        [-28.4182,  29.3181, -25.3123],\n",
      "        [-28.7755,  29.9714, -25.8984],\n",
      "        [-27.2169,  28.4636, -24.7154]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.6693,  25.0482,  25.6748, -28.4972,  29.4036, -25.3262],\n",
      "        [ 29.2297,  24.6495,  25.4656, -28.1919,  29.5680, -25.4417],\n",
      "        [ 29.3171,  24.5249,  25.3106, -28.7214,  29.6309, -25.7378],\n",
      "        [ 28.9663,  24.6219,  25.2737, -28.4182,  29.3181, -25.3123],\n",
      "        [ 28.6491,  24.1883,  24.5821, -28.7755,  29.9714, -25.8984],\n",
      "        [ 29.5396,  24.8472,  25.7717, -27.2169,  28.4636, -24.7154]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.091791152954102\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6963, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3232, 24.6045, 25.0801],\n",
      "        [29.9164, 25.2699, 25.9514],\n",
      "        [28.8128, 24.5939, 25.0159],\n",
      "        [28.3068, 24.2395, 25.0553],\n",
      "        [28.8989, 24.1546, 25.1277],\n",
      "        [28.6961, 24.5095, 25.0216]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.9259, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3224,  29.4327, -25.1360],\n",
      "        [-28.0222,  29.3320, -25.2972],\n",
      "        [-27.9178,  28.8806, -24.9120],\n",
      "        [-28.6126,  29.3476, -25.6540],\n",
      "        [-28.3868,  29.4111, -25.1534],\n",
      "        [-27.7164,  28.8984, -24.8820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3232,  24.6045,  25.0801, -28.3224,  29.4327, -25.1360],\n",
      "        [ 29.9164,  25.2699,  25.9514, -28.0222,  29.3320, -25.2972],\n",
      "        [ 28.8128,  24.5939,  25.0159, -27.9178,  28.8806, -24.9120],\n",
      "        [ 28.3068,  24.2395,  25.0553, -28.6126,  29.3476, -25.6540],\n",
      "        [ 28.8989,  24.1546,  25.1277, -28.3868,  29.4111, -25.1534],\n",
      "        [ 28.6961,  24.5095,  25.0216, -27.7164,  28.8984, -24.8820]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.015130519866943\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6765, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7038, 24.4273, 25.2153],\n",
      "        [28.8605, 24.3133, 24.8416],\n",
      "        [29.0688, 24.9474, 25.5508],\n",
      "        [29.2199, 24.5354, 25.1731],\n",
      "        [29.4632, 24.7813, 24.9741],\n",
      "        [29.4051, 24.9756, 25.5414]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2372, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.7515,  28.8715, -25.3413],\n",
      "        [-28.6689,  29.9568, -25.9003],\n",
      "        [-27.9526,  29.2281, -25.2297],\n",
      "        [-27.5778,  28.9301, -24.6237],\n",
      "        [-29.1161,  30.6007, -26.1950],\n",
      "        [-28.1271,  29.2848, -25.6456]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7038,  24.4273,  25.2153, -27.7515,  28.8715, -25.3413],\n",
      "        [ 28.8605,  24.3133,  24.8416, -28.6689,  29.9568, -25.9003],\n",
      "        [ 29.0688,  24.9474,  25.5508, -27.9526,  29.2281, -25.2297],\n",
      "        [ 29.2199,  24.5354,  25.1731, -27.5778,  28.9301, -24.6237],\n",
      "        [ 29.4632,  24.7813,  24.9741, -29.1161,  30.6007, -26.1950],\n",
      "        [ 29.4051,  24.9756,  25.5414, -28.1271,  29.2848, -25.6456]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.943209648132324\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0082, 23.8697, 24.3763],\n",
      "        [28.6123, 24.2239, 24.8456],\n",
      "        [28.7597, 24.0892, 25.2088],\n",
      "        [28.6460, 24.2184, 25.1141],\n",
      "        [29.2661, 24.7082, 25.5803],\n",
      "        [28.9758, 24.6922, 25.2632]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8615, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3880,  29.4704, -25.2835],\n",
      "        [-28.3967,  29.5808, -25.6959],\n",
      "        [-28.3350,  29.5152, -25.0042],\n",
      "        [-28.4789,  29.2872, -25.6991],\n",
      "        [-27.8248,  28.7625, -24.6909],\n",
      "        [-28.3211,  29.5997, -25.4120]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0082,  23.8697,  24.3763, -28.3880,  29.4704, -25.2835],\n",
      "        [ 28.6123,  24.2239,  24.8456, -28.3967,  29.5808, -25.6959],\n",
      "        [ 28.7597,  24.0892,  25.2088, -28.3350,  29.5152, -25.0042],\n",
      "        [ 28.6460,  24.2184,  25.1141, -28.4789,  29.2872, -25.6991],\n",
      "        [ 29.2661,  24.7082,  25.5803, -27.8248,  28.7625, -24.6909],\n",
      "        [ 28.9758,  24.6922,  25.2632, -28.3211,  29.5997, -25.4120]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.888181686401367\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.5832, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.0546, 24.1325, 24.7257],\n",
      "        [28.5139, 24.5397, 25.0517],\n",
      "        [29.1702, 24.3354, 25.0676],\n",
      "        [29.2473, 24.5996, 25.3201],\n",
      "        [29.0783, 24.4420, 25.1511],\n",
      "        [29.1282, 24.4687, 25.1655]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.1432, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1065,  29.5732, -25.2615],\n",
      "        [-28.5614,  30.0053, -25.5807],\n",
      "        [-28.2984,  29.7364, -25.4462],\n",
      "        [-27.9470,  29.1298, -25.2540],\n",
      "        [-27.8757,  29.1116, -25.3483],\n",
      "        [-28.0688,  29.6144, -25.1804]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.0546,  24.1325,  24.7257, -28.1065,  29.5732, -25.2615],\n",
      "        [ 28.5139,  24.5397,  25.0517, -28.5614,  30.0053, -25.5807],\n",
      "        [ 29.1702,  24.3354,  25.0676, -28.2984,  29.7364, -25.4462],\n",
      "        [ 29.2473,  24.5996,  25.3201, -27.9470,  29.1298, -25.2540],\n",
      "        [ 29.0783,  24.4420,  25.1511, -27.8757,  29.1116, -25.3483],\n",
      "        [ 29.1282,  24.4687,  25.1655, -28.0688,  29.6144, -25.1804]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.913216590881348\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.8498, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3817, 24.4492, 25.0454],\n",
      "        [29.1392, 24.9660, 25.3795],\n",
      "        [29.6308, 25.0625, 25.2270],\n",
      "        [29.3185, 24.7136, 25.5930],\n",
      "        [28.9850, 24.2513, 24.8338],\n",
      "        [29.4306, 24.8985, 25.4117]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8222, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6220,  28.3115, -24.6706],\n",
      "        [-28.1721,  29.6327, -25.6026],\n",
      "        [-28.0505,  29.3736, -25.1555],\n",
      "        [-28.4134,  29.7905, -25.5832],\n",
      "        [-28.2376,  29.1100, -25.2326],\n",
      "        [-28.3925,  29.8094, -25.5426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3817,  24.4492,  25.0454, -27.6220,  28.3115, -24.6706],\n",
      "        [ 29.1392,  24.9660,  25.3795, -28.1721,  29.6327, -25.6026],\n",
      "        [ 29.6308,  25.0625,  25.2270, -28.0505,  29.3736, -25.1555],\n",
      "        [ 29.3185,  24.7136,  25.5930, -28.4134,  29.7905, -25.5832],\n",
      "        [ 28.9850,  24.2513,  24.8338, -28.2376,  29.1100, -25.2326],\n",
      "        [ 29.4306,  24.8985,  25.4117, -28.3925,  29.8094, -25.5426]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.931395530700684\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3181, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9846, 24.3797, 25.0511],\n",
      "        [29.0757, 24.1963, 24.9539],\n",
      "        [28.4817, 23.7596, 24.4066],\n",
      "        [29.5114, 25.3782, 25.0154],\n",
      "        [29.3004, 24.8813, 25.4053],\n",
      "        [29.4872, 24.9354, 25.8748]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6301, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.6351,  29.9024, -25.4713],\n",
      "        [-27.7806,  29.2227, -24.8665],\n",
      "        [-28.0029,  28.8915, -24.9896],\n",
      "        [-27.8628,  29.3455, -25.2414],\n",
      "        [-28.6550,  29.3403, -25.3127],\n",
      "        [-27.8441,  29.4914, -25.1693]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9846,  24.3797,  25.0511, -28.6351,  29.9024, -25.4713],\n",
      "        [ 29.0757,  24.1963,  24.9539, -27.7806,  29.2227, -24.8665],\n",
      "        [ 28.4817,  23.7596,  24.4066, -28.0029,  28.8915, -24.9896],\n",
      "        [ 29.5114,  25.3782,  25.0154, -27.8628,  29.3455, -25.2414],\n",
      "        [ 29.3004,  24.8813,  25.4053, -28.6550,  29.3403, -25.3127],\n",
      "        [ 29.4872,  24.9354,  25.8748, -27.8441,  29.4914, -25.1693]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.037782669067383\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.9156, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1528, 25.0467, 25.2315],\n",
      "        [28.8687, 24.7762, 25.4843],\n",
      "        [29.0904, 24.4152, 25.1196],\n",
      "        [29.3200, 24.7552, 25.6770],\n",
      "        [29.0673, 24.4608, 25.4112],\n",
      "        [28.6607, 24.3033, 25.0026]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.0093, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.8647,  30.2443, -25.8845],\n",
      "        [-29.0989,  29.8389, -26.0211],\n",
      "        [-28.3201,  29.4145, -25.6390],\n",
      "        [-28.3990,  29.5972, -25.5979],\n",
      "        [-27.5539,  28.8033, -25.1744],\n",
      "        [-28.2183,  29.3640, -25.2142]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1528,  25.0467,  25.2315, -28.8647,  30.2443, -25.8845],\n",
      "        [ 28.8687,  24.7762,  25.4843, -29.0989,  29.8389, -26.0211],\n",
      "        [ 29.0904,  24.4152,  25.1196, -28.3201,  29.4145, -25.6390],\n",
      "        [ 29.3200,  24.7552,  25.6770, -28.3990,  29.5972, -25.5979],\n",
      "        [ 29.0673,  24.4608,  25.4112, -27.5539,  28.8033, -25.1744],\n",
      "        [ 28.6607,  24.3033,  25.0026, -28.2183,  29.3640, -25.2142]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.121135711669922\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7639, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3422, 24.6999, 25.4641],\n",
      "        [29.5799, 24.8452, 25.2381],\n",
      "        [29.1657, 24.7910, 25.3701],\n",
      "        [29.3200, 24.9563, 25.5824],\n",
      "        [28.7525, 24.3625, 25.1386],\n",
      "        [29.0788, 24.8452, 25.1113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.8982, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.9293,  29.5932, -25.6631],\n",
      "        [-28.0997,  29.5770, -25.4289],\n",
      "        [-28.3614,  29.6491, -25.5644],\n",
      "        [-28.7748,  29.9630, -25.8491],\n",
      "        [-28.5834,  30.0512, -25.9788],\n",
      "        [-27.9270,  29.1446, -25.1851]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3422,  24.6999,  25.4641, -28.9293,  29.5932, -25.6631],\n",
      "        [ 29.5799,  24.8452,  25.2381, -28.0997,  29.5770, -25.4289],\n",
      "        [ 29.1657,  24.7910,  25.3701, -28.3614,  29.6491, -25.5644],\n",
      "        [ 29.3200,  24.9563,  25.5824, -28.7748,  29.9630, -25.8491],\n",
      "        [ 28.7525,  24.3625,  25.1386, -28.5834,  30.0512, -25.9788],\n",
      "        [ 29.0788,  24.8452,  25.1113, -27.9270,  29.1446, -25.1851]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.10098123550415\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4564, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.9107, 24.3375, 25.0262],\n",
      "        [28.9983, 24.2358, 25.1684],\n",
      "        [29.0469, 24.8471, 25.0667],\n",
      "        [28.7960, 24.5955, 24.8378],\n",
      "        [29.0668, 24.4055, 25.0322],\n",
      "        [29.0692, 24.4157, 25.2618]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.9583, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.6197,  28.8763, -25.1378],\n",
      "        [-28.3164,  29.7786, -25.3207],\n",
      "        [-28.1881,  29.1557, -25.2178],\n",
      "        [-28.8110,  29.7906, -25.8612],\n",
      "        [-27.9416,  29.1118, -24.9011],\n",
      "        [-27.8066,  28.9398, -25.2319]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.9107,  24.3375,  25.0262, -27.6197,  28.8763, -25.1378],\n",
      "        [ 28.9983,  24.2358,  25.1684, -28.3164,  29.7786, -25.3207],\n",
      "        [ 29.0469,  24.8471,  25.0667, -28.1881,  29.1557, -25.2178],\n",
      "        [ 28.7960,  24.5955,  24.8378, -28.8110,  29.7906, -25.8612],\n",
      "        [ 29.0668,  24.4055,  25.0322, -27.9416,  29.1118, -24.9011],\n",
      "        [ 29.0692,  24.4157,  25.2618, -27.8066,  28.9398, -25.2319]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-6.945169925689697\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4420, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2411, 24.8110, 25.5171],\n",
      "        [29.4199, 24.9597, 25.3056],\n",
      "        [29.1564, 24.5833, 25.0230],\n",
      "        [29.0708, 24.0781, 25.1043],\n",
      "        [29.2223, 24.2101, 25.1963],\n",
      "        [29.3516, 24.8301, 25.1297]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.6816, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.0467,  28.8259, -25.1737],\n",
      "        [-27.8857,  29.1269, -25.1813],\n",
      "        [-28.1808,  29.4093, -25.2836],\n",
      "        [-28.2489,  29.2264, -25.3878],\n",
      "        [-28.2459,  28.9682, -25.0221],\n",
      "        [-28.3327,  29.5144, -25.6248]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2411,  24.8110,  25.5171, -28.0467,  28.8259, -25.1737],\n",
      "        [ 29.4199,  24.9597,  25.3056, -27.8857,  29.1269, -25.1813],\n",
      "        [ 29.1564,  24.5833,  25.0230, -28.1808,  29.4093, -25.2836],\n",
      "        [ 29.0708,  24.0781,  25.1043, -28.2489,  29.2264, -25.3878],\n",
      "        [ 29.2223,  24.2101,  25.1963, -28.2459,  28.9682, -25.0221],\n",
      "        [ 29.3516,  24.8301,  25.1297, -28.3327,  29.5144, -25.6248]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.025054931640625\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7988, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.6617, 24.0223, 24.9659],\n",
      "        [28.7839, 24.1132, 24.6674],\n",
      "        [29.0973, 24.7004, 25.2297],\n",
      "        [29.2151, 24.5895, 25.1105],\n",
      "        [29.5868, 24.8945, 25.5546],\n",
      "        [28.7184, 24.5194, 25.1719]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.7559, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2659,  29.4125, -25.6619],\n",
      "        [-28.3583,  29.4031, -25.3047],\n",
      "        [-28.4122,  29.5595, -25.6760],\n",
      "        [-28.1242,  29.2923, -25.6259],\n",
      "        [-28.0423,  29.2611, -25.3331],\n",
      "        [-28.9114,  29.7476, -26.0730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.6617,  24.0223,  24.9659, -28.2659,  29.4125, -25.6619],\n",
      "        [ 28.7839,  24.1132,  24.6674, -28.3583,  29.4031, -25.3047],\n",
      "        [ 29.0973,  24.7004,  25.2297, -28.4122,  29.5595, -25.6760],\n",
      "        [ 29.2151,  24.5895,  25.1105, -28.1242,  29.2923, -25.6259],\n",
      "        [ 29.5868,  24.8945,  25.5546, -28.0423,  29.2611, -25.3331],\n",
      "        [ 28.7184,  24.5194,  25.1719, -28.9114,  29.7476, -26.0730]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.983409881591797\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5122, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4616, 24.7071, 24.8812],\n",
      "        [29.2771, 24.8495, 25.6189],\n",
      "        [28.5760, 24.2803, 24.6349],\n",
      "        [29.0637, 24.3329, 24.8597],\n",
      "        [29.2656, 25.1086, 25.8812],\n",
      "        [28.8825, 24.3090, 24.7084]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.4245, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4964,  29.5413, -25.7354],\n",
      "        [-28.3444,  29.4474, -25.3851],\n",
      "        [-28.4151,  29.4600, -25.4238],\n",
      "        [-28.0420,  29.4277, -25.2553],\n",
      "        [-27.6920,  28.6962, -25.1618],\n",
      "        [-28.3391,  29.6422, -25.7185]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4616,  24.7071,  24.8812, -28.4964,  29.5413, -25.7354],\n",
      "        [ 29.2771,  24.8495,  25.6189, -28.3444,  29.4474, -25.3851],\n",
      "        [ 28.5760,  24.2803,  24.6349, -28.4151,  29.4600, -25.4238],\n",
      "        [ 29.0637,  24.3329,  24.8597, -28.0420,  29.4277, -25.2553],\n",
      "        [ 29.2656,  25.1086,  25.8812, -27.6920,  28.6962, -25.1618],\n",
      "        [ 28.8825,  24.3090,  24.7084, -28.3391,  29.6422, -25.7185]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.071230888366699\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9587, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4651, 24.9895, 25.7131],\n",
      "        [29.5670, 25.1681, 25.3129],\n",
      "        [29.0739, 24.5229, 25.3244],\n",
      "        [28.8725, 24.3505, 24.9917],\n",
      "        [29.4168, 24.5316, 25.7071],\n",
      "        [29.0442, 24.7852, 25.3135]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3997, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4316,  29.6339, -25.3239],\n",
      "        [-28.2285,  29.6272, -25.3106],\n",
      "        [-28.4445,  29.8868, -25.7726],\n",
      "        [-27.9704,  29.0258, -25.5019],\n",
      "        [-27.9669,  29.3937, -25.4402],\n",
      "        [-28.3334,  29.1477, -25.4266]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4651,  24.9895,  25.7131, -28.4316,  29.6339, -25.3239],\n",
      "        [ 29.5670,  25.1681,  25.3129, -28.2285,  29.6272, -25.3106],\n",
      "        [ 29.0739,  24.5229,  25.3244, -28.4445,  29.8868, -25.7726],\n",
      "        [ 28.8725,  24.3505,  24.9917, -27.9704,  29.0258, -25.5019],\n",
      "        [ 29.4168,  24.5316,  25.7071, -27.9669,  29.3937, -25.4402],\n",
      "        [ 29.0442,  24.7852,  25.3135, -28.3334,  29.1477, -25.4266]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.113711833953857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2987, 24.9975, 25.7465],\n",
      "        [29.2108, 24.8445, 25.3382],\n",
      "        [29.1741, 24.9947, 25.6102],\n",
      "        [29.0287, 24.6065, 24.8536],\n",
      "        [28.7502, 24.5417, 24.9254],\n",
      "        [29.1498, 24.7900, 25.5145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(46.9602, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8771,  28.9436, -25.0192],\n",
      "        [-27.6669,  29.1907, -25.1611],\n",
      "        [-27.8801,  29.6764, -25.2988],\n",
      "        [-27.8642,  29.2881, -25.1728],\n",
      "        [-27.6350,  28.5969, -24.7675],\n",
      "        [-28.2136,  29.3501, -25.5174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2987,  24.9975,  25.7465, -27.8771,  28.9436, -25.0192],\n",
      "        [ 29.2108,  24.8445,  25.3382, -27.6669,  29.1907, -25.1611],\n",
      "        [ 29.1741,  24.9947,  25.6102, -27.8801,  29.6764, -25.2988],\n",
      "        [ 29.0287,  24.6065,  24.8536, -27.8642,  29.2881, -25.1728],\n",
      "        [ 28.7502,  24.5417,  24.9254, -27.6350,  28.5969, -24.7675],\n",
      "        [ 29.1498,  24.7900,  25.5145, -28.2136,  29.3501, -25.5174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.048633575439453\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2314, 24.6823, 25.6259],\n",
      "        [29.3390, 25.0177, 25.4003],\n",
      "        [28.5096, 24.3712, 24.7885],\n",
      "        [29.1163, 24.9199, 25.2581],\n",
      "        [29.6015, 25.0110, 25.4532],\n",
      "        [28.9483, 24.6742, 25.0246]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.6780, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1809,  29.4428, -25.5752],\n",
      "        [-28.7060,  29.7628, -26.0387],\n",
      "        [-28.6400,  29.1474, -25.6324],\n",
      "        [-28.4227,  29.4950, -25.2235],\n",
      "        [-27.8419,  29.0421, -25.2021],\n",
      "        [-28.5184,  29.3756, -25.5236]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2314,  24.6823,  25.6259, -28.1809,  29.4428, -25.5752],\n",
      "        [ 29.3390,  25.0177,  25.4003, -28.7060,  29.7628, -26.0387],\n",
      "        [ 28.5096,  24.3712,  24.7885, -28.6400,  29.1474, -25.6324],\n",
      "        [ 29.1163,  24.9199,  25.2581, -28.4227,  29.4950, -25.2235],\n",
      "        [ 29.6015,  25.0110,  25.4532, -27.8419,  29.0421, -25.2021],\n",
      "        [ 28.9483,  24.6742,  25.0246, -28.5184,  29.3756, -25.5236]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.078799724578857\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.0957, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1389, 25.0924, 25.4812],\n",
      "        [29.9612, 25.3887, 25.8288],\n",
      "        [29.4235, 24.6151, 25.5871],\n",
      "        [29.9501, 25.1239, 25.8026],\n",
      "        [29.0501, 24.8015, 24.6698],\n",
      "        [28.3030, 24.5369, 24.8897]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8535, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.6461,  29.5862, -25.8756],\n",
      "        [-27.4698,  28.3816, -24.7392],\n",
      "        [-27.3086,  28.8581, -24.9542],\n",
      "        [-27.5476,  28.9909, -25.3361],\n",
      "        [-28.4639,  29.9058, -25.7755],\n",
      "        [-28.7169,  29.8472, -26.0239]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1389,  25.0924,  25.4812, -28.6461,  29.5862, -25.8756],\n",
      "        [ 29.9612,  25.3887,  25.8288, -27.4698,  28.3816, -24.7392],\n",
      "        [ 29.4235,  24.6151,  25.5871, -27.3086,  28.8581, -24.9542],\n",
      "        [ 29.9501,  25.1239,  25.8026, -27.5476,  28.9909, -25.3361],\n",
      "        [ 29.0501,  24.8015,  24.6698, -28.4639,  29.9058, -25.7755],\n",
      "        [ 28.3030,  24.5369,  24.8897, -28.7169,  29.8472, -26.0239]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.118189811706543\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2677, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2903, 24.6172, 25.2778],\n",
      "        [29.6169, 25.0880, 25.5986],\n",
      "        [29.8545, 25.0319, 25.6034],\n",
      "        [30.0325, 25.5566, 25.5936],\n",
      "        [29.8002, 25.2243, 25.4394],\n",
      "        [29.6627, 25.3956, 25.7073]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9335, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.5611,  29.1151, -24.7558],\n",
      "        [-28.2696,  29.1789, -24.8684],\n",
      "        [-28.0156,  29.1180, -25.3768],\n",
      "        [-27.7559,  29.0865, -25.2551],\n",
      "        [-28.4579,  30.2375, -25.5108],\n",
      "        [-28.1129,  29.3679, -25.4983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2903,  24.6172,  25.2778, -27.5611,  29.1151, -24.7558],\n",
      "        [ 29.6169,  25.0880,  25.5986, -28.2696,  29.1789, -24.8684],\n",
      "        [ 29.8545,  25.0319,  25.6034, -28.0156,  29.1180, -25.3768],\n",
      "        [ 30.0325,  25.5566,  25.5936, -27.7559,  29.0865, -25.2551],\n",
      "        [ 29.8002,  25.2243,  25.4394, -28.4579,  30.2375, -25.5108],\n",
      "        [ 29.6627,  25.3956,  25.7073, -28.1129,  29.3679, -25.4983]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.00209903717041\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.9295, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.5873, 24.3564, 24.9181],\n",
      "        [29.8055, 25.5434, 26.2452],\n",
      "        [28.7651, 23.8886, 25.0288],\n",
      "        [29.3234, 24.9000, 25.0530],\n",
      "        [29.7778, 24.8217, 25.7199],\n",
      "        [29.0529, 24.4135, 25.1229]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.6064, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.7714,  29.7854, -25.6916],\n",
      "        [-27.9210,  29.3041, -25.3252],\n",
      "        [-28.0463,  29.3045, -25.4199],\n",
      "        [-28.3037,  29.0483, -25.1652],\n",
      "        [-27.8189,  28.9108, -25.4208],\n",
      "        [-27.9787,  29.0024, -25.5174]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.5873,  24.3564,  24.9181, -28.7714,  29.7854, -25.6916],\n",
      "        [ 29.8055,  25.5434,  26.2452, -27.9210,  29.3041, -25.3252],\n",
      "        [ 28.7651,  23.8886,  25.0288, -28.0463,  29.3045, -25.4199],\n",
      "        [ 29.3234,  24.9000,  25.0530, -28.3037,  29.0483, -25.1652],\n",
      "        [ 29.7778,  24.8217,  25.7199, -27.8189,  28.9108, -25.4208],\n",
      "        [ 29.0529,  24.4135,  25.1229, -27.9787,  29.0024, -25.5174]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.04006814956665\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6106, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.8083, 24.7380, 25.2246],\n",
      "        [29.0797, 24.6079, 25.6333],\n",
      "        [28.8876, 24.5074, 25.1012],\n",
      "        [29.0080, 24.4364, 25.0156],\n",
      "        [29.6505, 25.1524, 25.9494],\n",
      "        [29.4389, 24.9821, 25.5942]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.3484, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.9075,  29.0013, -24.6835],\n",
      "        [-28.5241,  29.7610, -25.4275],\n",
      "        [-28.7256,  29.8423, -25.6500],\n",
      "        [-28.3434,  29.3541, -25.1904],\n",
      "        [-27.7838,  28.7664, -24.8107],\n",
      "        [-28.6843,  29.9823, -25.7883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.8083,  24.7380,  25.2246, -27.9075,  29.0013, -24.6835],\n",
      "        [ 29.0797,  24.6079,  25.6333, -28.5241,  29.7610, -25.4275],\n",
      "        [ 28.8876,  24.5074,  25.1012, -28.7256,  29.8423, -25.6500],\n",
      "        [ 29.0080,  24.4364,  25.0156, -28.3434,  29.3541, -25.1904],\n",
      "        [ 29.6505,  25.1524,  25.9494, -27.7838,  28.7664, -24.8107],\n",
      "        [ 29.4389,  24.9821,  25.5942, -28.6843,  29.9823, -25.7883]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-6.986654281616211\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3828, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2699, 24.8381, 25.4262],\n",
      "        [29.2919, 24.8073, 25.7485],\n",
      "        [28.7181, 24.4437, 25.0370],\n",
      "        [29.7119, 25.1497, 25.2742],\n",
      "        [29.2717, 24.7656, 25.1055],\n",
      "        [29.1533, 24.4837, 25.0415]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.3711, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3155,  29.5815, -25.3624],\n",
      "        [-28.0244,  29.2963, -25.1424],\n",
      "        [-28.8230,  30.0087, -25.6015],\n",
      "        [-28.2143,  29.5783, -25.6043],\n",
      "        [-28.4353,  29.4733, -25.4841],\n",
      "        [-27.9796,  29.4474, -25.0259]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2699,  24.8381,  25.4262, -28.3155,  29.5815, -25.3624],\n",
      "        [ 29.2919,  24.8073,  25.7485, -28.0244,  29.2963, -25.1424],\n",
      "        [ 28.7181,  24.4437,  25.0370, -28.8230,  30.0087, -25.6015],\n",
      "        [ 29.7119,  25.1497,  25.2742, -28.2143,  29.5783, -25.6043],\n",
      "        [ 29.2717,  24.7656,  25.1055, -28.4353,  29.4733, -25.4841],\n",
      "        [ 29.1533,  24.4837,  25.0415, -27.9796,  29.4474, -25.0259]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.091492652893066\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4661, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4496, 25.1444, 25.4469],\n",
      "        [29.5238, 24.8711, 25.1532],\n",
      "        [29.4076, 24.7494, 25.2633],\n",
      "        [29.3004, 24.9971, 25.5606],\n",
      "        [29.2673, 25.1958, 25.6667],\n",
      "        [29.9271, 25.1005, 26.1234]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.4381, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8618,  29.6559, -25.4524],\n",
      "        [-28.8918,  29.6078, -26.1781],\n",
      "        [-28.1831,  29.1130, -25.3122],\n",
      "        [-28.4513,  29.3165, -25.3079],\n",
      "        [-28.3994,  29.4457, -25.6148],\n",
      "        [-28.1964,  29.5229, -24.8420]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4496,  25.1444,  25.4469, -27.8618,  29.6559, -25.4524],\n",
      "        [ 29.5238,  24.8711,  25.1532, -28.8918,  29.6078, -26.1781],\n",
      "        [ 29.4076,  24.7494,  25.2633, -28.1831,  29.1130, -25.3122],\n",
      "        [ 29.3004,  24.9971,  25.5606, -28.4513,  29.3165, -25.3079],\n",
      "        [ 29.2673,  25.1958,  25.6667, -28.3994,  29.4457, -25.6148],\n",
      "        [ 29.9271,  25.1005,  26.1234, -28.1964,  29.5229, -24.8420]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.105643272399902\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1595, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2380, 24.4481, 24.9965],\n",
      "        [28.9519, 24.4928, 24.9252],\n",
      "        [28.9652, 24.8390, 24.8576],\n",
      "        [28.8047, 24.6266, 24.8083],\n",
      "        [29.4326, 24.8706, 25.4465],\n",
      "        [28.9974, 24.9736, 25.5488]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(37.8696, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3137,  29.6519, -25.7875],\n",
      "        [-27.9180,  29.0865, -24.7624],\n",
      "        [-28.2312,  29.4118, -25.4500],\n",
      "        [-28.8607,  30.0371, -26.1793],\n",
      "        [-28.8568,  29.7937, -25.9742],\n",
      "        [-28.6203,  29.6455, -25.7726]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2380,  24.4481,  24.9965, -28.3137,  29.6519, -25.7875],\n",
      "        [ 28.9519,  24.4928,  24.9252, -27.9180,  29.0865, -24.7624],\n",
      "        [ 28.9652,  24.8390,  24.8576, -28.2312,  29.4118, -25.4500],\n",
      "        [ 28.8047,  24.6266,  24.8083, -28.8607,  30.0371, -26.1793],\n",
      "        [ 29.4326,  24.8706,  25.4465, -28.8568,  29.7937, -25.9742],\n",
      "        [ 28.9974,  24.9736,  25.5488, -28.6203,  29.6455, -25.7726]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.073898792266846\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4899, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.8126, 25.5140, 25.7916],\n",
      "        [29.6126, 25.3920, 25.8577],\n",
      "        [29.5838, 25.0480, 25.8652],\n",
      "        [29.2809, 24.7394, 24.9042],\n",
      "        [29.1361, 24.5257, 25.2427],\n",
      "        [29.7121, 25.0873, 25.6744]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.8480, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4712,  29.5806, -25.8773],\n",
      "        [-28.3175,  29.7193, -25.4912],\n",
      "        [-27.7600,  29.2857, -25.1985],\n",
      "        [-28.9348,  29.9588, -25.9973],\n",
      "        [-28.2552,  29.3985, -25.1195],\n",
      "        [-28.4817,  29.2906, -25.4703]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.8126,  25.5140,  25.7916, -28.4712,  29.5806, -25.8773],\n",
      "        [ 29.6126,  25.3920,  25.8577, -28.3175,  29.7193, -25.4912],\n",
      "        [ 29.5838,  25.0480,  25.8652, -27.7600,  29.2857, -25.1985],\n",
      "        [ 29.2809,  24.7394,  24.9042, -28.9348,  29.9588, -25.9973],\n",
      "        [ 29.1361,  24.5257,  25.2427, -28.2552,  29.3985, -25.1195],\n",
      "        [ 29.7121,  25.0873,  25.6744, -28.4817,  29.2906, -25.4703]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.19742488861084\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.5737, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4035, 24.7084, 25.5638],\n",
      "        [29.3745, 24.5604, 25.0792],\n",
      "        [29.1786, 24.7596, 25.4048],\n",
      "        [28.1796, 24.2470, 24.8426],\n",
      "        [29.2680, 24.8330, 25.8876],\n",
      "        [29.9514, 25.2713, 25.7862]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.9954, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.5927,  29.5946, -25.4674],\n",
      "        [-28.3320,  29.3520, -25.5981],\n",
      "        [-28.4589,  29.6220, -25.6188],\n",
      "        [-28.8253,  29.8067, -25.9463],\n",
      "        [-28.2289,  29.4127, -24.9122],\n",
      "        [-28.5410,  29.6872, -25.6456]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4035,  24.7084,  25.5638, -28.5927,  29.5946, -25.4674],\n",
      "        [ 29.3745,  24.5604,  25.0792, -28.3320,  29.3520, -25.5981],\n",
      "        [ 29.1786,  24.7596,  25.4048, -28.4589,  29.6220, -25.6188],\n",
      "        [ 28.1796,  24.2470,  24.8426, -28.8253,  29.8067, -25.9463],\n",
      "        [ 29.2680,  24.8330,  25.8876, -28.2289,  29.4127, -24.9122],\n",
      "        [ 29.9514,  25.2713,  25.7862, -28.5410,  29.6872, -25.6456]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.124168872833252\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8978, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.2712, 25.1798, 25.7790],\n",
      "        [29.6891, 25.6024, 26.1476],\n",
      "        [29.4711, 24.9957, 25.5453],\n",
      "        [29.8690, 25.1106, 25.4064],\n",
      "        [29.3829, 24.5815, 25.3021],\n",
      "        [28.9600, 24.1629, 24.9551]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.8420, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.6429,  29.9033, -25.7075],\n",
      "        [-28.4159,  29.8878, -25.4910],\n",
      "        [-28.4111,  29.7296, -25.9616],\n",
      "        [-27.8401,  29.1907, -24.9456],\n",
      "        [-28.7359,  29.6385, -25.9135],\n",
      "        [-28.5294,  29.2982, -25.7992]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.2712,  25.1798,  25.7790, -28.6429,  29.9033, -25.7075],\n",
      "        [ 29.6891,  25.6024,  26.1476, -28.4159,  29.8878, -25.4910],\n",
      "        [ 29.4711,  24.9957,  25.5453, -28.4111,  29.7296, -25.9616],\n",
      "        [ 29.8690,  25.1106,  25.4064, -27.8401,  29.1907, -24.9456],\n",
      "        [ 29.3829,  24.5815,  25.3021, -28.7359,  29.6385, -25.9135],\n",
      "        [ 28.9600,  24.1629,  24.9551, -28.5294,  29.2982, -25.7992]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.170444011688232\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1143, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.3338, 23.9438, 25.1134],\n",
      "        [29.4195, 25.2168, 25.8598],\n",
      "        [29.1504, 24.9631, 25.6608],\n",
      "        [29.4027, 24.9018, 25.3047],\n",
      "        [29.1247, 24.9596, 25.3146],\n",
      "        [29.2099, 24.6923, 25.4156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(28.6509, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-29.0674,  30.0187, -25.7871],\n",
      "        [-28.4179,  29.8229, -25.7397],\n",
      "        [-28.5418,  29.7557, -25.6567],\n",
      "        [-28.4151,  29.7031, -25.6058],\n",
      "        [-29.0386,  30.1576, -25.9456],\n",
      "        [-28.0183,  29.2784, -25.3247]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.3338,  23.9438,  25.1134, -29.0674,  30.0187, -25.7871],\n",
      "        [ 29.4195,  25.2168,  25.8598, -28.4179,  29.8229, -25.7397],\n",
      "        [ 29.1504,  24.9631,  25.6608, -28.5418,  29.7557, -25.6567],\n",
      "        [ 29.4027,  24.9018,  25.3047, -28.4151,  29.7031, -25.6058],\n",
      "        [ 29.1247,  24.9596,  25.3146, -29.0386,  30.1576, -25.9456],\n",
      "        [ 29.2099,  24.6923,  25.4156, -28.0183,  29.2784, -25.3247]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.059605598449707\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7282, 24.0176, 24.6126],\n",
      "        [29.6504, 24.9654, 25.7741],\n",
      "        [29.1294, 24.4127, 25.3142],\n",
      "        [28.4551, 24.4000, 24.6678],\n",
      "        [29.5167, 24.5814, 25.7109],\n",
      "        [29.2073, 24.9817, 25.2945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.2903, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.7538,  29.0953, -25.6966],\n",
      "        [-27.8107,  28.9658, -25.4520],\n",
      "        [-28.7110,  30.0986, -26.0191],\n",
      "        [-28.1641,  28.9890, -24.9586],\n",
      "        [-28.6919,  30.0449, -26.0388],\n",
      "        [-28.2413,  29.8699, -26.0093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7282,  24.0176,  24.6126, -28.7538,  29.0953, -25.6966],\n",
      "        [ 29.6504,  24.9654,  25.7741, -27.8107,  28.9658, -25.4520],\n",
      "        [ 29.1294,  24.4127,  25.3142, -28.7110,  30.0986, -26.0191],\n",
      "        [ 28.4551,  24.4000,  24.6678, -28.1641,  28.9890, -24.9586],\n",
      "        [ 29.5167,  24.5814,  25.7109, -28.6919,  30.0449, -26.0388],\n",
      "        [ 29.2073,  24.9817,  25.2945, -28.2413,  29.8699, -26.0093]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.0097737312316895\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(3.5400, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.5678, 25.4506, 25.8476],\n",
      "        [29.4981, 24.9818, 25.3344],\n",
      "        [29.2939, 24.7423, 25.2374],\n",
      "        [29.0944, 24.8791, 25.2120],\n",
      "        [29.1667, 24.7923, 24.9321],\n",
      "        [29.1830, 24.7473, 24.9332]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.8359, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4461,  29.6262, -25.5398],\n",
      "        [-28.7506,  30.0912, -25.8797],\n",
      "        [-28.9748,  30.2406, -26.1667],\n",
      "        [-28.8056,  29.8653, -25.8321],\n",
      "        [-27.9794,  29.4511, -25.3959],\n",
      "        [-28.0513,  29.0221, -25.4265]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.5678,  25.4506,  25.8476, -28.4461,  29.6262, -25.5398],\n",
      "        [ 29.4981,  24.9818,  25.3344, -28.7506,  30.0912, -25.8797],\n",
      "        [ 29.2939,  24.7423,  25.2374, -28.9748,  30.2406, -26.1667],\n",
      "        [ 29.0944,  24.8791,  25.2120, -28.8056,  29.8653, -25.8321],\n",
      "        [ 29.1667,  24.7923,  24.9321, -27.9794,  29.4511, -25.3959],\n",
      "        [ 29.1830,  24.7473,  24.9332, -28.0513,  29.0221, -25.4265]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.183739185333252\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1157, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.9479, 25.2970, 26.0677],\n",
      "        [29.3153, 24.7932, 25.4694],\n",
      "        [29.7394, 24.9039, 25.6014],\n",
      "        [28.8907, 25.0643, 24.8035],\n",
      "        [29.2561, 25.1506, 25.5280],\n",
      "        [29.3095, 25.0904, 25.7615]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(56.1935, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.2310,  29.4847, -25.3151],\n",
      "        [-28.5401,  29.7551, -26.0696],\n",
      "        [-29.5141,  30.3710, -26.1766],\n",
      "        [-28.4738,  28.7558, -24.7172],\n",
      "        [-28.4474,  29.2305, -25.5541],\n",
      "        [-28.1451,  29.3496, -25.7094]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.9479,  25.2970,  26.0677, -28.2310,  29.4847, -25.3151],\n",
      "        [ 29.3153,  24.7932,  25.4694, -28.5401,  29.7551, -26.0696],\n",
      "        [ 29.7394,  24.9039,  25.6014, -29.5141,  30.3710, -26.1766],\n",
      "        [ 28.8907,  25.0643,  24.8035, -28.4738,  28.7558, -24.7172],\n",
      "        [ 29.2561,  25.1506,  25.5280, -28.4474,  29.2305, -25.5541],\n",
      "        [ 29.3095,  25.0904,  25.7615, -28.1451,  29.3496, -25.7094]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.1913676261901855\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2134, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.1975, 24.6864, 25.4738],\n",
      "        [29.4361, 25.1347, 25.9617],\n",
      "        [29.4355, 24.4676, 25.4052],\n",
      "        [30.0182, 25.4793, 25.9692],\n",
      "        [29.2991, 24.2475, 25.3676],\n",
      "        [29.1423, 24.9176, 25.4087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.5959, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.8925,  29.0218, -25.2171],\n",
      "        [-28.6485,  30.1841, -25.7214],\n",
      "        [-28.5042,  29.5611, -25.5331],\n",
      "        [-29.0185,  30.2905, -26.0129],\n",
      "        [-28.4637,  29.8122, -25.8286],\n",
      "        [-29.2879,  30.4053, -26.4486]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.1975,  24.6864,  25.4738, -27.8925,  29.0218, -25.2171],\n",
      "        [ 29.4361,  25.1347,  25.9617, -28.6485,  30.1841, -25.7214],\n",
      "        [ 29.4355,  24.4676,  25.4052, -28.5042,  29.5611, -25.5331],\n",
      "        [ 30.0182,  25.4793,  25.9692, -29.0185,  30.2905, -26.0129],\n",
      "        [ 29.2991,  24.2475,  25.3676, -28.4637,  29.8122, -25.8286],\n",
      "        [ 29.1423,  24.9176,  25.4087, -29.2879,  30.4053, -26.4486]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.060554027557373\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.6950, 24.9531, 25.5601],\n",
      "        [29.2506, 24.5659, 25.4838],\n",
      "        [29.3788, 25.3919, 25.3405],\n",
      "        [29.2038, 24.6552, 25.2956],\n",
      "        [29.2215, 24.8256, 25.4859],\n",
      "        [29.3695, 24.6128, 25.7819]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3385, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.9335,  30.0330, -26.1441],\n",
      "        [-28.5227,  30.0331, -26.1329],\n",
      "        [-28.5875,  29.8421, -25.6727],\n",
      "        [-28.8029,  29.6222, -25.5105],\n",
      "        [-28.0454,  29.5148, -25.3296],\n",
      "        [-28.4507,  30.0195, -25.5965]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.6950,  24.9531,  25.5601, -28.9335,  30.0330, -26.1441],\n",
      "        [ 29.2506,  24.5659,  25.4838, -28.5227,  30.0331, -26.1329],\n",
      "        [ 29.3788,  25.3919,  25.3405, -28.5875,  29.8421, -25.6727],\n",
      "        [ 29.2038,  24.6552,  25.2956, -28.8029,  29.6222, -25.5105],\n",
      "        [ 29.2215,  24.8256,  25.4859, -28.0454,  29.5148, -25.3296],\n",
      "        [ 29.3695,  24.6128,  25.7819, -28.4507,  30.0195, -25.5965]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.21909236907959\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.4501, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.6182, 24.5157, 25.0113],\n",
      "        [29.7888, 25.5338, 25.7714],\n",
      "        [28.3129, 24.2468, 24.9950],\n",
      "        [29.9816, 25.4483, 25.9106],\n",
      "        [29.5248, 24.9057, 25.7247],\n",
      "        [30.1313, 25.6875, 26.2423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.6482, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4785,  29.7992, -25.8355],\n",
      "        [-28.1453,  29.4968, -25.4323],\n",
      "        [-27.6694,  29.2015, -24.7274],\n",
      "        [-28.5519,  29.5667, -25.8693],\n",
      "        [-28.8308,  30.2678, -26.3074],\n",
      "        [-27.9830,  29.0213, -25.0854]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.6182,  24.5157,  25.0113, -28.4785,  29.7992, -25.8355],\n",
      "        [ 29.7888,  25.5338,  25.7714, -28.1453,  29.4968, -25.4323],\n",
      "        [ 28.3129,  24.2468,  24.9950, -27.6694,  29.2015, -24.7274],\n",
      "        [ 29.9816,  25.4483,  25.9106, -28.5519,  29.5667, -25.8693],\n",
      "        [ 29.5248,  24.9057,  25.7247, -28.8308,  30.2678, -26.3074],\n",
      "        [ 30.1313,  25.6875,  26.2423, -27.9830,  29.0213, -25.0854]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.134464263916016\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.6412, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4258, 25.1798, 25.7776],\n",
      "        [28.6076, 24.4037, 24.8903],\n",
      "        [29.2423, 24.9107, 25.4256],\n",
      "        [29.5448, 25.0040, 25.1445],\n",
      "        [29.3334, 24.8426, 25.5829],\n",
      "        [29.6034, 25.2035, 25.5620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(57.5448, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.8356,  29.9799, -25.8949],\n",
      "        [-28.5734,  29.7523, -25.5501],\n",
      "        [-28.1404,  29.8479, -25.7763],\n",
      "        [-27.9681,  29.5084, -25.4533],\n",
      "        [-27.9934,  29.7770, -25.8829],\n",
      "        [-27.9591,  29.0437, -25.0611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4258,  25.1798,  25.7776, -28.8356,  29.9799, -25.8949],\n",
      "        [ 28.6076,  24.4037,  24.8903, -28.5734,  29.7523, -25.5501],\n",
      "        [ 29.2423,  24.9107,  25.4256, -28.1404,  29.8479, -25.7763],\n",
      "        [ 29.5448,  25.0040,  25.1445, -27.9681,  29.5084, -25.4533],\n",
      "        [ 29.3334,  24.8426,  25.5829, -27.9934,  29.7770, -25.8829],\n",
      "        [ 29.6034,  25.2035,  25.5620, -27.9591,  29.0437, -25.0611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.213237762451172\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.7546, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.3492, 24.9581, 25.4175],\n",
      "        [29.8264, 25.1416, 25.7614],\n",
      "        [29.1119, 24.5910, 25.3049],\n",
      "        [29.8289, 25.6082, 25.7583],\n",
      "        [28.7590, 24.3599, 25.1665],\n",
      "        [28.9254, 24.4041, 25.3075]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(58.2148, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.3916,  29.4825, -25.5230],\n",
      "        [-28.7848,  29.8467, -25.9438],\n",
      "        [-28.7472,  29.8749, -26.3172],\n",
      "        [-28.5388,  29.7117, -25.9667],\n",
      "        [-28.3454,  29.6961, -25.7714],\n",
      "        [-28.2814,  29.5874, -25.8925]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.3492,  24.9581,  25.4175, -28.3916,  29.4825, -25.5230],\n",
      "        [ 29.8264,  25.1416,  25.7614, -28.7848,  29.8467, -25.9438],\n",
      "        [ 29.1119,  24.5910,  25.3049, -28.7472,  29.8749, -26.3172],\n",
      "        [ 29.8289,  25.6082,  25.7583, -28.5388,  29.7117, -25.9667],\n",
      "        [ 28.7590,  24.3599,  25.1665, -28.3454,  29.6961, -25.7714],\n",
      "        [ 28.9254,  24.4041,  25.3075, -28.2814,  29.5874, -25.8925]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.134105682373047\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[28.7964, 24.7664, 25.1798],\n",
      "        [28.8496, 24.3473, 25.2107],\n",
      "        [29.6447, 25.1889, 25.7461],\n",
      "        [29.0980, 24.9181, 25.3225],\n",
      "        [29.5380, 25.2778, 25.3810],\n",
      "        [29.1834, 24.5373, 25.3064]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(48.0266, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.4215,  29.7920, -25.7438],\n",
      "        [-28.5454,  29.6536, -25.7216],\n",
      "        [-28.0708,  29.4920, -25.4228],\n",
      "        [-28.6592,  29.9283, -25.9170],\n",
      "        [-27.8229,  29.4301, -24.9291],\n",
      "        [-27.8307,  29.1009, -25.5641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 28.7964,  24.7664,  25.1798, -28.4215,  29.7920, -25.7438],\n",
      "        [ 28.8496,  24.3473,  25.2107, -28.5454,  29.6536, -25.7216],\n",
      "        [ 29.6447,  25.1889,  25.7461, -28.0708,  29.4920, -25.4228],\n",
      "        [ 29.0980,  24.9181,  25.3225, -28.6592,  29.9283, -25.9170],\n",
      "        [ 29.5380,  25.2778,  25.3810, -27.8229,  29.4301, -24.9291],\n",
      "        [ 29.1834,  24.5373,  25.3064, -27.8307,  29.1009, -25.5641]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.105603218078613\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.1751, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.5447, 25.0373, 25.7582],\n",
      "        [29.8406, 25.4426, 26.1355],\n",
      "        [29.5875, 24.8282, 25.5969],\n",
      "        [29.4851, 24.8872, 25.0217],\n",
      "        [29.7431, 25.0302, 25.7349],\n",
      "        [28.9795, 24.9689, 25.7107]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.0806, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-27.4893,  28.8705, -24.8103],\n",
      "        [-28.1132,  29.2848, -25.5479],\n",
      "        [-28.3134,  29.4770, -25.5838],\n",
      "        [-28.3691,  29.4377, -25.6746],\n",
      "        [-28.3186,  28.8965, -25.3487],\n",
      "        [-28.7863,  29.6369, -25.7279]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.5447,  25.0373,  25.7582, -27.4893,  28.8705, -24.8103],\n",
      "        [ 29.8406,  25.4426,  26.1355, -28.1132,  29.2848, -25.5479],\n",
      "        [ 29.5875,  24.8282,  25.5969, -28.3134,  29.4770, -25.5838],\n",
      "        [ 29.4851,  24.8872,  25.0217, -28.3691,  29.4377, -25.6746],\n",
      "        [ 29.7431,  25.0302,  25.7349, -28.3186,  28.8965, -25.3487],\n",
      "        [ 28.9795,  24.9689,  25.7107, -28.7863,  29.6369, -25.7279]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.086069583892822\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(1.3305, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.4422, 24.9630, 25.6451],\n",
      "        [29.4748, 25.3884, 25.7832],\n",
      "        [30.1988, 25.5786, 25.8796],\n",
      "        [29.2872, 24.7684, 25.1105],\n",
      "        [29.3041, 24.8052, 24.8350],\n",
      "        [29.3758, 24.6592, 25.7494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.6115, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.5421,  29.7936, -25.3595],\n",
      "        [-28.9456,  30.0688, -25.8181],\n",
      "        [-28.4964,  29.4171, -25.6565],\n",
      "        [-28.3405,  29.1954, -24.8273],\n",
      "        [-29.0782,  30.1290, -25.7374],\n",
      "        [-28.5783,  29.3074, -25.5784]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.4422,  24.9630,  25.6451, -28.5421,  29.7936, -25.3595],\n",
      "        [ 29.4748,  25.3884,  25.7832, -28.9456,  30.0688, -25.8181],\n",
      "        [ 30.1988,  25.5786,  25.8796, -28.4964,  29.4171, -25.6565],\n",
      "        [ 29.2872,  24.7684,  25.1105, -28.3405,  29.1954, -24.8273],\n",
      "        [ 29.3041,  24.8052,  24.8350, -29.0782,  30.1290, -25.7374],\n",
      "        [ 29.3758,  24.6592,  25.7494, -28.5783,  29.3074, -25.5784]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.170560836791992\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.8322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0967, 24.6420, 24.9034],\n",
      "        [29.6877, 25.2080, 25.4820],\n",
      "        [29.6793, 25.6345, 25.8404],\n",
      "        [29.4104, 24.8536, 25.5838],\n",
      "        [29.5238, 25.3016, 25.4656],\n",
      "        [29.3313, 24.8506, 25.5197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.5191, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.1232,  29.0437, -25.2709],\n",
      "        [-28.4183,  29.4915, -25.5575],\n",
      "        [-28.6725,  29.9368, -25.9120],\n",
      "        [-28.5368,  29.7854, -25.8373],\n",
      "        [-28.3685,  29.3471, -25.5070],\n",
      "        [-28.3876,  29.5241, -25.7902]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0967,  24.6420,  24.9034, -28.1232,  29.0437, -25.2709],\n",
      "        [ 29.6877,  25.2080,  25.4820, -28.4183,  29.4915, -25.5575],\n",
      "        [ 29.6793,  25.6345,  25.8404, -28.6725,  29.9368, -25.9120],\n",
      "        [ 29.4104,  24.8536,  25.5838, -28.5368,  29.7854, -25.8373],\n",
      "        [ 29.5238,  25.3016,  25.4656, -28.3685,  29.3471, -25.5070],\n",
      "        [ 29.3313,  24.8506,  25.5197, -28.3876,  29.5241, -25.7902]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.052643299102783\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.2006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.8374, 25.7215, 26.0671],\n",
      "        [28.5655, 24.2681, 24.6655],\n",
      "        [29.1187, 24.9600, 25.1974],\n",
      "        [29.4747, 25.0077, 25.3882],\n",
      "        [29.7285, 25.1289, 25.4160],\n",
      "        [29.6527, 25.2749, 25.7745]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(39.1904, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.6858,  29.6615, -25.6399],\n",
      "        [-28.9267,  29.5878, -25.7075],\n",
      "        [-28.9026,  30.1580, -26.2618],\n",
      "        [-28.8084,  29.8068, -25.8396],\n",
      "        [-27.7778,  29.0074, -25.0398],\n",
      "        [-28.8261,  30.1262, -25.6232]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.8374,  25.7215,  26.0671, -28.6858,  29.6615, -25.6399],\n",
      "        [ 28.5655,  24.2681,  24.6655, -28.9267,  29.5878, -25.7075],\n",
      "        [ 29.1187,  24.9600,  25.1974, -28.9026,  30.1580, -26.2618],\n",
      "        [ 29.4747,  25.0077,  25.3882, -28.8084,  29.8068, -25.8396],\n",
      "        [ 29.7285,  25.1289,  25.4160, -27.7778,  29.0074, -25.0398],\n",
      "        [ 29.6527,  25.2749,  25.7745, -28.8261,  30.1262, -25.6232]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:-7.25870418548584\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.7402, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.6216, 24.4576, 25.5923],\n",
      "        [29.8774, 25.6431, 26.0495],\n",
      "        [29.2977, 24.9809, 25.5186],\n",
      "        [29.7391, 25.3073, 26.1094],\n",
      "        [29.4141, 25.1447, 25.4114],\n",
      "        [29.2952, 25.0679, 25.9913]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(58.5700, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-29.1873,  30.1541, -26.4645],\n",
      "        [-28.8337,  29.6196, -26.0694],\n",
      "        [-28.5826,  30.0485, -25.8523],\n",
      "        [-28.0860,  28.9091, -24.8004],\n",
      "        [-28.5168,  30.0130, -25.9532],\n",
      "        [-29.3297,  30.1394, -26.3611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.6216,  24.4576,  25.5923, -29.1873,  30.1541, -26.4645],\n",
      "        [ 29.8774,  25.6431,  26.0495, -28.8337,  29.6196, -26.0694],\n",
      "        [ 29.2977,  24.9809,  25.5186, -28.5826,  30.0485, -25.8523],\n",
      "        [ 29.7391,  25.3073,  26.1094, -28.0860,  28.9091, -24.8004],\n",
      "        [ 29.4141,  25.1447,  25.4114, -28.5168,  30.0130, -25.9532],\n",
      "        [ 29.2952,  25.0679,  25.9913, -29.3297,  30.1394, -26.3611]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.241481304168701\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(2.3140, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0159, 24.8222, 25.6870],\n",
      "        [30.2761, 25.4129, 25.9963],\n",
      "        [29.4229, 25.0562, 25.2179],\n",
      "        [29.5013, 25.0625, 25.8585],\n",
      "        [28.9732, 24.4182, 25.3733],\n",
      "        [28.8484, 24.4278, 25.3824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(38.3276, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.7639,  29.9041, -25.4110],\n",
      "        [-28.3531,  29.5230, -25.5182],\n",
      "        [-29.1473,  30.1998, -26.5920],\n",
      "        [-28.0272,  29.2887, -25.2496],\n",
      "        [-28.6281,  29.5607, -25.5583],\n",
      "        [-29.2899,  30.3644, -26.4335]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0159,  24.8222,  25.6870, -28.7639,  29.9041, -25.4110],\n",
      "        [ 30.2761,  25.4129,  25.9963, -28.3531,  29.5230, -25.5182],\n",
      "        [ 29.4229,  25.0562,  25.2179, -29.1473,  30.1998, -26.5920],\n",
      "        [ 29.5013,  25.0625,  25.8585, -28.0272,  29.2887, -25.2496],\n",
      "        [ 28.9732,  24.4182,  25.3733, -28.6281,  29.5607, -25.5583],\n",
      "        [ 28.8484,  24.4278,  25.3824, -29.2899,  30.3644, -26.4335]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.1654558181762695\n",
      "<class 'dict'>\n",
      "[SequenceClassifierOutput(loss=tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[29.0770, 24.3461, 24.5861],\n",
      "        [29.3080, 24.9295, 25.5329],\n",
      "        [29.6430, 25.3152, 25.4896],\n",
      "        [29.6075, 25.1387, 25.5302],\n",
      "        [29.6500, 25.0909, 25.8557],\n",
      "        [29.3715, 25.7391, 25.7814]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None), SequenceClassifierOutput(loss=tensor(47.3318, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-28.8807,  30.2262, -25.9247],\n",
      "        [-28.2096,  29.5301, -25.5133],\n",
      "        [-28.2632,  29.4534, -25.5387],\n",
      "        [-28.8252,  30.3062, -26.0819],\n",
      "        [-28.4573,  29.1518, -25.4084],\n",
      "        [-28.6869,  30.0118, -25.9651]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)]\n",
      "Printing last hidden states\n",
      "tensor([[ 29.0770,  24.3461,  24.5861, -28.8807,  30.2262, -25.9247],\n",
      "        [ 29.3080,  24.9295,  25.5329, -28.2096,  29.5301, -25.5133],\n",
      "        [ 29.6430,  25.3152,  25.4896, -28.2632,  29.4534, -25.5387],\n",
      "        [ 29.6075,  25.1387,  25.5302, -28.8252,  30.3062, -26.0819],\n",
      "        [ 29.6500,  25.0909,  25.8557, -28.4573,  29.1518, -25.4084],\n",
      "        [ 29.3715,  25.7391,  25.7814, -28.6869,  30.0118, -25.9651]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n",
      "epoch:1, loss:-7.1319122314453125\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# standard pytorch way of doing things\n",
    "# 1. create a custom Dataset \n",
    "# 2. pass the dataset to a dataloader\n",
    "# 3. iterate the dataloader and pass the inputs to the model\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 6\n",
    "grad_step = 1\n",
    "initialization_input = (max_len, batch_size)\n",
    "\n",
    "model1_tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased', add_prefix_space=True)\n",
    "model2_tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased', add_prefix_space=True)\n",
    "\n",
    "#Reading datasets and initializing data loaders\n",
    "dataset_location = '../2022.07.07_task5/'\n",
    "\n",
    "#Gives us tweet_id, sentence, and label for each dataset.\n",
    "train_data = read_task5(dataset_location , split = 'train')\n",
    "#test_data = read_task5(dataset_location , split = 'dev')#load test set\n",
    "labels_to_ids = task5_labels_to_ids\n",
    "#input_data = (train_data, dev_data, labels_to_ids)\n",
    "\n",
    "dataloader_m1 = initialize_data(model1_tokenizer, initialization_input, train_data, labels_to_ids, shuffle = True)\n",
    "dataloader_m2 = initialize_data(model2_tokenizer, initialization_input, train_data, labels_to_ids, shuffle = True)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "  # iterate the QA and the AQ inputs simultaneously\n",
    "  for step, combined_batch in enumerate(zip(dataloader_m1, dataloader_m2)):\n",
    "    batch_1, batch_2 = combined_batch\n",
    "    # training so, dropout needed to avoid overfitting\n",
    "    model.train()\n",
    "    # move input to GPU\n",
    "    inputs = {\n",
    "        \"input_ids\": [batch_1['input_ids'], batch_2['input_ids']],\n",
    "        \"attention_mask\": [batch_1['attention_mask'], batch_2['attention_mask']],\n",
    "        \"labels\": [batch_1['labels'], batch_2['labels']]}\n",
    "    print(type(inputs))\n",
    "    \n",
    "    output = model(**inputs)\n",
    "     \n",
    "# model outputs are always tuple in transformers (see doc)\n",
    "    loss = output[0][2]\n",
    " \n",
    "    # backpass\n",
    "    loss.backward()\n",
    "    print(f\"epoch:{epoch}, loss:{loss}\")\n",
    "    \n",
    "    # re-calculate the weights\n",
    "    optimizer.step()\n",
    "    # again set the grads to 0 for next epoch\n",
    "    model.zero_grad()\n",
    "  \n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9f608",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfbbc545",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8eacf03abee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 3. iterate the dataloader and pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_ids_m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks_m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_m1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_dataset_m1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks_m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_data' is not defined"
     ]
    }
   ],
   "source": [
    "# standard pytorch way of doing things\n",
    "# 1. create a custom Dataset \n",
    "# 2. pass the dataset to a dataloader\n",
    "# 3. iterate the dataloader and pass the inputs to the model\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 6\n",
    "grad_step = 1\n",
    "initialization_input = (max_len, batch_size)\n",
    "\n",
    "#Reading datasets and initializing data loaders\n",
    "dataset_location = '../2022.07.07_task5/'\n",
    "\n",
    "#Gives us tweet_id, sentence, and label for each dataset.\n",
    "train_data = read_task5(dataset_location , split = 'dev')\n",
    "#test_data = read_task5(dataset_location , split = 'dev')#load test set\n",
    "labels_to_ids = task5_labels_to_ids\n",
    "#input_data = (train_data, dev_data, labels_to_ids)\n",
    "\n",
    "dataloader_m1 = initialize_data(model1_tokenizer, initialization_input, train_data, labels_to_ids, shuffle = False)\n",
    "dataloader_m2 = initialize_data(model2_tokenizer, initialization_input, train_data, labels_to_ids, shuffle = False)\n",
    "\n",
    "\n",
    "complete_outputs, complete_label_ids = [], []\n",
    "\n",
    "# iterate the QA and the AQ inputs simultaneously\n",
    "for step, combined_batch in enumerate(zip(dataloader_m1, dataloader_m2)):\n",
    "  # only forward pass so no dropout\n",
    "  model.eval()\n",
    "  batch_1, batch_2 = combined_batch\n",
    "\n",
    "\n",
    "  # no back pass so no need to track variables for differentiation\n",
    "  with torch.no_grad():\n",
    "    inputs = {\n",
    "        \"input_ids\": [batch_1[0].to(device, dtype = torch.long), batch_2[0].to(device, dtype = torch.long)],\n",
    "        \"attention_mask\": [batch_1[1].to(device, dtype = torch.long), batch_2[1].to(device, dtype = torch.long)],\n",
    "        \"labels\": [batch_1[2].to(device, dtype = torch.long), batch_2[2].to(device, dtype = torch.long)]\n",
    "    }\n",
    "    outputs = model(**inputs)\n",
    "    tmp_eval_loss, logits = outputs[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "  complete_outputs.extend(outputs)\n",
    "  complete_label_ids.extend(label_ids)\n",
    "\n",
    "print(complete_outputs, complete_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9d522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
